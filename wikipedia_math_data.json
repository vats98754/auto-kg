{
  "Mathematics": {
    "title": "Mathematics",
    "url": "https://en.wikipedia.org/wiki/Mathematics",
    "summary": "Mathematics is a field of study that discovers and organizes methods, theories and theorems that are developed and proved for the needs of empirical sciences and mathematics itself. There are many areas of mathematics, which include number theory (the study of numbers), algebra (the study of formulas and related structures), geometry (the study of shapes and spaces that contain them), analysis (the study of continuous changes), and set theory (presently used as a foundation for all mathematics).\nMathematics involves the description and manipulation of abstract objects that consist of either abstractions from nature or—in modern mathematics—purely abstract entities that are stipulated to have certain properties, called axioms.  Mathematics uses pure reason to prove properties of objects, a proof consisting of a succession of applications of deductive rules to already established results. These results include previously proved theorems, axioms, and—in case of abstraction from nature—som",
    "content": "Mathematics is a field of study that discovers and organizes methods, theories and theorems that are developed and proved for the needs of empirical sciences and mathematics itself. There are many areas of mathematics, which include number theory (the study of numbers), algebra (the study of formulas and related structures), geometry (the study of shapes and spaces that contain them), analysis (the study of continuous changes), and set theory (presently used as a foundation for all mathematics).\nMathematics involves the description and manipulation of abstract objects that consist of either abstractions from nature or—in modern mathematics—purely abstract entities that are stipulated to have certain properties, called axioms.  Mathematics uses pure reason to prove properties of objects, a proof consisting of a succession of applications of deductive rules to already established results. These results include previously proved theorems, axioms, and—in case of abstraction from nature—some basic properties that are considered true starting points of the theory under consideration.\nMathematics is essential in the natural sciences, engineering, medicine, finance, computer science, and the social sciences. Although mathematics is extensively used for modeling phenomena, the fundamental truths of mathematics are independent of any scientific experimentation. Some areas of mathematics, such as statistics and game theory, are developed in close correlation with their applications and are often grouped under applied mathematics. Other areas are developed independently from any application (and are therefore called pure mathematics) but often later find practical applications.\nHistorically, the concept of a proof and its associated mathematical rigour first appeared in Greek mathematics, most notably in Euclid's Elements. Since its beginning, mathematics was primarily divided into geometry and arithmetic (the manipulation of natural numbers and fractions), until the 16th and 17th centuries, when algebra and infinitesimal calculus were introduced as new fields. Since then, the interaction between mathematical innovations and scientific discoveries has led to a correlated increase in the development of both. At the end of the 19th century, the foundational crisis of mathematics led to the systematization of the axiomatic method, which heralded a dramatic increase in the number of mathematical areas and their fields of application. The contemporary Mathematics Subject Classification lists more than sixty first-level areas of mathematics.\n\nAreas of mathematics\nBefore the Renaissance, mathematics was divided into two main areas: arithmetic, regarding the manipulation of numbers, and geometry, regarding the study of shapes. Some types of pseudoscience, such as numerology and astrology, were not then clearly distinguished from mathematics.\nDuring the Renaissance, two more areas appeared. Mathematical notation led to algebra which, roughly speaking, consists of the study and the manipulation of formulas. Calculus, consisting of the two subfields differential calculus and integral calculus, is the study of continuous functions, which model the typically nonlinear relationships between varying quantities, as represented by variables. This division into four main areas—arithmetic, geometry, algebra, and calculus—endured until the end of the 19th century. Areas such as celestial mechanics and solid mechanics were then studied by mathematicians, but now are considered as belonging to physics. The subject of combinatorics has been studied for much of recorded history, yet did not become a separate branch of mathematics until the seventeenth century.\nAt the end of the 19th century, the foundational crisis in mathematics and the resulting systematization of the axiomatic method led to an explosion of new areas of mathematics. The 2020 Mathematics Subject Classification contains no less than sixty-three first-level areas. Some of these areas correspond to the older division, as is true regarding number theory (the modern name for higher arithmetic) and geometry. Several other first-level areas have \"geometry\" in their names or are otherwise commonly considered part of geometry. Algebra and calculus do not appear as first-level areas but are respectively split into several first-level areas. Other first-level areas emerged during the 20th century or had not previously been considered as mathematics, such as mathematical logic and foundations.\n\nNumber theory\nNumber theory began with the manipulation of numbers, that is, natural numbers \n  \n    \n      \n        (\n        \n          N\n        \n        )\n        ,\n      \n    \n    {\\displaystyle (\\mathbb {N} ),}\n  \n and later expanded to integers \n  \n    \n      \n        (\n        \n          Z\n        \n        )\n      \n    \n    {\\displaystyle (\\mathbb {Z} )}\n  \n and rational numbers \n  \n    \n      \n        (\n        \n          Q\n        \n        )\n        .\n      \n    \n    {\\displaystyle (\\ma",
    "links": [
      "A Mathematician's Apology",
      "Abel Prize",
      "Abstract algebra",
      "Abstraction (mathematics)",
      "Accountant",
      "Actually infinite",
      "Actuary",
      "Addison-Wesley Publishing Company",
      "Addition",
      "Adrien-Marie Legendre",
      "Advances in Mathematics",
      "Aesthetic",
      "Affine geometry",
      "Al-Jabr",
      "Al-Khwarizmi",
      "Alan Sokal",
      "Albert Einstein",
      "Alfred Tarski",
      "Algebra",
      "Algebraic geometry",
      "Algebraic number theory",
      "Algebraic structure",
      "Algebraic topology",
      "Algorithm",
      "American Mathematical Society",
      "Amir Alexander",
      "Amy Roth McDuffie",
      "Analysis (mathematics)",
      "Analytic geometry",
      "Analytic number theory",
      "Ancient China",
      "Ancient Egypt",
      "Ancient Greek",
      "Ancient Greek mathematicians",
      "Ancient Greeks",
      "Ancient Near East",
      "Andrew Wiles",
      "André Weil",
      "Angle",
      "Apery's theorem",
      "Apodictic",
      "Apollonius of Perga",
      "Applied mathematics",
      "Approximation",
      "Approximation theory",
      "ArXiv (identifier)",
      "Arabic",
      "Archimedes",
      "Architecture",
      "Archive.today"
    ],
    "categories": [
      "Category:All Wikipedia articles written in American English",
      "Category:All articles with failed verification",
      "Category:Articles containing Ancient Greek (to 1453)-language text",
      "Category:Articles containing Greek-language text",
      "Category:Articles containing Latin-language text",
      "Category:Articles with failed verification from October 2024",
      "Category:Articles with short description",
      "Category:CS1 German-language sources (de)",
      "Category:CS1 errors: ISBN date",
      "Category:Formal sciences"
    ]
  },
  "Algebra": {
    "title": "Algebra",
    "url": "https://en.wikipedia.org/wiki/Algebra",
    "summary": "Algebra is a branch of mathematics that deals with abstract systems, known as algebraic structures, and the manipulation of expressions within those systems. It is a generalization of arithmetic that introduces variables and algebraic operations other than the standard arithmetic operations, such as addition and multiplication.\nElementary algebra is the main form of algebra taught in schools. It examines mathematical statements using variables for unspecified values and seeks to determine for which values the statements are true. To do so, it uses different methods of transforming equations to isolate variables. Linear algebra is a closely related field that investigates linear equations and combinations of them called systems of linear equations. It provides methods to find the values that solve all equations in the system at the same time, and to study the set of these solutions.\nAbstract algebra studies algebraic structures, which consist of a set of mathematical objects together wi",
    "content": "Algebra is a branch of mathematics that deals with abstract systems, known as algebraic structures, and the manipulation of expressions within those systems. It is a generalization of arithmetic that introduces variables and algebraic operations other than the standard arithmetic operations, such as addition and multiplication.\nElementary algebra is the main form of algebra taught in schools. It examines mathematical statements using variables for unspecified values and seeks to determine for which values the statements are true. To do so, it uses different methods of transforming equations to isolate variables. Linear algebra is a closely related field that investigates linear equations and combinations of them called systems of linear equations. It provides methods to find the values that solve all equations in the system at the same time, and to study the set of these solutions.\nAbstract algebra studies algebraic structures, which consist of a set of mathematical objects together with one or several operations defined on that set. It is a generalization of elementary and linear algebra since it allows mathematical objects other than numbers and non-arithmetic operations. It distinguishes between different types of algebraic structures, such as groups, rings, and fields, based on the number of operations they use and the laws they follow, called axioms. Universal algebra and category theory provide general frameworks to investigate abstract patterns that characterize different classes of algebraic structures.\nAlgebraic methods were first studied in the ancient period to solve specific problems in fields like geometry. Subsequent mathematicians examined general techniques to solve equations independent of their specific applications. They described equations and their solutions using words and abbreviations until the 16th and 17th centuries when a rigorous symbolic formalism was developed. In the mid-19th century, the scope of algebra broadened beyond a theory of equations to cover diverse types of algebraic operations and structures. Algebra is relevant to many branches of mathematics, such as geometry, topology, number theory, and calculus, and other fields of inquiry, like logic and the empirical sciences.\n\nDefinition and etymology\nAlgebra is the branch of mathematics that studies algebraic structures and the operations they use. An algebraic structure is a non-empty set of mathematical objects, such as the integers, together with algebraic operations defined on that set, like addition and multiplication. Algebra explores the laws, general characteristics, and types of algebraic structures. Within certain algebraic structures, it examines the use of variables in equations and how to manipulate these equations.\nAlgebra is often understood as a generalization of arithmetic. Arithmetic studies operations like addition, subtraction, multiplication, and division, in a particular domain of numbers, such as the real numbers. Elementary algebra constitutes the first level of abstraction. Like arithmetic, it restricts itself to specific types of numbers and operations. It generalizes these operations by allowing indefinite quantities in the form of variables in addition to numbers. A higher level of abstraction is found in abstract algebra, which is not limited to a particular domain and examines algebraic structures such as groups and rings. It extends beyond typical arithmetic operations by also covering other types of operations. Universal algebra is still more abstract in that it is not interested in specific algebraic structures but investigates the characteristics of algebraic structures in general.\n\nThe term \"algebra\" is sometimes used in a more narrow sense to refer only to elementary algebra or only to abstract algebra. When used as a countable noun, an algebra is a specific type of algebraic structure that involves a vector space equipped with a certain type of binary operation, a bilinear map. Depending on the context, \"algebra\" can also refer to other algebraic structures, like a Lie algebra or an associative algebra.\nThe word algebra comes from the Arabic term الجبر (al-jabr), which originally referred to the surgical treatment of bonesetting. In the 9th century, the term received a mathematical meaning when Muhammad ibn Musa al-Khwarizmi employed it to name a method for transforming equations and used it in the title of his treatise al-Kitāb al-Mukhtaṣar fī Ḥisāb al-Jabr wal-Muqābalah [The Compendious Book on Calculation by Completion and Balancing] which was translated into Latin as Liber Algebrae et Almucabola. The word entered the English language in the 16th century from Italian, Spanish, and medieval Latin. Initially, its meaning was restricted to the theory of equations, that is, to the art of manipulating polynomial equations in view of solving them. This changed in the 19th century when the scope of algebra broadened to cover the study of diverse types of algebraic operations and structures",
    "links": [
      "Abelian group",
      "Abel–Ruffini theorem",
      "Abstract algebra",
      "Addition",
      "Affine space",
      "Al-Jabr",
      "Al-Khwarizmi",
      "Alfred North Whitehead",
      "Algebra (disambiguation)",
      "Algebra over a field",
      "Algebraic closure",
      "Algebraic combinatorics",
      "Algebraic equation",
      "Algebraic expression",
      "Algebraic geometry",
      "Algebraic logic",
      "Algebraic number theory",
      "Algebraic operation",
      "Algebraic operations",
      "Algebraic structure",
      "Algebraic structures",
      "Algebraic topology",
      "Algebraic varieties",
      "Algebraic variety",
      "Analytic geometry",
      "Analytic number theory",
      "Ancient China",
      "Ancient Egypt",
      "Ancient Greece",
      "Ancient India",
      "Ancient period",
      "Applied mathematics",
      "Arabic",
      "Arithmetic",
      "Arithmetic geometry",
      "Arithmetica",
      "Ars Magna (Cardano book)",
      "Artificial intelligence",
      "Associative",
      "Associative algebra",
      "Associative property",
      "Automorphism",
      "Axiom",
      "Axioms",
      "Babylonia",
      "Balance scales",
      "Basis (linear algebra)",
      "Bhāskara II",
      "Bijective",
      "Bilinear map"
    ],
    "categories": [
      "Category:Algebra",
      "Category:Articles containing Arabic-language text",
      "Category:Articles containing Latin-language text",
      "Category:Articles with short description",
      "Category:CS1 German-language sources (de)",
      "Category:Featured articles",
      "Category:Pages using multiple image with auto scaled images",
      "Category:Short description is different from Wikidata",
      "Category:Use mdy dates from August 2024"
    ]
  },
  "Calculus": {
    "title": "Calculus",
    "url": "https://en.wikipedia.org/wiki/Calculus",
    "summary": "Calculus is the mathematical study of continuous change, in the same way that geometry is the study of shape, and algebra is the study of generalizations of arithmetic operations.\nOriginally called infinitesimal calculus or \"the calculus of infinitesimals\", it has two major branches, differential calculus and integral calculus. The former concerns instantaneous rates of change, and the slopes of curves, while the latter concerns accumulation of quantities, and areas under or between curves. These two branches are related to each other by the fundamental theorem of calculus. They make use of the fundamental notions of convergence of infinite sequences and infinite series to a well-defined limit. It is the \"mathematical backbone\" for dealing with problems where variables change with time or another reference variable.\nInfinitesimal calculus was formulated separately in the late 17th century by Isaac Newton and Gottfried Wilhelm Leibniz. Later work, including codifying the idea of limits,",
    "content": "Calculus is the mathematical study of continuous change, in the same way that geometry is the study of shape, and algebra is the study of generalizations of arithmetic operations.\nOriginally called infinitesimal calculus or \"the calculus of infinitesimals\", it has two major branches, differential calculus and integral calculus. The former concerns instantaneous rates of change, and the slopes of curves, while the latter concerns accumulation of quantities, and areas under or between curves. These two branches are related to each other by the fundamental theorem of calculus. They make use of the fundamental notions of convergence of infinite sequences and infinite series to a well-defined limit. It is the \"mathematical backbone\" for dealing with problems where variables change with time or another reference variable.\nInfinitesimal calculus was formulated separately in the late 17th century by Isaac Newton and Gottfried Wilhelm Leibniz. Later work, including codifying the idea of limits, put these developments on a more solid conceptual footing. The concepts and techniques found in calculus have diverse applications in science, engineering, and other branches of mathematics.\n\nEtymology\nIn mathematics education, calculus is an abbreviation of both infinitesimal calculus and integral calculus, which denotes courses of elementary mathematical analysis. \nIn Latin, the word calculus means “small pebble”, (the diminutive of calx, meaning \"stone\"), a meaning which still persists in medicine. Because such pebbles were used for counting out distances, tallying votes, and doing abacus arithmetic, the word came to be the Latin word for calculation. In this sense, it was used in English at least as early as 1672, several years before the publications of Leibniz and Newton, who wrote their mathematical texts in Latin.\nIn addition to differential calculus and integral calculus, the term is also used for naming specific methods of computation or theories that imply some sort of computation. Examples of this usage include propositional calculus, Ricci calculus, calculus of variations, lambda calculus, sequent calculus, and process calculus. Furthermore, the term \"calculus\" has variously been applied in ethics and philosophy, for such systems as Bentham's felicific calculus, and the ethical calculus.\n\nHistory\nModern calculus was developed in 17th-century Europe by Isaac Newton and Gottfried Wilhelm Leibniz (independently of each other, first publishing around the same time) but elements of it first appeared in ancient Egypt and later Greece, then in China and the Middle East, and still later again in medieval Europe and India.\n\nAncient precursors\nEgypt\nCalculations of volume and area, one goal of integral calculus, can be found in the Egyptian Moscow papyrus (c. 1820 BC), but the formulae are simple instructions, with no indication as to how they were obtained.\n\nGreece\nLaying the foundations for integral calculus and foreshadowing the concept of the limit, ancient Greek mathematician Eudoxus of Cnidus (c. 390–337 BC) developed the method of exhaustion to prove the formulas for cone and pyramid volumes.\nDuring the Hellenistic period, this method was further developed by Archimedes (c. 287 – c. 212 BC), who combined it with a concept of the indivisibles—a precursor to infinitesimals—allowing him to solve several problems now treated by integral calculus. In The Method of Mechanical Theorems he describes, for example, calculating the center of gravity of a solid hemisphere, the center of gravity of a frustum of a circular paraboloid, and the area of a region bounded by a parabola and one of its secant lines.\n\nChina\nThe method of exhaustion was later discovered independently in China by Liu Hui in the 3rd century AD to find the area of a circle. In the 5th century AD, Zu Gengzhi, son of Zu Chongzhi, established a method that would later be called Cavalieri's principle to find the volume of a sphere.\n\nMedieval\nMiddle East\nIn the Middle East, Hasan Ibn al-Haytham, Latinized as Alhazen (c. 965 – c. 1040 AD) derived a formula for the sum of fourth powers. He determined the equations to calculate the area enclosed by the curve represented by \n  \n    \n      \n        y\n        =\n        \n          x\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle y=x^{k}}\n  \n (which translates to the integral \n  \n    \n      \n        ∫\n        \n          x\n          \n            k\n          \n        \n        \n        d\n        x\n      \n    \n    {\\displaystyle \\int x^{k}\\,dx}\n  \n in contemporary notation), for any given non-negative integer value of \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n.He used the results to carry out what would now be called an integration of this function, where the formulae for the sums of integral squares and fourth powers allowed him to calculate the volume of a paraboloid.\n\nIndia\nBhāskara II (c. 1114–1185) was acquainted with some ideas of differential calculus and suggested tha",
    "links": [
      "(ε, δ)-definition of limit",
      "A Biography of Maria Gaetana Agnesi",
      "A History of Western Philosophy",
      "Abacus",
      "Abel's test",
      "Abraham Robinson",
      "Abraham de Moivre",
      "Absolute space and time",
      "Abstract algebra",
      "Acceleration",
      "Actuarial science",
      "Adequality",
      "Agnes Scott College",
      "Albert Einstein",
      "Algebra",
      "Algebraic geometry",
      "Algebraic number theory",
      "Algebraic topology",
      "Alternating series",
      "Alternating series test",
      "American Mathematical Society",
      "An Historical Account of Two Notable Corruptions of Scripture",
      "Analyse des Infiniment Petits pour l'Intelligence des Lignes Courbes",
      "Analytic function",
      "Analytic geometry",
      "Analytic number theory",
      "Ancient Greek",
      "Andrew M. Gleason",
      "André Weil",
      "Annette Imhausen",
      "Antiderivative",
      "Antonella Cupillari",
      "Apostrophe",
      "Applied mathematics",
      "Arc length",
      "Archimedes",
      "Archimedes use of infinitesimals",
      "Area",
      "Areas of mathematics",
      "Arithmetic",
      "Arithmetic geometry",
      "Arithmetic operations",
      "Arithmetica Universalis",
      "Arithmetico-geometric sequence",
      "Arithmetico–geometric sequence",
      "Astronomers Monument",
      "Augustin-Louis Cauchy",
      "Axiom",
      "BBC",
      "Basel problem"
    ],
    "categories": [
      "Category:Articles with Arabic-language sources (ar)",
      "Category:Articles with short description",
      "Category:Calculus",
      "Category:Pages using Sister project links with default search",
      "Category:Pages using multiple image with auto scaled images",
      "Category:Pages using sidebar with the child parameter",
      "Category:Short description is different from Wikidata",
      "Category:Use dmy dates from September 2024",
      "Category:Webarchive template wayback links",
      "Category:Wikipedia articles incorporating a citation from the 1911 Encyclopaedia Britannica with Wikisource reference"
    ]
  },
  "Geometry": {
    "title": "Geometry",
    "url": "https://en.wikipedia.org/wiki/Geometry",
    "summary": "Geometry (from Ancient Greek  γεωμετρία (geōmetría) 'land measurement'; from  γῆ (gê) 'earth, land' and  μέτρον (métron) 'a measure') is a branch of mathematics concerned with properties of space such as the distance, shape, size, and relative position of figures. Geometry is, along with arithmetic, one of the oldest branches of mathematics. A mathematician who works in the field of geometry is called a geometer. Until the 19th century, geometry was almost exclusively devoted to Euclidean geometry, which includes the notions of point, line, plane, distance, angle, surface, and curve, as fundamental concepts.\nOriginally developed to model the physical world, geometry has applications in almost all sciences, and also in art, architecture, and other activities that are related to graphics. Geometry also has applications in areas of mathematics that are apparently unrelated. For example, methods of algebraic geometry are fundamental in Wiles's proof of Fermat's Last Theorem, a problem that",
    "content": "Geometry (from Ancient Greek  γεωμετρία (geōmetría) 'land measurement'; from  γῆ (gê) 'earth, land' and  μέτρον (métron) 'a measure') is a branch of mathematics concerned with properties of space such as the distance, shape, size, and relative position of figures. Geometry is, along with arithmetic, one of the oldest branches of mathematics. A mathematician who works in the field of geometry is called a geometer. Until the 19th century, geometry was almost exclusively devoted to Euclidean geometry, which includes the notions of point, line, plane, distance, angle, surface, and curve, as fundamental concepts.\nOriginally developed to model the physical world, geometry has applications in almost all sciences, and also in art, architecture, and other activities that are related to graphics. Geometry also has applications in areas of mathematics that are apparently unrelated. For example, methods of algebraic geometry are fundamental in Wiles's proof of Fermat's Last Theorem, a problem that was stated in terms of elementary arithmetic, and remained unsolved for several centuries.\nDuring the 19th century several discoveries enlarged dramatically the scope of geometry. One of the oldest such discoveries is Carl Friedrich Gauss's Theorema Egregium (\"remarkable theorem\") that asserts roughly that the Gaussian curvature of a surface is independent from any specific embedding in a Euclidean space. This implies that surfaces can be studied intrinsically, that is, as stand-alone spaces, and has been expanded into the theory of manifolds and Riemannian geometry. Later in the 19th century, it appeared that geometries without the parallel postulate (non-Euclidean geometries) can be developed without introducing any contradiction. The geometry that underlies general relativity is a famous application of non-Euclidean geometry.\nSince the late 19th century, the scope of geometry has been greatly expanded, and the field has been split in many subfields that depend on the underlying methods—differential geometry, algebraic geometry, computational geometry, algebraic topology, discrete geometry (also known as combinatorial geometry), etc.—or on the properties of Euclidean spaces that are disregarded—projective geometry that consider only alignment of points but not distance and parallelism, affine geometry that omits the concept of angle and distance, finite geometry that omits continuity, and others. This enlargement of the scope of geometry led to a change of meaning of the word \"space\", which originally referred to the three-dimensional space of the physical world and its model provided by Euclidean geometry; presently a geometric space, or simply a space is a mathematical structure on which some geometry is defined.\n\nHistory\nThe earliest recorded beginnings of geometry can be traced to ancient Mesopotamia and Egypt in the 2nd millennium BC. Early geometry was a collection of empirically discovered principles concerning lengths, angles, areas, and volumes, which were developed to meet some practical need in surveying, construction, astronomy, and various crafts. The earliest known texts on geometry are the Egyptian Rhind Papyrus (2000–1800 BC) and Moscow Papyrus (c. 1890 BC), and the Babylonian clay tablets, such as Plimpton 322 (1900 BC). For example, the Moscow Papyrus gives a formula for calculating the volume of a truncated pyramid, or frustum. Later clay tablets (350–50 BC) demonstrate that Babylonian astronomers implemented trapezoid procedures for computing Jupiter's position and motion within time-velocity space. These geometric procedures anticipated the Oxford Calculators, including the mean speed theorem, by 14 centuries. South of Egypt the ancient Nubians established a system of geometry including early versions of sun clocks.\nIn the 7th century BC, the Greek mathematician Thales of Miletus used geometry to solve problems such as calculating the height of pyramids and the distance of ships from the shore. He is credited with the first use of deductive reasoning applied to geometry, by deriving four corollaries to Thales's theorem. Pythagoras established the Pythagorean School, which is credited with the first proof of the Pythagorean theorem, though the statement of the theorem has a long history. Eudoxus (408–c. 355 BC) developed the method of exhaustion, which allowed the calculation of areas and volumes of curvilinear figures, as well as a theory of ratios that avoided the problem of incommensurable magnitudes, which enabled subsequent geometers to make significant advances. Around 300 BC, geometry was revolutionized by Euclid, whose Elements, widely considered the most successful and influential textbook of all time, introduced mathematical rigor through the axiomatic method and is the earliest example of the format still used in mathematics today, that of definition, axiom, theorem, and proof. Although most of the contents of the Elements were already known, Euclid arranged them into a single, coherent logica",
    "links": [
      "Absolute geometry",
      "Abstract algebra",
      "Acceleration",
      "Acylindrically hyperbolic group",
      "Aerodynamics",
      "Affine geometry",
      "Affine space",
      "Ahmes",
      "Al-Mahani",
      "Albert Einstein",
      "Alexander Grothendieck",
      "Alfred North Whitehead",
      "Algebra",
      "Algebraic curve",
      "Algebraic geometry",
      "Algebraic number theory",
      "Algebraic set",
      "Algebraic topology",
      "Algebraic varieties",
      "Algorithm",
      "Algorithms",
      "Alhazen",
      "Altitude (triangle)",
      "Amenable group",
      "Anabelian geometry",
      "Analytic geometry",
      "Analytic number theory",
      "Ancient Egypt",
      "Ancient Greece",
      "Ancient Greek language",
      "Angle",
      "Angular measure",
      "Apollonius of Perga",
      "Applied mathematics",
      "Arab",
      "Archimedes",
      "Archimedes spiral",
      "Architectural geometry",
      "Architecture",
      "Area",
      "Area of a circle",
      "Areas of mathematics",
      "Arithmetic",
      "Arithmetic geometry",
      "Aryabhata",
      "Aryabhatiya",
      "Astronomy",
      "Automatic group",
      "Axiom",
      "Axiomatic method"
    ],
    "categories": [
      "Category:Articles containing Latin-language text",
      "Category:Articles with excerpts",
      "Category:Articles with short description",
      "Category:CS1 errors: ISBN date",
      "Category:Geometry",
      "Category:Pages using Sister project links with default search",
      "Category:Pages using sidebar with the child parameter",
      "Category:Short description is different from Wikidata",
      "Category:Use dmy dates from August 2019",
      "Category:Webarchive template wayback links"
    ]
  },
  "Topology": {
    "title": "Topology",
    "url": "https://en.wikipedia.org/wiki/Topology",
    "summary": "Topology (from the Greek words τόπος, 'place, location', and λόγος, 'study') is the branch of mathematics concerned with the properties of a geometric object that are preserved under continuous deformations, such as stretching, twisting, crumpling, and bending; that is, without closing holes, opening holes, tearing, gluing, or passing through itself.\nA topological space is a set endowed with a structure, called a topology, which allows defining continuous deformation of subspaces, and, more generally, all kinds of continuity. Euclidean spaces, and, more generally, metric spaces are examples of topological spaces, as any distance or metric defines a topology. The deformations that are considered in topology are homeomorphisms and homotopies. A property that is invariant under such deformations is a topological property. The following are basic examples of topological properties: the dimension, which allows distinguishing between a line and a surface; compactness, which allows distinguis",
    "content": "Topology (from the Greek words τόπος, 'place, location', and λόγος, 'study') is the branch of mathematics concerned with the properties of a geometric object that are preserved under continuous deformations, such as stretching, twisting, crumpling, and bending; that is, without closing holes, opening holes, tearing, gluing, or passing through itself.\nA topological space is a set endowed with a structure, called a topology, which allows defining continuous deformation of subspaces, and, more generally, all kinds of continuity. Euclidean spaces, and, more generally, metric spaces are examples of topological spaces, as any distance or metric defines a topology. The deformations that are considered in topology are homeomorphisms and homotopies. A property that is invariant under such deformations is a topological property. The following are basic examples of topological properties: the dimension, which allows distinguishing between a line and a surface; compactness, which allows distinguishing between a line and a circle; connectedness, which allows distinguishing a circle from two non-intersecting circles.\nThe ideas underlying topology go back to Gottfried Wilhelm Leibniz, who in the 17th century envisioned the geometria situs and analysis situs. Leonhard Euler's Seven Bridges of Königsberg problem and polyhedron formula are arguably the field's first theorems. The term topology was introduced by Johann Benedict Listing in the 19th century, although, it was not until the first decades of the 20th century that the idea of a topological space was developed.\n\nMotivation\nThe motivating insight behind topology is that some geometric problems depend not on the exact shape of the objects involved, but rather on the way they are put together. For example, the square and the circle have many properties in common: they are both one-dimensional objects (from a topological point of view) and both separate the plane into two parts, the part inside and the part outside.\nIn one of the first papers in topology, Leonhard Euler demonstrated that it was impossible to find a route through the town of Königsberg (now Kaliningrad) that would cross each of its seven bridges exactly once. This result did not depend on the lengths of the bridges or on their distance from one another, but only on connectivity properties: which bridges connect to which islands or riverbanks. This Seven Bridges of Königsberg problem led to the branch of mathematics known as graph theory.\nSimilarly, the hairy ball theorem of algebraic topology says that \"one cannot comb the hair flat on a hairy ball without creating a cowlick.\" This fact is immediately convincing to most people, even though they might not recognize the more formal statement of the theorem, that there is no nonvanishing continuous tangent vector field on the sphere. As with the Bridges of Königsberg, the result does not depend on the shape of the sphere; it applies to any kind of smooth blob, as long as it has no holes.\nTo deal with these problems that do not rely on the exact shape of the objects, one must be clear about just what properties these problems do rely on. From this need arises the notion of homeomorphism. The impossibility of crossing each bridge just once applies to any arrangement of bridges homeomorphic to those in Königsberg, and the hairy ball theorem applies to any space homeomorphic to a sphere.\n\nIntuitively, two spaces are homeomorphic if one can be deformed into the other without cutting or gluing. A famous example, known as the \"Topologist's Breakfast\", is that a topologist cannot distinguish a coffee mug from a doughnut. A pliable torus (shaped like a doughnut) can be reshaped to a coffee mug by creating a dimple and progressively enlarging it while shrinking the central hole into the mug's handle.\nHomeomorphism can be considered the most basic topological equivalence. Another is homotopy equivalence. This is harder to describe without getting technical, but the essential notion is that two objects are homotopy equivalent if they both result from \"squishing\" some larger object.\n\nHistory\nTopology, as a well-defined mathematical discipline, originates in the early part of the twentieth century, but some isolated results can be traced back several centuries. Among these are certain questions in geometry investigated by Leonhard Euler. His 1736 paper on the Seven Bridges of Königsberg is regarded as one of the first practical applications of topology. On 14 November 1750, Euler wrote to a friend that he had realized the importance of the edges of a polyhedron. This led to his polyhedron formula, V − E + F = 2 (where V, E, and F respectively indicate the number of vertices, edges, and faces of the polyhedron). Some authorities regard this analysis as the first theorem, signaling the birth of topology.\nFurther contributions were made by Augustin-Louis Cauchy, Ludwig Schläfli, Johann Benedict Listing, Bernhard Riemann and Enrico Betti. Listing introduced the term \"Topolog",
    "links": [
      "Abel Prize",
      "Abstract algebra",
      "Alexander–Briggs notation",
      "Algebra",
      "Algebraic geometry",
      "Algebraic number theory",
      "Algebraic topology",
      "Analysis Situs (paper)",
      "Analytic geometry",
      "Analytic number theory",
      "Applied mathematics",
      "ArXiv (identifier)",
      "Arithmetic",
      "Arithmetic geometry",
      "Augustin-Louis Cauchy",
      "Banach fixed-point theorem",
      "Bernhard Riemann",
      "Betti number",
      "Bibcode (identifier)",
      "Boolean algebra (structure)",
      "Bundle (mathematics)",
      "CW complex",
      "Calabi–Yau manifold",
      "Calculus",
      "Cantor set",
      "Category theory",
      "Cesare Arzelà",
      "Characteristic classes",
      "Characterizations of the category of topological spaces",
      "Chern class",
      "Circle",
      "Circuit topology",
      "Classification theorem",
      "Clifford A. Pickover",
      "Clopen set",
      "Closed set",
      "Closure (mathematics)",
      "Cobordism",
      "Cohomology",
      "Colin Adams (mathematician)",
      "Combinatorial topology",
      "Combinatorics",
      "Commutative algebra",
      "Compact space",
      "Compactness",
      "Complex analysis",
      "Complex geometry",
      "Complex plane",
      "Compressive strength",
      "Computational complexity theory"
    ],
    "categories": [
      "Category:Articles containing Ancient Greek (to 1453)-language text",
      "Category:Articles containing Greek-language text",
      "Category:Articles containing Latin-language text",
      "Category:Articles with short description",
      "Category:Commons link is on Wikidata",
      "Category:Mathematical structures",
      "Category:Short description matches Wikidata",
      "Category:Topology",
      "Category:Use dmy dates from February 2022",
      "Category:Webarchive template wayback links"
    ]
  },
  "Number theory": {
    "title": "Number theory",
    "url": "https://en.wikipedia.org/wiki/Number_theory",
    "summary": "Number theory is a branch of pure mathematics devoted primarily to the study of the integers and arithmetic functions. Number theorists study prime numbers as well as the properties of mathematical objects constructed from integers (for example, rational numbers), or defined as generalizations of the integers (for example, algebraic integers). \nIntegers can be considered either in themselves or as solutions to equations (Diophantine geometry). Questions in number theory can often be understood through the study of analytical objects, such as the Riemann zeta function, that encode properties of the integers, primes or other number-theoretic objects in some fashion (analytic number theory). One may also study real numbers in relation to rational numbers, as for instance how irrational numbers can be approximated by fractions (Diophantine approximation).\nNumber theory is one of the oldest branches of mathematics alongside geometry.  One quirk of number theory is that it deals with stateme",
    "content": "Number theory is a branch of pure mathematics devoted primarily to the study of the integers and arithmetic functions. Number theorists study prime numbers as well as the properties of mathematical objects constructed from integers (for example, rational numbers), or defined as generalizations of the integers (for example, algebraic integers). \nIntegers can be considered either in themselves or as solutions to equations (Diophantine geometry). Questions in number theory can often be understood through the study of analytical objects, such as the Riemann zeta function, that encode properties of the integers, primes or other number-theoretic objects in some fashion (analytic number theory). One may also study real numbers in relation to rational numbers, as for instance how irrational numbers can be approximated by fractions (Diophantine approximation).\nNumber theory is one of the oldest branches of mathematics alongside geometry.  One quirk of number theory is that it deals with statements that are simple to understand but are very difficult to solve. Examples of this are Fermat's Last Theorem, which was proved 358 years after the original formulation, and Goldbach's conjecture, which remains unsolved since the 18th century. German mathematician Carl Friedrich Gauss (1777–1855) said, \"Mathematics is the queen of the sciences—and number theory is the queen of mathematics.\" It was regarded as the example of pure mathematics with no applications outside mathematics until the 1970s, when it became known that prime numbers would be used as the basis for the creation of public-key cryptography algorithms.\n\nHistory\nNumber theory is the branch of mathematics that studies integers and their properties and relations. The integers comprise a set that extends the set of natural numbers \n  \n    \n      \n        {\n        1\n        ,\n        2\n        ,\n        3\n        ,\n        …\n        }\n      \n    \n    {\\displaystyle \\{1,2,3,\\dots \\}}\n  \n to include number \n  \n    \n      \n        0\n      \n    \n    {\\displaystyle 0}\n  \n and the negation of natural numbers \n  \n    \n      \n        {\n        −\n        1\n        ,\n        −\n        2\n        ,\n        −\n        3\n        ,\n        …\n        }\n      \n    \n    {\\displaystyle \\{-1,-2,-3,\\dots \\}}\n  \n. Number theorists study prime numbers as well as the properties of mathematical objects constructed from integers (for example, rational numbers), or defined as generalizations of the integers (for example, algebraic integers).\nNumber theory is closely related to arithmetic and some authors use the terms as synonyms. However, the word \"arithmetic\" is used today to mean the study of numerical operations and extends to the real numbers. In a more specific sense, number theory is restricted to the study of integers and focuses on their properties and relationships. Traditionally, it is known as higher arithmetic. By the early twentieth century, the term number theory had been widely adopted. The term number means whole numbers, which refers to either the natural numbers or the integers.\nElementary number theory studies aspects of integers that can be investigated using elementary methods such as elementary proofs. Analytic number theory, by contrast, relies on complex numbers and techniques from analysis and calculus. Algebraic number theory employs algebraic structures such as fields and rings to analyze the properties of and relations between numbers. Geometric number theory uses concepts from geometry to study numbers. Further branches of number theory are probabilistic number theory, combinatorial number theory, computational number theory, and applied number theory, which examines the application of number theory to science and technology.\n\nOrigins\nIn recorded history, knowledge of numbers existed in the ancient civilisations of Mesopotamia, Egypt, China, and India. The earliest historical find of an arithmetical nature is the Plimpton 322, dated c. 1800 BC. It is a broken clay tablet that contains a list of Pythagorean triples, that is, integers \n  \n    \n      \n        (\n        a\n        ,\n        b\n        ,\n        c\n        )\n      \n    \n    {\\displaystyle (a,b,c)}\n  \n such that \n  \n    \n      \n        \n          a\n          \n            2\n          \n        \n        +\n        \n          b\n          \n            2\n          \n        \n        =\n        \n          c\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle a^{2}+b^{2}=c^{2}}\n  \n. The triples are too numerous and too large to have been obtained by brute force. The table's layout suggests that it was constructed by means of what amounts, in modern language, to the identity\n  \n    \n      \n        \n          \n            (\n            \n              \n                \n                  1\n                  2\n                \n              \n              \n                (\n                \n                  x\n                  −\n                  \n                    \n                      1\n    ",
    "links": [
      "0",
      "1",
      "ACM Computing Classification System",
      "A Mathematician's Apology",
      "Abelian group",
      "Abraham Sachs",
      "Abstract algebra",
      "Abū Rayḥān al-Bīrūnī",
      "Academic Press",
      "Académie des sciences",
      "Addition",
      "Additive number theory",
      "Adrien-Marie Legendre",
      "Al-Fazari",
      "Al-Haytham",
      "Al-Karajī",
      "Al-Ma'mun",
      "Algebra",
      "Algebraic curve",
      "Algebraic function field",
      "Algebraic geometry",
      "Algebraic integer",
      "Algebraic number",
      "Algebraic number field",
      "Algebraic number theory",
      "Algebraic structures",
      "Algebraic surface",
      "Algebraic topology",
      "Algorithm",
      "Algorithm design",
      "Algorithmic efficiency",
      "American Mathematical Society",
      "American Oriental Society",
      "Amicable numbers",
      "An Introduction to the Theory of Numbers",
      "Anabelian geometry",
      "Analysis of algorithms",
      "Analytic geometry",
      "Analytic number theory",
      "Andrew Granville",
      "André Weil",
      "Application security",
      "Applied mathematics",
      "ArXiv (identifier)",
      "Arakelov theory",
      "Areas of mathematics",
      "Argument (complex analysis)",
      "Arithmetic",
      "Arithmetic combinatorics",
      "Arithmetic dynamics"
    ],
    "categories": [
      "Category:Articles containing Chinese-language text",
      "Category:Articles containing Latin-language text",
      "Category:Articles with short description",
      "Category:CS1: long volume value",
      "Category:CS1 Chinese-language sources (zh)",
      "Category:CS1 French-language sources (fr)",
      "Category:CS1 German-language sources (de)",
      "Category:CS1 Latin-language sources (la)",
      "Category:Commons category link from Wikidata",
      "Category:Harv and Sfn no-target errors"
    ]
  },
  "Analysis": {
    "title": "Analysis",
    "url": "https://en.wikipedia.org/wiki/Analysis",
    "summary": "Analysis (pl.: analyses) is the process of breaking a complex topic or substance into smaller parts in order to gain a better understanding of it. The technique has been applied in the study of mathematics and logic since before Aristotle (384–322 BC), though analysis as a formal concept is a relatively recent development.\nThe word comes from the Ancient Greek ἀνάλυσις (analysis, \"a breaking-up\" or \"an untying\" from ana- \"up, throughout\" and lysis \"a loosening\"). From it also comes the word's plural, analyses.\nAs a formal concept, the method has variously been ascribed to René Descartes (Discourse on the Method), and Galileo Galilei. It has also been ascribed to Isaac Newton, in the form of a practical method of physical discovery (which he did not name).\nThe converse of analysis is synthesis: putting the pieces back together again in a new or different whole.",
    "content": "Analysis (pl.: analyses) is the process of breaking a complex topic or substance into smaller parts in order to gain a better understanding of it. The technique has been applied in the study of mathematics and logic since before Aristotle (384–322 BC), though analysis as a formal concept is a relatively recent development.\nThe word comes from the Ancient Greek ἀνάλυσις (analysis, \"a breaking-up\" or \"an untying\" from ana- \"up, throughout\" and lysis \"a loosening\"). From it also comes the word's plural, analyses.\nAs a formal concept, the method has variously been ascribed to René Descartes (Discourse on the Method), and Galileo Galilei. It has also been ascribed to Isaac Newton, in the form of a practical method of physical discovery (which he did not name).\nThe converse of analysis is synthesis: putting the pieces back together again in a new or different whole.\n\nScience and technology\nChemistry\nThe field of chemistry uses analysis in three ways: to identify the components of a particular chemical compound (qualitative analysis), to identify the proportions of components in a mixture (quantitative analysis), and to break down chemical processes and examine chemical reactions between elements of matter. For an example of its use, analysis of the concentration of elements is important in managing a nuclear reactor, so nuclear scientists will analyze neutron activation to develop discrete measurements within vast samples. A matrix can have a considerable effect on the way a chemical analysis is conducted and the quality of its results. Analysis can be done manually or with a device.\n\nTypes of Analysis\nQualitative Analysis\nIt is concerned with which components are in a given sample or compound.\nExample: Precipitation reaction\nQuantitative Analysis\nIt is to determine the quantity of individual component present in a given sample or compound.\nExample: To find concentration by uv-spectrophotometer.\n\nIsotopes\nChemists can use isotope analysis to assist analysts with issues in anthropology, archeology, food chemistry, forensics, geology, and a host of other questions of physical science. Analysts can discern the origins of natural and man-made isotopes in the study of environmental radioactivity.\n\nComputer science\nRequirements analysis – encompasses those tasks that go into determining the needs or conditions to meet for a new or altered product, taking account of the possibly conflicting requirements of the various stakeholders, such as beneficiaries or users.\nCompetitive analysis (online algorithm) – shows how online algorithms perform and demonstrates the power of randomization in algorithms\nLexical analysis – the process of processing an input sequence of characters and producing as output a sequence of symbols\nObject-oriented analysis and design – à la Booch\nProgram analysis (computer science) – the process of automatically analysing the behavior of computer programs\nSemantic analysis (computer science) – a pass by a compiler that adds semantical information to the parse tree and performs certain checks\nStatic code analysis – the analysis of computer software that is performed without actually executing programs built from that\nStructured systems analysis and design methodology – à la Yourdon\nSyntax analysis – a process in compilers that recognizes the structure of programming languages, also known as parsing\nWorst-case execution time – determines the longest time that a piece of software can take to run\n\nEngineering\nAnalysts in the field of engineering look at requirements, structures, mechanisms, systems and dimensions. Electrical engineers analyse systems in electronics. Life cycles and system failures are broken down and studied by engineers. It is also looking at different factors incorporated within the design.\n\nMathematics\nModern mathematical analysis is the study of infinite processes. It is the branch of mathematics that includes calculus.  It can be applied in the study of classical concepts of mathematics, such as real numbers, complex variables, trigonometric functions, and algorithms, or of non-classical concepts like constructivism, harmonics, infinity, and vectors.\nFlorian Cajori explains in A History of Mathematics (1893) the difference between modern and ancient mathematical analysis, as distinct from logical analysis, as follows:\n\nThe terms synthesis and analysis are used in mathematics in a more special sense than in logic. In ancient mathematics they had a different meaning from what they now have. The oldest definition of mathematical analysis as opposed to synthesis is that given in [appended to] Euclid, XIII. 5, which in all probability was framed by Eudoxus: \"Analysis is the obtaining of the thing sought by assuming it and so reasoning up to an admitted truth; synthesis is the obtaining of the thing sought by reasoning up to the inference and proof of it.\" \n\nThe analytic method is not conclusive, unless all operations involved in it are known to be reversible. To remove all doubt, the Gree",
    "links": [
      "Academic writing",
      "Accident analysis",
      "Action research",
      "Adriaen van Ostade",
      "Agroecosystem analysis",
      "Alliteration",
      "Analysis (Homer)",
      "Analysis (disambiguation)",
      "Analysis (journal)",
      "Analysis of variance",
      "Analytical chemistry",
      "Analyzer",
      "Ancient Greek",
      "Anthropological linguistics",
      "Anthropology",
      "Antipositivism",
      "Applied linguistics",
      "Archeology",
      "Argument",
      "Aristotle",
      "Art-based research",
      "Art methodology",
      "Aura analysis",
      "Autoethnography",
      "Bibliometrics",
      "Biolinguistics",
      "Booch method",
      "Boolean analysis",
      "Bowling analysis",
      "Brainstorming",
      "Business",
      "Business analysis",
      "Business intelligence",
      "Cartography",
      "Case study",
      "Chemical compound",
      "Chemical element",
      "Chemical matter",
      "Chemical process",
      "Chemical reaction",
      "Chemical synthesis",
      "Chemistry",
      "Cipher",
      "Citation",
      "Clinical linguistics",
      "Cluster analysis",
      "Code (cryptography)",
      "Competitive analysis (online algorithm)",
      "Competitive intelligence",
      "Competitor analysis"
    ],
    "categories": [
      "Category:Abstraction",
      "Category:All Wikipedia articles lacking focus",
      "Category:All articles lacking in-text citations",
      "Category:Analysis",
      "Category:Articles containing Ancient Greek (to 1453)-language text",
      "Category:Articles lacking in-text citations from December 2020",
      "Category:Articles with Stanford Encyclopedia of Philosophy links",
      "Category:Articles with multiple maintenance issues",
      "Category:Articles with short description",
      "Category:CS1 maint: DOI inactive as of July 2025"
    ]
  },
  "Statistics": {
    "title": "Statistics",
    "url": "https://en.wikipedia.org/wiki/Statistics",
    "summary": "Statistics (from German: Statistik, orig. \"description of a state, a country\") is the discipline that concerns the collection, organization, analysis, interpretation, and presentation of data. In applying statistics to a scientific, industrial, or social problem, it is conventional to begin with a statistical population or a statistical model to be studied. Populations can be diverse groups of people or objects such as \"all people living in a country\" or \"every atom composing a crystal\". Statistics deals with every aspect of data, including the planning of data collection in terms of the design of surveys and experiments.\nWhen census data (comprising every member of the target population) cannot be collected, statisticians collect data by developing specific experiment designs and survey samples. Representative sampling assures that inferences and conclusions can reasonably extend from the sample to the population as a whole. An experimental study involves taking measurements of the sy",
    "content": "Statistics (from German: Statistik, orig. \"description of a state, a country\") is the discipline that concerns the collection, organization, analysis, interpretation, and presentation of data. In applying statistics to a scientific, industrial, or social problem, it is conventional to begin with a statistical population or a statistical model to be studied. Populations can be diverse groups of people or objects such as \"all people living in a country\" or \"every atom composing a crystal\". Statistics deals with every aspect of data, including the planning of data collection in terms of the design of surveys and experiments.\nWhen census data (comprising every member of the target population) cannot be collected, statisticians collect data by developing specific experiment designs and survey samples. Representative sampling assures that inferences and conclusions can reasonably extend from the sample to the population as a whole. An experimental study involves taking measurements of the system under study, manipulating the system, and then taking additional measurements using the same procedure to determine if the manipulation has modified the values of the measurements. In contrast, an observational study does not involve experimental manipulation.\nTwo main statistical methods are used in data analysis: descriptive statistics, which summarize data from a sample using indexes such as the mean or standard deviation, and inferential statistics, which draw conclusions from data that are subject to random variation (e.g., observational errors, sampling variation). Descriptive statistics are most often concerned with two sets of properties of a distribution (sample or population): central tendency (or location) seeks to characterize the distribution's central or typical value, while dispersion (or variability) characterizes the extent to which members of the distribution depart from its center and each other. Inferences made using mathematical statistics employ the framework of probability theory, which deals with the analysis of random phenomena.\nA standard statistical procedure involves the collection of data leading to a test of the relationship between two statistical data sets, or a data set and synthetic data drawn from an idealized model. A hypothesis is proposed for the statistical relationship between the two data sets, an alternative to an idealized null hypothesis of no relationship between two data sets. Rejecting or disproving the null hypothesis is done using statistical tests that quantify the sense in which the null can be proven false, given the data that are used in the test. Working from a null hypothesis, two basic forms of error are recognized: Type I errors (null hypothesis is rejected when it is in fact true, giving a \"false positive\") and Type II errors (null hypothesis fails to be rejected when it is in fact false, giving a \"false negative\"). Multiple problems have come to be associated with this framework, ranging from obtaining a sufficient sample size to specifying an adequate null hypothesis.\nStatistical measurement processes are also prone to error in regards to the data that they generate. Many of these errors are classified as random (noise) or systematic (bias), but other types of errors (e.g., blunder, such as when an analyst reports incorrect units) can also occur. The presence of missing data or censoring may result in biased estimates and specific techniques have been developed to address these problems.\n\nIntroduction\n\"Statistics is both the science of uncertainty and the technology of extracting information from data.\" - featured in the International Encyclopedia of Statistical Science.Statistics is the discipline that deals with data, facts and figures with which meaningful information is inferred. Data may represent a numerical value, in form of quantitative data, or a label, as with qualitative data. Data may be collected, presented and summarised, in one of two methods called descriptive statistics. Two elementary summaries of data, singularly called a statistic, are the mean and dispersion. Whereas inferential statistics interprets data from a population sample to induce statements and predictions about a population.\nStatistics is regarded as a body of science or a branch of mathematics. It is based on probability, a branch of mathematics that studies random events. Statistics is considered the science of uncertainty. This arises from the ways to cope with measurement and sampling error as well as dealing with uncertanties in modelling. Although probability and statistics were once paired together as a single subject, they are conceptually distinct from one another. The former is based on deducing answers to specific situations from a general theory of probability, meanwhile statistics induces statements about a population based on a data set. Statistics serves to bridge the gap between probability and applied mathematical fields.\nSome consider statistics to be a distinct m",
    "links": [
      "A. W. F. Edwards",
      "Abstract algebra",
      "Abundance estimation",
      "Academic discipline",
      "Accelerated failure time model",
      "Actuarial science",
      "Adaptive clinical trial",
      "Adrien-Marie Legendre",
      "Akaike information criterion",
      "Al-Khalil ibn Ahmad al-Farahidi",
      "Al-Kindi",
      "Algebra",
      "Algebraic geometry",
      "Algebraic number theory",
      "Algebraic topology",
      "Algorithms",
      "Alternative hypothesis",
      "Analysis of covariance",
      "Analysis of variance",
      "Analytic geometry",
      "Analytic number theory",
      "Ancillary statistic",
      "Anderson–Darling test",
      "Applied mathematics",
      "Areas of mathematics",
      "Arithmetic",
      "Arithmetic geometry",
      "Arithmetic mean",
      "Arithmetic–geometric mean",
      "Ars Conjectandi",
      "Artificial neural network",
      "Assembly line",
      "Astrostatistics",
      "Asymptotic theory (statistics)",
      "Auditing",
      "Autocorrelation",
      "Autoregressive conditional heteroskedasticity",
      "Autoregressive–moving-average model",
      "Average absolute deviation",
      "Average treatment effect",
      "Bar chart",
      "Baseball statistics",
      "Bayes' theorem",
      "Bayes estimator",
      "Bayes factor",
      "Bayesian Statistics",
      "Bayesian hierarchical modeling",
      "Bayesian inference",
      "Bayesian information criterion",
      "Bayesian linear regression"
    ],
    "categories": [
      "Category:All articles needing additional references",
      "Category:Arab inventions",
      "Category:Articles containing Latin-language text",
      "Category:Articles needing additional references from December 2020",
      "Category:Articles with short description",
      "Category:CS1 German-language sources (de)",
      "Category:Data",
      "Category:Formal sciences",
      "Category:Information",
      "Category:Mathematical and quantitative methods (economics)"
    ]
  },
  "Probability theory": {
    "title": "Probability theory",
    "url": "https://en.wikipedia.org/wiki/Probability_theory",
    "summary": "Probability theory or probability calculus is the branch of mathematics concerned with probability. Although there are several different probability interpretations, probability theory treats the concept in a rigorous mathematical manner by expressing it through a set of axioms. Typically these axioms formalise probability in terms of a probability space, which assigns a measure taking values between 0 and 1, termed the probability measure, to a set of outcomes called the sample space. Any specified subset of the sample space is called an event.\nCentral subjects in probability theory include discrete and continuous random variables, probability distributions, and stochastic processes (which provide mathematical abstractions of non-deterministic or uncertain processes or measured quantities that may either be single occurrences or evolve over time in a random fashion).\nAlthough it is not possible to perfectly predict random events, much can be said about their behavior. Two major result",
    "content": "Probability theory or probability calculus is the branch of mathematics concerned with probability. Although there are several different probability interpretations, probability theory treats the concept in a rigorous mathematical manner by expressing it through a set of axioms. Typically these axioms formalise probability in terms of a probability space, which assigns a measure taking values between 0 and 1, termed the probability measure, to a set of outcomes called the sample space. Any specified subset of the sample space is called an event.\nCentral subjects in probability theory include discrete and continuous random variables, probability distributions, and stochastic processes (which provide mathematical abstractions of non-deterministic or uncertain processes or measured quantities that may either be single occurrences or evolve over time in a random fashion).\nAlthough it is not possible to perfectly predict random events, much can be said about their behavior. Two major results in probability theory describing such behaviour are the law of large numbers and the central limit theorem.\nAs a mathematical foundation for statistics, probability theory is essential to many human activities that involve quantitative analysis of data. Methods of probability theory also apply to descriptions of complex systems given only partial knowledge of their state, as in statistical mechanics or sequential estimation. A great discovery of twentieth-century physics was the probabilistic nature of physical phenomena at atomic scales, described in quantum mechanics.\n\nHistory of probability\nThe modern mathematical theory of probability has its roots in attempts to analyze games of chance by Gerolamo Cardano in the sixteenth century, and by Pierre de Fermat and Blaise Pascal in the seventeenth century (for example the \"problem of points\"). Christiaan Huygens published a book on the subject in 1657. In the 19th century, what is considered the classical definition of probability was completed by Pierre Laplace.\nInitially, probability theory mainly considered discrete events, and its methods were mainly combinatorial. Eventually, analytical considerations compelled the incorporation of continuous variables into the theory.\nThis culminated in modern probability theory, on foundations laid by Andrey Nikolaevich Kolmogorov. Kolmogorov combined the notion of sample space, introduced by Richard von Mises, and measure theory and presented his axiom system for probability theory in 1933. This became the mostly undisputed axiomatic basis for modern probability theory; but, alternatives exist, such as the adoption of finite rather than countable additivity by Bruno de Finetti.\n\nTreatment\nMost introductions to probability theory treat discrete probability distributions and continuous probability distributions separately. The measure theory-based treatment of probability covers the discrete, continuous, a mix of the two, and more.\n\nMotivation\nConsider an experiment that can produce a number of outcomes. The set of all outcomes is called the sample space of the experiment. The power set of the sample space (or equivalently, the event space) is formed by considering all different collections of possible results. For example, rolling an honest die produces one of six possible results. One collection of possible results corresponds to getting an odd number. Thus, the subset {1,3,5} is an element of the power set of the sample space of dice rolls. These collections are called events. In this case, {1,3,5} is the event that the die falls on some odd number. If the results that actually occur fall in a given event, that event is said to have occurred.\nProbability is a way of assigning every \"event\" a value between zero and one, with the requirement that the event made up of all possible results (in our example, the event {1,2,3,4,5,6}) be assigned a value of one. To qualify as a probability distribution, the assignment of values must satisfy the requirement that if you look at a collection of mutually exclusive events (events that contain no common results, e.g., the events {1,6}, {3}, and {2,4} are all mutually exclusive), the probability that any of these events occurs is given by the sum of the probabilities of the events.\nThe probability that any one of the events {1,6}, {3}, or {2,4} will occur is 5/6. This is the same as saying that the probability of event {1,2,3,4,6} is 5/6. This event encompasses the possibility of any number except five being rolled. The mutually exclusive event {5} has a probability of 1/6, and the event {1,2,3,4,5,6} has a probability of 1, that is, absolute certainty.\nWhen doing calculations using the outcomes of an experiment, it is necessary that all those elementary events have a number assigned to them. This is done using a random variable. A random variable is a function that assigns to each elementary event in the sample space a real number. This function is usually denoted by a capital letter. In the case o",
    "links": [
      "Absolutely continuous",
      "Abstract algebra",
      "Algebra",
      "Algebra of physical space",
      "Algebraic geometry",
      "Algebraic number theory",
      "Algebraic structure",
      "Algebraic topology",
      "Algorithm",
      "Algorithm design",
      "Almost surely",
      "Analysis of algorithms",
      "Analytic geometry",
      "Analytic number theory",
      "Analytical mechanics",
      "Andrey Kolmogorov",
      "Andrey Nikolaevich Kolmogorov",
      "Applied mathematics",
      "Approximation theory",
      "Arithmetic",
      "Arithmetic geometry",
      "Automata theory",
      "Automated theorem proving",
      "Average",
      "Axiom system",
      "Axioms of probability",
      "Bayes' theorem",
      "Belmont, California",
      "Bernoulli distribution",
      "Bernoulli process",
      "Bernoulli trial",
      "Berry–Esseen theorem",
      "Bertrand's paradox (probability)",
      "Beta distribution",
      "Binomial distribution",
      "Blaise Pascal",
      "Boole's inequality",
      "Borel algebra",
      "Bosonic string theory",
      "Brownian motion",
      "Bruno de Finetti",
      "Calculus",
      "Calculus of variations",
      "Cambridge University Press",
      "Cantor distribution",
      "Catalog of articles in probability theory",
      "Category theory",
      "Central limit theorem",
      "Chaos theory",
      "Christiaan Huygens"
    ],
    "categories": [
      "Category:All articles lacking in-text citations",
      "Category:Articles lacking in-text citations from September 2009",
      "Category:Articles with short description",
      "Category:CS1 errors: ISBN date",
      "Category:CS1 maint: publisher location",
      "Category:Pages displaying short descriptions of redirect targets via Module:Annotated link",
      "Category:Probability theory",
      "Category:Short description matches Wikidata"
    ]
  },
  "Linear algebra": {
    "title": "Linear algebra",
    "url": "https://en.wikipedia.org/wiki/Linear_algebra",
    "summary": "Linear algebra is the branch of mathematics concerning linear equations such as\n\n  \n    \n      \n        \n          a\n          \n            1\n          \n        \n        \n          x\n          \n            1\n          \n        \n        +\n        ⋯\n        +\n        \n          a\n          \n            n\n          \n        \n        \n          x\n          \n            n\n          \n        \n        =\n        b\n        ,\n      \n    \n    {\\displaystyle a_{1}x_{1}+\\cdots +a_{n}x_{n}=b,}\n  \n\nlinear maps such as\n\n  \n    \n      \n        (\n        \n          x\n          \n            1\n          \n        \n        ,\n        …\n        ,\n        \n          x\n          \n            n\n          \n        \n        )\n        ↦\n        \n          a\n          \n            1\n          \n        \n        \n          x\n          \n            1\n          \n        \n        +\n        ⋯\n        +\n        \n          a\n          \n            n\n          \n        \n        \n          x\n          \n            n\n         ",
    "content": "Linear algebra is the branch of mathematics concerning linear equations such as\n\n  \n    \n      \n        \n          a\n          \n            1\n          \n        \n        \n          x\n          \n            1\n          \n        \n        +\n        ⋯\n        +\n        \n          a\n          \n            n\n          \n        \n        \n          x\n          \n            n\n          \n        \n        =\n        b\n        ,\n      \n    \n    {\\displaystyle a_{1}x_{1}+\\cdots +a_{n}x_{n}=b,}\n  \n\nlinear maps such as\n\n  \n    \n      \n        (\n        \n          x\n          \n            1\n          \n        \n        ,\n        …\n        ,\n        \n          x\n          \n            n\n          \n        \n        )\n        ↦\n        \n          a\n          \n            1\n          \n        \n        \n          x\n          \n            1\n          \n        \n        +\n        ⋯\n        +\n        \n          a\n          \n            n\n          \n        \n        \n          x\n          \n            n\n          \n        \n        ,\n      \n    \n    {\\displaystyle (x_{1},\\ldots ,x_{n})\\mapsto a_{1}x_{1}+\\cdots +a_{n}x_{n},}\n  \n\nand their representations in vector spaces and through matrices.\n\nLinear algebra is central to almost all areas of mathematics. For instance, linear algebra is fundamental in modern presentations of geometry, including for defining basic objects such as lines, planes and rotations. Also, functional analysis, a branch of mathematical analysis, may be viewed as the application of linear algebra to function spaces.\nLinear algebra is also used in most sciences and fields of engineering because it allows modeling many natural phenomena, and computing efficiently with such models. For nonlinear systems, which cannot be modeled with linear algebra, it is often used for dealing with first-order approximations, using the fact that the differential of a multivariate function at a point is the linear map that best approximates the function near that point.\n\nHistory\nThe procedure (using counting rods) for solving simultaneous linear equations now called Gaussian elimination appears in the ancient Chinese mathematical text Chapter Eight: Rectangular Arrays of The Nine Chapters on the Mathematical Art. Its use is illustrated in eighteen problems, with two to five equations.\nSystems of linear equations arose in Europe with the introduction in 1637 by René Descartes of coordinates in geometry. In fact, in this new geometry, now called Cartesian geometry, lines and planes are represented by linear equations, and computing their intersections amounts to solving systems of linear equations.\nThe first systematic methods for solving linear systems used determinants and were first considered by Leibniz in 1693. In 1750, Gabriel Cramer used them for giving explicit solutions of linear systems, now called Cramer's rule. Later, Gauss further described the method of elimination, which was initially listed as an advancement in geodesy.\nIn 1844 Hermann Grassmann published his \"Theory of Extension\" which included foundational new topics of what is today called linear algebra. In 1848, James Joseph Sylvester introduced the term matrix, which is Latin for womb.\nLinear algebra grew with ideas noted in the complex plane. For instance, two numbers w and z in \n  \n    \n      \n        \n          C\n        \n      \n    \n    {\\displaystyle \\mathbb {C} }\n  \n have a difference w – z, and the line segments wz and 0(w − z) are of the same length and direction. The segments are equipollent. The four-dimensional system \n  \n    \n      \n        \n          H\n        \n      \n    \n    {\\displaystyle \\mathbb {H} }\n  \n of quaternions was discovered by W.R. Hamilton in 1843. The term vector was introduced as v = xi + yj + zk representing a point in space. The quaternion difference p – q also produces a segment equipollent to pq. Other hypercomplex number systems also used the idea of a linear space with a basis.\nArthur Cayley introduced matrix multiplication and the inverse matrix in 1856, making possible the general linear group. The mechanism of group representation became available for describing complex and hypercomplex numbers. Crucially, Cayley used a single letter to denote a matrix, thus treating a matrix as an aggregate object. He also realized the connection between matrices and determinants and wrote \"There would be many things to say about this theory of matrices which should, it seems to me, precede the theory of determinants\".\nBenjamin Peirce published his Linear Associative Algebra (1872), and his son Charles Sanders Peirce extended the work later.\nThe telegraph required an explanatory system, and the 1873 publication by James Clerk Maxwell of A Treatise on Electricity and Magnetism instituted a field theory of forces and required differential geometry for expression. Linear algebra is flat differential geometry and serves in tangent spaces to manifolds. Electromagnetic symmetries of spacetime are expressed by the Lorentz transformations, and much of",
    "links": [
      "3Blue1Brown",
      "A Treatise on Electricity and Magnetism",
      "Abelian group",
      "Abstract algebra",
      "Additive inverse",
      "Affine space",
      "Algebra",
      "Algebra over a field",
      "Algebraic geometry",
      "Algebraic number theory",
      "Algebraic topology",
      "Algorithm",
      "Ambient space",
      "American Mathematical Society",
      "Analytic geometry",
      "Analytic number theory",
      "Ann Arbor, Michigan",
      "Applied mathematics",
      "Arithmetic",
      "Arithmetic geometry",
      "Arthur Cayley",
      "Associativity",
      "Atlanta, Georgia",
      "Atmosphere",
      "Augmented matrix",
      "Axiom",
      "Banach space",
      "Basic Linear Algebra Subprograms",
      "Basis (linear algebra)",
      "Benjamin Peirce",
      "Bidual",
      "Bijection",
      "Bijective",
      "Bilinear form",
      "Bilinear map",
      "Binary operation",
      "Bivector",
      "Block matrix",
      "Bra–ket notation",
      "Brisbane, Australia",
      "Cache (computing)",
      "Calculus",
      "Canonical map",
      "Cardinality",
      "Cartesian coordinates",
      "Cartesian geometry",
      "Category theory",
      "Cauchy–Schwarz inequality",
      "Change of basis",
      "Characteristic polynomial"
    ],
    "categories": [
      "Category:All pages needing cleanup",
      "Category:Articles needing cleanup from September 2018",
      "Category:Articles with short description",
      "Category:Cleanup tagged articles with a reason field from September 2018",
      "Category:Commons category link from Wikidata",
      "Category:Linear algebra",
      "Category:Numerical analysis",
      "Category:Short description is different from Wikidata",
      "Category:Wikipedia pages needing cleanup from September 2018"
    ]
  },
  "Abstract algebra": {
    "title": "Abstract algebra",
    "url": "https://en.wikipedia.org/wiki/Abstract_algebra",
    "summary": "In mathematics, more specifically algebra, abstract algebra or modern algebra is the study of algebraic structures, which are sets with specific operations acting on their elements. Algebraic structures include groups, rings, fields, modules, vector spaces, lattices, and algebras over a field. The term abstract algebra was coined in the early 20th century to distinguish it from older parts of algebra, and more specifically from elementary algebra, the use of variables to represent numbers in computation and reasoning. The abstract perspective on algebra has become so fundamental to advanced mathematics that it is simply called \"algebra\", while the term \"abstract algebra\" is seldom used except in pedagogy.\nAlgebraic structures, with their associated homomorphisms, form mathematical categories. Category theory gives a unified framework to study properties and constructions that are similar for various structures.\nUniversal algebra is a related subject that studies types of algebraic stru",
    "content": "In mathematics, more specifically algebra, abstract algebra or modern algebra is the study of algebraic structures, which are sets with specific operations acting on their elements. Algebraic structures include groups, rings, fields, modules, vector spaces, lattices, and algebras over a field. The term abstract algebra was coined in the early 20th century to distinguish it from older parts of algebra, and more specifically from elementary algebra, the use of variables to represent numbers in computation and reasoning. The abstract perspective on algebra has become so fundamental to advanced mathematics that it is simply called \"algebra\", while the term \"abstract algebra\" is seldom used except in pedagogy.\nAlgebraic structures, with their associated homomorphisms, form mathematical categories. Category theory gives a unified framework to study properties and constructions that are similar for various structures.\nUniversal algebra is a related subject that studies types of algebraic structures as single objects. For example, the structure of groups is a single object in universal algebra, which is called the variety of groups.\n\nHistory\nBefore the nineteenth century, algebra was defined as the study of polynomials. Abstract algebra came into existence during the nineteenth century as more complex problems and solution methods developed. Concrete problems and examples came from number theory, geometry, analysis, and the solutions of algebraic equations. Most theories that are now recognized as parts of abstract algebra started as collections of disparate facts from various branches of mathematics, acquired a common theme that served as a core around which various results were grouped, and finally became unified on a basis of a common set of concepts. This unification occurred in the early decades of the 20th century and resulted in the formal axiomatic definitions of various algebraic structures such as groups, rings, and fields. This historical development is almost the opposite of the treatment found in popular textbooks, such as van der Waerden's Moderne Algebra, which start each chapter with a formal definition of a structure and then follow it with concrete examples.\n\nElementary algebra\nThe study of polynomial equations or algebraic equations has a long history. Circa 1700 BC, the Babylonians were able to solve quadratic equations specified as word problems. This word problem stage is classified as rhetorical algebra and was the dominant approach up to the 16th century. Al-Khwarizmi originated the word \"algebra\" in 830 AD, but his work was entirely rhetorical algebra. Fully symbolic algebra did not appear until François Viète's 1591 New Algebra, and even this had some spelled out words that were given symbols in Descartes's 1637 La Géométrie. The formal study of solving symbolic equations led Leonhard Euler to accept what were then considered \"nonsense\" roots such as negative numbers and imaginary numbers, in the late 18th century. However, European mathematicians, for the most part, resisted these concepts until the middle of the 19th century.\nGeorge Peacock's 1830 Treatise of Algebra was the first attempt to place algebra on a strictly symbolic basis. He distinguished a new symbolical algebra, distinct from the old arithmetical algebra. Whereas in arithmetical algebra \n  \n    \n      \n        a\n        −\n        b\n      \n    \n    {\\displaystyle a-b}\n  \n is restricted to \n  \n    \n      \n        a\n        ≥\n        b\n      \n    \n    {\\displaystyle a\\geq b}\n  \n, in symbolical algebra all rules of operations hold with no restrictions. Using this Peacock could show laws such as \n  \n    \n      \n        (\n        −\n        a\n        )\n        (\n        −\n        b\n        )\n        =\n        a\n        b\n      \n    \n    {\\displaystyle (-a)(-b)=ab}\n  \n, by letting \n  \n    \n      \n        a\n        =\n        0\n        ,\n        c\n        =\n        0\n      \n    \n    {\\displaystyle a=0,c=0}\n  \n in \n  \n    \n      \n        (\n        a\n        −\n        b\n        )\n        (\n        c\n        −\n        d\n        )\n        =\n        a\n        c\n        +\n        b\n        d\n        −\n        a\n        d\n        −\n        b\n        c\n      \n    \n    {\\displaystyle (a-b)(c-d)=ac+bd-ad-bc}\n  \n. Peacock used what he termed the principle of the permanence of equivalent forms to justify his argument, but his reasoning suffered from the problem of induction. For example, \n  \n    \n      \n        \n          \n            a\n          \n        \n        \n          \n            b\n          \n        \n        =\n        \n          \n            a\n            b\n          \n        \n      \n    \n    {\\displaystyle {\\sqrt {a}}{\\sqrt {b}}={\\sqrt {ab}}}\n  \n holds for the nonnegative real numbers, but not for general complex numbers.\n\nEarly group theory\nSeveral areas of mathematics led to the study of groups. Lagrange's 1770 study of the solutions of the quintic equation led to the Galois group of a polynomial. Gauss's 1801 study of Fermat's litt",
    "links": [
      "Abelian group",
      "Abraham Fraenkel",
      "Abstrakt Algebra",
      "Addition",
      "Affine space",
      "Al-Khwarizmi",
      "Algebra",
      "Algebra (Lang)",
      "Algebra over a field",
      "Algebraic equation",
      "Algebraic equations",
      "Algebraic expression",
      "Algebraic function",
      "Algebraic function field",
      "Algebraic geometry",
      "Algebraic integer",
      "Algebraic number theory",
      "Algebraic structure",
      "Algebraic topology",
      "Algebraic variety",
      "Analytic geometry",
      "Analytic number theory",
      "Andrew Wiles",
      "Applied mathematics",
      "Arithmetic",
      "Arithmetic geometry",
      "Arithmetical algebra",
      "Arthur Cayley",
      "Artin–Wedderburn theorem",
      "Ascending chain condition",
      "Associative algebra",
      "Auguste Dick",
      "Automorphism",
      "Axiom",
      "Axiomatic system",
      "Bartel van der Waerden",
      "Basis (linear algebra)",
      "Benjamin Peirce",
      "Binary operation",
      "Binary quadratic form",
      "Biquadratic reciprocity",
      "Biquaternion",
      "Birkhäuser",
      "Boolean algebra (structure)",
      "Boson",
      "Calculus",
      "Cancellation property",
      "Category (mathematics)",
      "Category theory",
      "Characteristic (algebra)"
    ],
    "categories": [
      "Category:Abstract algebra",
      "Category:All articles with unsourced statements",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from March 2023",
      "Category:CS1 German-language sources (de)",
      "Category:CS1 Latin-language sources (la)",
      "Category:CS1 maint: location missing publisher",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Differential equations": {
    "title": "Differential equation",
    "url": "https://en.wikipedia.org/wiki/Differential_equation",
    "summary": "In mathematics, a differential equation is an equation that relates one or more unknown functions and their derivatives. In applications, the functions generally represent physical quantities, the derivatives represent their rates of change, and the differential equation defines a relationship between the two. Such relations are common in mathematical models and scientific laws; therefore, differential equations play a prominent role in many disciplines including engineering, physics, economics, and biology.\nThe study of differential equations consists mainly of the study of their solutions (the set of functions that satisfy each equation), and of the properties of their solutions. Only the simplest differential equations are solvable by explicit formulas; however, many properties of solutions of a given differential equation may be determined without computing them exactly.\nOften when a closed-form expression for the solutions is not available, solutions may be approximated numericall",
    "content": "In mathematics, a differential equation is an equation that relates one or more unknown functions and their derivatives. In applications, the functions generally represent physical quantities, the derivatives represent their rates of change, and the differential equation defines a relationship between the two. Such relations are common in mathematical models and scientific laws; therefore, differential equations play a prominent role in many disciplines including engineering, physics, economics, and biology.\nThe study of differential equations consists mainly of the study of their solutions (the set of functions that satisfy each equation), and of the properties of their solutions. Only the simplest differential equations are solvable by explicit formulas; however, many properties of solutions of a given differential equation may be determined without computing them exactly.\nOften when a closed-form expression for the solutions is not available, solutions may be approximated numerically using computers, and many numerical methods have been developed to determine solutions with a given degree of accuracy. The theory of dynamical systems analyzes the qualitative aspects of solutions, such as their average behavior over a long time interval.\n\nHistory\nDifferential equations came into existence with the invention of calculus by Isaac Newton and Gottfried Leibniz. In Chapter 2 of his 1671 work Methodus fluxionum et Serierum Infinitarum, Newton listed three kinds of differential equations:\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      d\n                      y\n                    \n                    \n                      d\n                      x\n                    \n                  \n                \n              \n              \n                \n                =\n                f\n                (\n                x\n                )\n              \n            \n            \n              \n                \n                  \n                    \n                      d\n                      y\n                    \n                    \n                      d\n                      x\n                    \n                  \n                \n              \n              \n                \n                =\n                f\n                (\n                x\n                ,\n                y\n                )\n              \n            \n            \n              \n                \n                  x\n                  \n                    1\n                  \n                \n                \n                  \n                    \n                      ∂\n                      y\n                    \n                    \n                      ∂\n                      \n                        x\n                        \n                          1\n                        \n                      \n                    \n                  \n                \n              \n              \n                \n                +\n                \n                  x\n                  \n                    2\n                  \n                \n                \n                  \n                    \n                      ∂\n                      y\n                    \n                    \n                      ∂\n                      \n                        x\n                        \n                          2\n                        \n                      \n                    \n                  \n                \n                =\n                y\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}{\\frac {dy}{dx}}&=f(x)\\\\[4pt]{\\frac {dy}{dx}}&=f(x,y)\\\\[4pt]x_{1}{\\frac {\\partial y}{\\partial x_{1}}}&+x_{2}{\\frac {\\partial y}{\\partial x_{2}}}=y\\end{aligned}}}\n  \n\nIn all these cases, y is an unknown function of x (or of x1 and x2), and f is a given function.\nHe solves these examples and others using infinite series and discusses the non-uniqueness of solutions.\nJacob Bernoulli proposed the Bernoulli differential equation in 1695. This is an ordinary differential equation of the form\n\n  \n    \n      \n        \n          y\n          ′\n        \n        +\n        P\n        (\n        x\n        )\n        y\n        =\n        Q\n        (\n        x\n        )\n        \n          y\n          \n            n\n          \n        \n        \n      \n    \n    {\\displaystyle y'+P(x)y=Q(x)y^{n}\\,}\n  \n\nfor which the following year Leibniz obtained solutions by simplifying it.\nHistorically, the problem of a vibrating string such as that of a musical instrument was studied by Jean le Rond d'Alembert, Leonhard Euler, Daniel Bernoulli, and Joseph-Louis Lagrange. In 1746, d’Alembert discovered the one-dimensional wave equation, and within ten years Euler discovered the three-dimensional wave equation.\nThe Euler–Lagrange equation was developed in the 1750s by Euler and Lagrange in connection with their studies of the tautochrone ",
    "links": [
      "Abstract algebra",
      "Abstract differential equation",
      "Acta Eruditorum",
      "Algebra",
      "Algebraic equations",
      "Algebraic geometry",
      "Algebraic number theory",
      "Algebraic topology",
      "American Journal of Physics",
      "American Mathematical Society",
      "Analytic geometry",
      "Analytic number theory",
      "Antiderivative",
      "Applied mathematics",
      "Arithmetic",
      "Arithmetic geometry",
      "Astronomy",
      "Asymptotic stability",
      "Augustin-Louis Cauchy",
      "Autonomous differential equation",
      "Autonomous system (mathematics)",
      "Bernoulli differential equation",
      "Bibcode (identifier)",
      "Bill Schelter",
      "Biology",
      "Black–Scholes",
      "Boundary value problem",
      "Calculus",
      "Calculus of variations",
      "Carathéodory's existence theorem",
      "Carl David Tolmé Runge",
      "Category theory",
      "Cauchy problem",
      "Cauchy–Kowalevski theorem",
      "Chaos theory",
      "Chemistry",
      "Classical mechanics",
      "Closed-form expression",
      "Combinatorics",
      "Commutative algebra",
      "Complex analysis",
      "Complex system",
      "Computational complexity theory",
      "Computational mathematics",
      "Computer algebra",
      "Computer algebra system",
      "Computer model",
      "Computer science",
      "Continuous function",
      "Continuum mechanics"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1 French-language sources (fr)",
      "Category:Commons category link is on Wikidata",
      "Category:Differential equations",
      "Category:Short description is different from Wikidata",
      "Category:Webarchive template wayback links"
    ]
  },
  "Complex analysis": {
    "title": "Complex analysis",
    "url": "https://en.wikipedia.org/wiki/Complex_analysis",
    "summary": "Complex analysis, traditionally known as the theory of functions of a complex variable, is the branch of mathematical analysis that investigates functions of complex numbers. It is helpful in many branches of mathematics, including algebraic geometry, number theory, analytic combinatorics, and applied mathematics, as well as in physics, including the branches of hydrodynamics, thermodynamics, quantum mechanics, and twistor theory. By extension, use of complex analysis also has applications in engineering fields such as nuclear, aerospace, mechanical and electrical engineering.\nAs a differentiable function of a complex variable is equal to the sum function given by its Taylor series (that is, it is analytic), complex analysis is particularly concerned with analytic functions of a complex variable, that is, holomorphic functions. \nThe concept can be extended to functions of several complex variables.\nComplex analysis is contrasted with real analysis, which deals with the study of real nu",
    "content": "Complex analysis, traditionally known as the theory of functions of a complex variable, is the branch of mathematical analysis that investigates functions of complex numbers. It is helpful in many branches of mathematics, including algebraic geometry, number theory, analytic combinatorics, and applied mathematics, as well as in physics, including the branches of hydrodynamics, thermodynamics, quantum mechanics, and twistor theory. By extension, use of complex analysis also has applications in engineering fields such as nuclear, aerospace, mechanical and electrical engineering.\nAs a differentiable function of a complex variable is equal to the sum function given by its Taylor series (that is, it is analytic), complex analysis is particularly concerned with analytic functions of a complex variable, that is, holomorphic functions. \nThe concept can be extended to functions of several complex variables.\nComplex analysis is contrasted with real analysis, which deals with the study of real numbers and functions of a real variable.\n\nHistory\nComplex analysis is one of the classical branches in mathematics, with roots in the 18th century and just prior. Important mathematicians associated with complex numbers include Euler, Gauss, Riemann, Cauchy, Weierstrass, and many more in the 20th century. Complex analysis, in particular the theory of conformal mappings, has many physical applications and is also used throughout analytic number theory. In modern times, it has become very popular through a new boost from complex dynamics and the pictures of fractals produced by iterating holomorphic functions.  Another important application of complex analysis is in string theory which examines conformal invariants in quantum field theory.\n\nComplex functions\nA complex function is a function from complex numbers to complex numbers. In other words, it is a function that has a (not necessarily proper) subset of the complex numbers as a domain and the complex numbers as a codomain. Complex functions are generally assumed to have a domain that contains a nonempty open subset of the complex plane.\nFor any complex function, the values \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n  \n from the domain and their images \n  \n    \n      \n        f\n        (\n        z\n        )\n      \n    \n    {\\displaystyle f(z)}\n  \n in the range may be separated into real and imaginary parts:\n\n  \n    \n      \n        z\n        =\n        x\n        +\n        i\n        y\n        \n        \n           and \n        \n        \n        f\n        (\n        z\n        )\n        =\n        f\n        (\n        x\n        +\n        i\n        y\n        )\n        =\n        u\n        (\n        x\n        ,\n        y\n        )\n        +\n        i\n        v\n        (\n        x\n        ,\n        y\n        )\n        ,\n      \n    \n    {\\displaystyle z=x+iy\\quad {\\text{ and }}\\quad f(z)=f(x+iy)=u(x,y)+iv(x,y),}\n  \n\nwhere \n  \n    \n      \n        x\n        ,\n        y\n        ,\n        u\n        (\n        x\n        ,\n        y\n        )\n        ,\n        v\n        (\n        x\n        ,\n        y\n        )\n      \n    \n    {\\displaystyle x,y,u(x,y),v(x,y)}\n  \n are all real-valued.\nIn other words, a complex function \n  \n    \n      \n        f\n        :\n        \n          C\n        \n        →\n        \n          C\n        \n      \n    \n    {\\displaystyle f:\\mathbb {C} \\to \\mathbb {C} }\n  \n may be decomposed into\n\n  \n    \n      \n        u\n        :\n        \n          \n            R\n          \n          \n            2\n          \n        \n        →\n        \n          R\n        \n        \n      \n    \n    {\\displaystyle u:\\mathbb {R} ^{2}\\to \\mathbb {R} \\quad }\n  \n and \n  \n    \n      \n        \n        v\n        :\n        \n          \n            R\n          \n          \n            2\n          \n        \n        →\n        \n          R\n        \n        ,\n      \n    \n    {\\displaystyle \\quad v:\\mathbb {R} ^{2}\\to \\mathbb {R} ,}\n  \n\ni.e., into two real-valued functions (\n  \n    \n      \n        u\n      \n    \n    {\\displaystyle u}\n  \n, \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n  \n) of two real variables (\n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n, \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n).\nSimilarly, any complex-valued function f on an arbitrary set X (is isomorphic to, and therefore, in that sense, it) can be considered as an ordered pair of two real-valued functions: (Re f, Im f) or, alternatively, as a vector-valued function from X into \n  \n    \n      \n        \n          \n            R\n          \n          \n            2\n          \n        \n        .\n      \n    \n    {\\displaystyle \\mathbb {R} ^{2}.}\n  \n\nSome properties of complex-valued functions (such as continuity) are nothing more than the corresponding properties of vector valued functions of two real variables. Other concepts of complex analysis, such as differentiability, are direct generalizations of the similar concepts for real functions, but may have very different prope",
    "links": [
      "A Course of Modern Analysis",
      "Absolute value",
      "Aerospace engineering",
      "Aleksei Ivanovich Markushevich",
      "Aleksei Sveshnikov",
      "Algebraic geometry",
      "Algebraically closed field",
      "Analytic combinatorics",
      "Analytic continuation",
      "Analytic function",
      "Analytic number theory",
      "Analyticity of holomorphic functions",
      "Andrew Forsyth",
      "Andrey Nikolayevich Tikhonov",
      "Angle",
      "Antiderivative (complex analysis)",
      "Applied mathematics",
      "Arc (geometry)",
      "Argument (complex analysis)",
      "Argument principle",
      "Athanassios S. Fokas",
      "Augustin-Louis Cauchy",
      "Bernhard Riemann",
      "Bounded function",
      "Brightness",
      "Calculus",
      "Calculus of variations",
      "Carl Friedrich Gauss",
      "Cauchy",
      "Cauchy's integral formula",
      "Cauchy's integral theorem",
      "Cauchy integral theorem",
      "Cauchy–Riemann conditions",
      "Cauchy–Riemann equations",
      "Codomain",
      "Complex Hilbert space",
      "Complex conjugate",
      "Complex dynamics",
      "Complex geometry",
      "Complex logarithm",
      "Complex manifold",
      "Complex number",
      "Complex numbers",
      "Complex plane",
      "Complexity theory (disambiguation)",
      "Conformal map",
      "Conformal mapping",
      "Conformality",
      "Connected space",
      "Constantin Carathéodory"
    ],
    "categories": [
      "Category:All articles lacking in-text citations",
      "Category:Articles lacking in-text citations from March 2021",
      "Category:Articles with excerpts",
      "Category:Articles with short description",
      "Category:Complex analysis",
      "Category:Complex numbers",
      "Category:Pages using Sister project links with hidden wikidata",
      "Category:Short description matches Wikidata"
    ]
  },
  "Real analysis": {
    "title": "Real analysis",
    "url": "https://en.wikipedia.org/wiki/Real_analysis",
    "summary": "In mathematics, the branch of real analysis studies the behavior of real numbers, sequences and series of real numbers, and real functions. Some particular properties of real-valued sequences and functions that real analysis studies include convergence, limits, continuity, smoothness, differentiability and integrability.\nReal analysis is distinguished from complex analysis, which deals with the study of complex numbers and their functions.",
    "content": "In mathematics, the branch of real analysis studies the behavior of real numbers, sequences and series of real numbers, and real functions. Some particular properties of real-valued sequences and functions that real analysis studies include convergence, limits, continuity, smoothness, differentiability and integrability.\nReal analysis is distinguished from complex analysis, which deals with the study of complex numbers and their functions.\n\nScope\nConstruction of the real numbers\nThe theorems of real analysis rely on the properties of the (established) real number system. The real number system consists of an uncountable set (\n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n), together with two binary operations denoted + and \n  \n    \n      \n        ⋅\n      \n    \n    {\\displaystyle \\cdot }\n  \n, and a total order denoted ≤. The operations make the real numbers a field, and, along with the order, an ordered field.  The real number system is the unique complete ordered field, in the sense that any other complete ordered field is isomorphic to it. Intuitively, completeness means that there are no 'gaps' (or 'holes') in the real numbers. This property distinguishes the real numbers from other ordered fields (e.g., the rational numbers \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n) and is critical to the proof of several key properties of functions of the real numbers. The completeness of the reals is often conveniently expressed as the least upper bound property (see below).\n\nOrder properties of the real numbers\nThe real numbers have various lattice-theoretic properties that are absent in the complex numbers. Also, the real numbers form an ordered field, in which sums and products of positive numbers are also positive. Moreover, the ordering of the real numbers is total, and the real numbers have the least upper bound property: Every nonempty subset of \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n that has an upper bound has a least upper bound that is also a real number. These order-theoretic properties lead to a number of fundamental results in real analysis, such as the monotone convergence theorem, the intermediate value theorem and the mean value theorem.\nHowever, while the results in real analysis are stated for real numbers, many of these results can be generalized to other mathematical objects. In particular, many ideas in functional analysis and operator theory generalize properties of the real numbers – such generalizations include the theories of Riesz spaces and positive operators. Also, mathematicians consider real and imaginary parts of complex sequences, or by pointwise evaluation of operator sequences.\n\nTopological properties of the real numbers\nMany of the theorems of real analysis are consequences of the topological properties of the real number line. The order properties of the real numbers described above are closely related to these topological properties. As a topological space, the real numbers has a standard topology, which is the order topology induced by order \n  \n    \n      \n        <\n      \n    \n    {\\displaystyle <}\n  \n. Alternatively, by defining the metric or distance function \n  \n    \n      \n        d\n        :\n        \n          R\n        \n        ×\n        \n          R\n        \n        →\n        \n          \n            R\n          \n          \n            ≥\n            0\n          \n        \n      \n    \n    {\\displaystyle d:\\mathbb {R} \\times \\mathbb {R} \\to \\mathbb {R} _{\\geq 0}}\n  \n using the absolute value function as \n  \n    \n      \n        d\n        (\n        x\n        ,\n        y\n        )\n        =\n        \n          |\n        \n        x\n        −\n        y\n        \n          |\n        \n      \n    \n    {\\displaystyle d(x,y)=|x-y|}\n  \n, the real numbers become the prototypical example of a metric space. The topology induced by metric \n  \n    \n      \n        d\n      \n    \n    {\\displaystyle d}\n  \n turns out to be identical to the standard topology induced by order \n  \n    \n      \n        <\n      \n    \n    {\\displaystyle <}\n  \n. Theorems like the intermediate value theorem that are essentially topological in nature can often be proved in the more general setting of metric or topological spaces rather than in \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n only. Often, such proofs tend to be shorter or simpler compared to classical proofs that apply direct methods.\n\nSequences\nA sequence is a function whose domain is a countable, totally ordered set. The domain is usually taken to be the natural numbers, although it is occasionally convenient to also consider bidirectional sequences indexed by the set of all integers, including negative indices.\nOf interest in real analysis, a real-valued sequence, here indexed by the natural numbers, is a map \n  \n    \n      \n        a\n        :\n        \n     ",
    "links": [
      "Absolute continuity",
      "Absolute convergence",
      "Absolute value",
      "Algebra",
      "Analytic function",
      "Andrey Kolmogorov",
      "Areas of mathematics",
      "Arzelà–Ascoli theorem",
      "Augustin-Louis Cauchy",
      "Banach space",
      "Bernard Bolzano",
      "Binary operation",
      "Bolzano–Weierstrass theorem",
      "Boundary (topology)",
      "Bounded set",
      "Brooks/Cole",
      "Bump function",
      "Calculus",
      "Calculus of variations",
      "Cantor set",
      "Cartesian coordinate system",
      "Cauchy integral formula",
      "Cauchy sequence",
      "Charalambos D. Aliprantis",
      "Closed interval",
      "Closed set",
      "Compactness",
      "Complete metric space",
      "Completeness (order theory)",
      "Complex-valued function",
      "Complex analysis",
      "Complex exponential",
      "Complex number",
      "Computational mathematics",
      "Construction of the real numbers",
      "Continuous function",
      "Convergent series",
      "Countable",
      "Curve",
      "Darboux integral",
      "David Bressoud",
      "Decision theory",
      "Derivative",
      "Differentiable function",
      "Differentiable manifold",
      "Differential calculus",
      "Differential equation",
      "Differential form",
      "Differential geometry",
      "Disc of convergence"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Pages using sidebar with the child parameter",
      "Category:Real analysis",
      "Category:Short description is different from Wikidata",
      "Category:Webarchive template wayback links",
      "Category:Wikipedia articles needing clarification from June 2021"
    ]
  },
  "Set theory": {
    "title": "Set theory",
    "url": "https://en.wikipedia.org/wiki/Set_theory",
    "summary": "Set theory is the branch of mathematical logic that studies sets, which can be informally described as collections of objects. Although objects of any kind can be collected into a set, set theory – as a branch of mathematics – is mostly concerned with those that are relevant to mathematics as a whole.\nThe modern study of set theory was initiated by the German mathematicians Richard Dedekind and Georg Cantor in the 1870s. In particular, Georg Cantor is commonly considered the founder of set theory. The non-formalized systems investigated during this early stage go under the name of naive set theory. After the discovery of paradoxes within naive set theory (such as Russell's paradox, Cantor's paradox and the Burali-Forti paradox), various axiomatic systems were proposed in the early twentieth century, of which Zermelo–Fraenkel set theory (with or without the axiom of choice) is still the best-known and most studied.\nSet theory is commonly employed as a foundational system for the whole o",
    "content": "Set theory is the branch of mathematical logic that studies sets, which can be informally described as collections of objects. Although objects of any kind can be collected into a set, set theory – as a branch of mathematics – is mostly concerned with those that are relevant to mathematics as a whole.\nThe modern study of set theory was initiated by the German mathematicians Richard Dedekind and Georg Cantor in the 1870s. In particular, Georg Cantor is commonly considered the founder of set theory. The non-formalized systems investigated during this early stage go under the name of naive set theory. After the discovery of paradoxes within naive set theory (such as Russell's paradox, Cantor's paradox and the Burali-Forti paradox), various axiomatic systems were proposed in the early twentieth century, of which Zermelo–Fraenkel set theory (with or without the axiom of choice) is still the best-known and most studied.\nSet theory is commonly employed as a foundational system for the whole of mathematics, particularly in the form of Zermelo–Fraenkel set theory with the axiom of choice. Besides its foundational role, set theory also provides the framework to develop a mathematical theory of infinity, and has various applications in computer science (such as in the theory of relational algebra), philosophy, formal semantics, and evolutionary dynamics. Its foundational appeal, together with its paradoxes, and its implications for the concept of infinity and its multiple applications have made set theory an area of major interest for logicians and philosophers of mathematics. Contemporary research into set theory covers a vast array of topics, ranging from the structure of the real number line to the study of the consistency of large cardinals.\n\nHistory\nEarly history\nThe basic notion of grouping objects has existed since at least the emergence of numbers, and the notion of treating sets as their own objects has existed since at least the Tree of Porphyry in 3rd-century AD. The simplicity and ubiquity of sets makes it hard to determine the origin of sets as now used in mathematics; however, Bernard Bolzano's Paradoxes of the Infinite (Paradoxien des Unendlichen, 1851) is generally considered the first rigorous introduction of sets to mathematics. In his work, he (among other things) expanded on Galileo's paradox, and introduced one-to-one correspondence of infinite sets, for example between the intervals \n  \n    \n      \n        [\n        0\n        ,\n        5\n        ]\n      \n    \n    {\\displaystyle [0,5]}\n  \n and \n  \n    \n      \n        [\n        0\n        ,\n        12\n        ]\n      \n    \n    {\\displaystyle [0,12]}\n  \n by the relation \n  \n    \n      \n        5\n        y\n        =\n        12\n        x\n      \n    \n    {\\displaystyle 5y=12x}\n  \n. However, he resisted saying these sets were equinumerous, and his work is generally considered to have been uninfluential in mathematics of his time.\nBefore mathematical set theory, basic concepts of infinity were considered to be in the domain of philosophy (see: Infinity (philosophy) and Infinity § History). Since the 5th century BC, beginning with Greek philosopher Zeno of Elea in the West (and early Indian mathematicians in the East), mathematicians had struggled with the concept of infinity. With the development of calculus in the late 17th century, philosophers began to generally distinguish between potential and actual infinity, wherein mathematics was only considered in the latter. Carl Friedrich Gauss famously stated: \"Infinity is nothing more than a figure of speech which helps us talk about limits. The notion of a completed infinity doesn't belong in mathematics.\"\nDevelopment of mathematical set theory was motivated by several mathematicians. Bernhard Riemann's lecture On the Hypotheses which lie at the Foundations of Geometry (1854) proposed new ideas about topology. His lectures also introduced the concept of basing mathematics in terms of sets or manifolds in the sense of a class (which he called Mannigfaltigkeit) now called point-set topology. The lecture was published by Richard Dedekind in 1868, along with Riemann's paper on trigonometric series (which presented the Riemann integral), The latter was a starting point a movement in real analysis for the study of “seriously” discontinuous functions. A young Georg Cantor entered into this area, which led him to the study of point-sets. Around 1871, influenced by Riemann, Dedekind began working with sets in his publications, which dealt very clearly and precisely with equivalence relations, partitions of sets, and homomorphisms. Thus, many of the usual set-theoretic procedures of twentieth-century mathematics go back to his work. However, he did not publish a formal explanation of his set theory until 1888.\n\nNaive set theory\nSet theory, as understood by modern mathematicians, is generally considered to be founded by a single paper in 1874 by Georg Cantor titled On a Property of the Collection of All Real Algebraic",
    "links": [
      "Abraham Fraenkel",
      "Abstract algebra",
      "Abstract logic",
      "Ackermann set theory",
      "Actual infinity",
      "Akihiro Kanamori",
      "Aleph",
      "Aleph number",
      "Algebra",
      "Algebra of sets",
      "Algebraic geometry",
      "Algebraic logic",
      "Algebraic number theory",
      "Algebraic topology",
      "Almost",
      "Alphabet (formal languages)",
      "Alternative set theory",
      "Amorphous set",
      "Analytic geometry",
      "Analytic number theory",
      "Andrey Kolmogorov",
      "Antinomy",
      "Applied mathematics",
      "Areas of mathematics",
      "Argument",
      "Aristotle",
      "Arithmetic",
      "Arithmetic geometry",
      "Arity",
      "Arthur Schoenflies",
      "Atomic formula",
      "Atomic sentence",
      "Automata theory",
      "Automated theorem proving",
      "Axiom",
      "Axiom of adjunction",
      "Axiom of choice",
      "Axiom of constructibility",
      "Axiom of countable choice",
      "Axiom of dependent choice",
      "Axiom of determinacy",
      "Axiom of extensionality",
      "Axiom of global choice",
      "Axiom of infinity",
      "Axiom of limitation of size",
      "Axiom of pairing",
      "Axiom of power set",
      "Axiom of projective determinacy",
      "Axiom of regularity",
      "Axiom of union"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1: long volume value",
      "Category:CS1 German-language sources (de)",
      "Category:CS1 maint: multiple names: authors list",
      "Category:CS1 maint: publisher location",
      "Category:Formal methods",
      "Category:Georg Cantor",
      "Category:Mathematical logic",
      "Category:Pages using Sister project links with default search",
      "Category:Pages using sidebar with the child parameter"
    ]
  },
  "Logic": {
    "title": "Logic",
    "url": "https://en.wikipedia.org/wiki/Logic",
    "summary": "Logic is the study of correct reasoning. It includes both formal and informal logic. Formal logic is the study of deductively valid inferences or logical truths. It examines how conclusions follow from premises based on the structure of arguments alone, independent of their topic and content. Informal logic is associated with informal fallacies, critical thinking, and argumentation theory. Informal logic examines arguments expressed in natural language whereas formal logic uses formal language. When used as a countable noun, the term \"a logic\" refers to a specific logical formal system that articulates a proof system. Logic plays a central role in many fields, such as philosophy, mathematics, computer science, and linguistics.\nLogic studies arguments, which consist of a set of premises that leads to a conclusion. An example is the argument from the premises \"it's Sunday\" and \"if it's Sunday then I don't have to work\" leading to the conclusion \"I don't have to work.\" Premises and conclu",
    "content": "Logic is the study of correct reasoning. It includes both formal and informal logic. Formal logic is the study of deductively valid inferences or logical truths. It examines how conclusions follow from premises based on the structure of arguments alone, independent of their topic and content. Informal logic is associated with informal fallacies, critical thinking, and argumentation theory. Informal logic examines arguments expressed in natural language whereas formal logic uses formal language. When used as a countable noun, the term \"a logic\" refers to a specific logical formal system that articulates a proof system. Logic plays a central role in many fields, such as philosophy, mathematics, computer science, and linguistics.\nLogic studies arguments, which consist of a set of premises that leads to a conclusion. An example is the argument from the premises \"it's Sunday\" and \"if it's Sunday then I don't have to work\" leading to the conclusion \"I don't have to work.\" Premises and conclusions express propositions or claims that can be true or false. An important feature of propositions is their internal structure. For example, complex propositions are made up of simpler propositions linked by logical vocabulary like \n  \n    \n      \n        ∧\n      \n    \n    {\\displaystyle \\land }\n  \n (and) or \n  \n    \n      \n        →\n      \n    \n    {\\displaystyle \\to }\n  \n (if...then). Simple propositions also have parts, like \"Sunday\" or \"work\" in the example. The truth of a proposition usually depends on the meanings of all of its parts. However, this is not the case for logically true propositions. They are true only because of their logical structure independent of the specific meanings of the individual parts.\nArguments can be either correct or incorrect. An argument is correct if its premises support its conclusion. Deductive arguments have the strongest form of support: if their premises are true then their conclusion must also be true. This is not the case for ampliative arguments, which arrive at genuinely new information not found in the premises. Many arguments in everyday discourse and the sciences are ampliative arguments. They are divided into inductive and abductive arguments. Inductive arguments are statistical generalizations, such as inferring that all ravens are black based on many individual observations of black ravens. Abductive arguments are inferences to the best explanation, for example, when a doctor concludes that a patient has a certain disease which explains the symptoms they suffer. Arguments that fall short of the standards of correct reasoning often embody fallacies. Systems of logic are theoretical frameworks for assessing the correctness of arguments.\nLogic has been studied since antiquity. Early approaches include Aristotelian logic, Stoic logic, Nyaya, and Mohism. Aristotelian logic focuses on reasoning in the form of syllogisms. It was considered the main system of logic in the Western world until it was replaced by modern formal logic, which has its roots in the work of late 19th-century mathematicians such as Gottlob Frege. Today, the most commonly used system is classical logic. It consists of propositional logic and first-order logic. Propositional logic only considers logical relations between full propositions. First-order logic also takes the internal parts of propositions into account, like predicates and quantifiers. Extended logics accept the basic intuitions behind classical logic and apply it to other fields, such as metaphysics, ethics, and epistemology. Deviant logics, on the other hand, reject certain classical intuitions and provide alternative explanations of the basic laws of logic.\n\nDefinition\nThe word \"logic\" originates from the Greek word logos, which has a variety of translations, such as reason, discourse, or language. Logic is traditionally defined as the study of the laws of thought or correct reasoning, and is usually understood in terms of inferences or arguments. Reasoning is the activity of drawing inferences. Arguments are the outward expression of inferences. An argument is a set of premises together with a conclusion. Logic is interested in whether arguments are correct, i.e. whether their premises support the conclusion. These general characterizations apply to logic in the widest sense, i.e., to both formal and informal logic since they are both concerned with assessing the correctness of arguments. Formal logic is the traditionally dominant field, and some logicians restrict logic to formal logic.\n\nFormal logic\nFormal logic (also known as symbolic logic) is widely used in mathematical logic. It uses a formal approach to study reasoning: it replaces concrete expressions with abstract symbols to examine the logical form of arguments independent of their concrete content. In this sense, it is topic-neutral since it is only concerned with the abstract structure of arguments and not with their concrete content.\nFormal logic is interested in deductively valid",
    "links": [
      "A priori and a posteriori",
      "Abductive reasoning",
      "Abhidharma",
      "Absolute idealism",
      "Abstract object",
      "Academic Skepticism",
      "Achintya Bheda Abheda",
      "Action theory (philosophy)",
      "Adriane Rini",
      "Advaita Vedanta",
      "Aesthetic emotions",
      "Aesthetics",
      "African philosophy",
      "Africana philosophy",
      "Agriculturalism",
      "Ajñana",
      "Albertus Magnus",
      "Alfred North Whitehead",
      "Alfred Tarski",
      "Algorithm",
      "American philosophy",
      "Ampliative",
      "Analytic philosophy",
      "Analytical Marxism",
      "Analytical feminism",
      "Analytic–synthetic distinction",
      "Anarchism",
      "Ancient Egyptian philosophy",
      "Ancient Greek philosophy",
      "Ancient Roman philosophy",
      "Ancient history",
      "Ancient philosophy",
      "Anekantavada",
      "Antecedent (logic)",
      "Anti-realism",
      "Antihumanism",
      "Antinomy",
      "Applied ethics",
      "Applied philosophy",
      "ArXiv (identifier)",
      "Argument",
      "Argumentation theory",
      "Aristotelian logic",
      "Aristotelianism",
      "Aristotle",
      "Atomic propositions",
      "Atomism",
      "Augustinianism",
      "Australian philosophy",
      "Automatic theorem prover"
    ],
    "categories": [
      "Category:Articles containing German-language text",
      "Category:Articles containing Latin-language text",
      "Category:Articles with hAudio microformats",
      "Category:Articles with short description",
      "Category:CS1 maint: ignored ISBN errors",
      "Category:CS1 maint: publisher location",
      "Category:Featured articles",
      "Category:Formal sciences",
      "Category:Logic",
      "Category:Pages that use a deprecated format of the math tags"
    ]
  },
  "Graph theory": {
    "title": "Graph theory",
    "url": "https://en.wikipedia.org/wiki/Graph_theory",
    "summary": "In mathematics and computer science, graph theory is the study of graphs, which are mathematical structures used to model pairwise relations between objects. A graph in this context is made up of vertices (also called nodes or points) which are connected by edges (also called arcs, links or lines). A distinction is made between undirected graphs, where edges link two vertices symmetrically, and directed graphs, where edges link two vertices asymmetrically. Graphs are one of the principal objects of study in discrete mathematics.",
    "content": "In mathematics and computer science, graph theory is the study of graphs, which are mathematical structures used to model pairwise relations between objects. A graph in this context is made up of vertices (also called nodes or points) which are connected by edges (also called arcs, links or lines). A distinction is made between undirected graphs, where edges link two vertices symmetrically, and directed graphs, where edges link two vertices asymmetrically. Graphs are one of the principal objects of study in discrete mathematics.\n\nDefinitions\nDefinitions in graph theory vary. The following are some of the more basic ways of defining graphs and related mathematical structures.\n\nGraph\nIn one restricted but very common sense of the term, a graph is an ordered pair \n  \n    \n      \n        G\n        =\n        (\n        V\n        ,\n        E\n        )\n      \n    \n    {\\displaystyle G=(V,E)}\n  \n comprising:\n\n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n, a set of vertices (also called nodes or points);\n\n  \n    \n      \n        E\n        ⊆\n        {\n        {\n        x\n        ,\n        y\n        }\n        ∣\n        x\n        ,\n        y\n        ∈\n        V\n        \n        \n          \n            and\n          \n        \n        \n        x\n        ≠\n        y\n        }\n      \n    \n    {\\displaystyle E\\subseteq \\{\\{x,y\\}\\mid x,y\\in V\\;{\\textrm {and}}\\;x\\neq y\\}}\n  \n, a set of edges (also called links or lines), which are unordered pairs of vertices (that is, an edge is associated with two distinct vertices).\nTo avoid ambiguity, this type of object may be called an undirected simple graph.\nIn the edge \n  \n    \n      \n        {\n        x\n        ,\n        y\n        }\n      \n    \n    {\\displaystyle \\{x,y\\}}\n  \n, the vertices \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n and \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n are called the endpoints of the edge. The edge is said to join \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n and \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n and to be incident on \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n and on \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n. A vertex may exist in a graph and not belong to an edge. Under this definition, multiple edges, in which two or more edges connect the same vertices, are not allowed.\n\nIn one more general sense of the term allowing multiple edges, a graph is an ordered triple \n  \n    \n      \n        G\n        =\n        (\n        V\n        ,\n        E\n        ,\n        ϕ\n        )\n      \n    \n    {\\displaystyle G=(V,E,\\phi )}\n  \n comprising:\n\n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n, a set of vertices (also called nodes or points);\n\n  \n    \n      \n        E\n      \n    \n    {\\displaystyle E}\n  \n, a set of edges (also called links or lines);\n\n  \n    \n      \n        ϕ\n        :\n        E\n        →\n        {\n        {\n        x\n        ,\n        y\n        }\n        ∣\n        x\n        ,\n        y\n        ∈\n        V\n        \n        \n          \n            and\n          \n        \n        \n        x\n        ≠\n        y\n        }\n      \n    \n    {\\displaystyle \\phi :E\\to \\{\\{x,y\\}\\mid x,y\\in V\\;{\\textrm {and}}\\;x\\neq y\\}}\n  \n, an incidence function mapping every edge to an unordered pair of vertices (that is, an edge is associated with two distinct vertices).\nTo avoid ambiguity, this type of object may be called an undirected multigraph.\nA loop is an edge that joins a vertex to itself. Graphs as defined in the two definitions above cannot have loops, because a loop joining a vertex \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n to itself is the edge (for an undirected simple graph) or is incident on (for an undirected multigraph) \n  \n    \n      \n        {\n        x\n        ,\n        x\n        }\n        =\n        {\n        x\n        }\n      \n    \n    {\\displaystyle \\{x,x\\}=\\{x\\}}\n  \n which is not in \n  \n    \n      \n        {\n        {\n        x\n        ,\n        y\n        }\n        ∣\n        x\n        ,\n        y\n        ∈\n        V\n        \n        \n          \n            and\n          \n        \n        \n        x\n        ≠\n        y\n        }\n      \n    \n    {\\displaystyle \\{\\{x,y\\}\\mid x,y\\in V\\;{\\textrm {and}}\\;x\\neq y\\}}\n  \n. To allow loops, the definitions must be expanded. For undirected simple graphs, the definition of \n  \n    \n      \n        E\n      \n    \n    {\\displaystyle E}\n  \n should be modified to \n  \n    \n      \n        E\n        ⊆\n        {\n        {\n        x\n        ,\n        y\n        }\n        ∣\n        x\n        ,\n        y\n        ∈\n        V\n        }\n      \n    \n    {\\displaystyle E\\subseteq \\{\\{x,y\\}\\mid x,y\\in V\\}}\n  \n. For undirected multigraphs, the definition of \n  \n    \n      \n        ϕ\n      \n    \n    {\\displaystyle \\phi }\n  \n should be modified to \n  \n    \n      \n        ϕ\n        :\n        E\n        →\n        {\n        {\n        x\n        ,\n        y\n        }\n ",
    "links": [
      "ACM Computing Classification System",
      "Abstract algebra",
      "Academic Press",
      "Adjacency list",
      "Adjacency matrix",
      "Alexandre-Théophile Vandermonde",
      "Alfred Kempe",
      "Alfréd Rényi",
      "Algebra",
      "Algebraic geometry",
      "Algebraic graph theory",
      "Algebraic number theory",
      "Algebraic topology",
      "Algorithm",
      "Algorithm design",
      "Algorithmic efficiency",
      "Analysis of algorithms",
      "Analytic geometry",
      "Analytic number theory",
      "Application security",
      "Applied mathematics",
      "ArXiv (identifier)",
      "Arboricity",
      "Arithmetic",
      "Arithmetic geometry",
      "Arthur Cayley",
      "Artificial intelligence",
      "Atom",
      "Augmented reality",
      "August Kekulé",
      "Augustin-Louis Cauchy",
      "Augustus De Morgan",
      "Automata theory",
      "Automated planning and scheduling",
      "Automatic theorem prover",
      "Bibcode (identifier)",
      "Binary relation",
      "BioRxiv (identifier)",
      "Biological pathway",
      "Biology",
      "Calculus",
      "Cambridge University Press",
      "Camille Jordan",
      "Category theory",
      "Chemical bond",
      "Chemical graph theory",
      "Chemistry",
      "Circle packing theorem",
      "Clique problem",
      "Combinatorics"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1: long volume value",
      "Category:CS1 errors: ISBN date",
      "Category:Commons link from Wikidata",
      "Category:Graph theory",
      "Category:Short description is different from Wikidata",
      "Category:Webarchive template wayback links"
    ]
  },
  "Combinatorics": {
    "title": "Combinatorics",
    "url": "https://en.wikipedia.org/wiki/Combinatorics",
    "summary": "Combinatorics is an area of mathematics primarily concerned with counting, both as a means and as an end to obtaining results, and certain properties of finite structures. It is closely related to many other areas of mathematics and has many applications ranging from logic to statistical physics and from evolutionary biology to computer science.\nCombinatorics is well known for the breadth of the problems it tackles. Combinatorial problems arise in many areas of pure mathematics, notably in algebra, probability theory, topology, and geometry, as well as in its many application areas. Many combinatorial questions have historically been considered in isolation, giving an ad hoc solution to a problem arising in some mathematical context. In the later twentieth century, however, powerful and general theoretical methods were developed, making combinatorics into an independent branch of mathematics in its own right. One of the oldest and most accessible parts of combinatorics is graph theory,",
    "content": "Combinatorics is an area of mathematics primarily concerned with counting, both as a means and as an end to obtaining results, and certain properties of finite structures. It is closely related to many other areas of mathematics and has many applications ranging from logic to statistical physics and from evolutionary biology to computer science.\nCombinatorics is well known for the breadth of the problems it tackles. Combinatorial problems arise in many areas of pure mathematics, notably in algebra, probability theory, topology, and geometry, as well as in its many application areas. Many combinatorial questions have historically been considered in isolation, giving an ad hoc solution to a problem arising in some mathematical context. In the later twentieth century, however, powerful and general theoretical methods were developed, making combinatorics into an independent branch of mathematics in its own right. One of the oldest and most accessible parts of combinatorics is graph theory, which by itself has numerous natural connections to other areas. Combinatorics is used frequently in computer science to obtain formulas and estimates in the analysis of algorithms.\n\nDefinition\nThe full scope of combinatorics is not universally agreed upon. According to H. J. Ryser, a definition of the subject is difficult because it crosses so many mathematical subdivisions. Insofar as an area can be described by the types of problems it addresses, combinatorics is involved with:\n\nthe enumeration (counting) of specified structures, sometimes referred to as arrangements or configurations in a very general sense, associated with finite systems,\nthe existence of such structures that satisfy certain given criteria,\nthe construction of these structures, perhaps in many ways, and\noptimization: finding the \"best\" structure or solution among several possibilities, be it the \"largest\", \"smallest\" or satisfying some other optimality criterion.\nLeon Mirsky has said: \"combinatorics is a range of linked studies which have something in common and yet diverge widely in their objectives, their methods, and the degree of coherence they have attained.\" One way to define combinatorics is, perhaps, to describe its subdivisions with their problems and techniques. This is the approach that is used below. However, there are also purely historical reasons for including or not including some topics under the combinatorics umbrella. Although primarily concerned with finite systems, some combinatorial questions and techniques can be extended to an infinite (specifically, countable) but discrete setting.\n\nHistory\nBasic combinatorial concepts and enumerative results appeared throughout the ancient world. The earliest recorded use of combinatorial techniques comes from problem 79 of the Rhind papyrus, which dates to the 16th century BC.  The problem concerns a certain geometric series, and has similarities to Fibonacci's problem of counting the number of compositions of 1s and 2s that sum to a given total. Indian physician Sushruta asserts in Sushruta Samhita that 63 combinations can be made out of 6 different tastes, taken one at a time, two at a time, etc., thus computing all 26 − 1 possibilities.  Greek historian Plutarch discusses an argument between Chrysippus (3rd century BCE) and Hipparchus (2nd century BCE) of a rather delicate enumerative problem, which was later shown to be related to Schröder–Hipparchus numbers. Earlier, in the Ostomachion, Archimedes (3rd century BCE) may have considered the number of configurations of a tiling puzzle, while combinatorial interests possibly were present in lost works by Apollonius.\nIn the Middle Ages, combinatorics continued to be studied, largely outside of the European civilization. The Indian mathematician Mahāvīra (c. 850) provided formulae for the number of permutations and combinations, and these formulas may have been familiar to Indian mathematicians as early as the 6th century CE.  The philosopher and astronomer Rabbi Abraham ibn Ezra (c. 1140) established the symmetry of binomial coefficients, while a closed formula was obtained later by the talmudist and mathematician Levi ben Gerson (better known as Gersonides), in 1321.\nThe arithmetical triangle—a graphical diagram showing relationships among the binomial coefficients—was presented by mathematicians in treatises dating as far back as the 10th century, and would eventually become known as Pascal's triangle. Later, in Medieval England, campanology provided examples of what is now known as Hamiltonian cycles in certain Cayley graphs on permutations.\nDuring the Renaissance, together with the rest of mathematics and the sciences, combinatorics enjoyed a rebirth. Works of Pascal, Newton, Jacob Bernoulli and Euler became foundational in the emerging field. In modern times, the works of J.J. Sylvester (late 19th century) and Percy MacMahon (early 20th century) helped lay the foundation for enumerative and algebraic combinatorics. Graph theory also enjoye",
    "links": [
      "ACM Computing Classification System",
      "Abraham ibn Ezra",
      "Abstract algebra",
      "Additive number theory",
      "Akihiro Kanamori",
      "Algebra",
      "Algebraic combinatorics",
      "Algebraic geometry",
      "Algebraic number theory",
      "Algebraic topology",
      "Algorithm",
      "Algorithm design",
      "Algorithmic efficiency",
      "Analysis",
      "Analysis of algorithms",
      "Analytic combinatorics",
      "Analytic geometry",
      "Analytic number theory",
      "Ancient Greece",
      "Ancient history",
      "Andreas Blass",
      "Apollonius of Perga",
      "Application security",
      "Applied mathematics",
      "Archimedean solid",
      "Archimedes",
      "Areas of mathematics",
      "Arithmetic",
      "Arithmetic combinatorics",
      "Arithmetic geometry",
      "Artificial intelligence",
      "Associahedron",
      "Astronomer",
      "Asymptotic analysis",
      "Augmented reality",
      "Automata theory",
      "Automated planning and scheduling",
      "Bijective proof",
      "Binary tree",
      "Binomial coefficient",
      "Birkhoff polytope",
      "Blaise Pascal",
      "Block design",
      "Boolean algebras",
      "Calculus",
      "Cambridge University Press",
      "Campanology",
      "Catalan number",
      "Category theory",
      "Cauchy's theorem (geometry)"
    ],
    "categories": [
      "Category:All articles lacking in-text citations",
      "Category:Articles lacking in-text citations from July 2022",
      "Category:Articles with short description",
      "Category:CS1 maint: multiple names: editors list",
      "Category:Combinatorics",
      "Category:Pages using Sister project links with hidden wikidata",
      "Category:Pages using sidebar with the child parameter",
      "Category:Short description matches Wikidata",
      "Category:Webarchive template wayback links",
      "Category:Wikipedia articles needing clarification from November 2022"
    ]
  },
  "Mathematical optimization": {
    "title": "Mathematical optimization",
    "url": "https://en.wikipedia.org/wiki/Mathematical_optimization",
    "summary": "Mathematical optimization (alternatively spelled optimisation) or mathematical programming is the selection of a best element, with regard to some criteria, from some set of available alternatives. It is generally divided into two subfields: discrete optimization and continuous optimization. Optimization problems arise in all quantitative disciplines from computer science and engineering to operations research and economics, and the development of solution methods has been of interest in mathematics for centuries.\nIn the more general approach, an optimization problem consists of maximizing or minimizing a real function by systematically choosing input values from within an allowed set and computing the value of the function. The generalization of optimization theory and techniques to other formulations constitutes a large area of applied mathematics.",
    "content": "Mathematical optimization (alternatively spelled optimisation) or mathematical programming is the selection of a best element, with regard to some criteria, from some set of available alternatives. It is generally divided into two subfields: discrete optimization and continuous optimization. Optimization problems arise in all quantitative disciplines from computer science and engineering to operations research and economics, and the development of solution methods has been of interest in mathematics for centuries.\nIn the more general approach, an optimization problem consists of maximizing or minimizing a real function by systematically choosing input values from within an allowed set and computing the value of the function. The generalization of optimization theory and techniques to other formulations constitutes a large area of applied mathematics.\n\nOptimization problems\nOptimization problems can be divided into two categories, depending on whether the variables are continuous or discrete: \n\nAn optimization problem with discrete variables is known as a discrete optimization, in which an object such as an integer, permutation or graph must be found from a countable set.\nA problem with continuous variables is known as a continuous optimization, in which optimal arguments from a continuous set must be found. They can include constrained problems and multimodal problems.\nAn optimization problem can be represented in the following way:\n\nGiven: a function \n  \n    \n      \n        f\n        :\n        A\n        →\n        \n          R\n        \n      \n    \n    {\\displaystyle f:A\\rightarrow \\mathbb {R} }\n  \n from some set A to the real numbers\nSought: an element x0 ∈ A such that f(x0) ≤ f(x) for all x ∈ A (\"minimization\") or such that f(x0) ≥ f(x) for all x ∈ A (\"maximization\").\nSuch a formulation is called an optimization problem or a mathematical programming problem (a term not directly related to computer programming, but still in use for example in linear programming – see History below). Many real-world and theoretical problems may be modeled in this general framework.\nSince the following is valid:\n\n  \n    \n      \n        f\n        (\n        \n          \n            x\n          \n          \n            0\n          \n        \n        )\n        ≥\n        f\n        (\n        \n          x\n        \n        )\n        ⇔\n        −\n        f\n        (\n        \n          \n            x\n          \n          \n            0\n          \n        \n        )\n        ≤\n        −\n        f\n        (\n        \n          x\n        \n        )\n        ,\n      \n    \n    {\\displaystyle f(\\mathbf {x} _{0})\\geq f(\\mathbf {x} )\\Leftrightarrow -f(\\mathbf {x} _{0})\\leq -f(\\mathbf {x} ),}\n  \n\nit suffices to solve only minimization problems. However, the opposite perspective of considering only maximization problems would be valid, too.\nProblems formulated using this technique in the fields of physics may refer to the technique as energy minimization, speaking of the value of the function f as representing the energy of the system being modeled. In machine learning, it is always necessary to continuously evaluate the quality of a data model by using a cost function where a minimum implies a set of possibly optimal parameters with an optimal (lowest) error.\nTypically, A is some subset of the Euclidean space \n  \n    \n      \n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{n}}\n  \n, often specified by a set of constraints, equalities or inequalities that the members of A have to satisfy. The domain A of f is called the search space or the choice set, while the elements of A are called candidate solutions or feasible solutions.\nThe function f is variously called an objective function, criterion function, loss function, cost function (minimization), utility function or fitness function (maximization), or, in certain fields, an energy function or energy functional. A feasible solution that minimizes (or maximizes) the objective function is called an optimal solution.\nIn mathematics, conventional optimization problems are usually stated in terms of minimization.\nA local minimum x* is defined as an element for which there exists some δ > 0 such that\n\n  \n    \n      \n        ∀\n        \n          x\n        \n        ∈\n        A\n        \n        \n          where\n        \n        \n        \n          ‖\n          \n            \n              x\n            \n            −\n            \n              \n                x\n              \n              \n                ∗\n              \n            \n          \n          ‖\n        \n        ≤\n        δ\n        ,\n        \n      \n    \n    {\\displaystyle \\forall \\mathbf {x} \\in A\\;{\\text{where}}\\;\\left\\Vert \\mathbf {x} -\\mathbf {x} ^{\\ast }\\right\\Vert \\leq \\delta ,\\,}\n  \n\nthe expression f(x*) ≤ f(x) holds;\nthat is to say, on some region around x* all of the function values are greater than or equal to the value at that element. \nLocal maxima are ",
    "links": [
      "Abstract algebra",
      "Active-set method",
      "Active filter",
      "Aerospace engineering",
      "Affine scaling",
      "Agent (economics)",
      "Albert W. Tucker",
      "Algebra",
      "Algebraic geometry",
      "Algebraic number theory",
      "Algebraic topology",
      "Algorithm",
      "American Economic Review",
      "An Essay on the Nature and Significance of Economic Science",
      "Analytic geometry",
      "Analytic number theory",
      "Applied mathematics",
      "Approximation algorithm",
      "Arg max",
      "Argument of a function",
      "Arithmetic",
      "Arithmetic geometry",
      "Arkadi Nemirovski",
      "Arthur David Hall III",
      "Artificial intelligence",
      "Asset pricing",
      "Augmented Lagrangian method",
      "Automated reasoning",
      "BFGS method",
      "Barbara Grosz",
      "Barrier function",
      "Bayesian optimization",
      "Bellman equation",
      "Bellman–Ford algorithm",
      "Benjamin S. Blanchard",
      "Bernard Koopman",
      "Berndt–Hall–Hall–Hausman algorithm",
      "Bibcode (identifier)",
      "Biological systems engineering",
      "Borůvka's algorithm",
      "Bounded set",
      "Brachistochrone curve",
      "Branch and bound",
      "Branch and cut",
      "Broyden–Fletcher–Goldfarb–Shanno algorithm",
      "Business process",
      "Calculus",
      "Calculus of variations",
      "Candidate solution",
      "Carl Friedrich Gauss"
    ],
    "categories": [
      "Category:All articles with style issues",
      "Category:Articles with short description",
      "Category:Commons category link from Wikidata",
      "Category:Mathematical and quantitative methods (economics)",
      "Category:Mathematical optimization",
      "Category:Operations research",
      "Category:Short description matches Wikidata",
      "Category:Webarchive template wayback links",
      "Category:Wikipedia articles with style issues from July 2025"
    ]
  },
  "Numerical analysis": {
    "title": "Numerical analysis",
    "url": "https://en.wikipedia.org/wiki/Numerical_analysis",
    "summary": "Numerical analysis is the study of algorithms that use numerical approximation (as opposed to symbolic manipulations) for the problems of mathematical analysis (as distinguished from discrete mathematics). It is the study of numerical methods that attempt to find approximate solutions of problems rather than the exact ones. Numerical analysis finds application in all fields of engineering and the physical sciences, and in the 21st century also the life and social sciences like economics, medicine, business and even the arts. Current growth in computing power has enabled the use of more complex numerical analysis, providing detailed and realistic mathematical models in science and engineering. Examples of numerical analysis include: ordinary differential equations as found in celestial mechanics (predicting the motions of planets, stars and galaxies), numerical linear algebra in data analysis, and stochastic differential equations and Markov chains for simulating living cells in medicin",
    "content": "Numerical analysis is the study of algorithms that use numerical approximation (as opposed to symbolic manipulations) for the problems of mathematical analysis (as distinguished from discrete mathematics). It is the study of numerical methods that attempt to find approximate solutions of problems rather than the exact ones. Numerical analysis finds application in all fields of engineering and the physical sciences, and in the 21st century also the life and social sciences like economics, medicine, business and even the arts. Current growth in computing power has enabled the use of more complex numerical analysis, providing detailed and realistic mathematical models in science and engineering. Examples of numerical analysis include: ordinary differential equations as found in celestial mechanics (predicting the motions of planets, stars and galaxies), numerical linear algebra in data analysis, and stochastic differential equations and Markov chains for simulating living cells in medicine and biology.\nBefore modern computers, numerical methods often relied on hand interpolation formulas, using data from large printed tables. Since the mid-20th century, computers calculate the required functions instead, but many of the same formulas continue to be used in software algorithms.\nThe numerical point of view goes back to the earliest mathematical writings. A tablet from the Yale Babylonian Collection (YBC 7289), gives a sexagesimal numerical approximation of the square root of 2, the length of the diagonal in a unit square.\nNumerical analysis continues this long tradition: rather than giving exact symbolic answers translated into digits and applicable only to real-world measurements, approximate solutions within specified error bounds are used.\n\nApplications\nThe overall goal of the field of numerical analysis is the design and analysis of techniques to give approximate but accurate solutions to a wide variety of hard problems, many of which are infeasible to solve symbolically:\n\nAdvanced numerical methods are essential in making numerical weather prediction feasible.\nComputing the trajectory of a spacecraft requires the accurate numerical solution of a system of ordinary differential equations.\nCar companies can improve the crash safety of their vehicles by using computer simulations of car crashes. Such simulations essentially consist of solving partial differential equations numerically.\nIn the financial field, (private investment funds) and other financial institutions use quantitative finance tools from numerical analysis to attempt to calculate the value of stocks and derivatives more precisely than other market participants.\nAirlines use sophisticated optimization algorithms to decide ticket prices, airplane and crew assignments and fuel needs. Historically, such algorithms were developed within the overlapping field of operations research.\nInsurance companies use numerical programs for actuarial analysis.\n\nHistory\nThe field of numerical analysis predates the invention of modern computers by many centuries. Linear interpolation was already in use more than 2000 years ago. Many great mathematicians of the past were preoccupied by numerical analysis, as is obvious from the names of important algorithms like Newton's method, Lagrange interpolation polynomial, Gaussian elimination, or Euler's method. The origins of modern numerical analysis are often linked to a 1947 paper by John von Neumann and Herman Goldstine,\nbut others consider modern numerical analysis to go back to work by E. T. Whittaker in 1912.\n\nTo facilitate computations by hand, large books were produced with formulas and tables of data such as interpolation points and function coefficients. Using these tables, often calculated out to 16 decimal places or more for some functions, one could look up values to plug into the formulas given and achieve very good numerical estimates of some functions. The canonical work in the field is the NIST publication edited by Abramowitz and Stegun, a 1000-plus page book of a very large number of commonly used formulas and functions and their values at many points. The function values are no longer very useful when a computer is available, but the large listing of formulas can still be very handy.\nThe mechanical calculator was also developed as a tool for hand computation. These calculators evolved into electronic computers in the 1940s, and it was then found that these computers were also useful for administrative purposes. But the invention of the computer also influenced the field of numerical analysis, since now longer and more complicated calculations could be done.\nThe Leslie Fox Prize for Numerical Analysis was initiated in 1985 by the Institute of Mathematics and its Applications.\n\nKey concepts\nDirect and iterative methods\nDirect methods compute the solution to a problem in a finite number of steps. These methods would give the precise answer if they were performed in infinite precision arithmetic. Examples ",
    "links": [
      "ACM Computing Classification System",
      "Abramowitz and Stegun",
      "Abstract algebra",
      "Acoustics",
      "Actuary",
      "Adhemar Bultheel",
      "Algebra",
      "Algebraic geometry",
      "Algebraic number theory",
      "Algebraic topology",
      "Algorithm",
      "Algorithm design",
      "Algorithmic efficiency",
      "Analysis of algorithms",
      "Analytic geometry",
      "Analytic number theory",
      "Analytical mechanics",
      "Application security",
      "Applied mathematics",
      "Applied physics",
      "Approximation",
      "Approximation theory",
      "ArXiv (identifier)",
      "Arbitrary-precision arithmetic",
      "Arithmetic",
      "Arithmetic geometry",
      "Artificial intelligence",
      "Association for Computing Machinery",
      "Astrophysics",
      "Atmospheric physics",
      "Atomic, molecular, and optical physics",
      "Atomic physics",
      "Augmented reality",
      "Automata theory",
      "Automated planning and scheduling",
      "Basic research",
      "Biophysics",
      "Bisection method",
      "Branches of physics",
      "C (programming language)",
      "Calculus",
      "California State University Fullerton",
      "Cambridge University Press",
      "Category theory",
      "Celestial mechanics",
      "Charles F. Van Loan",
      "Chemical physics",
      "Cholesky decomposition",
      "Classical electromagnetism",
      "Classical mechanics"
    ],
    "categories": [
      "Category:Articles with German-language sources (de)",
      "Category:Articles with short description",
      "Category:Computational science",
      "Category:Mathematical physics",
      "Category:Numerical analysis",
      "Category:Pages using Sister project links with hidden wikidata",
      "Category:Short description is different from Wikidata",
      "Category:Use dmy dates from October 2020",
      "Category:Webarchive template other archives",
      "Category:Webarchive template wayback links"
    ]
  },
  "Affine geometry": {
    "title": "Affine geometry",
    "url": "https://en.wikipedia.org/wiki/Affine_geometry",
    "summary": "In mathematics, affine geometry is what remains of Euclidean geometry when ignoring (mathematicians often say \"forgetting\") the metric notions of distance and angle.\nAs the notion of parallel lines is one of the main properties that is independent of any metric, affine geometry is often considered as the study of parallel lines. Therefore, Playfair's axiom (Given a line L and a point P not on L, there is exactly one line parallel to L that passes through P.) is fundamental in affine geometry. Comparisons of figures in affine geometry are made with affine transformations, which are mappings that preserve alignment of points and parallelism of lines.\nAffine geometry can be developed in two ways that are essentially equivalent.\nIn synthetic geometry, an affine space is a set of points to which is associated a set of lines, which satisfy some axioms (such as Playfair's axiom).\nAffine geometry can also be developed on the basis of linear algebra. In this context an affine space is a set of ",
    "content": "In mathematics, affine geometry is what remains of Euclidean geometry when ignoring (mathematicians often say \"forgetting\") the metric notions of distance and angle.\nAs the notion of parallel lines is one of the main properties that is independent of any metric, affine geometry is often considered as the study of parallel lines. Therefore, Playfair's axiom (Given a line L and a point P not on L, there is exactly one line parallel to L that passes through P.) is fundamental in affine geometry. Comparisons of figures in affine geometry are made with affine transformations, which are mappings that preserve alignment of points and parallelism of lines.\nAffine geometry can be developed in two ways that are essentially equivalent.\nIn synthetic geometry, an affine space is a set of points to which is associated a set of lines, which satisfy some axioms (such as Playfair's axiom).\nAffine geometry can also be developed on the basis of linear algebra. In this context an affine space is a set of points equipped with a set of transformations (that is bijective mappings), the translations, which forms a vector space (over a given field, commonly the real numbers), and such that for any given ordered pair of points there is a unique translation sending the first point to the second; the composition of two translations is their sum in the vector space of the translations.\nIn more concrete terms, this amounts to having an operation that associates to any ordered pair of points a vector and another operation that allows translation of a point by a vector to give another point; these operations are required to satisfy a number of axioms (notably that two successive translations have the effect of translation by the sum vector). By choosing any point as \"origin\", the points are in one-to-one correspondence with the vectors, but there is no preferred choice for the origin; thus an affine space may be viewed as obtained from its associated vector space by \"forgetting\" the origin (zero vector).\nThe idea of forgetting the metric can be applied in the theory of manifolds.  That is developed in the article Affine connection.\n\nHistory\nIn 1748, Leonhard Euler introduced the term affine (from Latin  affinis 'related') in his book Introductio in analysin infinitorum (volume 2, chapter XVIII). In 1827, August Möbius wrote on affine geometry in his Der barycentrische Calcul (chapter 3).\nAfter Felix Klein's Erlangen program, affine geometry was recognized as a generalization of Euclidean geometry.\nIn 1918, Hermann Weyl referred to affine geometry for his text Space, Time, Matter. He used affine geometry to introduce vector addition and subtraction at the earliest stages of his development of mathematical physics. Later, E. T. Whittaker wrote:\n\nWeyl's geometry is interesting historically as having been the first of the affine geometries to be worked out in detail: it is based on a special type of parallel transport [...using] worldlines of light-signals in four-dimensional space-time. A short element of one of these world-lines may be called a null-vector; then the parallel transport in question is such that it carries any null-vector at one point into the position of a null-vector at a neighboring point.\n\nSystems of axioms\nSeveral axiomatic approaches to affine geometry have been put forward:\n\nPappus' law\nAs affine geometry deals with parallel lines, one of the properties of parallels noted by Pappus of Alexandria has been taken as a premise:\n\nSuppose A, B, C are on one line and A', B', C' on another.  If the lines AB' and A'B are parallel and the lines BC' and B'C are parallel, then the lines CA' and C'A are parallel. (This is the affine version of Pappus's hexagon theorem).\nThe full axiom system proposed has point, line, and line containing point as primitive notions:\n\nTwo points are contained in just one line.\nFor any line L and any point P, not on L, there is just one line containing P and not containing any point of L. This line is said to be parallel to L.\nEvery line contains at least two points.\nThere are at least three points not belonging to one line.\nAccording to H. S. M. Coxeter:\n\nThe interest of these five axioms is enhanced by the fact that they can be developed into a vast body of propositions, holding not only in Euclidean geometry but also in Minkowski's geometry of  time and space (in the simple case of 1 + 1 dimensions, whereas the special theory of relativity needs 1 + 3). The extension to either Euclidean or Minkowskian geometry is achieved by adding various further axioms of orthogonality, etc.\nThe various types of affine geometry correspond to what interpretation is taken for rotation. Euclidean geometry corresponds to the ordinary idea of rotation, while Minkowski's geometry corresponds to hyperbolic rotation. With respect to perpendicular lines, they remain perpendicular when the plane is subjected to ordinary rotation. In the Minkowski geometry, lines that are hyperbolic-orthogonal remain in that relation when the",
    "links": [
      "Abelian group",
      "Absolute space and time",
      "Addison-Wesley",
      "Additive group",
      "Affine connection",
      "Affine group",
      "Affine plane (incidence geometry)",
      "Affine space",
      "Affine transformation",
      "Ahmes",
      "Algebraic geometry",
      "Alhazen",
      "Altitude (triangle)",
      "American Academy of Arts and Sciences",
      "American Mathematical Monthly",
      "Analytic geometry",
      "Angle",
      "Apollonius of Perga",
      "Archimedes",
      "Area",
      "Area of a circle",
      "Area of a triangle",
      "Arithmetic geometry",
      "Aryabhata",
      "August Möbius",
      "Axiom",
      "Barycentric coordinates (astronomy)",
      "Baudhayana",
      "Before Common Era",
      "Bernhard Riemann",
      "Bijective mapping",
      "Blaise Pascal",
      "Brahmagupta",
      "Carl Friedrich Gauss",
      "Centre (geometry)",
      "Centroid",
      "Ceva's Theorem",
      "Christiaan Huygens",
      "Circle",
      "Circumference",
      "Collinearity",
      "Combinatorics",
      "Complex geometry",
      "Computational geometry",
      "Cone",
      "Congruence (geometry)",
      "Convex geometry",
      "Cube",
      "Cuboid",
      "Curve"
    ],
    "categories": [
      "Category:Affine geometry",
      "Category:Articles containing German-language text",
      "Category:Articles containing Latin-language text",
      "Category:Articles with short description",
      "Category:Commons category link from Wikidata",
      "Category:Pages using sidebar with the child parameter",
      "Category:Short description matches Wikidata"
    ]
  },
  "Algebraic geometry": {
    "title": "Algebraic geometry",
    "url": "https://en.wikipedia.org/wiki/Algebraic_geometry",
    "summary": "Algebraic geometry is a branch of mathematics which uses abstract algebraic techniques, mainly from commutative algebra, to solve geometrical problems. Classically, it studies zeros of multivariate polynomials; the modern approach generalizes this in a few different aspects.\nThe fundamental objects of study in algebraic geometry are algebraic varieties, which are geometric manifestations of solutions of systems of polynomial equations. Examples of the most studied classes of algebraic varieties are lines, circles, parabolas, ellipses, hyperbolas, cubic curves like elliptic curves, and quartic curves like lemniscates and Cassini ovals. These are plane algebraic curves. A point of the plane lies on an algebraic curve if its coordinates satisfy a given polynomial equation. Basic questions involve the study of points of special interest like singular points, inflection points and points at infinity. More advanced questions involve the topology of the curve and the relationship between curv",
    "content": "Algebraic geometry is a branch of mathematics which uses abstract algebraic techniques, mainly from commutative algebra, to solve geometrical problems. Classically, it studies zeros of multivariate polynomials; the modern approach generalizes this in a few different aspects.\nThe fundamental objects of study in algebraic geometry are algebraic varieties, which are geometric manifestations of solutions of systems of polynomial equations. Examples of the most studied classes of algebraic varieties are lines, circles, parabolas, ellipses, hyperbolas, cubic curves like elliptic curves, and quartic curves like lemniscates and Cassini ovals. These are plane algebraic curves. A point of the plane lies on an algebraic curve if its coordinates satisfy a given polynomial equation. Basic questions involve the study of points of special interest like singular points, inflection points and points at infinity. More advanced questions involve the topology of the curve and the relationship between curves defined by different equations.\nAlgebraic geometry occupies a central place in modern mathematics and has multiple conceptual connections with such diverse fields as complex analysis, topology and number theory. As a study of systems of polynomial equations in several variables, the subject of algebraic geometry begins with finding specific solutions via equation solving, and then proceeds to understand the intrinsic properties of the totality of solutions of a system of equations. This understanding requires both conceptual theory and computational technique.\nIn the 20th century, algebraic geometry split into several subareas.\n\nThe mainstream of algebraic geometry is devoted to the study of the complex points of the algebraic varieties and more generally to the points with coordinates in an algebraically closed field.\nReal algebraic geometry is the study of the real algebraic varieties.\nDiophantine geometry and, more generally, arithmetic geometry is the study of algebraic varieties over fields that are not algebraically closed and, specifically, over fields of interest in algebraic number theory, such as the field of rational numbers, number fields, finite fields, function fields, and p-adic fields.\nA large part of singularity theory is devoted to the singularities of algebraic varieties.\nComputational algebraic geometry is an area that has emerged at the intersection of algebraic geometry and computer algebra, with the rise of computers. It consists mainly of algorithm design and software development for the study of properties of explicitly given algebraic varieties.\nMuch of the development of the mainstream of algebraic geometry in the 20th century occurred within an abstract algebraic framework, with increasing emphasis being placed on \"intrinsic\" properties of algebraic varieties not dependent on any particular way of embedding the variety in an ambient coordinate space; this parallels developments in topology, differential and complex geometry. One key achievement of this abstract algebraic geometry is Grothendieck's scheme theory which allows one to use sheaf theory to study algebraic varieties in a way which is very similar to its use in the study of differential and analytic manifolds. This is obtained by extending the notion of point: In classical algebraic geometry, a point of an affine variety may be identified, through Hilbert's Nullstellensatz, with a maximal ideal of the coordinate ring, while the points of the corresponding affine scheme are all prime ideals of this ring. This means that a point of such a scheme may be either a usual point or a subvariety. This approach also enables a unification of the language and the tools of classical algebraic geometry, mainly concerned with complex points, and of algebraic number theory. Wiles' proof of the longstanding conjecture called Fermat's Last Theorem is an example of the power of this approach.\n\nBasic notions\nZeros of simultaneous polynomials\nIn classical algebraic geometry, the main objects of interest are the vanishing sets of collections of polynomials, meaning the set of all points that simultaneously satisfy one or more polynomial equations. For instance, the two-dimensional sphere of radius 1 in three-dimensional Euclidean space R3 could be defined as the set of all points \n  \n    \n      \n        (\n        x\n        ,\n        y\n        ,\n        z\n        )\n      \n    \n    {\\displaystyle (x,y,z)}\n  \n with\n\n  \n    \n      \n        \n          x\n          \n            2\n          \n        \n        +\n        \n          y\n          \n            2\n          \n        \n        +\n        \n          z\n          \n            2\n          \n        \n        −\n        1\n        =\n        0.\n        \n      \n    \n    {\\displaystyle x^{2}+y^{2}+z^{2}-1=0.\\,}\n  \n\nA \"slanted\" circle in R3 can be defined as the set of all points \n  \n    \n      \n        (\n        x\n        ,\n        y\n        ,\n        z\n        )\n      \n    \n    {\\displaystyle (x,y,z)}\n  \n  which satisfy th",
    "links": [
      "Abelian integral",
      "Abelian variety",
      "Absolute geometry",
      "Abstract algebra",
      "Addition",
      "Affine geometry",
      "Affine space",
      "Affine variety",
      "Ahmes",
      "Alexander Grothendieck",
      "Algebra",
      "Algebraic Geometry (book)",
      "Algebraic Geometry (journal)",
      "Algebraic expression",
      "Algebraic function field",
      "Algebraic geometric code",
      "Algebraic geometry of projective spaces",
      "Algebraic number theory",
      "Algebraic space",
      "Algebraic stack",
      "Algebraic statistics",
      "Algebraic surface",
      "Algebraic topology",
      "Algebraic variety",
      "Algebraically closed field",
      "Algorithm",
      "Alhazen",
      "Alicia Dickenstein",
      "Allen Tannenbaum",
      "Altitude (triangle)",
      "American Mathematical Society",
      "An Invitation to Algebraic Geometry",
      "Anabelian geometry",
      "Analytic function",
      "Analytic geometry",
      "Analytic number theory",
      "Analytic variety",
      "André Weil",
      "Angle",
      "Annales de l'Institut Fourier",
      "Apollonius of Perga",
      "Applied mathematics",
      "ArXiv (identifier)",
      "Arakelov's geometry",
      "Archimedes",
      "Area",
      "Area of a circle",
      "Arithmetic",
      "Arithmetic geometry",
      "Arthur Cayley"
    ],
    "categories": [
      "Category:Algebraic geometry",
      "Category:All articles needing additional references",
      "Category:All articles with unsourced statements",
      "Category:Articles needing additional references from January 2020",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from January 2020",
      "Category:CS1 French-language sources (fr)",
      "Category:Pages using sidebar with the child parameter",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Algebraic number theory": {
    "title": "Algebraic number theory",
    "url": "https://en.wikipedia.org/wiki/Algebraic_number_theory",
    "summary": "Algebraic number theory is a branch of number theory that uses the techniques of abstract algebra to study the integers, rational numbers, and their generalizations. Number-theoretic questions are expressed in terms of properties of algebraic objects such as algebraic number fields and their rings of integers, finite fields, and function fields. These properties, such as whether a ring admits unique factorization, the behavior of ideals, and the Galois groups of fields, can resolve questions of primary importance in number theory, like the existence of solutions to Diophantine equations.",
    "content": "Algebraic number theory is a branch of number theory that uses the techniques of abstract algebra to study the integers, rational numbers, and their generalizations. Number-theoretic questions are expressed in terms of properties of algebraic objects such as algebraic number fields and their rings of integers, finite fields, and function fields. These properties, such as whether a ring admits unique factorization, the behavior of ideals, and the Galois groups of fields, can resolve questions of primary importance in number theory, like the existence of solutions to Diophantine equations.\n\nHistory\nDiophantus\nThe beginnings of algebraic number theory can be traced to Diophantine equations, named after the 3rd-century Alexandrian mathematician, Diophantus, who studied them and developed methods for the solution of some kinds of Diophantine equations. A typical Diophantine problem is to find two integers x and y such that their sum, and the sum of their squares, equal two given numbers A and B, respectively:\n\n  \n    \n      \n        A\n        =\n        x\n        +\n        y\n         \n      \n    \n    {\\displaystyle A=x+y\\ }\n  \n\n  \n    \n      \n        B\n        =\n        \n          x\n          \n            2\n          \n        \n        +\n        \n          y\n          \n            2\n          \n        \n        .\n         \n      \n    \n    {\\displaystyle B=x^{2}+y^{2}.\\ }\n  \n\nDiophantine equations have been studied for thousands of years. For example, the solutions to the quadratic Diophantine equation  x2 + y2 = z2 are given by the Pythagorean triples, originally solved by the Babylonians (c. 1800 BC). Solutions to linear Diophantine equations, such as 26x + 65y = 13, may be found using the Euclidean algorithm (c. 5th century BC).\nDiophantus's major work was the Arithmetica, of which only a portion has survived.\n\nFermat\nFermat's Last Theorem was first conjectured by Pierre de Fermat in 1637, famously in the margin of a copy of Arithmetica where he claimed he had a proof that was too large to fit in the margin. No successful proof was published until 1995 despite the efforts of countless mathematicians during the 358 intervening years. The unsolved problem stimulated the development of algebraic number theory in the 19th century and the proof of the modularity theorem in the 20th century.\n\nGauss\nOne of the founding works of algebraic number theory, the Disquisitiones Arithmeticae (Latin: Arithmetical Investigations) is a textbook of number theory written in Latin by Carl Friedrich Gauss in 1798 when Gauss was 21 and first published in 1801 when he was 24. In this book Gauss brings together results in number theory obtained by mathematicians such as Fermat, Euler, Lagrange and Legendre and adds important new results of his own. Before the Disquisitiones was published, number theory consisted of a collection of isolated theorems and conjectures. Gauss brought the work of his predecessors together with his own original work into a systematic framework, filled in gaps, corrected unsound proofs, and extended the subject in numerous ways.\nThe Disquisitiones was the starting point for the work of other nineteenth century European mathematicians including Ernst Kummer, Peter Gustav Lejeune Dirichlet and Richard Dedekind. Many of the annotations given by Gauss are in effect announcements of further research of his own, some of which remained unpublished. They must have appeared particularly cryptic to his contemporaries; we can now read them as containing the germs of the theories of L-functions and complex multiplication, in particular.\n\nDirichlet\nIn a couple of papers in 1838 and 1839 Peter Gustav Lejeune Dirichlet proved the first class number formula, for quadratic forms (later refined by his student Leopold Kronecker). The formula, which Jacobi called a result \"touching the utmost of human acumen\", opened the way for similar results regarding more general number fields. Based on his research of the structure of the unit group of quadratic fields, he proved the Dirichlet unit theorem, a fundamental result in algebraic number theory.\nHe first used the pigeonhole principle, a basic counting argument, in the proof of a theorem in diophantine approximation, later named after him Dirichlet's approximation theorem. He published important contributions to Fermat's last theorem, for which he proved the cases n = 5 and n = 14, and to the biquadratic reciprocity law. The Dirichlet divisor problem, for which he found the first results, is still an unsolved problem in number theory despite later contributions by other researchers.\n\nDedekind\nRichard Dedekind's study of Lejeune Dirichlet's work was what led him to his later study of algebraic number fields and ideals. In 1863, he published Lejeune Dirichlet's lectures on number theory as Vorlesungen über Zahlentheorie (\"Lectures on Number Theory\") about which it has been written that:\n\n\"Although the book is assuredly based on Dirichlet's lectures, and although Dedekind himself referre",
    "links": [
      "0",
      "1",
      "Abelian extension",
      "Abelian group",
      "Absolute value",
      "Absolute value (algebra)",
      "Abstract algebra",
      "Additive number theory",
      "Adele ring",
      "Adrien-Marie Legendre",
      "Albrecht Fröhlich",
      "Alexandria",
      "Algebraic curve",
      "Algebraic function field",
      "Algebraic geometry",
      "Algebraic integer",
      "Algebraic number",
      "Algebraic number field",
      "Algebraic structure",
      "Anabelian geometry",
      "Analytic number theory",
      "Andrew Wiles",
      "André Weil",
      "Arakelov theory",
      "Arithmetic",
      "Arithmetic combinatorics",
      "Arithmetic dynamics",
      "Arithmetic function",
      "Arithmetic geometry",
      "Arithmetic hyperbolic 3-manifold",
      "Arithmetic topology",
      "Arithmetica",
      "Artin L-function",
      "Artin reciprocity law",
      "Artin representation",
      "Associative algebra",
      "Cambridge University Press",
      "Carl Friedrich Gauss",
      "Category (mathematics)",
      "Category of rings",
      "Chinese remainder theorem",
      "Class field theory",
      "Class number (number theory)",
      "Class number formula",
      "Clifford algebra",
      "Cokernel",
      "Commutative algebra",
      "Commutative ring",
      "Commutator (ring theory)",
      "Complete field"
    ],
    "categories": [
      "Category:Algebraic number theory",
      "Category:Articles containing German-language text",
      "Category:Articles with short description",
      "Category:Commons category link from Wikidata",
      "Category:Number theory",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Algebraic structure": {
    "title": "Algebraic structure",
    "url": "https://en.wikipedia.org/wiki/Algebraic_structure",
    "summary": "In mathematics, an algebraic structure or algebraic system consists of a nonempty set A (called the underlying set, carrier set or domain), a collection of operations on A (typically binary operations such as addition and multiplication), and a finite set of identities (known as axioms) that these operations must satisfy.\nAn algebraic structure may be based on other algebraic structures with operations and axioms involving several structures. For instance, a vector space involves a second structure called a field, and an operation called scalar multiplication between elements of the field (called scalars), and elements of the vector space (called vectors).\nAbstract algebra is the name that is commonly given to the study of algebraic structures. The general theory of algebraic structures has been formalized in universal algebra. Category theory is another formalization that includes also other mathematical structures and functions between structures of the same type (homomorphisms).\nIn ",
    "content": "In mathematics, an algebraic structure or algebraic system consists of a nonempty set A (called the underlying set, carrier set or domain), a collection of operations on A (typically binary operations such as addition and multiplication), and a finite set of identities (known as axioms) that these operations must satisfy.\nAn algebraic structure may be based on other algebraic structures with operations and axioms involving several structures. For instance, a vector space involves a second structure called a field, and an operation called scalar multiplication between elements of the field (called scalars), and elements of the vector space (called vectors).\nAbstract algebra is the name that is commonly given to the study of algebraic structures. The general theory of algebraic structures has been formalized in universal algebra. Category theory is another formalization that includes also other mathematical structures and functions between structures of the same type (homomorphisms).\nIn universal algebra, an algebraic structure is called an algebra; this term may be ambiguous, since, in other contexts, an algebra is an algebraic structure that is a vector space over a field or a module over a commutative ring.\nThe collection of all structures of a given type (same operations and same laws) is called a variety in universal algebra; this term is also used with a completely different meaning in algebraic geometry, as an abbreviation of algebraic variety. In category theory, the collection of all structures of a given type and homomorphisms between them form a concrete category.\n\nIntroduction\nAddition and multiplication are prototypical examples of operations that combine two elements of a set to produce a third element of the same set. These operations obey several algebraic laws. For example, a + (b + c) = (a + b) + c and a(bc) = (ab)c are associative laws, and a + b = b + a and ab = ba are commutative laws. Many systems studied by mathematicians have operations that obey some, but not necessarily all, of the laws of ordinary arithmetic. For example, the possible moves of an object in three-dimensional space can be combined by performing a first move of the object, and then a second move from its new position. Such moves, formally called rigid motions, obey the associative law, but fail to satisfy the commutative law.\nSets with one or more operations that obey specific laws are called algebraic structures. When a new problem involves the same laws as such an algebraic structure, all the results that have been proved using only the laws of the structure can be directly applied to the new problem.\nIn full generality, algebraic structures may involve an arbitrary collection of operations, including operations that combine more than two elements (higher arity operations) and operations that take only one argument (unary operations) or even zero arguments (nullary operations). The examples listed below are by no means a complete list, but include the most common structures taught in undergraduate courses.\n\nCommon axioms\nEquational axioms\nAn axiom of an algebraic structure often has the form of an identity, that is, an equation such that the two sides of the equals sign are expressions that involve operations of the algebraic structure and variables. If the variables in the identity are replaced by arbitrary elements of the algebraic structure, the equality must remain true. Here are some common examples.\n\nCommutativity\nAn operation \n  \n    \n      \n        ∗\n      \n    \n    {\\displaystyle *}\n  \n is commutative if \n  \n    \n      \n        x\n        ∗\n        y\n        =\n        y\n        ∗\n        x\n      \n    \n    {\\displaystyle x*y=y*x}\n  \n for every x and y in the algebraic structure.\nAssociativity\nAn operation \n  \n    \n      \n        ∗\n      \n    \n    {\\displaystyle *}\n  \n is associative if \n  \n    \n      \n        (\n        x\n        ∗\n        y\n        )\n        ∗\n        z\n        =\n        x\n        ∗\n        (\n        y\n        ∗\n        z\n        )\n      \n    \n    {\\displaystyle (x*y)*z=x*(y*z)}\n  \n for every x, y and z in the algebraic structure.\nLeft distributivity\nAn operation \n  \n    \n      \n        ∗\n      \n    \n    {\\displaystyle *}\n  \n is left-distributive with respect to another operation \n  \n    \n      \n        +\n      \n    \n    {\\displaystyle +}\n  \n if \n  \n    \n      \n        x\n        ∗\n        (\n        y\n        +\n        z\n        )\n        =\n        (\n        x\n        ∗\n        y\n        )\n        +\n        (\n        x\n        ∗\n        z\n        )\n      \n    \n    {\\displaystyle x*(y+z)=(x*y)+(x*z)}\n  \n for every x, y and z in the algebraic structure (the second operation is denoted here as \n  \n    \n      \n        +\n      \n    \n    {\\displaystyle +}\n  \n, because the second operation is addition in many common examples).\nRight distributivity\nAn operation \n  \n    \n      \n        ∗\n      \n    \n    {\\displaystyle *}\n  \n is right-distributive with respect to another operation \n  \n    \n      \n       ",
    "links": [
      "Abelian group",
      "Absorption law",
      "Abstract algebra",
      "Abuse of notation",
      "Addition",
      "Additive inverse",
      "Affine space",
      "Algebra",
      "Algebra over a field",
      "Algebraic category",
      "Algebraic expression",
      "Algebraic geometry",
      "Algebraic number theory",
      "Algebraic varieties",
      "Algebraic variety",
      "An algebra",
      "Archimedean group",
      "Archimedean property",
      "Argument of a function",
      "Arity",
      "Associative algebra",
      "Associative law",
      "Associativity",
      "Automorphism",
      "Axiom",
      "Banach space",
      "Basis (linear algebra)",
      "Bialgebra",
      "Bilinear map",
      "Binary operation",
      "Boolean algebra (structure)",
      "Bounded lattice",
      "Cambridge University Press",
      "Categories for the Working Mathematician",
      "Category (mathematics)",
      "Category of groups",
      "Category of sets",
      "Category of topological spaces",
      "Category theory",
      "Commutative",
      "Commutative algebra",
      "Commutative law",
      "Commutative ring",
      "Commutativity",
      "Complemented lattice",
      "Complete lattice",
      "Complete metric space",
      "Composition algebra",
      "Concrete category",
      "Coordinate vector"
    ],
    "categories": [
      "Category:Abstract algebra",
      "Category:Algebraic structures",
      "Category:All articles lacking in-text citations",
      "Category:Articles lacking in-text citations from August 2024",
      "Category:Articles with short description",
      "Category:Mathematical structures",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Algebraic topology": {
    "title": "Algebraic topology",
    "url": "https://en.wikipedia.org/wiki/Algebraic_topology",
    "summary": "Algebraic topology is a branch of mathematics that uses tools from abstract algebra to study topological spaces. The basic goal is to find algebraic invariants that classify topological spaces up to homeomorphism, though usually most classify up to homotopy equivalence.\nAlthough algebraic topology primarily uses algebra to study topological problems, using topology to solve algebraic problems is sometimes also possible. Algebraic topology, for example, allows for a convenient proof that any subgroup of a free group is again a free group.",
    "content": "Algebraic topology is a branch of mathematics that uses tools from abstract algebra to study topological spaces. The basic goal is to find algebraic invariants that classify topological spaces up to homeomorphism, though usually most classify up to homotopy equivalence.\nAlthough algebraic topology primarily uses algebra to study topological problems, using topology to solve algebraic problems is sometimes also possible. Algebraic topology, for example, allows for a convenient proof that any subgroup of a free group is again a free group.\n\nMain branches\nBelow are some of the main areas studied in algebraic topology:\n\nHomotopy groups\nIn mathematics, homotopy groups are used in algebraic topology to classify topological spaces. The first and simplest homotopy group is the fundamental group, which records information about loops in a space. Intuitively, homotopy groups record information about the basic shape, or holes, of a topological space.\n\nHomology\nIn algebraic topology and abstract algebra, homology (in part from Greek ὁμός homos \"identical\") is a certain general procedure to associate a sequence of abelian groups or modules with a given mathematical object such as a topological space or a group.\n\nCohomology\nIn homology theory and algebraic topology, cohomology is a general term for a sequence of abelian groups defined from a cochain complex. That is, cohomology is defined as the abstract study of cochains, cocycles, and coboundaries. Cohomology can be viewed as a method of assigning algebraic invariants to a topological space that has a more refined algebraic structure than does homology. Cohomology arises from the algebraic dualization of the construction of homology. In less abstract language, cochains in the fundamental sense should assign \"quantities\" to the chains of homology theory.\n\nManifolds\nA manifold is a topological space that near each point resembles Euclidean space. Examples include the plane, the sphere, and the torus, which can all be realized in three dimensions, but also the Klein bottle and real projective plane which cannot be embedded in three dimensions, but can be embedded in four dimensions. Typically, results in algebraic topology focus on global, non-differentiable aspects of manifolds; for example Poincaré duality.\n\nKnot theory\nKnot theory is the study of mathematical knots. While inspired by knots that appear in daily life in shoelaces and rope, a mathematician's knot differs in that the ends are joined so that it cannot be undone. In precise mathematical language, a knot is an embedding of a circle in three-dimensional Euclidean space, \n  \n    \n      \n        \n          \n            R\n          \n          \n            3\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{3}}\n  \n. Two mathematical knots are equivalent if one can be transformed into the other via a deformation of \n  \n    \n      \n        \n          \n            R\n          \n          \n            3\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{3}}\n  \n upon itself (known as an ambient isotopy); these transformations correspond to manipulations of a knotted string that do not involve cutting the string or passing the string through itself.\n\nComplexes\nA simplicial complex is a topological space of a certain kind, constructed by \"gluing together\" points, line segments, triangles, and their n-dimensional counterparts (see illustration). Simplicial complexes should not be confused with the more abstract notion of a simplicial set appearing in modern simplicial homotopy theory. The purely combinatorial counterpart to a simplicial complex is an abstract simplicial complex.\nA CW complex is a type of topological space introduced by J. H. C. Whitehead to meet the needs of homotopy theory. This class of spaces is broader and has some better categorical properties than simplicial complexes, but still retains a combinatorial nature that allows for computation (often with a much smaller complex).\n\nMethod of algebraic invariants\nAn older name for the subject was combinatorial topology, implying an emphasis on how a space X was constructed from simpler ones (the modern standard tool for such construction is the CW complex). In the 1920s and 1930s, there was growing emphasis on investigating topological spaces by finding correspondences from them to algebraic groups, which led to the change of name to algebraic topology. The combinatorial topology name is still sometimes used to emphasize an algorithmic approach based on decomposition of spaces.\nIn the algebraic approach, one finds a correspondence between spaces and groups that respects the relation of homeomorphism (or more general homotopy) of spaces. This allows one to recast statements about topological spaces into statements about groups, which have a great deal of manageable structure, often making these statements easier to prove. Two major ways in which this can be done are through fundamental groups, or more generally homotopy theory, and",
    "links": [
      "Abelian group",
      "Abstract algebra",
      "Abstract simplicial complex",
      "Addison-Wesley",
      "Albrecht Dold",
      "Alexander Grothendieck",
      "Algebraic K-theory",
      "Algebraic invariant",
      "Algebraic structure",
      "Algebraic topology (object)",
      "Allen Hatcher",
      "Ambient isotopy",
      "American Journal of Mathematics",
      "ArXiv (identifier)",
      "Armand Borel",
      "Banach fixed-point theorem",
      "Barry Mazur",
      "Betti number",
      "Bibcode (identifier)",
      "Blakers–Massey theorem",
      "Borsuk–Ulam theorem",
      "Brouwer fixed point theorem",
      "Bundle (mathematics)",
      "CW complex",
      "Cambridge University Press",
      "Category (mathematics)",
      "Category theory",
      "Cellular approximation theorem",
      "Chain (algebraic topology)",
      "Chain complex",
      "Charles Ehresmann",
      "Chern class",
      "Circle",
      "Classification theorem",
      "Closed set",
      "Cobordism",
      "Coboundary",
      "Cohomology",
      "Combinatorial topology",
      "Compact space",
      "Connected space",
      "Continuity (topology)",
      "Continuous function",
      "Continuum (topology)",
      "Covering space",
      "Crossed module",
      "Daniel Kan",
      "Daniel Quillen",
      "De Rham cohomology",
      "Dennis Sullivan"
    ],
    "categories": [
      "Category:Algebraic topology",
      "Category:Articles with short description",
      "Category:CS1: long volume value",
      "Category:Commons category link from Wikidata",
      "Category:Short description matches Wikidata"
    ]
  },
  "Algorithm": {
    "title": "Algorithm",
    "url": "https://en.wikipedia.org/wiki/Algorithm",
    "summary": "In mathematics and computer science, an algorithm ( ) is a finite sequence of mathematically rigorous instructions, typically used to solve a class of specific problems or to perform a computation. Algorithms are used as specifications for performing calculations and data processing. More advanced algorithms can use conditionals to divert the code execution through various routes (referred to as automated decision-making) and deduce valid inferences (referred to as automated reasoning).\nIn contrast, a heuristic is an approach to solving problems without well-defined correct or optimal results. For example, although social media recommender systems are commonly called \"algorithms\", they actually rely on heuristics as there is no truly \"correct\" recommendation.\nAs an effective method, an algorithm can be expressed within a finite amount of space and time and in a well-defined formal language for calculating a function. Starting from an initial state and initial input (perhaps empty), the",
    "content": "In mathematics and computer science, an algorithm ( ) is a finite sequence of mathematically rigorous instructions, typically used to solve a class of specific problems or to perform a computation. Algorithms are used as specifications for performing calculations and data processing. More advanced algorithms can use conditionals to divert the code execution through various routes (referred to as automated decision-making) and deduce valid inferences (referred to as automated reasoning).\nIn contrast, a heuristic is an approach to solving problems without well-defined correct or optimal results. For example, although social media recommender systems are commonly called \"algorithms\", they actually rely on heuristics as there is no truly \"correct\" recommendation.\nAs an effective method, an algorithm can be expressed within a finite amount of space and time and in a well-defined formal language for calculating a function. Starting from an initial state and initial input (perhaps empty), the instructions describe a computation that, when executed, proceeds through a finite number of well-defined successive states, eventually producing \"output\" and terminating at a final ending state. The transition from one state to the next is not necessarily deterministic; some algorithms, known as randomized algorithms, incorporate random input.\n\nEtymology\nAround 825 AD, Persian scientist and polymath Muḥammad ibn Mūsā al-Khwārizmī wrote kitāb al-ḥisāb al-hindī (\"Book of Indian computation\") and kitab al-jam' wa'l-tafriq al-ḥisāb al-hindī (\"Addition and subtraction in Indian arithmetic\"). In the early 12th century, Latin translations of these texts involving the Hindu–Arabic numeral system and arithmetic appeared, for example Liber Alghoarismi de practica arismetrice, attributed to John of Seville, and Liber Algorismi de numero Indorum, attributed to Adelard of Bath. Here, alghoarismi or algorismi is the Latinization of Al-Khwarizmi's name; the text starts with the phrase Dixit Algorismi, or \"Thus spoke Al-Khwarizmi\".\nThe word algorism in English came to mean the use of place-value notation in calculations; it occurs in the Ancrene Wisse from circa 1225. By the time Geoffrey Chaucer wrote The Canterbury Tales in the late 14th century, he used a variant of the same word in describing augrym stones, stones used for place-value calculation. In the 15th century, under the influence of the Greek word ἀριθμός (arithmos, \"number\"; cf. \"arithmetic\"), the Latin word was altered to algorithmus. By 1596, this form of the word was used in English, as algorithm, by Thomas Hood.\n\nDefinition\nOne informal definition is \"a set of rules that precisely defines a sequence of operations\", which would include all computer programs (including programs that do not perform numeric calculations), and any prescribed bureaucratic procedure\nor cook-book recipe. In general, a program is an algorithm only if it stops eventually—even though infinite loops may sometimes prove desirable. Boolos, Jeffrey & 1974, 1999 define an algorithm to be an explicit set of instructions for determining an output, that can be followed by a computing machine or a human who could only carry out specific elementary operations on symbols.\nMost algorithms are intended to be implemented as computer programs. However, algorithms are also implemented by other means, such as in a biological neural network (for example, the human brain performing arithmetic or an insect looking for food), in an electrical circuit, or a mechanical device.\n\nHistory\nAncient algorithms\nStep-by-step procedures for solving mathematical problems have been recorded since antiquity. This includes in Babylonian mathematics (around 2500 BC), Egyptian mathematics (around 1550 BC), Indian mathematics (around 800 BC and later), the Ifa Oracle (around 500 BC), Greek mathematics (around 240 BC), Chinese mathematics (around 200 BC and later), and Arabic mathematics (around 800 AD).\nThe earliest evidence of algorithms is found in ancient Mesopotamian mathematics. A Sumerian clay tablet found in Shuruppak near Baghdad and dated to c. 2500 BC describes the earliest division algorithm. During the Hammurabi dynasty c. 1800 – c. 1600 BC, Babylonian clay tablets described algorithms for computing formulas. Algorithms were also used in Babylonian astronomy. Babylonian clay tablets describe and employ algorithmic procedures to compute the time and place of significant astronomical events.\nAlgorithms for arithmetic are also found in ancient Egyptian mathematics, dating back to the Rhind Mathematical Papyrus c. 1550 BC. Algorithms were later used in ancient Hellenistic mathematics. Two examples are the Sieve of Eratosthenes, which was described in the Introduction to Arithmetic by Nicomachus, and the Euclidean algorithm, which was first described in Euclid's Elements (c. 300 BC).Examples of ancient Indian mathematics included the Shulba Sutras, the Kerala School, and the Brāhmasphuṭasiddhānta.\nThe first cryptographic algorithm f",
    "links": [
      "A.A. Markov",
      "A. M. Turing",
      "ALGOL",
      "Abstract machine",
      "Ada Lovelace",
      "Adelard of Bath",
      "Al-Khwarizmi",
      "Al-Kindi",
      "Alan Turing",
      "Alan Turing: The Enigma",
      "Algebra of physical space",
      "Algebraic structure",
      "Algorism",
      "Algorithm (disambiguation)",
      "Algorithm aversion",
      "Algorithm characterizations",
      "Algorithm design",
      "Algorithm engineering",
      "Algorithmic bias",
      "Algorithmic composition",
      "Algorithmic efficiency",
      "Algorithmic entities",
      "Algorithmic paradigm",
      "Algorithmic synthesis",
      "Algorithmic technique",
      "Algorithmic topology",
      "Alonzo Church",
      "Analysis of algorithms",
      "Analytical engine",
      "Analytical mechanics",
      "Ancrene Wisse",
      "Andreas Blass",
      "Andrew Hodges",
      "Applied mathematics",
      "Approximation algorithm",
      "Approximation theory",
      "Arabic mathematics",
      "Arithmetic",
      "Array (data structure)",
      "Arthur Zimek",
      "Asger Aaboe",
      "Assembly code",
      "Assignment (computer science)",
      "Association for Computing Machinery",
      "Associative array",
      "Asymptotically optimal",
      "Automata theory",
      "Automated decision-making",
      "Automated reasoning",
      "Automated theorem proving"
    ],
    "categories": [
      "Category:Algorithms",
      "Category:Articles to be expanded from October 2023",
      "Category:Articles with example pseudocode",
      "Category:Articles with short description",
      "Category:CS1: abbreviated year range",
      "Category:Commons category link from Wikidata",
      "Category:Mathematical logic",
      "Category:Pages including recorded pronunciations",
      "Category:Pages using the Phonos extension",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Analysis (mathematics)": {
    "title": "Mathematical analysis",
    "url": "https://en.wikipedia.org/wiki/Mathematical_analysis",
    "summary": "Analysis is the branch of mathematics dealing with continuous functions, limits, and related theories, such as differentiation, integration, measure, infinite sequences, series, and analytic functions.\nThese theories are usually studied in the context of real and complex numbers and functions. Analysis evolved from calculus, which involves the elementary concepts and techniques of analysis.\nAnalysis may be distinguished from geometry; however, it can be applied to any space of mathematical objects that has a definition of nearness (a topological space) or specific distances between objects  (a metric space).",
    "content": "Analysis is the branch of mathematics dealing with continuous functions, limits, and related theories, such as differentiation, integration, measure, infinite sequences, series, and analytic functions.\nThese theories are usually studied in the context of real and complex numbers and functions. Analysis evolved from calculus, which involves the elementary concepts and techniques of analysis.\nAnalysis may be distinguished from geometry; however, it can be applied to any space of mathematical objects that has a definition of nearness (a topological space) or specific distances between objects  (a metric space).\n\nHistory\nAncient\nMathematical analysis formally developed in the 17th century during the Scientific Revolution, but many of its ideas can be traced back to earlier mathematicians. Early results in analysis were implicitly present in the early days of ancient Greek mathematics. For instance, an infinite geometric sum is implicit in Zeno's paradox of the dichotomy. (Strictly speaking, the point of the paradox is to deny that the infinite sum exists.) Later, Greek mathematicians such as Eudoxus and Archimedes made more explicit, but informal, use of the concepts of limits and convergence when they used the method of exhaustion to compute the area and volume of regions and solids. The explicit use of infinitesimals appears in Archimedes' The Method of Mechanical Theorems, a work rediscovered in the 20th century. In Asia, the Chinese mathematician Liu Hui used the method of exhaustion in the 3rd century CE to find the area of a circle. From Jain literature, it appears that Hindus were in possession of the formulae for the sum of the arithmetic and geometric series as early as the 4th century BCE.\nĀcārya Bhadrabāhu uses the sum of a geometric series in his Kalpasūtra in 433 BCE.\n\nMedieval\nZu Chongzhi established a method that would later be called Cavalieri's principle to find the volume of a sphere in the 5th century. In the 12th century, the Indian mathematician Bhāskara II used infinitesimal and used what is now known as Rolle's theorem.\nIn the 14th century, Madhava of Sangamagrama developed infinite series expansions, now called Taylor series, of functions such as sine, cosine, tangent and arctangent. Alongside his development of Taylor series of trigonometric functions, he also estimated the magnitude of the error terms resulting of truncating these series, and gave a rational approximation of some infinite series.  His followers at the Kerala School of Astronomy and Mathematics further expanded his works, up to the 16th century.\n\nModern\nFoundations\nThe modern foundations of mathematical analysis were established in 17th century Europe. This began when Fermat and Descartes developed analytic geometry, which is the precursor to modern calculus. Fermat's method of adequality allowed him to determine the maxima and minima of functions and the tangents of curves. Descartes's publication of La Géométrie in 1637, which introduced the Cartesian coordinate system, is considered to be the establishment of mathematical analysis. It would be a few decades later that Newton and Leibniz independently developed infinitesimal calculus, which grew, with the stimulus of applied work that continued through the 18th century, into analysis topics such as the calculus of variations, ordinary and partial differential equations, Fourier analysis, and generating functions. During this period, calculus techniques were applied to approximate discrete problems by continuous ones.\n\nModernization\nIn the 18th century, Euler introduced the notion of a mathematical function. Real analysis began to emerge as an independent subject when Bernard Bolzano introduced the modern definition of continuity in 1816, but Bolzano's work did not become widely known until the 1870s. In 1821, Cauchy began to put calculus on a firm logical foundation by rejecting the principle of the generality of algebra widely used in earlier work, particularly by Euler.  Instead, Cauchy formulated calculus in terms of geometric ideas and infinitesimals.  Thus, his definition of continuity required an infinitesimal change in x to correspond to an infinitesimal change in y.  He also introduced the concept of the Cauchy sequence, and started the formal theory of complex analysis. Poisson, Liouville, Fourier and others studied partial differential equations and harmonic analysis.  The contributions of these mathematicians and others, such as Weierstrass, developed the (ε, δ)-definition of limit approach, thus founding the modern field of mathematical analysis. Around the same time, Riemann introduced his theory of integration, and made significant advances in complex analysis.\nTowards the end of the 19th century, mathematicians started worrying that they were assuming the existence of a continuum of real numbers without proof. Dedekind then constructed the real numbers by Dedekind cuts, in which irrational numbers are formally defined, which serve to fill the \"gaps\" bet",
    "links": [
      "(ε, δ)-definition of limit",
      "A History of Vector Analysis",
      "Abstract algebra",
      "Addison–Wesley",
      "Adequality",
      "Aleksandr Danilovich Aleksandrov",
      "Aleksandr Khinchin",
      "Algebra",
      "Algebra of physical space",
      "Algebraic geometry",
      "Algebraic number theory",
      "Algebraic structure",
      "Algebraic topology",
      "Algorithm",
      "Algorithm design",
      "Amazon Standard Identification Number",
      "American Mathematical Society",
      "Analysis of algorithms",
      "Analytic combinatorics",
      "Analytic function",
      "Analytic geometry",
      "Analytic number theory",
      "Analytical mechanics",
      "Andrey Kolmogorov",
      "Andrey Nikolaevich Kolmogorov",
      "Applied mathematics",
      "Approximation",
      "Approximation theory",
      "Archimedes",
      "Area",
      "Areas of mathematics",
      "Arithmetic",
      "Arithmetic geometry",
      "Arithmetic series",
      "At the University Press",
      "Augustin Louis Cauchy",
      "Automata theory",
      "Automated theorem proving",
      "Axiom of choice",
      "Baire category theorem",
      "Bernard Bolzano",
      "Bernhard Riemann",
      "Bhadrabahu",
      "Bhāskara II",
      "Bibcode (identifier)",
      "Biology",
      "Boris Demidovich",
      "Bosonic string theory",
      "Calculus",
      "Calculus of variations"
    ],
    "categories": [
      "Category:Articles using Template:ASIN with an all-numeric value",
      "Category:Articles with short description",
      "Category:CS1 French-language sources (fr)",
      "Category:CS1 Italian-language sources (it)",
      "Category:CS1 errors: ISBN date",
      "Category:Commons category link from Wikidata",
      "Category:Mathematical analysis",
      "Category:Pages using sidebar with the child parameter",
      "Category:Short description matches Wikidata",
      "Category:Use dmy dates from May 2021"
    ]
  },
  "Analytic geometry": {
    "title": "Analytic geometry",
    "url": "https://en.wikipedia.org/wiki/Analytic_geometry",
    "summary": "In mathematics, analytic geometry, also known as coordinate geometry or Cartesian geometry, is the study of geometry using a coordinate system. This contrasts with synthetic geometry.\nAnalytic geometry is used in physics and engineering, and also in aviation, rocketry, space science, and spaceflight. It is the foundation of most modern fields of geometry, including algebraic, differential, discrete and computational geometry.\nUsually the Cartesian coordinate system is applied to manipulate equations for planes, straight lines, and circles, often in two and sometimes three dimensions. Geometrically, one studies the Euclidean plane (two dimensions) and Euclidean space. As taught in school books, analytic geometry can be explained more simply: it is concerned with defining and representing geometric shapes in a numerical way and extracting numerical information from shapes' numerical definitions and representations. That the algebra of the real numbers can be employed to yield results abo",
    "content": "In mathematics, analytic geometry, also known as coordinate geometry or Cartesian geometry, is the study of geometry using a coordinate system. This contrasts with synthetic geometry.\nAnalytic geometry is used in physics and engineering, and also in aviation, rocketry, space science, and spaceflight. It is the foundation of most modern fields of geometry, including algebraic, differential, discrete and computational geometry.\nUsually the Cartesian coordinate system is applied to manipulate equations for planes, straight lines, and circles, often in two and sometimes three dimensions. Geometrically, one studies the Euclidean plane (two dimensions) and Euclidean space. As taught in school books, analytic geometry can be explained more simply: it is concerned with defining and representing geometric shapes in a numerical way and extracting numerical information from shapes' numerical definitions and representations. That the algebra of the real numbers can be employed to yield results about the linear continuum of geometry relies on the Cantor–Dedekind axiom.\n\nHistory\nAncient Greece\nThe Greek mathematician Menaechmus solved problems and proved theorems by using a method that had a strong resemblance to the use of coordinates and it has sometimes been maintained that he had introduced analytic geometry.\nApollonius of Perga, in On Determinate Section, dealt with problems in a manner that may be called an analytic geometry of one dimension; with the question of finding points on a line that were in a ratio to the others. Apollonius in the Conics further developed a method that is so similar to analytic geometry that his work is sometimes thought to have anticipated the work of Descartes by some 1800 years. His application of reference lines, a diameter and a tangent is essentially no different from our modern use of a coordinate frame, where the distances measured along the diameter from the point of tangency are the abscissas, and the segments parallel to the tangent and intercepted between the axis and the curve are the ordinates. He further developed relations between the abscissas and the corresponding ordinates that are equivalent to rhetorical equations (expressed in words) of curves. However, although Apollonius came close to developing analytic geometry, he did not manage to do so since he did not take into account negative magnitudes and in every case the coordinate system was superimposed upon a given curve a posteriori instead of a priori. That is, equations were determined by curves, but curves were not determined by equations. Coordinates, variables, and equations were subsidiary notions applied to a specific geometric situation.\n\nPersia\nThe 11th-century Persian mathematician Omar Khayyam saw a strong relationship between geometry and algebra and was moving in the right direction when he helped close the gap between numerical and geometric algebra with his geometric solution of the general cubic equations, but the decisive step came later with Descartes. Omar Khayyam is credited with identifying the foundations of algebraic geometry, and his book Treatise on Demonstrations of Problems of Algebra (1070), which laid down the principles of analytic geometry, is part of the body of Persian mathematics that was eventually transmitted to Europe. Because of his thoroughgoing geometrical approach to algebraic equations, Khayyam can be considered a precursor to Descartes in the invention of analytic geometry.\n\nWestern Europe\nAnalytic geometry was independently invented by René Descartes and Pierre de Fermat, although Descartes is sometimes given sole credit. Cartesian geometry, the alternative term used for analytic geometry, is named after Descartes.\nDescartes made significant progress with the methods in an essay titled La Géométrie (Geometry), one of the three accompanying essays (appendices) published in 1637 together with his Discourse on the Method for Rightly Directing One's Reason and Searching for Truth in the Sciences, commonly referred to as Discourse on Method.\nLa Geometrie, written in his native French tongue, and its philosophical principles, provided a foundation for calculus in Europe. Initially the work was not well received, due, in part, to the many gaps in arguments and complicated equations. Only after the translation into Latin and the addition of commentary by van Schooten in 1649 (and further work thereafter) did Descartes's masterpiece receive due recognition.\nPierre de Fermat also pioneered the development of analytic geometry. Although not published in his lifetime, a manuscript form of Ad locos planos et solidos isagoge (Introduction to Plane and Solid Loci) was circulating in Paris in 1637, just prior to the publication of Descartes' Discourse. Clearly written and well received, the Introduction also laid the groundwork for analytical geometry. The key difference between Fermat's and Descartes' treatments is a matter of viewpoint: Fermat always started with an algebraic equation a",
    "links": [
      "Abstract algebra",
      "Aerospace engineering",
      "Affine coordinates",
      "Affine geometry",
      "Affine transformations",
      "Ahmes",
      "Algebra",
      "Algebraic equation",
      "Algebraic geometry",
      "Algebraic number theory",
      "Algebraic topology",
      "Alhazen",
      "Altitude (triangle)",
      "American Mathematical Monthly",
      "Analytic number theory",
      "Ancient Greece",
      "Angle",
      "Apollonius of Perga",
      "Applied geometry",
      "Applied mathematics",
      "Archimedes",
      "Area",
      "Area of a circle",
      "Arithmetic",
      "Arithmetic geometry",
      "Aryabhata",
      "Aviation",
      "Balloonist theory",
      "Baudhayana",
      "Before Common Era",
      "Bernhard Riemann",
      "Blaise Pascal",
      "Brahmagupta",
      "CRC Press",
      "Calculus",
      "Cantor–Dedekind axiom",
      "Carl Benjamin Boyer",
      "Carl Friedrich Gauss",
      "Cartesian circle",
      "Cartesian coordinate system",
      "Cartesian coordinates",
      "Cartesian diver",
      "Cartesian doubt",
      "Cartesian plane",
      "Cartesianism",
      "Category theory",
      "Causal adequacy principle",
      "Christiaan Huygens",
      "Christina, Queen of Sweden",
      "Circle"
    ],
    "categories": [
      "Category:All articles with unsourced statements",
      "Category:Analytic geometry",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from April 2022",
      "Category:Pages using sidebar with the child parameter",
      "Category:Short description matches Wikidata",
      "Category:Webarchive template wayback links"
    ]
  },
  "Apery's theorem": {
    "title": "Apéry's theorem",
    "url": "https://en.wikipedia.org/wiki/Ap%C3%A9ry%27s_theorem",
    "summary": "In mathematics, Apéry's theorem is a result in number theory that states the Apéry's constant ζ(3) is irrational. That is, the number\n\n  \n    \n      \n        ζ\n        (\n        3\n        )\n        =\n        \n          ∑\n          \n            n\n            =\n            1\n          \n          \n            ∞\n          \n        \n        \n          \n            1\n            \n              n\n              \n                3\n              \n            \n          \n        \n        =\n        \n          \n            1\n            \n              1\n              \n                3\n              \n            \n          \n        \n        +\n        \n          \n            1\n            \n              2\n              \n                3\n              \n            \n          \n        \n        +\n        \n          \n            1\n            \n              3\n              \n                3\n              \n            \n          \n        \n        +\n        ⋯\n        =\n        1.2020569\n        …\n      ",
    "content": "In mathematics, Apéry's theorem is a result in number theory that states the Apéry's constant ζ(3) is irrational. That is, the number\n\n  \n    \n      \n        ζ\n        (\n        3\n        )\n        =\n        \n          ∑\n          \n            n\n            =\n            1\n          \n          \n            ∞\n          \n        \n        \n          \n            1\n            \n              n\n              \n                3\n              \n            \n          \n        \n        =\n        \n          \n            1\n            \n              1\n              \n                3\n              \n            \n          \n        \n        +\n        \n          \n            1\n            \n              2\n              \n                3\n              \n            \n          \n        \n        +\n        \n          \n            1\n            \n              3\n              \n                3\n              \n            \n          \n        \n        +\n        ⋯\n        =\n        1.2020569\n        …\n      \n    \n    {\\displaystyle \\zeta (3)=\\sum _{n=1}^{\\infty }{\\frac {1}{n^{3}}}={\\frac {1}{1^{3}}}+{\\frac {1}{2^{3}}}+{\\frac {1}{3^{3}}}+\\cdots =1.2020569\\ldots }\n  \n\ncannot be written as a fraction \n  \n    \n      \n        p\n        \n          /\n        \n        q\n      \n    \n    {\\displaystyle p/q}\n  \n where p and q are integers. The theorem is named after Roger Apéry.\nThe special values of the Riemann zeta function at even integers \n  \n    \n      \n        2\n        n\n      \n    \n    {\\displaystyle 2n}\n  \n (\n  \n    \n      \n        n\n        >\n        0\n      \n    \n    {\\displaystyle n>0}\n  \n) can be shown in terms of Bernoulli numbers to be irrational, while it remains open whether the function's values are in general rational or not at the odd integers \n  \n    \n      \n        2\n        n\n        +\n        1\n      \n    \n    {\\displaystyle 2n+1}\n  \n (\n  \n    \n      \n        n\n        >\n        1\n      \n    \n    {\\displaystyle n>1}\n  \n) (though they are conjectured to be irrational).\n\nHistory\nLeonhard Euler proved that if n is a positive integer then\n\n  \n    \n      \n        \n          \n            1\n            \n              1\n              \n                2\n                n\n              \n            \n          \n        \n        +\n        \n          \n            1\n            \n              2\n              \n                2\n                n\n              \n            \n          \n        \n        +\n        \n          \n            1\n            \n              3\n              \n                2\n                n\n              \n            \n          \n        \n        +\n        \n          \n            1\n            \n              4\n              \n                2\n                n\n              \n            \n          \n        \n        +\n        ⋯\n        =\n        \n          \n            p\n            q\n          \n        \n        \n          π\n          \n            2\n            n\n          \n        \n      \n    \n    {\\displaystyle {\\frac {1}{1^{2n}}}+{\\frac {1}{2^{2n}}}+{\\frac {1}{3^{2n}}}+{\\frac {1}{4^{2n}}}+\\cdots ={\\frac {p}{q}}\\pi ^{2n}}\n  \n\nfor some rational number \n  \n    \n      \n        p\n        \n          /\n        \n        q\n      \n    \n    {\\displaystyle p/q}\n  \n. Specifically, writing the infinite series on the left as \n  \n    \n      \n        ζ\n        (\n        2\n        n\n        )\n      \n    \n    {\\displaystyle \\zeta (2n)}\n  \n, he showed\n\n  \n    \n      \n        ζ\n        (\n        2\n        n\n        )\n        =\n        (\n        −\n        1\n        \n          )\n          \n            n\n            +\n            1\n          \n        \n        \n          \n            \n              \n                B\n                \n                  2\n                  n\n                \n              \n              (\n              2\n              π\n              \n                )\n                \n                  2\n                  n\n                \n              \n            \n            \n              2\n              (\n              2\n              n\n              )\n              !\n            \n          \n        \n      \n    \n    {\\displaystyle \\zeta (2n)=(-1)^{n+1}{\\frac {B_{2n}(2\\pi )^{2n}}{2(2n)!}}}\n  \n\nwhere the \n  \n    \n      \n        \n          B\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle B_{n}}\n  \n are the rational Bernoulli numbers. Once it was proved that \n  \n    \n      \n        \n          π\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\pi ^{n}}\n  \n is always irrational, this showed that  \n  \n    \n      \n        ζ\n        (\n        2\n        n\n        )\n      \n    \n    {\\displaystyle \\zeta (2n)}\n  \n is irrational for all positive integers n.\nNo such representation in terms of π is known for the so-called zeta constants for odd arguments, the values \n  \n    \n      \n        ζ\n        (\n        2\n        n\n        +\n        1\n        )\n      \n    \n    {\\displaystyle \\zeta (2n+1)}\n  \n for positive integers n. It has been conjectured that the ratios of the",
    "links": [
      "Alfred van der Poorten",
      "Algebraic number",
      "Apéry's constant",
      "ArXiv (identifier)",
      "Bernoulli number",
      "Bernoulli numbers",
      "Bibcode (identifier)",
      "Conjecture",
      "Coprime",
      "Dimension (vector space)",
      "Doi (identifier)",
      "Frits Beukers",
      "Hadjicostas's formula",
      "Heisenberg model (quantum)",
      "Hendrik Lenstra",
      "Henri Cohen (number theorist)",
      "Hypergeometric series",
      "Integer",
      "Integral",
      "Irrational number",
      "JSTOR (identifier)",
      "Leonhard Euler",
      "Mathematics",
      "Minimal polynomial (field theory)",
      "Number theory",
      "On-Line Encyclopedia of Integer Sequences",
      "Parity (mathematics)",
      "Particular values of the Riemann zeta function",
      "Peter Gustav Lejeune Dirichlet",
      "Proceedings - Mathematical Sciences",
      "Proof by contradiction",
      "Rational number",
      "Riemann zeta function",
      "Roger Apéry",
      "S2CID (identifier)",
      "Sequence",
      "Shifted Legendre polynomials",
      "Tanguy Rivoal",
      "The Mathematical Intelligencer",
      "Transcendental number",
      "Vector space",
      "Wadim Zudilin",
      "Yuri Valentinovich Nesterenko",
      "Zeta constants"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1 Russian-language sources (ru)",
      "Category:CS1 uses Russian-language script (ru)",
      "Category:Short description is different from Wikidata",
      "Category:Theorems in number theory",
      "Category:Zeta and L-functions"
    ]
  },
  "American Mathematical Society": {
    "title": "American Mathematical Society",
    "url": "https://en.wikipedia.org/wiki/American_Mathematical_Society",
    "summary": "The American Mathematical Society (AMS) is an association of professional mathematicians dedicated to the interests of mathematical research and scholarship, and serves the national and international community through its publications, meetings, advocacy and other programs.\nThe society is one of the four parts of the Joint Policy Board for Mathematics and a member of the Conference Board of the Mathematical Sciences.",
    "content": "The American Mathematical Society (AMS) is an association of professional mathematicians dedicated to the interests of mathematical research and scholarship, and serves the national and international community through its publications, meetings, advocacy and other programs.\nThe society is one of the four parts of the Joint Policy Board for Mathematics and a member of the Conference Board of the Mathematical Sciences.\n\nHistory\nThe AMS was founded in 1888 as the New York Mathematical Society, the brainchild of Thomas Fiske, who was impressed by the London Mathematical Society on a visit to England. John Howard Van Amringe became the first president while Fiske became secretary. The society soon decided to publish a journal, but ran into some resistance over concerns about competing with the American Journal of Mathematics. The result was the Bulletin of the American Mathematical Society, with Fiske as editor-in-chief. The de facto journal, as intended, was influential in increasing membership. The popularity of the Bulletin soon led to the launches of the Transactions of the American Mathematical Society and Proceedings of the American Mathematical Society, which were also de facto journals.\nIn 1891, Charlotte Scott of Britain became the first woman to join the AMS, then called the New York Mathematical Society. The society reorganized under its present name (American Mathematical Society) and became a national society in 1894, and that year Scott became the first woman on the first Council of the society. In 1927 Anna Pell-Wheeler became the first woman to present a lecture at the society's Colloquium.\nIn 1951 there was a southeastern sectional meeting of the Mathematical Association of America in Nashville. The citation delivered at the 2007 MAA awards presentation, where Lee Lorch received a standing ovation, recorded that:\n\n\"Lee Lorch, the chair of the mathematics department at Fisk University, and three Black colleagues, Evelyn Boyd (now Granville), Walter Brown, and H. M. Holloway came to the meeting and were able to attend the scientific sessions. However, the organizer for the closing banquet refused to honor the reservations of these four mathematicians. (Letters in Science, August 10, 1951, pp. 161–162 spell out the details). Lorch and his colleagues wrote to the governing bodies of the AMS [American Mathematical Society] and MAA seeking bylaws against discrimination. Bylaws were not changed, but non-discriminatory policies were established and have been strictly observed since then.\"\nAlso in 1951, the American Mathematical Society's headquarters moved from New York City to Providence, Rhode Island. The society later added an office in Ann Arbor, Michigan in 1965 and an office in Washington, D.C. in 1992.\nIn 1954 the society called for the creation of a new teaching degree, a Doctor of Arts in Mathematics, similar to a PhD but without a research thesis.\nIn the 1970s, as reported in \"A Brief History of the Association for Women in Mathematics: The Presidents' Perspectives\" by Lenore Blum, \"In those years the AMS was governed by what could only be called an 'old boys network,' closed to all but those in the inner circle.\" Mary W. Gray challenged that situation by \"sitting in on the Council meeting in Atlantic City. When she was told she had to leave, she refused saying she would wait until the police came. (Mary relates the story somewhat differently: When she was told she had to leave, she responded she could find no rules in the by-laws restricting attendance at Council meetings. She was then told it was by 'gentlemen's agreement.' Naturally Mary replied 'Well, obviously I'm no gentleman.') After that time, Council meetings were open to observers and the process of democratization of the Society had begun.\" Also, in 1971 the AMS established its Joint Committee on Women in the Mathematical Sciences (JCW), which later became a joint committee of multiple scholarly societies.\nJulia Robinson was the first female president of the American Mathematical Society (1983–1984), but was unable to complete her term as she was suffering from leukemia.\nIn 1988, the Journal of the American Mathematical Society was created, as the flagship journal of the AMS.\n\nAMS and mathematical research\nThe American Mathematical Society plays a significant role in advancing mathematical research by fostering collaboration, supporting early-career researchers, and maintaining influential publications and databases.\n\nResearch collaborations and support\nThe AMS facilitates collaboration among mathematicians through a variety of programs aimed at different career stages. The Mathematical Research Communities, established in 2008, provides early-career researchers with opportunities to engage in intensive research workshops, collaborate with peers, and receive mentoring from senior mathematicians. These programs often lead to the formation of long-term research groups that contribute to emerging fields in mathematics.\nIn addition, the",
    "links": [
      "501(c)(3)",
      "AMS-LaTeX",
      "AMS-TeX",
      "Abraham Adrian Albert",
      "Agnes Scott College",
      "American Association for the Advancement of Science",
      "American Institute of Mathematics",
      "American Invitational Mathematics Examination",
      "American Journal of Mathematics",
      "American Mathematical Association of Two-Year Colleges",
      "American Mathematics Competitions",
      "Andrew Gleason",
      "Ann Arbor, Michigan",
      "Anna Johnson Pell Wheeler",
      "Arthur Byron Coble",
      "Arthur Jaffe",
      "Association for Women in Mathematics",
      "Bryna Kra",
      "Bulletin of the American Mathematical Society",
      "Bôcher Memorial Prize",
      "Canadian Mathematical Society",
      "Catherine A. Roberts",
      "Cathleen Synge Morawetz",
      "Charles B. Morrey Jr.",
      "Charlotte Scott",
      "Chelsea Publishing Company",
      "Cole Prize",
      "Conference Board of the Mathematical Sciences",
      "Cybersecurity",
      "Data science",
      "David Eisenbud",
      "David P. Robbins Prize",
      "David Vogan",
      "Deane Montgomery",
      "Doi (identifier)",
      "E. H. Moore",
      "Earle Raymond Hedrick",
      "Edward Burr Van Vleck",
      "Edward J. McShane",
      "Einar Hille",
      "Emory McClintock",
      "Eric M. Friedlander",
      "Ernest William Brown",
      "European Mathematical Society",
      "Evelyn Boyd Granville",
      "Felix Browder",
      "Fellowship",
      "Fisk University",
      "Frank Morley",
      "Fulkerson Prize"
    ],
    "categories": [
      "Category:1888 establishments in New York (state)",
      "Category:1951 establishments in Rhode Island",
      "Category:All articles with specifically marked weasel-worded phrases",
      "Category:All articles with unsourced statements",
      "Category:American Mathematical Society",
      "Category:Articles with short description",
      "Category:Articles with specifically marked weasel-worded phrases from February 2025",
      "Category:Articles with unsourced statements from February 2025",
      "Category:CS1 maint: url-status",
      "Category:Commons category link is on Wikidata"
    ]
  },
  "Analytic number theory": {
    "title": "Analytic number theory",
    "url": "https://en.wikipedia.org/wiki/Analytic_number_theory",
    "summary": "In mathematics, analytic number theory is a branch of number theory that uses methods from mathematical analysis to solve problems about the integers. It is often said to have begun with Peter Gustav Lejeune Dirichlet's 1837 introduction of Dirichlet L-functions to give the first proof of Dirichlet's theorem on arithmetic progressions. It is well known for its results on prime numbers (involving the Prime Number Theorem and Riemann zeta function) and additive number theory (such as the Goldbach conjecture and Waring's problem).",
    "content": "In mathematics, analytic number theory is a branch of number theory that uses methods from mathematical analysis to solve problems about the integers. It is often said to have begun with Peter Gustav Lejeune Dirichlet's 1837 introduction of Dirichlet L-functions to give the first proof of Dirichlet's theorem on arithmetic progressions. It is well known for its results on prime numbers (involving the Prime Number Theorem and Riemann zeta function) and additive number theory (such as the Goldbach conjecture and Waring's problem).\n\nBranches of analytic number theory\nAnalytic number theory can be split up into two major parts, divided more by the type of problems they attempt to solve than fundamental differences in technique.\n\nMultiplicative number theory deals with the distribution of the prime numbers, such as estimating the number of primes in an interval, and includes the prime number theorem and Dirichlet's theorem on primes in arithmetic progressions.\nAdditive number theory is concerned with the additive structure of the integers, such as Goldbach's conjecture that every even number greater than 2 is the sum of two primes. One of the main results in additive number theory is the solution to Waring's problem.\n\nHistory\nPrecursors\nMuch of analytic number theory was inspired by the prime number theorem. Let π(x) be the prime-counting function that gives the number of primes less than or equal to x, for any real number x. For example, π(10) = 4 because there are four prime numbers (2, 3, 5 and 7) less than or equal to 10. The prime number theorem then states that x / ln(x) is a good approximation to π(x), in the sense that the limit of the quotient of the two functions π(x) and x / ln(x) as x approaches infinity is 1:\n\n  \n    \n      \n        \n          lim\n          \n            x\n            →\n            ∞\n          \n        \n        \n          \n            \n              π\n              (\n              x\n              )\n            \n            \n              x\n              \n                /\n              \n              ln\n              ⁡\n              (\n              x\n              )\n            \n          \n        \n        =\n        1\n        ,\n      \n    \n    {\\displaystyle \\lim _{x\\to \\infty }{\\frac {\\pi (x)}{x/\\ln(x)}}=1,}\n  \n\nknown as the asymptotic law of distribution of prime numbers.\nAdrien-Marie Legendre conjectured in 1797 or 1798 that π(a) is approximated by the function a/(A ln(a) + B), where A and B are unspecified constants. In the second edition of his book on number theory (1808) he then made a more precise conjecture, with A = 1 and B ≈ −1.08366. Carl Friedrich Gauss considered the same question: \"Im Jahr 1792 oder 1793\" ('in the year 1792 or 1793'), according to his own recollection nearly sixty years later in a letter to Encke (1849), he  wrote in his logarithm table (he was then 15 or 16) the short note \"Primzahlen unter \n  \n    \n      \n        a\n        (\n        =\n        ∞\n        )\n        \n          \n            a\n            \n              ln\n              ⁡\n              a\n            \n          \n        \n      \n    \n    {\\displaystyle a(=\\infty ){\\frac {a}{\\ln a}}}\n  \n\" ('prime numbers under \n  \n    \n      \n        a\n        (\n        =\n        ∞\n        )\n        \n          \n            a\n            \n              ln\n              ⁡\n              a\n            \n          \n        \n      \n    \n    {\\displaystyle a(=\\infty ){\\frac {a}{\\ln a}}}\n  \n'). But Gauss never published this conjecture. In 1838 Peter Gustav Lejeune Dirichlet came up with his own approximating function,  the logarithmic integral li(x) (under the slightly different form of a series, which he communicated to Gauss). Both Legendre's and Dirichlet's formulas imply the same conjectured asymptotic equivalence of π(x) and x / ln(x) stated above, although it turned out that Dirichlet's approximation is considerably better if one considers the differences instead of quotients.\n\nDirichlet\nJohann Peter Gustav Lejeune Dirichlet is credited with the creation of analytic number theory, a field in which he found several deep results and in proving them introduced some fundamental tools, many of which were later named after him. In 1837 he published Dirichlet's theorem on arithmetic progressions, using mathematical analysis concepts to tackle an algebraic problem and thus creating the branch of analytic number theory. In proving the theorem, he introduced the Dirichlet characters and L-functions. In 1841 he generalized his arithmetic progressions theorem from integers to the ring of Gaussian integers \n  \n    \n      \n        \n          Z\n        \n        [\n        i\n        ]\n      \n    \n    {\\displaystyle \\mathbb {Z} [i]}\n  \n.\n\nChebyshev\nIn two papers from 1848 and 1850, the Russian mathematician Pafnuty L'vovich Chebyshev attempted to prove the asymptotic law of distribution of prime numbers. His work is notable for the use of the zeta function ζ(s) (for real values of the argument \"s\", as are works of Leonhard Euler,",
    "links": [
      "0",
      "1",
      "Additive number theory",
      "Adrien-Marie Legendre",
      "Algebraic number",
      "Algebraic number theory",
      "Anabelian geometry",
      "ArXiv (identifier)",
      "Arakelov theory",
      "Argument (complex analysis)",
      "Arithmetic",
      "Arithmetic combinatorics",
      "Arithmetic dynamics",
      "Arithmetic function",
      "Arithmetic geometry",
      "Arithmetic progression",
      "Arithmetic topology",
      "Automorphic L-function",
      "Automorphic form",
      "Auxiliary function",
      "Ben Green (mathematician)",
      "Bernhard Riemann",
      "Bertrand's postulate",
      "Bibcode (identifier)",
      "Cambridge University Press",
      "Carl Friedrich Gauss",
      "Carl Gauss",
      "Cem Yıldırım",
      "Charles Jean de la Vallée-Poussin",
      "Chinese remainder theorem",
      "Class field theory",
      "Combinatorics",
      "Complex analysis",
      "Complex plane",
      "Composite number",
      "Computational number theory",
      "Daniel Goldston",
      "David Hilbert",
      "Diophantine approximation",
      "Diophantine equation",
      "Diophantine geometry",
      "Diophantine problem",
      "Dirichlet's theorem on arithmetic progressions",
      "Dirichlet L-function",
      "Dirichlet character",
      "Dirichlet series",
      "Doi (identifier)",
      "Dover Publications",
      "Edmund Landau",
      "Edward Charles Titchmarsh"
    ],
    "categories": [
      "Category:Analytic number theory",
      "Category:Articles containing German-language text",
      "Category:Articles with short description",
      "Category:Short description matches Wikidata",
      "Category:Webarchive template wayback links"
    ]
  },
  "Approximation theory": {
    "title": "Approximation theory",
    "url": "https://en.wikipedia.org/wiki/Approximation_theory",
    "summary": "In mathematics, approximation theory is concerned with how functions can best be approximated with simpler functions, and with quantitatively characterizing the errors introduced thereby. What is meant by best and simpler will depend on the application.\nA closely related topic is the approximation of functions by generalized Fourier series, that is, approximations based upon summation of a series of terms based upon orthogonal polynomials.\nOne problem of particular interest is that of approximating a function in a computer mathematical library, using operations that can be performed on the computer or calculator (e.g. addition and multiplication), such that the result is as close to the actual function as possible. This is typically done with polynomial or rational (ratio of polynomials) approximations.\nThe objective is to make the approximation as close as possible to the actual function, typically with an accuracy close to that of the underlying computer's floating point arithmetic. ",
    "content": "In mathematics, approximation theory is concerned with how functions can best be approximated with simpler functions, and with quantitatively characterizing the errors introduced thereby. What is meant by best and simpler will depend on the application.\nA closely related topic is the approximation of functions by generalized Fourier series, that is, approximations based upon summation of a series of terms based upon orthogonal polynomials.\nOne problem of particular interest is that of approximating a function in a computer mathematical library, using operations that can be performed on the computer or calculator (e.g. addition and multiplication), such that the result is as close to the actual function as possible. This is typically done with polynomial or rational (ratio of polynomials) approximations.\nThe objective is to make the approximation as close as possible to the actual function, typically with an accuracy close to that of the underlying computer's floating point arithmetic. This is accomplished by using a polynomial of high degree, and/or narrowing the domain over which the polynomial has to approximate the function.\nNarrowing the domain can often be done through the use of various addition or scaling formulas for the function being approximated. Modern mathematical libraries often reduce the domain into many tiny segments and use a low-degree polynomial for each segment.\n\nOptimal polynomials\nOnce the domain (typically an interval) and degree of the polynomial are chosen, the polynomial itself is chosen in such a way as to minimize the worst-case error. That is, the goal is to minimize the maximum value of \n  \n    \n      \n        ∣\n        P\n        (\n        x\n        )\n        −\n        f\n        (\n        x\n        )\n        ∣\n      \n    \n    {\\displaystyle \\mid P(x)-f(x)\\mid }\n  \n, where P(x) is the approximating polynomial, f(x) is the actual function, and x varies over the chosen interval. For well-behaved functions, there exists an Nth-degree polynomial that will lead to an error curve that oscillates back and forth between \n  \n    \n      \n        +\n        ε\n      \n    \n    {\\displaystyle +\\varepsilon }\n  \n and \n  \n    \n      \n        −\n        ε\n      \n    \n    {\\displaystyle -\\varepsilon }\n  \n a total of N+2 times, giving a worst-case error of \n  \n    \n      \n        ε\n      \n    \n    {\\displaystyle \\varepsilon }\n  \n. It is seen that there exists an Nth-degree polynomial that can interpolate N+1 points in a curve. That such a polynomial is always optimal is asserted by the equioscillation theorem. It is possible to make contrived functions f(x) for which no such polynomial exists, but these occur rarely in practice.\nFor example, the graphs shown to the right show the error in approximating log(x) and exp(x) for N = 4. The red curves, for the optimal polynomial, are level, that is, they oscillate between \n  \n    \n      \n        +\n        ε\n      \n    \n    {\\displaystyle +\\varepsilon }\n  \n and \n  \n    \n      \n        −\n        ε\n      \n    \n    {\\displaystyle -\\varepsilon }\n  \n exactly. In each case, the number of extrema is N+2, that is, 6. Two of the extrema are at the end points of the interval, at the left and right edges of the graphs.\n\n To prove this is true in general, suppose P is a polynomial of degree N having the property described, that is, it gives rise to an error function that has N + 2 extrema, of alternating signs and equal magnitudes. The red graph to the right shows what this error function might look like for N = 4. Suppose Q(x) (whose error function is shown in blue to the right) is another N-degree polynomial that is a better approximation to f than P. In particular, Q is closer to f than P for each value xi where an extreme of P−f occurs, so\n\n  \n    \n      \n        \n          |\n        \n        Q\n        (\n        \n          x\n          \n            i\n          \n        \n        )\n        −\n        f\n        (\n        \n          x\n          \n            i\n          \n        \n        )\n        \n          |\n        \n        <\n        \n          |\n        \n        P\n        (\n        \n          x\n          \n            i\n          \n        \n        )\n        −\n        f\n        (\n        \n          x\n          \n            i\n          \n        \n        )\n        \n          |\n        \n        .\n      \n    \n    {\\displaystyle |Q(x_{i})-f(x_{i})|<|P(x_{i})-f(x_{i})|.}\n  \n\nWhen a maximum of P−f occurs at xi, then\n\n  \n    \n      \n        Q\n        (\n        \n          x\n          \n            i\n          \n        \n        )\n        −\n        f\n        (\n        \n          x\n          \n            i\n          \n        \n        )\n        ≤\n        \n          |\n        \n        Q\n        (\n        \n          x\n          \n            i\n          \n        \n        )\n        −\n        f\n        (\n        \n          x\n          \n            i\n          \n        \n        )\n        \n          |\n        \n        <\n        \n          |\n        \n        P\n        (\n        \n          x",
    "links": [
      "Algebra of physical space",
      "Algebraic structure",
      "Algorithm",
      "Algorithm design",
      "Analysis of algorithms",
      "Analytical mechanics",
      "Applied mathematics",
      "Approximation",
      "Approximation error",
      "Automata theory",
      "Automated theorem proving",
      "Bosonic string theory",
      "Brian P. Flannery",
      "Calculus of variations",
      "Chaos theory",
      "Characterization (mathematics)",
      "Chebyshev polynomials",
      "Classical field theory",
      "Clenshaw–Curtis quadrature",
      "Clifford algebra",
      "Clifford analysis",
      "Coding theory",
      "Combinatorics",
      "Computational geometry",
      "Computational mathematics",
      "Computational number theory",
      "Computational statistics",
      "Computer",
      "Computer algebra",
      "Conformal field theory",
      "Constraint programming",
      "Constraint satisfaction problem",
      "Constructive Approximation",
      "Control theory",
      "Cryptography",
      "Decision theory",
      "Degree of a polynomial",
      "Differential equation",
      "Differential form",
      "Differential geometry",
      "Discrete geometry",
      "Discrete mathematics",
      "Doi (identifier)",
      "Dynamical system",
      "East Journal on Approximations",
      "Effective field theory",
      "Elliott Ward Cheney Jr.",
      "Equioscillation theorem",
      "Estimation theory",
      "European Community on Computational Methods in Applied Sciences"
    ],
    "categories": [
      "Category:All Wikipedia articles written in American English",
      "Category:Approximation theory",
      "Category:Articles with short description",
      "Category:CS1 French-language sources (fr)",
      "Category:Numerical analysis",
      "Category:Short description matches Wikidata",
      "Category:Use American English from March 2019",
      "Category:Use mdy dates from September 2021"
    ]
  },
  "Algebraic structures": {
    "title": "Algebraic structure",
    "url": "https://en.wikipedia.org/wiki/Algebraic_structure",
    "summary": "In mathematics, an algebraic structure or algebraic system consists of a nonempty set A (called the underlying set, carrier set or domain), a collection of operations on A (typically binary operations such as addition and multiplication), and a finite set of identities (known as axioms) that these operations must satisfy.\nAn algebraic structure may be based on other algebraic structures with operations and axioms involving several structures. For instance, a vector space involves a second structure called a field, and an operation called scalar multiplication between elements of the field (called scalars), and elements of the vector space (called vectors).\nAbstract algebra is the name that is commonly given to the study of algebraic structures. The general theory of algebraic structures has been formalized in universal algebra. Category theory is another formalization that includes also other mathematical structures and functions between structures of the same type (homomorphisms).\nIn ",
    "content": "In mathematics, an algebraic structure or algebraic system consists of a nonempty set A (called the underlying set, carrier set or domain), a collection of operations on A (typically binary operations such as addition and multiplication), and a finite set of identities (known as axioms) that these operations must satisfy.\nAn algebraic structure may be based on other algebraic structures with operations and axioms involving several structures. For instance, a vector space involves a second structure called a field, and an operation called scalar multiplication between elements of the field (called scalars), and elements of the vector space (called vectors).\nAbstract algebra is the name that is commonly given to the study of algebraic structures. The general theory of algebraic structures has been formalized in universal algebra. Category theory is another formalization that includes also other mathematical structures and functions between structures of the same type (homomorphisms).\nIn universal algebra, an algebraic structure is called an algebra; this term may be ambiguous, since, in other contexts, an algebra is an algebraic structure that is a vector space over a field or a module over a commutative ring.\nThe collection of all structures of a given type (same operations and same laws) is called a variety in universal algebra; this term is also used with a completely different meaning in algebraic geometry, as an abbreviation of algebraic variety. In category theory, the collection of all structures of a given type and homomorphisms between them form a concrete category.\n\nIntroduction\nAddition and multiplication are prototypical examples of operations that combine two elements of a set to produce a third element of the same set. These operations obey several algebraic laws. For example, a + (b + c) = (a + b) + c and a(bc) = (ab)c are associative laws, and a + b = b + a and ab = ba are commutative laws. Many systems studied by mathematicians have operations that obey some, but not necessarily all, of the laws of ordinary arithmetic. For example, the possible moves of an object in three-dimensional space can be combined by performing a first move of the object, and then a second move from its new position. Such moves, formally called rigid motions, obey the associative law, but fail to satisfy the commutative law.\nSets with one or more operations that obey specific laws are called algebraic structures. When a new problem involves the same laws as such an algebraic structure, all the results that have been proved using only the laws of the structure can be directly applied to the new problem.\nIn full generality, algebraic structures may involve an arbitrary collection of operations, including operations that combine more than two elements (higher arity operations) and operations that take only one argument (unary operations) or even zero arguments (nullary operations). The examples listed below are by no means a complete list, but include the most common structures taught in undergraduate courses.\n\nCommon axioms\nEquational axioms\nAn axiom of an algebraic structure often has the form of an identity, that is, an equation such that the two sides of the equals sign are expressions that involve operations of the algebraic structure and variables. If the variables in the identity are replaced by arbitrary elements of the algebraic structure, the equality must remain true. Here are some common examples.\n\nCommutativity\nAn operation \n  \n    \n      \n        ∗\n      \n    \n    {\\displaystyle *}\n  \n is commutative if \n  \n    \n      \n        x\n        ∗\n        y\n        =\n        y\n        ∗\n        x\n      \n    \n    {\\displaystyle x*y=y*x}\n  \n for every x and y in the algebraic structure.\nAssociativity\nAn operation \n  \n    \n      \n        ∗\n      \n    \n    {\\displaystyle *}\n  \n is associative if \n  \n    \n      \n        (\n        x\n        ∗\n        y\n        )\n        ∗\n        z\n        =\n        x\n        ∗\n        (\n        y\n        ∗\n        z\n        )\n      \n    \n    {\\displaystyle (x*y)*z=x*(y*z)}\n  \n for every x, y and z in the algebraic structure.\nLeft distributivity\nAn operation \n  \n    \n      \n        ∗\n      \n    \n    {\\displaystyle *}\n  \n is left-distributive with respect to another operation \n  \n    \n      \n        +\n      \n    \n    {\\displaystyle +}\n  \n if \n  \n    \n      \n        x\n        ∗\n        (\n        y\n        +\n        z\n        )\n        =\n        (\n        x\n        ∗\n        y\n        )\n        +\n        (\n        x\n        ∗\n        z\n        )\n      \n    \n    {\\displaystyle x*(y+z)=(x*y)+(x*z)}\n  \n for every x, y and z in the algebraic structure (the second operation is denoted here as \n  \n    \n      \n        +\n      \n    \n    {\\displaystyle +}\n  \n, because the second operation is addition in many common examples).\nRight distributivity\nAn operation \n  \n    \n      \n        ∗\n      \n    \n    {\\displaystyle *}\n  \n is right-distributive with respect to another operation \n  \n    \n      \n       ",
    "links": [
      "Abelian group",
      "Absorption law",
      "Abstract algebra",
      "Abuse of notation",
      "Addition",
      "Additive inverse",
      "Affine space",
      "Algebra",
      "Algebra over a field",
      "Algebraic category",
      "Algebraic expression",
      "Algebraic geometry",
      "Algebraic number theory",
      "Algebraic varieties",
      "Algebraic variety",
      "An algebra",
      "Archimedean group",
      "Archimedean property",
      "Argument of a function",
      "Arity",
      "Associative algebra",
      "Associative law",
      "Associativity",
      "Automorphism",
      "Axiom",
      "Banach space",
      "Basis (linear algebra)",
      "Bialgebra",
      "Bilinear map",
      "Binary operation",
      "Boolean algebra (structure)",
      "Bounded lattice",
      "Cambridge University Press",
      "Categories for the Working Mathematician",
      "Category (mathematics)",
      "Category of groups",
      "Category of sets",
      "Category of topological spaces",
      "Category theory",
      "Commutative",
      "Commutative algebra",
      "Commutative law",
      "Commutative ring",
      "Commutativity",
      "Complemented lattice",
      "Complete lattice",
      "Complete metric space",
      "Composition algebra",
      "Concrete category",
      "Coordinate vector"
    ],
    "categories": [
      "Category:Abstract algebra",
      "Category:Algebraic structures",
      "Category:All articles lacking in-text citations",
      "Category:Articles lacking in-text citations from August 2024",
      "Category:Articles with short description",
      "Category:Mathematical structures",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Algebraic operation": {
    "title": "Algebraic operation",
    "url": "https://en.wikipedia.org/wiki/Algebraic_operation",
    "summary": "In mathematics, a basic algebraic operation is a mathematical operation similar to any one of the common operations of elementary algebra, which include addition, subtraction, multiplication, division, raising to a whole number power, and taking roots (fractional power). The operations of elementary algebra may be performed on numbers, in which case they are often called arithmetic operations. They may also be performed, in a similar way, on variables, algebraic expressions, and more generally, on elements of algebraic structures, such as groups and fields. An algebraic operation may also be defined more generally as a function from a Cartesian power of a given set to the same set.\nThe term algebraic operation may also be used for operations that may be defined by compounding basic algebraic operations, such as the dot product. In calculus and mathematical analysis, algebraic operation is also used for the operations that may be defined by purely algebraic methods. For example, exponen",
    "content": "In mathematics, a basic algebraic operation is a mathematical operation similar to any one of the common operations of elementary algebra, which include addition, subtraction, multiplication, division, raising to a whole number power, and taking roots (fractional power). The operations of elementary algebra may be performed on numbers, in which case they are often called arithmetic operations. They may also be performed, in a similar way, on variables, algebraic expressions, and more generally, on elements of algebraic structures, such as groups and fields. An algebraic operation may also be defined more generally as a function from a Cartesian power of a given set to the same set.\nThe term algebraic operation may also be used for operations that may be defined by compounding basic algebraic operations, such as the dot product. In calculus and mathematical analysis, algebraic operation is also used for the operations that may be defined by purely algebraic methods. For example, exponentiation with an integer or rational exponent is an algebraic operation, but not the general exponentiation with a real or complex exponent. Also, the derivative is an operation that is not algebraic.\n\nNotation\nMultiplication symbols are usually omitted, and implied, when there is no operator between two variables or terms, or when a coefficient is used. For example, 3 × x2 is written as 3x2, and 2 × x × y is written as 2xy. Sometimes, multiplication symbols are replaced with either a dot or center-dot, so that x × y is written as either x . y or x · y. Plain text, programming languages, and calculators also use a single asterisk to represent the multiplication symbol, and it must be explicitly used; for example, 3x is written as 3 * x.\nRather than using the ambiguous division sign (÷), division is usually represented with a vinculum, a horizontal line, as in ⁠3/x + 1⁠. In plain text and programming languages, a slash (also called a solidus) is used, e.g. 3 / (x + 1).\nExponents are usually formatted using superscripts, as in x2. In plain text, the TeX mark-up language, and some programming languages such as MATLAB and Julia, the caret symbol, ^, represents exponents, so x2 is written as x ^ 2. In programming languages such as Ada, Fortran, Perl, Python  and Ruby, a double asterisk is used, so x2 is written as x ** 2.\nThe plus–minus sign, ±, is used as a shorthand notation for two expressions written as one, representing one expression with a plus sign, the other with a minus sign. For example, y = x ± 1 represents the two equations y = x + 1 and y = x − 1. Sometimes, it is used for denoting a positive-or-negative term such as ±x.\n\nArithmetic vs algebraic operations\nAlgebraic operations work in the same way as arithmetic operations, as can be seen in the table below.\n\nNote: the use of the letters \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n and \n  \n    \n      \n        b\n      \n    \n    {\\displaystyle b}\n  \n is arbitrary, and the examples would have been equally valid if \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n and \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n were used.\n\nProperties of arithmetic and algebraic operations\nSee also\nAlgebraic expression\nAlgebraic function\nElementary algebra\nFactoring a quadratic expression\nOrder of operations\n\nNotes\n\n\n== References ==",
    "links": [
      "Ada (programming language)",
      "Addition",
      "Algebra",
      "Algebraic expression",
      "Algebraic function",
      "Algebraic structure",
      "Arithmetic operations",
      "Associative property",
      "Calculator",
      "Calculus",
      "Caret",
      "Cartesian product",
      "Coefficient",
      "Commutative property",
      "Complex number",
      "Derivative",
      "Division (mathematics)",
      "Division sign",
      "Dot product",
      "Elementary algebra",
      "Equation",
      "Exponentiation",
      "Factoring a quadratic expression",
      "Fernando Q. Gouvêa",
      "Field (mathematics)",
      "Fortran",
      "Fraction",
      "Function (mathematics)",
      "Group (mathematics)",
      "ISBN (identifier)",
      "ISO 80000-2",
      "Integer",
      "Julia (programming language)",
      "MATLAB",
      "Mathematical analysis",
      "Mathematical operation",
      "Mathematics",
      "Multiplication",
      "Nth root",
      "Number",
      "Obelus",
      "Operation (mathematics)",
      "Order of operations",
      "Perl",
      "Plain text",
      "Plus–minus sign",
      "Programming language",
      "Python (programming language)",
      "Quadratic equation",
      "Rational number"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Elementary algebra",
      "Category:Elementary mathematics",
      "Category:Short description matches Wikidata"
    ]
  },
  "Algebraic operations": {
    "title": "Algebraic operation",
    "url": "https://en.wikipedia.org/wiki/Algebraic_operation",
    "summary": "In mathematics, a basic algebraic operation is a mathematical operation similar to any one of the common operations of elementary algebra, which include addition, subtraction, multiplication, division, raising to a whole number power, and taking roots (fractional power). The operations of elementary algebra may be performed on numbers, in which case they are often called arithmetic operations. They may also be performed, in a similar way, on variables, algebraic expressions, and more generally, on elements of algebraic structures, such as groups and fields. An algebraic operation may also be defined more generally as a function from a Cartesian power of a given set to the same set.\nThe term algebraic operation may also be used for operations that may be defined by compounding basic algebraic operations, such as the dot product. In calculus and mathematical analysis, algebraic operation is also used for the operations that may be defined by purely algebraic methods. For example, exponen",
    "content": "In mathematics, a basic algebraic operation is a mathematical operation similar to any one of the common operations of elementary algebra, which include addition, subtraction, multiplication, division, raising to a whole number power, and taking roots (fractional power). The operations of elementary algebra may be performed on numbers, in which case they are often called arithmetic operations. They may also be performed, in a similar way, on variables, algebraic expressions, and more generally, on elements of algebraic structures, such as groups and fields. An algebraic operation may also be defined more generally as a function from a Cartesian power of a given set to the same set.\nThe term algebraic operation may also be used for operations that may be defined by compounding basic algebraic operations, such as the dot product. In calculus and mathematical analysis, algebraic operation is also used for the operations that may be defined by purely algebraic methods. For example, exponentiation with an integer or rational exponent is an algebraic operation, but not the general exponentiation with a real or complex exponent. Also, the derivative is an operation that is not algebraic.\n\nNotation\nMultiplication symbols are usually omitted, and implied, when there is no operator between two variables or terms, or when a coefficient is used. For example, 3 × x2 is written as 3x2, and 2 × x × y is written as 2xy. Sometimes, multiplication symbols are replaced with either a dot or center-dot, so that x × y is written as either x . y or x · y. Plain text, programming languages, and calculators also use a single asterisk to represent the multiplication symbol, and it must be explicitly used; for example, 3x is written as 3 * x.\nRather than using the ambiguous division sign (÷), division is usually represented with a vinculum, a horizontal line, as in ⁠3/x + 1⁠. In plain text and programming languages, a slash (also called a solidus) is used, e.g. 3 / (x + 1).\nExponents are usually formatted using superscripts, as in x2. In plain text, the TeX mark-up language, and some programming languages such as MATLAB and Julia, the caret symbol, ^, represents exponents, so x2 is written as x ^ 2. In programming languages such as Ada, Fortran, Perl, Python  and Ruby, a double asterisk is used, so x2 is written as x ** 2.\nThe plus–minus sign, ±, is used as a shorthand notation for two expressions written as one, representing one expression with a plus sign, the other with a minus sign. For example, y = x ± 1 represents the two equations y = x + 1 and y = x − 1. Sometimes, it is used for denoting a positive-or-negative term such as ±x.\n\nArithmetic vs algebraic operations\nAlgebraic operations work in the same way as arithmetic operations, as can be seen in the table below.\n\nNote: the use of the letters \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n and \n  \n    \n      \n        b\n      \n    \n    {\\displaystyle b}\n  \n is arbitrary, and the examples would have been equally valid if \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n and \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n were used.\n\nProperties of arithmetic and algebraic operations\nSee also\nAlgebraic expression\nAlgebraic function\nElementary algebra\nFactoring a quadratic expression\nOrder of operations\n\nNotes\n\n\n== References ==",
    "links": [
      "Ada (programming language)",
      "Addition",
      "Algebra",
      "Algebraic expression",
      "Algebraic function",
      "Algebraic structure",
      "Arithmetic operations",
      "Associative property",
      "Calculator",
      "Calculus",
      "Caret",
      "Cartesian product",
      "Coefficient",
      "Commutative property",
      "Complex number",
      "Derivative",
      "Division (mathematics)",
      "Division sign",
      "Dot product",
      "Elementary algebra",
      "Equation",
      "Exponentiation",
      "Factoring a quadratic expression",
      "Fernando Q. Gouvêa",
      "Field (mathematics)",
      "Fortran",
      "Fraction",
      "Function (mathematics)",
      "Group (mathematics)",
      "ISBN (identifier)",
      "ISO 80000-2",
      "Integer",
      "Julia (programming language)",
      "MATLAB",
      "Mathematical analysis",
      "Mathematical operation",
      "Mathematics",
      "Multiplication",
      "Nth root",
      "Number",
      "Obelus",
      "Operation (mathematics)",
      "Order of operations",
      "Perl",
      "Plain text",
      "Plus–minus sign",
      "Programming language",
      "Python (programming language)",
      "Quadratic equation",
      "Rational number"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Elementary algebra",
      "Category:Elementary mathematics",
      "Category:Short description matches Wikidata"
    ]
  },
  "Arithmetic": {
    "title": "Arithmetic",
    "url": "https://en.wikipedia.org/wiki/Arithmetic",
    "summary": "Arithmetic is an elementary branch of mathematics that deals with numerical operations like addition, subtraction, multiplication, and division. In a wider sense, it also includes exponentiation, extraction of roots, and taking logarithms.\nArithmetic systems can be distinguished based on the type of numbers they operate on. Integer arithmetic is about calculations with positive and negative integers. Rational number arithmetic involves operations on fractions of integers. Real number arithmetic is about calculations with real numbers, which include both rational and irrational numbers.\nAnother distinction is based on the numeral system employed to perform calculations. Decimal arithmetic is the most common. It uses the basic numerals from 0 to 9 and their combinations to express numbers. Binary arithmetic, by contrast, is used by most computers and represents numbers as combinations of the basic numerals 0 and 1. Computer arithmetic deals with the specificities of the implementation of",
    "content": "Arithmetic is an elementary branch of mathematics that deals with numerical operations like addition, subtraction, multiplication, and division. In a wider sense, it also includes exponentiation, extraction of roots, and taking logarithms.\nArithmetic systems can be distinguished based on the type of numbers they operate on. Integer arithmetic is about calculations with positive and negative integers. Rational number arithmetic involves operations on fractions of integers. Real number arithmetic is about calculations with real numbers, which include both rational and irrational numbers.\nAnother distinction is based on the numeral system employed to perform calculations. Decimal arithmetic is the most common. It uses the basic numerals from 0 to 9 and their combinations to express numbers. Binary arithmetic, by contrast, is used by most computers and represents numbers as combinations of the basic numerals 0 and 1. Computer arithmetic deals with the specificities of the implementation of binary arithmetic on computers. Some arithmetic systems operate on mathematical objects other than numbers, such as interval arithmetic and matrix arithmetic.\nArithmetic operations form the basis of many branches of mathematics, such as algebra, calculus, and statistics. They play a similar role in the sciences, like physics and economics. Arithmetic is present in many aspects of daily life, for example, to calculate change while shopping or to manage personal finances. It is one of the earliest forms of mathematics education that students encounter. Its cognitive and conceptual foundations are studied by psychology and philosophy.\nThe practice of arithmetic is at least thousands and possibly tens of thousands of years old. Ancient civilizations like the Egyptians and the Sumerians invented numeral systems to solve practical arithmetic problems in about 3000 BCE. Starting in the 7th and 6th centuries BCE, the ancient Greeks initiated a more abstract study of numbers and introduced the method of rigorous mathematical proofs. The ancient Indians developed the concept of zero and the decimal system, which Arab mathematicians further refined and spread to the Western world during the medieval period. The first mechanical calculators were invented in the 17th century. The 18th and 19th centuries saw the development of modern number theory and the formulation of axiomatic foundations of arithmetic. In the 20th century, the emergence of electronic calculators and computers revolutionized the accuracy and speed with which arithmetic calculations could be performed.\n\nDefinition, etymology, and related fields\nArithmetic is the fundamental branch of mathematics that studies numbers and their operations. In particular, it deals with numerical calculations using the arithmetic operations of addition, subtraction, multiplication, and division. In a wider sense, it also includes exponentiation, extraction of roots, and logarithm. The term arithmetic has its root in the Latin term arithmetica which derives from the Ancient Greek words ἀριθμός (arithmos), meaning 'number', and ἀριθμητική τέχνη (arithmetike tekhne), meaning 'the art of counting'.\nThere are disagreements about its precise definition. According to a narrow characterization, arithmetic deals only with natural numbers. However, the more common view is to include operations on integers, rational numbers, real numbers, and sometimes also complex numbers in its scope. Some definitions restrict arithmetic to the field of numerical calculations. When understood in a wider sense, it also includes the study of how the concept of numbers developed, the analysis of properties of and relations between numbers, and the examination of the axiomatic structure of arithmetic operations.\nArithmetic is closely related to number theory and some authors use the terms as synonyms. However, in a more specific sense, number theory is restricted to the study of integers and focuses on their properties and relationships such as divisibility, factorization, and primality. Traditionally, it is known as higher arithmetic.\n\nNumbers\nNumbers are mathematical objects used to count quantities and measure magnitudes. They are fundamental elements in arithmetic since all arithmetic operations are performed on numbers. There are different kinds of numbers and different numeral systems to represent them.\n\nKinds\nThe main kinds of numbers employed in arithmetic are natural numbers, whole numbers, integers, rational numbers, and real numbers. The natural numbers are whole numbers that start from 1 and go to infinity. They exclude 0 and negative numbers. They are also known as counting numbers and can be expressed as \n  \n    \n      \n        {\n        1\n        ,\n        2\n        ,\n        3\n        ,\n        4\n        ,\n        .\n        .\n        .\n        }\n      \n    \n    {\\displaystyle \\{1,2,3,4,...\\}}\n  \n. The symbol of the natural numbers is \n  \n    \n      \n        \n          N\n        \n      \n    \n    {\\displays",
    "links": [
      "A priori",
      "Abacus",
      "Absolute uncertainty",
      "Abstract algebra",
      "Abstract objects",
      "Addition",
      "Addition table",
      "Additive inverse",
      "Affine arithmetic",
      "Al-Khwarizmi",
      "Algebra",
      "Algebraic equations",
      "Algebraic geometry",
      "Algebraic number field",
      "Algebraic number theory",
      "Algebraic operations",
      "Algebraic topology",
      "Algorism",
      "Algorithm",
      "Analog computer",
      "Analytic geometry",
      "Analytic number theory",
      "Analúcia Schliemann",
      "Ancient Babylonians",
      "Ancient China",
      "Ancient Egypt",
      "Ancient Greek mathematicians",
      "Ancient Greeks",
      "Ancient India",
      "Ancient civilizations",
      "Anne Rooney",
      "Annie Cuyt",
      "Applied mathematics",
      "Approximation error",
      "ArXiv (identifier)",
      "Arbitrary-precision arithmetic",
      "Arithmetic (book)",
      "Arithmetic (song)",
      "Arithmetic geometry",
      "Aryabhata",
      "Aryabhatiya",
      "Associativity",
      "Axiom",
      "Axiomatic system",
      "Babylonians",
      "Bead",
      "Bibcode (identifier)",
      "Binary number",
      "Binary system",
      "Biology"
    ],
    "categories": [
      "Category:Arithmetic",
      "Category:Articles with short description",
      "Category:CS1 maint: DOI inactive as of July 2025",
      "Category:CS1 maint: ignored ISBN errors",
      "Category:Good articles",
      "Category:Pages using multiple image with auto scaled images",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Abelian group": {
    "title": "Abelian group",
    "url": "https://en.wikipedia.org/wiki/Abelian_group",
    "summary": "In mathematics, an abelian group, also called a commutative group, is a group in which the result of applying the group operation to two group elements does not depend on the order in which they are written. That is, the group operation is commutative. With addition as an operation, the integers and the real numbers form abelian groups, and the concept of an abelian group may be viewed as a generalization of these examples. Abelian groups are named after the Norwegian mathematician Niels Henrik Abel.\nThe concept of an abelian group underlies many fundamental algebraic structures, such as fields, rings, vector spaces, and algebras. The theory of abelian groups is generally simpler than that of their non-abelian counterparts, and finite abelian groups are very well understood and fully classified.",
    "content": "In mathematics, an abelian group, also called a commutative group, is a group in which the result of applying the group operation to two group elements does not depend on the order in which they are written. That is, the group operation is commutative. With addition as an operation, the integers and the real numbers form abelian groups, and the concept of an abelian group may be viewed as a generalization of these examples. Abelian groups are named after the Norwegian mathematician Niels Henrik Abel.\nThe concept of an abelian group underlies many fundamental algebraic structures, such as fields, rings, vector spaces, and algebras. The theory of abelian groups is generally simpler than that of their non-abelian counterparts, and finite abelian groups are very well understood and fully classified.\n\nDefinition\nAn abelian group is a set \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n, together with an operation ･ , that combines any two elements \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n and \n  \n    \n      \n        b\n      \n    \n    {\\displaystyle b}\n  \n of \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n to form another element of \n  \n    \n      \n        A\n        ,\n      \n    \n    {\\displaystyle A,}\n  \n denoted \n  \n    \n      \n        a\n        ⋅\n        b\n      \n    \n    {\\displaystyle a\\cdot b}\n  \n. The symbol ･ is a general placeholder for a concretely given operation. To qualify as an abelian group, the set and operation, \n  \n    \n      \n        (\n        A\n        ,\n        ⋅\n        )\n      \n    \n    {\\displaystyle (A,\\cdot )}\n  \n, must satisfy four requirements known as the abelian group axioms (some authors include in the axioms some properties that belong to the definition of an operation: namely that the operation is defined for any ordered pair of elements of A, that the result is well-defined, and that the result belongs to A):\n\nAssociativity\nFor all \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n, \n  \n    \n      \n        b\n      \n    \n    {\\displaystyle b}\n  \n, and \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  \n in \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n, the equation \n  \n    \n      \n        (\n        a\n        ⋅\n        b\n        )\n        ⋅\n        c\n        =\n        a\n        ⋅\n        (\n        b\n        ⋅\n        c\n        )\n      \n    \n    {\\displaystyle (a\\cdot b)\\cdot c=a\\cdot (b\\cdot c)}\n  \n holds.\nIdentity element\nThere exists an element \n  \n    \n      \n        e\n      \n    \n    {\\displaystyle e}\n  \n in \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n, such that for all elements \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n in \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n, the equation \n  \n    \n      \n        e\n        ⋅\n        a\n        =\n        a\n        ⋅\n        e\n        =\n        a\n      \n    \n    {\\displaystyle e\\cdot a=a\\cdot e=a}\n  \n holds.\nInverse element\nFor each \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n in \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n there exists an element \n  \n    \n      \n        b\n      \n    \n    {\\displaystyle b}\n  \n in \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n such that \n  \n    \n      \n        a\n        ⋅\n        b\n        =\n        b\n        ⋅\n        a\n        =\n        e\n      \n    \n    {\\displaystyle a\\cdot b=b\\cdot a=e}\n  \n, where \n  \n    \n      \n        e\n      \n    \n    {\\displaystyle e}\n  \n is the identity element.\nCommutativity\nFor all \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n, \n  \n    \n      \n        b\n      \n    \n    {\\displaystyle b}\n  \n in \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n, \n  \n    \n      \n        a\n        ⋅\n        b\n        =\n        b\n        ⋅\n        a\n      \n    \n    {\\displaystyle a\\cdot b=b\\cdot a}\n  \n.\nA group in which the group operation is not commutative is called a \"non-abelian group\" or \"non-commutative group\".\n\nFacts\nNotation\nThere are two main notational conventions for abelian groups – additive and multiplicative.\n\nGenerally, the multiplicative notation is the usual notation for groups, while the additive notation is the usual notation for modules and rings. The additive notation may also be used to emphasize that a particular group is abelian, whenever both abelian and non-abelian groups are considered, with some notable exceptions being near-rings and partially ordered groups, where an operation is written additively even when non-abelian.\n\nMultiplication table\nTo verify that a finite group is abelian, a table (matrix) – known as a Cayley table – can be constructed in a similar fashion to a multiplication table. If the group is \n  \n    \n      \n        G\n        =\n        {\n        \n          g\n          \n            1\n          \n        \n        =\n        e\n        ,\n        \n          g\n          \n            2\n          \n        \n        ,\n        ",
    "links": [
      "Abelian category",
      "Abelian variety",
      "Abelianization",
      "Abingdon-on-Thames",
      "Abraham Robinson",
      "Abstract algebra",
      "Academic Press",
      "Addition",
      "Additive group",
      "Additive identity",
      "Additive inverse",
      "Adjective",
      "Algebra over a field",
      "Algebraic group",
      "Algebraic structure",
      "Algebraically compact module",
      "Alternating group",
      "American Mathematical Monthly",
      "American Mathematical Society",
      "ArXiv (identifier)",
      "Arithmetic group",
      "Associative algebra",
      "Automorphism group",
      "Axiomatic set theory",
      "Baby monster group",
      "Baer's criterion",
      "Basel",
      "Basic subgroup",
      "Bialgebra",
      "Bibcode (identifier)",
      "Binary operation",
      "Boca Raton, Florida",
      "Boolean algebra (structure)",
      "Burnside ring",
      "CRC Press",
      "Cambridge, Massachusetts",
      "Camille Jordan",
      "Cardinal number",
      "Carl Friedrich Gauss",
      "Category of abelian groups",
      "Cauchy's theorem (group theory)",
      "Cayley table",
      "Center (group theory)",
      "Cham, Switzerland",
      "Characteristic subgroup",
      "Circle group",
      "Classification of finite simple groups",
      "Cokernel",
      "Commutative",
      "Commutative ring"
    ],
    "categories": [
      "Category:Abelian group theory",
      "Category:Articles with short description",
      "Category:CS1: long volume value",
      "Category:Niels Henrik Abel",
      "Category:Properties of groups",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Abel–Ruffini theorem": {
    "title": "Abel–Ruffini theorem",
    "url": "https://en.wikipedia.org/wiki/Abel%E2%80%93Ruffini_theorem",
    "summary": "In mathematics, the Abel–Ruffini theorem (also known as Abel's impossibility theorem) states that there is no solution in radicals to general polynomial equations of degree five or higher with arbitrary coefficients. Here, general means that the coefficients of the equation are viewed and manipulated as indeterminates.\nThe theorem is named after Paolo Ruffini, who made an incomplete proof in 1799 (which was refined and completed in 1813 and accepted by Cauchy) and Niels Henrik Abel, who provided a proof in 1824.\nAbel–Ruffini theorem refers also to the slightly stronger result that there are equations of degree five and higher that cannot be solved by radicals. This does not follow from Abel's statement of the theorem, but is a corollary of his proof, as his proof is based on the fact that some polynomials in the coefficients of the equation are not the zero polynomial. This improved statement follows directly from Galois theory § A non-solvable quintic example. Galois theory implies al",
    "content": "In mathematics, the Abel–Ruffini theorem (also known as Abel's impossibility theorem) states that there is no solution in radicals to general polynomial equations of degree five or higher with arbitrary coefficients. Here, general means that the coefficients of the equation are viewed and manipulated as indeterminates.\nThe theorem is named after Paolo Ruffini, who made an incomplete proof in 1799 (which was refined and completed in 1813 and accepted by Cauchy) and Niels Henrik Abel, who provided a proof in 1824.\nAbel–Ruffini theorem refers also to the slightly stronger result that there are equations of degree five and higher that cannot be solved by radicals. This does not follow from Abel's statement of the theorem, but is a corollary of his proof, as his proof is based on the fact that some polynomials in the coefficients of the equation are not the zero polynomial. This improved statement follows directly from Galois theory § A non-solvable quintic example. Galois theory implies also that \n\n  \n    \n      \n        \n          x\n          \n            5\n          \n        \n        −\n        x\n        −\n        1\n        =\n        0\n      \n    \n    {\\displaystyle x^{5}-x-1=0}\n  \n\nis the simplest equation that cannot be solved in radicals, and that almost all polynomials of degree five or higher cannot be solved in radicals.\nThe impossibility of solving in degree five or higher contrasts with the case of lower degree: one has the quadratic formula, the cubic formula, and the quartic formula for degrees two, three, and four, respectively.\n\nContext\nPolynomial equations of degree two can be solved with the quadratic formula, which has been known since antiquity. Similarly the cubic formula for degree three, and the quartic formula for degree four, were found during the 16th century. At that time a fundamental problem was whether equations of higher degree could be solved in a similar way.\nThe fact that every polynomial equation of positive degree has solutions, possibly non-real, was asserted during the 17th century, but completely proved only at the beginning of the 19th century. This is the fundamental theorem of algebra, which does not provide any tool for computing the solutions, although several methods are known for  approximating all solutions to any desired accuracy.\nFrom the 16th century to beginning of the 19th century, the main problem of algebra was to search for a formula for the solutions of polynomial equations of degree five and higher, hence the name the \"fundamental theorem of algebra\". This meant a solution in radicals, that is, an expression involving only the coefficients of the equation, and the operations of addition, subtraction, multiplication, division, and nth root extraction.\nThe Abel–Ruffini theorem proves that this is impossible. However, this impossibility does not imply that a specific equation of any degree cannot be solved in radicals. On the contrary, there are equations of any degree that can be solved in radicals. This is the case of the equation \n  \n    \n      \n        \n          x\n          \n            n\n          \n        \n        −\n        1\n        =\n        0\n      \n    \n    {\\displaystyle x^{n}-1=0}\n  \n for any n, and the equations defined by cyclotomic polynomials, all of whose solutions can be expressed in radicals.\nAbel's proof of the theorem does not explicitly contain the assertion that there are specific equations that cannot be solved by radicals. Such an assertion is not a consequence of Abel's statement of the theorem, as the statement does not exclude the possibility that \"every particular quintic equation might be soluble, with a special formula for each equation.\" However, the existence of specific equations that cannot be solved in radicals seems to be a consequence of Abel's proof, as the proof uses the fact that some polynomials in the coefficients are not the zero polynomial, and, given a finite number of polynomials, there are values of the variables at which none of the polynomials takes the value zero.\nSoon after Abel's publication of his proof, Évariste Galois introduced a theory, now called Galois theory, that allows deciding, for any given equation, whether it is solvable in radicals. This was purely theoretical before the rise of electronic computers. With modern computers and programs, deciding whether a polynomial is solvable by radicals can be done for polynomials of degree greater than 100. Computing the solutions in radicals of solvable polynomials requires huge computations. Even for the degree five, the expression of the solutions is so huge that it has no practical interest.\n\nProof\nThe proof of the Abel–Ruffini theorem predates Galois theory. However, Galois theory allows a better understanding of the subject, and modern proofs are generally based on it, while the original proofs of the Abel–Ruffini theorem are still presented for historical purposes.\nThe proofs based on Galois theory comprise four main steps: the characterization of so",
    "links": [
      "Abel's theorem",
      "Abelian group",
      "Addition",
      "Algebraic equation",
      "Algebraic independence",
      "Almost all",
      "Alternating group",
      "American Mathematical Monthly",
      "Ancient history",
      "ArXiv (identifier)",
      "Archive for History of Exact Sciences",
      "Arithmetic operations",
      "Askold Khovanskii",
      "Augustin-Louis Cauchy",
      "CRC Press",
      "Carl Friedrich Gauss",
      "Cauchy",
      "Coefficients",
      "Cubic equation",
      "Cubic formula",
      "Cyclic group",
      "Cyclic permutation",
      "Cyclotomic polynomial",
      "Disquisitiones Arithmeticae",
      "Division (mathematics)",
      "Doi (identifier)",
      "Electronic computer",
      "Expression (mathematics)",
      "Field (mathematics)",
      "Field automorphism",
      "Field theory (mathematics)",
      "Fundamental theorem of algebra",
      "Fundamental theorem of finite abelian groups",
      "Fundamental theorem of symmetric polynomials",
      "Galois correspondence",
      "Galois group",
      "Galois theory",
      "Grøndahl & Søn Forlag",
      "ISBN (identifier)",
      "Ian Stewart (mathematician)",
      "Indeterminate (variable)",
      "Irreducible polynomial",
      "JSTOR (identifier)",
      "Jean-Pierre Tignol",
      "Joseph Alfred Serret",
      "Joseph Liouville",
      "Joseph Louis Lagrange",
      "Journal de Mathématiques Pures et Appliquées",
      "Lagrange resolvents",
      "MIT Press"
    ],
    "categories": [
      "Category:Articles containing proofs",
      "Category:Articles with short description",
      "Category:CS1 French-language sources (fr)",
      "Category:CS1 Italian-language sources (it)",
      "Category:Galois theory",
      "Category:Niels Henrik Abel",
      "Category:Short description matches Wikidata",
      "Category:Solvable groups",
      "Category:Theorems about polynomials"
    ]
  },
  "Affine space": {
    "title": "Affine space",
    "url": "https://en.wikipedia.org/wiki/Affine_space",
    "summary": "In mathematics, an affine space is a geometric structure that generalizes some of the properties of Euclidean spaces in such a way that these are independent of the concepts of distance and measure of angles, keeping only the properties related to parallelism and ratio of lengths for parallel line segments. Affine space is the setting for affine geometry. \nAs in Euclidean space, the fundamental objects in an affine space are called points, which can be thought of as locations in the space without any size or shape: zero-dimensional. Through any pair of points an infinite straight line can be drawn, a one-dimensional set of points; through any three points that are not collinear, a two-dimensional plane can be drawn; and, in general, through k + 1 points in general position, a k-dimensional flat or affine subspace can be drawn. Affine space is characterized by a notion of pairs of parallel lines that lie within the same plane but never meet each-other (non-parallel lines within the same",
    "content": "In mathematics, an affine space is a geometric structure that generalizes some of the properties of Euclidean spaces in such a way that these are independent of the concepts of distance and measure of angles, keeping only the properties related to parallelism and ratio of lengths for parallel line segments. Affine space is the setting for affine geometry. \nAs in Euclidean space, the fundamental objects in an affine space are called points, which can be thought of as locations in the space without any size or shape: zero-dimensional. Through any pair of points an infinite straight line can be drawn, a one-dimensional set of points; through any three points that are not collinear, a two-dimensional plane can be drawn; and, in general, through k + 1 points in general position, a k-dimensional flat or affine subspace can be drawn. Affine space is characterized by a notion of pairs of parallel lines that lie within the same plane but never meet each-other (non-parallel lines within the same plane intersect in a point). Given any line, a line parallel to it can be drawn through any point in the space, and the equivalence class of parallel lines are said to share a direction.\nUnlike for vectors in a vector space, in an affine space there is no distinguished point that serves as an origin. There is no predefined concept of adding or multiplying points together, or multiplying a point by a scalar number. However, for any affine space, an associated vector space can be constructed from the differences between start and end points, which are called free vectors, displacement vectors, translation vectors or simply translations. Likewise, it makes sense to add a displacement vector to a point of an affine space, resulting in a new point translated from the starting point by that vector. While points cannot be arbitrarily added together, it is meaningful to take affine combinations of points: weighted sums with numerical coefficients summing to 1, resulting in another point. These coefficients define a barycentric coordinate system for the flat through the points.\nAny vector space may be viewed as an affine space; this amounts to \"forgetting\" the special role played by the zero vector. In this case, elements of the vector space may be viewed either as points of the affine space or as displacement vectors or translations. When considered as a point, the zero vector is called the origin. Adding a fixed vector to the elements of a linear subspace (vector subspace) of a vector space produces an affine subspace of the vector space. One commonly says that this affine subspace has been obtained by translating (away from the origin) the linear subspace by the translation vector (the vector added to all the elements of the linear space). In finite dimensions, such an affine subspace is the solution set of an inhomogeneous linear system. The displacement vectors for that affine space are the solutions of the corresponding homogeneous linear system, which is a linear subspace. Linear subspaces, in contrast, always contain the origin of the vector space.\nThe dimension of an affine space is defined as the dimension of the vector space of its translations. An affine space of dimension one is an affine line. An affine space of dimension 2 is an affine plane. An affine subspace of dimension n – 1 in an affine space or a vector space of dimension n is an affine hyperplane.\n\nInformal description\nThe following characterization may be easier to understand than the usual formal definition: an affine space is what is left of a vector space after one has forgotten which point is the origin (or, in the words of the French mathematician Marcel Berger, \"An affine space is nothing more than a vector space whose origin we try to forget about, by adding translations to the linear maps\"). Imagine that Alice knows that a certain point is the actual origin, but Bob believes that another point—call it p—is the origin. Two vectors, a and b, are to be added. Bob draws an arrow from point p to point a and another arrow from point p to point b, and completes the parallelogram to find what Bob thinks is a + b, but Alice knows that he has actually computed\n\np + (a − p) + (b − p).\nSimilarly, Alice and Bob may evaluate any linear combination of a and b, or of any finite set of vectors, and will generally get different answers. However, if the sum of the coefficients in a linear combination is 1, then Alice and Bob will arrive at the same answer.\nIf Alice travels to\n\nλa + (1 − λ)b\nthen Bob can similarly travel to\n\np + λ(a − p) + (1 − λ)(b − p) = λa + (1 − λ)b.\nUnder this condition, for all coefficients λ + (1 − λ) = 1, Alice and Bob describe the same point with the same linear combination, despite using different origins.\nWhile only Alice knows the \"linear structure\", both Alice and Bob know the \"affine structure\"—i.e. the values of affine combinations, defined as linear combinations in which the sum of the coefficients is 1. A set with an affine structure is an",
    "links": [
      "1-forms",
      "Additive group",
      "Adjoint bundle",
      "Affine algebraic set",
      "Affine combination",
      "Affine frame",
      "Affine geometry",
      "Affine group",
      "Affine hull",
      "Affine hyperplane",
      "Affine map",
      "Affine plane",
      "Affine transformation",
      "Affine variety",
      "Affinity space",
      "Algebra over a field",
      "Algebraic Geometry (book)",
      "Algebraic geometry",
      "Algebraic varieties",
      "Algebraically closed field",
      "Alice and Bob",
      "Analytic geometry",
      "Angle",
      "Associated vector bundle",
      "Associativity",
      "Barycentric coordinate system",
      "Bijection",
      "Canonical isomorphism",
      "Cartesian coordinates",
      "Centroid",
      "Characterization (mathematics)",
      "Chart (topology)",
      "Closed set",
      "Closure (mathematics)",
      "Coarser topology",
      "Coefficient",
      "Coherent sheaves",
      "Cohomology",
      "Column space",
      "Complementary subspace",
      "Complementary subspaces",
      "Complex affine space",
      "Complex plane",
      "Complex projective line",
      "Connection (mathematics)",
      "Coordinate frame",
      "Coordinate space",
      "Coordinate system",
      "Coset",
      "Desargues's theorem"
    ],
    "categories": [
      "Category:Affine geometry",
      "Category:Articles with short description",
      "Category:Linear algebra",
      "Category:Short description is different from Wikidata",
      "Category:Space (mathematics)"
    ]
  },
  "Algebra over a field": {
    "title": "Algebra over a field",
    "url": "https://en.wikipedia.org/wiki/Algebra_over_a_field",
    "summary": "In mathematics, an algebra over a field (often simply called an algebra) is a vector space equipped with a bilinear product. Thus, an algebra is an algebraic structure consisting of a set together with operations of multiplication and addition and scalar multiplication by elements of a field and satisfying the axioms implied by \"vector space\" and \"bilinear\".\nThe multiplication operation in an algebra may or may not be associative, leading to the notions of associative algebras where associativity of multiplication is assumed, and non-associative algebras, where associativity is not assumed (but not excluded, either). Given an integer n, the ring of real square matrices of order n is an example of an associative algebra over the field of real numbers under matrix addition and matrix multiplication since matrix multiplication is associative. Three-dimensional Euclidean space with multiplication given by the vector cross product is an example of a nonassociative algebra over the field of ",
    "content": "In mathematics, an algebra over a field (often simply called an algebra) is a vector space equipped with a bilinear product. Thus, an algebra is an algebraic structure consisting of a set together with operations of multiplication and addition and scalar multiplication by elements of a field and satisfying the axioms implied by \"vector space\" and \"bilinear\".\nThe multiplication operation in an algebra may or may not be associative, leading to the notions of associative algebras where associativity of multiplication is assumed, and non-associative algebras, where associativity is not assumed (but not excluded, either). Given an integer n, the ring of real square matrices of order n is an example of an associative algebra over the field of real numbers under matrix addition and matrix multiplication since matrix multiplication is associative. Three-dimensional Euclidean space with multiplication given by the vector cross product is an example of a nonassociative algebra over the field of real numbers since the vector cross product is nonassociative, satisfying the Jacobi identity instead.\nAn algebra is unital or unitary if it has an identity element with respect to the multiplication. The ring of real square matrices of order n forms a unital algebra since the identity matrix of order n is the identity element with respect to matrix multiplication. It is an example of a unital associative algebra, a (unital) ring that is also a vector space.\nMany authors use the term algebra to mean associative algebra, or unital associative algebra, or in  some subjects such as algebraic geometry, unital associative commutative algebra.\nReplacing the field of scalars by a commutative ring leads to the more general notion of an algebra over a ring. Algebras are not to be confused with vector spaces equipped with a bilinear form, like inner product spaces, as, for such a space, the result of a product is not in the space, but rather in the field of coefficients.\n\nDefinition and motivation\nMotivating examples\nDefinition\nLet K be a field, and let A be a vector space over K equipped with an additional binary operation from A × A to A, denoted here by · (that is, if x and y are any two elements of A, then x · y is an element of A that is called the product of x and y).  Then A is an algebra over K if the following identities hold for all elements x, y, z in A , and all elements (often called scalars) a and b in K:\n\nRight distributivity: (x + y) · z = x · z + y · z\nLeft distributivity: z · (x + y) = z · x + z · y\nCompatibility with scalars: (ax) · (by) = (ab) (x · y).\nThese three axioms are another way of saying that the binary operation is bilinear. An algebra over K is sometimes also called a K-algebra, and K is called the base field of A. The binary operation is often referred to as multiplication in A. The convention adopted in this article is that multiplication of elements of an algebra is not necessarily associative, although some authors use the term algebra to refer to an associative algebra.\nWhen a binary operation on a vector space is commutative, left distributivity and right distributivity are equivalent, and, in this case, only one distributivity requires a proof. In general, for non-commutative operations left distributivity and right distributivity are not equivalent, and require separate proofs.\n\nBasic concepts\nAlgebra homomorphisms\nGiven K-algebras A and B, a homomorphism of K-algebras or K-algebra homomorphism is a K-linear map f: A → B such that f(xy) = f(x) f(y) for all x, y in A. If A and B are unital, then a homomorphism satisfying f(1A) = 1B is said to be a unital homomorphism. The space of all K-algebra homomorphisms between A and B is frequently written as\n\n  \n    \n      \n        \n          \n            H\n            o\n            m\n          \n          \n            K\n            \n              -alg\n            \n          \n        \n        (\n        A\n        ,\n        B\n        )\n        .\n      \n    \n    {\\displaystyle \\mathbf {Hom} _{K{\\text{-alg}}}(A,B).}\n  \n\nA K-algebra isomorphism is a bijective K-algebra homomorphism.\n\nSubalgebras and ideals\nA subalgebra of an algebra over a field K is a linear subspace that has the property that the product of any two of its elements is again in the subspace. In other words, a subalgebra of an algebra is a non-empty subset of elements that is closed under addition, multiplication, and scalar multiplication. In symbols, we say that a subset L of a K-algebra A is a subalgebra if for every x, y in L and c in K, we have that x · y, x + y, and cx are all in L.\nIn the above example of the complex numbers viewed as a two-dimensional algebra over the real numbers, the one-dimensional real line is a subalgebra.\nA left ideal of a K-algebra is a linear subspace that has the property that any element of the subspace multiplied on the left by any element of the algebra produces an element of the subspace. In symbols, we say that a subset L of a K-algebra A is a left ideal if for",
    "links": [
      "Abelian group",
      "Algebra over an operad",
      "Algebraic geometry",
      "Algebraic structure",
      "Alternative algebra",
      "Anticommutative property",
      "Associative",
      "Associative algebra",
      "Associativity",
      "B*-algebra",
      "Banach algebra",
      "Banach space",
      "Basis (linear algebra)",
      "Bialgebra",
      "Bijective",
      "Bilinear form",
      "Bilinear map",
      "Bilinear operation",
      "Bilinear operator",
      "Binary operation",
      "Boolean algebra (structure)",
      "Bruno Buchberger",
      "C*-algebra",
      "Center (ring theory)",
      "Clifford algebra",
      "Commutative",
      "Commutative algebra",
      "Commutative ring",
      "Commutativity",
      "Complemented lattice",
      "Complex number",
      "Complex plane",
      "Composition algebra",
      "Continuous function",
      "Covariance and contravariance of vectors",
      "Cross product",
      "Differential algebra",
      "Dimension (linear algebra)",
      "Direct sum",
      "Distributivity",
      "Division ring",
      "Doi (identifier)",
      "Domain (ring theory)",
      "Dual number",
      "Eduard Study",
      "Einstein notation",
      "Euclidean space",
      "Extension of scalars",
      "Field (mathematics)",
      "Field extension"
    ],
    "categories": [
      "Category:Algebras",
      "Category:Articles with short description",
      "Category:Short description matches Wikidata",
      "Category:Wikipedia articles needing page number citations from November 2024"
    ]
  },
  "Algebraic closure": {
    "title": "Algebraic closure",
    "url": "https://en.wikipedia.org/wiki/Algebraic_closure",
    "summary": "In mathematics, particularly abstract algebra, an algebraic closure of a field K is an algebraic extension of K that is algebraically closed.  It is one of many closures in mathematics.\nUsing Zorn's lemma or the weaker ultrafilter lemma,  it can be shown that every field has an algebraic closure, and that the algebraic closure of a field K is unique up to an isomorphism that fixes every member of K. Because of this essential uniqueness, we often speak of the algebraic closure of K, rather than an algebraic closure of K.\nThe algebraic closure of a field K can be thought of as the largest algebraic extension of K.\nTo see this, note that if L is any algebraic extension of K, then the algebraic closure of L is also an algebraic closure of K, and so L is contained within the algebraic closure of K.\nThe algebraic closure of K is also the smallest algebraically closed field containing K,\nbecause if M is any algebraically closed field containing K, then the elements of M that are algebraic ove",
    "content": "In mathematics, particularly abstract algebra, an algebraic closure of a field K is an algebraic extension of K that is algebraically closed.  It is one of many closures in mathematics.\nUsing Zorn's lemma or the weaker ultrafilter lemma,  it can be shown that every field has an algebraic closure, and that the algebraic closure of a field K is unique up to an isomorphism that fixes every member of K. Because of this essential uniqueness, we often speak of the algebraic closure of K, rather than an algebraic closure of K.\nThe algebraic closure of a field K can be thought of as the largest algebraic extension of K.\nTo see this, note that if L is any algebraic extension of K, then the algebraic closure of L is also an algebraic closure of K, and so L is contained within the algebraic closure of K.\nThe algebraic closure of K is also the smallest algebraically closed field containing K,\nbecause if M is any algebraically closed field containing K, then the elements of M that are algebraic over K form an algebraic closure of K.\nThe algebraic closure of a field K has the same cardinality as K if K is infinite, and is countably infinite if K is finite.\n\nExamples\nThe fundamental theorem of algebra states that the algebraic closure of the field of real numbers is the field of complex numbers.\nThe algebraic closure of the field of rational numbers is the field of algebraic numbers.\nThere are many countable algebraically closed fields within the complex numbers, and strictly containing the field of algebraic numbers; these are the algebraic closures of transcendental extensions of the rational numbers, e.g. the algebraic closure of Q(π).\nFor a finite field of prime power order q, the algebraic closure is a countably infinite field that contains a copy of the field of order qn for each positive integer n (and is in fact the union of these copies).\n\nExistence of an algebraic closure and splitting fields\nLet \n  \n    \n      \n        S\n        =\n        {\n        \n          f\n          \n            λ\n          \n        \n        \n          |\n        \n        λ\n        ∈\n        Λ\n        }\n      \n    \n    {\\displaystyle S=\\{f_{\\lambda }|\\lambda \\in \\Lambda \\}}\n  \n be the set of all monic irreducible polynomials in K[x].\nFor each \n  \n    \n      \n        \n          f\n          \n            λ\n          \n        \n        ∈\n        S\n      \n    \n    {\\displaystyle f_{\\lambda }\\in S}\n  \n, introduce new variables \n  \n    \n      \n        \n          u\n          \n            λ\n            ,\n            1\n          \n        \n        ,\n        …\n        ,\n        \n          u\n          \n            λ\n            ,\n            d\n          \n        \n      \n    \n    {\\displaystyle u_{\\lambda ,1},\\ldots ,u_{\\lambda ,d}}\n  \n where \n  \n    \n      \n        d\n        =\n        \n          \n            d\n            e\n            g\n            r\n            e\n            e\n          \n        \n        (\n        \n          f\n          \n            λ\n          \n        \n        )\n      \n    \n    {\\displaystyle d={\\rm {degree}}(f_{\\lambda })}\n  \n.\nLet R be the polynomial ring over K generated by \n  \n    \n      \n        \n          u\n          \n            λ\n            ,\n            i\n          \n        \n      \n    \n    {\\displaystyle u_{\\lambda ,i}}\n  \n for all \n  \n    \n      \n        λ\n        ∈\n        Λ\n      \n    \n    {\\displaystyle \\lambda \\in \\Lambda }\n  \n and all \n  \n    \n      \n        i\n        ≤\n        \n          \n            d\n            e\n            g\n            r\n            e\n            e\n          \n        \n        (\n        \n          f\n          \n            λ\n          \n        \n        )\n        .\n      \n    \n    {\\displaystyle i\\leq {\\rm {degree}}(f_{\\lambda }).}\n  \n Write\n\n  \n    \n      \n        \n          f\n          \n            λ\n          \n        \n        −\n        \n          ∏\n          \n            i\n            =\n            1\n          \n          \n            d\n          \n        \n        (\n        x\n        −\n        \n          u\n          \n            λ\n            ,\n            i\n          \n        \n        )\n        =\n        \n          ∑\n          \n            j\n            =\n            0\n          \n          \n            d\n            −\n            1\n          \n        \n        \n          r\n          \n            λ\n            ,\n            j\n          \n        \n        ⋅\n        \n          x\n          \n            j\n          \n        \n        ∈\n        R\n        [\n        x\n        ]\n      \n    \n    {\\displaystyle f_{\\lambda }-\\prod _{i=1}^{d}(x-u_{\\lambda ,i})=\\sum _{j=0}^{d-1}r_{\\lambda ,j}\\cdot x^{j}\\in R[x]}\n  \n\nwith \n  \n    \n      \n        \n          r\n          \n            λ\n            ,\n            j\n          \n        \n        ∈\n        R\n      \n    \n    {\\displaystyle r_{\\lambda ,j}\\in R}\n  \n.\nLet  I be the ideal in R generated by the \n  \n    \n      \n        \n          r\n          \n            λ\n            ,\n            j\n          \n        \n      \n    \n    {\\displaystyle r_{\\lambda ,j}}\n  \n. Sinc",
    "links": [
      "Absolute Galois group",
      "Abstract algebra",
      "Algebraic closure (convex analysis)",
      "Algebraic extension",
      "Algebraic number",
      "Algebraically closed field",
      "American Mathematical Society",
      "Cardinal number",
      "Characteristic of a field",
      "Closure (mathematics)",
      "Complete field",
      "Complex number",
      "Countably infinite",
      "Doi (identifier)",
      "Field (mathematics)",
      "Finite field",
      "Fixed point (mathematics)",
      "Fundamental theorem of algebra",
      "I. G. Macdonald",
      "ISBN (identifier)",
      "Ideal of a ring",
      "Integer",
      "Irreducible polynomial",
      "Irving Kaplansky",
      "Isomorphism",
      "Mathematics",
      "Michael Atiyah",
      "Monic polynomial",
      "Perfect field",
      "Prime number",
      "Puiseux expansion",
      "Rational number",
      "Real number",
      "Separable extension",
      "Splitting field",
      "Springer-Verlag",
      "Transcendental extension",
      "Ultrafilter lemma",
      "Up to",
      "Zbl (identifier)",
      "Zorn's lemma"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Field extensions",
      "Category:Short description matches Wikidata"
    ]
  },
  "Algebraic combinatorics": {
    "title": "Algebraic combinatorics",
    "url": "https://en.wikipedia.org/wiki/Algebraic_combinatorics",
    "summary": "Algebraic combinatorics is an area of mathematics that employs methods of abstract algebra, notably group theory and representation theory, in various combinatorial contexts and, conversely, applies combinatorial techniques to problems in algebra.",
    "content": "Algebraic combinatorics is an area of mathematics that employs methods of abstract algebra, notably group theory and representation theory, in various combinatorial contexts and, conversely, applies combinatorial techniques to problems in algebra.\n\nHistory\nThe term \"algebraic combinatorics\" was introduced in the late 1970s. Through the early or mid-1990s, typical combinatorial objects of interest in algebraic combinatorics either admitted a lot of symmetries (association schemes, strongly regular graphs, posets with a group action) or possessed a rich algebraic structure, frequently of representation theoretic origin (symmetric functions, Young tableaux). This period is reflected in the area 05E, Algebraic combinatorics, of the AMS Mathematics Subject Classification, introduced in 1991.\n\nScope\nAlgebraic combinatorics has come to be seen more expansively as an area of mathematics where the interaction of combinatorial and algebraic methods is particularly strong and significant. Thus the combinatorial topics may be enumerative in nature or involve matroids, polytopes, partially ordered sets, or finite geometries. On the algebraic side, besides group theory and representation theory, lattice theory and commutative algebra are commonly used.\n\nImportant topics\nSymmetric functions\nThe ring of symmetric functions is a specific limit of the rings of symmetric polynomials in n indeterminates, as n goes to infinity. This ring serves as universal structure in which relations between symmetric polynomials can be expressed in a way independent of the number n of indeterminates (but its elements are neither polynomials nor functions). Among other things, this ring plays an important role in the representation theory of the symmetric groups.\n\nAssociation schemes\nAn association scheme is a collection of binary relations satisfying certain compatibility conditions. Association schemes provide a unified approach to many topics, for example combinatorial designs and coding theory. In algebra, association schemes generalize groups, and the theory of association schemes generalizes the character theory of linear representations of groups.\n\nStrongly regular graphs\nA strongly regular graph is defined as follows.  Let G = (V,E) be a regular graph with v vertices and degree k.  G is said to be strongly regular if there are also integers λ and μ such that:\n\nEvery two adjacent vertices have λ common neighbours.\nEvery two non-adjacent vertices have μ common neighbours.\nA graph of this kind is sometimes said to be a srg(v, k, λ, μ).\nSome authors exclude graphs which satisfy the definition trivially, namely those graphs which are the disjoint union of one or more equal-sized complete graphs, and their complements, the Turán graphs.\n\nYoung tableaux\nA Young tableau (pl.: tableaux) is a combinatorial object useful in representation theory and Schubert calculus. It provides a convenient way to describe the group representations of the symmetric and general linear groups and to study their properties. Young tableaux were introduced by Alfred Young, a mathematician at Cambridge University, in 1900. They were then applied to the study of the symmetric group by Georg Frobenius in 1903. Their theory was further developed by many mathematicians, including Percy MacMahon, W. V. D. Hodge, G. de B. Robinson, Gian-Carlo Rota, Alain Lascoux, Marcel-Paul Schützenberger and Richard P. Stanley.\n\nMatroids\nA matroid is a structure that captures and generalizes the notion of linear independence in vector spaces. There are many equivalent ways to define a matroid, the most significant being in terms of independent sets, bases, circuits, closed sets or flats, closure operators, and rank functions.\nMatroid theory borrows extensively from the terminology of linear algebra and graph theory, largely because it is the abstraction of various notions of central importance in these fields. Matroids have found applications in geometry, topology, combinatorial optimization, network theory and coding theory.\n\nFinite geometries\nA finite geometry is any geometric system that has only a finite number of points.\nThe familiar Euclidean geometry is not finite, because a Euclidean line contains infinitely many points. A geometry based on the graphics displayed on a computer screen, where the pixels are considered to be the points, would be a finite geometry. While there are many systems that could be called finite geometries, attention is mostly paid to the finite projective and affine spaces because of their regularity and simplicity.  Other significant types of finite geometry are finite Möbius or inversive planes and Laguerre planes, which are examples of a general type called Benz planes, and their higher-dimensional analogs such as higher finite inversive geometries.\nFinite geometries may be constructed via linear algebra, starting from vector spaces over a finite field; the affine and projective planes so constructed are called Galois geometries.  Finite geometries can ",
    "links": [
      "Abstract algebra",
      "Adjacent vertices",
      "Affine space",
      "Alain Lascoux",
      "Alfred Young (mathematician)",
      "Algebraic Combinatorics (journal)",
      "Algebraic graph theory",
      "American Mathematical Society",
      "Anders Björner",
      "Association scheme",
      "Banff International Research Station",
      "Benz plane",
      "Bernd Sturmfels",
      "Binary relation",
      "Cambridge University Press",
      "Chris Godsil",
      "Coding theory",
      "Combinatorial commutative algebra",
      "Combinatorial design",
      "Combinatorial optimization",
      "Combinatorics",
      "Commutative algebra",
      "Complement graph",
      "Complete graph",
      "Curtis Greene",
      "Doi (identifier)",
      "Doron Zeilberger",
      "Enumerative combinatorics",
      "Euclidean geometry",
      "Fano plane",
      "Finite field",
      "Finite geometry",
      "Finite set",
      "Galois geometry",
      "General linear group",
      "Geometry",
      "Georg Frobenius",
      "Gian-Carlo Rota",
      "Gilbert de Beauregard Robinson",
      "Graduate Texts in Mathematics",
      "Graph theory",
      "Group (mathematics)",
      "Group action (mathematics)",
      "Group character",
      "Group representation",
      "Group theory",
      "ISBN (identifier)",
      "Integer",
      "International Conference on Formal Power Series and Algebraic Combinatorics",
      "Internet Archive"
    ],
    "categories": [
      "Category:Algebraic combinatorics",
      "Category:Articles with short description",
      "Category:Commons category link from Wikidata",
      "Category:Short description is different from Wikidata",
      "Category:Use dmy dates from January 2022"
    ]
  },
  "Algebraic equation": {
    "title": "Algebraic equation",
    "url": "https://en.wikipedia.org/wiki/Algebraic_equation",
    "summary": "In mathematics, an algebraic equation or polynomial equation is an equation of the form \n  \n    \n      \n        P\n        =\n        0\n      \n    \n    {\\displaystyle P=0}\n  \n, where P is a polynomial, usually with rational numbers for coefficients. \nFor example, \n  \n    \n      \n        \n          x\n          \n            5\n          \n        \n        −\n        3\n        x\n        +\n        1\n        =\n        0\n      \n    \n    {\\displaystyle x^{5}-3x+1=0}\n  \n is an algebraic equation with integer coefficients and\n\n  \n    \n      \n        \n          y\n          \n            4\n          \n        \n        +\n        \n          \n            \n              x\n              y\n            \n            2\n          \n        \n        −\n        \n          \n            \n              x\n              \n                3\n              \n            \n            3\n          \n        \n        +\n        x\n        \n          y\n          \n            2\n          \n        \n        +\n        \n          y\n       ",
    "content": "In mathematics, an algebraic equation or polynomial equation is an equation of the form \n  \n    \n      \n        P\n        =\n        0\n      \n    \n    {\\displaystyle P=0}\n  \n, where P is a polynomial, usually with rational numbers for coefficients. \nFor example, \n  \n    \n      \n        \n          x\n          \n            5\n          \n        \n        −\n        3\n        x\n        +\n        1\n        =\n        0\n      \n    \n    {\\displaystyle x^{5}-3x+1=0}\n  \n is an algebraic equation with integer coefficients and\n\n  \n    \n      \n        \n          y\n          \n            4\n          \n        \n        +\n        \n          \n            \n              x\n              y\n            \n            2\n          \n        \n        −\n        \n          \n            \n              x\n              \n                3\n              \n            \n            3\n          \n        \n        +\n        x\n        \n          y\n          \n            2\n          \n        \n        +\n        \n          y\n          \n            2\n          \n        \n        +\n        \n          \n            1\n            7\n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle y^{4}+{\\frac {xy}{2}}-{\\frac {x^{3}}{3}}+xy^{2}+y^{2}+{\\frac {1}{7}}=0}\n  \n\nis a multivariate polynomial equation over the rationals.\nFor many authors, the term algebraic equation refers only to the univariate case, that is polynomial equations that involve only one variable. On the other hand, a polynomial equation may involve several variables (the multivariate case), in which case the term polynomial equation is usually preferred.\nSome but not all polynomial equations with rational coefficients have a solution that is an algebraic expression that can be found using a finite number of operations that involve only those same types of coefficients (that is, can be solved algebraically). This can be done for all such equations of degree one, two, three, or four; but for degree five or more it can only be done for some equations, not all. A large amount of research has been devoted to compute efficiently accurate approximations of the real or complex solutions of a univariate algebraic equation (see Root-finding algorithm) and of the common solutions of several multivariate polynomial equations (see System of polynomial equations).\n\nTerminology\nThe term \"algebraic equation\" dates from the time when the main problem of algebra was to solve univariate polynomial equations. This problem was completely solved during the 19th century; see Fundamental theorem of algebra, Abel–Ruffini theorem and Galois theory.\nSince then, the scope of algebra has been dramatically enlarged. In particular, it includes the study of equations that involve nth roots and, more generally, algebraic expressions. This makes the term algebraic equation ambiguous outside the context of the old problem. So the term polynomial equation is generally preferred when this ambiguity may occur, specially when considering multivariate equations.\n\nHistory\nThe study of algebraic equations is probably as old as mathematics: the Babylonian mathematicians, as early as 2000 BC could solve some kinds of quadratic equations (displayed on Old Babylonian clay tablets).\nUnivariate algebraic equations over the rationals (i.e., with rational coefficients) have a very long history. Ancient mathematicians wanted the solutions in the form of radical expressions, like \n  \n    \n      \n        x\n        =\n        \n          \n            \n              1\n              +\n              \n                \n                  5\n                \n              \n            \n            2\n          \n        \n      \n    \n    {\\displaystyle x={\\frac {1+{\\sqrt {5}}}{2}}}\n  \n for the positive solution of \n  \n    \n      \n        \n          x\n          \n            2\n          \n        \n        −\n        x\n        −\n        1\n        =\n        0\n      \n    \n    {\\displaystyle x^{2}-x-1=0}\n  \n. The ancient Egyptians knew how to solve equations of degree 2 in this manner. The Indian mathematician Brahmagupta (597–668 AD) explicitly described the quadratic formula in his treatise Brāhmasphuṭasiddhānta published in 628 AD, but written in words instead of symbols. In the 9th century Muhammad ibn Musa al-Khwarizmi and other Islamic mathematicians derived the quadratic formula, the general solution of equations of degree 2, and recognized the importance of the discriminant.  During the Renaissance in 1545, Gerolamo Cardano published the solution of  Scipione del Ferro and Niccolò Fontana Tartaglia to equations of degree 3 and that of  Lodovico Ferrari for equations of degree 4. Finally Niels Henrik Abel proved, in 1824, that equations of degree 5 and higher do not have general solutions using radicals. Galois theory, named after Évariste Galois, showed that some equations of at least degree 5 do not even have an idiosyncratic solution in radicals, and gave criteria for deciding if an equation is in fact solvable using radicals.\n\nAreas of study\nThe ",
    "links": [
      "Abel–Ruffini theorem",
      "Algebra",
      "Algebraic expression",
      "Algebraic extension",
      "Algebraic function",
      "Algebraic geometry",
      "Algebraic number",
      "Algebraic number theory",
      "Algebraic solution",
      "Algebraically closed field",
      "Babylonian mathematics",
      "Bezout method",
      "Charles Hermite",
      "Clay tablet",
      "Coefficient",
      "Complex number",
      "Complex numbers",
      "Cramer's theorem (algebraic curves)",
      "Cubic equation",
      "Cubic function",
      "Cyclotomic polynomials",
      "Degree of a polynomial",
      "Descartes method",
      "Diophantine equation",
      "Discriminant",
      "Elementary function",
      "Elliptical function",
      "Encyclopedia of Mathematics",
      "Equation",
      "Equation solving",
      "Eric W. Weisstein",
      "Euler method",
      "European Mathematical Society",
      "Exponentiation",
      "Ferrari method",
      "Field (mathematics)",
      "Field extension",
      "Field theory (mathematics)",
      "First Babylonian dynasty",
      "Fundamental theorem of algebra",
      "Galois group",
      "Galois theory",
      "Gerolamo Cardano",
      "Hyperbolic functions",
      "Imaginary unit",
      "Integer",
      "Integral domain",
      "Intermediate value theorem",
      "Lagrange method",
      "Leonhard Euler"
    ],
    "categories": [
      "Category:All articles lacking in-text citations",
      "Category:Articles lacking in-text citations from June 2023",
      "Category:Articles with short description",
      "Category:Equations",
      "Category:Polynomials",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Algebraic expression": {
    "title": "Algebraic expression",
    "url": "https://en.wikipedia.org/wiki/Algebraic_expression",
    "summary": "In mathematics, an algebraic expression is an expression built up from constants (usually, algebraic numbers), variables, and the basic algebraic operations: \naddition (+), subtraction (-), multiplication (×), division (÷), whole number powers, and roots (fractional powers).. For example, ⁠\n  \n    \n      \n        3\n        \n          x\n          \n            2\n          \n        \n        −\n        2\n        x\n        y\n        +\n        c\n      \n    \n    {\\displaystyle 3x^{2}-2xy+c}\n  \n⁠ is an algebraic expression. Since taking the square root is the same as raising to the power ⁠1/2⁠, the following is also an algebraic expression:\n\n  \n    \n      \n        \n          \n            \n              \n                1\n                −\n                \n                  x\n                  \n                    2\n                  \n                \n              \n              \n                1\n                +\n                \n                  x\n                  \n                    2\n  ",
    "content": "In mathematics, an algebraic expression is an expression built up from constants (usually, algebraic numbers), variables, and the basic algebraic operations: \naddition (+), subtraction (-), multiplication (×), division (÷), whole number powers, and roots (fractional powers).. For example, ⁠\n  \n    \n      \n        3\n        \n          x\n          \n            2\n          \n        \n        −\n        2\n        x\n        y\n        +\n        c\n      \n    \n    {\\displaystyle 3x^{2}-2xy+c}\n  \n⁠ is an algebraic expression. Since taking the square root is the same as raising to the power ⁠1/2⁠, the following is also an algebraic expression:\n\n  \n    \n      \n        \n          \n            \n              \n                1\n                −\n                \n                  x\n                  \n                    2\n                  \n                \n              \n              \n                1\n                +\n                \n                  x\n                  \n                    2\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\sqrt {\\frac {1-x^{2}}{1+x^{2}}}}}\n  \n\nAn algebraic equation is an equation involving polynomials, for which algebraic expressions may be solutions.\nIf you restrict your set of constants to be numbers, any algebraic expression can be called an arithmetic expression. However, algebraic expressions can be used on more abstract objects such as in Abstract algebra. If you restrict your constants to integers, the set of numbers that can be described with an algebraic expression are called Algebraic numbers.\nBy contrast, transcendental numbers like π  and e are not algebraic, since they are not derived from integer constants and algebraic operations. Usually, π is constructed as a geometric relationship, and the definition of e requires an infinite number of algebraic operations. More generally, expressions which are algebraically independent from their constants and/or variables are called transcendental.\n\nTerminology\nAlgebra has its own terminology to describe parts of an expression:\n\nConventions\nVariables\nBy convention, letters at the beginning of the alphabet (e.g.  \n  \n    \n      \n        a\n        ,\n        b\n        ,\n        c\n      \n    \n    {\\displaystyle a,b,c}\n  \n) are typically used to represent constants, and those toward the end of the alphabet (e.g. \n  \n    \n      \n        x\n        ,\n        y\n      \n    \n    {\\displaystyle x,y}\n  \n and \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n  \n) are used to represent variables. They are usually written in italics.\n\nExponents\nBy convention, terms with the highest power (exponent), are written on the left, for example, \n  \n    \n      \n        \n          x\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle x^{2}}\n  \n is written to the left of \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n. When a coefficient is one, it is usually omitted (e.g. \n  \n    \n      \n        1\n        \n          x\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle 1x^{2}}\n  \n is written \n  \n    \n      \n        \n          x\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle x^{2}}\n  \n). Likewise when the exponent (power) is one, (e.g. \n  \n    \n      \n        3\n        \n          x\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle 3x^{1}}\n  \n is written \n  \n    \n      \n        3\n        x\n      \n    \n    {\\displaystyle 3x}\n  \n), and, when the exponent is zero, the result is always 1 (e.g. \n  \n    \n      \n        3\n        \n          x\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle 3x^{0}}\n  \n is written \n  \n    \n      \n        3\n      \n    \n    {\\displaystyle 3}\n  \n, since \n  \n    \n      \n        \n          x\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle x^{0}}\n  \n is always \n  \n    \n      \n        1\n      \n    \n    {\\displaystyle 1}\n  \n).\n\nIn roots of polynomials\nThe roots of a polynomial expression of degree n, or equivalently the solutions of a polynomial equation, can always be written as algebraic expressions if n < 5 (see quadratic formula, cubic function, and quartic equation). Such a solution of an equation is called an algebraic solution. But the Abel–Ruffini theorem states that algebraic solutions do not exist for all such equations (just for some of them) if n \n  \n    \n      \n        ≥\n      \n    \n    {\\displaystyle \\geq }\n  \n 5.\n\nRational expressions\nGiven two polynomials ⁠\n  \n    \n      \n        P\n        (\n        x\n        )\n      \n    \n    {\\displaystyle P(x)}\n  \n⁠ and ⁠\n  \n    \n      \n        Q\n        (\n        x\n        )\n      \n    \n    {\\displaystyle Q(x)}\n  \n⁠\n, their quotient is called a rational expression or simply rational fraction. A rational expression \n  \n    \n      \n        \n          \n            \n              P\n              (\n              x\n              )\n            \n ",
    "links": [
      "Abel–Ruffini theorem",
      "Abstract algebra",
      "Addition",
      "Algebra",
      "Algebraic equation",
      "Algebraic function",
      "Algebraic number",
      "Algebraic numbers",
      "Algebraic operation",
      "Algebraic solution",
      "Algebraically independent",
      "Analytical expression",
      "Arithmetic",
      "Bessel function",
      "Closed-form expression",
      "Constant (mathematics)",
      "Continued fraction",
      "Cubic function",
      "David J. Darling",
      "Degree of a polynomial",
      "Derivative",
      "Division (mathematics)",
      "E (mathematical constant)",
      "Elementary arithmetic",
      "Equation",
      "Eric W. Weisstein",
      "Ernest Borisovich Vinberg",
      "Exponential function",
      "Exponentiation",
      "Expression (mathematics)",
      "Factorial",
      "Fraction",
      "Gamma function",
      "Hyperbolic function",
      "ISBN (identifier)",
      "Infinite product",
      "Integers",
      "Integral",
      "Inverse hyperbolic functions",
      "Inverse trigonometric functions",
      "Least common multiple",
      "Limit (mathematics)",
      "Logarithm",
      "MathWorld",
      "Mathematical constant",
      "Mathematics",
      "Monomial",
      "Multiplication",
      "Nth root",
      "Number"
    ],
    "categories": [
      "Category:All articles lacking reliable references",
      "Category:All articles needing additional references",
      "Category:All self-contradictory articles",
      "Category:Articles lacking reliable references from August 2024",
      "Category:Articles needing additional references from August 2024",
      "Category:Articles with short description",
      "Category:Elementary algebra",
      "Category:Self-contradictory articles from October 2024",
      "Category:Short description is different from Wikidata",
      "Category:Webarchive template wayback links"
    ]
  },
  "Algebraic logic": {
    "title": "Algebraic logic",
    "url": "https://en.wikipedia.org/wiki/Algebraic_logic",
    "summary": "In mathematical logic, algebraic logic is the reasoning obtained by manipulating equations with free variables.\nWhat is now usually called classical algebraic logic focuses on the identification and algebraic description of models appropriate for the study of various logics (in the form of classes of algebras that constitute the algebraic semantics for these deductive systems) and connected problems like representation and duality. Well known results like the representation theorem for Boolean algebras and Stone duality fall under the umbrella of classical algebraic logic (Czelakowski 2003).\nWorks in the more recent abstract algebraic logic (AAL) focus on the process of algebraization itself, like classifying various forms of algebraizability using the Leibniz operator (Czelakowski 2003).",
    "content": "In mathematical logic, algebraic logic is the reasoning obtained by manipulating equations with free variables.\nWhat is now usually called classical algebraic logic focuses on the identification and algebraic description of models appropriate for the study of various logics (in the form of classes of algebras that constitute the algebraic semantics for these deductive systems) and connected problems like representation and duality. Well known results like the representation theorem for Boolean algebras and Stone duality fall under the umbrella of classical algebraic logic (Czelakowski 2003).\nWorks in the more recent abstract algebraic logic (AAL) focus on the process of algebraization itself, like classifying various forms of algebraizability using the Leibniz operator (Czelakowski 2003).\n\nCalculus of relations\nA homogeneous binary relation is found in the power set of X × X for some set X, while a heterogeneous relation is found in the power set of X × Y, where X ≠ Y. Whether a given relation holds for two individuals is one bit of information, so relations are studied with Boolean arithmetic. Elements of the power set are partially ordered by inclusion, and lattice of these sets becomes an algebra through relative multiplication or composition of relations.\n\"The basic operations are set-theoretic union, intersection and complementation, the relative multiplication, and conversion.\"\nThe conversion refers to the converse relation that always exists, contrary to function theory. A given relation may be represented by a logical matrix; then the converse relation is represented by the transpose matrix. A relation obtained as the composition of two others is then represented by the logical matrix obtained by matrix multiplication using Boolean arithmetic.\n\nExample\nAn example of calculus of relations arises in erotetics, the theory of questions. In the universe of utterances there are statements S and questions Q. There are two relations π and α from Q to S: q α a holds when a is a direct answer to question q. The other relation, q π p holds when p is a presupposition of question q. The converse relation πT runs from S to Q so that the composition πTα is a homogeneous relation on S. The art of putting the right question to elicit a sufficient answer is recognized in Socratic method dialogue.\n\nFunctions\nThe description of the key binary relation properties has been formulated with the calculus of relations. The univalence property of functions describes a relation R that satisfies the formula \n  \n    \n      \n        \n          R\n          \n            T\n          \n        \n        R\n        ⊆\n        I\n        ,\n      \n    \n    {\\displaystyle R^{T}R\\subseteq I,}\n  \n where I is the identity relation on the range of R. The injective property corresponds to univalence of \n  \n    \n      \n        \n          R\n          \n            T\n          \n        \n      \n    \n    {\\displaystyle R^{T}}\n  \n, or the formula \n  \n    \n      \n        R\n        \n          R\n          \n            T\n          \n        \n        ⊆\n        I\n        ,\n      \n    \n    {\\displaystyle RR^{T}\\subseteq I,}\n  \n where this time I is the identity on the domain of R.\nBut a univalent relation is only a partial function, while a univalent total relation is a function. The formula for totality is \n  \n    \n      \n        I\n        ⊆\n        R\n        \n          R\n          \n            T\n          \n        \n        .\n      \n    \n    {\\displaystyle I\\subseteq RR^{T}.}\n  \n Charles Loewner and Gunther Schmidt use the term mapping for a total, univalent relation.\nThe facility of complementary relations inspired Augustus De Morgan and Ernst Schröder to  introduce equivalences using \n  \n    \n      \n        \n          \n            \n              R\n              ¯\n            \n          \n        \n      \n    \n    {\\displaystyle {\\bar {R}}}\n  \n for the complement of relation R. These equivalences provide alternative formulas for univalent relations (\n  \n    \n      \n        R\n        \n          \n            \n              I\n              ¯\n            \n          \n        \n        ⊆\n        \n          \n            \n              R\n              ¯\n            \n          \n        \n      \n    \n    {\\displaystyle R{\\bar {I}}\\subseteq {\\bar {R}}}\n  \n), and total relations (\n  \n    \n      \n        \n          \n            \n              R\n              ¯\n            \n          \n        \n        ⊆\n        R\n        \n          \n            \n              I\n              ¯\n            \n          \n        \n      \n    \n    {\\displaystyle {\\bar {R}}\\subseteq R{\\bar {I}}}\n  \n). \nTherefore, mappings satisfy the formula \n  \n    \n      \n        \n          \n            \n              R\n              ¯\n            \n          \n        \n        =\n        R\n        \n          \n            \n              I\n              ¯\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle {\\bar {R}}=R{\\bar {I}}.}\n  \n Schmidt uses this principle as \"slipping below negation from the",
    "links": [
      "A. N. Whitehead",
      "Abstract algebraic logic",
      "Abstract logic",
      "Ackermann set theory",
      "Aleph number",
      "Alexander Macfarlane",
      "Alfred Tarski",
      "Algebraic semantics (mathematical logic)",
      "Algebraic structure",
      "Alphabet (formal languages)",
      "American Mathematical Society",
      "Annals of Mathematics",
      "Argument",
      "Arity",
      "Atomic formula",
      "Atomic sentence",
      "Augustus De Morgan",
      "Automata theory",
      "Automated theorem proving",
      "Axiom",
      "Axiom of choice",
      "Axiom schema",
      "Axiomatic set theory",
      "Axiomatic system",
      "Axiomatization of Boolean algebras",
      "B. G. Teubner",
      "Banach–Tarski paradox",
      "Bertrand Russell",
      "Bijection",
      "Binary operation",
      "Binary relation",
      "Bit",
      "Boolean-valued model",
      "Boolean algebra",
      "Boolean algebra (structure)",
      "Boolean algebras canonically defined",
      "Boolean function",
      "Cambridge University Press",
      "Cantor's diagonal argument",
      "Cantor's paradox",
      "Cantor's theorem",
      "Cardinality",
      "Cartesian product",
      "Categorical theory",
      "Category (mathematics)",
      "Category of sets",
      "Category theory",
      "Charles Loewner",
      "Charles Sanders Peirce",
      "Christine Ladd"
    ],
    "categories": [
      "Category:Algebraic logic",
      "Category:Articles with short description",
      "Category:History of logic",
      "Category:Short description matches Wikidata",
      "Category:Wikipedia articles needing clarification from March 2023"
    ]
  },
  "Algebraic varieties": {
    "title": "Algebraic variety",
    "url": "https://en.wikipedia.org/wiki/Algebraic_variety",
    "summary": "Algebraic varieties are the central objects of study in algebraic geometry, a sub-field of mathematics. Classically, an algebraic variety is defined as the set of solutions of a system of polynomial equations over the real or complex numbers. Modern definitions generalize this concept in several different ways, while attempting to preserve the geometric intuition behind the original definition. \nConventions regarding the definition of an algebraic variety differ slightly. For example, some definitions require an algebraic variety to be irreducible, which means that it is not the union of two smaller sets that are closed in the Zariski topology. Under this definition, non-irreducible algebraic varieties are called algebraic sets. Other conventions do not require irreducibility.\nThe fundamental theorem of algebra establishes a link between algebra and geometry by showing that a monic polynomial (an algebraic object) in one variable with complex number coefficients is determined by the se",
    "content": "Algebraic varieties are the central objects of study in algebraic geometry, a sub-field of mathematics. Classically, an algebraic variety is defined as the set of solutions of a system of polynomial equations over the real or complex numbers. Modern definitions generalize this concept in several different ways, while attempting to preserve the geometric intuition behind the original definition. \nConventions regarding the definition of an algebraic variety differ slightly. For example, some definitions require an algebraic variety to be irreducible, which means that it is not the union of two smaller sets that are closed in the Zariski topology. Under this definition, non-irreducible algebraic varieties are called algebraic sets. Other conventions do not require irreducibility.\nThe fundamental theorem of algebra establishes a link between algebra and geometry by showing that a monic polynomial (an algebraic object) in one variable with complex number coefficients is determined by the set of its roots (a geometric object) in the complex plane. Generalizing this result, Hilbert's Nullstellensatz provides a fundamental correspondence between ideals of polynomial rings and algebraic sets. Using the Nullstellensatz and related results, mathematicians have established a strong correspondence between questions on algebraic sets and questions of ring theory. This correspondence is a defining feature of algebraic geometry.\nMany algebraic varieties are differentiable manifolds, but an algebraic variety may have singular points while a differentiable manifold cannot. Algebraic varieties can be characterized by their dimension. Algebraic varieties of dimension one are called algebraic curves and algebraic varieties of dimension two are called algebraic surfaces.\nIn the context of modern scheme theory, an algebraic variety over a field is an integral (irreducible and reduced) scheme over that field whose structure morphism is separated and of finite type.\n\nOverview and definitions\nAn affine variety over an algebraically closed field is conceptually the easiest type of variety to define, which will be done in this section. Next, one can define projective and quasi-projective varieties in a similar way. The most general definition of a variety is obtained by patching together smaller quasi-projective varieties. It is not obvious that one can construct genuinely new examples of varieties in this way, but Nagata gave an example of such a new variety in the 1950s.\n\nAffine varieties\nFor an algebraically closed field K and a natural number n, let An be an affine n-space over K, identified to \n  \n    \n      \n        \n          K\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle K^{n}}\n  \n through the choice of an affine coordinate system. The polynomials  f  in the ring K[x1, ..., xn] can be viewed as K-valued functions on An by evaluating  f  at the points in An, i.e. by choosing values in K for each xi. For each set S of polynomials in K[x1, ..., xn], define the zero-locus Z(S) to be the set of points in An on which the functions in S simultaneously vanish, that is to say\n\n  \n    \n      \n        Z\n        (\n        S\n        )\n        =\n        \n          {\n          \n            x\n            ∈\n            \n              \n                A\n              \n              \n                n\n              \n            \n            ∣\n            f\n            (\n            x\n            )\n            =\n            0\n            \n               for all \n            \n            f\n            ∈\n            S\n          \n          }\n        \n        .\n      \n    \n    {\\displaystyle Z(S)=\\left\\{x\\in \\mathbf {A} ^{n}\\mid f(x)=0{\\text{ for all }}f\\in S\\right\\}.}\n  \n\nA subset V of An is called an affine algebraic set if V = Z(S) for some S. A nonempty affine algebraic set V is called irreducible if it cannot be written as the union of two proper algebraic subsets. An irreducible affine algebraic set is also called an affine variety. (Some authors use the phrase affine variety to refer to any affine algebraic set, irreducible or not.)\nAffine varieties can be given a natural topology by declaring the closed sets to be precisely the affine algebraic sets. This topology is called the Zariski topology.\nGiven a subset V of An, we define I(V) to be the ideal of all polynomial functions vanishing on V:\n\n  \n    \n      \n        I\n        (\n        V\n        )\n        =\n        \n          {\n          \n            f\n            ∈\n            K\n            [\n            \n              x\n              \n                1\n              \n            \n            ,\n            …\n            ,\n            \n              x\n              \n                n\n              \n            \n            ]\n            ∣\n            f\n            (\n            x\n            )\n            =\n            0\n            \n               for all \n            \n            x\n            ∈\n            V\n          \n          }\n        \n        .\n      \n  ",
    "links": [
      "Abelian group",
      "Abelian variety",
      "Absolutely irreducible",
      "Abstract algebra",
      "Addition",
      "Affine coordinate system",
      "Affine space",
      "Affine variety",
      "Alexander Grothendieck",
      "Algebra",
      "Algebraic Geometry (book)",
      "Algebraic curve",
      "Algebraic expression",
      "Algebraic geometry",
      "Algebraic geometry of projective spaces",
      "Algebraic manifold",
      "Algebraic number theory",
      "Algebraic space",
      "Algebraic stack",
      "Algebraic surface",
      "Algebraic torus",
      "Algebraically closed field",
      "Analytic variety",
      "André Weil",
      "Associated graded ring",
      "Automorphism",
      "Basis (linear algebra)",
      "Birational geometry",
      "Category theory",
      "Characteristic class",
      "Characteristic variety",
      "Chern class",
      "CiteSeerX (identifier)",
      "Claude Chevalley",
      "Closed immersion",
      "Closed set",
      "Commensurability (group theory)",
      "Commutative algebra",
      "Compactification (algebraic geometry)",
      "Complete variety",
      "Complex number",
      "Complex plane",
      "Composition algebra",
      "Constructible set (topology)",
      "Coordinate vector",
      "D-module",
      "David Cox (mathematician)",
      "David Eisenbud",
      "David Mumford",
      "Determinant"
    ],
    "categories": [
      "Category:Algebraic geometry",
      "Category:Algebraic varieties",
      "Category:All articles lacking in-text citations",
      "Category:Articles lacking in-text citations from March 2013",
      "Category:Articles with short description",
      "Category:Pages that use a deprecated format of the math tags",
      "Category:Short description matches Wikidata",
      "Category:Wikipedia articles incorporating text from PlanetMath"
    ]
  },
  "Algebraic variety": {
    "title": "Algebraic variety",
    "url": "https://en.wikipedia.org/wiki/Algebraic_variety",
    "summary": "Algebraic varieties are the central objects of study in algebraic geometry, a sub-field of mathematics. Classically, an algebraic variety is defined as the set of solutions of a system of polynomial equations over the real or complex numbers. Modern definitions generalize this concept in several different ways, while attempting to preserve the geometric intuition behind the original definition. \nConventions regarding the definition of an algebraic variety differ slightly. For example, some definitions require an algebraic variety to be irreducible, which means that it is not the union of two smaller sets that are closed in the Zariski topology. Under this definition, non-irreducible algebraic varieties are called algebraic sets. Other conventions do not require irreducibility.\nThe fundamental theorem of algebra establishes a link between algebra and geometry by showing that a monic polynomial (an algebraic object) in one variable with complex number coefficients is determined by the se",
    "content": "Algebraic varieties are the central objects of study in algebraic geometry, a sub-field of mathematics. Classically, an algebraic variety is defined as the set of solutions of a system of polynomial equations over the real or complex numbers. Modern definitions generalize this concept in several different ways, while attempting to preserve the geometric intuition behind the original definition. \nConventions regarding the definition of an algebraic variety differ slightly. For example, some definitions require an algebraic variety to be irreducible, which means that it is not the union of two smaller sets that are closed in the Zariski topology. Under this definition, non-irreducible algebraic varieties are called algebraic sets. Other conventions do not require irreducibility.\nThe fundamental theorem of algebra establishes a link between algebra and geometry by showing that a monic polynomial (an algebraic object) in one variable with complex number coefficients is determined by the set of its roots (a geometric object) in the complex plane. Generalizing this result, Hilbert's Nullstellensatz provides a fundamental correspondence between ideals of polynomial rings and algebraic sets. Using the Nullstellensatz and related results, mathematicians have established a strong correspondence between questions on algebraic sets and questions of ring theory. This correspondence is a defining feature of algebraic geometry.\nMany algebraic varieties are differentiable manifolds, but an algebraic variety may have singular points while a differentiable manifold cannot. Algebraic varieties can be characterized by their dimension. Algebraic varieties of dimension one are called algebraic curves and algebraic varieties of dimension two are called algebraic surfaces.\nIn the context of modern scheme theory, an algebraic variety over a field is an integral (irreducible and reduced) scheme over that field whose structure morphism is separated and of finite type.\n\nOverview and definitions\nAn affine variety over an algebraically closed field is conceptually the easiest type of variety to define, which will be done in this section. Next, one can define projective and quasi-projective varieties in a similar way. The most general definition of a variety is obtained by patching together smaller quasi-projective varieties. It is not obvious that one can construct genuinely new examples of varieties in this way, but Nagata gave an example of such a new variety in the 1950s.\n\nAffine varieties\nFor an algebraically closed field K and a natural number n, let An be an affine n-space over K, identified to \n  \n    \n      \n        \n          K\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle K^{n}}\n  \n through the choice of an affine coordinate system. The polynomials  f  in the ring K[x1, ..., xn] can be viewed as K-valued functions on An by evaluating  f  at the points in An, i.e. by choosing values in K for each xi. For each set S of polynomials in K[x1, ..., xn], define the zero-locus Z(S) to be the set of points in An on which the functions in S simultaneously vanish, that is to say\n\n  \n    \n      \n        Z\n        (\n        S\n        )\n        =\n        \n          {\n          \n            x\n            ∈\n            \n              \n                A\n              \n              \n                n\n              \n            \n            ∣\n            f\n            (\n            x\n            )\n            =\n            0\n            \n               for all \n            \n            f\n            ∈\n            S\n          \n          }\n        \n        .\n      \n    \n    {\\displaystyle Z(S)=\\left\\{x\\in \\mathbf {A} ^{n}\\mid f(x)=0{\\text{ for all }}f\\in S\\right\\}.}\n  \n\nA subset V of An is called an affine algebraic set if V = Z(S) for some S. A nonempty affine algebraic set V is called irreducible if it cannot be written as the union of two proper algebraic subsets. An irreducible affine algebraic set is also called an affine variety. (Some authors use the phrase affine variety to refer to any affine algebraic set, irreducible or not.)\nAffine varieties can be given a natural topology by declaring the closed sets to be precisely the affine algebraic sets. This topology is called the Zariski topology.\nGiven a subset V of An, we define I(V) to be the ideal of all polynomial functions vanishing on V:\n\n  \n    \n      \n        I\n        (\n        V\n        )\n        =\n        \n          {\n          \n            f\n            ∈\n            K\n            [\n            \n              x\n              \n                1\n              \n            \n            ,\n            …\n            ,\n            \n              x\n              \n                n\n              \n            \n            ]\n            ∣\n            f\n            (\n            x\n            )\n            =\n            0\n            \n               for all \n            \n            x\n            ∈\n            V\n          \n          }\n        \n        .\n      \n  ",
    "links": [
      "Abelian group",
      "Abelian variety",
      "Absolutely irreducible",
      "Abstract algebra",
      "Addition",
      "Affine coordinate system",
      "Affine space",
      "Affine variety",
      "Alexander Grothendieck",
      "Algebra",
      "Algebraic Geometry (book)",
      "Algebraic curve",
      "Algebraic expression",
      "Algebraic geometry",
      "Algebraic geometry of projective spaces",
      "Algebraic manifold",
      "Algebraic number theory",
      "Algebraic space",
      "Algebraic stack",
      "Algebraic surface",
      "Algebraic torus",
      "Algebraically closed field",
      "Analytic variety",
      "André Weil",
      "Associated graded ring",
      "Automorphism",
      "Basis (linear algebra)",
      "Birational geometry",
      "Category theory",
      "Characteristic class",
      "Characteristic variety",
      "Chern class",
      "CiteSeerX (identifier)",
      "Claude Chevalley",
      "Closed immersion",
      "Closed set",
      "Commensurability (group theory)",
      "Commutative algebra",
      "Compactification (algebraic geometry)",
      "Complete variety",
      "Complex number",
      "Complex plane",
      "Composition algebra",
      "Constructible set (topology)",
      "Coordinate vector",
      "D-module",
      "David Cox (mathematician)",
      "David Eisenbud",
      "David Mumford",
      "Determinant"
    ],
    "categories": [
      "Category:Algebraic geometry",
      "Category:Algebraic varieties",
      "Category:All articles lacking in-text citations",
      "Category:Articles lacking in-text citations from March 2013",
      "Category:Articles with short description",
      "Category:Pages that use a deprecated format of the math tags",
      "Category:Short description matches Wikidata",
      "Category:Wikipedia articles incorporating text from PlanetMath"
    ]
  },
  "Arithmetic geometry": {
    "title": "Arithmetic geometry",
    "url": "https://en.wikipedia.org/wiki/Arithmetic_geometry",
    "summary": "In mathematics, arithmetic geometry is roughly the application of techniques from algebraic geometry to problems in number theory. Arithmetic geometry is centered around Diophantine geometry, the study of rational points of algebraic varieties.\nIn more abstract terms, arithmetic geometry can be defined as the study of schemes of finite type over the spectrum of the ring of integers.",
    "content": "In mathematics, arithmetic geometry is roughly the application of techniques from algebraic geometry to problems in number theory. Arithmetic geometry is centered around Diophantine geometry, the study of rational points of algebraic varieties.\nIn more abstract terms, arithmetic geometry can be defined as the study of schemes of finite type over the spectrum of the ring of integers.\n\nOverview\nThe classical objects of interest in arithmetic geometry are rational points: sets of solutions of a system of polynomial equations over number fields, finite fields, p-adic fields, or function fields, i.e. fields that are not algebraically closed excluding the real numbers. Rational points can be directly characterized by height functions which measure their arithmetic complexity.\nThe structure of algebraic varieties defined over non-algebraically closed fields has become a central area of interest that arose with the modern abstract development of algebraic geometry. Over finite fields, étale cohomology provides topological invariants associated to algebraic varieties. p-adic Hodge theory gives tools to examine when cohomological properties of varieties over the complex numbers extend to those over p-adic fields.\n\nHistory\n19th century: early arithmetic geometry\nIn the early 19th century, Carl Friedrich Gauss observed that non-zero integer solutions to homogeneous polynomial equations with rational coefficients exist if non-zero rational solutions exist.\nIn the 1850s, Leopold Kronecker formulated the Kronecker–Weber theorem, introduced the theory of divisors, and made numerous other connections between number theory and algebra. He then conjectured his \"liebster Jugendtraum\" (\"dearest dream of youth\"), a generalization that was later put forward by Hilbert in a modified form as his twelfth problem, which outlines a goal to have number theory operate only with rings that are quotients of polynomial rings over the integers.\n\nEarly-to-mid 20th century: algebraic developments and the Weil conjectures\nIn the late 1920s, André Weil demonstrated profound connections between algebraic geometry and number theory with his doctoral work leading to the Mordell–Weil theorem which demonstrates that the set of rational points of an abelian variety is a finitely generated abelian group.\nModern foundations of algebraic geometry were developed based on contemporary commutative algebra, including valuation theory and the theory of ideals by Oscar Zariski and others in the 1930s and 1940s.\nIn 1949, André Weil posed the landmark Weil conjectures about the local zeta-functions of algebraic varieties over finite fields. These conjectures offered a framework between algebraic geometry and number theory that propelled Alexander Grothendieck to recast the foundations making use of sheaf theory (together with Jean-Pierre Serre), and later scheme theory, in the 1950s and 1960s. Bernard Dwork proved one of the four Weil conjectures (rationality of the local zeta function) in 1960. Grothendieck developed étale cohomology theory to prove two of the Weil conjectures (together with Michael Artin and Jean-Louis Verdier) by 1965. The last of the Weil conjectures (an analogue of the Riemann hypothesis) would be finally proven in 1974 by Pierre Deligne.\n\nMid-to-late 20th century: developments in modularity, p-adic methods, and beyond\nBetween 1956 and 1957, Yutaka Taniyama and Goro Shimura posed the Taniyama–Shimura conjecture (now known as the modularity theorem) relating elliptic curves to modular forms. This connection would ultimately lead to the first proof of Fermat's Last Theorem in number theory through algebraic geometry techniques of modularity lifting developed by Andrew Wiles in 1995.\nIn the 1960s, Goro Shimura introduced Shimura varieties as generalizations of modular curves. Since the 1979, Shimura varieties have played a crucial role in the Langlands program as a natural realm of examples for testing conjectures.\nIn papers in 1977 and 1978, Barry Mazur proved the torsion conjecture giving a complete list of the possible torsion subgroups of elliptic curves over the rational numbers. Mazur's first proof of this theorem depended upon a complete analysis of the rational points on certain modular curves. In 1996, the proof of the torsion conjecture was extended to all number fields by Loïc Merel.\nIn 1983, Gerd Faltings proved the Mordell conjecture, demonstrating that a curve of genus greater than 1 has only finitely many rational points (where the Mordell–Weil theorem only demonstrates finite generation of the set of rational points as opposed to finiteness).\nIn 2001, the proof of the local Langlands conjectures for GLn was based on the geometry of certain Shimura varieties.\nIn the 2010s, Peter Scholze developed perfectoid spaces and new cohomology theories in arithmetic geometry over p-adic fields with application to Galois representations and certain cases of the weight-monodromy conjecture.\n\nSee also\nAnabelian geometry\nFrobenioid\nArithmetic",
    "links": [
      "0",
      "1",
      "Abelian variety",
      "Abstract algebra",
      "Additive number theory",
      "Affine geometry",
      "Ahmes",
      "Alexander Grothendieck",
      "Algebra",
      "Algebraic function field",
      "Algebraic geometry",
      "Algebraic number",
      "Algebraic number theory",
      "Algebraic topology",
      "Algebraic variety",
      "Algebraically closed",
      "Alhazen",
      "Altitude (triangle)",
      "American Journal of Mathematics",
      "Anabelian geometry",
      "Analytic geometry",
      "Analytic number theory",
      "Andrew Wiles",
      "André Weil",
      "Angle",
      "Apollonius of Perga",
      "Applied mathematics",
      "Arakelov theory",
      "Archimedes",
      "Area",
      "Area of a circle",
      "Arithmetic",
      "Arithmetic combinatorics",
      "Arithmetic dynamics",
      "Arithmetic function",
      "Arithmetic of abelian varieties",
      "Arithmetic topology",
      "Armand Borel",
      "Aryabhata",
      "Barry Mazur",
      "Baudhayana",
      "Before Common Era",
      "Bernard Dwork",
      "Bernhard Riemann",
      "Bibcode (identifier)",
      "Bill Casselman (mathematician)",
      "Birch and Swinnerton-Dyer conjecture",
      "Bjorn Poonen",
      "Blaise Pascal",
      "Brahmagupta"
    ],
    "categories": [
      "Category:Arithmetic geometry",
      "Category:Articles with short description",
      "Category:CS1: long volume value",
      "Category:CS1 French-language sources (fr)",
      "Category:CS1 German-language sources (de)",
      "Category:CS1 Japanese-language sources (ja)",
      "Category:Pages using sidebar with the child parameter",
      "Category:Short description matches Wikidata"
    ]
  },
  "Associative algebra": {
    "title": "Associative algebra",
    "url": "https://en.wikipedia.org/wiki/Associative_algebra",
    "summary": "In mathematics, an associative algebra A over a commutative ring (often a field) K is a ring A together with a ring homomorphism from K into the center of A. This is thus an algebraic structure with an addition,  a multiplication, and a scalar multiplication (the multiplication by the image of the ring homomorphism of an element of K). The addition and multiplication operations together give A the structure of a ring; the addition and scalar multiplication operations together give A the structure of a module or vector space over K. In this article we will also use the term K-algebra to mean an associative algebra over  K. A standard first example of a K-algebra is a ring of square matrices over a commutative ring K, with the usual matrix multiplication.\nA commutative algebra is an associative algebra for which the multiplication is commutative, or, equivalently, an associative algebra that is also a commutative ring.\nIn this article associative algebras are assumed to have a multiplica",
    "content": "In mathematics, an associative algebra A over a commutative ring (often a field) K is a ring A together with a ring homomorphism from K into the center of A. This is thus an algebraic structure with an addition,  a multiplication, and a scalar multiplication (the multiplication by the image of the ring homomorphism of an element of K). The addition and multiplication operations together give A the structure of a ring; the addition and scalar multiplication operations together give A the structure of a module or vector space over K. In this article we will also use the term K-algebra to mean an associative algebra over  K. A standard first example of a K-algebra is a ring of square matrices over a commutative ring K, with the usual matrix multiplication.\nA commutative algebra is an associative algebra for which the multiplication is commutative, or, equivalently, an associative algebra that is also a commutative ring.\nIn this article associative algebras are assumed to have a multiplicative identity, denoted 1; they are sometimes called unital associative algebras for clarification. In some areas of mathematics this assumption is not made, and we will call such structures non-unital associative algebras. We will also assume that all rings are unital, and all ring homomorphisms are unital.\nEvery ring is an associative algebra over its center and over the integers.\n\nDefinition\nLet R be a commutative ring (so R could be a field). An associative R-algebra A (or more simply, an R-algebra A) is a ring A \nthat is also an R-module in such a way that the two additions (the ring addition and the module addition) are the same operation, and scalar multiplication satisfies\n\n  \n    \n      \n        r\n        ⋅\n        (\n        x\n        y\n        )\n        =\n        (\n        r\n        ⋅\n        x\n        )\n        y\n        =\n        x\n        (\n        r\n        ⋅\n        y\n        )\n      \n    \n    {\\displaystyle r\\cdot (xy)=(r\\cdot x)y=x(r\\cdot y)}\n  \n\nfor all r in R and x, y in the algebra. (This definition implies that the algebra, being a ring, is unital, since rings are supposed to have a multiplicative identity.)\nEquivalently, an associative algebra A is a ring together with a ring homomorphism from R to the center of A. If f is such a homomorphism, the scalar multiplication is (r, x) ↦ f(r)x (here the multiplication is the ring multiplication); if the scalar multiplication is given, the ring homomorphism is given by r ↦ r ⋅ 1A. (See also § From ring homomorphisms below).\nEvery ring is an associative Z-algebra, where Z denotes the ring of the integers.\nA commutative algebra is an associative algebra that is also a commutative ring.\n\nAs a monoid object in the category of modules\nThe definition is equivalent to saying that a unital associative R-algebra is a monoid object in R-Mod (the monoidal category of R-modules). By definition, a ring is a monoid object in the category of abelian groups; thus, the notion of an associative algebra is obtained by replacing the category of abelian groups with the category of modules.\nPushing this idea further, some authors have introduced a \"generalized ring\" as a monoid object in some other category that behaves like the category of modules. Indeed, this reinterpretation allows one to avoid making an explicit reference to elements of an algebra A. For example, the associativity can be expressed as follows. By the universal property of a tensor product of modules, the multiplication (the R-bilinear map) corresponds to a unique R-linear map\n\n  \n    \n      \n        m\n        :\n        A\n        \n          ⊗\n          \n            R\n          \n        \n        A\n        →\n        A\n      \n    \n    {\\displaystyle m:A\\otimes _{R}A\\to A}\n  \n.\nThe associativity then refers to the identity:\n\n  \n    \n      \n        m\n        ∘\n        (\n        \n          id\n        \n        ⊗\n        m\n        )\n        =\n        m\n        ∘\n        (\n        m\n        ⊗\n        id\n        )\n        .\n      \n    \n    {\\displaystyle m\\circ ({\\operatorname {id} }\\otimes m)=m\\circ (m\\otimes \\operatorname {id} ).}\n\nFrom ring homomorphisms\nAn associative algebra amounts to a ring homomorphism whose image lies in the center. Indeed, starting with a ring A and a ring homomorphism η : R → A whose image lies in the center of A, we can make A an R-algebra by defining\n\n  \n    \n      \n        r\n        ⋅\n        x\n        =\n        η\n        (\n        r\n        )\n        x\n      \n    \n    {\\displaystyle r\\cdot x=\\eta (r)x}\n  \n\nfor all r ∈ R and x ∈ A. If A is an R-algebra, taking x = 1, the same formula in turn defines a ring homomorphism η : R → A whose image lies in the center.\nIf a ring is commutative then it equals its center, so that a commutative R-algebra can be defined simply as a commutative ring A together with a commutative ring homomorphism η : R → A.\nThe ring homomorphism η appearing in the above is often called a structure map. In the commutative case, one can consider the category whose objects are r",
    "links": [
      "Abelian group",
      "Abstract algebra",
      "Affine scheme",
      "Algebra (disambiguation)",
      "Algebra homomorphism",
      "Algebra of dual numbers",
      "Algebra over a field",
      "Algebra representation",
      "Algebraic closure",
      "Algebraic group",
      "Algebraic number field",
      "Algebraic number theory",
      "Algebraic structure",
      "ArXiv (identifier)",
      "Artinian ring",
      "Artin–Wedderburn theorem",
      "Axiom",
      "Azumaya algebra",
      "Banach algebra",
      "Banach space",
      "Bialgebra",
      "Bibcode (identifier)",
      "Bimodule",
      "Boolean algebra (structure)",
      "Brauer algebra",
      "Categorial duality",
      "Category (mathematics)",
      "Category of abelian groups",
      "Category of commutative rings",
      "Category of modules",
      "Category of rings",
      "Center (ring theory)",
      "Center of a ring",
      "Central simple algebra",
      "Change of rings",
      "Characteristic (algebra)",
      "Clifford algebra",
      "Coalgebra",
      "Combinatorics",
      "Commutative",
      "Commutative algebra",
      "Commutative diagram",
      "Commutative ring",
      "Commutator (ring theory)",
      "Complemented lattice",
      "Complex Lie group",
      "Complex number",
      "Composition algebra",
      "Comultiplication",
      "Continuous function (topology)"
    ],
    "categories": [
      "Category:Algebraic geometry",
      "Category:Algebras",
      "Category:All Wikipedia articles written in American English",
      "Category:All articles to be expanded",
      "Category:All articles with unsourced statements",
      "Category:Articles to be expanded from March 2023",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from October 2023",
      "Category:CS1 errors: ISBN date",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Basis (linear algebra)": {
    "title": "Basis (linear algebra)",
    "url": "https://en.wikipedia.org/wiki/Basis_(linear_algebra)",
    "summary": "In mathematics, a set B of elements of  a vector space V is called a basis (pl.: bases) if every element of V can be written in a unique way as a finite linear combination of elements of B. The coefficients of this linear combination are referred to as components or coordinates of the vector with respect to B. The elements of a basis are called basis vectors.\nEquivalently, a set B is a basis if its elements are linearly independent and every element of V is a linear combination of elements of B. In other words, a basis is a linearly independent spanning set.\nA vector space can have several bases; however all the bases have the same number of elements, called the dimension of the vector space.\nThis article deals mainly with finite-dimensional vector spaces. However, many of the principles are also valid for infinite-dimensional vector spaces.\nBasis vectors find applications in the study of crystal structures and frames of reference.",
    "content": "In mathematics, a set B of elements of  a vector space V is called a basis (pl.: bases) if every element of V can be written in a unique way as a finite linear combination of elements of B. The coefficients of this linear combination are referred to as components or coordinates of the vector with respect to B. The elements of a basis are called basis vectors.\nEquivalently, a set B is a basis if its elements are linearly independent and every element of V is a linear combination of elements of B. In other words, a basis is a linearly independent spanning set.\nA vector space can have several bases; however all the bases have the same number of elements, called the dimension of the vector space.\nThis article deals mainly with finite-dimensional vector spaces. However, many of the principles are also valid for infinite-dimensional vector spaces.\nBasis vectors find applications in the study of crystal structures and frames of reference.\n\nDefinition\nA basis B of a vector space V over a field F (such as the real numbers R or the complex numbers C) is a linearly independent subset of V that spans V. This means that a subset B of V is a basis if it satisfies the two following conditions:\n\nlinear independence\nfor every finite subset \n  \n    \n      \n        {\n        \n          \n            v\n          \n          \n            1\n          \n        \n        ,\n        …\n        ,\n        \n          \n            v\n          \n          \n            m\n          \n        \n        }\n      \n    \n    {\\displaystyle \\{\\mathbf {v} _{1},\\dotsc ,\\mathbf {v} _{m}\\}}\n  \n of B, if \n  \n    \n      \n        \n          c\n          \n            1\n          \n        \n        \n          \n            v\n          \n          \n            1\n          \n        \n        +\n        ⋯\n        +\n        \n          c\n          \n            m\n          \n        \n        \n          \n            v\n          \n          \n            m\n          \n        \n        =\n        \n          0\n        \n      \n    \n    {\\displaystyle c_{1}\\mathbf {v} _{1}+\\cdots +c_{m}\\mathbf {v} _{m}=\\mathbf {0} }\n  \n for some \n  \n    \n      \n        \n          c\n          \n            1\n          \n        \n        ,\n        …\n        ,\n        \n          c\n          \n            m\n          \n        \n      \n    \n    {\\displaystyle c_{1},\\dotsc ,c_{m}}\n  \n in F, then \n  \n    \n      \n        \n          c\n          \n            1\n          \n        \n        =\n        ⋯\n        =\n        \n          c\n          \n            m\n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle c_{1}=\\cdots =c_{m}=0}\n  \n;\nspanning property\nfor every vector v in V, one can choose \n  \n    \n      \n        \n          a\n          \n            1\n          \n        \n        ,\n        …\n        ,\n        \n          a\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle a_{1},\\dotsc ,a_{n}}\n  \n in F and \n  \n    \n      \n        \n          \n            v\n          \n          \n            1\n          \n        \n        ,\n        …\n        ,\n        \n          \n            v\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {v} _{1},\\dotsc ,\\mathbf {v} _{n}}\n  \n in B such that \n  \n    \n      \n        \n          v\n        \n        =\n        \n          a\n          \n            1\n          \n        \n        \n          \n            v\n          \n          \n            1\n          \n        \n        +\n        ⋯\n        +\n        \n          a\n          \n            n\n          \n        \n        \n          \n            v\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {v} =a_{1}\\mathbf {v} _{1}+\\cdots +a_{n}\\mathbf {v} _{n}}\n  \n.\nThe scalars \n  \n    \n      \n        \n          a\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle a_{i}}\n  \n are called the coordinates of the vector v with respect to the basis B, and by the first property they are uniquely determined.\nA vector space that has a finite basis is called finite-dimensional. In this case, the finite subset can be taken as B itself to check for linear independence in the above definition.\nIt is often convenient or even necessary to have an ordering on the basis vectors, for example, when discussing orientation, or when one considers the scalar coefficients of a vector with respect to a basis without referring explicitly to the basis elements. In this case, the ordering is necessary for associating each coefficient to the corresponding basis element. This ordering can be done by numbering the basis elements. In order to emphasize that an order has been chosen, one speaks of an ordered basis, which is therefore not simply an unstructured set, but a sequence, an indexed family, or similar; see § Ordered bases and coordinates below.\n\nExamples\nThe set R2 of the ordered pairs of real numbers is a vector space under the operations of component-wise addition\n\n  \n    \n      \n        (\n        a\n        ,\n        b\n        )",
    "links": [
      "Abelian group",
      "Abstract index notation",
      "Aequationes Mathematicae",
      "Affine connection",
      "Affine frame",
      "Affine space",
      "Albert Einstein",
      "Aleksandr Gorban",
      "Aleph-nought",
      "American Mathematical Society",
      "Angular momentum",
      "Antisymmetric tensor",
      "ArXiv (identifier)",
      "August Ferdinand Möbius",
      "Augustin-Louis Cauchy",
      "Axiom of choice",
      "Baire category theorem",
      "Banach space",
      "Basic Linear Algebra Subprograms",
      "Basis (disambiguation)",
      "Basis of a linear program",
      "Basis of a matroid",
      "Bernard Bolzano",
      "Bernhard Riemann",
      "Bernstein polynomial",
      "Bilinear map",
      "Bivector",
      "Block matrix",
      "Canonical basis",
      "Cardinal number",
      "Cardinality",
      "Carl Friedrich Gauss",
      "Cartan formalism (physics)",
      "Cartesian frame",
      "Cauchy stress tensor",
      "Change of basis",
      "Chebyshev polynomials",
      "CiteSeerX (identifier)",
      "Column vector",
      "Comparison of linear algebra libraries",
      "Complete space",
      "Complex number",
      "Computer vision",
      "Cone (linear algebra)",
      "Connection form",
      "Continuum mechanics",
      "Convex hull",
      "Convex set",
      "Coordinate space",
      "Coordinate system"
    ],
    "categories": [
      "Category:Articles containing proofs",
      "Category:Articles with short description",
      "Category:Axiom of choice",
      "Category:CS1: long volume value",
      "Category:CS1 French-language sources (fr)",
      "Category:CS1 German-language sources (de)",
      "Category:CS1 Italian-language sources (it)",
      "Category:CS1 maint: location missing publisher",
      "Category:Linear algebra",
      "Category:Pages displaying short descriptions of redirect targets via Module:Annotated link"
    ]
  },
  "Algebra (disambiguation)": {
    "title": "Algebra (disambiguation)",
    "url": "https://en.wikipedia.org/wiki/Algebra_(disambiguation)",
    "summary": "The word 'algebra' is used for various branches and structures of mathematics. For their overview, see Algebra. The name comes from the famous 10th century book Al-Jabr by Al-Khwarizmi.",
    "content": "The word 'algebra' is used for various branches and structures of mathematics. For their overview, see Algebra. The name comes from the famous 10th century book Al-Jabr by Al-Khwarizmi.\n\nThe bare word \"algebra\"\nThe bare word \"algebra\" may refer to:\n\nElementary algebra\nAbstract algebra\nAlgebra over a field\nIn universal algebra, algebra has an axiomatic definition, roughly as an instance of any of a number of algebraic structures, such as groups, rings, etc.\n\nBranches of mathematics\nElementary algebra, i.e. \"high-school algebra\"\nAbstract algebra\nLinear algebra\nRelational algebra\nUniversal algebra\nThe term is also traditionally used for the field of:\n\nComputer algebra, dealing with software systems for symbolic mathematical computation, which often offer capabilities beyond what is normally understood to be \"algebra\"\n\nMathematical structures\nVector space with multiplication\nAn \"algebra\", or to be verbose, an algebra over a field, is a vector space equipped with a bilinear vector product. Some notable algebras in this sense are:\n\nIn ring theory and linear algebra:\nAlgebra over a commutative ring, a module equipped with a bilinear product. Generalization of algebras over a field\nAssociative algebra, a module equipped with an associative bilinear vector product\nSuperalgebra, a \n  \n    \n      \n        \n          \n            Z\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {Z} _{2}}\n  \n-graded algebra\nLie algebras, Poisson algebras, and Jordan algebras, important examples of (potentially) nonassociative algebras\nIn functional analysis:\nBanach algebra, an associative algebra A over the real or complex numbers which at the same time is also a Banach space\nOperator algebra, continuous linear operators on a topological vector space with multiplication given by the composition\n*-algebra, An algebra with a notion of adjoints\nC*-algebra, a Banach algebra equipped with a unary involution operation\nVon Neumann algebra (or W*-algebra)\nSee also coalgebra, the dual notion.\n\nOther structures\nA different class of \"algebras\" consists of objects which generalize logical connectives, sets, and lattices.\n\nIn logic:\nRelational algebra, in which a set of finitary relations that is closed under certain operators\nBoolean algebra and Boolean algebra (structure)\nHeyting algebra\nIn measure theory:\nAlgebra over a set, a collection of sets closed under finite unions and complementation\nSigma algebra, a collection of sets closed under countable unions and complementation\n\"Algebra\" can also describe more general structures:\n\nIn category theory and computer science:\nF-algebra and F-coalgebra\nT-algebra\n\nOther uses\nAlgebra Blessett, singer from the U.S, goes by the stage name Algebra\n\nSee also\nAlgebraic (disambiguation)\nList of all articles whose title begins with \"algebra\"",
    "links": [
      "*-algebra",
      "Abstract algebra",
      "Al-Jabr",
      "Algebra",
      "Algebra (singer)",
      "Algebra over a commutative ring",
      "Algebra over a field",
      "Algebra over a set",
      "Algebraic (disambiguation)",
      "Associative algebra",
      "Banach algebra",
      "Boolean algebra",
      "Boolean algebra (structure)",
      "C*-algebra",
      "Category theory",
      "Coalgebra",
      "Computer algebra",
      "Computer science",
      "Elementary algebra",
      "F-algebra",
      "F-coalgebra",
      "Functional analysis",
      "Heyting algebra",
      "Jordan algebra",
      "Lattice (order)",
      "Lie algebra",
      "Linear algebra",
      "Logic",
      "Logical connective",
      "Measure theory",
      "Operator algebra",
      "Poisson algebra",
      "Relational algebra",
      "Ring theory",
      "Set (mathematics)",
      "Sigma algebra",
      "Superalgebra",
      "T-algebra",
      "Universal algebra",
      "Von Neumann algebra",
      "Help:Disambiguation"
    ],
    "categories": [
      "Category:All article disambiguation pages",
      "Category:All disambiguation pages",
      "Category:Mathematics disambiguation pages",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Arabic": {
    "title": "Arabic",
    "url": "https://en.wikipedia.org/wiki/Arabic",
    "summary": "Arabic (endonym: اَلْعَرَبِيَّةُ, romanized: al-ʿarabiyyah, pronounced [al ʕaraˈbijːa] , or عَرَبِيّ, ʿarabīy, pronounced [ˈʕarabiː]  or [ʕaraˈbij]) is a Central Semitic language of the Afroasiatic language family spoken primarily in the Arab world. The International Organization for Standardization (ISO) assigns language codes to 32 varieties of Arabic, including its standard form of Literary Arabic, known as Modern Standard Arabic, which is derived from Classical Arabic. This distinction exists primarily among Western linguists; Arabic speakers themselves generally do not distinguish between Modern Standard Arabic and Classical Arabic, but rather refer to both as al-ʿarabiyyatu l-fuṣḥā (اَلعَرَبِيَّةُ ٱلْفُصْحَىٰ \"the eloquent Arabic\") or simply al-fuṣḥā (اَلْفُصْحَىٰ).\nArabic is the third most widespread official language after English and French, one of six official languages of the United Nations, and the liturgical language of Islam. Arabic is widely taught in schools and univers",
    "content": "Arabic (endonym: اَلْعَرَبِيَّةُ, romanized: al-ʿarabiyyah, pronounced [al ʕaraˈbijːa] , or عَرَبِيّ, ʿarabīy, pronounced [ˈʕarabiː]  or [ʕaraˈbij]) is a Central Semitic language of the Afroasiatic language family spoken primarily in the Arab world. The International Organization for Standardization (ISO) assigns language codes to 32 varieties of Arabic, including its standard form of Literary Arabic, known as Modern Standard Arabic, which is derived from Classical Arabic. This distinction exists primarily among Western linguists; Arabic speakers themselves generally do not distinguish between Modern Standard Arabic and Classical Arabic, but rather refer to both as al-ʿarabiyyatu l-fuṣḥā (اَلعَرَبِيَّةُ ٱلْفُصْحَىٰ \"the eloquent Arabic\") or simply al-fuṣḥā (اَلْفُصْحَىٰ).\nArabic is the third most widespread official language after English and French, one of six official languages of the United Nations, and the liturgical language of Islam. Arabic is widely taught in schools and universities around the world and is used to varying degrees in workplaces, governments and the media. During the Middle Ages, Arabic was a major vehicle of culture and learning, especially in science, mathematics and philosophy. As a result, many European languages have borrowed words from it. Arabic influence, mainly in vocabulary, is seen in European languages (mainly Spanish and to a lesser extent Portuguese, Catalan, and Sicilian) owing to the proximity of Europe and the long-lasting Arabic cultural and linguistic presence, mainly in Southern Iberia, during the Al-Andalus era. Maltese is a Semitic language developed from a dialect of Arabic and written in the Latin alphabet. The Balkan languages, including Albanian, Greek, Serbo-Croatian, and Bulgarian, have also  acquired many words of Arabic origin, mainly through direct contact with Ottoman Turkish.\nArabic has influenced languages across the globe throughout its history, especially languages where Islam is the predominant religion and in countries that were conquered by Muslims. The most markedly influenced languages are Persian, Turkish, Hindustani (Hindi and Urdu), Kashmiri, Kurdish, Bosnian, Kazakh, Bengali, Malay (Indonesian and Malaysian), Maldivian, Pashto, Punjabi, Albanian, Armenian, Azerbaijani, Sicilian, Spanish, Greek, Bulgarian, Tagalog, Sindhi, Odia, Hebrew and African languages such as Hausa, Amharic, Tigrinya, Somali, Tamazight, and Swahili. Conversely, Arabic has borrowed some words (mostly nouns) from other languages, including its sister-language Aramaic, Persian, Greek, and Latin and to a lesser extent and more recently from Turkish, English, French, and Italian.\nArabic is spoken by as many as 380 million speakers, both native and non-native, in the Arab world, making it the fifth most spoken language in the world and the fourth most used language on the internet in terms of users. It also serves as the liturgical language of more than 2 billion Muslims. In 2011, Bloomberg Businessweek ranked Arabic the fourth most useful language for business, after English, Mandarin Chinese, and French. Arabic is written with the Arabic alphabet, an abjad script that is written from right to left.\nClassical Arabic (and Modern Standard Arabic) is considered a conservative language among Semitic languages, it preserved the complete Proto-Semitic three grammatical cases and declension (ʾiʿrāb), and it was used in the reconstruction of Proto-Semitic since it preserves as contrastive 28 out of the evident 29 consonantal phonemes.\n\nClassification\nArabic is usually classified as a Central Semitic language. Linguists still differ as to the best classification of Semitic language sub-groups. The Semitic languages changed between Proto-Semitic and the emergence of Central Semitic languages, particularly in grammar. Innovations of the Central Semitic languages—all maintained in Arabic—include:\n\nThe conversion of the suffix-conjugated stative formation (jalas-) into a past tense.\nThe conversion of the prefix-conjugated preterite-tense formation (yajlis-) into a present tense.\nThe elimination of other prefix-conjugated mood/aspect forms (e.g., a present tense formed by doubling the middle root, a perfect formed by infixing a /t/ after the first root consonant, probably a jussive formed by a stress shift) in favor of new moods formed by endings attached to the prefix-conjugation forms (e.g., -u for indicative, -a for subjunctive, no ending for jussive, -an or -anna for energetic).\nThe development of an internal passive.\nThere are several features which Classical Arabic, the modern Arabic varieties, as well as the Safaitic and Hismaic inscriptions share which are unattested in any other Central Semitic language variety, including the Dadanitic and Taymanitic languages of the northern Hejaz. These features are evidence of common descent from a hypothetical ancestor, Proto-Arabic. The following features of Proto-Arabic can be reconstructed with confidence:\n\nnegative particles m * /mā/; lʾ",
    "links": [
      "107th United States Congress",
      "ALA-LC",
      "A Dictionary of Modern Written Arabic",
      "Abbasid Caliphate",
      "Abjad",
      "Abjad numerals",
      "Abu Hayyan al-Gharnati",
      "Abu al-Aswad al-Du'ali",
      "Abyssinian languages",
      "Academy of the Arabic Language in Cairo",
      "Academy of the Arabic Language in Israel",
      "Academy of the Arabic Language in Khartum",
      "Académie française",
      "Accusative case",
      "Adjective",
      "Afghanistan",
      "African Union",
      "Afroasiatic languages",
      "Ahmed Lutfi el-Sayed",
      "Ajami script",
      "Akkadian language",
      "Al-Ajurrumiyya",
      "Al-Akhfash al-Akbar",
      "Al-Alfiyya of Ibn Malik",
      "Al-Andalus",
      "Al-Hirah",
      "Al-Idah fi Ulum al-Balagha",
      "Al-Jahiz",
      "Al-Khalil ibn Ahmad al-Farahidi",
      "Al-Mu'jam al-Kabir (dictionary)",
      "Al-Mufradat fi Gharib al-Quran",
      "Al-Qāmūs al-Muḥīṭ",
      "Albanian language",
      "Aleph",
      "Aleppo Arabic",
      "Algeria",
      "Algerian Arabic",
      "Algerian Braille",
      "Algerian Saharan Arabic",
      "Allomorph",
      "Amharic",
      "Amharic language",
      "Amiri Press",
      "Ammonite language",
      "Amorite language",
      "Analytic language",
      "Anatolian Arabic",
      "Ancient Greece",
      "Ancient Greek",
      "Ancient North Arabian"
    ],
    "categories": [
      "Category:All Wikipedia articles written in American English",
      "Category:All articles with dead external links",
      "Category:All articles with unsourced statements",
      "Category:Arabic language",
      "Category:Articles containing Arabic-language text",
      "Category:Articles containing Catalan-language text",
      "Category:Articles containing French-language text",
      "Category:Articles containing Spanish-language text",
      "Category:Articles containing video clips",
      "Category:Articles with dead external links from July 2023"
    ]
  },
  "(ε, δ)-definition of limit": {
    "title": "Limit of a function",
    "url": "https://en.wikipedia.org/wiki/Limit_of_a_function",
    "summary": "In mathematics, the limit of a function is a fundamental concept in calculus and analysis concerning the behavior of that function near a particular input which may or may not be in the domain of the function.\nFormal definitions, first devised in the early 19th century, are given below. Informally, a function f assigns an output f(x) to every input x. We say that the function has a limit L at an input p, if f(x) gets closer and closer to L as x moves closer and closer to p. More specifically, the output value can be made arbitrarily close to L if the input to f is taken sufficiently close to p. On the other hand, if some inputs very close to p are taken to outputs that stay a fixed distance apart, then we say the limit does not exist.\nThe notion of a limit has many applications in modern calculus. In particular, the many definitions of continuity employ the concept of limit: roughly, a function is continuous if all of its limits agree with the values of the function. The concept of lim",
    "content": "In mathematics, the limit of a function is a fundamental concept in calculus and analysis concerning the behavior of that function near a particular input which may or may not be in the domain of the function.\nFormal definitions, first devised in the early 19th century, are given below. Informally, a function f assigns an output f(x) to every input x. We say that the function has a limit L at an input p, if f(x) gets closer and closer to L as x moves closer and closer to p. More specifically, the output value can be made arbitrarily close to L if the input to f is taken sufficiently close to p. On the other hand, if some inputs very close to p are taken to outputs that stay a fixed distance apart, then we say the limit does not exist.\nThe notion of a limit has many applications in modern calculus. In particular, the many definitions of continuity employ the concept of limit: roughly, a function is continuous if all of its limits agree with the values of the function. The concept of limit also appears in the definition of the derivative: in the calculus of one variable, this is the limiting value of the slope of secant lines to the graph of a function.\n\nHistory\nAlthough implicit in the development of calculus of the 17th and 18th centuries, the modern idea of the limit of a function goes back to Bernard Bolzano who, in 1817, introduced the basics of the epsilon-delta technique (see (ε, δ)-definition of limit below) to define continuous functions. However, his work was not known during his lifetime. Bruce Pourciau argues that Isaac Newton, in his 1687 Principia, demonstrates a more sophisticated understanding of limits than he is generally given credit for, including being the first to present an epsilon argument.\nIn his 1821 book Cours d'analyse, Augustin-Louis Cauchy discussed variable quantities, infinitesimals and limits, and defined continuity of \n  \n    \n      \n        y\n        =\n        f\n        (\n        x\n        )\n      \n    \n    {\\displaystyle y=f(x)}\n  \n by saying that an infinitesimal change in x necessarily produces an infinitesimal change in y, while Grabiner claims that he used a rigorous epsilon-delta definition in proofs. In 1861, Karl Weierstrass first introduced the epsilon-delta definition of limit in the form it is usually written today. He also introduced the notations \n  \n    \n      \n        lim\n      \n    \n    {\\textstyle \\lim }\n  \n and \n  \n    \n      \n        \n          \n            lim\n            \n              x\n              →\n              \n                x\n                \n                  0\n                \n              \n            \n          \n          \n            .\n          \n        \n      \n    \n    {\\textstyle \\textstyle \\lim _{x\\to x_{0}}\\displaystyle .}\n  \n\nThe modern notation of placing the arrow below the limit symbol is due to G. H. Hardy, which is introduced in his book A Course of Pure Mathematics in 1908.\n\nMotivation\nImagine a person walking on a landscape represented by the graph y = f(x). Their horizontal position is given by x, much like the position given by a map of the land or by a global positioning system. Their altitude is given by the coordinate y. Suppose they walk towards a position x = p, as they get closer and closer to this point, they will notice that their altitude approaches a specific value L.  If asked about the altitude corresponding to x = p, they would reply by saying y = L.\nWhat, then, does it mean to say, their altitude is approaching L? It means that their altitude gets nearer and nearer to L—except for a possible small error in accuracy. For example, suppose we set a particular accuracy goal for our traveler: they must get within ten meters of L. They report back that indeed, they can get within ten vertical meters of L, arguing that as long as they are within fifty horizontal meters of p, their altitude is always within ten meters of L.\nThe accuracy goal is then changed: can they get within one vertical meter? Yes, supposing that they are able to move within five horizontal meters of p, their altitude will always remain within one meter from the target altitude L. Summarizing the aforementioned concept we can say that the traveler's altitude approaches L as their horizontal position approaches p, so as to say that for every target accuracy goal, however small it may be, there is some neighbourhood of p where all (not just some) altitudes correspond to all the horizontal positions, except maybe the horizontal position p itself, in that neighbourhood fulfill that accuracy goal.\nThe initial informal statement can now be explicated:\n\nIn fact, this explicit statement is quite close to the formal definition of the limit of a function, with values in a topological space.\nMore specifically, to say that\n\n  \n    \n      \n        \n          lim\n          \n            x\n            →\n            p\n          \n        \n        f\n        (\n        x\n        )\n        =\n        L\n        ,\n      \n    \n    {\\displaystyle \\lim _{x\\to p}f(x)=L,}\n  \n\n",
    "links": [
      "A Course of Modern Analysis",
      "A Course of Pure Mathematics",
      "Abel's test",
      "Alternating series",
      "Alternating series test",
      "American Mathematical Monthly",
      "Antiderivative",
      "Antiquitates Mathematicae",
      "ArXiv (identifier)",
      "Arithmetico–geometric sequence",
      "Asymptote",
      "Augustin-Louis Cauchy",
      "Axiom of choice",
      "Bernard Bolzano",
      "Big O notation",
      "Binomial series",
      "Calculus",
      "Calculus of variations",
      "Calculus on Euclidean space",
      "Cauchy condensation test",
      "Chain rule",
      "Classification of discontinuities",
      "Continuous function",
      "Contour integration",
      "Convergence tests",
      "Cours d'Analyse",
      "Cours d'analyse",
      "Curl (mathematics)",
      "Degree of a polynomial",
      "Deleted neighborhood",
      "Delta Epsilon (fraternity)",
      "Dependent variable",
      "Derivative",
      "Differential (infinitesimal)",
      "Differential (mathematics)",
      "Differential calculus",
      "Differential of a function",
      "Differentiation rules",
      "Dimension (vector space)",
      "Direct comparison test",
      "Directional derivative",
      "Dirichlet's test",
      "Dirichlet function",
      "Disc integration",
      "Distance",
      "Divergence",
      "Divergence theorem",
      "Doi (identifier)",
      "Domain (mathematical analysis)",
      "E. T. Whittaker"
    ],
    "categories": [
      "Category:Articles containing French-language text",
      "Category:Articles with short description",
      "Category:CS1 German-language sources (de)",
      "Category:Commons category link from Wikidata",
      "Category:Functions and mappings",
      "Category:Limits (mathematics)",
      "Category:Missing redirects",
      "Category:Pages displaying short descriptions of redirect targets via Module:Annotated link",
      "Category:Pages using sidebar with the child parameter",
      "Category:Short description matches Wikidata"
    ]
  },
  "A Biography of Maria Gaetana Agnesi": {
    "title": "A Biography of Maria Gaetana Agnesi",
    "url": "https://en.wikipedia.org/wiki/A_Biography_of_Maria_Gaetana_Agnesi",
    "summary": "A Biography of Maria Gaetana Agnesi, an Eighteenth-Century Woman Mathematician: With Translations of Some of Her Work from Italian into English is a biography of Italian mathematician and philosopher Maria Gaetana Agnesi (1718–1799). It was written and translated by Antonella Cupillari, with a foreword by Patricia R. Allaire, and published in 2008 by the Edwin Mellen Press.",
    "content": "A Biography of Maria Gaetana Agnesi, an Eighteenth-Century Woman Mathematician: With Translations of Some of Her Work from Italian into English is a biography of Italian mathematician and philosopher Maria Gaetana Agnesi (1718–1799). It was written and translated by Antonella Cupillari, with a foreword by Patricia R. Allaire, and published in 2008 by the Edwin Mellen Press.\n\nTopics\nThe main part of the book, over 100 pages, is a translation into English of an Italian-language biography of Agnesi, Elogio storico di Donna Maria Gaetana Agnesi, which was written in the year of her death by historian Antonio Francesco Frisi and republished in 1965. It covers the cultural background that allowed her to become a mathematician, and her brief mathematical career from her teens to her thirties, as well as her work caring for the needy in the remaining fifty years of her life.\nFrisi was a family friend of Agnesi. He was the first to write a biography about her. To balance this material with a more objective view of Agnesi, Cupillari has added over 50 pages of notes, derived from two more Italian-language biographies of Agnesi, Maria Gaetana Àgnesi (Luisa Anzoletti, 1900) and Maria Gaetana Agnesi (Giovanna Tilche, 1984). Another large section includes  translations and explanations of excerpts from Agnesi's mathematical textbook, Institutioni Analitiche (1748), which was \"the first textbook to provide a unified treatment of algebra, Cartesian geometry and calculus\", and by being written in vernacular Italian rather than Latin was aimed at a wider audience than the educated scholars of her day. Cupillari concludes her biography with a bibliography of material about Agnesi.\n\nAudience and reception\nReviewers Luigi Pepe and Franka Bruckler recommend the book as a \"useful introduction\" and \"unique, comprehensive source\" on Agnesi and her work, particularly for people who read English but not Italian. Bruckler includes among its potential readers historians of mathematics, mathematics educators, and members of the public. Reviewer Edith Mendez describes the book as \"an easy read\", and its mathematics as accessible to undergraduate mathematics students, but this is contradicted by Peter Ruane, who found the \"fragmented\" and \"eulogistic\" first part difficult to follow and to stomach. Mendez also criticizes the book for being inadequately copyedited, and Ruane suggests that the book would have been improved by more context of what was happening in mathematics in Europe at the time.\n\n\n== References ==",
    "links": [
      "Antonella Cupillari",
      "Antonio Francesco Frisi",
      "Biography",
      "Edwin Mellen Press",
      "ISBN (identifier)",
      "MR (identifier)",
      "Maria Gaetana Agnesi",
      "MathSciNet",
      "ZbMATH",
      "Zbl (identifier)"
    ],
    "categories": [
      "Category:2007 non-fiction books",
      "Category:Articles with short description",
      "Category:Biographies about philosophers",
      "Category:Biographies and autobiographies of mathematicians",
      "Category:Short description matches Wikidata"
    ]
  },
  "Absolute space and time": {
    "title": "Absolute space and time",
    "url": "https://en.wikipedia.org/wiki/Absolute_space_and_time",
    "summary": "Absolute space and time is a concept in physics and philosophy about the properties of the universe. In physics, absolute space and time may be a preferred frame.",
    "content": "Absolute space and time is a concept in physics and philosophy about the properties of the universe. In physics, absolute space and time may be a preferred frame.\n\nEarly concept\nA version of the concept of absolute space (in the sense of a preferred frame) can be seen in Aristotelian physics. Robert S. Westman writes that a \"whiff\" of absolute space can be observed in Copernicus's De revolutionibus orbium coelestium, where Copernicus uses the concept of an immobile sphere of stars.\n\nNewton\nOriginally introduced by Sir Isaac Newton in Philosophiæ Naturalis Principia Mathematica, the concepts of absolute time and space provided a theoretical foundation that facilitated Newtonian mechanics. According to Newton, absolute time and space respectively are independent aspects of objective reality:\n\nAbsolute, true and mathematical time, of itself, and from its own nature flows equably without regard to anything external, and by another name is called duration: relative, apparent and common time, is some sensible and external (whether accurate or unequable) measure of duration by the means of motion, which is commonly used instead of true time ...\nAccording to Newton, absolute time exists independently of any perceiver and progresses at a consistent pace throughout the universe. Unlike relative time, Newton believed absolute time was imperceptible and could only be understood mathematically. According to Newton, humans are only capable of perceiving relative time, which is a measurement of perceivable objects in motion (like the Moon or Sun). From these movements, we infer the passage of time.\n\nAbsolute space, in its own nature, without regard to anything external, remains always similar and immovable. Relative space is some movable dimension or measure of the absolute spaces; which our senses determine by its position to bodies: and which is vulgarly taken for immovable space ...\nAbsolute motion is the translation of a body from one absolute place into another: and relative motion, the translation from one relative place into another ...\nThese notions imply that absolute space and time do not depend upon physical events, but are a backdrop or stage setting within which physical phenomena occur. Thus, every object has an absolute state of motion relative to absolute space, so that an object must be either in a state of absolute rest, or moving at some absolute speed. To support his views, Newton provided some empirical examples: according to Newton, a solitary rotating sphere can be inferred to rotate about its axis relative to absolute space by observing the bulging of its equator, and a solitary pair of spheres tied by a rope can be inferred to be in absolute rotation about their center of gravity (barycenter) by observing the tension in the rope.\n\nDiffering views\nHistorically, there have been differing views on the concept of absolute space and time. Gottfried Leibniz was of the opinion that space made no sense except as the relative location of bodies, and time made no sense except as the relative movement of bodies. George Berkeley suggested that, lacking any point of reference, a sphere in an otherwise empty universe could not be conceived to rotate, and a pair of spheres could be conceived to rotate relative to one another, but not to rotate about their center of gravity, an example later raised by Albert Einstein in his development of general relativity.\nA more recent form of these objections was made by Ernst Mach. Mach's principle proposes that mechanics is entirely about relative motion of bodies and, in particular, mass is an expression of such relative motion. So, for example, a single particle in a universe with no other bodies would have zero mass. According to Mach, Newton's examples simply illustrate relative rotation of spheres and the bulk of the universe.\n\nWhen, accordingly, we say that a body preserves unchanged its direction and velocity in space, our assertion is nothing more or less than an abbreviated reference to the entire universe.—Ernst Mach\nThese views opposing absolute space and time may be seen from a modern stance as an attempt to introduce operational definitions for space and time, a perspective made explicit in the special theory of relativity.\nEven within the context of Newtonian mechanics, the modern view is that absolute space is unnecessary. Instead, the notion of inertial frame of reference has taken precedence, that is, a preferred set of frames of reference that move uniformly with respect to one another. The laws of physics transform from one inertial frame to another according to Galilean relativity, leading to the following objections to absolute space, as outlined by Milutin Blagojević:\n\nThe existence of absolute space contradicts the internal logic of classical mechanics since, according to Galilean principle of relativity, none of the inertial frames can be singled out.\nAbsolute space does not explain inertial forces since they are related to acceleration with respect ",
    "links": [
      "12-hour clock",
      "24-hour analogue dial",
      "24-hour clock",
      "A series and B series",
      "Abraham de Moivre",
      "Absolute rotation",
      "Absolute theory",
      "Acceleration",
      "Afterlife",
      "Age (geology)",
      "Ages of Man",
      "Albert Einstein",
      "An Historical Account of Two Notable Corruptions of Scripture",
      "Andrew Motte",
      "Apeiron",
      "ArXiv (identifier)",
      "Archaeology",
      "Aristotelian physics",
      "Arithmetica Universalis",
      "Arrow of time",
      "Astrarium",
      "Astronomers Monument",
      "Astronomical chronology",
      "Astronomical clock",
      "Atomic clock",
      "B-theory of time",
      "Barycentric coordinates (astronomy)",
      "Benjamin Pulleyn",
      "Bibcode (identifier)",
      "Big History",
      "Bucket argument",
      "CRC Press",
      "Calculus",
      "Calendar",
      "Calendar era",
      "Catherine Barton",
      "Celestial sphere",
      "Chemical clock",
      "Chinese calendar",
      "Chronemics",
      "Chronobiology",
      "Chronocentrism",
      "Chronological dating",
      "Chronology",
      "Chronometry",
      "Chronon",
      "Chronozone",
      "Circadian rhythm",
      "CiteSeerX (identifier)",
      "Classical mechanics"
    ],
    "categories": [
      "Category:Aristotelianism",
      "Category:Articles with short description",
      "Category:Classical mechanics",
      "Category:Commons category link from Wikidata",
      "Category:Concepts in metaphysics",
      "Category:Philosophy of time",
      "Category:Physical cosmology",
      "Category:Short description matches Wikidata",
      "Category:Space and time",
      "Category:Theory of relativity"
    ]
  },
  "Alternating series": {
    "title": "Alternating series",
    "url": "https://en.wikipedia.org/wiki/Alternating_series",
    "summary": "In mathematics, an alternating series is an infinite series of terms that alternate between positive and negative signs. In capital-sigma notation this is expressed\n\n  \n    \n      \n        \n          ∑\n          \n            n\n            =\n            0\n          \n          \n            ∞\n          \n        \n        (\n        −\n        1\n        \n          )\n          \n            n\n          \n        \n        \n          a\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\sum _{n=0}^{\\infty }(-1)^{n}a_{n}}\n  \n or \n  \n    \n      \n        \n          ∑\n          \n            n\n            =\n            0\n          \n          \n            ∞\n          \n        \n        (\n        −\n        1\n        \n          )\n          \n            n\n            +\n            1\n          \n        \n        \n          a\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\sum _{n=0}^{\\infty }(-1)^{n+1}a_{n}}\n  \n\nwith an > 0 for all n.\nLike any series, an a",
    "content": "In mathematics, an alternating series is an infinite series of terms that alternate between positive and negative signs. In capital-sigma notation this is expressed\n\n  \n    \n      \n        \n          ∑\n          \n            n\n            =\n            0\n          \n          \n            ∞\n          \n        \n        (\n        −\n        1\n        \n          )\n          \n            n\n          \n        \n        \n          a\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\sum _{n=0}^{\\infty }(-1)^{n}a_{n}}\n  \n or \n  \n    \n      \n        \n          ∑\n          \n            n\n            =\n            0\n          \n          \n            ∞\n          \n        \n        (\n        −\n        1\n        \n          )\n          \n            n\n            +\n            1\n          \n        \n        \n          a\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\sum _{n=0}^{\\infty }(-1)^{n+1}a_{n}}\n  \n\nwith an > 0 for all n.\nLike any series, an alternating series is a convergent series if and only if the sequence of partial sums of the series converges to a limit. The alternating series test guarantees that an alternating series is convergent if the terms an converge to 0 monotonically, but this condition is not necessary for convergence.\n\nExamples\nThe geometric series ⁠1/2⁠ − ⁠1/4⁠ + ⁠1/8⁠ − ⁠1/16⁠ + ⋯ sums to ⁠1/3⁠.\nThe alternating harmonic series has a finite sum but the harmonic series does not. The series\n\n  \n    \n      \n        1\n        −\n        \n          \n            1\n            3\n          \n        \n        +\n        \n          \n            1\n            5\n          \n        \n        −\n        …\n        =\n        \n          ∑\n          \n            n\n            =\n            0\n          \n          \n            ∞\n          \n        \n        \n          \n            \n              (\n              −\n              1\n              \n                )\n                \n                  n\n                \n              \n            \n            \n              2\n              n\n              +\n              1\n            \n          \n        \n      \n    \n    {\\displaystyle 1-{\\frac {1}{3}}+{\\frac {1}{5}}-\\ldots =\\sum _{n=0}^{\\infty }{\\frac {(-1)^{n}}{2n+1}}}\n  \n\nconverges to \n  \n    \n      \n        \n          \n            π\n            4\n          \n        \n      \n    \n    {\\displaystyle {\\frac {\\pi }{4}}}\n  \n, but is not absolutely convergent.\nThe Mercator series provides an analytic power series expression of the natural logarithm, given by\n\n  \n    \n      \n        \n          ∑\n          \n            n\n            =\n            1\n          \n          \n            ∞\n          \n        \n        \n          \n            \n              (\n              −\n              1\n              \n                )\n                \n                  n\n                  +\n                  1\n                \n              \n            \n            n\n          \n        \n        \n          x\n          \n            n\n          \n        \n        =\n        ln\n        ⁡\n        (\n        1\n        +\n        x\n        )\n        ,\n        \n        \n        \n        \n          |\n        \n        x\n        \n          |\n        \n        ≤\n        1\n        ,\n        x\n        ≠\n        −\n        1.\n      \n    \n    {\\displaystyle \\sum _{n=1}^{\\infty }{\\frac {(-1)^{n+1}}{n}}x^{n}=\\ln(1+x),\\;\\;\\;|x|\\leq 1,x\\neq -1.}\n  \n\nThe functions sine and cosine used in trigonometry and introduced in elementary algebra as the ratio of sides of a right triangle can also be defined as alternating series in calculus.\n\n  \n    \n      \n        sin\n        ⁡\n        x\n        =\n        \n          ∑\n          \n            n\n            =\n            0\n          \n          \n            ∞\n          \n        \n        (\n        −\n        1\n        \n          )\n          \n            n\n          \n        \n        \n          \n            \n              x\n              \n                2\n                n\n                +\n                1\n              \n            \n            \n              (\n              2\n              n\n              +\n              1\n              )\n              !\n            \n          \n        \n      \n    \n    {\\displaystyle \\sin x=\\sum _{n=0}^{\\infty }(-1)^{n}{\\frac {x^{2n+1}}{(2n+1)!}}}\n  \n and\n\n  \n    \n      \n        cos\n        ⁡\n        x\n        =\n        \n          ∑\n          \n            n\n            =\n            0\n          \n          \n            ∞\n          \n        \n        (\n        −\n        1\n        \n          )\n          \n            n\n          \n        \n        \n          \n            \n              x\n              \n                2\n                n\n              \n            \n            \n              (\n              2\n              n\n              )\n              !\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\cos x=\\sum _{n=0}^{\\infty }(-1)^{n}{\\frac {x^{2n}}{(2n)!}}.}\n  \n\nWhen the alternating factor (–1)n is removed from these series one o",
    "links": [
      "1/2 + 1/4 + 1/8 + 1/16 + ⋯",
      "1/2 − 1/4 + 1/8 − 1/16 + ⋯",
      "1/4 + 1/16 + 1/64 + 1/256 + ⋯",
      "1 + 1 + 1 + 1 + ⋯",
      "1 + 2 + 3 + 4 + ⋯",
      "1 + 2 + 4 + 8 + ⋯",
      "1 − 1 + 2 − 6 + 24 − 120 + ⋯",
      "1 − 2 + 3 − 4 + ⋯",
      "1 − 2 + 4 − 8 + ⋯",
      "Abel's test",
      "Absolute convergence",
      "Agnew's theorem",
      "Alternating series test",
      "Analytic number theory",
      "Antiderivative",
      "ArXiv (identifier)",
      "Arithmetic progression",
      "Arithmetico–geometric sequence",
      "Bessel function",
      "Binomial series",
      "Calculus",
      "Calculus of variations",
      "Calculus on Euclidean space",
      "Capital-sigma notation",
      "Cauchy condensation test",
      "Cauchy criterion",
      "Cauchy sequence",
      "Chain rule",
      "Complete sequence",
      "Complex number",
      "Conditional convergence",
      "Continuous function",
      "Contour integration",
      "Convergence tests",
      "Convergent series",
      "Cube (algebra)",
      "Curl (mathematics)",
      "Derivative",
      "Differential (infinitesimal)",
      "Differential (mathematics)",
      "Differential calculus",
      "Differential of a function",
      "Differentiation rules",
      "Direct comparison test",
      "Directional derivative",
      "Dirichlet's test",
      "Dirichlet eta function",
      "Dirichlet series",
      "Disc integration",
      "Divergence"
    ],
    "categories": [
      "Category:All articles needing additional references",
      "Category:Articles needing additional references from January 2010",
      "Category:Articles with short description",
      "Category:Pages using sidebar with the child parameter",
      "Category:Real analysis",
      "Category:Series (mathematics)",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Alternating series test": {
    "title": "Alternating series test",
    "url": "https://en.wikipedia.org/wiki/Alternating_series_test",
    "summary": "In mathematical analysis, the alternating series test proves that an alternating series is convergent when its terms decrease monotonically in absolute value and approach zero in the limit. The test was devised by Gottfried Leibniz and is sometimes known as Leibniz's test, Leibniz's rule, or the Leibniz criterion. The test is only sufficient, not necessary, so some convergent alternating series may fail the first part of the test.\nFor a generalization, see Dirichlet's test.",
    "content": "In mathematical analysis, the alternating series test proves that an alternating series is convergent when its terms decrease monotonically in absolute value and approach zero in the limit. The test was devised by Gottfried Leibniz and is sometimes known as Leibniz's test, Leibniz's rule, or the Leibniz criterion. The test is only sufficient, not necessary, so some convergent alternating series may fail the first part of the test.\nFor a generalization, see Dirichlet's test.\n\nHistory\nLeibniz discussed the criterion in his unpublished De quadratura arithmetica of 1676 and shared his result with Jakob Hermann in June 1705 and with Johann Bernoulli in October, 1713. It was only formally published in 1993.\n\nFormal statement\nAlternating series test\nA series of the form\n\n  \n    \n      \n        \n          ∑\n          \n            n\n            =\n            0\n          \n          \n            ∞\n          \n        \n        (\n        −\n        1\n        \n          )\n          \n            n\n          \n        \n        \n          a\n          \n            n\n          \n        \n        =\n        \n          a\n          \n            0\n          \n        \n        −\n        \n          a\n          \n            1\n          \n        \n        +\n        \n          a\n          \n            2\n          \n        \n        −\n        \n          a\n          \n            3\n          \n        \n        +\n        ⋯\n      \n    \n    {\\displaystyle \\sum _{n=0}^{\\infty }(-1)^{n}a_{n}=a_{0}-a_{1}+a_{2}-a_{3}+\\cdots }\n  \n\nwhere either all an are positive or all an are negative, is called an alternating series.\nThe alternating series test guarantees that an alternating series converges if the following two conditions are met:\n\n  \n    \n      \n        \n          |\n        \n        \n          a\n          \n            n\n          \n        \n        \n          |\n        \n      \n    \n    {\\displaystyle |a_{n}|}\n  \n decreases monotonically, i.e., \n  \n    \n      \n        \n          |\n        \n        \n          a\n          \n            n\n            +\n            1\n          \n        \n        \n          |\n        \n        ≤\n        \n          |\n        \n        \n          a\n          \n            n\n          \n        \n        \n          |\n        \n      \n    \n    {\\displaystyle |a_{n+1}|\\leq |a_{n}|}\n  \n, and\n\n  \n    \n      \n        \n          lim\n          \n            n\n            →\n            ∞\n          \n        \n        \n          a\n          \n            n\n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle \\lim _{n\\to \\infty }a_{n}=0}\n  \n .\n\nAlternating series estimation theorem\nMoreover, let L denote the sum of the series, then the partial sum \n  \n    \n      \n        \n          S\n          \n            k\n          \n        \n        =\n        \n          ∑\n          \n            n\n            =\n            0\n          \n          \n            k\n          \n        \n        (\n        −\n        1\n        \n          )\n          \n            n\n          \n        \n        \n          a\n          \n            n\n          \n        \n        \n      \n    \n    {\\textstyle S_{k}=\\sum _{n=0}^{k}(-1)^{n}a_{n}\\!}\n  \n approximates L with error bounded by the next omitted term:\n\n  \n    \n      \n        \n          |\n          \n            \n              S\n              \n                k\n              \n            \n            −\n            L\n          \n          |\n        \n        ≤\n        \n          |\n          \n            \n              S\n              \n                k\n              \n            \n            −\n            \n              S\n              \n                k\n                +\n                1\n              \n            \n          \n          |\n        \n        =\n        \n          a\n          \n            k\n            +\n            1\n          \n        \n        .\n        \n      \n    \n    {\\displaystyle \\left|S_{k}-L\\right\\vert \\leq \\left|S_{k}-S_{k+1}\\right\\vert =a_{k+1}.\\!}\n\nProof\nSuppose we are given a series of the form \n  \n    \n      \n        \n          ∑\n          \n            n\n            =\n            1\n          \n          \n            ∞\n          \n        \n        (\n        −\n        1\n        \n          )\n          \n            n\n            −\n            1\n          \n        \n        \n          a\n          \n            n\n          \n        \n        \n      \n    \n    {\\textstyle \\sum _{n=1}^{\\infty }(-1)^{n-1}a_{n}\\!}\n  \n, where \n  \n    \n      \n        \n          lim\n          \n            n\n            →\n            ∞\n          \n        \n        \n          a\n          \n            n\n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle \\lim _{n\\rightarrow \\infty }a_{n}=0}\n  \n and \n  \n    \n      \n        \n          a\n          \n            n\n          \n        \n        ≥\n        \n          a\n          \n            n\n            +\n            1\n          \n        \n      \n    \n    {\\displaystyle a_{n}\\geq a_{n+1}}\n  \n for all natural numbers n. (The case \n  \n    \n      \n        \n          ∑\n          \n   ",
    "links": [
      "A Course in Modern Analysis",
      "Abel's test",
      "Agnew's theorem",
      "Alternating harmonic series",
      "Alternating series",
      "Antiderivative",
      "ArXiv (identifier)",
      "Arithmetico–geometric sequence",
      "Best of all possible worlds",
      "Binomial series",
      "Calculus",
      "Calculus of variations",
      "Calculus on Euclidean space",
      "Calculus ratiocinator",
      "Cambridge University Press",
      "Cauchy's convergence test",
      "Cauchy condensation test",
      "Cengage",
      "Chain rule",
      "Characteristica universalis",
      "Compossibility",
      "Continuous function",
      "Contour integration",
      "Convergence tests",
      "Convergent series",
      "Curl (mathematics)",
      "De Arte Combinatoria",
      "Derivative",
      "Difference (philosophy)",
      "Differential (infinitesimal)",
      "Differential (mathematics)",
      "Differential calculus",
      "Differential of a function",
      "Differentiation rules",
      "Direct comparison test",
      "Directional derivative",
      "Dirichlet's test",
      "Disc integration",
      "Discourse on Metaphysics",
      "Divergence",
      "Divergence theorem",
      "Doi (identifier)",
      "Dover Publications",
      "Dynamism (metaphysics)",
      "E. T. Whittaker",
      "Eberhard Knobloch",
      "Euler substitution",
      "Exterior derivative",
      "Faà di Bruno's formula",
      "Fractional calculus"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1 German-language sources (de)",
      "Category:CS1 Latin-language sources (la)",
      "Category:Convergence tests",
      "Category:Gottfried Wilhelm Leibniz",
      "Category:Pages using sidebar with the child parameter",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Analytic function": {
    "title": "Analytic function",
    "url": "https://en.wikipedia.org/wiki/Analytic_function",
    "summary": "In mathematics, an analytic function is a function that is locally given by a convergent power series. There exist both real analytic functions and complex analytic functions. Functions of each type are infinitely differentiable, but complex analytic functions exhibit properties that do not generally hold for real analytic functions.\nA function is analytic if and only if for every \n  \n    \n      \n        \n          x\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle x_{0}}\n  \n in its domain, its Taylor series about \n  \n    \n      \n        \n          x\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle x_{0}}\n  \n converges to the function in some neighborhood of \n  \n    \n      \n        \n          x\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle x_{0}}\n  \n. This is stronger than merely being infinitely differentiable at \n  \n    \n      \n        \n          x\n          \n            0\n          \n        \n      \n ",
    "content": "In mathematics, an analytic function is a function that is locally given by a convergent power series. There exist both real analytic functions and complex analytic functions. Functions of each type are infinitely differentiable, but complex analytic functions exhibit properties that do not generally hold for real analytic functions.\nA function is analytic if and only if for every \n  \n    \n      \n        \n          x\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle x_{0}}\n  \n in its domain, its Taylor series about \n  \n    \n      \n        \n          x\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle x_{0}}\n  \n converges to the function in some neighborhood of \n  \n    \n      \n        \n          x\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle x_{0}}\n  \n. This is stronger than merely being infinitely differentiable at \n  \n    \n      \n        \n          x\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle x_{0}}\n  \n, and therefore having a well-defined Taylor series; the Fabius function provides an example of a function that is infinitely differentiable but not analytic.\n\nDefinitions\nFormally, a function \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n is real analytic on an open set \n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n  \n in the real line if for any \n  \n    \n      \n        \n          x\n          \n            0\n          \n        \n        ∈\n        D\n      \n    \n    {\\displaystyle x_{0}\\in D}\n  \n one  can write\n\n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        \n          ∑\n          \n            n\n            =\n            0\n          \n          \n            ∞\n          \n        \n        \n          a\n          \n            n\n          \n        \n        \n          \n            (\n            \n              x\n              −\n              \n                x\n                \n                  0\n                \n              \n            \n            )\n          \n          \n            n\n          \n        \n        =\n        \n          a\n          \n            0\n          \n        \n        +\n        \n          a\n          \n            1\n          \n        \n        (\n        x\n        −\n        \n          x\n          \n            0\n          \n        \n        )\n        +\n        \n          a\n          \n            2\n          \n        \n        (\n        x\n        −\n        \n          x\n          \n            0\n          \n        \n        \n          )\n          \n            2\n          \n        \n        +\n        ⋯\n      \n    \n    {\\displaystyle f(x)=\\sum _{n=0}^{\\infty }a_{n}\\left(x-x_{0}\\right)^{n}=a_{0}+a_{1}(x-x_{0})+a_{2}(x-x_{0})^{2}+\\cdots }\n  \n\nin which the coefficients \n  \n    \n      \n        \n          a\n          \n            0\n          \n        \n        ,\n        \n          a\n          \n            1\n          \n        \n        ,\n        …\n      \n    \n    {\\displaystyle a_{0},a_{1},\\dots }\n  \n are real numbers and the series is convergent to \n  \n    \n      \n        f\n        (\n        x\n        )\n      \n    \n    {\\displaystyle f(x)}\n  \n for \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n in a neighborhood of \n  \n    \n      \n        \n          x\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle x_{0}}\n  \n.\nAlternatively, a real analytic function is an infinitely differentiable function such that the Taylor series at any point \n  \n    \n      \n        \n          x\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle x_{0}}\n  \n in its domain\n\n  \n    \n      \n        T\n        (\n        x\n        )\n        =\n        \n          ∑\n          \n            n\n            =\n            0\n          \n          \n            ∞\n          \n        \n        \n          \n            \n              \n                f\n                \n                  (\n                  n\n                  )\n                \n              \n              (\n              \n                x\n                \n                  0\n                \n              \n              )\n            \n            \n              n\n              !\n            \n          \n        \n        (\n        x\n        −\n        \n          x\n          \n            0\n          \n        \n        \n          )\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle T(x)=\\sum _{n=0}^{\\infty }{\\frac {f^{(n)}(x_{0})}{n!}}(x-x_{0})^{n}}\n  \n\nconverges to \n  \n    \n      \n        f\n        (\n        x\n        )\n      \n    \n    {\\displaystyle f(x)}\n  \n for \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n in a neighborhood of \n  \n    \n      \n        \n          x\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle x_{0}}\n  \n pointwise. The set of all real analytic functions on a given set \n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n  \n is often denoted by \n  \n    \n      \n        \n  ",
    "links": [
      "Absolute value",
      "Accumulation point",
      "Algebraic function",
      "Analytic continuation",
      "Analytic expression",
      "Analytic signal",
      "Analyticity of holomorphic functions",
      "Antiderivative (complex analysis)",
      "Argument principle",
      "Augustin-Louis Cauchy",
      "Ball (mathematics)",
      "Banach space",
      "Bernhard Riemann",
      "Bessel function",
      "Bijection",
      "Binary relation",
      "Boolean-valued function",
      "Boolean function",
      "Bounded function",
      "Carl Friedrich Gauss",
      "Cauchy's integral formula",
      "Cauchy's integral theorem",
      "Cauchy–Riemann equations",
      "Compact set",
      "Complex-valued function",
      "Complex analysis",
      "Complex conjugate",
      "Complex manifold",
      "Complex number",
      "Complex plane",
      "Complex pole",
      "Conformal map",
      "Connected space",
      "Constant function",
      "Continuous function",
      "Convergent series",
      "Degrees of freedom (physics and chemistry)",
      "Derivative",
      "Discrete space",
      "Disk (mathematics)",
      "Doi (identifier)",
      "Domain of a function",
      "Domain of holomorphy",
      "Elementary function",
      "Encyclopedia of Mathematics",
      "Entire function",
      "Eric W. Weisstein",
      "Essential singularity",
      "Euler's formula",
      "European Mathematical Society"
    ],
    "categories": [
      "Category:Analytic functions",
      "Category:Articles with short description",
      "Category:CS1 errors: ISBN date",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Antiderivative": {
    "title": "Antiderivative",
    "url": "https://en.wikipedia.org/wiki/Antiderivative",
    "summary": "In calculus, an antiderivative, inverse derivative, primitive function, primitive integral or indefinite integral of a continuous function f is a differentiable function F whose derivative is equal to the original function f. This can be stated symbolically as F'  = f. The process of solving for antiderivatives is called antidifferentiation (or indefinite integration), and its opposite operation is called differentiation, which is the process of finding a derivative. Antiderivatives are often denoted by capital Roman letters such as F and G.\nAntiderivatives are related to definite integrals through the second fundamental theorem of calculus: the definite integral of a function over a closed interval where the function is Riemann integrable is equal to the difference between the values of an antiderivative evaluated at the endpoints of the interval.\nIn physics, antiderivatives arise in the context of rectilinear motion (e.g., in explaining the relationship between position, velocity and",
    "content": "In calculus, an antiderivative, inverse derivative, primitive function, primitive integral or indefinite integral of a continuous function f is a differentiable function F whose derivative is equal to the original function f. This can be stated symbolically as F'  = f. The process of solving for antiderivatives is called antidifferentiation (or indefinite integration), and its opposite operation is called differentiation, which is the process of finding a derivative. Antiderivatives are often denoted by capital Roman letters such as F and G.\nAntiderivatives are related to definite integrals through the second fundamental theorem of calculus: the definite integral of a function over a closed interval where the function is Riemann integrable is equal to the difference between the values of an antiderivative evaluated at the endpoints of the interval.\nIn physics, antiderivatives arise in the context of rectilinear motion (e.g., in explaining the relationship between position, velocity and acceleration). The discrete equivalent of the notion of antiderivative is antidifference.\n\nExamples\nThe function \n  \n    \n      \n        F\n        (\n        x\n        )\n        =\n        \n          \n            \n              \n                x\n                \n                  3\n                \n              \n              3\n            \n          \n        \n      \n    \n    {\\displaystyle F(x)={\\tfrac {x^{3}}{3}}}\n  \n is an antiderivative of \n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        \n          x\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle f(x)=x^{2}}\n  \n, since the derivative of \n  \n    \n      \n        \n          \n            \n              \n                x\n                \n                  3\n                \n              \n              3\n            \n          \n        \n      \n    \n    {\\displaystyle {\\tfrac {x^{3}}{3}}}\n  \n is \n  \n    \n      \n        \n          x\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle x^{2}}\n  \n. Since the derivative of a constant is zero, \n  \n    \n      \n        \n          x\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle x^{2}}\n  \n will have an infinite number of antiderivatives, such as \n  \n    \n      \n        \n          \n            \n              \n                x\n                \n                  3\n                \n              \n              3\n            \n          \n        \n        ,\n        \n          \n            \n              \n                x\n                \n                  3\n                \n              \n              3\n            \n          \n        \n        +\n        1\n        ,\n        \n          \n            \n              \n                x\n                \n                  3\n                \n              \n              3\n            \n          \n        \n        −\n        2\n      \n    \n    {\\displaystyle {\\tfrac {x^{3}}{3}},{\\tfrac {x^{3}}{3}}+1,{\\tfrac {x^{3}}{3}}-2}\n  \n, etc. Thus, all the antiderivatives of \n  \n    \n      \n        \n          x\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle x^{2}}\n  \n can be obtained by changing the value of C in \n  \n    \n      \n        F\n        (\n        x\n        )\n        =\n        \n          \n            \n              \n                x\n                \n                  3\n                \n              \n              3\n            \n          \n        \n        +\n        C\n      \n    \n    {\\displaystyle F(x)={\\tfrac {x^{3}}{3}}+C}\n  \n, where C is an arbitrary constant known as the constant of integration. The graphs of antiderivatives of a given function are vertical translations of each other, with each graph's vertical location depending upon the value C.\nMore generally, the power function \n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        \n          x\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle f(x)=x^{n}}\n  \n has antiderivative \n  \n    \n      \n        F\n        (\n        x\n        )\n        =\n        \n          \n            \n              \n                x\n                \n                  n\n                  +\n                  1\n                \n              \n              \n                n\n                +\n                1\n              \n            \n          \n        \n        +\n        C\n      \n    \n    {\\displaystyle F(x)={\\tfrac {x^{n+1}}{n+1}}+C}\n  \n if n ≠ −1, and \n  \n    \n      \n        F\n        (\n        x\n        )\n        =\n        ln\n        ⁡\n        \n          |\n        \n        x\n        \n          |\n        \n        +\n        C\n      \n    \n    {\\displaystyle F(x)=\\ln |x|+C}\n  \n if n = −1.\nIn physics, the integration of acceleration yields velocity plus a constant. The constant is the initial velocity term that would be lost upon taking the derivative of velocity, because the derivative of a constant term is zero. This same pattern applies to further integrations and derivatives of motion (pos",
    "links": [
      "(ε, δ)-definition of limit",
      "0 (number)",
      "Abel's test",
      "Acceleration",
      "Acceleration (physics)",
      "Adequality",
      "Alternating series",
      "Alternating series test",
      "Antiderivative (complex analysis)",
      "Antidifference",
      "Arc length",
      "Area",
      "Arithmetico-geometric sequence",
      "Arithmetico–geometric sequence",
      "Bernoulli number",
      "Binomial series",
      "Binomial theorem",
      "Bounded function",
      "Brook Taylor",
      "Brooks/Cole",
      "Calculus",
      "Calculus of variations",
      "Calculus on Euclidean space",
      "Cauchy condensation test",
      "Cauchy formula for repeated integration",
      "Chain rule",
      "Colin Maclaurin",
      "Computer algebra system",
      "Concave function",
      "Constant function",
      "Constant of integration",
      "Continuous function",
      "Contour integral",
      "Contour integration",
      "Convergence tests",
      "Countable",
      "Curl (mathematics)",
      "Curvature",
      "Darboux's theorem (analysis)",
      "Definite integral",
      "Dense set",
      "Derivative",
      "Differentiable function",
      "Differential (infinitesimal)",
      "Differential (mathematics)",
      "Differential Galois theory",
      "Differential calculus",
      "Differential equation",
      "Differential form",
      "Differential geometry of curves"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Integral calculus",
      "Category:Linear operators in calculus",
      "Category:Pages using sidebar with the child parameter",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Arithmetico-geometric sequence": {
    "title": "Arithmetico-geometric sequence",
    "url": "https://en.wikipedia.org/wiki/Arithmetico-geometric_sequence",
    "summary": "In mathematics, an arithmetico-geometric sequence is the result of element-by-element multiplication of the elements of a geometric progression with the corresponding elements of an arithmetic progression. The nth element of an arithmetico-geometric sequence is the product of the nth element of an arithmetic sequence and the nth element of a geometric sequence. An arithmetico-geometric series is a sum of terms that are the elements of an arithmetico-geometric sequence. Arithmetico-geometric sequences and series arise in various applications, such as the computation of expected values in probability theory, especially in Bernoulli processes.\nFor instance, the sequence\n\n  \n    \n      \n        \n          \n            \n              \n                0\n              \n            \n            \n              \n                1\n              \n            \n          \n        \n        ,\n         \n        \n          \n            \n              \n                1\n              \n            \n      ",
    "content": "In mathematics, an arithmetico-geometric sequence is the result of element-by-element multiplication of the elements of a geometric progression with the corresponding elements of an arithmetic progression. The nth element of an arithmetico-geometric sequence is the product of the nth element of an arithmetic sequence and the nth element of a geometric sequence. An arithmetico-geometric series is a sum of terms that are the elements of an arithmetico-geometric sequence. Arithmetico-geometric sequences and series arise in various applications, such as the computation of expected values in probability theory, especially in Bernoulli processes.\nFor instance, the sequence\n\n  \n    \n      \n        \n          \n            \n              \n                0\n              \n            \n            \n              \n                1\n              \n            \n          \n        \n        ,\n         \n        \n          \n            \n              \n                1\n              \n            \n            \n              \n                2\n              \n            \n          \n        \n        ,\n         \n        \n          \n            \n              \n                2\n              \n            \n            \n              \n                4\n              \n            \n          \n        \n        ,\n         \n        \n          \n            \n              \n                3\n              \n            \n            \n              \n                8\n              \n            \n          \n        \n        ,\n         \n        \n          \n            \n              \n                4\n              \n            \n            \n              \n                16\n              \n            \n          \n        \n        ,\n         \n        \n          \n            \n              \n                5\n              \n            \n            \n              \n                32\n              \n            \n          \n        \n        ,\n        ⋯\n      \n    \n    {\\displaystyle {\\frac {\\color {blue}{0}}{\\color {green}{1}}},\\ {\\frac {\\color {blue}{1}}{\\color {green}{2}}},\\ {\\frac {\\color {blue}{2}}{\\color {green}{4}}},\\ {\\frac {\\color {blue}{3}}{\\color {green}{8}}},\\ {\\frac {\\color {blue}{4}}{\\color {green}{16}}},\\ {\\frac {\\color {blue}{5}}{\\color {green}{32}}},\\cdots }\n  \n\nis an arithmetico-geometric sequence. The arithmetic component appears in the numerator (in blue), and the geometric one in the denominator (in green). The series summation of the infinite elements of this sequence has been called Gabriel's staircase and it has a value of 2. In general,\n\n  \n    \n      \n        \n          ∑\n          \n            k\n            =\n            1\n          \n          \n            ∞\n          \n        \n        \n          \n            k\n          \n        \n        \n          \n            \n              r\n              \n                k\n              \n            \n          \n        \n        =\n        \n          \n            r\n            \n              (\n              1\n              −\n              r\n              \n                )\n                \n                  2\n                \n              \n            \n          \n        \n        \n        \n          for \n        \n        −\n        1\n        <\n        r\n        <\n        1.\n      \n    \n    {\\displaystyle \\sum _{k=1}^{\\infty }{\\color {blue}k}{\\color {green}r^{k}}={\\frac {r}{(1-r)^{2}}}\\quad {\\text{for }}-1<r<1.}\n  \n\nThe label of arithmetico-geometric sequence may also be given to different objects combining characteristics of both arithmetic and geometric sequences. For instance, the French notion of arithmetico-geometric sequence refers to sequences that satisfy recurrence relations of the form \n  \n    \n      \n        \n          u\n          \n            n\n            +\n            1\n          \n        \n        =\n        r\n        \n          u\n          \n            n\n          \n        \n        +\n        d\n      \n    \n    {\\displaystyle u_{n+1}=ru_{n}+d}\n  \n, which combine the defining recurrence relations  \n  \n    \n      \n        \n          u\n          \n            n\n            +\n            1\n          \n        \n        =\n        \n          u\n          \n            n\n          \n        \n        +\n        d\n      \n    \n    {\\displaystyle u_{n+1}=u_{n}+d}\n  \n for arithmetic sequences and \n  \n    \n      \n        \n          u\n          \n            n\n            +\n            1\n          \n        \n        =\n        r\n        \n          u\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle u_{n+1}=ru_{n}}\n  \n for geometric sequences. These sequences are therefore solutions to a special class of linear difference equation: inhomogeneous first order linear recurrences with constant coefficients.\n\nElements\nThe elements of an arithmetico-geometric sequence \n  \n    \n      \n        (\n        \n          A\n          \n            n\n          \n        \n        \n          G\n          \n            n\n          \n        \n        \n          )\n          \n            n\n            ≥\n ",
    "links": [
      "(ε, δ)-definition of limit",
      "Abel's test",
      "Adequality",
      "Alternating series",
      "Alternating series test",
      "Antiderivative",
      "Arc length",
      "Arithmetic progression",
      "Arithmetico–geometric sequence",
      "Arithmetic–geometric mean",
      "Bernoulli number",
      "Bernoulli process",
      "Binomial series",
      "Binomial theorem",
      "Brook Taylor",
      "Calculus",
      "Calculus of variations",
      "Calculus on Euclidean space",
      "Cauchy condensation test",
      "Chain rule",
      "Closed-form expression",
      "Coin flipping",
      "Colin Maclaurin",
      "Concave function",
      "Constant of integration",
      "Continuous function",
      "Contour integral",
      "Contour integration",
      "Convergence tests",
      "Curl (mathematics)",
      "Curvature",
      "Derivative",
      "Differential (infinitesimal)",
      "Differential (mathematics)",
      "Differential calculus",
      "Differential equation",
      "Differential form",
      "Differential geometry of curves",
      "Differential geometry of surfaces",
      "Differential of a function",
      "Differential operator",
      "Differentiation rules",
      "Direct comparison test",
      "Directional derivative",
      "Dirichlet's test",
      "Disc integration",
      "Divergence",
      "Divergence theorem",
      "Divergent series",
      "Doi (identifier)"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Geometric series",
      "Category:Integer sequences",
      "Category:Pages using sidebar with the child parameter",
      "Category:Series (mathematics)",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Arithmetico–geometric sequence": {
    "title": "Arithmetico-geometric sequence",
    "url": "https://en.wikipedia.org/wiki/Arithmetico-geometric_sequence",
    "summary": "In mathematics, an arithmetico-geometric sequence is the result of element-by-element multiplication of the elements of a geometric progression with the corresponding elements of an arithmetic progression. The nth element of an arithmetico-geometric sequence is the product of the nth element of an arithmetic sequence and the nth element of a geometric sequence. An arithmetico-geometric series is a sum of terms that are the elements of an arithmetico-geometric sequence. Arithmetico-geometric sequences and series arise in various applications, such as the computation of expected values in probability theory, especially in Bernoulli processes.\nFor instance, the sequence\n\n  \n    \n      \n        \n          \n            \n              \n                0\n              \n            \n            \n              \n                1\n              \n            \n          \n        \n        ,\n         \n        \n          \n            \n              \n                1\n              \n            \n      ",
    "content": "In mathematics, an arithmetico-geometric sequence is the result of element-by-element multiplication of the elements of a geometric progression with the corresponding elements of an arithmetic progression. The nth element of an arithmetico-geometric sequence is the product of the nth element of an arithmetic sequence and the nth element of a geometric sequence. An arithmetico-geometric series is a sum of terms that are the elements of an arithmetico-geometric sequence. Arithmetico-geometric sequences and series arise in various applications, such as the computation of expected values in probability theory, especially in Bernoulli processes.\nFor instance, the sequence\n\n  \n    \n      \n        \n          \n            \n              \n                0\n              \n            \n            \n              \n                1\n              \n            \n          \n        \n        ,\n         \n        \n          \n            \n              \n                1\n              \n            \n            \n              \n                2\n              \n            \n          \n        \n        ,\n         \n        \n          \n            \n              \n                2\n              \n            \n            \n              \n                4\n              \n            \n          \n        \n        ,\n         \n        \n          \n            \n              \n                3\n              \n            \n            \n              \n                8\n              \n            \n          \n        \n        ,\n         \n        \n          \n            \n              \n                4\n              \n            \n            \n              \n                16\n              \n            \n          \n        \n        ,\n         \n        \n          \n            \n              \n                5\n              \n            \n            \n              \n                32\n              \n            \n          \n        \n        ,\n        ⋯\n      \n    \n    {\\displaystyle {\\frac {\\color {blue}{0}}{\\color {green}{1}}},\\ {\\frac {\\color {blue}{1}}{\\color {green}{2}}},\\ {\\frac {\\color {blue}{2}}{\\color {green}{4}}},\\ {\\frac {\\color {blue}{3}}{\\color {green}{8}}},\\ {\\frac {\\color {blue}{4}}{\\color {green}{16}}},\\ {\\frac {\\color {blue}{5}}{\\color {green}{32}}},\\cdots }\n  \n\nis an arithmetico-geometric sequence. The arithmetic component appears in the numerator (in blue), and the geometric one in the denominator (in green). The series summation of the infinite elements of this sequence has been called Gabriel's staircase and it has a value of 2. In general,\n\n  \n    \n      \n        \n          ∑\n          \n            k\n            =\n            1\n          \n          \n            ∞\n          \n        \n        \n          \n            k\n          \n        \n        \n          \n            \n              r\n              \n                k\n              \n            \n          \n        \n        =\n        \n          \n            r\n            \n              (\n              1\n              −\n              r\n              \n                )\n                \n                  2\n                \n              \n            \n          \n        \n        \n        \n          for \n        \n        −\n        1\n        <\n        r\n        <\n        1.\n      \n    \n    {\\displaystyle \\sum _{k=1}^{\\infty }{\\color {blue}k}{\\color {green}r^{k}}={\\frac {r}{(1-r)^{2}}}\\quad {\\text{for }}-1<r<1.}\n  \n\nThe label of arithmetico-geometric sequence may also be given to different objects combining characteristics of both arithmetic and geometric sequences. For instance, the French notion of arithmetico-geometric sequence refers to sequences that satisfy recurrence relations of the form \n  \n    \n      \n        \n          u\n          \n            n\n            +\n            1\n          \n        \n        =\n        r\n        \n          u\n          \n            n\n          \n        \n        +\n        d\n      \n    \n    {\\displaystyle u_{n+1}=ru_{n}+d}\n  \n, which combine the defining recurrence relations  \n  \n    \n      \n        \n          u\n          \n            n\n            +\n            1\n          \n        \n        =\n        \n          u\n          \n            n\n          \n        \n        +\n        d\n      \n    \n    {\\displaystyle u_{n+1}=u_{n}+d}\n  \n for arithmetic sequences and \n  \n    \n      \n        \n          u\n          \n            n\n            +\n            1\n          \n        \n        =\n        r\n        \n          u\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle u_{n+1}=ru_{n}}\n  \n for geometric sequences. These sequences are therefore solutions to a special class of linear difference equation: inhomogeneous first order linear recurrences with constant coefficients.\n\nElements\nThe elements of an arithmetico-geometric sequence \n  \n    \n      \n        (\n        \n          A\n          \n            n\n          \n        \n        \n          G\n          \n            n\n          \n        \n        \n          )\n          \n            n\n            ≥\n ",
    "links": [
      "(ε, δ)-definition of limit",
      "Abel's test",
      "Adequality",
      "Alternating series",
      "Alternating series test",
      "Antiderivative",
      "Arc length",
      "Arithmetic progression",
      "Arithmetico–geometric sequence",
      "Arithmetic–geometric mean",
      "Bernoulli number",
      "Bernoulli process",
      "Binomial series",
      "Binomial theorem",
      "Brook Taylor",
      "Calculus",
      "Calculus of variations",
      "Calculus on Euclidean space",
      "Cauchy condensation test",
      "Chain rule",
      "Closed-form expression",
      "Coin flipping",
      "Colin Maclaurin",
      "Concave function",
      "Constant of integration",
      "Continuous function",
      "Contour integral",
      "Contour integration",
      "Convergence tests",
      "Curl (mathematics)",
      "Curvature",
      "Derivative",
      "Differential (infinitesimal)",
      "Differential (mathematics)",
      "Differential calculus",
      "Differential equation",
      "Differential form",
      "Differential geometry of curves",
      "Differential geometry of surfaces",
      "Differential of a function",
      "Differential operator",
      "Differentiation rules",
      "Direct comparison test",
      "Directional derivative",
      "Dirichlet's test",
      "Disc integration",
      "Divergence",
      "Divergence theorem",
      "Divergent series",
      "Doi (identifier)"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Geometric series",
      "Category:Integer sequences",
      "Category:Pages using sidebar with the child parameter",
      "Category:Series (mathematics)",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Archimedes": {
    "title": "Archimedes",
    "url": "https://en.wikipedia.org/wiki/Archimedes",
    "summary": "Archimedes of Syracuse ( AR-kih-MEE-deez; c. 287 – c. 212 BC) was an Ancient Greek mathematician, physicist, engineer, astronomer, and inventor from the ancient city of Syracuse in Sicily. Although few details of his life are known, based on his surviving work, he is considered one of the leading scientists in classical antiquity, and one of the greatest mathematicians of all time. Archimedes anticipated modern calculus and analysis by applying the concept of the infinitesimals and the method of exhaustion to derive and rigorously prove many geometrical theorems, including the area of a circle, the surface area and volume of a sphere, the area of an ellipse, the area under a parabola, the volume of a segment of a paraboloid of revolution, the volume of a segment of a hyperboloid of revolution, and the area of a spiral.\nArchimedes' other mathematical achievements include deriving an approximation of pi (π), defining and investigating the Archimedean spiral, and devising a system using e",
    "content": "Archimedes of Syracuse ( AR-kih-MEE-deez; c. 287 – c. 212 BC) was an Ancient Greek mathematician, physicist, engineer, astronomer, and inventor from the ancient city of Syracuse in Sicily. Although few details of his life are known, based on his surviving work, he is considered one of the leading scientists in classical antiquity, and one of the greatest mathematicians of all time. Archimedes anticipated modern calculus and analysis by applying the concept of the infinitesimals and the method of exhaustion to derive and rigorously prove many geometrical theorems, including the area of a circle, the surface area and volume of a sphere, the area of an ellipse, the area under a parabola, the volume of a segment of a paraboloid of revolution, the volume of a segment of a hyperboloid of revolution, and the area of a spiral.\nArchimedes' other mathematical achievements include deriving an approximation of pi (π), defining and investigating the Archimedean spiral, and devising a system using exponentiation for expressing very large numbers. He was also one of the first to apply mathematics to physical phenomena, working on statics and hydrostatics. Archimedes' achievements in this area include a proof of the law of the lever, the widespread use of the concept of center of gravity, and the enunciation of the law of buoyancy known as Archimedes' principle. In astronomy, he made measurements of the apparent diameter of the Sun and the size of the universe. He is also said to have built a planetarium device that demonstrated the movements of the known celestial bodies, and may have been a precursor to the Antikythera mechanism. He is also credited with designing innovative machines, such as his screw pump, compound pulleys, and defensive war machines to protect his native Syracuse from invasion.\nArchimedes died during the siege of Syracuse, when he was killed by a Roman soldier despite orders that he should not be harmed. Cicero describes visiting Archimedes' tomb, which was surmounted by a sphere and a cylinder that Archimedes requested be placed there to represent his most valued mathematical discovery.\nUnlike his inventions, Archimedes' mathematical writings were little known in antiquity. Alexandrian mathematicians read and quoted him, but the first comprehensive compilation was not made until c. 530 AD by Isidore of Miletus in Byzantine Constantinople, while Eutocius' commentaries on Archimedes' works in the same century opened them to wider readership for the first time. In the Middle ages, Archimedes' work was translated into Arabic in the 9th century and then into Latin in the 12th century, and were an influential source of ideas for scientists during the Renaissance and in the Scientific Revolution. The discovery in 1906 of works by Archimedes, in the Archimedes Palimpsest, has provided new insights into how he obtained mathematical results.\n\nBiography\nThe details of Archimedes's life are obscure; a biography of Archimedes mentioned by Eutocius was allegedly written by his friend Heraclides Lembus, but this work has been lost, and modern scholarship is doubtful that it was written by Heraclides to begin with. \nBased on a statement by the Byzantine Greek scholar John Tzetzes that Archimedes lived for 75 years before his death in 212 BC, Archimedes is estimated to have been born c. 287 BC in the seaport city of Syracuse, Sicily, at that time a self-governing colony in Magna Graecia. In the Sand-Reckoner, Archimedes gives his father's name as Phidias, an astronomer about whom nothing else is known; Plutarch wrote in his Parallel Lives that Archimedes was related to King Hiero II, the ruler of Syracuse, although Cicero and Silius Italicus suggest he was of humble origin. It is also unknown whether he ever married or had children, or if he ever visited Alexandria, Egypt, during his youth; though his surviving written works, addressed to Dositheus of Pelusium, a student of the Alexandrian astronomer Conon of Samos, and to the head librarian Eratosthenes of Cyrene, suggested that he maintained collegial relations with scholars based there. In the preface to On Spirals addressed to Dositheus, Archimedes says that \"many years have elapsed since Conon's death.\" Conon of Samos lived c. 280–220 BC, suggesting that Archimedes may have been an older man when writing some of his works.\n\nGolden wreath\nAnother story of a problem that Archimedes is credited solving with in service of Hiero II is the \"wreath problem.\" According to Vitruvius, writing about two centuries after Archimedes' death, King Hiero II of Syracuse had commissioned a golden wreath for a temple to the immortal gods, and had supplied pure gold to be used by the goldsmith. However, the king had begun to suspect that the goldsmith had substituted some cheaper silver and kept some of the pure gold for himself, and, unable to make the smith confess, asked Archimedes to investigate. Later, while stepping into a bath, Archimedes allegedly noticed that the level of t",
    "links": [
      "1/4 + 1/16 + 1/64 + 1/256 + · · ·",
      "A. G. Drachmann",
      "A History of Greek Mathematics",
      "Alexandria",
      "Alfred North Whitehead",
      "Almagest",
      "Anaxagoras",
      "Ancient Egyptian mathematics",
      "Ancient Greece",
      "Ancient Greek",
      "Ancient Greek astronomy",
      "Ancient Greek mathematics",
      "Andrews University",
      "Angle bisector theorem",
      "Angle trisection",
      "Angular velocity",
      "Annales de chimie et de physique",
      "Anthemius of Tralles",
      "Antikythera mechanism",
      "Apollonian circles",
      "Apollonian gasket",
      "Apollonius's theorem",
      "Apollonius of Perga",
      "Applied mathematics",
      "Approximations of π",
      "Apuleius",
      "ArXiv (identifier)",
      "Arabic language",
      "Arbelos",
      "Archimedean point",
      "Archimedean property",
      "Archimedean solid",
      "Archimedean spiral",
      "Archimedes' cattle problem",
      "Archimedes' heat ray",
      "Archimedes' principle",
      "Archimedes' screw",
      "Archimedes' use of infinitesimals",
      "Archimedes's cattle problem",
      "Archimedes's principle",
      "Archimedes's screw",
      "Archimedes (crater)",
      "Archimedes (disambiguation)",
      "Archimedes Palimpsest",
      "Archimedes number",
      "Archimedes paradox",
      "Architonnerre",
      "Archytas",
      "Area of a circle",
      "Aristaeus the Elder"
    ],
    "categories": [
      "Category:210s BC deaths",
      "Category:280s BC births",
      "Category:3rd-century BC Greek mathematicians",
      "Category:3rd-century BC Greek writers",
      "Category:3rd-century BC Syracusans",
      "Category:All articles to be expanded",
      "Category:All articles with unsourced statements",
      "Category:Ancient Greek engineers",
      "Category:Ancient Greek geometers",
      "Category:Ancient Greek inventors"
    ]
  },
  "Absolute geometry": {
    "title": "Absolute geometry",
    "url": "https://en.wikipedia.org/wiki/Absolute_geometry",
    "summary": "Absolute geometry is a geometry based on an axiom system for Euclidean geometry without the parallel postulate or any of its alternatives. Traditionally, this has meant using only the first four of Euclid's postulates. The term was introduced by János Bolyai in 1832. It is sometimes referred to as neutral geometry, as it is neutral with respect to the parallel postulate. The first four of Euclid's postulates are now considered insufficient as a basis of Euclidean geometry, so other systems (such as  Hilbert's axioms without the parallel axiom) are used instead.",
    "content": "Absolute geometry is a geometry based on an axiom system for Euclidean geometry without the parallel postulate or any of its alternatives. Traditionally, this has meant using only the first four of Euclid's postulates. The term was introduced by János Bolyai in 1832. It is sometimes referred to as neutral geometry, as it is neutral with respect to the parallel postulate. The first four of Euclid's postulates are now considered insufficient as a basis of Euclidean geometry, so other systems (such as  Hilbert's axioms without the parallel axiom) are used instead.\n\nProperties\nIn Euclid's Elements, the first 28 Propositions and Proposition 31 avoid using the parallel postulate, and therefore are valid in absolute geometry.  One can also prove in absolute geometry the exterior angle theorem (an exterior angle of a triangle is larger than either of the remote angles), as well as the Saccheri–Legendre theorem, which states that the sum of the measures of the angles in a triangle has at most 180°.\nProposition 31 is the construction of a parallel line to a given line through a point not on the given line. As the proof only requires the use of Proposition 27 (the Alternate Interior Angle Theorem), it is a valid construction in absolute geometry. More precisely, given any line l and any point P not on l, there is at least one line through P which is parallel to l. This can be proved using a familiar construction: given a line l and a point P not on l, drop the perpendicular m from P to l, then erect a perpendicular n to m through P.  By the alternate interior angle theorem, l is parallel to n.  (The alternate interior angle theorem states that if lines a and b are cut by a transversal t such that there is a pair of congruent alternate interior angles, then a and b are parallel.)  The foregoing construction, and the alternate interior angle theorem, do not depend on the parallel postulate and are therefore valid in absolute geometry.\nIn absolute geometry, it is also provable that two lines perpendicular to the same line cannot intersect (i.e., must be parallel).\n\nRelation to other geometries\nThe theorems of absolute geometry hold in hyperbolic geometry, which is a non-Euclidean geometry, as well as in Euclidean geometry. Absolute geometry is inconsistent with elliptic geometry or spherical geometry: the notion of ordering or betweenness of points on lines, used to axiomatize absolute geometry, is inconsistent with these other geometries.\nAbsolute geometry is an extension of ordered geometry, and thus, all theorems in ordered geometry hold in absolute geometry. The converse is not true. Absolute geometry assumes the first four of Euclid's Axioms (or their equivalents), to be contrasted with affine geometry, which does not assume Euclid's third and fourth axioms.\n(3: \"To describe a circle with any centre and distance radius.\",\n4: \"That all right angles are equal to one another.\" ) \nOrdered geometry is a common foundation of both absolute and affine geometry.\nThe geometry of special relativity has been developed starting with nine axioms and eleven propositions of absolute geometry. The authors Edwin B. Wilson and Gilbert N. Lewis then proceed beyond absolute geometry when they introduce hyperbolic rotation as the transformation relating two frames of reference.\n\nHilbert planes\nA plane that satisfies Hilbert's Incidence, Betweenness and Congruence axioms is called a Hilbert plane. Hilbert planes are models of absolute geometry.\n\nIncompleteness\nAbsolute geometry is an incomplete axiomatic system, in the sense that one can add extra independent axioms without making the axiom system inconsistent.  One can extend absolute geometry by adding various axioms about parallel lines and get mutually incompatible but internally consistent axiom systems, giving rise to Euclidean or hyperbolic geometry.  Thus every theorem of absolute geometry is a theorem of hyperbolic geometry and Euclidean geometry.  However the converse is not true.\n\nSee also\nAffine geometry\nErlangen program\nFoundations of geometry\nIncidence geometry\nNon-Euclidean geometry\n\nNotes\nReferences\nCoxeter, H. S. M. (1969), Introduction to Geometry (2nd ed.), New York: John Wiley & Sons\nFaber, Richard L. (1983), Foundations of Euclidean and Non-Euclidean Geometry, New York: Marcel Dekker, ISBN 0-8247-1748-1\nFine, Benjamin; Moldenhauer, Anja; Rosenberger, Gerhard; Schürenberg, Annika; Wienke, Leonard (2022), Geometry and Discrete Mathematics: A Selection of Highlights, De Gruyter Textbooks (2nd ed.), Walter de Gruyter, ISBN 9783110740783\nGreenberg, Marvin Jay (2007), Euclidean and Non-Euclidean Geometries: Development and History (4th ed.), New York: W. H. Freeman, ISBN 0-7167-9948-0\nGreenberg, Marvin Jay (2010), \"Old and New Results in the Foundations of Elementary Plane Euclidean and Non-Euclidean Geometries\" (PDF), Mathematical Association of America Monthly, 117: 198–219, archived from the original (PDF) on 2023-03-27, retrieved 2018-11-01\nHartshorne, Robin (2005), Geo",
    "links": [
      "Affine geometry",
      "Ahmes",
      "Algebraic geometry",
      "Alhazen",
      "Altitude (triangle)",
      "American Academy of Arts and Sciences",
      "Analytic geometry",
      "Angle",
      "Apollonius of Perga",
      "Archimedes",
      "Area",
      "Area of a circle",
      "Arithmetic geometry",
      "Aryabhata",
      "Axiom system",
      "Axiomatic system",
      "Baudhayana",
      "Before Common Era",
      "Bernhard Riemann",
      "Blaise Pascal",
      "Brahmagupta",
      "Carl Friedrich Gauss",
      "Christiaan Huygens",
      "Circle",
      "Circumference",
      "Completeness (logic)",
      "Complex geometry",
      "Computational geometry",
      "Congruence (geometry)",
      "Convex geometry",
      "Cube",
      "Cuboid",
      "Curve",
      "Cylinder (geometry)",
      "David Hilbert",
      "Diagonal",
      "Diameter",
      "Differential geometry",
      "Digital geometry",
      "Dimension (geometry)",
      "Diophantine geometry",
      "Discrete differential geometry",
      "Discrete geometry",
      "Dodecahedron",
      "Edwin B. Wilson",
      "Elliptic geometry",
      "Eric W. Weisstein",
      "Erlangen program",
      "Euclid",
      "Euclid's Elements"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Classical geometry",
      "Category:Commons category link from Wikidata",
      "Category:Pages using sidebar with the child parameter",
      "Category:Short description matches Wikidata"
    ]
  },
  "Acylindrically hyperbolic group": {
    "title": "Acylindrically hyperbolic group",
    "url": "https://en.wikipedia.org/wiki/Acylindrically_hyperbolic_group",
    "summary": "In the mathematical subject of geometric group theory, an acylindrically hyperbolic group is a group admitting a non-elementary 'acylindrical' isometric action on some geodesic hyperbolic metric space. This notion generalizes the notions of a hyperbolic group and of a relatively hyperbolic group and includes a significantly wider class of examples, such as mapping class groups and Out(Fn).",
    "content": "In the mathematical subject of geometric group theory, an acylindrically hyperbolic group is a group admitting a non-elementary 'acylindrical' isometric action on some geodesic hyperbolic metric space. This notion generalizes the notions of a hyperbolic group and of a relatively hyperbolic group and includes a significantly wider class of examples, such as mapping class groups and Out(Fn).\n\nFormal definition\nAcylindrical action\nLet G be a group with an isometric action on some geodesic hyperbolic metric space X. This action is called acylindrical if for every \n  \n    \n      \n        R\n        ≥\n        0\n      \n    \n    {\\displaystyle R\\geq 0}\n  \n there exist \n  \n    \n      \n        N\n        >\n        0\n        ,\n        L\n        >\n        0\n      \n    \n    {\\displaystyle N>0,L>0}\n  \n such that for every \n  \n    \n      \n        x\n        ,\n        y\n        ∈\n        X\n      \n    \n    {\\displaystyle x,y\\in X}\n  \n with \n  \n    \n      \n        d\n        (\n        x\n        ,\n        y\n        )\n        ≥\n        L\n      \n    \n    {\\displaystyle d(x,y)\\geq L}\n  \n one has\n\n  \n    \n      \n        #\n        {\n        g\n        ∈\n        G\n        ∣\n        d\n        (\n        x\n        ,\n        g\n        x\n        )\n        ≤\n        R\n        ,\n        d\n        (\n        y\n        ,\n        g\n        y\n        )\n        ≤\n        R\n        }\n        ≤\n        N\n        .\n      \n    \n    {\\displaystyle \\#\\{g\\in G\\mid d(x,gx)\\leq R,d(y,gy)\\leq R\\}\\leq N.}\n  \n\nIf the above property holds for a specific \n  \n    \n      \n        R\n        ≥\n        0\n      \n    \n    {\\displaystyle R\\geq 0}\n  \n, the action of G on X is called R-acylindrical.  The notion of acylindricity provides a suitable substitute for being a proper action in the more general context where non-proper actions are allowed. \nAn acylindrical isometric action of a group G on a geodesic hyperbolic metric space X is non-elementary if G admits two independent hyperbolic isometries of X, that is, two loxodromic elements \n  \n    \n      \n        g\n        ,\n        h\n        ∈\n        G\n      \n    \n    {\\displaystyle g,h\\in G}\n  \n such that their fixed point sets \n  \n    \n      \n        {\n        \n          g\n          \n            +\n          \n        \n        ,\n        \n          g\n          \n            −\n          \n        \n        }\n        ⊆\n        ∂\n        X\n      \n    \n    {\\displaystyle \\{g^{+},g^{-}\\}\\subseteq \\partial X}\n  \n and \n  \n    \n      \n        {\n        \n          h\n          \n            +\n          \n        \n        ,\n        \n          h\n          \n            −\n          \n        \n        }\n        ⊆\n        ∂\n        X\n      \n    \n    {\\displaystyle \\{h^{+},h^{-}\\}\\subseteq \\partial X}\n  \n are disjoint. \nIt is known (Theorem 1.1 in ) that an acylindrical action of a group G on a geodesic hyperbolic metric space X is non-elementary if and only if this action has unbounded orbits in X and the group G is not a finite extension of a cyclic group generated by loxodromic isometry of X.\n\nAcylindrically hyperbolic group\nA group G is called acylindrically hyperbolic if G admits a non-elementary acylindrical isometric action on some geodesic hyperbolic metric space X.\n\nEquivalent characterizations\nIt is known (Theorem 1.2 in ) that for a group G the following conditions are equivalent:\n\nThe group G is acylindrically hyperbolic.\nThere exists a (possibly infinite) generating set S for G, such that the Cayley graph \n  \n    \n      \n        Γ\n        (\n        G\n        ,\n        S\n        )\n      \n    \n    {\\displaystyle \\Gamma (G,S)}\n  \n is hyperbolic, and the natural translation action of G on \n  \n    \n      \n        Γ\n        (\n        G\n        ,\n        S\n        )\n      \n    \n    {\\displaystyle \\Gamma (G,S)}\n  \n is a non-elementary acylindrical action.\nThe group G is not virtually cyclic, and there exists an isometric action of G on a geodesic hyperbolic metric space X such that at least one element of G acts on X with the WPD ('Weakly Properly Discontinuous') property.\nThe group G contains a proper infinite 'hyperbolically embedded' subgroup.\n\nHistory\nProperties\nEvery acylindrically hyperbolic group G is SQ-universal, that is, every countable group embeds as a subgroup in some quotient group of G.\nThe class of acylindrically hyperbolic groups is closed under taking infinite normal subgroups, and, more generally, under taking 's-normal' subgroups. Here a subgroup \n  \n    \n      \n        H\n        ≤\n        G\n      \n    \n    {\\displaystyle H\\leq G}\n  \n is called s-normal in \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n if for every \n  \n    \n      \n        g\n        ∈\n        G\n      \n    \n    {\\displaystyle g\\in G}\n  \n one has \n  \n    \n      \n        \n          |\n        \n        H\n        ∩\n        \n          g\n          \n            −\n            1\n          \n        \n        H\n        g\n        \n          |\n        \n        =\n        ∞\n      \n    \n    {\\displaystyle |H\\cap g^{-1}Hg|=\\infty }\n  \n.\nIf G is an acylindric",
    "links": [
      "Advances in Mathematics",
      "ArXiv (identifier)",
      "Asymptotic cone",
      "Bass–Serre theory",
      "Baumslag–Solitar group",
      "Bounded cohomology",
      "C*-algebra",
      "CAT(0) space",
      "Cayley graph",
      "Conjugacy classes",
      "Denis Osin",
      "Doi (identifier)",
      "Geometric and Functional Analysis",
      "Geometric group theory",
      "Geometry & Topology",
      "Group (mathematics)",
      "Group action (mathematics)",
      "Groups, Geometry, and Dynamics",
      "Hyperbolic group",
      "Hyperbolic metric space",
      "ISBN (identifier)",
      "Journal für die reine und angewandte Mathematik",
      "Journal of the European Mathematical Society",
      "MR (identifier)",
      "Mapping class group",
      "Mathematische Annalen",
      "Mathematische Zeitschrift",
      "Memoirs of the American Mathematical Society",
      "Normal subgroup",
      "Notices of the American Mathematical Society",
      "Out(Fn)",
      "Proper action",
      "Quotient group",
      "Relatively hyperbolic group",
      "S2CID (identifier)",
      "SQ-universal group",
      "Simple random walk",
      "Small cancellation theory",
      "Special linear group",
      "Subgroup",
      "Transactions of the American Mathematical Society",
      "Virtually cyclic group",
      "Word-hyperbolic group"
    ],
    "categories": [
      "Category:Geometric group theory",
      "Category:Geometric topology",
      "Category:Geometry",
      "Category:Group theory"
    ]
  },
  "Algebraic curve": {
    "title": "Algebraic curve",
    "url": "https://en.wikipedia.org/wiki/Algebraic_curve",
    "summary": "In mathematics, an affine algebraic plane curve is the zero set of a polynomial in two variables. A projective algebraic plane curve is the zero set in a projective plane of a homogeneous polynomial in three variables. An affine algebraic plane curve can be completed in a projective algebraic plane curve by homogenizing its defining polynomial. Conversely, a projective algebraic plane curve of homogeneous equation h(x, y, t) = 0 can be restricted to the affine algebraic plane curve of equation h(x, y, 1) = 0. These two operations are each inverse to the other; therefore, the phrase algebraic plane curve is often used without specifying explicitly whether it is the affine or the projective case that is considered.\nIf the defining polynomial of a plane algebraic curve is irreducible, then one has an irreducible plane algebraic curve. Otherwise, the algebraic curve is the union of one or several irreducible curves, called its components, that are defined by the irreducible factors.\nMore g",
    "content": "In mathematics, an affine algebraic plane curve is the zero set of a polynomial in two variables. A projective algebraic plane curve is the zero set in a projective plane of a homogeneous polynomial in three variables. An affine algebraic plane curve can be completed in a projective algebraic plane curve by homogenizing its defining polynomial. Conversely, a projective algebraic plane curve of homogeneous equation h(x, y, t) = 0 can be restricted to the affine algebraic plane curve of equation h(x, y, 1) = 0. These two operations are each inverse to the other; therefore, the phrase algebraic plane curve is often used without specifying explicitly whether it is the affine or the projective case that is considered.\nIf the defining polynomial of a plane algebraic curve is irreducible, then one has an irreducible plane algebraic curve. Otherwise, the algebraic curve is the union of one or several irreducible curves, called its components, that are defined by the irreducible factors.\nMore generally, an algebraic curve is an algebraic variety of dimension one. In some contexts, an algebraic set of dimension one is also called an algebraic curve, but this will not be the case in this article. Equivalently, an algebraic curve is an algebraic variety that is birationally equivalent to an irreducible algebraic plane curve. If the curve is contained in an affine space or a projective space, one can take a projection for such a birational equivalence.\nThese birational equivalences reduce most of the study of algebraic curves to the study of algebraic plane curves. However, some properties are not kept under birational equivalence and must be studied on non-plane curves. This is, in particular, the case for the degree and smoothness. For example, there exist smooth curves of genus 0 and degree greater than two, but any plane projection of such curves has singular points (see Genus–degree formula).\nA non-plane curve is often called a space curve or a skew curve.\n\nIn Euclidean geometry\nAn algebraic curve in the Euclidean plane is the set of the points whose coordinates are the solutions of a bivariate polynomial equation p(x, y) = 0. This equation is often called the implicit equation of the curve, in contrast to the curves that are the graph of a function defining explicitly y as a function of x.\nWith a curve given by such an implicit equation, the first problems are to determine the shape of the curve and to draw it. These problems are not as easy to solve as in the case of the graph of a function, for which y may easily be computed for various values of x. The fact that the defining equation is a polynomial implies that the curve has some structural properties that may help in solving these problems.\nEvery algebraic curve may be uniquely decomposed into a finite number of smooth monotone arcs (also called branches) sometimes connected by some points sometimes called \"remarkable points\", and possibly a finite number of isolated points called acnodes. A smooth monotone arc is the graph of a smooth function which is defined and monotone on an open interval of the x-axis. In each direction, an arc is either unbounded (usually called an infinite arc) or has an endpoint which is either a singular point (this will be defined below) or a point with a tangent parallel to one of the coordinate axes.\nFor example, for the Tschirnhausen cubic, there are two infinite arcs having the origin (0,0) as of endpoint. This point is the only singular point of the curve. There are also two arcs having this singular point as one endpoint and having a second endpoint with a horizontal tangent. Finally, there are two other arcs each having one of these points with horizontal tangent as the first endpoint and having the unique point with vertical tangent as the second endpoint. In contrast, the sinusoid is certainly not an algebraic curve, having an infinite number of monotone arcs.\nTo draw an algebraic curve, it is important to know the remarkable points and their tangents, the infinite branches and their asymptotes (if any) and the way in which the arcs connect them. It is also useful to consider the inflection points as remarkable points. When all this information is drawn on a sheet of paper, the shape of the curve usually appears rather clearly. If not, it suffices to add a few other points and their tangents to get a good description of the curve.\nThe methods for computing the remarkable points and their tangents are described below in the section Remarkable points of a plane curve.\n\nPlane projective curves\nIt is often desirable to consider curves in the projective space. An algebraic curve in the projective plane or plane projective curve is the set of the points in a projective plane whose projective coordinates are zeros of a homogeneous polynomial in three variables P(x, y, z).\nEvery affine algebraic curve of equation p(x, y) = 0 may be completed into the projective curve of equation \n  \n    \n      \n        \n          \n          \n     ",
    "links": [
      "310 helix",
      "AF+BG theorem",
      "Abelian group",
      "Abel–Jacobi map",
      "Acnode",
      "Affine space",
      "Ak singularity",
      "Algebraic conjugate",
      "Algebraic element",
      "Algebraic extension",
      "Algebraic function field",
      "Algebraic geometry and analytic geometry",
      "Algebraic set",
      "Algebraic variety",
      "Algebraically closed field",
      "Alpha helix",
      "Analytic function",
      "Arc (geometry)",
      "Archimedean spiral",
      "Asymptote",
      "Belyi's theorem",
      "Beta helix",
      "Bezout's theorem",
      "Birational equivalence",
      "Birational geometry",
      "Birkhoff–Grothendieck theorem",
      "Bitangent",
      "Blowing up",
      "Boerdijk–Coxeter helix",
      "Bolza surface",
      "Brill–Noether theory",
      "Bring's curve",
      "Bézout's theorem",
      "Cayley–Bacharach theorem",
      "Characteristic (algebra)",
      "Claude Chevalley",
      "Clifford's theorem on special divisors",
      "Coherent sheaf cohomology",
      "Collagen helix",
      "Compact Riemann surface",
      "Compact space",
      "Complete algebraic curve",
      "Complex number",
      "Conic section",
      "Connected space",
      "Coordinates",
      "Coprime integers",
      "Cotes's spiral",
      "Counting points on elliptic curves",
      "Cramer's paradox"
    ],
    "categories": [
      "Category:Algebraic curves",
      "Category:All articles lacking in-text citations",
      "Category:All articles with unsourced statements",
      "Category:Articles lacking in-text citations from August 2023",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from April 2025",
      "Category:CS1 errors: ISBN date",
      "Category:Commons category link from Wikidata",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Algebraic set": {
    "title": "Algebraic variety",
    "url": "https://en.wikipedia.org/wiki/Algebraic_variety",
    "summary": "Algebraic varieties are the central objects of study in algebraic geometry, a sub-field of mathematics. Classically, an algebraic variety is defined as the set of solutions of a system of polynomial equations over the real or complex numbers. Modern definitions generalize this concept in several different ways, while attempting to preserve the geometric intuition behind the original definition. \nConventions regarding the definition of an algebraic variety differ slightly. For example, some definitions require an algebraic variety to be irreducible, which means that it is not the union of two smaller sets that are closed in the Zariski topology. Under this definition, non-irreducible algebraic varieties are called algebraic sets. Other conventions do not require irreducibility.\nThe fundamental theorem of algebra establishes a link between algebra and geometry by showing that a monic polynomial (an algebraic object) in one variable with complex number coefficients is determined by the se",
    "content": "Algebraic varieties are the central objects of study in algebraic geometry, a sub-field of mathematics. Classically, an algebraic variety is defined as the set of solutions of a system of polynomial equations over the real or complex numbers. Modern definitions generalize this concept in several different ways, while attempting to preserve the geometric intuition behind the original definition. \nConventions regarding the definition of an algebraic variety differ slightly. For example, some definitions require an algebraic variety to be irreducible, which means that it is not the union of two smaller sets that are closed in the Zariski topology. Under this definition, non-irreducible algebraic varieties are called algebraic sets. Other conventions do not require irreducibility.\nThe fundamental theorem of algebra establishes a link between algebra and geometry by showing that a monic polynomial (an algebraic object) in one variable with complex number coefficients is determined by the set of its roots (a geometric object) in the complex plane. Generalizing this result, Hilbert's Nullstellensatz provides a fundamental correspondence between ideals of polynomial rings and algebraic sets. Using the Nullstellensatz and related results, mathematicians have established a strong correspondence between questions on algebraic sets and questions of ring theory. This correspondence is a defining feature of algebraic geometry.\nMany algebraic varieties are differentiable manifolds, but an algebraic variety may have singular points while a differentiable manifold cannot. Algebraic varieties can be characterized by their dimension. Algebraic varieties of dimension one are called algebraic curves and algebraic varieties of dimension two are called algebraic surfaces.\nIn the context of modern scheme theory, an algebraic variety over a field is an integral (irreducible and reduced) scheme over that field whose structure morphism is separated and of finite type.\n\nOverview and definitions\nAn affine variety over an algebraically closed field is conceptually the easiest type of variety to define, which will be done in this section. Next, one can define projective and quasi-projective varieties in a similar way. The most general definition of a variety is obtained by patching together smaller quasi-projective varieties. It is not obvious that one can construct genuinely new examples of varieties in this way, but Nagata gave an example of such a new variety in the 1950s.\n\nAffine varieties\nFor an algebraically closed field K and a natural number n, let An be an affine n-space over K, identified to \n  \n    \n      \n        \n          K\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle K^{n}}\n  \n through the choice of an affine coordinate system. The polynomials  f  in the ring K[x1, ..., xn] can be viewed as K-valued functions on An by evaluating  f  at the points in An, i.e. by choosing values in K for each xi. For each set S of polynomials in K[x1, ..., xn], define the zero-locus Z(S) to be the set of points in An on which the functions in S simultaneously vanish, that is to say\n\n  \n    \n      \n        Z\n        (\n        S\n        )\n        =\n        \n          {\n          \n            x\n            ∈\n            \n              \n                A\n              \n              \n                n\n              \n            \n            ∣\n            f\n            (\n            x\n            )\n            =\n            0\n            \n               for all \n            \n            f\n            ∈\n            S\n          \n          }\n        \n        .\n      \n    \n    {\\displaystyle Z(S)=\\left\\{x\\in \\mathbf {A} ^{n}\\mid f(x)=0{\\text{ for all }}f\\in S\\right\\}.}\n  \n\nA subset V of An is called an affine algebraic set if V = Z(S) for some S. A nonempty affine algebraic set V is called irreducible if it cannot be written as the union of two proper algebraic subsets. An irreducible affine algebraic set is also called an affine variety. (Some authors use the phrase affine variety to refer to any affine algebraic set, irreducible or not.)\nAffine varieties can be given a natural topology by declaring the closed sets to be precisely the affine algebraic sets. This topology is called the Zariski topology.\nGiven a subset V of An, we define I(V) to be the ideal of all polynomial functions vanishing on V:\n\n  \n    \n      \n        I\n        (\n        V\n        )\n        =\n        \n          {\n          \n            f\n            ∈\n            K\n            [\n            \n              x\n              \n                1\n              \n            \n            ,\n            …\n            ,\n            \n              x\n              \n                n\n              \n            \n            ]\n            ∣\n            f\n            (\n            x\n            )\n            =\n            0\n            \n               for all \n            \n            x\n            ∈\n            V\n          \n          }\n        \n        .\n      \n  ",
    "links": [
      "Abelian group",
      "Abelian variety",
      "Absolutely irreducible",
      "Abstract algebra",
      "Addition",
      "Affine coordinate system",
      "Affine space",
      "Affine variety",
      "Alexander Grothendieck",
      "Algebra",
      "Algebraic Geometry (book)",
      "Algebraic curve",
      "Algebraic expression",
      "Algebraic geometry",
      "Algebraic geometry of projective spaces",
      "Algebraic manifold",
      "Algebraic number theory",
      "Algebraic space",
      "Algebraic stack",
      "Algebraic surface",
      "Algebraic torus",
      "Algebraically closed field",
      "Analytic variety",
      "André Weil",
      "Associated graded ring",
      "Automorphism",
      "Basis (linear algebra)",
      "Birational geometry",
      "Category theory",
      "Characteristic class",
      "Characteristic variety",
      "Chern class",
      "CiteSeerX (identifier)",
      "Claude Chevalley",
      "Closed immersion",
      "Closed set",
      "Commensurability (group theory)",
      "Commutative algebra",
      "Compactification (algebraic geometry)",
      "Complete variety",
      "Complex number",
      "Complex plane",
      "Composition algebra",
      "Constructible set (topology)",
      "Coordinate vector",
      "D-module",
      "David Cox (mathematician)",
      "David Eisenbud",
      "David Mumford",
      "Determinant"
    ],
    "categories": [
      "Category:Algebraic geometry",
      "Category:Algebraic varieties",
      "Category:All articles lacking in-text citations",
      "Category:Articles lacking in-text citations from March 2013",
      "Category:Articles with short description",
      "Category:Pages that use a deprecated format of the math tags",
      "Category:Short description matches Wikidata",
      "Category:Wikipedia articles incorporating text from PlanetMath"
    ]
  },
  "Algorithms": {
    "title": "Algorithm",
    "url": "https://en.wikipedia.org/wiki/Algorithm",
    "summary": "In mathematics and computer science, an algorithm ( ) is a finite sequence of mathematically rigorous instructions, typically used to solve a class of specific problems or to perform a computation. Algorithms are used as specifications for performing calculations and data processing. More advanced algorithms can use conditionals to divert the code execution through various routes (referred to as automated decision-making) and deduce valid inferences (referred to as automated reasoning).\nIn contrast, a heuristic is an approach to solving problems without well-defined correct or optimal results. For example, although social media recommender systems are commonly called \"algorithms\", they actually rely on heuristics as there is no truly \"correct\" recommendation.\nAs an effective method, an algorithm can be expressed within a finite amount of space and time and in a well-defined formal language for calculating a function. Starting from an initial state and initial input (perhaps empty), the",
    "content": "In mathematics and computer science, an algorithm ( ) is a finite sequence of mathematically rigorous instructions, typically used to solve a class of specific problems or to perform a computation. Algorithms are used as specifications for performing calculations and data processing. More advanced algorithms can use conditionals to divert the code execution through various routes (referred to as automated decision-making) and deduce valid inferences (referred to as automated reasoning).\nIn contrast, a heuristic is an approach to solving problems without well-defined correct or optimal results. For example, although social media recommender systems are commonly called \"algorithms\", they actually rely on heuristics as there is no truly \"correct\" recommendation.\nAs an effective method, an algorithm can be expressed within a finite amount of space and time and in a well-defined formal language for calculating a function. Starting from an initial state and initial input (perhaps empty), the instructions describe a computation that, when executed, proceeds through a finite number of well-defined successive states, eventually producing \"output\" and terminating at a final ending state. The transition from one state to the next is not necessarily deterministic; some algorithms, known as randomized algorithms, incorporate random input.\n\nEtymology\nAround 825 AD, Persian scientist and polymath Muḥammad ibn Mūsā al-Khwārizmī wrote kitāb al-ḥisāb al-hindī (\"Book of Indian computation\") and kitab al-jam' wa'l-tafriq al-ḥisāb al-hindī (\"Addition and subtraction in Indian arithmetic\"). In the early 12th century, Latin translations of these texts involving the Hindu–Arabic numeral system and arithmetic appeared, for example Liber Alghoarismi de practica arismetrice, attributed to John of Seville, and Liber Algorismi de numero Indorum, attributed to Adelard of Bath. Here, alghoarismi or algorismi is the Latinization of Al-Khwarizmi's name; the text starts with the phrase Dixit Algorismi, or \"Thus spoke Al-Khwarizmi\".\nThe word algorism in English came to mean the use of place-value notation in calculations; it occurs in the Ancrene Wisse from circa 1225. By the time Geoffrey Chaucer wrote The Canterbury Tales in the late 14th century, he used a variant of the same word in describing augrym stones, stones used for place-value calculation. In the 15th century, under the influence of the Greek word ἀριθμός (arithmos, \"number\"; cf. \"arithmetic\"), the Latin word was altered to algorithmus. By 1596, this form of the word was used in English, as algorithm, by Thomas Hood.\n\nDefinition\nOne informal definition is \"a set of rules that precisely defines a sequence of operations\", which would include all computer programs (including programs that do not perform numeric calculations), and any prescribed bureaucratic procedure\nor cook-book recipe. In general, a program is an algorithm only if it stops eventually—even though infinite loops may sometimes prove desirable. Boolos, Jeffrey & 1974, 1999 define an algorithm to be an explicit set of instructions for determining an output, that can be followed by a computing machine or a human who could only carry out specific elementary operations on symbols.\nMost algorithms are intended to be implemented as computer programs. However, algorithms are also implemented by other means, such as in a biological neural network (for example, the human brain performing arithmetic or an insect looking for food), in an electrical circuit, or a mechanical device.\n\nHistory\nAncient algorithms\nStep-by-step procedures for solving mathematical problems have been recorded since antiquity. This includes in Babylonian mathematics (around 2500 BC), Egyptian mathematics (around 1550 BC), Indian mathematics (around 800 BC and later), the Ifa Oracle (around 500 BC), Greek mathematics (around 240 BC), Chinese mathematics (around 200 BC and later), and Arabic mathematics (around 800 AD).\nThe earliest evidence of algorithms is found in ancient Mesopotamian mathematics. A Sumerian clay tablet found in Shuruppak near Baghdad and dated to c. 2500 BC describes the earliest division algorithm. During the Hammurabi dynasty c. 1800 – c. 1600 BC, Babylonian clay tablets described algorithms for computing formulas. Algorithms were also used in Babylonian astronomy. Babylonian clay tablets describe and employ algorithmic procedures to compute the time and place of significant astronomical events.\nAlgorithms for arithmetic are also found in ancient Egyptian mathematics, dating back to the Rhind Mathematical Papyrus c. 1550 BC. Algorithms were later used in ancient Hellenistic mathematics. Two examples are the Sieve of Eratosthenes, which was described in the Introduction to Arithmetic by Nicomachus, and the Euclidean algorithm, which was first described in Euclid's Elements (c. 300 BC).Examples of ancient Indian mathematics included the Shulba Sutras, the Kerala School, and the Brāhmasphuṭasiddhānta.\nThe first cryptographic algorithm f",
    "links": [
      "A.A. Markov",
      "A. M. Turing",
      "ALGOL",
      "Abstract machine",
      "Ada Lovelace",
      "Adelard of Bath",
      "Al-Khwarizmi",
      "Al-Kindi",
      "Alan Turing",
      "Alan Turing: The Enigma",
      "Algebra of physical space",
      "Algebraic structure",
      "Algorism",
      "Algorithm (disambiguation)",
      "Algorithm aversion",
      "Algorithm characterizations",
      "Algorithm design",
      "Algorithm engineering",
      "Algorithmic bias",
      "Algorithmic composition",
      "Algorithmic efficiency",
      "Algorithmic entities",
      "Algorithmic paradigm",
      "Algorithmic synthesis",
      "Algorithmic technique",
      "Algorithmic topology",
      "Alonzo Church",
      "Analysis of algorithms",
      "Analytical engine",
      "Analytical mechanics",
      "Ancrene Wisse",
      "Andreas Blass",
      "Andrew Hodges",
      "Applied mathematics",
      "Approximation algorithm",
      "Approximation theory",
      "Arabic mathematics",
      "Arithmetic",
      "Array (data structure)",
      "Arthur Zimek",
      "Asger Aaboe",
      "Assembly code",
      "Assignment (computer science)",
      "Association for Computing Machinery",
      "Associative array",
      "Asymptotically optimal",
      "Automata theory",
      "Automated decision-making",
      "Automated reasoning",
      "Automated theorem proving"
    ],
    "categories": [
      "Category:Algorithms",
      "Category:Articles to be expanded from October 2023",
      "Category:Articles with example pseudocode",
      "Category:Articles with short description",
      "Category:CS1: abbreviated year range",
      "Category:Commons category link from Wikidata",
      "Category:Mathematical logic",
      "Category:Pages including recorded pronunciations",
      "Category:Pages using the Phonos extension",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Amenable group": {
    "title": "Amenable group",
    "url": "https://en.wikipedia.org/wiki/Amenable_group",
    "summary": "In mathematics, an amenable group is a locally compact topological group G carrying a kind of averaging operation on bounded functions that is invariant under translation by group elements. The original definition, in terms of a finitely additive measure (or mean) on subsets of G, was introduced by John von Neumann in 1929 under the German name \"messbar\" (\"measurable\" in English, although nowadays German mathematicians use the term \"Mittelbare Gruppe\") in response to the Banach–Tarski paradox. In 1949 Mahlon M. Day introduced the English translation \"amenable\", apparently as a pun on \"mean\".\nThe critical step in the Banach–Tarski paradox construction is to find inside the rotation group SO(3) a free subgroup on two generators. Amenable groups cannot contain such groups, and do not allow this kind of paradoxical construction.\nAmenability has many equivalent definitions. In the field of analysis, the definition is in terms of linear functionals.  An intuitive way to understand this versi",
    "content": "In mathematics, an amenable group is a locally compact topological group G carrying a kind of averaging operation on bounded functions that is invariant under translation by group elements. The original definition, in terms of a finitely additive measure (or mean) on subsets of G, was introduced by John von Neumann in 1929 under the German name \"messbar\" (\"measurable\" in English, although nowadays German mathematicians use the term \"Mittelbare Gruppe\") in response to the Banach–Tarski paradox. In 1949 Mahlon M. Day introduced the English translation \"amenable\", apparently as a pun on \"mean\".\nThe critical step in the Banach–Tarski paradox construction is to find inside the rotation group SO(3) a free subgroup on two generators. Amenable groups cannot contain such groups, and do not allow this kind of paradoxical construction.\nAmenability has many equivalent definitions. In the field of analysis, the definition is in terms of linear functionals.  An intuitive way to understand this version is that the support of the regular representation is the whole space of irreducible representations.\nIn discrete group theory, where G has the discrete topology, a simpler definition is used.  In this setting, a group is amenable if one can say what proportion of G any given subset takes up. For example, any subgroup of the group of integers \n  \n    \n      \n        (\n        \n          Z\n        \n        ,\n        +\n        )\n      \n    \n    {\\displaystyle (\\mathbb {Z} ,+)}\n  \n is generated by some integer \n  \n    \n      \n        p\n        ≥\n        0\n      \n    \n    {\\displaystyle p\\geq 0}\n  \n. If \n  \n    \n      \n        p\n        =\n        0\n      \n    \n    {\\displaystyle p=0}\n  \n then the subgroup takes up 0 proportion. Otherwise, it takes up \n  \n    \n      \n        1\n        \n          /\n        \n        p\n      \n    \n    {\\displaystyle 1/p}\n  \n of the whole group. Even though both the group and the subgroup has infinitely many elements, there is a well-defined sense of proportion.\nIf a group has a Følner sequence then it is automatically amenable.\n\nDefinition for locally compact groups\nLet G be a locally compact Hausdorff group. Then it is well known that it possesses a unique, up-to-scale left- (or right-) translation invariant nontrivial ring measure, the Haar measure. (This is a Borel regular measure when G is second-countable; the left and right Haar measures coincide when G is compact.) Consider the Banach space L∞(G) of essentially bounded measurable functions within this measure space (which is clearly independent of the scale of the Haar measure).\nDefinition 1. A linear functional Λ in Hom(L∞(G), R) is said to be a mean if Λ has norm 1 and is non-negative, i.e. f ≥ 0 a.e. implies Λ(f) ≥ 0.\nDefinition 2. A mean Λ in Hom(L∞(G), R) is said to be left-invariant (respectively right-invariant) if Λ(g·f) = Λ(f) for all g in G, and f in L∞(G) with respect to the left (respectively right) shift action of g·f(x) = f(g−1x) (respectively f·g(x) =  f(xg−1)).\nDefinition 3. A locally compact Hausdorff group is called amenable if it admits a left- (or right-)invariant mean.\nBy identifying Hom(L∞(G), R) with the space of finitely-additive Borel measures which are absolutely continuous with respect to the Haar measure on G (a ba space), the terminology becomes more natural: a mean in Hom(L∞(G), R) induces a left-invariant, finitely additive Borel measure on G which gives the whole group weight 1.\n\nExample\nAs an example for compact groups, consider the circle group. The graph of a typical function f ≥ 0 looks like a jagged curve above a circle, which can be made by tearing off the end of a paper tube. The linear functional would then average the curve by snipping off some paper from one place and gluing it to another place, creating a flat top again. This is the invariant mean, i.e. the average value \n  \n    \n      \n        Λ\n        (\n        f\n        )\n        =\n        \n          ∫\n          \n            \n              R\n            \n            \n              /\n            \n            \n              Z\n            \n          \n        \n        f\n         \n        d\n        λ\n      \n    \n    {\\displaystyle \\Lambda (f)=\\int _{\\mathbb {R} /\\mathbb {Z} }f\\ d\\lambda }\n  \n where \n  \n    \n      \n        λ\n      \n    \n    {\\displaystyle \\lambda }\n  \n is Lebesgue measure.\nLeft-invariance would mean that rotating the tube does not change the height of the flat top at the end. That is, only the shape of the tube matters. Combined with linearity, positivity, and norm-1, this is sufficient to prove that the invariant mean we have constructed is unique.\nAs an example for locally compact groups, consider the group of integers. A bounded function f is simply a bounded function of type \n  \n    \n      \n        f\n        :\n        \n          Z\n        \n        →\n        \n          R\n        \n      \n    \n    {\\displaystyle f:\\mathbb {Z} \\to \\mathbb {R} }\n  \n, and its mean is the running average \n  \n    \n      \n        \n          lim\n          \n ",
    "links": [
      "Abelian group",
      "Affine transformation",
      "Aleksandr Olshansky",
      "Algebraic geometry",
      "Almost everywhere",
      "Amenable Banach algebra",
      "Annals of Mathematics",
      "ArXiv (identifier)",
      "Axiom of choice",
      "Ba space",
      "Banach space",
      "Banach–Tarski paradox",
      "Benjamin Weiss",
      "Bibcode (identifier)",
      "Borel regular measure",
      "Bounded function",
      "Bulletin of the American Mathematical Society",
      "Burnside group",
      "C*-algebra",
      "CiteSeerX (identifier)",
      "Commentarii Mathematici Helvetici",
      "Compact space",
      "Convex set",
      "Convolution",
      "Counting measure",
      "Direct product of groups",
      "Discrete group",
      "Discrete group theory",
      "Discrete topology",
      "Doi (identifier)",
      "Donald Samuel Ornstein",
      "Elementary amenable group",
      "Eric W. Weisstein",
      "Essentially bounded",
      "FC-group",
      "Finite group",
      "Finitely generated group",
      "Finitely presented group",
      "Free group",
      "Free subgroup",
      "Fundamenta Mathematicae",
      "Fundamental group",
      "Fundamental theorem of finitely generated abelian groups",
      "Følner sequence",
      "German language",
      "Grigorchuk group",
      "Group (mathematics)",
      "Group algebra of a locally compact group",
      "Group extension",
      "Growth rate (group theory)"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1 French-language sources (fr)",
      "Category:Geometric group theory",
      "Category:Short description is different from Wikidata",
      "Category:Topological groups",
      "Category:Wikipedia articles incorporating text from PlanetMath"
    ]
  },
  "Anabelian geometry": {
    "title": "Anabelian geometry",
    "url": "https://en.wikipedia.org/wiki/Anabelian_geometry",
    "summary": "Anabelian geometry is a theory in arithmetic geometry which describes the way in which the algebraic fundamental group of a certain arithmetic variety X, or some related geometric object, can help to recover X. The first results for number fields and their absolute Galois groups were obtained by Jürgen Neukirch, Masatoshi Gündüz Ikeda, Kenkichi Iwasawa, and  Kôji Uchida (Neukirch–Uchida theorem, 1969), prior to conjectures made about hyperbolic curves over number fields by  Alexander Grothendieck. As introduced in Letter to Faltings (1983; see also Esquisse d'un Programme in 1984) the latter were about how topological homomorphisms between two arithmetic fundamental groups of two hyperbolic curves over number fields correspond to maps between the curves. A first version of Grothendieck's anabelian conjecture was solved by Hiroaki Nakamura and Akio Tamagawa (for affine curves), then completed by Shinichi Mochizuki.\nThe theory has since grown in varieties (absolute, mono-anabelian, and c",
    "content": "Anabelian geometry is a theory in arithmetic geometry which describes the way in which the algebraic fundamental group of a certain arithmetic variety X, or some related geometric object, can help to recover X. The first results for number fields and their absolute Galois groups were obtained by Jürgen Neukirch, Masatoshi Gündüz Ikeda, Kenkichi Iwasawa, and  Kôji Uchida (Neukirch–Uchida theorem, 1969), prior to conjectures made about hyperbolic curves over number fields by  Alexander Grothendieck. As introduced in Letter to Faltings (1983; see also Esquisse d'un Programme in 1984) the latter were about how topological homomorphisms between two arithmetic fundamental groups of two hyperbolic curves over number fields correspond to maps between the curves. A first version of Grothendieck's anabelian conjecture was solved by Hiroaki Nakamura and Akio Tamagawa (for affine curves), then completed by Shinichi Mochizuki.\nThe theory has since grown in varieties (absolute, mono-anabelian, and combinatorial versions) and with multiple interactions with number theory, algebraic geometry, and low-dimensional topology.\n\nFormulation of a conjecture of Grothendieck on curves\nThe \"anabelian question\" has been formulated as\n\nHow much information about the isomorphism class of the variety X is contained in the knowledge of the étale fundamental group\nA concrete example is the case of curves, which may be affine as well as projective. Suppose given a hyperbolic curve C, i.e., the complement of n points in a projective algebraic curve of genus g, taken to be smooth and irreducible, defined over a field K that is finitely generated (over its prime field), such that\n\n  \n    \n      \n        2\n        −\n        2\n        g\n        −\n        n\n        <\n        0\n      \n    \n    {\\displaystyle 2-2g-n<0}\n  \n.\nGrothendieck conjectured that the algebraic fundamental group G of C, a profinite group, determines C itself (i.e., the isomorphism class of G determines that of C). This was proved by Mochizuki. An example is for the case of \n  \n    \n      \n        g\n        =\n        0\n      \n    \n    {\\displaystyle g=0}\n  \n (the projective line) and \n  \n    \n      \n        n\n        =\n        4\n      \n    \n    {\\displaystyle n=4}\n  \n, when the isomorphism class of C is determined by the cross-ratio in K of the four points removed (almost, there being an order to the four points in a cross-ratio, but not in the points removed). There are also results for the case of K a local field.\n\nMono-anabelian geometry\nShinichi Mochizuki introduced and developed the mono-anabelian geometry, an approach which restores, for a certain class of hyperbolic curves over number fields or some other fields, the curve from its algebraic fundamental group. Key results of mono-anabelian geometry were published in Mochizuki's \"Topics in Absolute Anabelian Geometry\" I (2012), II (2013), and III (2015).\nThe opposite approach of mono-anabelian geometry is bi-anabelian geometry, a term coined by Mochizuki in \"Topics in Absolute Anabelian Geometry III\" to indicate the classical approach.\nMono-anabelian geometry deals with certain types (strictly Belyi type) of hyperbolic curves over number fields and local fields. This theory considerably extends anabelian geometry. Its main aim to construct algorithms which produce the curve, up to an isomorphism, from the étale fundamental group of such a curve. In particular, for the first time this theory produces a simultaneous functorial restoration of the ground number field and its completion, from the fundamental group of a large class of punctured elliptic curves over number fields. Inter-universal Teichmüller theory of Shinichi Mochizuki is closely connected to and uses various results of mono-anabelian geometry in their absolute form.\n\nCombinatorial anabelian geometry\nShinichi Mochizuki also introduced combinatorial anabelian geometry which deals with issues of hyperbolic curves and other related schemes over algebraically closed fields. The first results were published in Mochizuki's \"A combinatorial version of the Grothendieck conjecture\" (2007) and \"On the combinatorial cuspidalization of hyperbolic curves\" (2010). The field was later applied to hyperbolic curves by Yuichiro Hoshi and Mochizuki in a series of four papers, \"Topics surrounding the combinatorial anabelian geometry of hyperbolic curves\" (2012-2013).\nCombinatorial anabelian geometry concerns the reconstruction of scheme- or ring-theoretic objects from more primitive combinatorial constituent data. The origin of combinatorial anabelian geometry is in some of such combinatorial ideas of the arithmetic of braid groups and their Lie algebras of Makoto Matsumoto et al., then later in Mochizuki's proofs of the Grothendieck conjecture. Some of the results of combinatorial anabelian geometry provide alternative proofs of partial cases of the Grothendieck conjecture without using p-adic Hodge theory. Combinatorial anabelian geometry helps to study various aspects of the ",
    "links": [
      "0",
      "1",
      "Absolute Galois group",
      "Additive number theory",
      "Affine curvature",
      "Alexander Grothendieck",
      "Algebraic curve",
      "Algebraic fundamental group",
      "Algebraic geometry",
      "Algebraic number",
      "Algebraic number theory",
      "Analytic number theory",
      "Annals of Mathematics",
      "ArXiv (identifier)",
      "Arakelov theory",
      "Arithmetic",
      "Arithmetic combinatorics",
      "Arithmetic dynamics",
      "Arithmetic function",
      "Arithmetic geometry",
      "Arithmetic topology",
      "Arithmetic variety",
      "Belyi's theorem",
      "Cambridge University Press",
      "Chinese remainder theorem",
      "Class field theory",
      "Composite number",
      "Computational number theory",
      "Cross-ratio",
      "Diophantine approximation",
      "Diophantine equation",
      "Diophantine geometry",
      "Doi (identifier)",
      "Esquisse d'un Programme",
      "Fiber functor",
      "Florian Pop",
      "Genus (curve)",
      "Geometry of numbers",
      "German Mathematical Society",
      "Grothendieck conjecture",
      "Grothendieck–Teichmüller group",
      "Hdl (identifier)",
      "Hodge–Arakelov theory",
      "Hyperbolic curve",
      "Inter-universal Teichmüller theory",
      "Irrational number",
      "Irrationality measure",
      "Iwasawa theory",
      "Iwasawa–Tate theory",
      "JSTOR (identifier)"
    ],
    "categories": [
      "Category:Arithmetic geometry",
      "Category:Articles with short description",
      "Category:CS1: long volume value",
      "Category:Noncommutative geometry",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Architectural geometry": {
    "title": "Architectural geometry",
    "url": "https://en.wikipedia.org/wiki/Architectural_geometry",
    "summary": "Architectural geometry is an area of research which combines applied geometry and architecture, which looks at the design, analysis and manufacture processes. It lies at the core of architectural design and strongly challenges contemporary practice, the so-called architectural practice of the digital age.\nArchitectural geometry is influenced by following fields: differential geometry, topology, fractal geometry, and cellular automata.\n\nTopics include:\n\nfreeform curves and surfaces creation\ndevelopable surfaces\ndiscretisation\ngenerative design\ndigital prototyping and manufacturing",
    "content": "Architectural geometry is an area of research which combines applied geometry and architecture, which looks at the design, analysis and manufacture processes. It lies at the core of architectural design and strongly challenges contemporary practice, the so-called architectural practice of the digital age.\nArchitectural geometry is influenced by following fields: differential geometry, topology, fractal geometry, and cellular automata.\n\nTopics include:\n\nfreeform curves and surfaces creation\ndevelopable surfaces\ndiscretisation\ngenerative design\ndigital prototyping and manufacturing\n\nSee also\nGeometric design\nComputer-aided architectural design\nMathematics and architecture\nFractal geometry\nBlobitecture\n\nReferences\nExternal links\nTheory\n\nCharles Jencks: The New Paradigm in Architecture\nInstitutions\n\nGeometric Modeling and Industrial Geometry\nStädelschule Architecture Class\nSIAL - The Spatial Information Architecture Laboratory\nCompanies\n\nEvolute Research and Consulting\nEvents\n\nSmart Geometry\nAdvances in Architectural Geometry,([1] Conference Proceedings, 80MB)\nResource collections\n\nGeometry in Action: Architecture\nTools\n\nK3DSurf — A program to visualize and manipulate Mathematical models in three, four, five and six dimensions. K3DSurf supports Parametric equations and Isosurfaces\nJavaView — a 3D geometry viewer and a mathematical visualization software.\nGenerative Components — Generative design software that captures and exploits the critical relationships between design intent and geometry.\nParaCloud GEM— A software for components population based on points of interest, with no requirement for scripting.\nGrasshopper— a graphical algorithm editor tightly integrated with Rhino's 3-D modeling tools.",
    "links": [
      "Architecture",
      "Blobitecture",
      "Cellular automata",
      "Computer-aided architectural design",
      "Differential geometry",
      "Fractal geometry",
      "Geometric design",
      "ISBN (identifier)",
      "Mathematics and architecture",
      "Topology",
      "Wikipedia:Stub",
      "Template:Architecture-stub",
      "Template talk:Architecture-stub",
      "Help:Authority control"
    ],
    "categories": [
      "Category:All stub articles",
      "Category:Architecture stubs",
      "Category:Articles with short description",
      "Category:Computer-aided design",
      "Category:Computer-aided design software",
      "Category:Short description matches Wikidata"
    ]
  },
  "Automatic group": {
    "title": "Automatic group",
    "url": "https://en.wikipedia.org/wiki/Automatic_group",
    "summary": "In mathematics, an automatic group is a finitely generated group equipped with several finite-state automata. These automata represent the Cayley graph of the group.  That is, they can tell whether a given word representation of a group element is in a \"canonical form\" and can tell whether two elements given in canonical words differ by a generator.\nMore precisely, let G be a group and A be a finite set of generators.  Then an automatic structure of G with respect to A is a set of finite-state automata:\n\nthe word-acceptor, which accepts for every element of G at least one word in \n  \n    \n      \n        \n          A\n          \n            ∗\n          \n        \n      \n    \n    {\\displaystyle A^{\\ast }}\n  \n representing it;\nmultipliers, one for each \n  \n    \n      \n        a\n        ∈\n        A\n        ∪\n        {\n        1\n        }\n      \n    \n    {\\displaystyle a\\in A\\cup \\{1\\}}\n  \n, which accept a pair (w1, w2), for words wi accepted by the word-acceptor, precisely when \n  \n    \n    ",
    "content": "In mathematics, an automatic group is a finitely generated group equipped with several finite-state automata. These automata represent the Cayley graph of the group.  That is, they can tell whether a given word representation of a group element is in a \"canonical form\" and can tell whether two elements given in canonical words differ by a generator.\nMore precisely, let G be a group and A be a finite set of generators.  Then an automatic structure of G with respect to A is a set of finite-state automata:\n\nthe word-acceptor, which accepts for every element of G at least one word in \n  \n    \n      \n        \n          A\n          \n            ∗\n          \n        \n      \n    \n    {\\displaystyle A^{\\ast }}\n  \n representing it;\nmultipliers, one for each \n  \n    \n      \n        a\n        ∈\n        A\n        ∪\n        {\n        1\n        }\n      \n    \n    {\\displaystyle a\\in A\\cup \\{1\\}}\n  \n, which accept a pair (w1, w2), for words wi accepted by the word-acceptor, precisely when \n  \n    \n      \n        \n          w\n          \n            1\n          \n        \n        a\n        =\n        \n          w\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle w_{1}a=w_{2}}\n  \n in G.\nThe property of being automatic does not depend on the set of generators.\n\nProperties\nAutomatic groups have word problem solvable in quadratic time. More strongly, a given word can actually be put into canonical form in quadratic time, based on which the word problem may be solved by testing whether the canonical forms of two words represent the same element (using the multiplier for \n  \n    \n      \n        a\n        =\n        1\n      \n    \n    {\\displaystyle a=1}\n  \n).\nAutomatic groups are characterized by the fellow traveler property. Let \n  \n    \n      \n        d\n        (\n        x\n        ,\n        y\n        )\n      \n    \n    {\\displaystyle d(x,y)}\n  \n denote the distance between \n  \n    \n      \n        x\n        ,\n        y\n        ∈\n        G\n      \n    \n    {\\displaystyle x,y\\in G}\n  \n in the Cayley graph of \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n. Then, G is automatic with respect to a word acceptor L if and only if there is a constant \n  \n    \n      \n        C\n        ∈\n        \n          N\n        \n      \n    \n    {\\displaystyle C\\in \\mathbb {N} }\n  \n such that for all words \n  \n    \n      \n        u\n        ,\n        v\n        ∈\n        L\n      \n    \n    {\\displaystyle u,v\\in L}\n  \n which differ by at most one generator, the distance between the respective prefixes of u and v is bounded by C. In other words, \n  \n    \n      \n        ∀\n        u\n        ,\n        v\n        ∈\n        L\n        ,\n        d\n        (\n        u\n        ,\n        v\n        )\n        ≤\n        1\n        ⇒\n        ∀\n        k\n        ∈\n        \n          N\n        \n        ,\n        d\n        (\n        \n          u\n          \n            \n              |\n            \n            k\n          \n        \n        ,\n        \n          v\n          \n            \n              |\n            \n            k\n          \n        \n        )\n        ≤\n        C\n      \n    \n    {\\displaystyle \\forall u,v\\in L,d(u,v)\\leq 1\\Rightarrow \\forall k\\in \\mathbb {N} ,d(u_{|k},v_{|k})\\leq C}\n  \n where \n  \n    \n      \n        \n          w\n          \n            \n              |\n            \n            k\n          \n        \n      \n    \n    {\\displaystyle w_{|k}}\n  \n for the k-th prefix of \n  \n    \n      \n        w\n      \n    \n    {\\displaystyle w}\n  \n (or \n  \n    \n      \n        w\n      \n    \n    {\\displaystyle w}\n  \n itself if \n  \n    \n      \n        k\n        >\n        \n          |\n        \n        w\n        \n          |\n        \n      \n    \n    {\\displaystyle k>|w|}\n  \n). This means that when reading the words synchronously, it is possible to keep track of the difference between both elements with a finite number of states (the neighborhood of the identity with diameter C in the Cayley graph).\n\nExamples of automatic groups\nThe automatic groups include:\n\nFinite groups. To see this take the regular language to be the set of all words in the finite group.\nEuclidean groups\nAll finitely generated Coxeter groups\nGeometrically finite groups\n\nExamples of non-automatic groups\nBaumslag–Solitar groups\nNon-Euclidean nilpotent groups\nNot every CAT(0) group is biautomatic\n\nBiautomatic groups\nA group is biautomatic if it has two multiplier automata, for left and right multiplication by elements of the generating set, respectively.  A biautomatic group is clearly automatic. \nExamples include:\n\nHyperbolic groups.\nAny Artin group of finite type, including braid groups.\n\nAutomatic structures\nThe idea of describing algebraic structures with finite-automata can be generalized from groups to other structures. For instance, it generalizes naturally to automatic semigroups.\n\nReferences\nFurther reading\nChiswell, Ian (2008), A Course in Formal Languages, Automata and Groups, Springer, ISBN 978-1-84800-939-4.",
    "links": [
      "ArXiv (identifier)",
      "Artin group of finite type",
      "Automatic semigroup",
      "Baumslag–Solitar group",
      "Braid group",
      "CAT(0) group",
      "Cayley graph",
      "CiteSeerX (identifier)",
      "Coxeter group",
      "David B. A. Epstein",
      "Doi (identifier)",
      "Euclidean group",
      "Finite-state automata",
      "Finite group",
      "Finitely generated group",
      "Geometrically finite group",
      "Hyperbolic group",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "James W. Cannon",
      "Mathematics",
      "Mathematische Annalen",
      "Mike Paterson",
      "Nilpotent group",
      "Ruth Charney",
      "S2CID (identifier)",
      "Theoretical Computer Science",
      "William Thurston",
      "Word Processing in Groups",
      "Word problem for groups"
    ],
    "categories": [
      "Category:Combinatorics on words",
      "Category:Computability theory",
      "Category:Computational group theory",
      "Category:Properties of groups"
    ]
  },
  "Analysis Situs (paper)": {
    "title": "Analysis Situs (paper)",
    "url": "https://en.wikipedia.org/wiki/Analysis_Situs_(paper)",
    "summary": "\"Analysis Situs\" is a seminal mathematics paper that Henri Poincaré published in 1895. Poincaré published five supplements to the paper between 1899 and 1904.\nThese papers provided the first systematic treatment of topology and revolutionized the subject by using algebraic structures to distinguish between non-homeomorphic topological spaces, founding the field of algebraic topology. Poincaré's papers introduced the concepts of the fundamental group and simplicial homology, provided an early formulation of the Poincaré duality theorem, introduced the Euler–Poincaré characteristic for chain complexes, and raised several important conjectures, including the celebrated Poincaré conjecture, which was later proven as a theorem. The 1895 paper coined the mathematical term \"homeomorphism\".",
    "content": "\"Analysis Situs\" is a seminal mathematics paper that Henri Poincaré published in 1895. Poincaré published five supplements to the paper between 1899 and 1904.\nThese papers provided the first systematic treatment of topology and revolutionized the subject by using algebraic structures to distinguish between non-homeomorphic topological spaces, founding the field of algebraic topology. Poincaré's papers introduced the concepts of the fundamental group and simplicial homology, provided an early formulation of the Poincaré duality theorem, introduced the Euler–Poincaré characteristic for chain complexes, and raised several important conjectures, including the celebrated Poincaré conjecture, which was later proven as a theorem. The 1895 paper coined the mathematical term \"homeomorphism\".\n\nFootnotes\nReferences\nPoincaré, Henri (1895). \"Analysis situs\". Journal de l'École Polytechnique. (2). 1: 1–123.\nPoincaré, Henri (1899). \"Complément à l'Analysis Situs\". Rendiconti del Circolo Matematico di Palermo. 13 (2): 285–343. doi:10.1007/BF03024461.\nPoincaré, Henri (1900). \"Second complément à l'Analysis Situs\" (PDF). Proceedings of the London Mathematical Society. 32: 277–308. doi:10.1112/plms/s1-32.1.277.\nPoincaré, Henri (1902a). \"Sur certaines surfaces algébriques: troisième complément à l'Analysis Situs\". Bulletin de la Société Mathématique de France. 30: 49–70. doi:10.24033/bsmf.657.\nPoincaré, Henri (1902b). \"Sur les cycles des surfaces algébriques: quatrième complément à l'Analysis Situs\". Journal de mathématiques pures et appliquées. (5). 8: 169–214.\nPoincaré, Henri (1904). \"Cinquième complément à l'analysis situs\". Rendiconti del Circolo Matematico di Palermo. 18: 45–110. doi:10.1007/bf03014091.\nPoincaré, Henri (2009). Papers on Topology: Analysis Situs and Its Five Supplements (PDF). Translated by John Stillwell.\nDieudonné, Jean (1989). A History of Algebraic and Differential Topology 1900–1960. Boston: Birkhäuser. ISBN 0-8176-3388-X.",
    "links": [
      "Academic publishing",
      "Algebraic topology",
      "Analysis Situs (book)",
      "Birkhäuser",
      "Bulletin de la Société Mathématique de France",
      "Chain complex",
      "Circolo Matematico di Palermo",
      "Doi (identifier)",
      "Euler characteristic",
      "Fundamental group",
      "Henri Poincaré",
      "Homeomorphism",
      "ISBN (identifier)",
      "Jean Dieudonné",
      "John Stillwell",
      "Mathematics",
      "Poincaré conjecture",
      "Poincaré duality",
      "Proceedings of the London Mathematical Society",
      "Simplicial homology",
      "Theorem",
      "Topological space",
      "Topology",
      "Wikipedia:Stub",
      "Template:Mathematics-lit-stub",
      "Template talk:Mathematics-lit-stub"
    ],
    "categories": [
      "Category:All stub articles",
      "Category:Articles with short description",
      "Category:Mathematics literature stubs",
      "Category:Mathematics papers",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Banach fixed-point theorem": {
    "title": "Banach fixed-point theorem",
    "url": "https://en.wikipedia.org/wiki/Banach_fixed-point_theorem",
    "summary": "In mathematics, the Banach fixed-point theorem (also known as the contraction mapping theorem or contractive mapping theorem or Banach–Caccioppoli theorem) is an important tool in the theory of metric spaces; it guarantees the existence and uniqueness of fixed points of certain self-maps of metric spaces and provides a constructive method to find those fixed points. It can be understood as an abstract formulation of Picard's method of successive approximations. The theorem is named after Stefan Banach (1892–1945) who first stated it in 1922.",
    "content": "In mathematics, the Banach fixed-point theorem (also known as the contraction mapping theorem or contractive mapping theorem or Banach–Caccioppoli theorem) is an important tool in the theory of metric spaces; it guarantees the existence and uniqueness of fixed points of certain self-maps of metric spaces and provides a constructive method to find those fixed points. It can be understood as an abstract formulation of Picard's method of successive approximations. The theorem is named after Stefan Banach (1892–1945) who first stated it in 1922.\n\nStatement\nDefinition. Let \n  \n    \n      \n        (\n        X\n        ,\n        d\n        )\n      \n    \n    {\\displaystyle (X,d)}\n  \n be a metric space. Then a map \n  \n    \n      \n        T\n        :\n        X\n        →\n        X\n      \n    \n    {\\displaystyle T:X\\to X}\n  \n is called a contraction mapping on X if there exists \n  \n    \n      \n        q\n        ∈\n        [\n        0\n        ,\n        1\n        )\n      \n    \n    {\\displaystyle q\\in [0,1)}\n  \n such that\n\n  \n    \n      \n        d\n        (\n        T\n        (\n        x\n        )\n        ,\n        T\n        (\n        y\n        )\n        )\n        ≤\n        q\n        d\n        (\n        x\n        ,\n        y\n        )\n      \n    \n    {\\displaystyle d(T(x),T(y))\\leq qd(x,y)}\n  \n\nfor all \n  \n    \n      \n        x\n        ,\n        y\n        ∈\n        X\n        .\n      \n    \n    {\\displaystyle x,y\\in X.}\n  \n\nBanach fixed-point theorem. Let \n  \n    \n      \n        (\n        X\n        ,\n        d\n        )\n      \n    \n    {\\displaystyle (X,d)}\n  \n be a non-empty complete metric space with a contraction mapping \n  \n    \n      \n        T\n        :\n        X\n        →\n        X\n        .\n      \n    \n    {\\displaystyle T:X\\to X.}\n  \n Then T admits a unique fixed-point \n  \n    \n      \n        \n          x\n          \n            ∗\n          \n        \n      \n    \n    {\\displaystyle x^{*}}\n  \n in X (i.e. \n  \n    \n      \n        T\n        (\n        \n          x\n          \n            ∗\n          \n        \n        )\n        =\n        \n          x\n          \n            ∗\n          \n        \n      \n    \n    {\\displaystyle T(x^{*})=x^{*}}\n  \n). Furthermore, \n  \n    \n      \n        \n          x\n          \n            ∗\n          \n        \n      \n    \n    {\\displaystyle x^{*}}\n  \n can be found as follows: start with an arbitrary element \n  \n    \n      \n        \n          x\n          \n            0\n          \n        \n        ∈\n        X\n      \n    \n    {\\displaystyle x_{0}\\in X}\n  \n and define a sequence \n  \n    \n      \n        (\n        \n          x\n          \n            n\n          \n        \n        \n          )\n          \n            n\n            ∈\n            \n              N\n            \n          \n        \n      \n    \n    {\\displaystyle (x_{n})_{n\\in \\mathbb {N} }}\n  \n by \n  \n    \n      \n        \n          x\n          \n            n\n          \n        \n        =\n        T\n        (\n        \n          x\n          \n            n\n            −\n            1\n          \n        \n        )\n      \n    \n    {\\displaystyle x_{n}=T(x_{n-1})}\n  \n for \n  \n    \n      \n        n\n        ≥\n        1.\n      \n    \n    {\\displaystyle n\\geq 1.}\n  \n Then \n  \n    \n      \n        \n          lim\n          \n            n\n            →\n            ∞\n          \n        \n        \n          x\n          \n            n\n          \n        \n        =\n        \n          x\n          \n            ∗\n          \n        \n      \n    \n    {\\displaystyle \\lim _{n\\to \\infty }x_{n}=x^{*}}\n  \n.\nRemark 1. The following inequalities are equivalent and describe the speed of convergence:\n\n  \n    \n      \n        \n          \n            \n              \n                d\n                (\n                \n                  x\n                  \n                    ∗\n                  \n                \n                ,\n                \n                  x\n                  \n                    n\n                  \n                \n                )\n              \n              \n                \n                ≤\n                \n                  \n                    \n                      q\n                      \n                        n\n                      \n                    \n                    \n                      1\n                      −\n                      q\n                    \n                  \n                \n                d\n                (\n                \n                  x\n                  \n                    1\n                  \n                \n                ,\n                \n                  x\n                  \n                    0\n                  \n                \n                )\n                ,\n              \n            \n            \n              \n                d\n                (\n                \n                  x\n                  \n                    ∗\n                  \n                \n                ,\n                \n                  x\n                  \n                    n\n                    +\n           ",
    "links": [
      "Algebraic topology",
      "Approach space",
      "Baire category theorem",
      "Ball (mathematics)",
      "Betti number",
      "Bing metrization theorem",
      "Borel set",
      "Bounded set",
      "Brouwer fixed-point theorem",
      "Bundle (mathematics)",
      "CW complex",
      "Cantor space",
      "Caristi fixed-point theorem",
      "Category of metric spaces",
      "Cauchy sequence",
      "Cauchy space",
      "Chebyshev distance",
      "Chern class",
      "Closed set",
      "Coarse structure",
      "Cobordism",
      "Cohomology",
      "Combinatorial topology",
      "Compact metric space",
      "Compact space",
      "Complete metric space",
      "Connected space",
      "Continuity (topology)",
      "Continuum (topology)",
      "Contraction mapping",
      "Convergence proof techniques",
      "Convex metric space",
      "Corollary",
      "Cosmic space",
      "Cournot competition",
      "Czesław Bessaga",
      "David Kinderlehrer",
      "De Rham cohomology",
      "Delone set",
      "Diameter of a set",
      "Differential topology",
      "Digital topology",
      "Dilation (metric space)",
      "Discrete space",
      "Distance set",
      "Diversity (mathematics)",
      "Doi (identifier)",
      "Doubling space",
      "Economics Letters",
      "Empty set"
    ],
    "categories": [
      "Category:Articles containing proofs",
      "Category:Articles with short description",
      "Category:CS1 German-language sources (de)",
      "Category:Eponymous theorems of mathematics",
      "Category:Fixed-point theorems",
      "Category:Metric geometry",
      "Category:Short description matches Wikidata",
      "Category:Topology",
      "Category:Wikipedia articles incorporating text from PlanetMath"
    ]
  },
  "Boolean algebra (structure)": {
    "title": "Boolean algebra (structure)",
    "url": "https://en.wikipedia.org/wiki/Boolean_algebra_(structure)",
    "summary": "In abstract algebra, a Boolean algebra or Boolean lattice is a complemented distributive lattice. This type of algebraic structure captures essential properties of both set operations and logic operations. A Boolean algebra can be seen as a generalization of a power set algebra or a field of sets, or its elements can be viewed as generalized truth values. It is also a special case of a De Morgan algebra and a Kleene algebra (with involution).\nEvery Boolean algebra gives rise to a Boolean ring, and vice versa, with ring multiplication corresponding to conjunction or meet ∧, and ring addition to exclusive disjunction or symmetric difference (not disjunction ∨). However, the theory of Boolean rings has an inherent asymmetry between the two operators, while the axioms and theorems of Boolean algebra express the symmetry of the theory described by the duality principle.",
    "content": "In abstract algebra, a Boolean algebra or Boolean lattice is a complemented distributive lattice. This type of algebraic structure captures essential properties of both set operations and logic operations. A Boolean algebra can be seen as a generalization of a power set algebra or a field of sets, or its elements can be viewed as generalized truth values. It is also a special case of a De Morgan algebra and a Kleene algebra (with involution).\nEvery Boolean algebra gives rise to a Boolean ring, and vice versa, with ring multiplication corresponding to conjunction or meet ∧, and ring addition to exclusive disjunction or symmetric difference (not disjunction ∨). However, the theory of Boolean rings has an inherent asymmetry between the two operators, while the axioms and theorems of Boolean algebra express the symmetry of the theory described by the duality principle.\n\nHistory\nThe term \"Boolean algebra\" honors George Boole (1815–1864), a self-educated English mathematician. He introduced the algebraic system initially in a small pamphlet, The Mathematical Analysis of Logic, published in 1847 in response to an ongoing public controversy between Augustus De Morgan and William Hamilton, and later as a more substantial book, The Laws of Thought, published in 1854. Boole's formulation differs from that described above in some important respects. For example, conjunction and disjunction in Boole were not a dual pair of operations. Boolean algebra emerged in the 1860s, in papers written by William Jevons and Charles Sanders Peirce. The first systematic presentation of Boolean algebra and distributive lattices is owed to the 1890 Vorlesungen of Ernst Schröder. The first extensive treatment of Boolean algebra in English is A. N. Whitehead's 1898 Universal Algebra. Boolean algebra as an axiomatic algebraic structure in the modern axiomatic sense begins with a 1904 paper by Edward V. Huntington. Boolean algebra came of age as serious mathematics with the work of Marshall Stone in the 1930s, and with Garrett Birkhoff's 1940 Lattice Theory. In the 1960s, Paul Cohen, Dana Scott, and others found deep new results in mathematical logic and axiomatic set theory using offshoots of Boolean algebra, namely forcing and Boolean-valued models.\n\nDefinition\nA Boolean algebra is a set A, equipped with two binary operations ∧ (called \"meet\" or \"and\"), ∨ (called \"join\" or \"or\"), a unary operation ¬ (called \"complement\" or \"not\") and two elements 0 and 1 in A (called \"bottom\" and \"top\", or \"least\" and \"greatest\" element, also denoted by the symbols ⊥ and ⊤, respectively), such that for all elements a, b and c of A, the following axioms hold:\n\nNote, however, that the absorption law and even the associativity law can be excluded from the set of axioms as they can be derived from the other axioms (see Proven properties).\nA Boolean algebra with only one element is called a trivial Boolean algebra or a degenerate Boolean algebra. (In older works, some authors required 0 and 1 to be distinct elements in order to exclude this case.)\nIt follows from the last three pairs of axioms above (identity, distributivity and complements), or from the absorption axiom, that\n\na = b ∧ a     if and only if     a ∨ b = b.\nThe relation ≤ defined by a ≤ b if these equivalent conditions hold, is a partial order with least element 0 and greatest element 1. The meet a ∧ b and the join a ∨ b of two elements coincide with their infimum and supremum, respectively, with respect to ≤.\nThe first four pairs of axioms constitute a definition of a bounded lattice.\nIt follows from the first five pairs of axioms that any complement is unique.\nThe set of axioms is self-dual in the sense that if one exchanges ∨ with ∧ and 0 with 1 in an axiom, the result is again an axiom. Therefore, by applying this operation to a Boolean algebra (or Boolean lattice), one obtains another Boolean algebra with the same elements; it is called its dual.\n\nExamples\nThe simplest non-trivial Boolean algebra, the two-element Boolean algebra, has only two elements, 0 and 1, and is defined by the rules:\n\nIt has applications in logic, interpreting 0 as false, 1 as true, ∧ as and, ∨ as or, and ¬ as not. Expressions involving variables and the Boolean operations represent statement forms, and two such expressions can be shown to be equal using the above axioms if and only if the corresponding statement forms are logically equivalent.\nThe two-element Boolean algebra is also used for circuit design in electrical engineering; here 0 and 1 represent the two different states of one bit in a digital circuit, typically high and low voltage. Circuits are described by expressions containing variables, and two such expressions are equal for all values of the variables if and only if the corresponding circuits have the same input–output behavior. Furthermore, every possible input–output behavior can be modeled by a suitable Boolean expression.\nThe two-element Boolean algebra is also important in the general theory of B",
    "links": [
      "2-valued morphism",
      "A.N. Whitehead",
      "A. N. Whitehead",
      "Abelian group",
      "Absorption law",
      "Abstract algebra",
      "Abstract rewriting system",
      "Alexandrov topology",
      "Alfred North Whitehead",
      "Alfred Tarski",
      "Algebra of sets",
      "Algebra over a field",
      "Algebraic structure",
      "Algebraic system",
      "Antichain",
      "Antisymmetric relation",
      "Argonne National Laboratory",
      "Artificial Intelligence (journal)",
      "Associative algebra",
      "Associativity",
      "Asymmetric relation",
      "Augustus De Morgan",
      "Automated theorem proving",
      "Axiom",
      "Axiom of choice",
      "Axiomatic set theory",
      "Banach lattice",
      "Better-quasi-ordering",
      "Bialgebra",
      "Bijection",
      "Binary operation",
      "Binary relation",
      "Bit",
      "Boolean-valued function",
      "Boolean-valued model",
      "Boolean algebra",
      "Boolean algebras canonically defined",
      "Boolean domain",
      "Boolean function",
      "Boolean logic",
      "Boolean prime ideal theorem",
      "Boolean ring",
      "Bounded lattice",
      "Brute force search",
      "Canonical form (Boolean algebra)",
      "Cantor's isomorphism theorem",
      "Cantor–Bernstein theorem",
      "Category theory",
      "Central idempotent",
      "Chain-complete partial order"
    ],
    "categories": [
      "Category:Algebraic structures",
      "Category:All articles lacking in-text citations",
      "Category:All articles with unsourced statements",
      "Category:Articles lacking in-text citations from July 2013",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from July 2020",
      "Category:Boolean algebra",
      "Category:CS1 errors: ISBN date",
      "Category:Ockham algebras",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Cantor set": {
    "title": "Cantor set",
    "url": "https://en.wikipedia.org/wiki/Cantor_set",
    "summary": "In mathematics, the Cantor set is a set of points lying on a single line segment that has a number of unintuitive properties. It was discovered in 1874 by Henry John Stephen Smith and mentioned by German mathematician Georg Cantor in 1883.\nThrough consideration of this set, Cantor and others helped lay the foundations of modern point-set topology. The most common construction is the Cantor ternary set, built by removing the middle third of a line segment and then repeating the process with the remaining shorter segments. Cantor mentioned this ternary construction only in passing, as an example of a perfect set that is nowhere dense.\nMore generally, in topology, a Cantor space is a topological space homeomorphic to the Cantor ternary set (equipped with its subspace topology). The Cantor set is naturally homeomorphic to the countable product \n  \n    \n      \n        \n          \n            \n              2\n              _\n            \n          \n          \n            \n              N\n   ",
    "content": "In mathematics, the Cantor set is a set of points lying on a single line segment that has a number of unintuitive properties. It was discovered in 1874 by Henry John Stephen Smith and mentioned by German mathematician Georg Cantor in 1883.\nThrough consideration of this set, Cantor and others helped lay the foundations of modern point-set topology. The most common construction is the Cantor ternary set, built by removing the middle third of a line segment and then repeating the process with the remaining shorter segments. Cantor mentioned this ternary construction only in passing, as an example of a perfect set that is nowhere dense.\nMore generally, in topology, a Cantor space is a topological space homeomorphic to the Cantor ternary set (equipped with its subspace topology). The Cantor set is naturally homeomorphic to the countable product \n  \n    \n      \n        \n          \n            \n              2\n              _\n            \n          \n          \n            \n              N\n            \n          \n        \n      \n    \n    {\\displaystyle {\\underline {2}}^{\\mathbb {N} }}\n  \n of the discrete two-point space \n  \n    \n      \n        \n          \n            2\n            _\n          \n        \n      \n    \n    {\\displaystyle {\\underline {2}}}\n  \n. By a theorem of L. E. J. Brouwer, this is equivalent to being perfect, nonempty, compact, metrizable and zero-dimensional.\n\nConstruction and formula of the ternary set\nThe Cantor ternary set \n  \n    \n      \n        \n          \n            C\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {C}}}\n  \n is created by iteratively deleting the open middle third from a set of line segments. One starts by deleting the open middle third \n  \n    \n      \n        \n          (\n          \n            \n              \n                1\n                3\n              \n            \n            ,\n            \n              \n                2\n                3\n              \n            \n          \n          )\n        \n      \n    \n    {\\textstyle \\left({\\frac {1}{3}},{\\frac {2}{3}}\\right)}\n  \n from the interval \n  \n    \n      \n        \n          \n            [\n            \n              0\n              ,\n              1\n            \n            ]\n          \n        \n      \n    \n    {\\displaystyle \\textstyle \\left[0,1\\right]}\n  \n, leaving two line segments: \n  \n    \n      \n        \n          [\n          \n            0\n            ,\n            \n              \n                1\n                3\n              \n            \n          \n          ]\n        \n        ∪\n        \n          [\n          \n            \n              \n                2\n                3\n              \n            \n            ,\n            1\n          \n          ]\n        \n      \n    \n    {\\textstyle \\left[0,{\\frac {1}{3}}\\right]\\cup \\left[{\\frac {2}{3}},1\\right]}\n  \n.  Next, the open middle third of each of these remaining segments is deleted, leaving four line segments: \n  \n    \n      \n        \n          [\n          \n            0\n            ,\n            \n              \n                1\n                9\n              \n            \n          \n          ]\n        \n        ∪\n        \n          [\n          \n            \n              \n                2\n                9\n              \n            \n            ,\n            \n              \n                1\n                3\n              \n            \n          \n          ]\n        \n        ∪\n        \n          [\n          \n            \n              \n                2\n                3\n              \n            \n            ,\n            \n              \n                7\n                9\n              \n            \n          \n          ]\n        \n        ∪\n        \n          [\n          \n            \n              \n                8\n                9\n              \n            \n            ,\n            1\n          \n          ]\n        \n      \n    \n    {\\textstyle \\left[0,{\\frac {1}{9}}\\right]\\cup \\left[{\\frac {2}{9}},{\\frac {1}{3}}\\right]\\cup \\left[{\\frac {2}{3}},{\\frac {7}{9}}\\right]\\cup \\left[{\\frac {8}{9}},1\\right]}\n  \n.\nThe Cantor ternary set contains all points in the interval \n  \n    \n      \n        [\n        0\n        ,\n        1\n        ]\n      \n    \n    {\\displaystyle [0,1]}\n  \n that are not deleted at any step in this infinite process. The same construction can be described recursively by setting\n\n  \n    \n      \n        \n          C\n          \n            0\n          \n        \n        :=\n        [\n        0\n        ,\n        1\n        ]\n      \n    \n    {\\displaystyle C_{0}:=[0,1]}\n  \n\nand\n\n  \n    \n      \n        \n          C\n          \n            n\n          \n        \n        :=\n        \n          \n            \n              C\n              \n                n\n                −\n                1\n              \n            \n            3\n          \n        \n        ∪\n        \n          (\n          \n            \n              \n                2\n                3\n              \n            \n            +\n            \n              \n       ",
    "links": [
      "A. Zygmund",
      "ASIN (identifier)",
      "Absolute difference",
      "Absolute value (algebra)",
      "Accumulation point",
      "Ad infinitum",
      "Aleksandr Lyapunov",
      "Algebraic number",
      "Almost all",
      "Antoine's necklace",
      "Apollonian gasket",
      "Assouad dimension",
      "Attractor",
      "Automorphism",
      "Axiom of choice",
      "Axiomatic set theory",
      "Baire space",
      "Barnsley fern",
      "Basis (topology)",
      "Benoit Mandelbrot",
      "Bill Gosper",
      "Binary numeral system",
      "Binary tree",
      "Blancmange curve",
      "Brownian motion",
      "Brownian motor",
      "Buddhabrot",
      "Burning Ship fractal",
      "Cambridge University Press",
      "Cantor cube",
      "Cantor function",
      "Cantor space",
      "Cantor–Bernstein–Schröder theorem",
      "Cardinality",
      "Cartesian product",
      "Category (mathematics)",
      "Category theory",
      "Chaos: Making a New Science",
      "Chaos game",
      "Chaos theory",
      "Classification of discontinuities",
      "Clopen set",
      "Closed interval",
      "Closed set",
      "Coastline paradox",
      "Compact group",
      "Compact space",
      "Complement (set theory)",
      "Complete metric space",
      "Conjecture"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1 German-language sources (de)",
      "Category:CS1 Italian-language sources (it)",
      "Category:CS1 errors: ISBN date",
      "Category:CS1 maint: location missing publisher",
      "Category:Georg Cantor",
      "Category:L-systems",
      "Category:Measure theory",
      "Category:Sets of real numbers",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Characterizations of the category of topological spaces": {
    "title": "Axiomatic foundations of topological spaces",
    "url": "https://en.wikipedia.org/wiki/Axiomatic_foundations_of_topological_spaces",
    "summary": "In the mathematical field of topology, a topological space is usually defined by declaring its open sets. However, this is not necessary, as there are many equivalent axiomatic foundations, each leading to exactly the same concept. For instance, a topological space determines a class of closed sets, of closure and interior operators, and of convergence of various types of objects. Each of these can instead be taken as the primary class of objects, with all of the others (including the class of open sets) directly determined from that new starting point. For example, in Kazimierz Kuratowski's well-known textbook on point-set topology, a topological space is defined as a set together with a certain type of \"closure operator,\" and all other concepts are derived therefrom. Likewise, the neighborhood-based axioms (in the context of Hausdorff spaces) can be retraced to Felix Hausdorff's original definition of a topological space in Grundzüge der Mengenlehre.\nMany different textbooks use many",
    "content": "In the mathematical field of topology, a topological space is usually defined by declaring its open sets. However, this is not necessary, as there are many equivalent axiomatic foundations, each leading to exactly the same concept. For instance, a topological space determines a class of closed sets, of closure and interior operators, and of convergence of various types of objects. Each of these can instead be taken as the primary class of objects, with all of the others (including the class of open sets) directly determined from that new starting point. For example, in Kazimierz Kuratowski's well-known textbook on point-set topology, a topological space is defined as a set together with a certain type of \"closure operator,\" and all other concepts are derived therefrom. Likewise, the neighborhood-based axioms (in the context of Hausdorff spaces) can be retraced to Felix Hausdorff's original definition of a topological space in Grundzüge der Mengenlehre.\nMany different textbooks use many different inter-dependences of concepts to develop point-set topology. The result is always the same collection of objects: open sets, closed sets, and so on. For many practical purposes, the question of which foundation is chosen is irrelevant, as long as the meaning and interrelation between objects (many of which are given in this article), which are the same regardless of choice of development, are understood. However, there are cases where it can be useful to have flexibility. For instance, there are various natural notions of convergence of measures, and it is not immediately clear whether they arise from a topological structure or not. Such questions are greatly clarified by the topological axioms based on convergence.\n\nStandard definitions via open sets\nA topological space is a set \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n together with a collection \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n of subsets of \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n satisfying:\n\nThe empty set and \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n are in \n  \n    \n      \n        S\n        .\n      \n    \n    {\\displaystyle S.}\n  \n\nThe union of any collection of sets in \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n is also in \n  \n    \n      \n        S\n        .\n      \n    \n    {\\displaystyle S.}\n  \n\nThe intersection of any pair of sets in \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n is also in \n  \n    \n      \n        S\n        .\n      \n    \n    {\\displaystyle S.}\n  \n Equivalently, the intersection of any finite collection of sets in \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n is also in \n  \n    \n      \n        S\n        .\n      \n    \n    {\\displaystyle S.}\n  \n\nGiven a topological space \n  \n    \n      \n        (\n        X\n        ,\n        S\n        )\n        ,\n      \n    \n    {\\displaystyle (X,S),}\n  \n one refers to the elements of \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n as the open sets of \n  \n    \n      \n        X\n        ,\n      \n    \n    {\\displaystyle X,}\n  \n and it is common only to refer to \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n in this way, or by the label topology. Then one makes the following secondary definitions:\n\nGiven a second topological space \n  \n    \n      \n        Y\n        ,\n      \n    \n    {\\displaystyle Y,}\n  \n a function \n  \n    \n      \n        f\n        :\n        X\n        →\n        Y\n      \n    \n    {\\displaystyle f:X\\to Y}\n  \n is said to be continuous if and only if for every open subset \n  \n    \n      \n        U\n      \n    \n    {\\displaystyle U}\n  \n of \n  \n    \n      \n        Y\n        ,\n      \n    \n    {\\displaystyle Y,}\n  \n one has that \n  \n    \n      \n        \n          f\n          \n            −\n            1\n          \n        \n        (\n        U\n        )\n      \n    \n    {\\displaystyle f^{-1}(U)}\n  \n is an open subset of \n  \n    \n      \n        X\n        .\n      \n    \n    {\\displaystyle X.}\n  \n\nA subset \n  \n    \n      \n        C\n      \n    \n    {\\displaystyle C}\n  \n of \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is closed if and only if its complement \n  \n    \n      \n        X\n        ∖\n        C\n      \n    \n    {\\displaystyle X\\setminus C}\n  \n is open.\nGiven a subset \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n of \n  \n    \n      \n        X\n        ,\n      \n    \n    {\\displaystyle X,}\n  \n the closure is the set of all points such that any open set containing such a point must intersect \n  \n    \n      \n        A\n        .\n      \n    \n    {\\displaystyle A.}\n  \n\nGiven a subset \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n of \n  \n    \n      \n        X\n        ,\n      \n    \n    {\\displaystyle X,}\n  \n the interior is the union of all open sets contained in \n  \n    \n      \n        A\n        .\n      \n    \n    {\\displaystyle A.}\n  \n\nGiven an element \n  \n    \n      \n        x\n      \n",
    "links": [
      "Boundary (topology)",
      "Cauchy space",
      "Closed set",
      "Convergence of measures",
      "Convergence space",
      "Convergent filter",
      "Convergent net",
      "Convergent prefilter",
      "De Morgan's laws",
      "Derived set (mathematics)",
      "Doi (identifier)",
      "Dover Publications",
      "Empty set",
      "Felix Hausdorff",
      "Filter (set theory)",
      "Filters in topology",
      "Fréchet–Urysohn space",
      "Function composition",
      "Grundzüge der Mengenlehre",
      "Hausdorff space",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "Interior (topology)",
      "Intersection (set theory)",
      "James Dugundji",
      "John L. Kelley",
      "Kazimierz Kuratowski",
      "Kuratowski closure axioms",
      "Lexicographic order",
      "Limit point",
      "Mathematics",
      "Mineola, N.Y.",
      "Neighbourhood (mathematics)",
      "Neighbourhood system",
      "Net (mathematics)",
      "OCLC (identifier)",
      "Open set",
      "Point-set topology",
      "Power set",
      "Prefilter",
      "Ryszard Engelking",
      "Sequential space",
      "Set (mathematics)",
      "Subnet (mathematics)",
      "Subset",
      "Topological space",
      "Topology",
      "Topology (structure)",
      "Union (set theory)",
      "Wikipedia:Citation needed"
    ],
    "categories": [
      "Category:All articles with unsourced statements",
      "Category:Articles with unsourced statements from December 2021",
      "Category:Categories in category theory",
      "Category:General topology"
    ]
  },
  "Circuit topology": {
    "title": "Circuit topology",
    "url": "https://en.wikipedia.org/wiki/Circuit_topology",
    "summary": "The circuit topology of a folded linear polymer refers to the arrangement of its intra-molecular contacts. Examples of linear polymers with intra-molecular contacts are nucleic acids and proteins. Proteins fold via the formation of contacts of various natures, including hydrogen bonds, disulfide bonds, and beta-beta interactions. RNA molecules fold by forming hydrogen bonds between nucleotides, forming nested or non-nested structures. Contacts in the genome are established via protein bridges including CTCF and cohesins and are measured by technologies including Hi-C. Circuit topology categorises the topological arrangement of these physical contacts, that are referred to as hard contacts (or h-contacts). Furthermore, chains can fold via knotting (or the formation of \"soft\" contacts (s-contacts)). Circuit topology uses a similar language to categorise both \"soft\" and \"hard\" contacts, and provides a full description of a folded linear chain. In this framework, a \"circuit\" refers to a se",
    "content": "The circuit topology of a folded linear polymer refers to the arrangement of its intra-molecular contacts. Examples of linear polymers with intra-molecular contacts are nucleic acids and proteins. Proteins fold via the formation of contacts of various natures, including hydrogen bonds, disulfide bonds, and beta-beta interactions. RNA molecules fold by forming hydrogen bonds between nucleotides, forming nested or non-nested structures. Contacts in the genome are established via protein bridges including CTCF and cohesins and are measured by technologies including Hi-C. Circuit topology categorises the topological arrangement of these physical contacts, that are referred to as hard contacts (or h-contacts). Furthermore, chains can fold via knotting (or the formation of \"soft\" contacts (s-contacts)). Circuit topology uses a similar language to categorise both \"soft\" and \"hard\" contacts, and provides a full description of a folded linear chain. In this framework, a \"circuit\" refers to a segment of the chain where each contact site within the segment forms connections with other contact sites within the same segment, and thus is not left unpaired. A folded chain can thus be studied based on its constituting circuits.\nA simple example of a folded chain is a chain with two hard contacts. For a chain with two binary contacts, three arrangements are available: parallel (P), series (S), and crossed (X). For a chain with n contacts, the topology can be described by an n by n matrix in which each element illustrates the relation between a pair of contacts and may take one of the three states, P, S and X. Multivalent contacts can also be categorised in full or via decomposition into several binary contacts. Similarly, circuit topology allows for the classification of the pairwise arrangements of chain crossings and tangles, thus providing a complete 3D description of folded chains. Furthermore, one can apply circuit topology operations to soft and hard contacts to generate complex folds, using a bottom-up engineering approach.\nBoth knot theory and circuit topology aim to describe chain entanglement, making it important to understand their relationship. Knot theory considers any entangled chain as a connected sum of prime knots, which are themselves undecomposable. Circuit topology splits any entangled chains (including prime knots) into basic structural units called soft contacts, and lists simple rules on how soft contacts can be put together.  An advantage of circuit topology is that it can be applied to open linear chains with intra-chain interactions, so-called hard contacts. This enabled topological analysis of proteins and genomes, which are often described as \"unknot\" in knot theory.  Finally, circuit topology enables studying interactions between hard contacts and entanglements and can identify slip knots, while knot theory typically overlooks hard contacts and split knots. Thus, circuit topology serves as a complementary approach to knot theory.\nCircuit topology has implications for folding kinetics and molecular evolution and has been applied to engineer polymers including molecular origami. Circuit topology along with contact order and size are determinants of the folding rate of linear polymers. The approach can also be used for medical applications including the prediction of pathogenicity of mutations.\n\nFurther reading\nScalvini, Barbara; Sheikhhassani, Vahid; Mashaghi, Alireza (2021). \"Topological principles of protein folding\". Physical Chemistry Chemical Physics. 23 (37): 21316–21328. Bibcode:2021PCCP...2321316S. doi:10.1039/D1CP03390E. hdl:1887/3277889. PMID 34545868. S2CID 237583577.\nGolovnev, Anatoly; Mashaghi, Alireza (September 2020). \"Generalized Circuit Topology of Folded Linear Chains\". iScience. 23 (9): 101492. Bibcode:2020iSci...23j1492G. doi:10.1016/j.isci.2020.101492. PMC 7481252. PMID 32896769.\nHeidari, Maziar; Schiessel, Helmut; Mashaghi, Alireza (24 June 2020). \"Circuit Topology Analysis of Polymer Folding Reactions\". ACS Central Science. 6 (6): 839–847. doi:10.1021/acscentsci.0c00308. PMC 7318069. PMID 32607431.\n\nReferences\nSee also\nMolecular topology",
    "links": [
      "ArXiv (identifier)",
      "Bibcode (identifier)",
      "CTCF",
      "Chromosome conformation capture",
      "Circuit topology (electrical)",
      "Cohesin",
      "Doi (identifier)",
      "Hdl (identifier)",
      "ISBN (identifier)",
      "Knot theory",
      "Molecular evolution",
      "Nucleic acid",
      "PMC (identifier)",
      "PMID (identifier)",
      "Polymer",
      "Prime knot",
      "Protein",
      "S2CID (identifier)",
      "Topology (chemistry)"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Knot theory",
      "Category:Mathematical chemistry",
      "Category:Molecular geometry",
      "Category:Molecular topology",
      "Category:Short description matches Wikidata",
      "Category:Structural bioinformatics",
      "Category:Supramolecular chemistry",
      "Category:Topology"
    ]
  },
  "Classification theorem": {
    "title": "Classification theorem",
    "url": "https://en.wikipedia.org/wiki/Classification_theorem",
    "summary": "In mathematics, a classification theorem answers the classification problem: \"What are the objects of a given type, up to some equivalence?\". It gives a non-redundant enumeration: each object is equivalent to exactly one class.\nA few issues related to classification are the following.\n\nThe equivalence problem is \"given two objects, determine if they are equivalent\".\nA complete set of invariants, together with which invariants are realizable, solves the classification problem, and is often a step in solving it. (A combination of invariant values is realizable if there in fact exists an object whose invariants take on the specified set of values)\nA computable complete set of invariants (together with which invariants are realizable) solves both the classification problem and the equivalence problem.\nA canonical form solves the classification problem, and is more data: it not only classifies every class, but provides a distinguished (canonical) element of each class.\nThere exist many clas",
    "content": "In mathematics, a classification theorem answers the classification problem: \"What are the objects of a given type, up to some equivalence?\". It gives a non-redundant enumeration: each object is equivalent to exactly one class.\nA few issues related to classification are the following.\n\nThe equivalence problem is \"given two objects, determine if they are equivalent\".\nA complete set of invariants, together with which invariants are realizable, solves the classification problem, and is often a step in solving it. (A combination of invariant values is realizable if there in fact exists an object whose invariants take on the specified set of values)\nA computable complete set of invariants (together with which invariants are realizable) solves both the classification problem and the equivalence problem.\nA canonical form solves the classification problem, and is more data: it not only classifies every class, but provides a distinguished (canonical) element of each class.\nThere exist many classification theorems in mathematics, as described below.\n\nGeometry\nClassification of Euclidean plane isometries\nClassification of Platonic solids\nClassification theorems of surfaces\nClassification of two-dimensional closed manifolds – Two-dimensional manifoldPages displaying short descriptions of redirect targets\nEnriques–Kodaira classification – Mathematical classification of surfaces of algebraic surfaces (complex dimension two, real dimension four)\nNielsen–Thurston classification – Characterizes homeomorphisms of a compact orientable surface which characterizes homeomorphisms of a compact surface\nThurston's eight model geometries, and the geometrization conjecture – Three dimensional analogue of uniformization conjecture\nBerger classification – Concept in differential geometry\nClassification of Riemannian symmetric spaces – (pseudo-)Riemannian manifold whose geodesics are reversible\nClassification of 3-dimensional lens spaces – Class of topological space\nClassification of manifolds – Basic question in geometry and topology\n\nAlgebra\nClassification of finite simple groups – Theorem classifying finite simple groups\nClassification of Abelian groups – Commutative group (mathematics)\nClassification of Finitely generated abelian group – Commutative group where every element is the sum of elements from one finite subset\nClassification of Rank 3 permutation group – Five sporadic simple groupsPages displaying short descriptions of redirect targets\nClassification of 2-transitive permutation groups\nArtin–Wedderburn theorem – Classification of semi-simple rings and algebrasPages displaying short descriptions of redirect targets — a classification theorem for semisimple rings\nClassification of Clifford algebras\nClassification of low-dimensional real Lie algebras\nClassification of Simple Lie algebras and groups\nClassification of simple complex Lie algebras – Direct sum of simple Lie algebras\nClassification of simple real Lie algebras – Term in mathematics\nClassification of centerless simple Lie groups – Connected non-abelian Lie group lacking nontrivial connected normal subgroups\nClassification of simple Lie groups – Connected non-abelian Lie group lacking nontrivial connected normal subgroupsPages displaying short descriptions of redirect targets\nBianchi classification – Lie algebra classification\nADE classification – Mathematical classification\nLanglands classification – Mathematical theory\n\nLinear algebra\nFinite-dimensional vector space – Number of vectors in any basis of the vector spacePages displaying short descriptions of redirect targetss (by dimension)\nRank–nullity theorem – In linear algebra, relation between 3 dimensions (by rank and nullity)\nStructure theorem for finitely generated modules over a principal ideal domain – Statement in abstract algebra\nJordan normal form – Form of a matrix indicating its eigenvalues and their algebraic multiplicities\nFrobenius normal form – Canonical form of matrices over a field (rational canonical form)\nSylvester's law of inertia – Theorem of matrix algebra of invariance properties under basis transformations\n\nAnalysis\nClassification of discontinuities – Mathematical analysis of discontinuous points\n\nDynamical systems\nClassification of Fatou components\nRatner classification theorem\n\nMathematical physics\nClassification of electromagnetic fields\nPetrov classification – Classification used in differential geometry and general relativity\nSegre classification – Algebraic classification of rank two symmetric tensors\nWigner's classification – Classification of irreducible representations of the Poincaré group\n\nSee also\nRepresentation theorem – Proof that every structure with certain properties is isomorphic to another structure\nComparison theorem\nList of manifolds\nList of theorems\n\n\n== References ==",
    "links": [
      "ADE classification",
      "Abelian group",
      "Algebraic surfaces",
      "Artin–Wedderburn theorem",
      "Bianchi classification",
      "Canonical form",
      "Classification",
      "Classification of Clifford algebras",
      "Classification of Fatou components",
      "Classification of discontinuities",
      "Classification of electromagnetic fields",
      "Classification of finite simple groups",
      "Classification of low-dimensional real Lie algebras",
      "Classification of manifolds",
      "Classification of two-dimensional closed manifolds",
      "Comparison theorem",
      "Complete set of invariants",
      "Enriques–Kodaira classification",
      "Enumeration",
      "Equivalence relation",
      "Euclidean plane isometry",
      "Finite-dimensional vector space",
      "Finitely generated abelian group",
      "Frobenius normal form",
      "Geometrization conjecture",
      "Holonomy",
      "Jordan normal form",
      "Langlands classification",
      "Lens space",
      "List of manifolds",
      "List of simple Lie groups",
      "List of theorems",
      "Mathematics",
      "Multiple transitivity",
      "Nielsen–Thurston classification",
      "Petrov classification",
      "Platonic solid",
      "Rank 3 permutation group",
      "Rank–nullity theorem",
      "Ratner's theorems",
      "Representation theorem",
      "Satake diagram",
      "Segre classification",
      "Semisimple Lie algebra",
      "Simple Lie group",
      "Structure theorem for finitely generated modules over a principal ideal domain",
      "Sylvester's law of inertia",
      "Symmetric space",
      "Wigner's classification",
      "Wikipedia:Citing sources"
    ],
    "categories": [
      "Category:All Wikipedia articles needing clarification",
      "Category:All articles lacking sources",
      "Category:Articles lacking sources from December 2009",
      "Category:Articles with short description",
      "Category:Mathematical classification systems",
      "Category:Mathematical theorems",
      "Category:Pages displaying short descriptions of redirect targets via Module:Annotated link",
      "Category:Short description matches Wikidata",
      "Category:Wikipedia articles needing clarification from October 2020"
    ]
  },
  "Clopen set": {
    "title": "Clopen set",
    "url": "https://en.wikipedia.org/wiki/Clopen_set",
    "summary": "In topology, a clopen set (a portmanteau of closed-open set) in a topological space is a set which is both open and closed.  That this is possible may seem counterintuitive, as the common meanings of open and closed are antonyms, but their mathematical definitions are not mutually exclusive.  A set is closed if its complement is open, which leaves the possibility of an open set whose complement is also open, making both sets both open and closed, and therefore clopen. As described by topologist James Munkres, unlike a door, \"a set can be open, or closed, or both, or neither!\" emphasizing that the meaning of \"open\"/\"closed\" for doors is unrelated to their meaning for sets (and so the open/closed door dichotomy does not transfer to open/closed sets). This contrast to doors gave the class of topological spaces known as \"door spaces\" their name.",
    "content": "In topology, a clopen set (a portmanteau of closed-open set) in a topological space is a set which is both open and closed.  That this is possible may seem counterintuitive, as the common meanings of open and closed are antonyms, but their mathematical definitions are not mutually exclusive.  A set is closed if its complement is open, which leaves the possibility of an open set whose complement is also open, making both sets both open and closed, and therefore clopen. As described by topologist James Munkres, unlike a door, \"a set can be open, or closed, or both, or neither!\" emphasizing that the meaning of \"open\"/\"closed\" for doors is unrelated to their meaning for sets (and so the open/closed door dichotomy does not transfer to open/closed sets). This contrast to doors gave the class of topological spaces known as \"door spaces\" their name.\n\nExamples\nIn any topological space \n  \n    \n      \n        X\n        ,\n      \n    \n    {\\displaystyle X,}\n  \n the empty set and the whole space \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n are both clopen.\nNow consider the space \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n which consists of the union of the two open intervals \n  \n    \n      \n        (\n        0\n        ,\n        1\n        )\n      \n    \n    {\\displaystyle (0,1)}\n  \n and \n  \n    \n      \n        (\n        2\n        ,\n        3\n        )\n      \n    \n    {\\displaystyle (2,3)}\n  \n of \n  \n    \n      \n        \n          R\n        \n        .\n      \n    \n    {\\displaystyle \\mathbb {R} .}\n  \n The topology on \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is inherited as the subspace topology from the ordinary topology on the real line \n  \n    \n      \n        \n          R\n        \n        .\n      \n    \n    {\\displaystyle \\mathbb {R} .}\n  \n In \n  \n    \n      \n        X\n        ,\n      \n    \n    {\\displaystyle X,}\n  \n the set \n  \n    \n      \n        (\n        0\n        ,\n        1\n        )\n      \n    \n    {\\displaystyle (0,1)}\n  \n is clopen, as is the set \n  \n    \n      \n        (\n        2\n        ,\n        3\n        )\n        .\n      \n    \n    {\\displaystyle (2,3).}\n  \n This is a quite typical example: whenever a space is made up of a finite number of disjoint connected components in this way, the components will be clopen.\nNow let \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n be an infinite set under the discrete metric – that is, two points \n  \n    \n      \n        p\n        ,\n        q\n        ∈\n        X\n      \n    \n    {\\displaystyle p,q\\in X}\n  \n have distance 1 if they're not the same point, and 0 otherwise. Under the resulting metric space, any singleton set is open; hence any set, being the union of single points, is open. Since any set is open, the complement of any set is open too, and therefore any set is closed. So, all sets in this metric space are clopen.\nAs a less trivial example, consider the space \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n of all rational numbers with their ordinary topology, and the set \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n of all positive rational numbers whose square is bigger than 2. Using the fact that \n  \n    \n      \n        \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle {\\sqrt {2}}}\n  \n is not in \n  \n    \n      \n        \n          Q\n        \n        ,\n      \n    \n    {\\displaystyle \\mathbb {Q} ,}\n  \n one can show quite easily that \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n is a clopen subset of \n  \n    \n      \n        \n          Q\n        \n        .\n      \n    \n    {\\displaystyle \\mathbb {Q} .}\n  \n (\n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n is not a clopen subset of the real line \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n; it is neither open nor closed in \n  \n    \n      \n        \n          R\n        \n        .\n      \n    \n    {\\displaystyle \\mathbb {R} .}\n  \n)\n\nProperties\nA topological space \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is connected if and only if the only clopen sets are the empty set and \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n itself.\nA set is clopen if and only if its boundary is empty.\nAny clopen set is a union of (possibly infinitely many) connected components.\nIf all connected components of \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n are open (for instance, if \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n has only finitely many components, or if \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is locally connected), then a set is clopen in \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n if and only if it is a union of connected components.\nA topological space \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is discrete if and only if all of its subsets are ",
    "links": [
      "Boolean algebra (structure)",
      "Boundary (topology)",
      "Closed set",
      "Complement (set theory)",
      "Connected component (topology)",
      "Connected space",
      "Discrete metric",
      "Discrete space",
      "Disjoint sets",
      "Door",
      "Door space",
      "Empty set",
      "Half-open interval",
      "ISBN (identifier)",
      "Infinite set",
      "Intersection (set theory)",
      "Interval (mathematics)",
      "James Munkres",
      "List of set identities and relations",
      "Locally connected",
      "Metric space",
      "Mutually exclusive",
      "OCLC (identifier)",
      "Open set",
      "Portmanteau",
      "Prentice Hall, Inc",
      "Rational number",
      "Real line",
      "Robert G. Bartle",
      "Singleton set",
      "Square (algebra)",
      "Stone's representation theorem for Boolean algebras",
      "Topological space",
      "Topological subspace",
      "Topology",
      "Union (set theory)",
      "Upper Saddle River, NJ"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:General topology",
      "Category:Pages with references accessible to Internet Archive patrons with print disabilities",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Closed set": {
    "title": "Closed set",
    "url": "https://en.wikipedia.org/wiki/Closed_set",
    "summary": "In geometry, topology, and related branches of mathematics, a closed set is a set whose complement is an open set. In a topological space, a closed set can be defined as a set which contains all its limit points. In a complete metric space, a closed set is a set which is closed under the limit operation. This should not be confused with closed manifold.\nSets that are both open and closed and are called clopen sets.",
    "content": "In geometry, topology, and related branches of mathematics, a closed set is a set whose complement is an open set. In a topological space, a closed set can be defined as a set which contains all its limit points. In a complete metric space, a closed set is a set which is closed under the limit operation. This should not be confused with closed manifold.\nSets that are both open and closed and are called clopen sets.\n\nDefinition\nGiven a topological space \n  \n    \n      \n        (\n        X\n        ,\n        τ\n        )\n      \n    \n    {\\displaystyle (X,\\tau )}\n  \n, the following statements are equivalent:\n\na set \n  \n    \n      \n        A\n        ⊆\n        X\n      \n    \n    {\\displaystyle A\\subseteq X}\n  \n is closed in \n  \n    \n      \n        X\n        .\n      \n    \n    {\\displaystyle X.}\n  \n\n  \n    \n      \n        \n          A\n          \n            c\n          \n        \n        =\n        X\n        ∖\n        A\n      \n    \n    {\\displaystyle A^{c}=X\\setminus A}\n  \n is an open subset of \n  \n    \n      \n        (\n        X\n        ,\n        τ\n        )\n      \n    \n    {\\displaystyle (X,\\tau )}\n  \n; that is, \n  \n    \n      \n        \n          A\n          \n            c\n          \n        \n        ∈\n        τ\n        .\n      \n    \n    {\\displaystyle A^{c}\\in \\tau .}\n  \n\n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n is equal to its closure in \n  \n    \n      \n        X\n        .\n      \n    \n    {\\displaystyle X.}\n  \n\n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n contains all of its limit points.\n\n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n contains all of its boundary points.\nAn alternative characterization of closed sets is available via sequences and nets.  A subset \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n of a topological space \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is closed in \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n if and only if every limit of every net of elements of \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n also belongs to \n  \n    \n      \n        A\n        .\n      \n    \n    {\\displaystyle A.}\n  \n In a first-countable space (such as a metric space), it is enough to consider only convergent sequences, instead of all nets.  One value of this characterization is that it may be used as a definition in the context of convergence spaces, which are more general than topological spaces. Notice that this characterization also depends on the surrounding space \n  \n    \n      \n        X\n        ,\n      \n    \n    {\\displaystyle X,}\n  \n because whether or not a sequence or net converges in \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n depends on what points are present in \n  \n    \n      \n        X\n        .\n      \n    \n    {\\displaystyle X.}\n  \n \nA point \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n in \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is said to be close to a subset \n  \n    \n      \n        A\n        ⊆\n        X\n      \n    \n    {\\displaystyle A\\subseteq X}\n  \n if \n  \n    \n      \n        x\n        ∈\n        \n          cl\n          \n            X\n          \n        \n        ⁡\n        A\n      \n    \n    {\\displaystyle x\\in \\operatorname {cl} _{X}A}\n  \n (or equivalently, if \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n belongs to the closure of \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n in the topological subspace \n  \n    \n      \n        A\n        ∪\n        {\n        x\n        }\n        ,\n      \n    \n    {\\displaystyle A\\cup \\{x\\},}\n  \n meaning \n  \n    \n      \n        x\n        ∈\n        \n          cl\n          \n            A\n            ∪\n            {\n            x\n            }\n          \n        \n        ⁡\n        A\n      \n    \n    {\\displaystyle x\\in \\operatorname {cl} _{A\\cup \\{x\\}}A}\n  \n where \n  \n    \n      \n        A\n        ∪\n        {\n        x\n        }\n      \n    \n    {\\displaystyle A\\cup \\{x\\}}\n  \n is endowed with the subspace topology induced on it by \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n).  \nBecause the closure of \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n in \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is thus the set of all points in \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n that are close to \n  \n    \n      \n        A\n        ,\n      \n    \n    {\\displaystyle A,}\n  \n this terminology allows for a plain English description of closed subsets: \n\na subset is closed if and only if it contains every point that is close to it.\nIn terms of net convergence, a point \n  \n    \n      \n        x\n        ∈\n        X\n      \n    \n    {\\displaystyle x\\in X}\n  \n is close to a subset \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n if and only if there exists some net (valued) in \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n that converges to \n  \n    \n      \n     ",
    "links": [
      "Algebraic topology",
      "Banach fixed-point theorem",
      "Betti number",
      "Boundary (topology)",
      "Bundle (mathematics)",
      "CW complex",
      "Cantor set",
      "Characterization (mathematics)",
      "Chern class",
      "Clopen set",
      "Clopen sets",
      "Closed (disambiguation)",
      "Closed manifold",
      "Closed map",
      "Closed region",
      "Closure (mathematics)",
      "Closure (topology)",
      "Cobordism",
      "Cohomology",
      "Combinatorial topology",
      "Compact space",
      "Complement (set theory)",
      "Complete metric space",
      "Completely regular space",
      "Connected space",
      "Continuity (topology)",
      "Continuous function",
      "Continuous map",
      "Continuum (topology)",
      "Convergence space",
      "Countable set",
      "De Rham cohomology",
      "Differentiable manifold",
      "Differential topology",
      "Digital topology",
      "Disconnected space",
      "Dover Publications",
      "Empty set",
      "Eric Schechter",
      "Euler characteristic",
      "F-sigma set",
      "Finite set",
      "First-countable space",
      "Fundamental group",
      "Gauge space",
      "General topology",
      "Geometric topology",
      "Geometry",
      "H-closed space",
      "Hausdorff space"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:General topology",
      "Category:Pages displaying short descriptions of redirect targets via Module:Annotated link",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Combinatorial topology": {
    "title": "Combinatorial topology",
    "url": "https://en.wikipedia.org/wiki/Combinatorial_topology",
    "summary": "In mathematics, combinatorial topology was an older name for algebraic topology, dating from the time when topological invariants of spaces (for example the Betti numbers) were regarded as derived from combinatorial decompositions of spaces, such as decomposition into simplicial complexes. After the proof of the simplicial approximation theorem this approach provided rigour.\nThe change of name reflected the move to organise topological classes such as cycles-modulo-boundaries explicitly into abelian groups. This point of view is often attributed to Emmy Noether, and so the change of title may reflect her influence. The transition is also attributed to the work of Heinz Hopf, who was influenced by Noether, and to Leopold Vietoris and Walther Mayer, who independently defined homology.\nA fairly precise date can be supplied in the internal notes of the Bourbaki group. While this kind of topology was still \"combinatorial\" in 1942, it had become \"algebraic\" by 1944. This corresponds also to ",
    "content": "In mathematics, combinatorial topology was an older name for algebraic topology, dating from the time when topological invariants of spaces (for example the Betti numbers) were regarded as derived from combinatorial decompositions of spaces, such as decomposition into simplicial complexes. After the proof of the simplicial approximation theorem this approach provided rigour.\nThe change of name reflected the move to organise topological classes such as cycles-modulo-boundaries explicitly into abelian groups. This point of view is often attributed to Emmy Noether, and so the change of title may reflect her influence. The transition is also attributed to the work of Heinz Hopf, who was influenced by Noether, and to Leopold Vietoris and Walther Mayer, who independently defined homology.\nA fairly precise date can be supplied in the internal notes of the Bourbaki group. While this kind of topology was still \"combinatorial\" in 1942, it had become \"algebraic\" by 1944. This corresponds also to the period where homological algebra and category theory were introduced for the study of topological spaces, and largely supplanted combinatorial methods.\nMore recently the term combinatorial topology has been revived for investigations carried out by treating topological objects as composed of pieces as in the older combinatorial topology, which is again found useful.\nAzriel Rosenfeld (1973) proposed digital topology for a type of image processing that can be considered as a new development of combinatorial topology. The digital forms of the Euler characteristic theorem and the Gauss–Bonnet theorem were obtained by Li Chen and Yongwu Rong. A 2D grid cell topology already appeared in the Alexandrov–Hopf book Topologie I (1935).\nGottfried Wilhelm Leibniz had envisioned a form of combinatorial topology as early as 1679 in his work Characteristica Geometrica.\n\nSee also\nHauptvermutung\nTopological combinatorics\nTopological graph theory\n\nNotes\nReferences\nAlexandrov, Pavel S. (1956), Combinatorial Topology Vols. I, II, III, translated by Horace Komm, Graylock Press, MR 1643155\nHilton, Peter (1988), \"A Brief, Subjective History of Homology and Homotopy Theory in This Century\", Mathematics Magazine, 60 (5), Mathematical Association of America: 282–291, doi:10.1080/0025570X.1988.11977391, JSTOR 2689545\nTeicher, Mina, ed. (1999), The Heritage of Emmy Noether, Israel Mathematical Conference Proceedings, Bar-Ilan University/American Mathematical Society/Oxford University Press, ISBN 978-0-19-851045-1, OCLC 223099225\nNovikov, Sergei P. (2001) [1994], \"Combinatorial topology\", Encyclopedia of Mathematics, EMS Press",
    "links": [
      "Abelian group",
      "Algebraic topology",
      "American Mathematical Society",
      "ArXiv (identifier)",
      "Azriel Rosenfeld",
      "Banach fixed-point theorem",
      "Bar-Ilan University",
      "Betti number",
      "Bourbaki group",
      "Bundle (mathematics)",
      "CW complex",
      "Category theory",
      "Chern class",
      "CiteSeerX (identifier)",
      "Closed set",
      "Cobordism",
      "Cohomology",
      "Compact space",
      "Connected space",
      "Continuity (topology)",
      "Continuum (topology)",
      "De Rham cohomology",
      "Differential topology",
      "Digital topology",
      "Doi (identifier)",
      "Emmy Noether",
      "Encyclopedia of Mathematics",
      "Euler characteristic",
      "European Mathematical Society",
      "Friedrich Hirzebruch",
      "Fundamental group",
      "Gauss–Bonnet theorem",
      "General topology",
      "Geometric topology",
      "Gottfried Wilhelm Leibniz",
      "Grid cell topology",
      "Hauptvermutung",
      "Hausdorff space",
      "Heinz Hopf",
      "Homological algebra",
      "Homology (mathematics)",
      "Homology group",
      "Homotopy",
      "Homotopy group",
      "ISBN (identifier)",
      "Image processing",
      "Interior (topology)",
      "Invariance of domain",
      "JSTOR (identifier)",
      "Klein bottle"
    ],
    "categories": [
      "Category:Algebraic topology",
      "Category:Articles with French-language sources (fr)",
      "Category:Articles with short description",
      "Category:Combinatorics",
      "Category:Short description matches Wikidata"
    ]
  },
  "Commutative algebra": {
    "title": "Commutative algebra",
    "url": "https://en.wikipedia.org/wiki/Commutative_algebra",
    "summary": "Commutative algebra, first known as ideal theory, is the branch of algebra that studies commutative rings, their ideals, and modules over such rings. Both algebraic geometry and algebraic number theory build on commutative algebra. Prominent examples of commutative rings include polynomial rings; rings of algebraic integers, including the ordinary integers \n  \n    \n      \n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} }\n  \n; and p-adic integers.\nCommutative algebra is the main technical tool of algebraic geometry, and many results and concepts of commutative algebra are strongly related with geometrical concepts.\nThe study of rings that are not necessarily commutative is known as noncommutative algebra; it includes ring theory, representation theory, and the theory of Banach algebras.",
    "content": "Commutative algebra, first known as ideal theory, is the branch of algebra that studies commutative rings, their ideals, and modules over such rings. Both algebraic geometry and algebraic number theory build on commutative algebra. Prominent examples of commutative rings include polynomial rings; rings of algebraic integers, including the ordinary integers \n  \n    \n      \n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} }\n  \n; and p-adic integers.\nCommutative algebra is the main technical tool of algebraic geometry, and many results and concepts of commutative algebra are strongly related with geometrical concepts.\nThe study of rings that are not necessarily commutative is known as noncommutative algebra; it includes ring theory, representation theory, and the theory of Banach algebras.\n\nOverview\nCommutative algebra is essentially the study of the rings occurring in algebraic number theory and algebraic geometry.\nSeveral concepts of commutative algebras have been developed in relation with algebraic number theory, such as Dedekind rings (the main class of commutative rings occurring in algebraic number theory), integral extensions, and valuation rings.\nPolynomial rings in several indeterminates over a field are examples of commutative rings. Since algebraic geometry is fundamentally the study of the common zeros of these rings, many results and concepts of algebraic geometry have counterparts in commutative algebra, and their names recall often their geometric origin; for example \"Krull dimension\", \"localization of a ring\", \"local ring\", \"regular ring\".\nAn affine algebraic variety corresponds to a prime ideal in a polynomial ring, and the points of such an affine variety correspond to the maximal ideals that contain this prime ideal. The Zariski topology, originally defined on an algebraic variety, has been extended to the sets of the prime ideals of any commutative ring; for this topology, the closed sets are the sets of prime ideals that contain a given ideal. \nThe spectrum of a ring is a ringed space formed by the prime ideals equipped with the Zariski topology, and the localizations of the ring at the open sets of a basis of this topology. This is the starting point of scheme theory, a generalization of algebraic geometry introduced by Grothendieck, which is strongly based on commutative algebra, and has induced, in turns, many developments of commutative algebra.\n\nHistory\nThe subject, first known as ideal theory, began with Richard Dedekind's work on ideals, itself based on the earlier work of Ernst Kummer and Leopold Kronecker. Later, David Hilbert introduced the term ring to generalize the earlier term number ring. Hilbert introduced a more abstract approach to replace the more concrete and computationally oriented methods grounded in such things as complex analysis and classical invariant theory.  In turn, Hilbert strongly influenced Emmy Noether, who recast many earlier results in terms of an ascending chain condition, now known as the Noetherian condition. Another important milestone was the work of Hilbert's student Emanuel Lasker, who introduced primary ideals and proved the first version of the Lasker–Noether theorem.\nThe main figure responsible for the birth of commutative algebra as a mature subject was Wolfgang Krull, who introduced the fundamental notions of localization and completion of a ring, as well as that of regular local rings. He established the concept of the Krull dimension of a ring, first for Noetherian rings before moving on to expand his theory to cover general valuation rings and Krull rings. To this day, Krull's principal ideal theorem is widely considered the single most important foundational theorem in commutative algebra. These results paved the way for the introduction of commutative algebra into algebraic geometry, an idea which would revolutionize the latter subject.\nMuch of the modern development of commutative algebra emphasizes modules.  Both  ideals of a ring R and R-algebras are special cases of R-modules, so module theory encompasses both ideal theory and the theory of ring extensions.  Though it was already incipient in Kronecker's work, the modern approach to commutative algebra using module theory is usually credited to Krull and Noether.\n\nMain tools and results\nNoetherian rings\nA Noetherian ring, named after Emmy Noether, is a ring in which every  ideal is finitely generated; that is, all elements of any ideal can be written as a linear combinations of a finite set of elements, with coefficients in the ring. \nMany commonly considered commutative rings are Noetherian, in particular, every field, the ring of the integer, and every polynomial ring in one or several indeterminates over them. The fact that polynomial rings over a field are Noetherian is called Hilbert's basis theorem.\nMoreover, many ring constructions preserve the Noetherian property. In particular, if a commutative ring R is Noetherian, the same is true for every polynom",
    "links": [
      "Abstract algebra",
      "Affine algebraic variety",
      "Alexander Grothendieck",
      "Algebra",
      "Algebraic fraction",
      "Algebraic geometry",
      "Algebraic integer",
      "Algebraic number field",
      "Algebraic number theory",
      "Algebraic structure",
      "Algebraic topology",
      "Algebraic varieties",
      "Analytic geometry",
      "Analytic number theory",
      "Annihilator (ring theory)",
      "Applied mathematics",
      "Arithmetic",
      "Arithmetic geometry",
      "Ascending chain condition",
      "Associated prime",
      "Associative algebra",
      "Banach algebra",
      "Basis (topology)",
      "Calculus",
      "Category of rings",
      "Category theory",
      "Clifford algebra",
      "Closed set",
      "Combinatorial commutative algebra",
      "Combinatorics",
      "Commutative algebra (structure)",
      "Commutative ring",
      "Commutator (ring theory)",
      "Completion (ring theory)",
      "Completion of a ring",
      "Complex analysis",
      "Computational complexity theory",
      "Computational mathematics",
      "Computer algebra",
      "Computer science",
      "Control theory",
      "David Eisenbud",
      "David Hilbert",
      "Dedekind ring",
      "Deligne–Mumford stack",
      "Denominator",
      "Descending chain condition",
      "Differential equation",
      "Differential geometry",
      "Differential topology"
    ],
    "categories": [
      "Category:All articles lacking in-text citations",
      "Category:Articles lacking in-text citations from June 2019",
      "Category:Articles with short description",
      "Category:Commutative algebra",
      "Category:Short description matches Wikidata"
    ]
  },
  "Compact space": {
    "title": "Compact space",
    "url": "https://en.wikipedia.org/wiki/Compact_space",
    "summary": "In mathematics, specifically general topology, compactness is a property that seeks to generalize the notion of a closed and bounded subset of Euclidean space. The idea is that a compact space has no \"punctures\" or \"missing endpoints\", i.e., it includes all limiting values of points. For example, the open interval (0,1) would not be compact because it excludes the limiting values of 0 and 1, whereas the closed interval [0,1] would be compact. Similarly, the space of rational numbers \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n is not compact, because it has infinitely many \"punctures\" corresponding to the irrational numbers, and the space of real numbers \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n is not compact either, because it excludes the two limiting values \n  \n    \n      \n        +\n        ∞\n      \n    \n    {\\displaystyle +\\infty }\n  \n and \n  \n    \n      \n        −\n        ∞\n    ",
    "content": "In mathematics, specifically general topology, compactness is a property that seeks to generalize the notion of a closed and bounded subset of Euclidean space. The idea is that a compact space has no \"punctures\" or \"missing endpoints\", i.e., it includes all limiting values of points. For example, the open interval (0,1) would not be compact because it excludes the limiting values of 0 and 1, whereas the closed interval [0,1] would be compact. Similarly, the space of rational numbers \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n is not compact, because it has infinitely many \"punctures\" corresponding to the irrational numbers, and the space of real numbers \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n is not compact either, because it excludes the two limiting values \n  \n    \n      \n        +\n        ∞\n      \n    \n    {\\displaystyle +\\infty }\n  \n and \n  \n    \n      \n        −\n        ∞\n      \n    \n    {\\displaystyle -\\infty }\n  \n. However, the extended real number line would be compact, since it contains both infinities. There are many ways to make this heuristic notion precise. These ways usually agree in a metric space, but may not be equivalent in other topological spaces.\nOne such generalization is that a topological space is sequentially compact if every infinite sequence of points sampled from the space has an infinite subsequence that converges to some point of the space. The Bolzano–Weierstrass theorem states that a subset of Euclidean space is compact in this sequential sense if and only if it is closed and bounded.  Thus, if one chooses an infinite number of points in the closed unit interval [0, 1], some of those points will get arbitrarily close to some real number in that space. \nFor instance, some of the numbers in the sequence  ⁠1/2⁠, ⁠4/5⁠, ⁠1/3⁠, ⁠5/6⁠, ⁠1/4⁠, ⁠6/7⁠, ... accumulate to 0 (while others accumulate to 1). \nSince neither 0 nor 1 are members of the open unit interval (0, 1), those same sets of points would not accumulate to any point of it, so the open unit interval is not compact. Although subsets (subspaces) of Euclidean space can be compact, the entire space itself is not compact, since it is not bounded. For example, considering \n  \n    \n      \n        \n          \n            R\n          \n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{1}}\n  \n (the real number line), the sequence of points  0,  1,  2,  3, ... has no subsequence that converges to any real number.\nCompactness was formally introduced by Maurice Fréchet in 1906 to generalize the Bolzano–Weierstrass theorem from spaces of geometrical points to spaces of functions. The Arzelà–Ascoli theorem and the Peano existence theorem exemplify applications of this notion of compactness to classical analysis. Following its initial introduction, various equivalent notions of compactness, including sequential compactness and limit point compactness, were developed in general metric spaces. In general topological spaces, however, these notions of compactness are not necessarily equivalent. The most useful notion—and the standard definition of the unqualified term compactness—is phrased in terms of the existence of finite families of open sets that \"cover\" the space, in the sense that each point of the space lies in some set contained in the family. This more subtle notion, introduced by Pavel Alexandrov and Pavel Urysohn in 1929, exhibits compact spaces as generalizations of finite sets. In spaces that are compact in this sense, it is often possible to patch together information that holds locally—that is, in a neighborhood of each point—into corresponding statements that hold throughout the space, and many theorems are of this character.\nThe term compact set is sometimes used as a synonym for compact space, but also often refers to a compact subspace of a topological space.\n\nHistorical development\nIn the 19th century, several disparate mathematical properties were understood that would later be seen as consequences of compactness.  On the one hand, Bernard Bolzano (1817) had been aware that any bounded sequence of points (in the line or plane, for instance) has a subsequence that must eventually get arbitrarily close to some other point, called a limit point. \nBolzano's proof relied on the method of bisection: the sequence was placed into an interval that was then divided into two equal parts, and a part containing infinitely many terms of the sequence was selected. \nThe process could then be repeated by dividing the resulting smaller interval into smaller and smaller parts—until it closes down on the desired limit point. The full significance of Bolzano's theorem, and its method of proof, would not emerge until almost 50 years later when it was rediscovered by Karl Weierstrass.\nIn the 1880s, it became clear that results similar to the Bolzano–Weierstrass theorem could be formulated for spaces",
    "links": [
      "Abraham Robinson",
      "Accumulation point",
      "Adele ring",
      "Alaoglu's theorem",
      "Alexander's sub-base theorem",
      "Alexandroff one-point compactification",
      "Algebraic geometry",
      "Algebraic topology",
      "Annales Scientifiques de l'École Normale Supérieure",
      "ArXiv (identifier)",
      "Arzelà–Ascoli theorem",
      "Axiom of choice",
      "Axiom of countable choice",
      "Banach algebra",
      "Banach fixed-point theorem",
      "Banach space",
      "Bernard Bolzano",
      "Betti number",
      "Bolzano–Weierstrass theorem",
      "Boolean algebra",
      "Boundary (topology)",
      "Bounded linear operator",
      "Bounded set",
      "Bundle (mathematics)",
      "CW complex",
      "Cantor set",
      "Carl Benjamin Boyer",
      "Cesare Arzelà",
      "Chern class",
      "Closed mapping",
      "Closed set",
      "Closed unit ball",
      "Cobordism",
      "Cocountable topology",
      "Cofinite topology",
      "Cohomology",
      "Combinatorial topology",
      "Commutative ring",
      "Compact operator",
      "Compactification (mathematics)",
      "Compactly generated space",
      "Compactness (disambiguation)",
      "Compactness theorem",
      "Complete accumulation point",
      "Complete lattice",
      "Complete space",
      "Completely regular space",
      "Completeness (topology)",
      "Complex number",
      "Connected space"
    ],
    "categories": [
      "Category:Articles containing French-language text",
      "Category:Articles with short description",
      "Category:Compactness (mathematics)",
      "Category:General topology",
      "Category:Properties of topological spaces",
      "Category:Short description is different from Wikidata",
      "Category:Topology",
      "Category:Wikipedia articles incorporating text from PlanetMath"
    ]
  },
  "Complex geometry": {
    "title": "Complex geometry",
    "url": "https://en.wikipedia.org/wiki/Complex_geometry",
    "summary": "In mathematics, complex geometry is the study of geometric structures and constructions arising out of, or described by, the complex numbers. In particular, complex geometry is concerned with the study of spaces such as complex manifolds and complex algebraic varieties, functions of several complex variables, and holomorphic constructions such as holomorphic vector bundles and coherent sheaves. Application of transcendental methods to algebraic geometry falls in this category, together with more geometric aspects of complex analysis.\nComplex geometry sits at the intersection of algebraic geometry, differential geometry, and complex analysis, and uses tools from all three areas. Because of the blend of techniques and ideas from various areas, problems in complex geometry are often more tractable or concrete than in general. For example, the classification of complex manifolds and complex algebraic varieties through the minimal model program and the construction of moduli spaces sets the",
    "content": "In mathematics, complex geometry is the study of geometric structures and constructions arising out of, or described by, the complex numbers. In particular, complex geometry is concerned with the study of spaces such as complex manifolds and complex algebraic varieties, functions of several complex variables, and holomorphic constructions such as holomorphic vector bundles and coherent sheaves. Application of transcendental methods to algebraic geometry falls in this category, together with more geometric aspects of complex analysis.\nComplex geometry sits at the intersection of algebraic geometry, differential geometry, and complex analysis, and uses tools from all three areas. Because of the blend of techniques and ideas from various areas, problems in complex geometry are often more tractable or concrete than in general. For example, the classification of complex manifolds and complex algebraic varieties through the minimal model program and the construction of moduli spaces sets the field apart from differential geometry, where the classification of possible smooth manifolds is a significantly harder problem. Additionally, the extra structure of complex geometry allows, especially in the compact setting, for global analytic results to be proven with great success, including Shing-Tung Yau's proof of the Calabi conjecture, the Hitchin–Kobayashi correspondence, the nonabelian Hodge correspondence, and existence results for Kähler–Einstein metrics and constant scalar curvature Kähler metrics. These results often feed back into complex algebraic geometry, and for example recently the classification of Fano manifolds using K-stability has benefited tremendously both from techniques in analysis and in pure birational geometry.\nComplex geometry has significant applications to theoretical physics, where it is essential in understanding conformal field theory, string theory, and mirror symmetry. It is often a source of examples in other areas of mathematics, including in representation theory where generalized flag varieties may be studied using complex geometry leading to the Borel–Weil–Bott theorem, or in symplectic geometry, where Kähler manifolds are symplectic, in Riemannian geometry where complex manifolds provide examples of exotic metric structures such as Calabi–Yau manifolds and hyperkähler manifolds, and in gauge theory, where holomorphic vector bundles often admit solutions to important differential equations arising out of physics such as the Yang–Mills equations. Complex geometry additionally is impactful in pure algebraic geometry, where analytic results in the complex setting such as Hodge theory of Kähler manifolds inspire understanding of Hodge structures for varieties and schemes as well as p-adic Hodge theory, deformation theory for complex manifolds inspires understanding of the deformation theory of schemes, and results about the cohomology of complex manifolds inspired the formulation of the Weil conjectures and Grothendieck's standard conjectures. On the other hand, results and techniques from many of these fields often feed back into complex geometry, and for example developments in the mathematics of string theory and mirror symmetry have revealed much about the nature of Calabi–Yau manifolds, which string theorists predict should have the structure of Lagrangian fibrations through the SYZ conjecture, and the development of Gromov–Witten theory of symplectic manifolds has led to advances in enumerative geometry of complex varieties.\nThe Hodge conjecture, one of the millennium prize problems, is a problem in complex geometry.\n\nIdea\nBroadly, complex geometry is concerned with spaces and geometric objects which are modelled, in some sense, on the complex plane. Features of the complex plane and complex analysis of a single variable, such as an intrinsic notion of orientability (that is, being able to consistently rotate 90 degrees counterclockwise at every point in the complex plane), and the rigidity of holomorphic functions (that is, the existence of a single complex derivative implies complex differentiability to all orders) are seen to manifest in all forms of the study of complex geometry. As an example, every complex manifold is canonically orientable, and a form of Liouville's theorem holds on compact complex manifolds or projective complex algebraic varieties.\nComplex geometry is different in flavour to what might be called real geometry, the study of spaces based around the geometric and analytical properties of the real number line. For example, whereas smooth manifolds admit partitions of unity, collections of smooth functions which can be identically equal to one on some open set, and identically zero elsewhere, complex manifolds admit no such collections of holomorphic functions. Indeed, this is the manifestation of the identity theorem, a typical result in complex analysis of a single variable. In some sense, the novelty of complex geometry may be traced back to this fundament",
    "links": [
      "Abelian varieties",
      "Affine geometry",
      "Ahmes",
      "Algebraic geometry",
      "Algebraic geometry and analytic geometry",
      "Algebraic variety",
      "Alhazen",
      "Almost complex manifold",
      "Altitude (triangle)",
      "Ample line bundle",
      "Analysis",
      "Analytic geometry",
      "Analytic varieties",
      "Analytic variety",
      "Angle",
      "Apollonius of Perga",
      "Archimedes",
      "Area",
      "Area of a circle",
      "Arithmetic geometry",
      "Aryabhata",
      "Atiyah-Singer index theorem",
      "Baudhayana",
      "Before Common Era",
      "Bernhard Riemann",
      "Biholomorphism",
      "Birational geometry",
      "Bivector (complex)",
      "Blaise Pascal",
      "Borel–Weil–Bott theorem",
      "Brahmagupta",
      "Calabi conjecture",
      "Calabi–Yau manifold",
      "Cambridge University Press",
      "Carl Friedrich Gauss",
      "Cartan's theorems A and B",
      "Christiaan Huygens",
      "Circle",
      "Circumference",
      "Classification theorem",
      "Coherent sheaf",
      "Coherent sheaves",
      "Cohomology",
      "Cohomology groups",
      "Compact space",
      "Complex-analytic variety",
      "Complex Lie group",
      "Complex algebraic variety",
      "Complex analysis",
      "Complex analytic space"
    ],
    "categories": [
      "Category:Algebraic geometry",
      "Category:All Wikipedia articles written in American English",
      "Category:Articles with short description",
      "Category:Complex geometry",
      "Category:Complex manifolds",
      "Category:Pages using sidebar with the child parameter",
      "Category:Several complex variables",
      "Category:Short description matches Wikidata",
      "Category:Use American English from March 2019"
    ]
  },
  "Augustin-Louis Cauchy": {
    "title": "Augustin-Louis Cauchy",
    "url": "https://en.wikipedia.org/wiki/Augustin-Louis_Cauchy",
    "summary": "Baron Augustin-Louis Cauchy  (UK:   KOH-shee,    KOW-shee, US:  koh-SHEE; French: [oɡystɛ̃ lwi  koʃi]; 21 August 1789 – 23 May 1857) was a French mathematician, engineer, and physicist. He was one of the first to rigorously state and prove the key theorems of calculus (thereby creating real analysis), pioneered the field complex analysis, and the study of permutation groups in abstract algebra. Cauchy also contributed to a number of topics in mathematical physics, notably continuum mechanics.\nA profound mathematician, Cauchy had a great influence over his contemporaries and successors; Hans Freudenthal stated:\n\n\"More concepts and theorems have been named for Cauchy than for any other mathematician (in elasticity alone there are sixteen concepts and theorems named for Cauchy).\"\nCauchy was a prolific worker; he wrote approximately eight hundred research articles and five complete textbooks on a variety of topics in the fields of mathematics and mathematical physics.",
    "content": "Baron Augustin-Louis Cauchy  (UK:   KOH-shee,    KOW-shee, US:  koh-SHEE; French: [oɡystɛ̃ lwi  koʃi]; 21 August 1789 – 23 May 1857) was a French mathematician, engineer, and physicist. He was one of the first to rigorously state and prove the key theorems of calculus (thereby creating real analysis), pioneered the field complex analysis, and the study of permutation groups in abstract algebra. Cauchy also contributed to a number of topics in mathematical physics, notably continuum mechanics.\nA profound mathematician, Cauchy had a great influence over his contemporaries and successors; Hans Freudenthal stated:\n\n\"More concepts and theorems have been named for Cauchy than for any other mathematician (in elasticity alone there are sixteen concepts and theorems named for Cauchy).\"\nCauchy was a prolific worker; he wrote approximately eight hundred research articles and five complete textbooks on a variety of topics in the fields of mathematics and mathematical physics.\n\nBiography\nYouth and education\nCauchy was the son of Louis François Cauchy (1760–1848) and Marie-Madeleine Desestre. Cauchy had two brothers: Alexandre Laurent Cauchy (1792–1857), who became a president of a division of the court of appeal in 1847 and a judge of the court of cassation in 1849, and Eugene François Cauchy (1802–1877), a publicist who also wrote several mathematical works. From his childhood he was good at math.\nCauchy married Aloise de Bure in 1818. She was a close relative of the publisher who published most of Cauchy's works. They had two daughters, Marie Françoise Alicia (1819) and Marie Mathilde (1823).\nCauchy's father was a highly ranked official in the Parisian police of the \nAncien Régime, but lost this position due to the French Revolution (14 July 1789), which broke out one month before Augustin-Louis was born. The Cauchy family survived the revolution and the following Reign of Terror during 1793–94 by escaping to Arcueil, where Cauchy received his first education, from his father. After the execution of Robespierre in 1794, it was safe for the family to return to Paris. There, Louis-François Cauchy found a bureaucratic job in 1800, and quickly advanced his career. When Napoleon came to power in 1799, Louis-François Cauchy was further promoted, and became Secretary-General of the Senate, working directly under Laplace (who is now better known for his work on mathematical physics). The mathematician Lagrange was also a friend of the Cauchy family.\nOn Lagrange's advice, Augustin-Louis was enrolled in the École Centrale du Panthéon, the best secondary school of Paris at that time, in the fall of 1802. Most of the curriculum consisted of classical languages; the ambitious Cauchy, being a brilliant student, won many prizes in Latin and the humanities. In spite of these successes, Cauchy chose an engineering career, and prepared himself for the entrance examination to the École Polytechnique.\nIn 1805, he placed second of 293 applicants on this exam and was admitted. One of the main purposes of this school was to give future civil and military engineers a high-level scientific and mathematical education. The school functioned under military discipline, which caused Cauchy some problems in adapting. Nevertheless, he completed the course in 1807, at age 18, and went on to the École des Ponts et Chaussées (School for Bridges and Roads). He graduated in civil engineering, with the highest honors.\n\nEngineering days\nAfter finishing school in 1810, Cauchy accepted a job as a junior engineer in Cherbourg, where Napoleon intended to build a naval base. Here Cauchy stayed for three years, and was assigned the Ourcq Canal project and the Saint-Cloud Bridge project, and worked at the Harbor of Cherbourg. Although he had an extremely busy managerial job, he still found time to prepare three mathematical manuscripts, which he submitted to the Première Classe (First Class) of the Institut de France. Cauchy's first two manuscripts (on polyhedra) were accepted; the third one (on directrices of conic sections) was rejected.\nIn September 1812, at 23 years old, Cauchy returned to Paris after becoming ill from overwork. Another reason for his return to the capital was that he was losing interest in his engineering job, being more and more attracted to the abstract beauty of mathematics; in Paris, he would have a much better chance to find a mathematics related position. When his health improved in 1813, Cauchy chose not to return to Cherbourg. Although he formally kept his engineering position, he was transferred from the payroll of the Ministry of the Marine to the Ministry of the Interior. The next three years Cauchy was mainly on unpaid sick leave; he spent his time fruitfully, working on mathematics (on the related topics of symmetric functions, the symmetric group and the theory of higher-order algebraic equations). He attempted admission to the First Class of the Institut de France but failed on three different occasions between 1813 and 1815. ",
    "links": [
      "Abraham Robinson",
      "Absolute convergence",
      "Abstract algebra",
      "Académie des Sciences",
      "Adequality",
      "Alexandre Borovik",
      "American Academy of Arts and Sciences",
      "American English",
      "American Philosophical Society",
      "Analyse des Infiniment Petits pour l'Intelligence des Lignes Courbes",
      "Analytic function",
      "Ancien Régime",
      "ArXiv (identifier)",
      "Arcueil",
      "Argument principle",
      "Augustin-Jean Fresnel",
      "Baron",
      "Bibliothèque du Roi",
      "British English",
      "Bureau des Longitudes",
      "Calculus",
      "Canal de l'Ourcq",
      "Catholic Encyclopedia",
      "Cauchy's convergence test",
      "Cauchy's equation",
      "Cauchy's functional equation",
      "Cauchy's integral formula",
      "Cauchy's integral theorem",
      "Cauchy's radical test",
      "Cauchy's theorem (geometry)",
      "Cauchy's theorem (group theory)",
      "Cauchy (crater)",
      "Cauchy (disambiguation)",
      "Cauchy argument principle",
      "Cauchy boundary condition",
      "Cauchy condensation test",
      "Cauchy determinant",
      "Cauchy distribution",
      "Cauchy formula for repeated integration",
      "Cauchy horizon",
      "Cauchy momentum equation",
      "Cauchy principal value",
      "Cauchy problem",
      "Cauchy product",
      "Cauchy sequence",
      "Cauchy stress tensor",
      "Cauchy surface",
      "Cauchy–Binet formula",
      "Cauchy–Euler equation",
      "Cauchy–Frobenius lemma"
    ],
    "categories": [
      "Category:1789 births",
      "Category:1857 deaths",
      "Category:19th-century French mathematicians",
      "Category:Academic staff of the University of Turin",
      "Category:Articles incorporating a citation from the 1913 Catholic Encyclopedia with Wikisource reference",
      "Category:Articles with Internet Archive links",
      "Category:Articles with hCards",
      "Category:Articles with short description",
      "Category:Augustin-Louis Cauchy",
      "Category:CS1: long volume value"
    ]
  },
  "Betti number": {
    "title": "Betti number",
    "url": "https://en.wikipedia.org/wiki/Betti_number",
    "summary": "In algebraic topology, the Betti numbers are used to distinguish topological spaces based on the connectivity of n-dimensional simplicial complexes. For the most reasonable finite-dimensional spaces (such as compact manifolds, finite simplicial complexes or CW complexes), the sequence of Betti numbers is 0 from some point onward (Betti numbers vanish above the dimension of a space), and they are all finite.\nThe nth Betti number represents the rank of the nth homology group, denoted Hn, which tells us the maximum number of cuts that can be made before separating a surface into two pieces or 0-cycles, 1-cycles, etc. For example, if \n  \n    \n      \n        \n          H\n          \n            n\n          \n        \n        (\n        X\n        )\n        ≅\n        0\n      \n    \n    {\\displaystyle H_{n}(X)\\cong 0}\n  \n then \n  \n    \n      \n        \n          b\n          \n            n\n          \n        \n        (\n        X\n        )\n        =\n        0\n      \n    \n    {\\displaystyle b_{n}(X)=0",
    "content": "In algebraic topology, the Betti numbers are used to distinguish topological spaces based on the connectivity of n-dimensional simplicial complexes. For the most reasonable finite-dimensional spaces (such as compact manifolds, finite simplicial complexes or CW complexes), the sequence of Betti numbers is 0 from some point onward (Betti numbers vanish above the dimension of a space), and they are all finite.\nThe nth Betti number represents the rank of the nth homology group, denoted Hn, which tells us the maximum number of cuts that can be made before separating a surface into two pieces or 0-cycles, 1-cycles, etc. For example, if \n  \n    \n      \n        \n          H\n          \n            n\n          \n        \n        (\n        X\n        )\n        ≅\n        0\n      \n    \n    {\\displaystyle H_{n}(X)\\cong 0}\n  \n then \n  \n    \n      \n        \n          b\n          \n            n\n          \n        \n        (\n        X\n        )\n        =\n        0\n      \n    \n    {\\displaystyle b_{n}(X)=0}\n  \n, if \n  \n    \n      \n        \n          H\n          \n            n\n          \n        \n        (\n        X\n        )\n        ≅\n        \n          Z\n        \n      \n    \n    {\\displaystyle H_{n}(X)\\cong \\mathbb {Z} }\n  \n then \n  \n    \n      \n        \n          b\n          \n            n\n          \n        \n        (\n        X\n        )\n        =\n        1\n      \n    \n    {\\displaystyle b_{n}(X)=1}\n  \n, if \n  \n    \n      \n        \n          H\n          \n            n\n          \n        \n        (\n        X\n        )\n        ≅\n        \n          Z\n        \n        ⊕\n        \n          Z\n        \n      \n    \n    {\\displaystyle H_{n}(X)\\cong \\mathbb {Z} \\oplus \\mathbb {Z} }\n  \n then \n  \n    \n      \n        \n          b\n          \n            n\n          \n        \n        (\n        X\n        )\n        =\n        2\n      \n    \n    {\\displaystyle b_{n}(X)=2}\n  \n, if \n  \n    \n      \n        \n          H\n          \n            n\n          \n        \n        (\n        X\n        )\n        ≅\n        \n          Z\n        \n        ⊕\n        \n          Z\n        \n        ⊕\n        \n          Z\n        \n      \n    \n    {\\displaystyle H_{n}(X)\\cong \\mathbb {Z} \\oplus \\mathbb {Z} \\oplus \\mathbb {Z} }\n  \n then \n  \n    \n      \n        \n          b\n          \n            n\n          \n        \n        (\n        X\n        )\n        =\n        3\n      \n    \n    {\\displaystyle b_{n}(X)=3}\n  \n, etc. Note that only the ranks of infinite groups are considered, so for example if  \n  \n    \n      \n        \n          H\n          \n            n\n          \n        \n        (\n        X\n        )\n        ≅\n        \n          \n            Z\n          \n          \n            k\n          \n        \n        ⊕\n        \n          Z\n        \n        \n          /\n        \n        (\n        2\n        )\n      \n    \n    {\\displaystyle H_{n}(X)\\cong \\mathbb {Z} ^{k}\\oplus \\mathbb {Z} /(2)}\n  \n, where \n  \n    \n      \n        \n          Z\n        \n        \n          /\n        \n        (\n        2\n        )\n      \n    \n    {\\displaystyle \\mathbb {Z} /(2)}\n  \n is the finite cyclic group of order 2, then \n  \n    \n      \n        \n          b\n          \n            n\n          \n        \n        (\n        X\n        )\n        =\n        k\n      \n    \n    {\\displaystyle b_{n}(X)=k}\n  \n. These finite components of the homology groups are their torsion subgroups, and they are denoted by torsion coefficients.\nThe term \"Betti number\" was coined by Henri Poincaré after Enrico Betti. The modern formulation is due to Emmy Noether. Betti numbers are used today in fields such as simplicial homology, computer science and digital images.\n\nGeometric interpretation\nInformally, the kth Betti number refers to the number of k-dimensional holes on a topological surface. A \"k-dimensional hole\" is a k-dimensional cycle that is not a boundary of a (k+1)-dimensional object.\nThe first few Betti numbers have the following definitions for 0-dimensional, 1-dimensional, and 2-dimensional simplicial complexes:\n\nb0 is the number of connected components;\nb1 is the number of one-dimensional or \"circular\" holes;\nb2 is the number of two-dimensional \"voids\" or \"cavities\".\nThus, for example, a torus has one connected surface component so b0 = 1, two \"circular\" holes (one equatorial and one meridional) so b1 = 2, and a single cavity enclosed within the surface so b2 = 1.\nAnother interpretation of bk is the maximum number of k-dimensional curves that can be removed while the object remains connected. For example, the torus remains connected after removing two 1-dimensional curves (equatorial and meridional) so b1 = 2.\nThe two-dimensional Betti numbers are easier to understand because we can see the world in 0, 1, 2, and 3-dimensions.\n\nFormal definition\nFor a non-negative integer k, the kth Betti number bk(X) of the space X is defined as the rank (number of linearly independent generators) of the abelian group Hk(X), the kth homology group of X. The kth homology group is \n  \n    \n      \n        \n          H\n          \n  ",
    "links": [
      "Abelian group",
      "Algebraic topology",
      "Banach fixed-point theorem",
      "Binomial coefficient",
      "Bundle (mathematics)",
      "CW complex",
      "CW complexes",
      "Characteristic (field)",
      "Characteristic p",
      "Chern class",
      "Closed differential form",
      "Closed manifold",
      "Closed set",
      "Cobordism",
      "Cohomology",
      "Combinatorial topology",
      "Compact manifold",
      "Compact space",
      "Complex projective space",
      "Computer science",
      "Connected space",
      "Continuity (topology)",
      "Continuum (topology)",
      "Critical point (mathematics)",
      "Cyclic group",
      "Cyclomatic complexity",
      "Cyclomatic number",
      "De Rham's theorem",
      "De Rham cohomology",
      "De Rham complex",
      "Differential topology",
      "Digital images",
      "Digital topology",
      "Doi (identifier)",
      "Edward Witten",
      "Emmy Noether",
      "Enrico Betti",
      "Euler characteristic",
      "Exact differential form",
      "Exterior derivative",
      "Field (mathematics)",
      "Finite cyclic group",
      "Fundamental group",
      "General topology",
      "Generating function",
      "Geometric topology",
      "Graph homology",
      "Gustav Kirchhoff",
      "Harmonic form",
      "Hausdorff space"
    ],
    "categories": [
      "Category:Algebraic topology",
      "Category:Articles with short description",
      "Category:Generating functions",
      "Category:Graph invariants",
      "Category:Short description is different from Wikidata",
      "Category:Topological graph theory"
    ]
  },
  "Category theory": {
    "title": "Category theory",
    "url": "https://en.wikipedia.org/wiki/Category_theory",
    "summary": "Category theory is a general theory of mathematical structures and their relations. It was introduced by Samuel Eilenberg and Saunders Mac Lane in the middle of the 20th century in their foundational work on algebraic topology. Category theory is used in most areas of mathematics. In particular, many constructions of new mathematical objects from previous ones that appear similarly in several contexts are conveniently expressed and unified in terms of categories. Examples include quotient spaces, direct products, completion, and duality.\nMany areas of computer science also rely on category theory, such as functional programming and semantics.\nA category is formed by two sorts of objects: the objects of the category, and the morphisms, which relate two objects called the source and the target of the morphism. Metaphorically, a morphism is an arrow that maps its source to its target. Morphisms can be composed if the target of the first morphism equals the source of the second one. Morphi",
    "content": "Category theory is a general theory of mathematical structures and their relations. It was introduced by Samuel Eilenberg and Saunders Mac Lane in the middle of the 20th century in their foundational work on algebraic topology. Category theory is used in most areas of mathematics. In particular, many constructions of new mathematical objects from previous ones that appear similarly in several contexts are conveniently expressed and unified in terms of categories. Examples include quotient spaces, direct products, completion, and duality.\nMany areas of computer science also rely on category theory, such as functional programming and semantics.\nA category is formed by two sorts of objects: the objects of the category, and the morphisms, which relate two objects called the source and the target of the morphism. Metaphorically, a morphism is an arrow that maps its source to its target. Morphisms can be composed if the target of the first morphism equals the source of the second one. Morphism composition has similar properties as function composition (associativity and existence of an identity morphism for each object). Morphisms are often some sort of functions, but this is not always the case. For example, a monoid may be viewed as a category with a single object, whose morphisms are the elements of the monoid.\nThe second fundamental concept of category theory is the concept of a functor, which plays the role of a morphism between two categories \n  \n    \n      \n        \n          \n            \n              C\n            \n          \n          \n            1\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {C}}_{1}}\n  \n and \n  \n    \n      \n        \n          \n            \n              C\n            \n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {C}}_{2}}\n  \n: it maps objects of \n  \n    \n      \n        \n          \n            \n              C\n            \n          \n          \n            1\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {C}}_{1}}\n  \n to objects of \n  \n    \n      \n        \n          \n            \n              C\n            \n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {C}}_{2}}\n  \n and morphisms of \n  \n    \n      \n        \n          \n            \n              C\n            \n          \n          \n            1\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {C}}_{1}}\n  \n to morphisms of \n  \n    \n      \n        \n          \n            \n              C\n            \n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {C}}_{2}}\n  \n in such a way that sources are mapped to sources, and targets are mapped to targets (or, in the case of a contravariant functor, sources are mapped to targets and vice-versa). A third fundamental concept is a natural transformation that may be viewed as a morphism of functors.\n\nCategories, objects, and morphisms\nCategories\nA category \n  \n    \n      \n        \n          \n            C\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {C}}}\n  \n consists of the following three mathematical entities:\n\nA class \n  \n    \n      \n        \n          ob\n        \n        (\n        \n          \n            C\n          \n        \n        )\n      \n    \n    {\\displaystyle {\\text{ob}}({\\mathcal {C}})}\n  \n, whose elements are called objects;\nA class \n  \n    \n      \n        \n          hom\n        \n        (\n        \n          \n            C\n          \n        \n        )\n      \n    \n    {\\displaystyle {\\text{hom}}({\\mathcal {C}})}\n  \n, whose elements are called morphisms or maps or arrows. Each morphism \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n has a source object  \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n and target object \n  \n    \n      \n        b\n      \n    \n    {\\displaystyle b}\n  \n.The expression \n  \n    \n      \n        f\n        :\n        a\n        →\n        b\n      \n    \n    {\\displaystyle f:a\\rightarrow b}\n  \n would be verbally stated as \"\n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n is a morphism from a to b\".The expression \n  \n    \n      \n        \n          hom\n        \n        (\n        a\n        ,\n        b\n        )\n      \n    \n    {\\displaystyle {\\text{hom}}(a,b)}\n  \n – alternatively expressed as \n  \n    \n      \n        \n          \n            hom\n          \n          \n            \n              C\n            \n          \n        \n        (\n        a\n        ,\n        b\n        )\n      \n    \n    {\\displaystyle {\\text{hom}}_{\\mathcal {C}}(a,b)}\n  \n, \n  \n    \n      \n        \n          mor\n        \n        (\n        a\n        ,\n        b\n        )\n      \n    \n    {\\displaystyle {\\text{mor}}(a,b)}\n  \n, or \n  \n    \n      \n        \n          \n            C\n          \n        \n        (\n        a\n        ,\n        b\n        )\n      \n    \n    {\\displaystyle {\\mathcal {C}}(a,b)}\n  \n – denotes the hom-class of all morphisms from \n  \n  ",
    "links": [
      "2-category",
      "2-functor",
      "2-group",
      "2-ring",
      "3-category",
      "ACM Computing Classification System",
      "Abelian category",
      "Abstract algebra",
      "Additive category",
      "Adjoint functors",
      "Algebra",
      "Algebraic category",
      "Algebraic geometry",
      "Algebraic number theory",
      "Algebraic structure",
      "Algebraic topology",
      "Algorithm",
      "Algorithm design",
      "Algorithmic efficiency",
      "Analysis of algorithms",
      "Analytic geometry",
      "Analytic number theory",
      "Application security",
      "Applied category theory",
      "Applied mathematics",
      "ArXiv (identifier)",
      "Arithmetic",
      "Arithmetic geometry",
      "Artificial intelligence",
      "Associativity",
      "Augmented reality",
      "Automata theory",
      "Automated planning and scheduling",
      "Automorphism",
      "Axiom of reducibility",
      "Axiomatic set theory",
      "Axiomatic system",
      "Benjamin C. Pierce",
      "Bibcode (identifier)",
      "Bicategory",
      "Binary operation",
      "Calculus",
      "Cambridge University Press",
      "Carlos Simpson",
      "Cartesian closed category",
      "Categorical abstract machine",
      "Categorical logic",
      "Categorical theory",
      "Categories for the Working Mathematician",
      "Categorification"
    ],
    "categories": [
      "Category:All articles needing additional references",
      "Category:All articles with unsourced statements",
      "Category:Articles needing additional references from November 2015",
      "Category:Articles needing additional references from November 2024",
      "Category:Articles with Stanford Encyclopedia of Philosophy links",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from February 2020",
      "Category:Articles with unsourced statements from June 2024",
      "Category:CS1 interwiki-linked names",
      "Category:Category theory"
    ]
  },
  "Computational complexity theory": {
    "title": "Computational complexity theory",
    "url": "https://en.wikipedia.org/wiki/Computational_complexity_theory",
    "summary": "In theoretical computer science and mathematics, computational complexity theory focuses on classifying computational problems according to their resource usage, and explores the relationships between these classifications. A computational problem is a task solved by a computer. A computation problem is solvable by mechanical application of mathematical steps, such as an algorithm.\nA problem is regarded as inherently difficult if its solution requires significant resources, whatever the algorithm used. The theory formalizes this intuition, by introducing mathematical models of computation to study these problems and quantifying their computational complexity, i.e., the amount of resources needed to solve them, such as time and storage. Other measures of complexity are also used, such as the amount of communication (used in communication complexity), the number of gates in a circuit (used in circuit complexity) and the number of processors (used in parallel computing). One of the roles ",
    "content": "In theoretical computer science and mathematics, computational complexity theory focuses on classifying computational problems according to their resource usage, and explores the relationships between these classifications. A computational problem is a task solved by a computer. A computation problem is solvable by mechanical application of mathematical steps, such as an algorithm.\nA problem is regarded as inherently difficult if its solution requires significant resources, whatever the algorithm used. The theory formalizes this intuition, by introducing mathematical models of computation to study these problems and quantifying their computational complexity, i.e., the amount of resources needed to solve them, such as time and storage. Other measures of complexity are also used, such as the amount of communication (used in communication complexity), the number of gates in a circuit (used in circuit complexity) and the number of processors (used in parallel computing). One of the roles of computational complexity theory is to determine the practical limits on what computers can and cannot do. The P versus NP problem, one of the seven Millennium Prize Problems, is part of the field of computational complexity.\nClosely related fields in theoretical computer science are analysis of algorithms and computability theory. A key distinction between analysis of algorithms and computational complexity theory is that the former is devoted to analyzing the amount of resources needed by a particular algorithm to solve a problem, whereas the latter asks a more general question about all possible algorithms that could be used to solve the same problem. More precisely, computational complexity theory tries to classify problems that can or cannot be solved with appropriately restricted resources. In turn, imposing restrictions on the available resources is what distinguishes computational complexity from computability theory: the latter theory asks what kinds of problems can, in principle, be solved algorithmically.\n\nComputational problems\nProblem instances\nA computational problem can be viewed as an infinite collection of instances together with a set (possibly empty) of solutions for every instance. The input string for a computational problem is referred to as a problem instance, and should not be confused with the problem itself. In computational complexity theory, a problem refers to the abstract question to be solved. In contrast, an instance of this problem is a rather concrete utterance, which can serve as the input for a decision problem. For example, consider the problem of primality testing. The instance is a number (e.g., 15) and the solution is \"yes\" if the number is prime and \"no\" otherwise (in this case, 15 is not prime and the answer is \"no\"). Stated another way, the instance is a particular input to the problem, and the solution is the output corresponding to the given input.\nTo further highlight the difference between a problem and an instance, consider the following instance of the decision version of the travelling salesman problem: Is there a route of at most 2000 kilometres passing through all of Germany's 14 largest cities? The quantitative answer to this particular problem instance is of little use for solving other instances of the problem, such as asking for a round trip through all sites in Milan whose total length is at most 10 km. For this reason, complexity theory addresses computational problems and not particular problem instances.\n\nRepresenting problem instances\nWhen considering computational problems, a problem instance is a string over an alphabet. Usually, the alphabet is taken to be the binary alphabet (i.e., the set {0,1}), and thus the strings are bitstrings. As in a real-world computer, mathematical objects other than bitstrings must be suitably encoded. For example, integers can be represented in binary notation, and graphs can be encoded directly via their adjacency matrices, or by encoding their adjacency lists in binary.\nEven though some proofs of complexity-theoretic theorems regularly assume some concrete choice of input encoding, one tries to keep the discussion abstract enough to be independent of the choice of encoding. This can be achieved by ensuring that different representations can be transformed into each other efficiently.\n\nDecision problems as formal languages\nDecision problems are one of the central objects of study in computational complexity theory. A decision problem is a type of computational problem where the answer is either yes or no (alternatively, 1 or 0). A decision problem can be viewed as a formal language, where the members of the language are instances whose output is yes, and the non-members are those instances whose output is no. The objective is to decide, with the aid of an algorithm, whether a given input string is a member of the formal language under consideration. If the algorithm deciding this problem returns the answer yes, the algorithm is sai",
    "links": [
      "2-EXPTIME",
      "AC0",
      "ACC0",
      "ACM Computing Classification System",
      "AC (complexity)",
      "ALL (complexity)",
      "AM (complexity)",
      "APX",
      "Abstract machine",
      "Adjacency list",
      "Adjacency matrix",
      "Age of the universe",
      "Alan Turing",
      "Algorithm",
      "Algorithm design",
      "Algorithmic efficiency",
      "Alphabet (computer science)",
      "Alternating Turing machine",
      "Amortized analysis",
      "Analog computation",
      "Analysis of algorithms",
      "Application security",
      "ArXiv (identifier)",
      "Arithmetical hierarchy",
      "Arthur Jaffe",
      "Arthur–Merlin protocol",
      "Artificial intelligence",
      "Augmented reality",
      "Automata theory",
      "Automated planning and scheduling",
      "Axiom",
      "BPP (complexity)",
      "BQP",
      "Best, worst and average case",
      "Bibcode (identifier)",
      "Big O notation",
      "Binary notation",
      "Biology",
      "Bitstring",
      "Blum's speedup theorem",
      "Blum axioms",
      "Blum complexity axioms",
      "Bonnie Berger",
      "Boolean circuit",
      "Boolean hierarchy",
      "Boolean satisfiability problem",
      "Boris Trakhtenbrot",
      "CC (complexity)",
      "Cellular automata",
      "Christos Papadimitriou"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1: long volume value",
      "Category:CS1 maint: publisher location",
      "Category:Commons category link from Wikidata",
      "Category:Computational complexity theory",
      "Category:Computational fields of study",
      "Category:Short description is different from Wikidata",
      "Category:Use mdy dates from September 2017"
    ]
  },
  "Algebraic integer": {
    "title": "Algebraic integer",
    "url": "https://en.wikipedia.org/wiki/Algebraic_integer",
    "summary": "In algebraic number theory, an algebraic integer is a complex number that is integral over the integers. That is, an algebraic integer is a complex root of some monic polynomial (a polynomial whose leading coefficient is 1) whose coefficients are integers. The set of all algebraic integers A is closed under addition, subtraction and multiplication and therefore is a commutative subring of the complex numbers.\nThe ring of integers of a number field K, denoted by OK, is the intersection of K and A: it can also be characterized as the maximal order of the field K. Each algebraic integer belongs to the ring of integers of some number field. A number α is an algebraic integer if and only if the ring \n  \n    \n      \n        \n          Z\n        \n        [\n        α\n        ]\n      \n    \n    {\\displaystyle \\mathbb {Z} [\\alpha ]}\n  \n is finitely generated as an abelian group, which is to say, as a \n  \n    \n      \n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} }\n  \n-mo",
    "content": "In algebraic number theory, an algebraic integer is a complex number that is integral over the integers. That is, an algebraic integer is a complex root of some monic polynomial (a polynomial whose leading coefficient is 1) whose coefficients are integers. The set of all algebraic integers A is closed under addition, subtraction and multiplication and therefore is a commutative subring of the complex numbers.\nThe ring of integers of a number field K, denoted by OK, is the intersection of K and A: it can also be characterized as the maximal order of the field K. Each algebraic integer belongs to the ring of integers of some number field. A number α is an algebraic integer if and only if the ring \n  \n    \n      \n        \n          Z\n        \n        [\n        α\n        ]\n      \n    \n    {\\displaystyle \\mathbb {Z} [\\alpha ]}\n  \n is finitely generated as an abelian group, which is to say, as a \n  \n    \n      \n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} }\n  \n-module.\n\nDefinitions\nThe following are equivalent definitions of an algebraic integer. Let K be a number field (i.e., a finite extension of \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n, the field of rational numbers), in other words, \n  \n    \n      \n        K\n        =\n        \n          Q\n        \n        (\n        θ\n        )\n      \n    \n    {\\displaystyle K=\\mathbb {Q} (\\theta )}\n  \n for some algebraic number \n  \n    \n      \n        θ\n        ∈\n        \n          C\n        \n      \n    \n    {\\displaystyle \\theta \\in \\mathbb {C} }\n  \n by the primitive element theorem.\n\nα ∈ K is an algebraic integer if there exists a monic polynomial \n  \n    \n      \n        f\n        (\n        x\n        )\n        ∈\n        \n          Z\n        \n        [\n        x\n        ]\n      \n    \n    {\\displaystyle f(x)\\in \\mathbb {Z} [x]}\n  \n such that f(α) = 0.\nα ∈ K is an algebraic integer if the minimal monic polynomial of α over \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n is in \n  \n    \n      \n        \n          Z\n        \n        [\n        x\n        ]\n      \n    \n    {\\displaystyle \\mathbb {Z} [x]}\n  \n.\nα ∈ K is an algebraic integer if \n  \n    \n      \n        \n          Z\n        \n        [\n        α\n        ]\n      \n    \n    {\\displaystyle \\mathbb {Z} [\\alpha ]}\n  \n is a finitely generated \n  \n    \n      \n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} }\n  \n-module.\nα ∈ K is an algebraic integer if there exists a non-zero finitely generated \n  \n    \n      \n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} }\n  \n-submodule \n  \n    \n      \n        M\n        ⊂\n        \n          C\n        \n      \n    \n    {\\displaystyle M\\subset \\mathbb {C} }\n  \n such that αM ⊆ M.\nAlgebraic integers are a special case of integral elements of a ring extension. In particular, an algebraic integer is an integral element of a finite extension \n  \n    \n      \n        K\n        \n          /\n        \n        \n          Q\n        \n      \n    \n    {\\displaystyle K/\\mathbb {Q} }\n  \n.\nNote that if P(x) is a primitive polynomial that has integer coefficients but is not monic, and P is irreducible over \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n, then none of the roots of P are algebraic integers (but are algebraic numbers). Here primitive is used in the sense that the highest common factor of the coefficients of P is 1, which is weaker than requiring the coefficients to be pairwise relatively prime.\n\nExamples\nThe only algebraic integers that are found in the set of rational numbers are the integers. In other words, the intersection of \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n and A is exactly \n  \n    \n      \n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} }\n  \n. The rational number ⁠a/b⁠ is not an algebraic integer unless b divides a. The leading coefficient of the polynomial bx − a is the integer b.\nThe square root \n  \n    \n      \n        \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle {\\sqrt {n}}}\n  \n of a nonnegative integer n is an algebraic integer, but is irrational unless n is a perfect square.\nIf d is a square-free integer then the extension \n  \n    \n      \n        K\n        =\n        \n          Q\n        \n        (\n        \n          \n            d\n          \n        \n        \n        )\n      \n    \n    {\\displaystyle K=\\mathbb {Q} ({\\sqrt {d}}\\,)}\n  \n is a quadratic field of rational numbers. The ring of algebraic integers OK contains \n  \n    \n      \n        \n          \n            d\n          \n        \n      \n    \n    {\\displaystyle {\\sqrt {d}}}\n  \n since this is a root of the monic polynomial x2 − d. Moreover, if d ≡ 1 mod 4, then the element \n  \n    \n      \n        \n          \n            1\n            2\n          \n        \n        (\n        1\n        +\n        \n      ",
    "links": [
      "Abelian group",
      "Abel–Ruffini theorem",
      "Algebraic element",
      "Algebraic number",
      "Algebraic number theory",
      "Algebraically closed field",
      "Bézout domain",
      "Chebyshev nodes",
      "Commutative ring",
      "Complex number",
      "Constant term",
      "Constructible number",
      "Coprime",
      "Cyclotomic field",
      "Degree of a field extension",
      "Degree of a polynomial",
      "Dirichlet's unit theorem",
      "Divisor",
      "Doubling the cube",
      "Eisenstein integer",
      "Field (mathematics)",
      "Field extension",
      "Finite extension",
      "Finitely generated abelian group",
      "Fundamental unit (number theory)",
      "Gaussian integer",
      "Golden ratio",
      "Group of units",
      "Highest common factor",
      "ISBN (identifier)",
      "Ideal (ring theory)",
      "If and only if",
      "Integer",
      "Integral basis",
      "Integral element",
      "Integrality",
      "Integrally closed domain",
      "Intersection (set theory)",
      "Irrational number",
      "Irreducible polynomial",
      "Leading coefficient",
      "Look-and-say sequence",
      "Minimal polynomial (field theory)",
      "Modular arithmetic",
      "Module (mathematics)",
      "Monic polynomial",
      "Multiplicative inverse",
      "Number field",
      "Order (ring theory)",
      "Perron number"
    ],
    "categories": [
      "Category:Algebraic numbers",
      "Category:All Wikipedia articles written in American English",
      "Category:Articles with short description",
      "Category:Integers",
      "Category:Short description matches Wikidata",
      "Category:Use American English from January 2019",
      "Category:Use mdy dates from September 2021"
    ]
  },
  "Algebraic function field": {
    "title": "Algebraic function field",
    "url": "https://en.wikipedia.org/wiki/Algebraic_function_field",
    "summary": "In mathematics, an algebraic function field (often abbreviated as function field) of \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n variables over a field \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n is a finitely generated field extension \n  \n    \n      \n        K\n        \n          /\n        \n        k\n      \n    \n    {\\displaystyle K/k}\n  \n which has transcendence degree \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n over \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n. Equivalently, an algebraic function field of \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n variables over \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n may be defined as a finite field extension of the field \n  \n    \n      \n        K\n        =\n        k\n        (\n        \n          x\n          \n            1\n          \n        \n        ,\n        …\n        ,\n        \n          x\n          \n            n\n          \n",
    "content": "In mathematics, an algebraic function field (often abbreviated as function field) of \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n variables over a field \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n is a finitely generated field extension \n  \n    \n      \n        K\n        \n          /\n        \n        k\n      \n    \n    {\\displaystyle K/k}\n  \n which has transcendence degree \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n over \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n. Equivalently, an algebraic function field of \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n variables over \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n may be defined as a finite field extension of the field \n  \n    \n      \n        K\n        =\n        k\n        (\n        \n          x\n          \n            1\n          \n        \n        ,\n        …\n        ,\n        \n          x\n          \n            n\n          \n        \n        )\n      \n    \n    {\\displaystyle K=k(x_{1},\\dots ,x_{n})}\n  \n of rational functions in \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n variables over \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n.\n\nExample\nAs an example, in the polynomial ring \n  \n    \n      \n        k\n        [\n        x\n        ,\n        y\n        ]\n      \n    \n    {\\displaystyle k[x,y]}\n  \n consider the ideal generated by the irreducible polynomial \n  \n    \n      \n        \n          y\n          \n            2\n          \n        \n        −\n        \n          x\n          \n            3\n          \n        \n      \n    \n    {\\displaystyle y^{2}-x^{3}}\n  \n and form the field of fractions of the quotient ring \n  \n    \n      \n        k\n        [\n        x\n        ,\n        y\n        ]\n        \n          /\n        \n        (\n        \n          y\n          \n            2\n          \n        \n        −\n        \n          x\n          \n            3\n          \n        \n        )\n      \n    \n    {\\displaystyle k[x,y]/(y^{2}-x^{3})}\n  \n. This is a function field of one variable over \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n; it can also be written as \n  \n    \n      \n        k\n        (\n        x\n        )\n        (\n        \n          \n            \n              x\n              \n                3\n              \n            \n          \n        \n        )\n      \n    \n    {\\displaystyle k(x)({\\sqrt {x^{3}}})}\n  \n (with degree 2 over \n  \n    \n      \n        k\n        (\n        x\n        )\n      \n    \n    {\\displaystyle k(x)}\n  \n) or as \n  \n    \n      \n        k\n        (\n        y\n        )\n        (\n        \n          \n            \n              y\n              \n                2\n              \n            \n            \n              3\n            \n          \n        \n        )\n      \n    \n    {\\displaystyle k(y)({\\sqrt[{3}]{y^{2}}})}\n  \n (with degree 3 over \n  \n    \n      \n        k\n        (\n        y\n        )\n      \n    \n    {\\displaystyle k(y)}\n  \n). We see that the degree of an algebraic function field is not a well-defined notion.\n\nCategory structure\nThe algebraic function fields over \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n form a category; the morphisms from function field \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n to \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  \n are the ring homomorphisms \n  \n    \n      \n        f\n        :\n        K\n        →\n        L\n      \n    \n    {\\displaystyle f:K\\to L}\n  \n with \n  \n    \n      \n        f\n        (\n        a\n        )\n        =\n        a\n      \n    \n    {\\displaystyle f(a)=a}\n  \n for all \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n in \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n. All these morphisms are injective. If \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n is a function field over \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n of \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n variables, and \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  \n is a function field in \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n  \n variables, and \n  \n    \n      \n        n\n        >\n        m\n      \n    \n    {\\displaystyle n>m}\n  \n, then there are no morphisms from \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n to \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  \n.\n\nFunction fields arising from varieties, curves and Riemann surfaces\nThe function field of an algebraic variety of dimension \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n over \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n is an algebraic function field of \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n variables over \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n.\nTwo varieties are birationally equivalent if and only if their function fi",
    "links": [
      "Absolute value (algebra)",
      "Algebraic element",
      "Algebraic function",
      "Birational geometry",
      "Category (mathematics)",
      "Complex number",
      "Cryptography",
      "Discrete valuation ring",
      "Drinfeld module",
      "Elliptic curve",
      "Equivalence of categories",
      "Error correcting code",
      "Field (mathematics)",
      "Field extension",
      "Field of fractions",
      "Finite field",
      "Finite field extension",
      "Function field (scheme theory)",
      "Function field analogy",
      "Function field of an algebraic variety",
      "Global field",
      "Glossary of scheme theory",
      "Holomorphic",
      "ISBN (identifier)",
      "Ideal (ring theory)",
      "Injective function",
      "Inverse Galois problem",
      "Irreducible polynomial",
      "Klein surface",
      "Mathematics",
      "Meromorphic function",
      "Morphism (category theory)",
      "Morphism of varieties",
      "Number field",
      "Polynomial ring",
      "Prime number theorem",
      "Public key cryptography",
      "Quotient ring",
      "Rational functions",
      "Rational mapping",
      "Rational number",
      "Regular map (algebraic geometry)",
      "Regular scheme",
      "Riemann surface",
      "Ring homomorphism",
      "Scheme (mathematics)",
      "Set (mathematics)",
      "Subring",
      "Surjective",
      "Topology"
    ],
    "categories": [
      "Category:All articles needing additional references",
      "Category:Articles needing additional references from December 2021",
      "Category:Articles with short description",
      "Category:Field (mathematics)",
      "Category:Short description matches Wikidata"
    ]
  },
  "Algebraic number": {
    "title": "Algebraic number",
    "url": "https://en.wikipedia.org/wiki/Algebraic_number",
    "summary": "In mathematics, an algebraic number is a number that is a root of a non-zero polynomial in one variable with integer (or, equivalently, rational) coefficients.  For example, the golden ratio \n  \n    \n      \n        (\n        1\n        +\n        \n          \n            5\n          \n        \n        )\n        \n          /\n        \n        2\n      \n    \n    {\\displaystyle (1+{\\sqrt {5}})/2}\n  \n is an algebraic number, because it is a root of the polynomial \n  \n    \n      \n        \n          X\n          \n            2\n          \n        \n        −\n        X\n        −\n        1\n      \n    \n    {\\displaystyle X^{2}-X-1}\n  \n, i.e., a solution of the equation \n  \n    \n      \n        \n          x\n          \n            2\n          \n        \n        −\n        x\n        −\n        1\n        =\n        0\n      \n    \n    {\\displaystyle x^{2}-x-1=0}\n  \n, and the complex number \n  \n    \n      \n        1\n        +\n        i\n      \n    \n    {\\displaystyle 1+i}\n  \n is algebraic as a root of \n  \n    \n     ",
    "content": "In mathematics, an algebraic number is a number that is a root of a non-zero polynomial in one variable with integer (or, equivalently, rational) coefficients.  For example, the golden ratio \n  \n    \n      \n        (\n        1\n        +\n        \n          \n            5\n          \n        \n        )\n        \n          /\n        \n        2\n      \n    \n    {\\displaystyle (1+{\\sqrt {5}})/2}\n  \n is an algebraic number, because it is a root of the polynomial \n  \n    \n      \n        \n          X\n          \n            2\n          \n        \n        −\n        X\n        −\n        1\n      \n    \n    {\\displaystyle X^{2}-X-1}\n  \n, i.e., a solution of the equation \n  \n    \n      \n        \n          x\n          \n            2\n          \n        \n        −\n        x\n        −\n        1\n        =\n        0\n      \n    \n    {\\displaystyle x^{2}-x-1=0}\n  \n, and the complex number \n  \n    \n      \n        1\n        +\n        i\n      \n    \n    {\\displaystyle 1+i}\n  \n is algebraic as a root of \n  \n    \n      \n        \n          X\n          \n            4\n          \n        \n        +\n        4\n      \n    \n    {\\displaystyle X^{4}+4}\n  \n. Algebraic numbers include all integers, rational numbers, and n-th roots of integers.\nAlgebraic complex numbers are closed under addition, subtraction, multiplication and division, and hence form a field, denoted \n  \n    \n      \n        \n          \n            \n              Q\n            \n            ¯\n          \n        \n      \n    \n    {\\displaystyle {\\overline {\\mathbb {Q} }}}\n  \n. The set of algebraic real numbers \n  \n    \n      \n        \n          \n            \n              Q\n            \n            ¯\n          \n        \n        ∩\n        \n          R\n        \n      \n    \n    {\\displaystyle {\\overline {\\mathbb {Q} }}\\cap \\mathbb {R} }\n  \n is also a field.\nNumbers which are not algebraic are called transcendental and include π and e. There are countably many algebraic numbers, hence almost all real (or complex) numbers (in the sense of Lebesgue measure) are transcendental.\n\nExamples\nAll rational numbers are algebraic. Any rational number, expressed as the quotient of an integer a and a (non-zero) natural number b, satisfies the above definition, because x = ⁠a/b⁠ is the root of a non-zero polynomial, namely bx − a.\nQuadratic irrational numbers, irrational solutions of a quadratic polynomial ax2 + bx + c with integer coefficients a, b, and c, are algebraic numbers. If the quadratic polynomial is monic (a = 1), the roots are further qualified as quadratic integers.\nGaussian integers, complex numbers a + bi for which both a and b are integers, are also quadratic integers. This is because a + bi and a − bi are the two roots of the quadratic x2 − 2ax + a2 + b2.\nA constructible number can be constructed from a given unit length using a straightedge and compass. It includes all quadratic irrational roots, all rational numbers, and all numbers that can be formed from these using the basic arithmetic operations and the extraction of square roots. (By designating cardinal directions for +1, −1, +i, and −i, complex numbers such as \n  \n    \n      \n        3\n        +\n        i\n        \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle 3+i{\\sqrt {2}}}\n  \n are considered constructible.)\nAny expression formed from algebraic numbers using any finite combination of the basic arithmetic operations and extraction of nth roots gives another algebraic number.\nPolynomial roots that cannot be expressed in terms of the basic arithmetic operations and extraction of nth roots (such as the roots of x5 − x + 1). That happens with many but not all polynomials of degree 5 or higher.\nValues of trigonometric functions of rational multiples of π (except when undefined): for example, cos ⁠π/7⁠, cos ⁠3π/7⁠, and cos ⁠5π/7⁠ satisfy 8x3 − 4x2 − 4x + 1 = 0. This polynomial is irreducible over the rationals and so the three cosines are conjugate algebraic numbers. Likewise, tan ⁠3π/16⁠, tan ⁠7π/16⁠, tan ⁠11π/16⁠, and tan ⁠15π/16⁠ satisfy the irreducible polynomial x4 − 4x3 − 6x2 + 4x + 1 = 0, and so are conjugate algebraic integers. This is the equivalent of angles which, when measured in degrees, have rational numbers.\nSome but not all irrational numbers are algebraic:\nThe numbers \n  \n    \n      \n        \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle {\\sqrt {2}}}\n  \n and \n  \n    \n      \n        \n          \n            \n              3\n              \n                3\n              \n            \n            2\n          \n        \n      \n    \n    {\\displaystyle {\\frac {\\sqrt[{3}]{3}}{2}}}\n  \n are algebraic since they are roots of polynomials x2 − 2 and 8x3 − 3, respectively.\nThe golden ratio φ is algebraic since it is a root of the polynomial x2 − x − 1.\nThe numbers π and e are not algebraic numbers (see the Lindemann–Weierstrass theorem).\n\nProperties\nIf a polynomial with rational coefficients is multiplied through by the least common denominator, the resulting polynomial wit",
    "links": [
      "Abel–Ruffini theorem",
      "Addition",
      "Adele ring",
      "Algebra of physical space",
      "Algebraic closure",
      "Algebraic integer",
      "Algebraic number field",
      "Algebraic solution",
      "Algebraically closed field",
      "Almost all",
      "Almost everywhere",
      "Arithmetic operations",
      "Arithmetical numbers",
      "Bicomplex number",
      "Bioctonion",
      "Biquaternion",
      "Cardinal number",
      "Chebyshev nodes",
      "Clifford algebra",
      "Closed-form expression",
      "Closed-form number",
      "Complex number",
      "Complex plane",
      "Composition algebra",
      "Computable number",
      "Constructible number",
      "Countable set",
      "Cyclotomic field",
      "Dedekind domain",
      "Definable number",
      "Definable real number",
      "Degree of a field extension",
      "Degree of a polynomial",
      "Dense set",
      "Densely ordered",
      "Division (mathematics)",
      "Division algebra",
      "Doi (identifier)",
      "Doubling the cube",
      "Dual-complex number",
      "Dual number",
      "Dual quaternion",
      "E. M. Wright",
      "E (mathematical constant)",
      "Eisenstein integer",
      "Elementary number",
      "Extended natural numbers",
      "Extended real number line",
      "Field (mathematics)",
      "Finite set"
    ],
    "categories": [
      "Category:Algebraic numbers",
      "Category:Articles with short description",
      "Category:Short description matches Wikidata",
      "Category:Use shortened footnotes from September 2024",
      "Category:Wikipedia articles needing clarification from July 2024"
    ]
  },
  "Algebraic number field": {
    "title": "Algebraic number field",
    "url": "https://en.wikipedia.org/wiki/Algebraic_number_field",
    "summary": "In mathematics, an algebraic number field (or simply number field) is an extension field \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n of the field of rational numbers \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n such that the field extension \n  \n    \n      \n        K\n        \n          /\n        \n        \n          Q\n        \n      \n    \n    {\\displaystyle K/\\mathbb {Q} }\n  \n has finite degree (and hence is an algebraic field extension).\nThus \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n is a field that contains \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n and has finite dimension when considered as a vector space over \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n.\nThe study of algebraic number fields, that is, of algebraic extensions of the field of rational numbers, is the central topic of algebraic n",
    "content": "In mathematics, an algebraic number field (or simply number field) is an extension field \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n of the field of rational numbers \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n such that the field extension \n  \n    \n      \n        K\n        \n          /\n        \n        \n          Q\n        \n      \n    \n    {\\displaystyle K/\\mathbb {Q} }\n  \n has finite degree (and hence is an algebraic field extension).\nThus \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n is a field that contains \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n and has finite dimension when considered as a vector space over \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n.\nThe study of algebraic number fields, that is, of algebraic extensions of the field of rational numbers, is the central topic of algebraic number theory. This study reveals hidden structures behind the rational numbers, by using algebraic methods.\n\nDefinition\nPrerequisites\nThe notion of algebraic number field relies on the concept of a field. A field consists of a set of elements together with two operations, namely addition, and multiplication, and some distributivity assumptions. These operations make the field into an abelian group under addition, and they make the nonzero elements of the field into another abelian group under multiplication. A prominent example of a field is the field of rational numbers, commonly denoted \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n, together with its usual operations of addition and multiplication.\nAnother notion needed to define algebraic number fields is vector spaces. To the extent needed here, vector spaces can be thought of as consisting of sequences (or tuples)\n\n  \n    \n      \n        (\n        \n          x\n          \n            1\n          \n        \n        ,\n        \n          x\n          \n            2\n          \n        \n        ,\n        …\n        )\n      \n    \n    {\\displaystyle (x_{1},x_{2},\\dots )}\n  \n\nwhose entries are elements of a fixed field, such as the field \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n. Any two such sequences can be added by adding the corresponding entries. Furthermore, all members of any sequence can be multiplied by a single element c of the fixed field. These two operations known as vector addition and scalar multiplication satisfy a number of properties that serve to define vector spaces abstractly. Vector spaces are allowed to be \"infinite-dimensional\", that is to say that the sequences constituting the vector spaces may be of infinite length. If, however, the vector space consists of finite sequences\n\n  \n    \n      \n        (\n        \n          x\n          \n            1\n          \n        \n        ,\n        …\n        ,\n        \n          x\n          \n            n\n          \n        \n        )\n      \n    \n    {\\displaystyle (x_{1},\\dots ,x_{n})}\n  \n,\nthe vector space is said to be of finite dimension, \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n.\n\nDefinition\nAn algebraic number field (or simply number field) is a finite-degree field extension of the field of rational numbers. Here degree means the dimension of the field as a vector space over \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n.\n\nExamples\nThe smallest and most basic number field is the field \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n of rational numbers. Many properties of general number fields are modeled after the properties of \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n. At the same time, many other properties of algebraic number fields are substantially different from the properties of rational numbers—one notable example is that the ring of algebraic integers of a number field is not a principal ideal domain, and not even a unique factorization domain, in general.\nThe Gaussian rationals, denoted \n  \n    \n      \n        \n          Q\n        \n        (\n        i\n        )\n      \n    \n    {\\displaystyle \\mathbb {Q} (i)}\n  \n (read as \"\n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n adjoined \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n\"), form the first (historically) non-trivial example of a number field. Its elements are elements of the form \n  \n    \n      \n        a\n        +\n        b\n        i\n      \n    \n    {\\displaystyle a+bi}\n  \n where both \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n and \n  \n    \n      \n        b\n      \n    \n    {\\displaystyle b}\n  \n are rational numbers and \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n is the imaginary unit. S",
    "links": [
      "Abelian extension",
      "Abelianization",
      "Absolute Galois group",
      "Absolute value",
      "Absolute value (algebra)",
      "Abstract algebra",
      "Addition",
      "Adele ring",
      "Adjunction (field theory)",
      "Algebraic K-theory",
      "Algebraic closure",
      "Algebraic curve",
      "Algebraic extension",
      "Algebraic field extension",
      "Algebraic function field",
      "Algebraic geometry",
      "Algebraic integer",
      "Algebraic number",
      "Algebraic number theory",
      "Algebraic numbers",
      "Algebraic structure",
      "American Mathematical Society",
      "Analytic continuation",
      "André Weil",
      "Arithmetic progression",
      "Artin reciprocity law",
      "Associative algebra",
      "Bilinear form",
      "Branched covering",
      "Brauer group",
      "Category of rings",
      "Cauchy sequence",
      "Cayley–Hamilton theorem",
      "Characteristic polynomial",
      "Chebotarev's density theorem",
      "Class field theory",
      "Class number (number theory)",
      "Class number formula",
      "Class number problem",
      "Clifford algebra",
      "Commutative algebra",
      "Commutative algebra (structure)",
      "Commutative ring",
      "Commutator (ring theory)",
      "Completion (ring theory)",
      "Complex conjugate",
      "Complex number",
      "Computer algebra system",
      "Coordinate ring",
      "Coprime"
    ],
    "categories": [
      "Category:Algebraic number theory",
      "Category:Articles with short description",
      "Category:Field (mathematics)",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Algebraic surface": {
    "title": "Algebraic surface",
    "url": "https://en.wikipedia.org/wiki/Algebraic_surface",
    "summary": "In mathematics, an algebraic surface is an algebraic variety of dimension two. Thus, an algebraic surface is a solution of a set of polynomial equations, in which there are two independent directions at every point.  An example of an algebraic surface is the sphere, which is determined by the single polynomial equation \n  \n    \n      \n        \n          x\n          \n            2\n          \n        \n        +\n        \n          y\n          \n            2\n          \n        \n        +\n        \n          z\n          \n            2\n          \n        \n        =\n        1.\n      \n    \n    {\\displaystyle x^{2}+y^{2}+z^{2}=1.}\n  \n  Studying the intrinsic geometry of algebraic surfaces is a central topic in algebraic geometry. The theory is much more complicated than for algebraic curves (one-dimensional cases), and was developed substantially by the Italian school of algebraic geometry in the late 19th and early 20th centuries.\nIt remains an active field of research.\nIn the simplest cases, a",
    "content": "In mathematics, an algebraic surface is an algebraic variety of dimension two. Thus, an algebraic surface is a solution of a set of polynomial equations, in which there are two independent directions at every point.  An example of an algebraic surface is the sphere, which is determined by the single polynomial equation \n  \n    \n      \n        \n          x\n          \n            2\n          \n        \n        +\n        \n          y\n          \n            2\n          \n        \n        +\n        \n          z\n          \n            2\n          \n        \n        =\n        1.\n      \n    \n    {\\displaystyle x^{2}+y^{2}+z^{2}=1.}\n  \n  Studying the intrinsic geometry of algebraic surfaces is a central topic in algebraic geometry. The theory is much more complicated than for algebraic curves (one-dimensional cases), and was developed substantially by the Italian school of algebraic geometry in the late 19th and early 20th centuries.\nIt remains an active field of research.\nIn the simplest cases, algebraic surfaces are studied as algebraic varieties over the complex numbers.  For example, the familiar sphere (for real \n  \n    \n      \n        x\n        ,\n        y\n        ,\n        z\n      \n    \n    {\\displaystyle x,y,z}\n  \n), becomes a complex (affine) quadric surface, which simultaneously incorporates the sphere and hyperboloids of one and two sheets, and this allows some complications (such as the topology: whether the surface is connected, or simply connected) to be deferred somewhat.  Higher degree surfaces include, for example, the Kummer surface.  The classification of algebraic surfaces is much more intricate than the classification of algebraic curves, which have dimension one, and is already quite complicated.\nAlgebraic surfaces, like algebraic curves, may possess singularities, which are points where there is no tangent plane. A singularity may be a self-crossing point or a point where the number of \"free\" dimensions may drop, such as at a cusp. Catastrophe theory is strongly related with the classification of surface singularities. Likewise, algebraic surfaces may be defined over other fields than the complex numbers.  This article focuses primarily on the complex case.\n\nClassification by the Kodaira dimension\nIn the case of dimension one, varieties are classified by only the topological genus, but, in dimension two, one needs to distinguish the arithmetic genus \n  \n    \n      \n        \n          p\n          \n            a\n          \n        \n      \n    \n    {\\displaystyle p_{a}}\n  \n and the geometric genus \n  \n    \n      \n        \n          p\n          \n            g\n          \n        \n      \n    \n    {\\displaystyle p_{g}}\n  \n because one cannot distinguish birationally only the topological genus. Then, irregularity is introduced for the classification of varieties. A summary of the results (in detail, for each kind of surface refers to each redirection), follows:\nExamples of algebraic surfaces include (κ is the Kodaira dimension):\n\nκ = −∞: the projective plane, quadrics in P3, cubic surfaces, Veronese surface, del Pezzo surfaces, ruled surfaces\nκ = 0 : K3 surfaces, abelian surfaces, Enriques surfaces, hyperelliptic surfaces\nκ = 1: elliptic surfaces\nκ = 2: surfaces of general type.\nFor more examples see the list of algebraic surfaces.\nThe first five examples are in fact birationally equivalent. That is, for example, a cubic surface has a function field isomorphic to that of the projective plane, being the rational functions in two indeterminates. The Cartesian product of two curves also provides examples.\n\nBirational geometry of surfaces\nThe birational geometry of algebraic surfaces is rich, because of blowing up (also known as a monoidal transformation), under which a point is replaced by the curve of all limiting tangent directions coming into it (a projective line). Certain curves may also be blown down, but there is a restriction (self-intersection number must be −1).\n\nCastelnuovo's Theorem\nOne of the fundamental theorems for the birational geometry of surfaces is Castelnuovo's theorem. This states that any birational map between algebraic surfaces is given by a finite sequence of blowups and blowdowns.\n\nProperties\nThe Nakai criterion says that:\n\nA Divisor D on a surface S is ample if and only if D2 > 0 and for all irreducible curve C on S D•C > 0.\nAmple divisors have a nice property such as it is the pullback of some hyperplane bundle of projective space, whose properties are very well known. Let \n  \n    \n      \n        \n          \n            D\n          \n        \n        (\n        S\n        )\n      \n    \n    {\\displaystyle {\\mathcal {D}}(S)}\n  \n be the abelian group consisting of all the divisors on S. Then due to the intersection theorem\n\n  \n    \n      \n        \n          \n            D\n          \n        \n        (\n        S\n        )\n        ×\n        \n          \n            D\n          \n        \n        (\n        S\n        )\n        →\n        \n          Z\n        \n        :\n        (\n        X\n  ",
    "links": [
      "Abelian surface",
      "Affine variety",
      "Algebraic curve",
      "Algebraic equivalence",
      "Algebraic geometry",
      "Algebraic variety",
      "Ample line bundle",
      "Arithmetic genus",
      "Birational geometry",
      "Birational invariant",
      "Birationally equivalent",
      "Blowing up",
      "Castelnuovo's contraction theorem",
      "Catastrophe theory",
      "Classification of algebraic surfaces",
      "Complex number",
      "Complex projective plane",
      "Connected space",
      "Cubic surface",
      "Cusp (algebraic geometry)",
      "Degree (algebraic geometry)",
      "Del Pezzo surface",
      "Dimension of an algebraic variety",
      "Elliptic surface",
      "Encyclopedia of Mathematics",
      "Enriques surface",
      "Enriques–Kodaira classification",
      "European Mathematical Society",
      "Field (mathematics)",
      "Function field of an algebraic variety",
      "Geometric genus",
      "Hodge cycle",
      "Hodge index theorem",
      "Hodge number",
      "Homological equivalence",
      "Hyperboloid",
      "Hyperelliptic surface",
      "ISBN (identifier)",
      "Intersection number",
      "Irregularity of a surface",
      "Italian school of algebraic geometry",
      "K3 surface",
      "Kodaira dimension",
      "Kummer surface",
      "List of algebraic surfaces",
      "MR (identifier)",
      "Mathematics",
      "Max Noether",
      "Minimal model program",
      "Monoidal transformation"
    ],
    "categories": [
      "Category:Algebraic surfaces",
      "Category:Articles with short description",
      "Category:Short description matches Wikidata"
    ]
  },
  "Algorithm design": {
    "title": "Algorithm",
    "url": "https://en.wikipedia.org/wiki/Algorithm",
    "summary": "In mathematics and computer science, an algorithm ( ) is a finite sequence of mathematically rigorous instructions, typically used to solve a class of specific problems or to perform a computation. Algorithms are used as specifications for performing calculations and data processing. More advanced algorithms can use conditionals to divert the code execution through various routes (referred to as automated decision-making) and deduce valid inferences (referred to as automated reasoning).\nIn contrast, a heuristic is an approach to solving problems without well-defined correct or optimal results. For example, although social media recommender systems are commonly called \"algorithms\", they actually rely on heuristics as there is no truly \"correct\" recommendation.\nAs an effective method, an algorithm can be expressed within a finite amount of space and time and in a well-defined formal language for calculating a function. Starting from an initial state and initial input (perhaps empty), the",
    "content": "In mathematics and computer science, an algorithm ( ) is a finite sequence of mathematically rigorous instructions, typically used to solve a class of specific problems or to perform a computation. Algorithms are used as specifications for performing calculations and data processing. More advanced algorithms can use conditionals to divert the code execution through various routes (referred to as automated decision-making) and deduce valid inferences (referred to as automated reasoning).\nIn contrast, a heuristic is an approach to solving problems without well-defined correct or optimal results. For example, although social media recommender systems are commonly called \"algorithms\", they actually rely on heuristics as there is no truly \"correct\" recommendation.\nAs an effective method, an algorithm can be expressed within a finite amount of space and time and in a well-defined formal language for calculating a function. Starting from an initial state and initial input (perhaps empty), the instructions describe a computation that, when executed, proceeds through a finite number of well-defined successive states, eventually producing \"output\" and terminating at a final ending state. The transition from one state to the next is not necessarily deterministic; some algorithms, known as randomized algorithms, incorporate random input.\n\nEtymology\nAround 825 AD, Persian scientist and polymath Muḥammad ibn Mūsā al-Khwārizmī wrote kitāb al-ḥisāb al-hindī (\"Book of Indian computation\") and kitab al-jam' wa'l-tafriq al-ḥisāb al-hindī (\"Addition and subtraction in Indian arithmetic\"). In the early 12th century, Latin translations of these texts involving the Hindu–Arabic numeral system and arithmetic appeared, for example Liber Alghoarismi de practica arismetrice, attributed to John of Seville, and Liber Algorismi de numero Indorum, attributed to Adelard of Bath. Here, alghoarismi or algorismi is the Latinization of Al-Khwarizmi's name; the text starts with the phrase Dixit Algorismi, or \"Thus spoke Al-Khwarizmi\".\nThe word algorism in English came to mean the use of place-value notation in calculations; it occurs in the Ancrene Wisse from circa 1225. By the time Geoffrey Chaucer wrote The Canterbury Tales in the late 14th century, he used a variant of the same word in describing augrym stones, stones used for place-value calculation. In the 15th century, under the influence of the Greek word ἀριθμός (arithmos, \"number\"; cf. \"arithmetic\"), the Latin word was altered to algorithmus. By 1596, this form of the word was used in English, as algorithm, by Thomas Hood.\n\nDefinition\nOne informal definition is \"a set of rules that precisely defines a sequence of operations\", which would include all computer programs (including programs that do not perform numeric calculations), and any prescribed bureaucratic procedure\nor cook-book recipe. In general, a program is an algorithm only if it stops eventually—even though infinite loops may sometimes prove desirable. Boolos, Jeffrey & 1974, 1999 define an algorithm to be an explicit set of instructions for determining an output, that can be followed by a computing machine or a human who could only carry out specific elementary operations on symbols.\nMost algorithms are intended to be implemented as computer programs. However, algorithms are also implemented by other means, such as in a biological neural network (for example, the human brain performing arithmetic or an insect looking for food), in an electrical circuit, or a mechanical device.\n\nHistory\nAncient algorithms\nStep-by-step procedures for solving mathematical problems have been recorded since antiquity. This includes in Babylonian mathematics (around 2500 BC), Egyptian mathematics (around 1550 BC), Indian mathematics (around 800 BC and later), the Ifa Oracle (around 500 BC), Greek mathematics (around 240 BC), Chinese mathematics (around 200 BC and later), and Arabic mathematics (around 800 AD).\nThe earliest evidence of algorithms is found in ancient Mesopotamian mathematics. A Sumerian clay tablet found in Shuruppak near Baghdad and dated to c. 2500 BC describes the earliest division algorithm. During the Hammurabi dynasty c. 1800 – c. 1600 BC, Babylonian clay tablets described algorithms for computing formulas. Algorithms were also used in Babylonian astronomy. Babylonian clay tablets describe and employ algorithmic procedures to compute the time and place of significant astronomical events.\nAlgorithms for arithmetic are also found in ancient Egyptian mathematics, dating back to the Rhind Mathematical Papyrus c. 1550 BC. Algorithms were later used in ancient Hellenistic mathematics. Two examples are the Sieve of Eratosthenes, which was described in the Introduction to Arithmetic by Nicomachus, and the Euclidean algorithm, which was first described in Euclid's Elements (c. 300 BC).Examples of ancient Indian mathematics included the Shulba Sutras, the Kerala School, and the Brāhmasphuṭasiddhānta.\nThe first cryptographic algorithm f",
    "links": [
      "A.A. Markov",
      "A. M. Turing",
      "ALGOL",
      "Abstract machine",
      "Ada Lovelace",
      "Adelard of Bath",
      "Al-Khwarizmi",
      "Al-Kindi",
      "Alan Turing",
      "Alan Turing: The Enigma",
      "Algebra of physical space",
      "Algebraic structure",
      "Algorism",
      "Algorithm (disambiguation)",
      "Algorithm aversion",
      "Algorithm characterizations",
      "Algorithm design",
      "Algorithm engineering",
      "Algorithmic bias",
      "Algorithmic composition",
      "Algorithmic efficiency",
      "Algorithmic entities",
      "Algorithmic paradigm",
      "Algorithmic synthesis",
      "Algorithmic technique",
      "Algorithmic topology",
      "Alonzo Church",
      "Analysis of algorithms",
      "Analytical engine",
      "Analytical mechanics",
      "Ancrene Wisse",
      "Andreas Blass",
      "Andrew Hodges",
      "Applied mathematics",
      "Approximation algorithm",
      "Approximation theory",
      "Arabic mathematics",
      "Arithmetic",
      "Array (data structure)",
      "Arthur Zimek",
      "Asger Aaboe",
      "Assembly code",
      "Assignment (computer science)",
      "Association for Computing Machinery",
      "Associative array",
      "Asymptotically optimal",
      "Automata theory",
      "Automated decision-making",
      "Automated reasoning",
      "Automated theorem proving"
    ],
    "categories": [
      "Category:Algorithms",
      "Category:Articles to be expanded from October 2023",
      "Category:Articles with example pseudocode",
      "Category:Articles with short description",
      "Category:CS1: abbreviated year range",
      "Category:Commons category link from Wikidata",
      "Category:Mathematical logic",
      "Category:Pages including recorded pronunciations",
      "Category:Pages using the Phonos extension",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Algorithmic efficiency": {
    "title": "Algorithmic efficiency",
    "url": "https://en.wikipedia.org/wiki/Algorithmic_efficiency",
    "summary": "In computer science, algorithmic efficiency is a property of an algorithm which relates to the amount of computational resources used by the algorithm. Algorithmic efficiency can be thought of as analogous to engineering productivity for a repeating or continuous process.\nFor maximum efficiency it is desirable to minimize resource usage. However, different resources such as time and space complexity cannot be compared directly, so which of two algorithms is considered to be more efficient often depends on which measure of efficiency is considered most important.\nFor example, cycle sort and timsort are both algorithms to sort a list of items from smallest to largest. Cycle sort organizes the list in time proportional to the number of elements squared (\n  \n    \n      \n        O\n        (\n        \n          n\n          \n            2\n          \n        \n        )\n      \n    \n    {\\textstyle O(n^{2})}\n  \n, see Big O notation), but minimizes the writes to the original array and only require",
    "content": "In computer science, algorithmic efficiency is a property of an algorithm which relates to the amount of computational resources used by the algorithm. Algorithmic efficiency can be thought of as analogous to engineering productivity for a repeating or continuous process.\nFor maximum efficiency it is desirable to minimize resource usage. However, different resources such as time and space complexity cannot be compared directly, so which of two algorithms is considered to be more efficient often depends on which measure of efficiency is considered most important.\nFor example, cycle sort and timsort are both algorithms to sort a list of items from smallest to largest. Cycle sort organizes the list in time proportional to the number of elements squared (\n  \n    \n      \n        O\n        (\n        \n          n\n          \n            2\n          \n        \n        )\n      \n    \n    {\\textstyle O(n^{2})}\n  \n, see Big O notation), but minimizes the writes to the original array and only requires a small amount of extra memory which is constant with respect to the length of the list (\n  \n    \n      \n        O\n        (\n        1\n        )\n      \n    \n    {\\textstyle O(1)}\n  \n). Timsort sorts the list in time linearithmic (proportional to a quantity times its logarithm) in the list's length (\n  \n    \n      \n        O\n        (\n        n\n        log\n        ⁡\n        n\n        )\n      \n    \n    {\\textstyle O(n\\log n)}\n  \n), but has a space requirement linear in the length of the list (\n  \n    \n      \n        O\n        (\n        n\n        )\n      \n    \n    {\\textstyle O(n)}\n  \n). If large lists must be sorted at high speed for a given application, timsort is a better choice; however, if minimizing the program/erase cycles and memory footprint of the sorting is more important, cycle sort is a better choice.\n\nBackground\nThe importance of efficiency with respect to time was emphasized by Ada Lovelace in 1843 as applied to Charles Babbage's mechanical analytical engine:\n\n\"In almost every computation a great variety of arrangements for the succession of the processes is possible, and various considerations must influence the selections amongst them for the purposes of a calculating engine. One essential object is to choose that arrangement which shall tend to reduce to a minimum the time necessary for completing the calculation\"\nEarly electronic computers had both limited speed and limited random access memory. Therefore, a space–time trade-off occurred. A task could use a fast algorithm using a lot of memory, or it could use a slow algorithm using little memory. The engineering trade-off was therefore to use the fastest algorithm that could fit in the available memory.\nModern computers are significantly faster than early computers and have a much larger amount of memory available (gigabytes instead of kilobytes). Nevertheless, Donald Knuth emphasized that efficiency is still an important consideration:\n\n  \"In established engineering disciplines a 12% improvement, easily obtained, is never considered marginal and I believe the same viewpoint should prevail in software engineering\"\n\nOverview\nAn algorithm is considered efficient if its resource consumption, also known as computational cost, is at or below some acceptable level. Roughly speaking, 'acceptable' means:  it will run in a reasonable amount of time or space on an available computer, typically as a function of the size of the input. Since the 1950s computers have seen dramatic increases in both the available computational power and in the available amount of memory, so current acceptable levels would have been unacceptable even 10 years ago. In fact, thanks to the approximate doubling of computer power every 2 years, tasks that are acceptably efficient on modern smartphones and embedded systems may have been unacceptably inefficient for industrial servers 10 years ago.\nComputer manufacturers frequently bring out new models, often with higher performance. Software costs can be quite high, so in some cases the simplest and cheapest way of getting higher performance might be to just buy a faster computer, provided it is compatible with an existing computer.\nThere are many ways in which the resources used by an algorithm can be measured: the two most common measures are speed and memory usage; other measures could include transmission speed, temporary disk usage, long-term disk usage, power consumption, total cost of ownership, response time to external stimuli, etc. Many of these measures depend on the size of the input to the algorithm, i.e. the amount of data to be processed. They might also depend on the way in which the data is arranged; for example, some sorting algorithms perform poorly on data which is already sorted, or which is sorted in reverse order.\nIn practice, there are other factors which can affect the efficiency of an algorithm, such as requirements for accuracy and/or reliability. As detailed below, the way in which an algorithm is implemented can also ",
    "links": [
      "ACM Computing Classification System",
      "ARM architecture",
      "Accuracy and precision",
      "Ada Lovelace",
      "Adaptability",
      "Algorithm",
      "Algorithm design",
      "Analysis of algorithms",
      "Analysis of parallel algorithms",
      "Apache Hadoop",
      "Application programming interface",
      "Application security",
      "Arithmetic logic unit",
      "Arthur Zimek",
      "Artificial intelligence",
      "Asymptote",
      "Augmented reality",
      "Automata theory",
      "Automated planning and scheduling",
      "Auxiliary memory",
      "Backward compatibility",
      "Benchmark (computing)",
      "Best, worst and average case",
      "Big O notation",
      "Binary search algorithm",
      "Binomial heap",
      "Boolean satisfiability problem",
      "Brute-force search",
      "Bubble sort",
      "CPU cache",
      "CPU core",
      "CPU time",
      "CUDA",
      "Cache-aware model",
      "Cache (computing)",
      "Cache coherence",
      "Cache hierarchy",
      "Cache miss",
      "Cache replacement policies",
      "Central processing unit",
      "Charles Babbage",
      "CiteSeerX (identifier)",
      "Clock cycle",
      "Code generation (compiler)",
      "Communication protocol",
      "Compiler",
      "Compiler construction",
      "Compiler optimization",
      "Computability theory",
      "Computational biology"
    ],
    "categories": [
      "Category:All articles containing potentially dated statements",
      "Category:All articles needing additional references",
      "Category:All articles with style issues",
      "Category:All articles with unsourced statements",
      "Category:Analysis of algorithms",
      "Category:Articles containing potentially dated statements from 2018",
      "Category:Articles needing additional references from January 2024",
      "Category:Articles with multiple maintenance issues",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from July 2024"
    ]
  },
  "Analysis of algorithms": {
    "title": "Analysis of algorithms",
    "url": "https://en.wikipedia.org/wiki/Analysis_of_algorithms",
    "summary": "In computer science, the analysis of algorithms is the process of finding the computational complexity of algorithms—the amount of time, storage, or other resources needed to execute them. Usually, this involves determining a function that relates the size of an algorithm's input to the number of steps it takes (its time complexity) or the number of storage locations it uses (its space complexity). An algorithm is said to be efficient when this function's values are small, or grow slowly compared to a growth in the size of the input. Different inputs of the same size may cause the algorithm to have different behavior, so best, worst and average case descriptions might all be of practical interest.  When not otherwise specified, the function describing the performance of an algorithm is usually an upper bound, determined from the worst case inputs to the algorithm.\nThe term \"analysis of algorithms\" was coined by Donald Knuth. Algorithm analysis is an important part of a broader computat",
    "content": "In computer science, the analysis of algorithms is the process of finding the computational complexity of algorithms—the amount of time, storage, or other resources needed to execute them. Usually, this involves determining a function that relates the size of an algorithm's input to the number of steps it takes (its time complexity) or the number of storage locations it uses (its space complexity). An algorithm is said to be efficient when this function's values are small, or grow slowly compared to a growth in the size of the input. Different inputs of the same size may cause the algorithm to have different behavior, so best, worst and average case descriptions might all be of practical interest.  When not otherwise specified, the function describing the performance of an algorithm is usually an upper bound, determined from the worst case inputs to the algorithm.\nThe term \"analysis of algorithms\" was coined by Donald Knuth. Algorithm analysis is an important part of a broader computational complexity theory, which provides theoretical estimates for the resources needed by any algorithm which solves a given computational problem. These estimates provide an insight into reasonable directions of search for efficient algorithms.\nIn theoretical analysis of algorithms it is common to estimate their complexity in the asymptotic sense, i.e., to estimate the complexity function for arbitrarily large input. Big O notation, Big-omega notation and Big-theta notation are used to this end. For instance, binary search is said to run in a number of steps proportional to the logarithm of the size n of the sorted list being searched, or in O(log n), colloquially \"in logarithmic time\". Usually asymptotic estimates are used because different implementations of the same algorithm may differ in efficiency. However the efficiencies of any two \"reasonable\" implementations of a given algorithm are related by a constant multiplicative factor  called a hidden constant.\nExact (not asymptotic) measures of efficiency can sometimes be computed but they usually require certain assumptions concerning the particular implementation of the algorithm, called a model of computation. A model of computation may be defined in terms of an abstract computer, e.g. Turing machine, and/or by postulating that certain operations are executed in unit time.\nFor example, if the sorted list to which we apply binary search has n elements, and we can guarantee that each lookup of an element in the list can be done in unit time, then at most log2(n) + 1 time units are needed to return an answer.\n\nCost models\nTime efficiency estimates depend on what we define to be a step. For the analysis to correspond usefully to the actual run-time, the time required to perform a step must be guaranteed to be bounded above by a constant. One must be careful here; for instance, some analyses count an addition of two numbers as one step. This assumption may not be warranted in certain contexts. For example, if the numbers involved in a computation may be arbitrarily large, the time required by a single addition can no longer be assumed to be constant.\nTwo cost models are generally used:\n\nthe uniform cost model, also called unit-cost model (and similar variations), assigns a constant cost to every machine operation, regardless of the size of the numbers involved\nthe logarithmic cost model, also called logarithmic-cost measurement (and similar variations), assigns a cost to every machine operation proportional to the number of bits involved\nThe latter is more cumbersome to use, so it is only employed when necessary, for example in the analysis of arbitrary-precision arithmetic algorithms, like those used in cryptography.\nA key point which is often overlooked is that published lower bounds for problems are often given for a model of computation that is more restricted than the set of operations that you could use in practice and therefore there are algorithms that are faster than what would naively be thought possible.\n\nRun-time analysis\nRun-time analysis is a theoretical classification that estimates and anticipates the increase in running time (or run-time or execution time) of an algorithm as its input size (usually denoted as n) increases.  Run-time efficiency is a topic of great interest in computer science:  A program can take seconds, hours, or even years to finish executing, depending on which algorithm it implements. While software profiling techniques can be used to measure an algorithm's run-time in practice, they cannot provide timing data for all infinitely many possible inputs; the latter can only be achieved by the theoretical methods of run-time analysis.\n\nShortcomings of empirical metrics\nSince algorithms are platform-independent (i.e. a given algorithm can be implemented in an arbitrary programming language on an arbitrary computer running an arbitrary operating system), there are additional significant drawbacks to using an empirical approach to gauge the compa",
    "links": [
      "ACM Computing Classification System",
      "Abstract machine",
      "Algorithm",
      "Algorithm design",
      "Algorithmic efficiency",
      "Amortized analysis",
      "Analysis of parallel algorithms",
      "Application security",
      "Arbitrary-precision arithmetic",
      "Arithmetic progression",
      "Artificial intelligence",
      "Asymptotic analysis",
      "Asymptotic computational complexity",
      "Augmented reality",
      "Automata theory",
      "Automated planning and scheduling",
      "Benchmark (computing)",
      "Best, worst and average case",
      "Big-omega notation",
      "Big-theta notation",
      "Big O notation",
      "Binary search",
      "Binary search algorithm",
      "Cambridge University Press",
      "Charles E. Leiserson",
      "Clifford Stein",
      "Collation",
      "Communication protocol",
      "Compiler construction",
      "Computability theory",
      "Computational biology",
      "Computational chemistry",
      "Computational complexity",
      "Computational complexity theory",
      "Computational engineering",
      "Computational geometry",
      "Computational mathematics",
      "Computational physics",
      "Computational problem",
      "Computational social science",
      "Computer",
      "Computer accessibility",
      "Computer animation",
      "Computer architecture",
      "Computer data storage",
      "Computer file",
      "Computer graphics",
      "Computer hardware",
      "Computer network",
      "Computer program"
    ],
    "categories": [
      "Category:All articles lacking in-text citations",
      "Category:Analysis of algorithms",
      "Category:Articles lacking in-text citations from March 2010",
      "Category:Articles with short description",
      "Category:Commons category link from Wikidata",
      "Category:Computational complexity theory",
      "Category:Short description matches Wikidata",
      "Category:Webarchive template wayback links"
    ]
  },
  "Argument (complex analysis)": {
    "title": "Argument (complex analysis)",
    "url": "https://en.wikipedia.org/wiki/Argument_(complex_analysis)",
    "summary": "In mathematics (particularly in complex analysis), the argument of a complex number z, denoted arg(z), is the angle between the positive real axis and the line joining the origin and z, represented as a point in the complex plane, shown as \n  \n    \n      \n        φ\n      \n    \n    {\\displaystyle \\varphi }\n  \n in Figure 1. By convention the positive real axis is drawn pointing rightward, the positive imaginary axis is drawn pointing upward, and complex numbers with positive real part are considered to have an anticlockwise argument with positive sign.\nWhen any real-valued angle is considered, the argument is a multivalued function operating on the nonzero complex numbers. The principal value of this function is single-valued, typically chosen to be the unique value of the argument that lies within the interval (−π, π]. In this article the multi-valued function will be denoted arg(z) and its principal value will be denoted Arg(z), but in some sources the capitalization of these symbols i",
    "content": "In mathematics (particularly in complex analysis), the argument of a complex number z, denoted arg(z), is the angle between the positive real axis and the line joining the origin and z, represented as a point in the complex plane, shown as \n  \n    \n      \n        φ\n      \n    \n    {\\displaystyle \\varphi }\n  \n in Figure 1. By convention the positive real axis is drawn pointing rightward, the positive imaginary axis is drawn pointing upward, and complex numbers with positive real part are considered to have an anticlockwise argument with positive sign.\nWhen any real-valued angle is considered, the argument is a multivalued function operating on the nonzero complex numbers. The principal value of this function is single-valued, typically chosen to be the unique value of the argument that lies within the interval (−π, π]. In this article the multi-valued function will be denoted arg(z) and its principal value will be denoted Arg(z), but in some sources the capitalization of these symbols is exchanged.\nIn some older mathematical texts, the term \"amplitude\" was used interchangeably with argument to denote the angle of a complex number. This usage is seen in older references such as Lars Ahlfors' Complex Analysis: An introduction to the theory of analytic functions of one complex variable (1979), where amplitude referred to the argument of a complex number. While this term is largely outdated in modern texts, it still appears in some regional educational resources, where it is sometimes used in introductory-level textbooks.\n\nDefinition\nAn argument of the nonzero complex number z = x + iy, denoted arg(z), is defined in two equivalent ways:\n\nGeometrically, in the complex plane, as the 2D polar angle \n  \n    \n      \n        φ\n      \n    \n    {\\displaystyle \\varphi }\n  \n from the positive real axis to the vector representing z. The numeric value is given by the angle in radians, and is positive if measured counterclockwise.\nAlgebraically, as any real quantity \n  \n    \n      \n        φ\n      \n    \n    {\\displaystyle \\varphi }\n  \n such that \n  \n    \n      \n        z\n        =\n        r\n        (\n        cos\n        ⁡\n        φ\n        +\n        i\n        sin\n        ⁡\n        φ\n        )\n        =\n        r\n        \n          e\n          \n            i\n            φ\n          \n        \n      \n    \n    {\\displaystyle z=r(\\cos \\varphi +i\\sin \\varphi )=re^{i\\varphi }}\n  \n for some positive real r (see Euler's formula). The quantity r is the modulus (or absolute value) of z, denoted |z|: \n  \n    \n      \n        r\n        =\n        \n          \n            \n              x\n              \n                2\n              \n            \n            +\n            \n              y\n              \n                2\n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle r={\\sqrt {x^{2}+y^{2}}}.}\n  \n\nThe argument of zero is usually left undefined. The names magnitude, for the modulus, and phase, for the argument, are sometimes used equivalently.\nUnder both definitions, it can be seen that the argument of any non-zero complex number has many possible values: firstly, as a geometrical angle, it is clear that whole circle rotations do not change the point, so angles differing by an integer multiple of 2π radians (a complete turn) are the same, as reflected by figure 2 on the right. Similarly, from the periodicity of sin \n and cos, the second definition also has this property.\n\nPrincipal value\nBecause a complete rotation around the origin leaves a complex number unchanged, there are many choices which could be made for \n  \n    \n      \n        φ\n      \n    \n    {\\displaystyle \\varphi }\n  \n by circling the origin any number of times. This is shown in figure 2, a representation of the multi-valued (set-valued) function \n  \n    \n      \n        f\n        (\n        x\n        ,\n        y\n        )\n        =\n        arg\n        ⁡\n        (\n        x\n        +\n        i\n        y\n        )\n      \n    \n    {\\displaystyle f(x,y)=\\arg(x+iy)}\n  \n, where a vertical line (not shown in the figure) cuts the surface at heights representing all the possible choices of angle for that point.\nWhen a well-defined function is required, then the usual choice, known as the principal value, is the value in the open-closed interval (−π, π] radians, that is from −π to π radians excluding −π radians itself (equiv., from −180 to +180 degrees, excluding −180° itself). This represents an angle of up to half a complete circle from the positive real axis in either direction.\nSome authors define the range of the principal value as being in the closed-open interval [0, 2π).\n\nNotation\nThe principal value sometimes has the initial letter capitalized, as in Arg z, especially when a general version of the argument is also being considered. Note that notation varies, so arg and Arg may be interchanged in different texts.\nThe set of all possible values of the argument can be written in terms of Arg as:\n\n  \n    \n      \n        arg\n        ⁡\n        ",
    "links": [
      "2D polar angle",
      "Absolute value",
      "Angle",
      "Anticlockwise",
      "Argand diagram",
      "Argument (disambiguation)",
      "Argument of a function",
      "Atan2",
      "Cartesian coordinate system",
      "Complex analysis",
      "Complex logarithm",
      "Complex number",
      "Complex plane",
      "Cosine",
      "Degree (angle)",
      "Encyclopedia of Mathematics",
      "Euler's formula",
      "HarperCollins",
      "ISBN (identifier)",
      "Imaginary number",
      "Indeterminate form",
      "Interval (mathematics)",
      "Lars Ahlfors",
      "MATLAB",
      "Magnitude (mathematics)",
      "Maple (software)",
      "Mathematics",
      "Multi-valued",
      "Multivalued function",
      "Newcastle University",
      "Periodic function",
      "Phase (waves)",
      "Plane (geometry)",
      "Principal value",
      "Radian",
      "Real number",
      "Sine",
      "Turn (angle)",
      "Undefined (mathematics)",
      "Well-defined"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Complex analysis",
      "Category:Short description is different from Wikidata",
      "Category:Signal processing",
      "Category:Trigonometry"
    ]
  },
  "0": {
    "title": "0",
    "url": "https://en.wikipedia.org/wiki/0",
    "summary": "0 (zero) is a number representing an empty quantity. Adding (or subtracting) 0 to any number leaves that number unchanged; in mathematical terminology, 0 is the additive identity of the integers, rational numbers, real numbers, and complex numbers, as well as other algebraic structures. Multiplying any number by 0 results in 0, and consequently division by zero has no meaning in arithmetic.\nAs a numerical digit, 0 plays a crucial role in decimal notation: it indicates that the power of ten corresponding to the place containing a 0 does not contribute to the total. For example, \"205\" in decimal means two hundreds, no tens, and five ones. The same principle applies in place-value notations that uses a base other than ten, such as binary and hexadecimal. The modern use of 0 in this manner derives from Indian mathematics that was transmitted to Europe via medieval Islamic mathematicians and popularized by Fibonacci. It was independently used by the Maya.\nCommon names for the number 0 in En",
    "content": "0 (zero) is a number representing an empty quantity. Adding (or subtracting) 0 to any number leaves that number unchanged; in mathematical terminology, 0 is the additive identity of the integers, rational numbers, real numbers, and complex numbers, as well as other algebraic structures. Multiplying any number by 0 results in 0, and consequently division by zero has no meaning in arithmetic.\nAs a numerical digit, 0 plays a crucial role in decimal notation: it indicates that the power of ten corresponding to the place containing a 0 does not contribute to the total. For example, \"205\" in decimal means two hundreds, no tens, and five ones. The same principle applies in place-value notations that uses a base other than ten, such as binary and hexadecimal. The modern use of 0 in this manner derives from Indian mathematics that was transmitted to Europe via medieval Islamic mathematicians and popularized by Fibonacci. It was independently used by the Maya.\nCommon names for the number 0 in English include zero, nought, naught (), and nil. In contexts where at least one adjacent digit distinguishes it from the letter O, the number is sometimes pronounced as oh or o (). Informal or slang terms for 0 include zilch and zip. Historically, ought, aught (), and cipher have also been used.\n\nEtymology\nThe word zero came into the English language via French zéro from the Italian zero, a contraction of the Venetian zevero form of Italian zefiro via ṣafira or ṣifr. In pre-Islamic time the word ṣifr (Arabic صفر) had the meaning \"empty\". Sifr evolved to mean zero when it was used to translate śūnya (Sanskrit: शून्य) from India. The first known English use of zero was in 1598.\nThe Italian mathematician Fibonacci (c. 1170 – c. 1250), who grew up in North Africa and is credited with introducing the decimal system to Europe, used the term zephyrum. This became zefiro in Italian, and was then contracted to zero in Venetian. The Italian word zefiro was already in existence (meaning \"west wind\" from Latin and Greek Zephyrus) and may have influenced the spelling when transcribing Arabic ṣifr.\n\nModern usage\nDepending on the context, there may be different words used for the number zero, or the concept of zero. For the simple notion of lacking, the words \"nothing\" (although this is not accurate) and \"none\" are often used. The British English words \"nought\" or \"naught\", and \"nil\" are also synonymous.\nIt is often called \"oh\" in the context of reading out a string of digits, such as telephone numbers, street addresses, credit card numbers, military time, or years. For example, the area code 201 may be pronounced \"two oh one\", and the year 1907 is often pronounced \"nineteen oh seven\". The presence of other digits, indicating that the string contains only numbers, avoids confusion with the letter O. For this reason, systems that include strings with both letters and numbers (such as postcodes in the UK) may exclude the use of the letter O.\nSlang words for zero include \"zip\", \"zilch\", \"nada\", and \"scratch\". In the context of sports, \"nil\" is sometimes used, especially in British English. Several sports have specific words for a score of zero, such as \"love\" in tennis – possibly from French l'œuf, \"the egg\" – and \"duck\" in cricket, a shortening of \"duck's egg\". \"Goose egg\" is another general slang term used for zero.\n\nHistory\nAncient Near East\nAncient Egyptian numerals were of base 10. They used hieroglyphs for the digits and were not positional. In one papyrus written around 1770 BC, a scribe recorded daily incomes and expenditures for the pharaoh's court, using the nfr hieroglyph to indicate cases where the amount of a foodstuff received was exactly equal to the amount disbursed. Egyptologist Alan Gardiner suggested that the nfr hieroglyph was being used as a symbol for zero. The same symbol was also used to indicate the base level in drawings of tombs and pyramids, and distances were measured relative to the base line as being above or below this line.\nBy the middle of the 2nd millennium BC, Babylonian mathematics had a sophisticated base 60 positional numeral system. The lack of a positional value (or zero) was indicated by a space between sexagesimal numerals. In a tablet unearthed at Kish (dating to as early as 700 BC), the scribe Bêl-bân-aplu used three hooks as a placeholder in the same Babylonian system. By 300 BC, a punctuation symbol (two slanted wedges) was repurposed as a placeholder.\nThe Babylonian positional numeral system differed from the later Hindu–Arabic system in that it did not explicitly specify the magnitude of the leading sexagesimal digit, so that for example the lone digit 1 () might represent any of 1, 60, 3600 = 602, etc., similar to the significand of a floating-point number but without an explicit exponent, and so only distinguished implicitly from context. The zero-like placeholder mark was only ever used in between digits, but never alone or at the end of a number.\n\nPre-Columbian Americas\nThe Mesoamerican Long C",
    "links": [
      "0 (disambiguation)",
      "1",
      "1,000,000",
      "1,000,000,000",
      "10",
      "10,000",
      "10,000,000",
      "10,000,000,000",
      "100",
      "100,000",
      "100,000,000",
      "100,000,000,000",
      "1000 (number)",
      "1001 (number)",
      "100 (number)",
      "101 (number)",
      "1023 (number)",
      "1024 (number)",
      "102 (number)",
      "103 (number)",
      "104 (number)",
      "105 (number)",
      "106 (number)",
      "107 (number)",
      "1089 (number)",
      "108 (number)",
      "1093 (number)",
      "109 (number)",
      "10 (number)",
      "1105 (number)",
      "110 (number)",
      "111 (number)",
      "112 (number)",
      "113 (number)",
      "114 (number)",
      "115 (number)",
      "116 (number)",
      "117 (number)",
      "118 (number)",
      "119 (number)",
      "11 (number)",
      "120 (number)",
      "121 (number)",
      "122 (number)",
      "1234 (number)",
      "123 (number)",
      "124 (number)",
      "125 (number)",
      "126 (number)",
      "127 (number)"
    ],
    "categories": [
      "Category:0 (number)",
      "Category:All articles with self-published sources",
      "Category:All articles with unsourced statements",
      "Category:Articles containing Arabic-language text",
      "Category:Articles containing French-language text",
      "Category:Articles containing Italian-language text",
      "Category:Articles containing Latin-language text",
      "Category:Articles containing Medieval Latin-language text",
      "Category:Articles containing Sanskrit-language text",
      "Category:Articles containing Venetian-language text"
    ]
  },
  "1": {
    "title": "1",
    "url": "https://en.wikipedia.org/wiki/1",
    "summary": "1 (one, unit, unity) is a number, numeral, and glyph. It is the first and smallest positive integer of the infinite sequence of natural numbers. This fundamental property has led to its unique uses in other fields, ranging from science to sports, where it commonly denotes the first, leading, or top thing in a group. 1 is the unit of counting or measurement, a determiner for singular nouns, and a gender-neutral pronoun. Historically, the representation of 1 evolved from ancient Sumerian and Babylonian symbols to the modern Arabic numeral.\nIn mathematics, 1 is the multiplicative identity, meaning that any number multiplied by 1 equals the same number. 1 is by convention not considered a prime number. In digital technology, 1 represents the \"on\" state in binary code, the foundation of computing. Philosophically, 1 symbolizes the ultimate reality or source of existence in various traditions.",
    "content": "1 (one, unit, unity) is a number, numeral, and glyph. It is the first and smallest positive integer of the infinite sequence of natural numbers. This fundamental property has led to its unique uses in other fields, ranging from science to sports, where it commonly denotes the first, leading, or top thing in a group. 1 is the unit of counting or measurement, a determiner for singular nouns, and a gender-neutral pronoun. Historically, the representation of 1 evolved from ancient Sumerian and Babylonian symbols to the modern Arabic numeral.\nIn mathematics, 1 is the multiplicative identity, meaning that any number multiplied by 1 equals the same number. 1 is by convention not considered a prime number. In digital technology, 1 represents the \"on\" state in binary code, the foundation of computing. Philosophically, 1 symbolizes the ultimate reality or source of existence in various traditions.\n\nIn mathematics\nThe number 1 is the first natural number after 0. Each natural number, including 1, is constructed by succession, that is, by adding 1 to the previous natural number. The number 1 is the multiplicative identity of the integers, real numbers, and complex numbers, that is, any number \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n multiplied by 1 remains unchanged (\n  \n    \n      \n        1\n        ×\n        n\n        =\n        n\n        ×\n        1\n        =\n        n\n      \n    \n    {\\displaystyle 1\\times n=n\\times 1=n}\n  \n). As a result, the square (\n  \n    \n      \n        \n          1\n          \n            2\n          \n        \n        =\n        1\n      \n    \n    {\\displaystyle 1^{2}=1}\n  \n), square root (\n  \n    \n      \n        \n          \n            1\n          \n        \n        =\n        1\n      \n    \n    {\\displaystyle {\\sqrt {1}}=1}\n  \n), and any other power of 1 is always equal to 1 itself. 1 is its own factorial (\n  \n    \n      \n        1\n        !\n        =\n        1\n      \n    \n    {\\displaystyle 1!=1}\n  \n), and 0! is also 1. These are a special case of the empty product. Although 1 meets the naïve definition of a prime number, being evenly divisible only by 1 and itself (also 1), by modern convention it is regarded as neither a prime nor a composite number.\nDifferent mathematical constructions of the natural numbers represent 1 in various ways. In Giuseppe Peano's original formulation of the Peano axioms, a set of postulates to define the natural numbers in a precise and logical way, 1 was treated as the starting point of the sequence of natural numbers. Peano later revised his axioms to begin the sequence with 0. In the Von Neumann cardinal assignment of natural numbers, where each number is defined as a set that contains all numbers before it, 1 is represented as the singleton \n  \n    \n      \n        {\n        0\n        }\n      \n    \n    {\\displaystyle \\{0\\}}\n  \n, a set containing only the element 0.\nThe unary numeral system, as used in tallying, is an example of a \"base-1\" number system, since only one mark – the tally itself – is needed. While this is the simplest way to represent the natural numbers, base-1 is rarely used as a practical base for counting due to its difficult readability.\nIn many mathematical and engineering problems, numeric values are typically normalized to fall within the unit interval ([0,1]), where 1 represents the maximum possible value. For example, by definition 1 is the probability of an event that is absolutely or almost certain to occur. Likewise, vectors are often normalized into unit vectors (i.e., vectors of magnitude one), because these often have more desirable properties. Functions are often normalized by the condition that they have integral one, maximum value one, or square integral one, depending on the application.\n1 is the value of Legendre's constant, introduced in 1808 by Adrien-Marie Legendre to express the asymptotic behavior of the prime-counting function. The Weil's conjecture on Tamagawa numbers states that the Tamagawa number \n  \n    \n      \n        τ\n        (\n        G\n        )\n      \n    \n    {\\displaystyle \\tau (G)}\n  \n, a geometrical measure of a connected linear algebraic group over a global number field, is 1 for all simply connected groups (those that are path-connected with no 'holes').\n1 is the most common leading digit in many sets of real-world numerical data. This is a consequence of Benford’s law, which states that the probability for a specific leading digit \n  \n    \n      \n        d\n      \n    \n    {\\displaystyle d}\n  \n is \n  \n    \n      \n        \n          log\n          \n            10\n          \n        \n        ⁡\n        \n          (\n          \n            \n              \n                d\n                +\n                1\n              \n              d\n            \n          \n          )\n        \n      \n    \n    {\\textstyle \\log _{10}\\left({\\frac {d+1}{d}}\\right)}\n  \n. The tendency for real-world numbers to grow exponentially or logarithmically biases the distribution towards smaller leading digits, with ",
    "links": [
      "0",
      "0.999...",
      "0 (number)",
      "1,000,000",
      "1,000,000,000",
      "10",
      "10,000",
      "10,000,000",
      "10,000,000,000",
      "100",
      "100,000",
      "100,000,000",
      "100,000,000,000",
      "1000 (number)",
      "1001 (number)",
      "100 (number)",
      "101 (number)",
      "1023 (number)",
      "1024 (number)",
      "102 (number)",
      "103 (number)",
      "104 (number)",
      "105 (number)",
      "106 (number)",
      "107 (number)",
      "1089 (number)",
      "108 (number)",
      "1093 (number)",
      "109 (number)",
      "10 (number)",
      "1105 (number)",
      "110 (number)",
      "111 (number)",
      "112 (number)",
      "113 (number)",
      "114 (number)",
      "115 (number)",
      "116 (number)",
      "117 (number)",
      "118 (number)",
      "119 (number)",
      "11 (number)",
      "120 (number)",
      "121 (number)",
      "122 (number)",
      "1234 (number)",
      "123 (number)",
      "124 (number)",
      "125 (number)",
      "126 (number)"
    ],
    "categories": [
      "Category:1 (number)",
      "Category:Articles containing Chinese-language text",
      "Category:Articles with short description",
      "Category:Good articles",
      "Category:Integers",
      "Category:Pages using multiple image with auto scaled images",
      "Category:Short description is different from Wikidata",
      "Category:Wikipedia indefinitely semi-protected pages"
    ]
  },
  "Additive number theory": {
    "title": "Additive number theory",
    "url": "https://en.wikipedia.org/wiki/Additive_number_theory",
    "summary": "Additive number theory is the subfield of number theory concerning the study of subsets of integers and their behavior under addition. More abstractly, the field of additive number theory includes the study of abelian groups and commutative semigroups with an operation of addition. Additive number theory has close ties to combinatorial number theory and the geometry of numbers. Principal objects of study include the sumset of two subsets A and B of elements from an abelian group G,\n\n  \n    \n      \n        A\n        +\n        B\n        =\n        {\n        a\n        +\n        b\n        :\n        a\n        ∈\n        A\n        ,\n        b\n        ∈\n        B\n        }\n        ,\n      \n    \n    {\\displaystyle A+B=\\{a+b:a\\in A,b\\in B\\},}\n  \n\nand the h-fold sumset of A, \n\n  \n    \n      \n        h\n        A\n        =\n        \n          \n            \n              \n                \n                  A\n                  +\n                  ⋯\n                  +\n                  A\n              ",
    "content": "Additive number theory is the subfield of number theory concerning the study of subsets of integers and their behavior under addition. More abstractly, the field of additive number theory includes the study of abelian groups and commutative semigroups with an operation of addition. Additive number theory has close ties to combinatorial number theory and the geometry of numbers. Principal objects of study include the sumset of two subsets A and B of elements from an abelian group G,\n\n  \n    \n      \n        A\n        +\n        B\n        =\n        {\n        a\n        +\n        b\n        :\n        a\n        ∈\n        A\n        ,\n        b\n        ∈\n        B\n        }\n        ,\n      \n    \n    {\\displaystyle A+B=\\{a+b:a\\in A,b\\in B\\},}\n  \n\nand the h-fold sumset of A, \n\n  \n    \n      \n        h\n        A\n        =\n        \n          \n            \n              \n                \n                  A\n                  +\n                  ⋯\n                  +\n                  A\n                \n                ⏟\n              \n            \n            h\n          \n        \n        \n        .\n      \n    \n    {\\displaystyle hA={\\underset {h}{\\underbrace {A+\\cdots +A} }}\\,.}\n\nAdditive number theory\nThe field is principally devoted to consideration of direct problems over (typically) the integers, that is, determining the structure of hA from the structure of A: for example, determining which elements can be represented as a sum from hA, where A is a fixed subset. Two classical problems of this type are the Goldbach conjecture (which is the conjecture that 2ℙ contains all even numbers greater than two, where ℙ is the set of primes) and Waring's problem (which asks how large must h be to guarantee that hAk contains all positive integers, where \n\n  \n    \n      \n        \n          A\n          \n            k\n          \n        \n        =\n        {\n        \n          0\n          \n            k\n          \n        \n        ,\n        \n          1\n          \n            k\n          \n        \n        ,\n        \n          2\n          \n            k\n          \n        \n        ,\n        \n          3\n          \n            k\n          \n        \n        ,\n        …\n        }\n      \n    \n    {\\displaystyle A_{k}=\\{0^{k},1^{k},2^{k},3^{k},\\ldots \\}}\n  \n\nis the set of kth powers). Many of these problems are studied using the tools from the Hardy-Littlewood circle method and from sieve methods.  For example, Vinogradov proved that every sufficiently large odd number is the sum of three primes, and so every sufficiently large even integer is the sum of four primes.  Hilbert proved that, for every integer k > 1, every non-negative integer is the sum of a bounded number of kth powers.  In general, a set A of nonnegative integers is called a basis of order h if hA contains all positive integers, and it is called an asymptotic basis if hA contains all sufficiently large integers.  Much current research in this area concerns properties of general asymptotic bases of finite order.  For example, a set A is called a minimal asymptotic basis of order h if A is an asymptotic basis of order h but no proper subset of A is an asymptotic basis of order h.  It has been proved that minimal asymptotic bases of order h exist for all h, and that there also exist asymptotic bases of order h that contain no minimal asymptotic bases of order h. Another question to be considered is how small can the number of representations of n as a sum of h elements in an asymptotic basis can be. This is the content of the Erdős–Turán conjecture on additive bases.\n\nSee also\nShapley–Folkman lemma\nAdditive combinatorics\nMultiplicative combinatorics\nMultiplicative number theory\n\nReferences\nHenry Mann (1976). Addition Theorems: The Addition Theorems of Group Theory and Number Theory (Corrected reprint of 1965 Wiley ed.). Huntington, New York: Robert E. Krieger Publishing Company. ISBN 0-88275-418-1.\nNathanson, Melvyn B. (1996). Additive Number Theory: The Classical Bases. Graduate Texts in Mathematics. Vol. 164. Springer-Verlag. ISBN 0-387-94656-X. Zbl 0859.11002.\nNathanson, Melvyn B. (1996). Additive Number Theory: Inverse Problems and the Geometry of Sumsets. Graduate Texts in Mathematics. Vol. 165. Springer-Verlag. ISBN 0-387-94655-1. Zbl 0859.11003.\nTao, Terence; Vu, Van (2006). Additive Combinatorics. Cambridge Studies in Advanced Mathematics. Vol. 105. Cambridge University Press.\n\nExternal links\n\"Additive number theory\", Encyclopedia of Mathematics, EMS Press, 2001 [1994]\nWeisstein, Eric W. \"Additive Number Theory\". MathWorld.",
    "links": [
      "Abelian group",
      "Addition",
      "Additive combinatorics",
      "Cambridge University Press",
      "Combinatorial number theory",
      "Commutative semigroup",
      "David Hilbert",
      "Encyclopedia of Mathematics",
      "Erdős–Turán conjecture on additive bases",
      "Eric W. Weisstein",
      "European Mathematical Society",
      "Geometry of numbers",
      "Goldbach conjecture",
      "Graduate Texts in Mathematics",
      "Hardy-Littlewood circle method",
      "Henry Mann",
      "ISBN (identifier)",
      "Integer",
      "MathWorld",
      "Multiplicative combinatorics",
      "Multiplicative number theory",
      "Number theory",
      "Prime number",
      "Shapley–Folkman lemma",
      "Sieve theory",
      "Springer-Verlag",
      "Sumset",
      "Terence Tao",
      "Van H. Vu",
      "Waring's problem",
      "Zbl (identifier)"
    ],
    "categories": [
      "Category:Additive number theory",
      "Category:Articles with short description",
      "Category:Short description matches Wikidata"
    ]
  },
  "Amicable numbers": {
    "title": "Amicable numbers",
    "url": "https://en.wikipedia.org/wiki/Amicable_numbers",
    "summary": "In mathematics, the amicable numbers are two different natural numbers related in such a way that the sum of the proper divisors of each is equal to the other number. That is, s(a)=b and s(b)=a, where s(n)=σ(n) − n is equal to the sum of positive divisors of n except n itself (see also divisor function).\nThe smallest pair of amicable numbers is (220, 284). They are amicable because the proper divisors of 220 are 1, 2, 4, 5, 10, 11, 20, 22, 44, 55 and 110, of which the sum is 284; and the proper divisors of 284 are 1, 2, 4, 71 and 142, of which the sum is 220.\nThe first ten amicable pairs are: (220, 284), (1184, 1210), (2620, 2924), (5020, 5564), (6232, 6368), (10744, 10856), (12285, 14595), (17296, 18416), (63020, 76084), and (66928, 66992) (sequence A259180 in the OEIS). It is unknown if there are infinitely many pairs of amicable numbers.\nA pair of amicable numbers constitutes an aliquot sequence of period 2. A related concept is that of a perfect number, which is a number that equal",
    "content": "In mathematics, the amicable numbers are two different natural numbers related in such a way that the sum of the proper divisors of each is equal to the other number. That is, s(a)=b and s(b)=a, where s(n)=σ(n) − n is equal to the sum of positive divisors of n except n itself (see also divisor function).\nThe smallest pair of amicable numbers is (220, 284). They are amicable because the proper divisors of 220 are 1, 2, 4, 5, 10, 11, 20, 22, 44, 55 and 110, of which the sum is 284; and the proper divisors of 284 are 1, 2, 4, 71 and 142, of which the sum is 220.\nThe first ten amicable pairs are: (220, 284), (1184, 1210), (2620, 2924), (5020, 5564), (6232, 6368), (10744, 10856), (12285, 14595), (17296, 18416), (63020, 76084), and (66928, 66992) (sequence A259180 in the OEIS). It is unknown if there are infinitely many pairs of amicable numbers.\nA pair of amicable numbers constitutes an aliquot sequence of period 2. A related concept is that of a perfect number, which is a number that equals the sum of its own proper divisors, in other words a number which forms an aliquot sequence of period 1. Numbers that are members of an aliquot sequence with period greater than 2 are known as sociable numbers.\n\nHistory\nAmicable numbers were known to the Pythagoreans, who credited them with many mystical properties. A general formula by which some of these numbers could be derived was invented circa 850 by the Iraqi mathematician Thābit ibn Qurra (826–901). Other Arab mathematicians who studied amicable numbers are al-Majriti (died 1007), al-Baghdadi (980–1037), and al-Fārisī (1260–1320). The Iranian mathematician Muhammad Baqir Yazdi (16th century) discovered the pair (9363584, 9437056), though this has often been attributed to Descartes. Much of the work of Eastern mathematicians in this area has been forgotten.\nThābit ibn Qurra's formula was rediscovered by Fermat (1601–1665) and Descartes (1596–1650), to whom it is sometimes ascribed, and extended by Euler (1707–1783). It was extended further by Borho in 1972. Fermat and Descartes also rediscovered pairs of amicable numbers known to Arab mathematicians. Euler also discovered dozens of new pairs. The second smallest pair, (1184, 1210), was discovered in 1867 by 16-year-old B. Nicolò I. Paganini (not to be confused with the composer and violinist), having been overlooked by earlier mathematicians.\n\nThere are over 1 billion known amicable pairs.\n\nRules for generation\nWhile these rules do generate some pairs of amicable numbers, many other pairs are known, so these rules are by no means comprehensive.\nIn particular, the two rules below produce only even amicable pairs, so they are of no interest for the open problem of finding amicable pairs coprime to 210 = 2·3·5·7, while over 1000 pairs coprime to 30 = 2·3·5 are known [García, Pedersen & te Riele (2003), Sándor & Crstici (2004)].\n\nThābit ibn Qurrah theorem\nThe Thābit ibn Qurrah theorem is a method for discovering amicable numbers invented in the 9th century by the Arab mathematician Thābit ibn Qurrah.\nIt states that if\n\n  \n    \n      \n        \n          \n            \n              \n                p\n              \n              \n                \n                =\n                3\n                ×\n                \n                  2\n                  \n                    n\n                    −\n                    1\n                  \n                \n                −\n                1\n                ,\n              \n            \n            \n              \n                q\n              \n              \n                \n                =\n                3\n                ×\n                \n                  2\n                  \n                    n\n                  \n                \n                −\n                1\n                ,\n              \n            \n            \n              \n                r\n              \n              \n                \n                =\n                9\n                ×\n                \n                  2\n                  \n                    2\n                    n\n                    −\n                    1\n                  \n                \n                −\n                1\n                ,\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}p&=3\\times 2^{n-1}-1,\\\\q&=3\\times 2^{n}-1,\\\\r&=9\\times 2^{2n-1}-1,\\end{aligned}}}\n  \n\nwhere n > 1 is an integer and p, q, r are prime numbers, then 2n × p × q and 2n × r are a pair of amicable numbers. This formula gives the pairs (220, 284) for n = 2, (17296, 18416) for n = 4, and (9363584, 9437056) for n = 7, but no other such pairs are known. Numbers of the form 3 × 2n − 1 are known as Thabit numbers. In order for Ibn Qurrah's formula to produce an amicable pair, two consecutive Thabit numbers must be prime; this severely restricts the possible values of n.\nTo establish the theorem, Thâbit ibn Qurra proved nine lemmas divided into two groups. The first three lemmas deal with the determin",
    "links": [
      "220 (number)",
      "284 (number)",
      "Abundant number",
      "Achilles number",
      "Addition",
      "Additive persistence",
      "Aliquot sequence",
      "Almost perfect number",
      "Almost prime",
      "Amenable number",
      "American Mathematical Society",
      "Amicable pairs",
      "Amicable triple",
      "Andante (TV series)",
      "Apeirogon (novel)",
      "Arab",
      "Arithmetic dynamics",
      "Arithmetic function",
      "Arithmetic number",
      "Aronson's sequence",
      "Automorphic number",
      "Ban number",
      "Bell number",
      "Betrothed numbers",
      "Bibcode (identifier)",
      "Binary number",
      "Blum integer",
      "Brady Haran",
      "Brian Clegg (writer)",
      "Cake number",
      "Carmichael number",
      "Catalan number",
      "Catalan pseudoprime",
      "Centered cube number",
      "Centered decagonal number",
      "Centered dodecahedral number",
      "Centered heptagonal number",
      "Centered hexagonal number",
      "Centered icosahedral number",
      "Centered nonagonal number",
      "Centered octagonal number",
      "Centered octahedral number",
      "Centered pentagonal number",
      "Centered polygonal number",
      "Centered polyhedral number",
      "Centered square number",
      "Centered tetrahedral number",
      "Centered triangular number",
      "Colossally abundant number",
      "Colum McCann"
    ],
    "categories": [
      "Category:Arithmetic dynamics",
      "Category:Articles with short description",
      "Category:CS1 Italian-language sources (it)",
      "Category:CS1 maint: multiple names: authors list",
      "Category:Divisor function",
      "Category:Integer sequences",
      "Category:Short description matches Wikidata",
      "Category:Webarchive template wayback links",
      "Category:Wikipedia articles incorporating a citation from the 1911 Encyclopaedia Britannica with Wikisource reference",
      "Category:Wikipedia articles incorporating text from the 1911 Encyclopædia Britannica"
    ]
  },
  "An Introduction to the Theory of Numbers": {
    "title": "An Introduction to the Theory of Numbers",
    "url": "https://en.wikipedia.org/wiki/An_Introduction_to_the_Theory_of_Numbers",
    "summary": "An Introduction to the Theory of Numbers is a classic textbook in the field of number theory, by G. H. Hardy and E. M. Wright.  It is on the list of 173 books essential for undergraduate math libraries.\nThe book grew out of a series of lectures by Hardy and Wright and was first published in 1938.\nThe third edition added an elementary proof of the prime number theorem, and the sixth edition added a chapter on elliptic curves.",
    "content": "An Introduction to the Theory of Numbers is a classic textbook in the field of number theory, by G. H. Hardy and E. M. Wright.  It is on the list of 173 books essential for undergraduate math libraries.\nThe book grew out of a series of lectures by Hardy and Wright and was first published in 1938.\nThe third edition added an elementary proof of the prime number theorem, and the sixth edition added a chapter on elliptic curves.\n\nSee also\nList of important publications in mathematics\n\nReferences\nBell, E. T. (1939), \"Book Review: An Introduction to the Theory of Numbers\", Bulletin of the American Mathematical Society, 45 (7): 507–509, doi:10.1090/S0002-9904-1939-07025-0, ISSN 0002-9904\nHardy, Godfrey Harold; Wright, E. M. (1938), An introduction to the theory of numbers. (First ed.), Oxford: Clarendon Press, JFM 64.0093.03, Zbl 0020.29201{{citation}}:  CS1 maint: publisher location (link)\nHardy, Godfrey Harold; Wright, E. M. (1954) [1938], An introduction to the theory of numbers (Third ed.), Oxford, at the Clarendon Press, MR 0067125\nHardy, Godfrey Harold; Wright, E. M. (1971) [1938], An introduction to the theory of numbers (Fourth ed.), The Clarendon Press Oxford University Press\nHardy, Godfrey Harold; Wright, E. M. (1979) [1938], An introduction to the theory of numbers (Fifth ed.), The Clarendon Press Oxford University Press, ISBN 978-0-19-853171-5, MR 0568909\nHardy, Godfrey Harold; Wright, E. M. (2008) [1938], Heath-Brown, D. R.; Silverman, J. H. (eds.), An introduction to the theory of numbers (Sixth ed.), Oxford University Press, ISBN 978-0-19-921986-5, MR 2445243\n\nReviews\nE. T. Bell (July 1939). \"Review: G. H. Hardy and E. M. Wright, An Introduction to the Theory of Numbers\", Bull. Amer. Math. Soc. 45(7): pp. 507–509\nAnderson, Ian (2010). \"Reviews - An introduction to the theory of numbers (sixth edition), by G. H. Hardy and E. M. Wright. Pp. 620. 2008. £30 (paperback). ISBN: 978-0-19-921986-5 (Oxford University Press)\". The Mathematical Gazette. 94 (529): 184. doi:10.1017/S0025557200007464. ISSN 0025-5572.\nRobertson, Edmund; O'Connor, John (July 2020). \"Reviews of G H Hardy and E M Wright's Theory of Numbers\". MacTutor History of Mathematics Archive. Retrieved 29 May 2025.\n\n\n== Citations ==",
    "links": [
      "Academic publishing",
      "Bulletin of the American Mathematical Society",
      "Clarendon Press",
      "Doi (identifier)",
      "E. M. Wright",
      "Elliptic curve",
      "G. H. Hardy",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "JFM (identifier)",
      "List of important publications in mathematics",
      "MR (identifier)",
      "MacTutor History of Mathematics Archive",
      "Mathematics",
      "Number theory",
      "OCLC (identifier)",
      "Oxford University Press",
      "Prime number theorem",
      "Textbook",
      "The Mathematical Gazette",
      "Zbl (identifier)",
      "Wikipedia:Stub",
      "Template:Citation",
      "Template:Mathematics-lit-stub",
      "Template talk:Mathematics-lit-stub",
      "Category:CS1 maint: publisher location"
    ],
    "categories": [
      "Category:1938 non-fiction books",
      "Category:All stub articles",
      "Category:Articles with short description",
      "Category:CS1 maint: publisher location",
      "Category:Mathematics literature stubs",
      "Category:Mathematics textbooks",
      "Category:Number theory",
      "Category:Short description matches Wikidata"
    ]
  },
  "Arakelov theory": {
    "title": "Arakelov theory",
    "url": "https://en.wikipedia.org/wiki/Arakelov_theory",
    "summary": "In mathematics, Arakelov theory (or Arakelov geometry) is an approach to Diophantine geometry, named for Suren Arakelov. It is used to study Diophantine equations in higher dimensions.",
    "content": "In mathematics, Arakelov theory (or Arakelov geometry) is an approach to Diophantine geometry, named for Suren Arakelov. It is used to study Diophantine equations in higher dimensions.\n\nBackground\nThe main motivation behind Arakelov geometry is that there is a correspondence between prime ideals \n  \n    \n      \n        \n          \n            p\n          \n        \n        ∈\n        \n          Spec\n        \n        (\n        \n          Z\n        \n        )\n      \n    \n    {\\displaystyle {\\mathfrak {p}}\\in {\\text{Spec}}(\\mathbb {Z} )}\n  \n and finite places \n  \n    \n      \n        \n          v\n          \n            p\n          \n        \n        :\n        \n          \n            Q\n          \n          \n            ∗\n          \n        \n        →\n        \n          R\n        \n      \n    \n    {\\displaystyle v_{p}:\\mathbb {Q} ^{*}\\to \\mathbb {R} }\n  \n, but there also exists a place at infinity \n  \n    \n      \n        \n          v\n          \n            ∞\n          \n        \n      \n    \n    {\\displaystyle v_{\\infty }}\n  \n, given by the Archimedean valuation, which doesn't have a corresponding prime ideal. Arakelov geometry gives a technique for compactifying \n  \n    \n      \n        \n          Spec\n        \n        (\n        \n          Z\n        \n        )\n      \n    \n    {\\displaystyle {\\text{Spec}}(\\mathbb {Z} )}\n  \n into a complete space \n  \n    \n      \n        \n          \n            \n              \n                Spec\n              \n              (\n              \n                Z\n              \n              )\n            \n            ¯\n          \n        \n      \n    \n    {\\displaystyle {\\overline {{\\text{Spec}}(\\mathbb {Z} )}}}\n  \n which has a prime lying at infinity. Arakelov's original construction studies one such theory, where a definition of divisors is constructed for a scheme \n  \n    \n      \n        \n          \n            X\n          \n        \n      \n    \n    {\\displaystyle {\\mathfrak {X}}}\n  \n of relative dimension 1 over \n  \n    \n      \n        \n          Spec\n        \n        (\n        \n          \n            \n              O\n            \n          \n          \n            K\n          \n        \n        )\n      \n    \n    {\\displaystyle {\\text{Spec}}({\\mathcal {O}}_{K})}\n  \n such that it extends to a Riemann surface \n  \n    \n      \n        \n          X\n          \n            ∞\n          \n        \n        =\n        \n          \n            X\n          \n        \n        (\n        \n          C\n        \n        )\n      \n    \n    {\\displaystyle X_{\\infty }={\\mathfrak {X}}(\\mathbb {C} )}\n  \n for every valuation at infinity. In addition, he equips these Riemann surfaces with Hermitian metrics on holomorphic vector bundles over X(C), the complex points of \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n. This extra Hermitian structure is applied as a substitute for the failure of the scheme Spec(Z) to be a complete variety.\nNote that other techniques exist for constructing a complete space extending \n  \n    \n      \n        \n          Spec\n        \n        (\n        \n          Z\n        \n        )\n      \n    \n    {\\displaystyle {\\text{Spec}}(\\mathbb {Z} )}\n  \n, which is the basis of F1 geometry.\n\nOriginal definition of divisors\nLet \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n be a field, \n  \n    \n      \n        \n          \n            \n              O\n            \n          \n          \n            K\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {O}}_{K}}\n  \n its ring of integers, and \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n a genus \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n  \n curve over \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n with a non-singular model \n  \n    \n      \n        \n          \n            X\n          \n        \n        →\n        \n          Spec\n        \n        (\n        \n          \n            \n              O\n            \n          \n          \n            K\n          \n        \n        )\n      \n    \n    {\\displaystyle {\\mathfrak {X}}\\to {\\text{Spec}}({\\mathcal {O}}_{K})}\n  \n, called an arithmetic surface. Also, let \n  \n    \n      \n        ∞\n        :\n        K\n        →\n        \n          C\n        \n      \n    \n    {\\displaystyle \\infty :K\\to \\mathbb {C} }\n  \n be an inclusion of fields (which is supposed to represent a place at infinity). Also, let \n  \n    \n      \n        \n          X\n          \n            ∞\n          \n        \n      \n    \n    {\\displaystyle X_{\\infty }}\n  \n be the associated Riemann surface from the base change to \n  \n    \n      \n        \n          C\n        \n      \n    \n    {\\displaystyle \\mathbb {C} }\n  \n. Using this data, one can define a c-divisor as a formal linear combination \n  \n    \n      \n        D\n        =\n        \n          ∑\n          \n            i\n          \n        \n        \n          k\n          \n            i\n          \n        \n        \n          C\n          \n            i\n          \n        \n        +\n        \n          ∑\n          \n            ∞\n ",
    "links": [
      "Absolute value (algebra)",
      "Adelic group",
      "Ample line bundle",
      "Annales Scientifiques de l'École Normale Supérieure",
      "Annals of Mathematics",
      "ArXiv (identifier)",
      "Arithmetic surface",
      "Bibcode (identifier)",
      "Bogomolov conjecture",
      "Chern character",
      "Chern class",
      "Chow ring",
      "Christophe Soulé",
      "Complete variety",
      "Compositio Mathematica",
      "Diophantine equation",
      "Diophantine geometry",
      "Doi (identifier)",
      "Emmanuel Ullmo",
      "Encyclopedia of Mathematics",
      "European Mathematical Society",
      "Field with one element",
      "Gerd Faltings",
      "Green's function",
      "Grothendieck–Riemann–Roch theorem",
      "Henri Gillet",
      "Hermitian metric",
      "Hodge theory",
      "Hodge–Arakelov theory",
      "Holomorphic vector bundle",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "Intersection theory",
      "Inventiones Mathematicae",
      "JSTOR (identifier)",
      "Journal of the American Mathematical Society",
      "Lucien Szpiro",
      "MR (identifier)",
      "Mathematics",
      "Mordell conjecture",
      "Noether formula",
      "P-adic Hodge theory",
      "P-adic valuation",
      "Paul Vojta",
      "Pierre Deligne",
      "Power series",
      "Riemann surface",
      "S2CID (identifier)",
      "Scheme (mathematics)",
      "Serge Lang"
    ],
    "categories": [
      "Category:Algebraic geometry",
      "Category:Articles with short description",
      "Category:Diophantine geometry",
      "Category:Short description matches Wikidata"
    ]
  },
  "Accident analysis": {
    "title": "Accident analysis",
    "url": "https://en.wikipedia.org/wiki/Accident_analysis",
    "summary": "Accident analysis is a process carried out in order to determine the cause or causes of an accident (that can result in single or multiple outcomes) so as to prevent further accidents of a similar kind. It is part of accident investigation or incident investigation . These analyses may be performed by a range of experts, including forensic scientists, forensic engineers or health and safety advisers. Accident investigators, particularly those in the aircraft industry, are colloquially known as \"tin-kickers\". Health and safety and patient safety professionals prefer using the term \"incident\" in place of the term \"accident\". Its retrospective nature means that accident analysis is primarily an exercise of directed explanation; conducted using the theories or methods the analyst has to hand, which directs the way in which the events, aspects, or features of accident phenomena are highlighted and explained. These analyses are also invaluable in determining ways to prevent future incidents ",
    "content": "Accident analysis is a process carried out in order to determine the cause or causes of an accident (that can result in single or multiple outcomes) so as to prevent further accidents of a similar kind. It is part of accident investigation or incident investigation . These analyses may be performed by a range of experts, including forensic scientists, forensic engineers or health and safety advisers. Accident investigators, particularly those in the aircraft industry, are colloquially known as \"tin-kickers\". Health and safety and patient safety professionals prefer using the term \"incident\" in place of the term \"accident\". Its retrospective nature means that accident analysis is primarily an exercise of directed explanation; conducted using the theories or methods the analyst has to hand, which directs the way in which the events, aspects, or features of accident phenomena are highlighted and explained. These analyses are also invaluable in determining ways to prevent future incidents from occurring. They provide good insight by determining root causes, into what failures occurred that led to the incident.\n\nSequence\nAccident analysis is generally performed in four key steps. OSHA combines the last two steps into a singular final step of preparing and issuing a report. However, most organizations follow some form of these steps, in this order:\n\nFact gathering: After an accident, a forensic process is started to gather all possibly relevant facts that may contribute to understanding the accident. This can be physical evidence, digital evidence, and/or first-hand accounts from witnesses. In occupational settings, this could also be records of machinery, personnel present, and operating procedures.\nFact Analysis: After the forensic process has been completed or at least delivered some results, the facts are put together to give a \"big picture.\" The history of the accident is reconstructed and checked for consistency and plausibility. This is also where the use of analysis methods can come into play.\n\nConclusion Drawing: If the accident history is sufficiently informative, conclusions can be drawn. These conclusions can be firm findings that were direct causing factors or they can be a list of possible contributing factors.\nCounter-measures: In some cases, the development of counter-measures or recommendations are made to prevent further accidents of the same kind. The analysis step can also aid in pointing out other possible risk factors that could be mitigated during this step. These counter measures can be things like the implementation of controls following the hierarchy of controls.\n\nMethods\nThere exist numerous forms of Accident Analysis methods. These can generally be divided into four main categories which break up how and who completes the analysis.\n\nCausal Analysis (Root cause analysis) uses the principle of causality to determine the course of events. Though people casually speak of a \"chain of events\", results from Causal Analysis usually have the form of directed a-cyclic graphs – the nodes being events and the edges the cause-effect relations. Methods of Causal Analysis differ in their respective notion of causation.\nSystematic Analysis relies on using a standardized system or model for developing conclusions. This tends to be a rigorous effort that is performed by an expert. This method leaves little room for doubt and can be beneficial by ensuring expert bias does not come into play.\nExpert Analysis relies on the knowledge and experience of field experts. This form of analysis usually lacks a rigorous (formal/semiformal) methodological approach. This usually affects falsifiability and objectivity of analyses. This is of importance when conclusions are heavily disputed among experts.\nOrganizational Analysis relies on systemic theories of organization. Most theories imply that if a system's behavior stayed within the bounds of the ideal organization then no accidents can occur. Organizational Analysis can be falsified and results from analyses can be checked for objectivity. Choosing an organizational theory for accident analysis comes from the assumption that the system to be analyzed conforms to that theory.\n\nModels\nMany models or systems have been developed to characterise and analyse accidents.\n\nSome of common models are similar to Hazard Analysis models. When used for accident analysis they are worked in reverse. Instead of trying to identify possibly problems and ways to mitigate those problems, the models are used to find the cause of an incident that has already occurred. Some common types of these models include the Five Why's model, Ishikawa (fishbone) diagram, the Fault Tree Analysis (FTA), or the Failure Mode and Effect Analysis (FMEA).\n\nFive Why's Model: Also known as \"Why-Because\" model, this model uses the idea of breaking an incident up into the fine details. Asking why something occurred, and what occurred that made that happen. It is used to determine exact causes and can extend m",
    "links": [
      "AcciMap approach",
      "Accident",
      "Accident classification",
      "Chain of events (accident analysis)",
      "Debugging",
      "Directed acyclic graph",
      "Doi (identifier)",
      "Failure mode and effects analysis",
      "Falsifiability",
      "Fault tree analysis",
      "Forensic engineering",
      "Forensic photography",
      "Forensic science",
      "Forensic scientists",
      "Hazard analysis",
      "Health and safety",
      "Hierarchy of hazard controls",
      "Human factors and ergonomics",
      "Human reliability",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "Ishikawa diagram",
      "Patient safety",
      "Photogrammetry",
      "Pilot error",
      "Risk matrix",
      "Root cause analysis",
      "Safety engineering",
      "Swiss cheese model",
      "System accident",
      "Trace evidence",
      "Help:Authority control"
    ],
    "categories": [
      "Category:Accident analysis",
      "Category:Analysis",
      "Category:Articles with short description",
      "Category:Failure",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Agroecosystem analysis": {
    "title": "Agroecosystem analysis",
    "url": "https://en.wikipedia.org/wiki/Agroecosystem_analysis",
    "summary": "Agroecosystem analysis is a thorough analysis of an agricultural environment which considers aspects from ecology, sociology, economics, and politics with equal weight. There are many aspects to consider; however, it is literally impossible to account for all of them. This is one of the issues when trying to conduct an analysis of an agricultural environment.\nIn the past, an agroecosystem analysis approach might be used to determine the sustainability of an agricultural system. It has become apparent, however, that the \"sustainability\" of the system depends heavily on the definition of sustainability chosen by the observer. Therefore, agroecosystem analysis is used to bring the richness of the true complexity of agricultural systems to an analysis to identify reconfigurations of the system (or holon) that will best suit individual situations.\nAgroecosystem analysis is a tool of the multidisciplinary subject known as Agroecology. Agroecology and agroecosystem analysis are not the same a",
    "content": "Agroecosystem analysis is a thorough analysis of an agricultural environment which considers aspects from ecology, sociology, economics, and politics with equal weight. There are many aspects to consider; however, it is literally impossible to account for all of them. This is one of the issues when trying to conduct an analysis of an agricultural environment.\nIn the past, an agroecosystem analysis approach might be used to determine the sustainability of an agricultural system. It has become apparent, however, that the \"sustainability\" of the system depends heavily on the definition of sustainability chosen by the observer. Therefore, agroecosystem analysis is used to bring the richness of the true complexity of agricultural systems to an analysis to identify reconfigurations of the system (or holon) that will best suit individual situations.\nAgroecosystem analysis is a tool of the multidisciplinary subject known as Agroecology. Agroecology and agroecosystem analysis are not the same as sustainable agriculture, though the use of agroecosystem analysis may help a farming system ensure its viability. Agroecosystem analysis is not a new practice, agriculturalists and farmers have been doing it since societies switched from hunting and gathering (hunter-gatherer) for food to settling in one area. Every time a person involved in agriculture evaluates their situation to identify methods to make the system function in a way that better suits their interests, they are performing an agroecosystem analysis.\n\nAgroecosystem analysis and sustainable agriculture differ\nIt is difficult to discuss these differences without the aid of an example. Consider the case of a conventional (see conventional agriculture) apple farmer. This farmer may choose to change his farm to conform to the standards of USDA approved organic agriculture because he felt motivated by social or moral norms or the potential of increased profits or a host of other reasons. This farmer evaluated his situation and reconfigured it to try to improve it. Some might look at this situation and conclude that the apple farmer chose organic apple production because it is more sustainable for the environment. But, what if a few years later the farmer finds that he is struggling to make a profit and decides to go back to conventional agriculture?  The farmer performed another agroecosystem analysis and arrived at a reconfiguration that some might see as unsustainable. This example illustrates how agroecosystem analysis is not required to lead a more environmentally sustainable form of agriculture. Agroecosystem analysis might produce a reconfiguration that is more economically sustainable or socially sustainable or politically sustainable for a farmer (or other actor). By definition, however, agroecosystem analysis is not required to produce an environmentally sustainable configuration for an agricultural system.\n\nApproach to analysis\nWilliam L. Bland, from the University of Wisconsin–Madison, developed the idea of a farm as a Holon (philosophy) This term, holon, was originally introduced by Arthur Koestler in 1966, in which he referred to a holon as an entity in which it is a part by itself, a holon, while contributing to a larger entity, which is also a holon. Bland develops this for an agricultural environment or farm as, \"The farm holon is both the whole in which smaller holons exists, and a part of larger entities, themselves holons.\" This idea was expanded upon by Bland and Michael M. Bell University of Wisconsin–Madison in their 2007 article \"A holon approach to agroecology,\" because it is difficult to account for boundary and change when using a systems thinking approach. One major difference between Koestler's holon and the holon idea developed for agroecosystem analysis is that the latter can only be defined as a holon if it has intentionality.\nThe farm itself is a holon and within the farm holon, other holons exist. For example, a farm animal, the farm family, and a farmworker can all be considered holons within the farm. Additionally, the farm is considered a holon which is in part connected to other holons such as the county in which the farm resides, the bank from which the farmer borrowed money, or the grain elevator where the farmer can sell goods. Things like the tractor or the barn are not holons because they lack intentionality.\nWhen conducting an agroecosystem analysis, the analyst should approach the farm as the farm itself and the \"ecology of contexts\" in which the farm and the farmer function. A \"context\" is anything that might influence functioning of the farm and cause it to change. According to Bland and Bell, examples of contexts include, \"family, farm business, genetic heart disease, and spiritual beliefs.\" These examples illustrate the breadth of contexts that could influence why farmers do what they do. Bland concluded his model of a farm as a holon by stating, \"A farm is not sustainable (disintegrates) when it cannot find an overall",
    "links": [
      "Agricultural",
      "Agriculturalists",
      "Agroecology",
      "Agroecosystem",
      "Arthur Koestler",
      "Bank",
      "Barn",
      "Conventional agriculture",
      "County",
      "Dordt College",
      "Ecology",
      "Ecology of contexts",
      "Economics",
      "Family",
      "Farm",
      "Farmer",
      "Farmers",
      "Farmworker",
      "Grain elevator",
      "Holon (philosophy)",
      "Hunter-gatherer",
      "ISBN (identifier)",
      "Intentionality",
      "Livestock",
      "Organic agriculture",
      "Politics",
      "Sociology",
      "Sustainability",
      "Sustainable",
      "Sustainable agriculture",
      "Systems thinking",
      "Tractor",
      "USDA",
      "University of Wisconsin–Madison",
      "Wayback Machine"
    ],
    "categories": [
      "Category:Agriculture",
      "Category:Agroecology",
      "Category:Agronomy",
      "Category:Webarchive template wayback links"
    ]
  },
  "Analysis (Homer)": {
    "title": "Homeric scholarship",
    "url": "https://en.wikipedia.org/wiki/Homeric_scholarship",
    "summary": "Homeric scholarship is the study of any Homeric topic, especially the two large surviving epics, the Iliad and Odyssey. It is currently part of the academic discipline of classical studies. The subject is one of the oldest in education.",
    "content": "Homeric scholarship is the study of any Homeric topic, especially the two large surviving epics, the Iliad and Odyssey. It is currently part of the academic discipline of classical studies. The subject is one of the oldest in education.\n\nAncient scholarship\nScholia\nScholia are ancient commentaries, preserved in the margins of manuscripts. The term marginalia includes them. Some are interlinear, written in very small characters. Over time the scholia were copied along with the work. When the copyist ran out of free text space, he listed them on separate pages or in separate works. The works of Homer have been heavily annotated since antiquity.\nThe number of manuscripts of the Iliad is currently (2014) approximately 1800. The papyri of the Odyssey are fewer in number but are still in the order of dozens. The inventory is incomplete, and new finds continue to be made, but not all these texts contain scholia. No compendium has collated all of the Homeric scholia.\nFollowing the Principle of Economy for the allocation of scarce publication space to overwhelming numbers of scholia, the compilers have had to make decisions about what is important enough to compile. Certain types have been distinguished; scholia have lines of descent of their own. Eleanor Dickey summarizes the most important three, identified by letter as A, bT, and D.\nA, \"the Venetian scholia\", are the scholia of Venetus A, a major manuscript of the Iliad, dated to the 10th century, and located in the Biblioteca Marciana (Library of St. Mark's) of Venice. The sources of the scholia are noted at the end of each book. There are basically four. The hypothetical original text of the scholia, a manuscript of the 4th century CE, is therefore called, in German, the Viermännerkommentar (VMK), \"four-man commentary\", where the men are Aristonicus, Didymus, Herodian, and Nicanor. Their comments, and these scholia, are termed \"critical\". A-scholia are found in other manuscripts as well. Venetus A contains some bT scholia.\nThe bT-scholia have come down to us through two sources: the 11th century T, the \"Townleian\" scholia, so designated because the manuscript, Townleyanus, was once in the collection of Lord Townley, and a lost manuscript, b, whose descendants include the manuscript known as Venetus B. The bT manuscripts descend from an earlier manuscript, c. The bT-scholia are termed exegetical, as opposed to critical.\nThe D scholia, or scholia Didymi, named erroneously for Didymus, are the earliest and largest group. They occur primarily in the 9th century Z manuscript (Rome, Biblioteca Nazionale), and the 11th century Q manuscript, but also in some others, such as A and T. The D scholia were once thought to be the work of the 1st century BCE scholar Didymus; they are now known to go back to 5th and 4th century BCE school manuscripts, pre-dating the Alexandrine tradition, and representing “the oldest surviving stratum of Homeric scholarship.” Some are also called the scholia minora and the scholia vulgata, the former name referring to the short length of many. These are glossaries. Among the non-minor scholia are mythological (allegorical) aetia, plots, and paraphrases, explaining the meanings of obscure words.\nThe order of precedence and chronological order of these Iliad scholia is D, A, bT, and other. Material in them probably ranges from the 5th century BCE (the D scholia) to as late as the 7th or 8th century CE (the latest bT scholia). The same scheme applies to the Odyssey, except that A scholia, mainly of the Iliad, are in deficit. There are no printed works publishing all the scholia on the Iliad and Odyssey. Only partial publications according to various principles have been possible.\nThe first was that of Janus Lascaris in 1517, containing the D-scholia. Some subsequent works concentrate on manuscripts or parts of them, others on type of scholia, and still others on books of the Iliad, or source. Larger compendia are relatively recent. One that has already become a standard is the 7-volume compendium of A- and bT-scholia by Hartmut Erbse. Volumes 1–5 are reserved for a number of books of the Iliad each, amounting to some 3000 pages, approximately. The last two volumes are indices. And yet, Dickey says of it. “The seven volumes of Erbse’s edition thus represent only a small fraction of all the preserved scholia ...,” from which it can be seen that the opinions, elucidations and emendations to the Iliad and Odyssey in manuscript texts far outweigh those texts in numbers of pages.\n\nClassical scholarship\nBy the Classical Period the Homeric Question had advanced to the point of trying to determine what works were attributable to Homer. The Iliad and the Odyssey were beyond question. They were considered to have been written by Homer. The D-scholia suggest that they were taught in the schools; however, the language was no longer self-evident. The extensive glossaries of the D-scholia were intended to bridge the gap between the spoken language and Homeric G",
    "links": [
      "A True Story",
      "Acamas",
      "Achilles",
      "Achilles' heel",
      "Achilles and Briseis",
      "Achilles and Patroclus",
      "Achilleus",
      "Aeaea",
      "Aelius Herodianus",
      "Aeneas",
      "Aeneid",
      "Aeolia (mythical island)",
      "Aeolic Greek",
      "Aeolus",
      "Aesepus",
      "Against Apion",
      "Agamemnon",
      "Agapenor",
      "Age of Bronze (comics)",
      "Agelaus",
      "Agenor, son of Antenor",
      "Aithiopis",
      "Ajax the Great",
      "Ajax the Lesser",
      "Albania",
      "Albanian epic poetry",
      "Albert Lord",
      "Alcathous",
      "Alcimus (mythology)",
      "Alcinous",
      "Alexander Pope",
      "Alexander the Great",
      "Alexandria",
      "Alfred Heubeck",
      "Allegorical interpretations of Plato",
      "Ambrosian Iliad",
      "Amphimachus",
      "Amphimedon",
      "Amphinomus",
      "Anchises",
      "And Then There Was Silence",
      "Andromache",
      "Andromache Mourning Hector",
      "Angelo Colocci",
      "Antenor (Trojan)",
      "Anthology",
      "Anticlea",
      "Anticlus",
      "Antilochus",
      "Antinous of Ithaca"
    ],
    "categories": [
      "Category:All articles with unsourced statements",
      "Category:Articles containing Ancient Greek (to 1453)-language text",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from August 2015",
      "Category:Articles with unsourced statements from December 2024",
      "Category:Articles with unsourced statements from November 2010",
      "Category:CS1 German-language sources (de)",
      "Category:CS1 Greek-language sources (el)",
      "Category:CS1 Latin-language sources (la)",
      "Category:CS1 errors: ISBN date"
    ]
  },
  "Analysis (journal)": {
    "title": "Analysis (journal)",
    "url": "https://en.wikipedia.org/wiki/Analysis_(journal)",
    "summary": "Analysis is a peer-reviewed academic journal of philosophy established in 1933 that is published quarterly by Oxford University Press on behalf of the Analysis Trust. Prior to January 2009, the journal was published by Blackwell Publishing. Electronic access to this journal is available via JSTOR (1933–2013), Wiley InterScience (1996–2008), and Oxford Journals (2009–present). The journal publishes short, concise articles (of up to 4000 words, excluding bibliography) in virtually any field of the analytic tradition.",
    "content": "Analysis is a peer-reviewed academic journal of philosophy established in 1933 that is published quarterly by Oxford University Press on behalf of the Analysis Trust. Prior to January 2009, the journal was published by Blackwell Publishing. Electronic access to this journal is available via JSTOR (1933–2013), Wiley InterScience (1996–2008), and Oxford Journals (2009–present). The journal publishes short, concise articles (of up to 4000 words, excluding bibliography) in virtually any field of the analytic tradition.\n\nEditors\n1933–1948: Austin Duncan-Jones\n1948–1956: Margaret MacDonald\n1956–1965: Bernard Mayo\n1965–1971: Peter Winch\n1971–1976: C. J. F. Williams\n1976–1987: Christopher Kirwan\n1987–1999: Peter Smith\n2000–2016: Michael Clark\n2016–2017: Chris Daly and David Liggins\n2017–2021: David Liggins\n2021–2024: David Liggins, Stacie Friend, and Lee Walters\n2024–present: Stacie Friend, Lee Walters, and Roger Clark\n\nNoteworthy articles\nA number of noteworthy works by notable authors have been published in the journal. These include{\n\nToulmin, Stephen. (1948). \"The Logical Status of Psycho-Analysis\". 9 (2), pp. 23–29.\nChurch, Alonzo. (1950). \"On Carnap's Analysis of Statements of Assertion and Belief\". 10 (5), pp. 97–99.\nAnderson, Alan Ross. (1951). \"A Note on Subjunctive and Counterfactual Conditionals\". 12 (2), pp. 35–38.\nNuel Belnap. (1962) \"Tonk, Plonk and Plink\". 22 (6) pp. 130–134.\nGettier, Edmund. (1963). \"Is Justified True Belief Knowledge?\". 23 (6), pp. 121–123.\nLewis, David. (1988). \"Vague Identity: Evans Misunderstood\". 48 (3), pp. 128–130.\nClark, Andy and Chalmers, David. (1998). \"The Extended Mind\". 58 (1), pp. 7–19.\nKnobe, Joshua. (2003). \"Intentional Action and Side Effects in Ordinary Language\". 63 (279), pp. 190–194.\n\nSee also\nList of philosophy journals\n\nReferences\nExternal links\nOfficial website\n\"Analysis article listing search page\" – via JSTOR.\nAnalysis (journal) at PhilPapers",
    "links": [
      "Academic journal",
      "Academic publishing",
      "Alan Ross Anderson",
      "Alonzo Church",
      "American Philosophical Quarterly",
      "Analytic philosophy",
      "Ancient Philosophy (journal)",
      "Andy Clark",
      "Apeiron (philosophy journal)",
      "Archiv für Begriffsgeschichte",
      "Archiv für Geschichte der Philosophie",
      "Augustinian Studies",
      "Austin Duncan-Jones",
      "Australasian Journal of Philosophy",
      "Berkeley Studies",
      "Bernard Mayo",
      "British Journal for the History of Philosophy",
      "British Journal for the Philosophy of Science",
      "British Journal of Aesthetics",
      "C. J. F. Williams",
      "Canadian Journal of Philosophy",
      "David Chalmers",
      "David Lewis (philosopher)",
      "David Liggins",
      "Deleuze Studies",
      "Derrida Today",
      "Dionysius (journal)",
      "Editor-in-chief",
      "Edmund Gettier",
      "Epoché (journal)",
      "Erkenntnis",
      "Ethics (journal)",
      "European Journal of Philosophy",
      "Feminist Philosophy Quarterly",
      "Hegel-Studien",
      "Hegel Bulletin",
      "Heidegger Studies",
      "History of Philosophy Quarterly",
      "Hume Studies",
      "Hypatia (journal)",
      "ISO 4",
      "ISSN (identifier)",
      "International Journal of Applied Philosophy",
      "International Journal of Baudrillard Studies",
      "Is Justified True Belief Knowledge?",
      "Isis (journal)",
      "JSTOR",
      "JSTOR (identifier)",
      "John Wiley & Sons",
      "Joshua Knobe"
    ],
    "categories": [
      "Category:Academic journals established in 1933",
      "Category:Analytic philosophy literature",
      "Category:Articles with short description",
      "Category:English-language journals",
      "Category:Logic journals",
      "Category:Oxford University Press academic journals",
      "Category:Quarterly journals",
      "Category:Quarterly journals (infobox)",
      "Category:Short description is different from Wikidata",
      "Category:Use dmy dates from April 2022"
    ]
  },
  "Analysis of variance": {
    "title": "Analysis of variance",
    "url": "https://en.wikipedia.org/wiki/Analysis_of_variance",
    "summary": "Analysis of variance (ANOVA) is a family of statistical methods used to compare the means of two or more groups by analyzing variance. Specifically, ANOVA compares the amount of variation between the group means to the amount of variation within each group. If the between-group variation is substantially larger than the within-group variation, it suggests that the group means are likely different. This comparison is done using an F-test. The underlying principle of ANOVA is based on the law of total variance, which states that the total variance in a dataset can be broken down into components attributable to different sources. In the case of ANOVA, these sources are the variation between groups and the variation within groups. \nANOVA was developed by the statistician Ronald Fisher. In its simplest form, it provides a statistical test of whether two or more population means are equal, and therefore generalizes the t-test beyond two means.",
    "content": "Analysis of variance (ANOVA) is a family of statistical methods used to compare the means of two or more groups by analyzing variance. Specifically, ANOVA compares the amount of variation between the group means to the amount of variation within each group. If the between-group variation is substantially larger than the within-group variation, it suggests that the group means are likely different. This comparison is done using an F-test. The underlying principle of ANOVA is based on the law of total variance, which states that the total variance in a dataset can be broken down into components attributable to different sources. In the case of ANOVA, these sources are the variation between groups and the variation within groups. \nANOVA was developed by the statistician Ronald Fisher. In its simplest form, it provides a statistical test of whether two or more population means are equal, and therefore generalizes the t-test beyond two means.\n\nHistory\nWhile the analysis of variance reached fruition in the 20th century, antecedents extend centuries into the past according to Stigler. These include hypothesis testing, the partitioning of sums of squares, experimental techniques and the additive model. Laplace was performing hypothesis testing in the 1770s. Around 1800, Laplace and Gauss developed the least-squares method for combining observations, which improved upon methods then used in astronomy and geodesy. It also initiated much study of the contributions to sums of squares. Laplace knew how to estimate a variance from a residual (rather than a total) sum of squares. By 1827, Laplace was using least squares methods to address ANOVA problems regarding measurements of atmospheric tides. Before 1800, astronomers had isolated observational errors resulting \nfrom reaction times (the \"personal equation\") and had developed methods of reducing the errors. The experimental methods used in the study of the personal equation were later accepted by the emerging field of psychology  which developed strong (full factorial) experimental methods to which randomization and blinding were soon added. An eloquent non-mathematical explanation of the additive effects model was available in 1885.\nRonald Fisher introduced the term variance and proposed its formal analysis in a 1918 article on theoretical population genetics, The Correlation Between Relatives on the Supposition of Mendelian Inheritance. His first application of the analysis of variance to data analysis was published in 1921, Studies in Crop Variation I. This divided the variation of a time series into components representing annual causes and slow deterioration. Fisher's next piece, Studies in Crop Variation II, written with Winifred Mackenzie and published in 1923, studied the variation in yield across plots sown with different varieties and subjected to different fertiliser treatments.  Analysis of variance became widely known after being included in Fisher's 1925 book Statistical Methods for Research Workers.\nRandomization models were developed by several researchers. The first was published in Polish by Jerzy Neyman in 1923.\n\nExample\nThe analysis of variance can be used to describe otherwise complex relations among variables. A dog show provides an example. A dog show is not a random sampling of the breed: it is typically limited to dogs that are adult, pure-bred, and exemplary. A histogram of dog weights from a show is likely to be rather complicated, like the yellow-orange distribution shown in the illustrations. Suppose we wanted to predict the weight of a dog based on a certain set of characteristics of each dog. One way to do that is to explain the distribution of weights by dividing the dog population into groups based on those characteristics. A successful grouping will split dogs such that (a) each group has a low variance of dog weights (meaning the group is relatively homogeneous) and (b) the mean of each group is distinct (if two groups have the same mean, then it isn't reasonable to conclude that the groups are, in fact, separate in any meaningful way).\nIn the illustrations to the right, groups are identified as X1, X2, etc. In the first illustration, the dogs are divided according to the product (interaction) of two binary groupings: young vs old, and short-haired vs long-haired (e.g., group 1 is young, short-haired dogs, group 2 is young, long-haired dogs, etc.). Since the distributions of dog weight within each of the groups (shown in blue) has a relatively large variance, and since the means are very similar across groups, grouping dogs by these characteristics does not produce an effective way to explain the variation in dog weights: knowing which group a dog is in doesn't allow us to predict its weight much better than simply knowing the dog is in a dog show. Thus, this grouping fails to explain the variation in the overall distribution (yellow-orange).\nAn attempt to explain the weight distribution by grouping dogs as pet vs working breed and le",
    "links": [
      "ANOVA-simultaneous component analysis",
      "ANOVA on ranks",
      "A priori and a posteriori",
      "Accelerated failure time model",
      "Actuarial science",
      "Adaptive clinical trial",
      "Air pollution",
      "Akaike information criterion",
      "Alternative hypothesis",
      "Analysis of covariance",
      "Analysis of molecular variance",
      "Analysis of rhythmic variance",
      "Anderson–Darling test",
      "Approximation theory",
      "ArXiv (identifier)",
      "Arithmetic mean",
      "Arithmetic–geometric mean",
      "Asymptomatic carrier",
      "Asymptotic theory (statistics)",
      "Autocorrelation",
      "Autoregressive conditional heteroskedasticity",
      "Autoregressive–moving-average model",
      "Auxology",
      "Average absolute deviation",
      "Bachelor of Science in Public Health",
      "Bar chart",
      "Bartlett's test",
      "Bayes estimator",
      "Bayes factor",
      "Bayesian experimental design",
      "Bayesian inference",
      "Bayesian information criterion",
      "Bayesian linear regression",
      "Bayesian probability",
      "Behavior change (public health)",
      "Behavioural change theories",
      "Bias of an estimator",
      "Binomial regression",
      "Bioinformatics",
      "Biological hazard",
      "Biostatistics",
      "Biplot",
      "Blind experiment",
      "Blocking (statistics)",
      "Bootstrapping (statistics)",
      "Box plot",
      "Box–Behnken design",
      "Box–Jenkins method",
      "Breusch–Godfrey test",
      "Calibration curve"
    ],
    "categories": [
      "Category:All articles with incomplete citations",
      "Category:All articles with unsourced statements",
      "Category:All pages needing factual verification",
      "Category:Analysis of variance",
      "Category:Articles with incomplete citations from November 2012",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from October 2013",
      "Category:CS1: long volume value",
      "Category:CS1 maint: location missing publisher",
      "Category:Commons category link is on Wikidata"
    ]
  },
  "Anthropological linguistics": {
    "title": "Anthropological linguistics",
    "url": "https://en.wikipedia.org/wiki/Anthropological_linguistics",
    "summary": "Anthropological linguistics is the subfield of linguistics and anthropology which deals with the place of language in its wider social and cultural context, and its role in making and maintaining cultural practices and societal structures. While many linguists believe that a true field of anthropological linguistics is nonexistent, preferring the term linguistic anthropology to cover this subfield, many others regard the two as interchangeable.",
    "content": "Anthropological linguistics is the subfield of linguistics and anthropology which deals with the place of language in its wider social and cultural context, and its role in making and maintaining cultural practices and societal structures. While many linguists believe that a true field of anthropological linguistics is nonexistent, preferring the term linguistic anthropology to cover this subfield, many others regard the two as interchangeable.\n\nHistory\nAlthough researchers studied the two fields together at various points in the nineteenth century, the intersection of anthropology and linguistics significantly grew in prominence during the early twentieth century. As American scholarship became increasingly interested in the diversity of Native American societies in the New World, anthropologists and linguists worked in conjunction to analyze Native American languages and to study how language related to the origins, distribution, and characteristics of these indigenous populations.\nThis interdisciplinary approach distinguished American anthropology from its European counterpart; while European anthropology largely focused on ethnography, American anthropology began to integrate linguistics and other disciplines. Anthropological linguistics initially focused largely on unwritten language, but now examines languages both with and without written traditions.\nEarly anthropological linguists primarily focused on three major areas: linguistic description, classification, and methodology.\n\nLinguistic Description: Scholars such as Franz Boas, Edward Sapir, Leonard Bloomfield, and Mary Haas drafted descriptions of linguistic structure and the linguistic characteristics of different languages. They conducted research as fieldwork, using recordings of texts from native speakers and performing analysis to categorize the texts by linguistic form and genre.\nClassification: Classification involved outlining the genetic relationships among languages. Linguistic classifications allowed anthropological linguists to organize large amounts of information about specific populations. By classifying language, scholars could systematize and order data from their ethnographic work.\nMethodology: By analytically breaking down language, anthropological linguistics could use the constituent parts to derive social and cultural information. It also made pattern-identification possible, with Boas and Sapir using these procedures to show that linguistic patterning was unrealized among speakers of a given language.\n\nOverview\nAnthropological linguistics is one of many disciplines which studies the role of languages in the social lives of individuals and within communities. To do this, experts have had to understand not only the logic behind linguistic systems – such as their grammars – but also record the activities in which those systems are used. In the 1960s and 1970s, sociolinguistics and anthropological linguistics were often viewed as one single field of study, but they have since become more separate as more academic distance has been put between them. Though there are many similarities and a definite sharing of topics – such as gender and language – they are two related but separate entities. Anthropological linguistics came about in the United States as a subfield of anthropology, when anthropologists were beginning to study the indigenous cultures, and the indigenous languages could no longer be ignored, and quickly morphed into the subfield of linguistics that it is known as today.\nAnthropological linguistics has had a major impact in the studies of such areas as visual perception (especially colour) and bioregional democracy, both of which are concerned with distinctions that are made in languages about perceptions of the surroundings.\nConventional linguistic anthropology also has implications for sociology and self-organization of peoples. Study of the Penan people, for instance, reveals that their language employs six different and distinct words whose best English translation is \"we\". Anthropological linguistics studies these distinctions, and relates them to types of societies and to actual bodily adaptation to the senses, much as it studies distinctions made in languages regarding the colours of the rainbow: seeing the tendency to increase the diversity of terms, as evidence that there are distinctions that bodies in this environment must make, leading to situated knowledge and perhaps a situated ethics, whose final evidence is the differentiated set of terms used to denote \"we\".\nThe two branches of anthropological linguistics are nomenclatural/classificational and ethnographic/sociolinguistics.\nIndexicality refers to language forms that is tied to meaning through association of specific and general, as opposed to direct naming. For example, an anthropological linguist may utilize indexicality to analyze what an individual's use of language reveals about his or her social class. Indexicality is inherent in form-function re",
    "links": [
      "Actor–network theory",
      "Aerial archaeology",
      "Africa",
      "Alabama",
      "Alliance theory",
      "American English",
      "Anthropological Linguistics (journal)",
      "Anthropological theories of value",
      "Anthropology",
      "Anthropology of art",
      "Anthropology of development",
      "Anthropology of food",
      "Anthropology of institutions",
      "Anthropology of media",
      "Anthropology of religion",
      "Anthropometry",
      "Anthrozoology",
      "Applied anthropology",
      "Applied linguistics",
      "Archaeology",
      "Australia",
      "Autonomy of syntax",
      "Aviation archaeology",
      "Battlefield archaeology",
      "Behaviorism",
      "Bias",
      "Biblical archaeology",
      "Bibliography of anthropology",
      "Bioarchaeology",
      "Biocultural anthropology",
      "Biological anthropology",
      "Bioregional democracy",
      "Boasian anthropology",
      "Code-switching",
      "Cognitive anthropology",
      "Cognitive grammar",
      "Colonialism",
      "Colour",
      "Comparative method",
      "Computational linguistics",
      "Conservative and innovative language",
      "Construction grammar",
      "Context (language use)",
      "Conversation analysis",
      "Corpus linguistics",
      "Cross-cultural studies",
      "Cultural anthropology",
      "Cultural materialism (anthropology)",
      "Cultural relativism",
      "Culture"
    ],
    "categories": [
      "Category:Anthropological linguistics",
      "Category:Articles with short description",
      "Category:Commons category link from Wikidata",
      "Category:Short description matches Wikidata",
      "Category:Symbolic anthropology"
    ]
  },
  "Aura analysis": {
    "title": "Aura (paranormal)",
    "url": "https://en.wikipedia.org/wiki/Aura_(paranormal)",
    "summary": "According to spiritual  beliefs, an aura or energy field is a colored emanation said to enclose a human body or any animal or object. In some esoteric positions, the aura is described as a subtle body. Psychics and holistic medicine practitioners often claim to have the ability to see the size, color and type of vibration of an aura.\nIn spiritual alternative medicine, the human aura is seen as part of a hidden anatomy that reflects the state of being and health of a client, often understood to even comprise centers of vital force called chakras. Such claims are not supported by scientific evidence and are thus considered pseudoscience. When tested under scientific controlled experiments, the ability to see auras has not been proven to exist.",
    "content": "According to spiritual  beliefs, an aura or energy field is a colored emanation said to enclose a human body or any animal or object. In some esoteric positions, the aura is described as a subtle body. Psychics and holistic medicine practitioners often claim to have the ability to see the size, color and type of vibration of an aura.\nIn spiritual alternative medicine, the human aura is seen as part of a hidden anatomy that reflects the state of being and health of a client, often understood to even comprise centers of vital force called chakras. Such claims are not supported by scientific evidence and are thus considered pseudoscience. When tested under scientific controlled experiments, the ability to see auras has not been proven to exist.\n\nEtymology\nIn Latin and Ancient Greek, aura means wind, breeze or breath. It was used in Middle English to mean \"gentle breeze\". By the end of the 19th century, the word was used in some spiritualist circles to describe a speculated subtle emanation around the body.\n\nHistory\nThe concept of auras was first popularized by Charles Webster Leadbeater, a former priest of the Church of England and a member of the mystic Theosophical Society. He had studied theosophy in India, and believed he had the capacity to use his clairvoyant powers to make scientific investigations. He claimed that he had discovered that most men came from Mars but the more advanced men came from the Moon, and that hydrogen atoms were made of six bodies contained in an egg-like form. In his book Man Visible and Invisible, published in 1903, Leadbeater illustrated the aura of man at various stages of his moral evolution, from the \"savage\" to the saint. In 1910, he introduced the modern conception of auras by incorporating the Tantric notion of chakras in his book The Inner Life. Leadbeater did not simply present the Tantric beliefs to the West: he reconstructed and reinterpreted them by mixing them with his own ideas. Some of Leadbeater's innovations are describing chakras as energy vortices, and associating each of them with a gland, an organ and other body parts.\nIn the following years, Leadbeater's ideas on the aura and chakras were adopted and reinterpreted by other theosophists such as Rudolf Steiner and Edgar Cayce, but his occult anatomy remained of minor interest within the esoteric counterculture until the 1980s, when it was picked up by the New Age movement.\nIn 1977, American esotericist Christopher Hills published the book Nuclear Evolution: The Rainbow Body, which presented a modified version of Leadbeater's occult anatomy. Whereas Leadbeater had drawn each chakras with intricately detailed shapes and multiple colors, Hills presented them as a sequence of centers, each one being associated with a color of the rainbow. Most of the subsequent New Age writers based their representations of the aura on Hill's interpretation of Leadbeater's ideas. Chakras became a part of mainstream esoteric speculations in the 1980s and 1990s. Many New Age techniques that aim to clear blockages of the chakras were developed during those years, such as crystal healing and aura-soma. By the late 1990s chakras were less connected with their theosophical  and Hinduist roots, and more infused with New Age ideas. A variety of New Age books proposed different links between each chakras and colors, personality traits, illnesses, Christian sacraments, etc. Various type of holistic healing within the New Age movement claim to use aura reading techniques, such as bioenergetic analysis, spiritual energy and energy medicine.\n\nAuric energy\nIn yoga participants attempt to focus on, or enhance their \"auric energy shield\". The concept of auric energy is spiritual and is concerned with metaphysics. Some people think that the aura carries a person's soul after death.\n\nAura photography\nThere have been numerous attempts to capture an energy field around the human body, going as far back as photographs by French physician Hippolyte Baraduc in the 1890s. Supernatural interpretations of these images have often been the result of a lack of understanding of the simple natural phenomena behind them, such as heat emanating from a human body producing aura-like images under infrared photography.\n\nIn 1939, Semyon Davidovich Kirlian discovered that by placing an object or body part directly on photographic paper, and then passing a high voltage across the object, he would obtain the image of a glowing contour surrounding the object. This process came to be known as Kirlian photography. Some parapsychologists, such as Thelma Moss of UCLA, have proposed that these images show levels of psychic powers and bioenergies. However, studies have found that the Kirlian effect is caused by the presence of moisture on the object being photographed. Electricity produces an area of gas ionization around the object if it is moist, which is the case for living things. This causes an alternation of the electric charge pattern on the film. After rigorous experi",
    "links": [
      "Affirmations (New Age)",
      "Age of Aquarius",
      "Alternative medicine",
      "American Psychical Institute",
      "American Society for Psychical Research",
      "An Experiment with Time",
      "Ancient Greek",
      "André Neher",
      "Anomalistics",
      "Anomalous experiences",
      "Apparitional experience",
      "Argument from ignorance",
      "Argumentum ad populum",
      "Association for the Scientific Study of Anomalous Phenomena",
      "Astral projection",
      "Astrology",
      "Aura (disambiguation)",
      "Aureola",
      "Bandwagon effect",
      "Begging the question",
      "Bibcode (identifier)",
      "Bilocation",
      "Bioenergetic analysis",
      "Biofeedback",
      "Breathwork (New Age)",
      "British College of Psychic Science",
      "Cambridge Ghost Society",
      "Chakra",
      "Charles Webster Leadbeater",
      "Christopher Hills",
      "Clairvoyance",
      "Close encounter",
      "Cognitive dissonance",
      "Cold reading",
      "Cold spot (paranormal)",
      "College of Psychic Studies",
      "Committee for Skeptical Inquiry",
      "Communal reinforcement",
      "Confirmation bias",
      "Contrived experiment",
      "Creative visualization (New Age)",
      "Cryptozoology",
      "Crystal gazing",
      "Crystal healing",
      "Deathbed phenomena",
      "Debunker",
      "Demonology",
      "Dermo-optical perception",
      "Deva (theosophy)",
      "Doi (identifier)"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1 French-language sources (fr)",
      "Category:Energy (esotericism)",
      "Category:Hindu philosophical concepts",
      "Category:New Age",
      "Category:Paranormal terminology",
      "Category:Parapsychology",
      "Category:Pseudoscience",
      "Category:Short description matches Wikidata",
      "Category:Theosophical philosophical concepts"
    ]
  },
  "Autoethnography": {
    "title": "Autoethnography",
    "url": "https://en.wikipedia.org/wiki/Autoethnography",
    "summary": "Autoethnography is a form of ethnographic research in which a researcher connects personal experiences to wider cultural, political, and social meanings and understandings. It is considered a form of qualitative and arts-based research.\nAutoethnography has been used across various disciplines, including anthropology, arts education, communication studies, education, educational administration, English literature, ethnic studies, gender studies, history, human resource development, marketing, music therapy, nursing, organizational behavior, paramedicine, performance studies, physiotherapy, psychology, social work, sociology, and theology and religious studies.",
    "content": "Autoethnography is a form of ethnographic research in which a researcher connects personal experiences to wider cultural, political, and social meanings and understandings. It is considered a form of qualitative and arts-based research.\nAutoethnography has been used across various disciplines, including anthropology, arts education, communication studies, education, educational administration, English literature, ethnic studies, gender studies, history, human resource development, marketing, music therapy, nursing, organizational behavior, paramedicine, performance studies, physiotherapy, psychology, social work, sociology, and theology and religious studies.\n\nDefinitions\nHistorically, researchers have had trouble reaching a consensus regarding the definition of autoethnography. Whereas some scholars situate autoethnography within the family of narrative methods, others place it within the ethnographic tradition. However, it generally refers to research that involves critical observation of an individual's lived experiences and connecting those experience to broader cultural, political, and social concepts.\nAutoethnography can refer to research in which a researcher reflexively studies a group they belong to or their subjective experience. In the 1970s, autoethnography was more narrowly defined as \"insider ethnography\", referring to studies of the (culture of) a group of which the researcher is a member.\nAccording to Adams et al., autoethnography\n\nuses a researcher's personal experience to describe and critique cultural beliefs, practices, and experiences;\nacknowledges and values a researcher's relationships with others\nuses deep and careful self-reflection—typically referred to as “reflexivity”—to name and interrogate the intersections between self and society, the particular and the general, the personal and the political\nshows people in the process of figuring out what to do, how to live, and the meaning of their struggles\nbalances intellectual and methodological rigor, emotion, and creativity\nstrives for social justice and to make life better.\nBochner and Ellis have also defined autoethnography as \"an autobiographical genre of writing and research that displays multiple layers of consciousness, connecting the personal to the cultural.\" They further indicate that autoethnography is typically written in first-person and can \"appear in a variety of forms,\" such as \"short stories, poetry, fiction, novels, photographic essays, personal essays, journals, fragmented and layered writing, and social science prose.\"\n\nHistory\nMid-1800s\nAnthropologists began conducting ethnographic research in the mid-1800s to study the cultures people they deemed \"exotic\" and/or \"primitive.\" Typically, these early ethnographers aimed to merely observe and write \"objective\" accounts of these groups to provide others a better understanding of various cultures. They also \"recognized and wrestled with questions of how to render textual accounts that would provide clear, accurate, rich descriptions of cultural practices of others\" and \"were concerned with offering valid, reliable, and objective interpretations in their writings.\"\n\nEarly- to mid-1900s\nIn the early to mid 1900s, it became clear that observation and fieldwork interfered with the cultural groups' natural and typical behaviors. Additionally, researchers realized the role they play in analyzing others' behaviors. As such, \"serious questions arose about the possibility and legitimacy of offering purely objective accounts of cultural practices, traditions, symbols, meanings, premises, rituals, rules, and other social engagements.\"\nTo help combat potential issues of validity, ethnographers began using what Gilbert Ryle refers to as thick description: a description of human social behavior in which the writer-researcher describes the behavior and provides \"commentary on, context for, and interpretation of these behaviors into the text.\" By doing so, the researcher aims to \"evoke a cultural scene vividly, in detail, and with care,\" so readers can understand and attempt to interpret the scene for themselves, much like in more traditional research methods.\nA few ethnographers, especially those related to the Chicago school, began incorporating aspects of autoethnography into their work, such as narrated life histories. While they created more lifelike representations of their subject than their predecessors, these researchers often \"romanticized the subject\" by creating narratives with \"the three stages of the classic morality tale: being in a state of grace, being seduced by evil and falling from grace, and finally achieving redemption through suffering.\" Such researchers include Robert Parks, Nels Anderson, Everett Hughes, and Fred Davis.\nDuring this time period, new theoretical constructs, such as feminism, began to emerge and with it, grew qualitative research. However, researchers were trying to \"fit the classical traditional model of internal and external validity to construc",
    "links": [
      "Academic administration",
      "Academic writing",
      "Action research",
      "Adult education",
      "Aleksandr Solzhenitsyn",
      "Allophilia",
      "Analysis",
      "Anthropology",
      "Antipositivism",
      "Argument",
      "Arlene Croce",
      "Art-based research",
      "Art Bochner",
      "Art methodology",
      "Arthur P. Bochner",
      "Autobiography",
      "Bibliometrics",
      "Bill T. Jones",
      "Carolyn Ellis",
      "Cartography",
      "Case study",
      "Chicago school (sociology)",
      "Citation",
      "Clan",
      "Clinical ethnography",
      "Communication studies",
      "Consociationalism",
      "Constructivism (philosophy of science)",
      "Content analysis",
      "Critical ethnography",
      "Critical rationalism",
      "Critical realism (philosophy of the social sciences)",
      "Critical theory",
      "Cross-race effect",
      "Cultural appropriation",
      "Cultural assimilation",
      "Cultural identity",
      "Cultural mapping",
      "Demographics of Greenland",
      "Demographics of Mexico",
      "Demonym",
      "Descriptive research",
      "Descriptive statistics",
      "Detribalization",
      "Diaspora",
      "Diaspora politics",
      "Discourse analysis",
      "Documentary film",
      "Doi (identifier)",
      "Dominant minority"
    ],
    "categories": [
      "Category:All articles with unsourced statements",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from December 2022",
      "Category:Articles with unsourced statements from May 2021",
      "Category:CS1: long volume value",
      "Category:CS1 maint: multiple names: authors list",
      "Category:Ethnography",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Boolean analysis": {
    "title": "Boolean analysis",
    "url": "https://en.wikipedia.org/wiki/Boolean_analysis",
    "summary": "Boolean analysis was introduced by Flament (1976). The goal of a Boolean analysis is to detect deterministic dependencies between the items of a questionnaire or similar data-structures in observed response patterns. These deterministic dependencies have the form of logical formulas connecting the items. Assume, for example, that a questionnaire contains items i, j, and k. Examples of such deterministic dependencies are then i → j, i ∧ j → k, and i ∨ j → k.\nSince the basic work of Flament (1976) a number of different methods for Boolean analysis have been developed. See, for example, Buggenhaut and Degreef (1987), Duquenne (1987), item tree analysis Leeuwe (1974), Schrepp (1999), or Theuns (1998). These methods share the goal to derive deterministic dependencies between the items of a questionnaire from data, but differ in the algorithms to reach this goal.\nBoolean analysis is an explorative method to detect deterministic dependencies between items. The detected dependencies must be co",
    "content": "Boolean analysis was introduced by Flament (1976). The goal of a Boolean analysis is to detect deterministic dependencies between the items of a questionnaire or similar data-structures in observed response patterns. These deterministic dependencies have the form of logical formulas connecting the items. Assume, for example, that a questionnaire contains items i, j, and k. Examples of such deterministic dependencies are then i → j, i ∧ j → k, and i ∨ j → k.\nSince the basic work of Flament (1976) a number of different methods for Boolean analysis have been developed. See, for example, Buggenhaut and Degreef (1987), Duquenne (1987), item tree analysis Leeuwe (1974), Schrepp (1999), or Theuns (1998). These methods share the goal to derive deterministic dependencies between the items of a questionnaire from data, but differ in the algorithms to reach this goal.\nBoolean analysis is an explorative method to detect deterministic dependencies between items. The detected dependencies must be confirmed in subsequent research. Methods of Boolean analysis do not assume that the detected dependencies describe the data completely. There may be other probabilistic dependencies as well. Thus, a Boolean analysis tries to detect interesting deterministic structures in the data, but has not the goal to uncover all structural aspects in the data set. Therefore, it makes sense to use other methods, like for example latent class analysis, together with a Boolean analysis.\n\nApplication areas\nThe investigation of deterministic dependencies has some tradition in educational psychology. The items represent in this area usually skills or cognitive abilities of subjects. Bart and Airasian (1974) use Boolean analysis to establish logical implications on a set of Piagetian tasks. Other examples in this tradition are the learning hierarchies of Gagné (1968) or the theory of structural learning of Scandura (1971).\nThere are several attempts to use boolean analysis, especially item tree analysis to construct knowledge spaces from data. Examples can be found in Held and Korossy (1998), or Schrepp (2002).\nMethods of Boolean analysis are used in a number of social science studies to get insight into the structure of dichotomous data. Bart and Krus (1973) use, for example, Boolean analysis to establish a hierarchical order on items that describe socially unaccepted behavior. Janssens (1999) used a method of Boolean analysis to investigate the integration process of minorities into the value system of the dominant culture. Romme (1995a) introduced Boolean comparative analysis to the management sciences, and applied it in a study of self-organizing processes in management teams (Romme 1995b).\n\nRelations to other areas\nBoolean analysis has some relations to other research areas. There is a close connection between Boolean analysis and knowledge spaces. The theory of knowledge spaces provides a theoretical framework for the formal description of human knowledge. A knowledge domain is in this approach represented by a set Q of problems. The knowledge of a subject in the domain is then described by the subset of problems from Q he or she is able to solve. This set is called the knowledge state of the subject. Because of dependencies between the items (for example, if solving item j implies solving item i) not all elements of the power set of Q will, in general, be possible knowledge states. The set of all possible knowledge states is called the knowledge structure.  Methods of Boolean analysis can be used to construct a knowledge structure from data (for example, Theuns, 1998 or Schrepp, 1999). The main difference between both research areas is that Boolean analysis concentrates on the extraction of structures from data while knowledge space theory focus on the structural properties of the relation between a knowledge structure and the logical formulas which describe it.\nClosely related to knowledge space theory is formal concept analysis (Ganter and Wille, 1996). Similar to knowledge space theory this approach concentrates on the formal description and visualization of existing dependencies. Formal concept analysis offers very effective  ways to construct such dependencies from data, with a focus on if-then expressions (\"implications\"). There is even a method,  called attribute exploration, for extracting all implications from hard-to-access data.\nAnother related field is data mining. Data mining deals with the extraction of knowledge from large databases. Several data mining algorithms extract dependencies of the form j → i (called association rules) from the database.\nThe main difference between Boolean analysis and the extraction of association rules in data mining is the interpretation of the extracted implications. The goal of a Boolean analysis is to extract implications from the data which are (with the exception of random errors in the response behavior) true for all rows in the data set. For data mining applications it is sufficient to det",
    "links": [
      "Association rules",
      "Boolean algebra (logic)",
      "Data mining",
      "Determinism",
      "Dichotomous",
      "Educational psychology",
      "Exploratory data analysis",
      "Formal concept analysis",
      "Fred S. Roberts",
      "Georges Romme",
      "ISBN (identifier)",
      "Implication (information science)",
      "Item tree analysis",
      "Knowledge space",
      "Latent class model",
      "Questionnaire",
      "Social science",
      "Theory of cognitive development"
    ],
    "categories": [
      "Category:Logic and statistics",
      "Category:Statistical analysis"
    ]
  },
  "Bowling analysis": {
    "title": "Bowling analysis",
    "url": "https://en.wikipedia.org/wiki/Bowling_analysis",
    "summary": "In cricket, a bowling analysis (sometimes shortened to just analysis, especially in the phrase innings analysis, and also referred to as bowling figures) usually refers to a notation summarising a bowler's performance in terms of overs bowled, how many of those overs are maidens (i.e. with no runs conceded), total runs conceded and number of wickets taken. Bowling analyses are generally given for each innings in cricket scoreboards printed in Wisden Cricketers' Almanack, newspapers and so on, but they are also sometimes quoted for other periods of time, such as a single spell of bowling. Typically, the analysis is given in the following format: Overs – Maidens – Runs conceded – Wickets. \nIn some cases, overs and maidens are omitted from bowling figures, and are recorded showing 'Wickets/Runs'; for example, 7/15 by Glenn McGrath against Namibia shows he took his 7 wickets for 15 runs.\nSometimes, in limited overs cricket, the 'maidens' figure is replaced by the number of dot balls bowled",
    "content": "In cricket, a bowling analysis (sometimes shortened to just analysis, especially in the phrase innings analysis, and also referred to as bowling figures) usually refers to a notation summarising a bowler's performance in terms of overs bowled, how many of those overs are maidens (i.e. with no runs conceded), total runs conceded and number of wickets taken. Bowling analyses are generally given for each innings in cricket scoreboards printed in Wisden Cricketers' Almanack, newspapers and so on, but they are also sometimes quoted for other periods of time, such as a single spell of bowling. Typically, the analysis is given in the following format: Overs – Maidens – Runs conceded – Wickets. \nIn some cases, overs and maidens are omitted from bowling figures, and are recorded showing 'Wickets/Runs'; for example, 7/15 by Glenn McGrath against Namibia shows he took his 7 wickets for 15 runs.\nSometimes, in limited overs cricket, the 'maidens' figure is replaced by the number of dot balls bowled.\nIn Test cricket, the best bowling analysis for a single innings is 10/53 by Jim Laker.  The best bowling analysis in an  ODI is 8/19 by Chaminda Vaas. The best bowling analysis in a Twenty20 International is 6/7 by Deepak Chahar. In first-class cricket,  the best bowling analysis for a single innings is 10/10 by Hedley Verity.\n\n\n== References ==",
    "links": [
      "Bowler (cricket)",
      "Chaminda Vaas",
      "Cricket",
      "Deepak Chahar",
      "ESPNcricinfo",
      "Encyclopædia Britannica",
      "First-class cricket",
      "Glenn McGrath",
      "Glossary of cricket terms",
      "Hedley Verity",
      "Innings",
      "Jim Laker",
      "Limited overs cricket",
      "Merriam-Webster",
      "Namibia national cricket team",
      "Old Trafford Cricket Ground",
      "One Day International",
      "Over (cricket)",
      "Run (cricket)",
      "Samit Patel",
      "Test cricket",
      "The Oval",
      "Twenty20 International",
      "Wicket (cricket)",
      "Wisden Cricketers' Almanack",
      "Wikipedia:Stub",
      "File:Patel scoreboard.JPG",
      "Template:Cricket-term-stub",
      "Template talk:Cricket-term-stub",
      "Category:Cricket terminology"
    ],
    "categories": [
      "Category:All stub articles",
      "Category:Articles with short description",
      "Category:Bowling (cricket)",
      "Category:Cricket records and statistics",
      "Category:Cricket terminology",
      "Category:Cricket terminology stubs",
      "Category:Short description matches Wikidata",
      "Category:Use dmy dates from April 2017"
    ]
  },
  "Business analysis": {
    "title": "Business analysis",
    "url": "https://en.wikipedia.org/wiki/Business_analysis",
    "summary": "Business analysis is a professional discipline focused on identifying business needs and determining solutions to business problems. Solutions may include a software-systems development component, process improvements, or organizational changes, and may involve extensive analysis, strategic planning and policy development. A person dedicated to carrying out these tasks within an organization is called a business analyst or BA.\nBusiness analysts are not limited to projects involving software system development. They may also collaborate across the organization, addressing business challenges alongside key stakeholders. Whilst most of the work that business analysts do today relates to software development / solutions, this is due to the ongoing massive changes businesses all over the world are experiencing in their attempts to digitise.\nAlthough there are different role definitions, depending upon the organization, there does seem to be an area of common ground where most\nbusiness analy",
    "content": "Business analysis is a professional discipline focused on identifying business needs and determining solutions to business problems. Solutions may include a software-systems development component, process improvements, or organizational changes, and may involve extensive analysis, strategic planning and policy development. A person dedicated to carrying out these tasks within an organization is called a business analyst or BA.\nBusiness analysts are not limited to projects involving software system development. They may also collaborate across the organization, addressing business challenges alongside key stakeholders. Whilst most of the work that business analysts do today relates to software development / solutions, this is due to the ongoing massive changes businesses all over the world are experiencing in their attempts to digitise.\nAlthough there are different role definitions, depending upon the organization, there does seem to be an area of common ground where most\nbusiness analysts work. The responsibilities appear to be:\n\nTo investigate business systems, taking a holistic view of the situation. This may include examining elements of the organisation structures and staff development issues as well as current processes and IT systems.\nTo evaluate actions to improve the operation of a business system. Again, this may require an examination of organisational structure and staff development needs, to ensure that they are in line with any proposed process redesign and IT system development.\nTo document the business requirements for the IT system support using appropriate documentation standards.\nIn line with this, the core business analyst role could be defined as an internal consultancy role that has the responsibility for investigating business situations, identifying and evaluating options for improving business systems, defining requirements and ensuring the effective use of information systems in meeting the needs of the business.\n\nSub-disciplines\nBusiness analysis as a discipline includes requirements analysis, sometimes also called requirements engineering. It focuses on ensuring the changes made to an organisation are aligned with its strategic goals. These changes include changes to strategies, structures, policies, business rules, processes, and information systems.\nExamples of business analysis include:\n\nEnterprise analysis or company analysis\nFocuses on understanding the needs of the business as a whole, its strategic direction, and identifying initiatives that will allow a business to meet those strategic goals. It also includes:\n\nCreating and maintaining the business architecture\nConducting feasibility studies\nIdentifying new business opportunities\nScoping and defining new business opportunities\nPreparing the business case\nConducting the initial risk assessment\n\nRequirements planning and management\nInvolves planning on how the business analyst will go about gathering the requirement, in what order, using which techniques, which stakeholders, and the schedule that s/he will follow. Requirement management on the other hand involves the process business analyst will follow to maintain a finalized requirement up to date, including any requested changes in the requirements.\n\nRequirements elicitation\nDescribes techniques for collecting requirements from stakeholders in a project. Techniques for requirements elicitation include:\n\nBrainstorming\nDocument analysis\nFocus group\nInterface analysis\nInterviews/questionnaire\nWorkshops\nReverse engineering\nSurveys\nUser task analysis\nProcess mapping\nObservation/job shadowing\nDesign thinking\nPrototyping\n\nRequirements analysis and documentation\nDescribes how to develop and specify requirements in enough detail to allow them to be successfully implemented by a project team.\n\nAnalysis\nThe major forms of analysis are:\n\nArchitecture analysis\nBusiness process analysis\nObject-oriented analysis\nStructured analysis\nData warehouse analysis, storage and databases analysis\n\nDocumentation\nRequirements documentation can take several forms:\n\nTextual – for example, stories that summarize specific information\nMatrix – for example, a table of requirements with priorities\nDiagrams – for example, how data flows from one structure to the other\nWireframe – for example, how elements are required in a website,\nModels – for example, 3-D models that describes a character in a computer game\n\nRequirements communication\nDescribes techniques for ensuring that stakeholders have a shared understanding of the requirements and how they will be implemented.\n\nSolution assessment and validation\nDescribes how the business analyst can perform correctness of a proposed solution, how to support the implementation of a solution, and how to assess possible shortcomings in the implementation.\n\nTechniques\nThere are a number of generic business techniques that a business analyst will use when facilitating business change.\nSome of these techniques include:\n\nPESTLE\nThis is used to perform an external environ",
    "links": [
      "Accounting",
      "Advisory board",
      "Annual general meeting",
      "Architecture analysis and design language",
      "Asset management",
      "Audit",
      "Audit committee",
      "BADIR",
      "Board of directors",
      "Brainstorming",
      "Brand management",
      "Business administration",
      "Business analyst",
      "Business analytics",
      "Business architecture",
      "Business case",
      "Business development",
      "Business ethics",
      "Business intelligence",
      "Business judgment rule",
      "Business model",
      "Business needs",
      "Business opportunity",
      "Business plan",
      "Business process",
      "Business process management",
      "Business process mapping",
      "Business process modeling",
      "Business process reengineering",
      "Business statistics",
      "Capability management in business",
      "Capacity management",
      "Capital budgeting",
      "Capital management",
      "Cash conversion cycle",
      "Chairman",
      "Change management",
      "Change management (people)",
      "Chief brand officer",
      "Chief business officer",
      "Chief executive officer",
      "Chief financial officer",
      "Chief human resources officer",
      "Chief information officer",
      "Chief marketing officer",
      "Chief operating officer",
      "Chief product officer",
      "Chief technology officer",
      "Cognitive work analysis",
      "Commercial bank"
    ],
    "categories": [
      "Category:All articles needing additional references",
      "Category:All articles with vague or ambiguous time",
      "Category:Articles needing additional references from June 2023",
      "Category:Articles with short description",
      "Category:Articles with specifically marked weasel-worded phrases from July 2022",
      "Category:Business analysis",
      "Category:CS1: unfit URL",
      "Category:Pages displaying short descriptions of redirect targets via Module:Annotated link",
      "Category:Project management",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Cartography": {
    "title": "Cartography",
    "url": "https://en.wikipedia.org/wiki/Cartography",
    "summary": "Cartography () is the study and practice of making and using maps. Combining science, aesthetics and technique, cartography builds on the premise that reality (or an imagined reality) can be modeled in ways that communicate spatial information effectively.\nThe fundamental objectives of traditional cartography are to:\n\nSet the map's agenda and select traits of the object to be mapped. This is the concern of map editing. Traits may be physical, such as roads or land masses, or may be abstract, such as toponyms or political boundaries.\nRepresent the terrain of the mapped object on flat media. This is the concern of map projections.\nEliminate the mapped object's characteristics that are irrelevant to the map's purpose. This is the concern of generalization.\nReduce the complexity of the characteristics that will be mapped. This is also the concern of generalization.\nOrchestrate the elements of the map to best convey its message to its audience. This is the concern of map design.\nModern cart",
    "content": "Cartography () is the study and practice of making and using maps. Combining science, aesthetics and technique, cartography builds on the premise that reality (or an imagined reality) can be modeled in ways that communicate spatial information effectively.\nThe fundamental objectives of traditional cartography are to:\n\nSet the map's agenda and select traits of the object to be mapped. This is the concern of map editing. Traits may be physical, such as roads or land masses, or may be abstract, such as toponyms or political boundaries.\nRepresent the terrain of the mapped object on flat media. This is the concern of map projections.\nEliminate the mapped object's characteristics that are irrelevant to the map's purpose. This is the concern of generalization.\nReduce the complexity of the characteristics that will be mapped. This is also the concern of generalization.\nOrchestrate the elements of the map to best convey its message to its audience. This is the concern of map design.\nModern cartography constitutes many theoretical and practical foundations of geographic information systems (GIS) and geographic information science (GISc).\n\nHistory\nAncient times\nWhat is the earliest known map is a matter of some debate, both because the term \"map\" is not well-defined and because some artifacts that might be maps might actually be something else. A wall painting that might depict the ancient Anatolian city of Çatalhöyük (previously known as Catal Huyuk or Çatal Hüyük) has been dated to the late 7th millennium BCE. Among the prehistoric alpine rock carvings of Mount Bego (France) and Valcamonica (Italy), dated to the 4th millennium BCE, geometric patterns consisting of dotted rectangles and lines are widely interpreted in archaeological literature as depicting cultivated plots. Other known maps of the ancient world include the Minoan \"House of the Admiral\" wall painting from c. 1600 BCE, showing a seaside community in an oblique perspective, and an engraved map of the holy Babylonian city of Nippur, from the Kassite period (14th – 12th centuries BCE). The oldest surviving world maps are from 9th century BCE Babylonia. One shows Babylon on the Euphrates, surrounded by Assyria, Urartu and several cities, all, in turn, surrounded by a \"bitter river\" (Oceanus). Another depicts Babylon as being north of the center of the world.\n\nThe ancient Greeks and Romans created maps from the time of Anaximander in the 6th century BCE. In the 2nd century CE, Ptolemy wrote his treatise on cartography, Geographia. This contained Ptolemy's world map – the world then known to Western society (Ecumene). As early as the 8th century, Arab scholars were translating the works of the Greek geographers into Arabic. Roads were essential in the Roman world, motivating the creation of maps, called itinerarium, that portrayed the world as experienced via the roads. The Tabula Peutingeriana is the only surviving example.\n\nIn ancient China, geographical literature dates to the 5th century BCE. The oldest extant Chinese maps come from the State of Qin, dated back to the 4th century BCE, during the Warring States period. In the book Xin Yi Xiang Fa Yao, published in 1092 by the Chinese scientist Su Song, a star map on the equidistant cylindrical projection. Although this method of charting seems to have existed in China even before this publication and scientist, the greatest significance of the star maps by Su Song is that they represent the oldest existent star maps in printed form.\nEarly forms of cartography of India included depictions of the pole star and surrounding constellations. These charts may have been used for navigation.\n\nMiddle Ages and Renaissance\nMappae mundi ('maps of the world') are the medieval European maps of the world. About 1,100 of these are known to have survived: of these, some 900 are found illustrating manuscripts, and the remainder exist as stand-alone documents.\n\nThe Arab geographer Muhammad al-Idrisi produced his medieval atlas Tabula Rogeriana (Book of Roger) in 1154. By combining the knowledge of Africa, the Indian Ocean, Europe, and the Far East (which he learned through contemporary accounts from Arab merchants and explorers) with the information he inherited from the classical geographers, he was able to write detailed descriptions of a multitude of countries. Along with the substantial text he had written, he created a world map influenced mostly by the Ptolemaic conception of the world, but with significant influence from multiple Arab geographers. It remained the most accurate world map for the next three centuries. The map was divided into seven climatic zones, with detailed descriptions of each zone. As part of this work, a smaller, circular map depicting the south on top and Arabia in the center was made. Al-Idrisi also made an estimate of the circumference of the world, accurate to within 10%.\n\nIn the Age of Discovery, from the 15th century to the 17th century, European cartographers both copied earlier maps (some",
    "links": [
      "ACM Transactions on Spatial Algorithms and Systems",
      "Aaron Koblin",
      "Abraham Ortelius",
      "Ade Olufeko",
      "Adolphe Quetelet",
      "Aerial photography",
      "Aesthetics",
      "Africa",
      "Age of Discovery",
      "Age of Earth",
      "Age of Enlightenment",
      "Agricultural geography",
      "Alan MacEachren",
      "Alfred Inselberg",
      "Anatolian Studies",
      "Anaximander",
      "Ancient China",
      "Ancient Greek language",
      "Ancient Greeks",
      "André-Michel Guerry",
      "Animal geographies",
      "Animated mapping",
      "Antarctica",
      "Applied aesthetics",
      "Arctic Ocean",
      "Arthur H. Robinson",
      "Arthur Lyon Bowley",
      "Asia",
      "Assyria",
      "Astronomy",
      "Atlantic Ocean",
      "Atlas",
      "Atmosphere of Earth",
      "Atmospheric science",
      "August Kekulé",
      "Australia (continent)",
      "Axial precession",
      "Babylon",
      "Babylonia",
      "Babylonian world map",
      "Bang Wong",
      "Basic Books",
      "Battista Agnese",
      "Bedolina Map",
      "Behavioral geography",
      "Ben Fry",
      "Ben Shneiderman",
      "Berlin Conference",
      "Bibcode (identifier)",
      "Biogeochemical cycle"
    ],
    "categories": [
      "Category:All articles needing additional references",
      "Category:All articles with unsourced statements",
      "Category:Articles containing Ancient Greek (to 1453)-language text",
      "Category:Articles containing Latin-language text",
      "Category:Articles needing additional references from June 2022",
      "Category:Articles needing additional references from March 2024",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from July 2011",
      "Category:CS1: long volume value",
      "Category:Cartography"
    ]
  },
  "Cluster analysis": {
    "title": "Cluster analysis",
    "url": "https://en.wikipedia.org/wiki/Cluster_analysis",
    "summary": "Cluster analysis, or clustering, is a data analysis technique aimed at partitioning a set of objects into groups such that objects within the same group (called a cluster) exhibit greater similarity to one another (in some specific sense defined by the analyst) than to those in other groups (clusters). It is a main task of exploratory data analysis, and a common technique for statistical data analysis, used in many fields, including pattern recognition, image analysis, information retrieval, bioinformatics, data compression, computer graphics and machine learning.\nCluster analysis refers to a family of algorithms and tasks rather than one specific algorithm. It can be achieved by various algorithms that differ significantly in their understanding of what constitutes a cluster and how to efficiently find them. Popular notions of clusters include groups with small distances between cluster members, dense areas of the data space, intervals or particular statistical distributions. Clusteri",
    "content": "Cluster analysis, or clustering, is a data analysis technique aimed at partitioning a set of objects into groups such that objects within the same group (called a cluster) exhibit greater similarity to one another (in some specific sense defined by the analyst) than to those in other groups (clusters). It is a main task of exploratory data analysis, and a common technique for statistical data analysis, used in many fields, including pattern recognition, image analysis, information retrieval, bioinformatics, data compression, computer graphics and machine learning.\nCluster analysis refers to a family of algorithms and tasks rather than one specific algorithm. It can be achieved by various algorithms that differ significantly in their understanding of what constitutes a cluster and how to efficiently find them. Popular notions of clusters include groups with small distances between cluster members, dense areas of the data space, intervals or particular statistical distributions. Clustering can therefore be formulated as a multi-objective optimization problem. The appropriate clustering algorithm and parameter settings (including parameters such as the distance function to use, a density threshold or the number of expected clusters) depend on the individual data set and intended use of the results. Cluster analysis as such is not an automatic task, but an iterative process of knowledge discovery or interactive multi-objective optimization that involves trial and failure. It is often necessary to modify data preprocessing and model parameters until the result achieves the desired properties.\nBesides the term clustering, there are a number of terms with similar meanings, including automatic classification, numerical taxonomy, botryology (from Greek: βότρυς 'grape'), typological analysis, and community detection. The subtle differences are often in the use of the results: while in data mining, the resulting groups are the matter of interest, in automatic classification the resulting discriminative power is of interest.\nCluster analysis originated in anthropology by Driver and Kroeber in 1932 and introduced to psychology by Joseph Zubin in 1938 and Robert Tryon in 1939 and famously used by Cattell beginning in 1943 for trait theory classification in personality psychology.\n\nDefinition\nThe notion of a \"cluster\" cannot be precisely defined, which is one of the reasons why there are so many clustering algorithms. There is a common denominator: a group of data objects. However, different researchers employ different cluster models, and for each of these cluster models again different algorithms can be given. The notion of a cluster, as found by different algorithms, varies significantly in its properties. Understanding these \"cluster models\" is key to understanding the differences between the various algorithms. Typical cluster models include:\n\nConnectivity models: for example, hierarchical clustering builds models based on distance connectivity.\nCentroid models: for example, the k-means algorithm represents each cluster by a single mean vector.\nDistribution models: clusters are modeled using statistical distributions, such as multivariate normal distributions used by the expectation-maximization algorithm.\nDensity models: for example, DBSCAN and OPTICS defines clusters as connected dense regions in the data space.\nSubspace models: in biclustering (also known as co-clustering or two-mode-clustering), clusters are modeled with both cluster members and relevant attributes.\nGroup models: some algorithms do not provide a refined model for their results and just provide the grouping information.\nGraph-based models: a clique, that is, a subset of nodes in a graph such that every two nodes in the subset are connected by an edge can be considered as a prototypical form of cluster. Relaxations of the complete connectivity requirement (a fraction of the edges can be missing) are known as quasi-cliques, as in the HCS clustering algorithm.\nSigned graph models: Every path in a signed graph has a sign from the product of the signs on the edges. Under the assumptions of balance theory, edges may change sign and result in a bifurcated graph. The weaker \"clusterability axiom\" (no cycle has exactly one negative edge) yields results with more than two clusters, or subgraphs with only positive edges.\nNeural models: the most well-known unsupervised neural network is the self-organizing map and these models can usually be characterized as similar to one or more of the above models, and including subspace models when neural networks implement a form of Principal Component Analysis or Independent Component Analysis.\nA \"clustering\" is essentially a set of such clusters, usually containing all objects in the data set. Additionally, it may specify the relationship of the clusters to each other, for example, a hierarchy of clusters embedded in each other. Clusterings can be roughly distinguished as:\n\nHard clustering: each object belongs to a clu",
    "links": [
      "15.ai",
      "AAAI Conference on Artificial Intelligence",
      "AAAI Press",
      "ACM Press",
      "Accelerated failure time model",
      "Action selection",
      "Activation function",
      "Active learning (machine learning)",
      "Actuarial science",
      "Adaptive clinical trial",
      "Adjusted Rand index",
      "Adjusted mutual information",
      "Adobe Firefly",
      "Adversarial machine learning",
      "Affinity propagation",
      "Aidan Gomez",
      "Akaike information criterion",
      "Alan Turing",
      "AlexNet",
      "Alex Graves (computer scientist)",
      "Alex Krizhevsky",
      "Algorithm",
      "Allen Newell",
      "AlphaFold",
      "AlphaGo",
      "AlphaZero",
      "Analysis of covariance",
      "Analysis of variance",
      "Anderson–Darling test",
      "Andrej Karpathy",
      "Andrew Ng",
      "Animal",
      "Anomaly detection",
      "Apprenticeship learning",
      "ArXiv (identifier)",
      "Arithmetic mean",
      "Arithmetic–geometric mean",
      "Arthur Zimek",
      "Artificial general intelligence",
      "Artificial human companion",
      "Artificial intelligence",
      "Artificial neural network",
      "Ashish Vaswani",
      "Association for Computing Machinery",
      "Association rule learning",
      "Asymptotic theory (statistics)",
      "Attention (machine learning)",
      "Aurora (text-to-image model)",
      "AutoGPT",
      "Autocorrelation"
    ],
    "categories": [
      "Category:All articles needing additional references",
      "Category:All articles with unsourced statements",
      "Category:All pages needing factual verification",
      "Category:Articles containing Greek-language text",
      "Category:Articles needing additional references from April 2025",
      "Category:Articles needing additional references from November 2016",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from July 2018",
      "Category:Articles with unsourced statements from May 2018",
      "Category:Articles with unsourced statements from May 2023"
    ]
  },
  "Code (cryptography)": {
    "title": "Code (cryptography)",
    "url": "https://en.wikipedia.org/wiki/Code_(cryptography)",
    "summary": "In cryptology, a code is a method used to encrypt a message that operates at the level of meaning; that is, words or phrases are converted into something else. A code might transform \"change\" into \"CVGDK\" or \"cocktail lounge\". The U.S. National Security Agency defined a code as \"A substitution cryptosystem in which the plaintext elements are primarily words, phrases, or sentences, and the code equivalents (called \"code groups\") typically consist of letters or digits (or both) in otherwise meaningless combinations of identical length.\" A codebook is needed to encrypt, and decrypt the phrases or words.\nBy contrast, ciphers encrypt messages at the level of individual letters, or small groups of letters, or even, in modern ciphers, individual bits. Messages can be transformed first by a code, and then by a cipher. Such multiple encryption, or \"superencryption\" aims to make cryptanalysis more difficult.\nAnother comparison between codes and ciphers is that a code typically represents a lette",
    "content": "In cryptology, a code is a method used to encrypt a message that operates at the level of meaning; that is, words or phrases are converted into something else. A code might transform \"change\" into \"CVGDK\" or \"cocktail lounge\". The U.S. National Security Agency defined a code as \"A substitution cryptosystem in which the plaintext elements are primarily words, phrases, or sentences, and the code equivalents (called \"code groups\") typically consist of letters or digits (or both) in otherwise meaningless combinations of identical length.\" A codebook is needed to encrypt, and decrypt the phrases or words.\nBy contrast, ciphers encrypt messages at the level of individual letters, or small groups of letters, or even, in modern ciphers, individual bits. Messages can be transformed first by a code, and then by a cipher. Such multiple encryption, or \"superencryption\" aims to make cryptanalysis more difficult.\nAnother comparison between codes and ciphers is that a code typically represents a letter or groups of letters directly without the use of mathematics. As such the numbers are configured to represent  these three values: 1001 = A, 1002 = B, 1003 = C, ... . The resulting message, then would be 1001 1002 1003 to communicate ABC. Ciphers, however, utilize a mathematical formula to represent letters or groups of letters.  For example, A = 1, B = 2, C = 3, ... . Thus the message ABC results by multiplying each letter's value by 13. The message ABC, then would be 13 26 39.\nCodes have a variety of drawbacks, including susceptibility to cryptanalysis and the difficulty of managing the cumbersome codebooks, so ciphers are now the dominant technique in modern cryptography.\nIn contrast, because codes are representational, they are not susceptible to mathematical analysis of the individual codebook elements. In the example, the message 13 26 39 can be cracked by dividing each number by 13 and then ranking them alphabetically. However, the focus of codebook cryptanalysis is the comparative frequency of the individual code elements matching the same frequency of letters within the plaintext messages using frequency analysis. In the above example, the code group, 1001, 1002, 1003, might occur more than once and that frequency might match the number of times that ABC occurs in plain text messages.\n(In the past, or in non-technical contexts, code and cipher are often used to refer to any form of encryption).\n\nOne- and two-part codes\nCodes are defined by \"codebooks\" (physical or notional), which are dictionaries of codegroups listed with their corresponding plaintext. Codes originally had the codegroups assigned in 'plaintext order' for convenience of the code designed, or the encoder. For example, in a code using numeric code groups, a plaintext word starting with \"a\" would have a low-value group, while one starting with \"z\" would have a high-value group. The same codebook could be used to \"encode\" a plaintext message into a coded message or \"codetext\", and \"decode\" a codetext back into plaintext message.\nIn order to make life more difficult for codebreakers, codemakers  designed codes with no predictable relationship between the codegroups and the ordering of the matching plaintext. In practice, this meant that two codebooks were now required, one to  find codegroups for encoding, the other to look up codegroups to find plaintext for decoding. Such \"two-part\" codes required more effort to develop, and twice as much effort to distribute (and discard safely when replaced), but they were harder to break. The Zimmermann Telegram in January 1917 used the German diplomatic \"0075\" two-part code system which contained upwards of 10,000 phrases and individual words.\n\nOne-time code\nA one-time code is a prearranged word, phrase or symbol that is intended to be used only once to convey a simple message, often the signal to execute or abort some plan or confirm that it has succeeded or failed.  One-time codes are often designed to be included in what would appear to be an innocent conversation. Done properly they are almost impossible to detect, though a trained analyst monitoring the communications of someone who has already aroused suspicion might be able to recognize a comment like \"Aunt Bertha has gone into labor\" as having an ominous meaning. Famous example of one time codes include:\n\nIn the Bible, Jonathan prearranges a code with David, who is going into hiding from Jonathan's father, King Saul. If, during archery practice, Jonathan tells the servant retrieving arrows \"the arrows are on this side of you,\" it's safe for David to return to court, if the command is \"the arrows are beyond you,\" David must flee.\n\"One if by land; two if by sea\" in \"Paul Revere's Ride\" made famous in the poem by Henry Wadsworth Longfellow\n\"Climb Mount Niitaka\" - the signal to Japanese planes to begin the attack on Pearl Harbor\nDuring World War II the British Broadcasting Corporation's overseas service frequently included \"personal messages\" as part of its reg",
    "links": [
      "Atomic bomb",
      "Attack on Pearl Harbor",
      "Bit",
      "British Broadcasting Corporation",
      "British Naval Intelligence",
      "Cipher",
      "Ciphers",
      "Cliff Pickover",
      "Code",
      "Code (disambiguation)",
      "Code talkers",
      "Codebook",
      "Communication",
      "Crib (cryptanalysis)",
      "Cryptanalysis",
      "Cryptology",
      "D-day",
      "David Kahn (writer)",
      "Encryption",
      "French Resistance",
      "Frequency analysis",
      "Friday (novel)",
      "Gardening (cryptography)",
      "Harry Truman",
      "Henry Wadsworth Longfellow",
      "ISBN (identifier)",
      "JN-25",
      "Jonathan (1 Samuel)",
      "Joseph Stalin",
      "Key (cryptography)",
      "King David",
      "Leslie Groves",
      "Message",
      "Monoalphabetic substitution cipher",
      "Multiple encryption",
      "National Security Agency",
      "One-time pad",
      "Paul Revere's Ride (poem)",
      "Potsdam Conference",
      "Radio Londres",
      "Robert A. Heinlein",
      "September 11 attacks",
      "Spanish Civil War",
      "Special Operations Executive",
      "Traffic analysis",
      "Trench code",
      "Trinity test",
      "Wayback Machine",
      "World War II",
      "Zimmermann Telegram"
    ],
    "categories": [
      "Category:All articles needing additional references",
      "Category:All articles that may contain original research",
      "Category:Articles needing additional references from January 2016",
      "Category:Articles that may contain original research from August 2020",
      "Category:Articles with multiple maintenance issues",
      "Category:Articles with short description",
      "Category:Commons category link is locally defined",
      "Category:Cryptography",
      "Category:Short description is different from Wikidata",
      "Category:Webarchive template wayback links"
    ]
  },
  "Competitive analysis (online algorithm)": {
    "title": "Competitive analysis (online algorithm)",
    "url": "https://en.wikipedia.org/wiki/Competitive_analysis_(online_algorithm)",
    "summary": "Competitive analysis is a method invented for analyzing online algorithms, in which the performance of an online algorithm (which must satisfy an unpredictable sequence of requests, completing each request without being able to see the future) is compared to the performance of an optimal offline algorithm that can view the sequence of requests in advance.  An algorithm is competitive if its competitive ratio—the ratio between its performance and the offline algorithm's performance—is bounded.  Unlike traditional worst-case analysis, where the performance of an algorithm is measured only for \"hard\" inputs, competitive analysis requires that an algorithm perform well both on hard and easy inputs, where \"hard\" and \"easy\" are defined by the performance of the optimal offline algorithm.\nFor many algorithms, performance is dependent not only on the size of the inputs, but also on their values.  For example, sorting an array of elements varies in difficulty depending on the initial order.  Su",
    "content": "Competitive analysis is a method invented for analyzing online algorithms, in which the performance of an online algorithm (which must satisfy an unpredictable sequence of requests, completing each request without being able to see the future) is compared to the performance of an optimal offline algorithm that can view the sequence of requests in advance.  An algorithm is competitive if its competitive ratio—the ratio between its performance and the offline algorithm's performance—is bounded.  Unlike traditional worst-case analysis, where the performance of an algorithm is measured only for \"hard\" inputs, competitive analysis requires that an algorithm perform well both on hard and easy inputs, where \"hard\" and \"easy\" are defined by the performance of the optimal offline algorithm.\nFor many algorithms, performance is dependent not only on the size of the inputs, but also on their values.  For example, sorting an array of elements varies in difficulty depending on the initial order.  Such data-dependent algorithms are analysed for average-case and worst-case data.  Competitive analysis is a way of doing worst case analysis for on-line and randomized algorithms, which are typically data dependent.\nIn competitive analysis, one imagines an \"adversary\" which deliberately chooses difficult data, to maximize the ratio of the cost of the algorithm being studied and some optimal algorithm.  When considering a randomized algorithm, one must further distinguish between an oblivious adversary, which has no knowledge of the random choices made by the algorithm pitted against it, and an adaptive adversary which has full knowledge of the algorithm's internal state at any point during its execution.  (For a deterministic algorithm, there is no difference; either adversary can simply compute what state that algorithm must have at any time in the future, and choose difficult data accordingly.)\nFor example, the quicksort algorithm chooses one element, called the \"pivot\", that is, on average, not too far from the center value of the data being sorted. Quicksort then separates the data into two piles, one of which contains all elements with value less than the value of the pivot, and the other containing the rest of the elements.  If quicksort chooses the pivot in some deterministic fashion (for instance, always choosing the first element in the list), then it is easy for an adversary to arrange the data beforehand so that quicksort will perform in worst-case time.  If, however, quicksort chooses some random element to be the pivot, then an adversary without knowledge of what random numbers are coming up cannot arrange the data to guarantee worst-case execution time for quicksort.\nThe classic on-line problem first analysed with competitive analysis (Sleator & Tarjan 1985) is the list update problem: Given a list of items and a sequence of requests for the various items, minimize the cost of accessing the list where the elements closer to the front of the list cost less to access.  (Typically, the cost of accessing an item is equal to its position in the list.)  After an access, the list may be rearranged.  Most rearrangements have a cost.  The Move-To-Front algorithm simply moves the requested item to the front after the access, at no cost.  The Transpose algorithm swaps the accessed item with the item immediately before it, also at no cost.  Classical methods of analysis showed that Transpose is optimal in certain contexts.  In practice, Move-To-Front performed much better.  Competitive analysis was used to show that an adversary can make Transpose perform arbitrarily badly compared to an optimal algorithm, whereas Move-To-Front can never be made to incur more than twice the cost of an optimal algorithm.\nIn the case of online requests from a server, competitive algorithms are used to overcome uncertainties about the future. That is, the algorithm does not \"know\" the future, while the imaginary adversary (the \"competitor\") \"knows\". Similarly, competitive algorithms were developed for distributed systems, where the algorithm has to react to a request arriving at one location, without \"knowing\" what has just happened in a remote location. This setting was presented in (Awerbuch, Kutten & Peleg 1992).\n\nSee also\nAdversary (online algorithm)\nAmortized analysis\nK-server problem\nList update problem\nOnline algorithm\n\nReferences\nSleator, D.; Tarjan, R. (1985), \"Amortized efficiency of list update and paging rules\", Communications of the ACM, 28 (2): 202–208, doi:10.1145/2786.2793.\nAspnes, James (1998), \"Competitive analysis of distributed algorithms\", in Fiat, A.; Woeginger, G. J. (eds.), Online Algorithms: The State of the Art, Lecture Notes in Computer Science, vol. 1442, pp. 118–146, doi:10.1007/BFb0029567, ISBN 978-3-540-64917-5.\nBorodin, A.; El-Yaniv, R. (1998), Online Computation and Competitive Analysis, Cambridge University Press, ISBN 0-521-56392-5.\nAwerbuch, B.; Kutten, S.; Peleg, D. (1992), \"Competitive Distributed Job Schedu",
    "links": [
      "Adversary (online algorithm)",
      "Allan Borodin",
      "Amortized analysis",
      "Amos Fiat",
      "Best, worst and average case",
      "Daniel Sleator",
      "Doi (identifier)",
      "Gerhard J. Woeginger",
      "ISBN (identifier)",
      "K-server problem",
      "List update problem",
      "Online algorithm",
      "Quicksort",
      "Randomized algorithm",
      "Robert Tarjan",
      "Shay Kutten"
    ],
    "categories": [
      "Category:Analysis of algorithms",
      "Category:Articles with short description",
      "Category:Online algorithms",
      "Category:Short description matches Wikidata"
    ]
  },
  "Competitor analysis": {
    "title": "Competitor analysis",
    "url": "https://en.wikipedia.org/wiki/Competitor_analysis",
    "summary": "Competitive analysis in marketing and strategic management is an assessment of the strengths and weaknesses of current and potential competitors. This analysis provides both an offensive and defensive strategic context to identify opportunities and threats. Profiling combines all of the relevant sources of competitor analysis into one framework in the support of efficient and effective strategy formulation, implementation, monitoring and adjustment. \nCompetitive analysis is an essential component of corporate strategy. It is argued that most firms do not conduct this type of analysis systematically enough. Instead, many enterprises operate on what is called \"informal impressions, conjectures, and intuition gained through the tidbits of information about competitors every manager continually receives.\" As a result, traditional environmental scanning places many firms at risk of dangerous competitive blindspots due to a lack of robust competitor analysis. It is important to conduct the c",
    "content": "Competitive analysis in marketing and strategic management is an assessment of the strengths and weaknesses of current and potential competitors. This analysis provides both an offensive and defensive strategic context to identify opportunities and threats. Profiling combines all of the relevant sources of competitor analysis into one framework in the support of efficient and effective strategy formulation, implementation, monitoring and adjustment. \nCompetitive analysis is an essential component of corporate strategy. It is argued that most firms do not conduct this type of analysis systematically enough. Instead, many enterprises operate on what is called \"informal impressions, conjectures, and intuition gained through the tidbits of information about competitors every manager continually receives.\" As a result, traditional environmental scanning places many firms at risk of dangerous competitive blindspots due to a lack of robust competitor analysis. It is important to conduct the competitor analysis at various business stages to provide the best possible product or service for customers.\n\nCompetitive analysis\nOne common and useful technique is constructing a competitor array. The steps may include:\n\nDefine the industry – scope and nature of the industry.\nDetermine who the competitors are.\nDetermine who the customers are and what benefits they expect.\nDetermine the key strengths – for example price, service, convenience, inventory, etc.\nRank the key success factors by giving each one a weighting – The sum of all the weightings must add up to one.\nRate each competitor on each of the key success factors.\nMultiply each cell in the matrix by the factor weighting.\nTwo additional columns can be added. In one column, a company can be rated on each of the key success factors (try to be objective and honest). In another column, benchmarks can be listed. They are the ideal standards of comparisons on each of the factors. They reflect the workings of a company using all the industry's best practices.\n\nCompetitive profiling\nThe strategic rationale of competitor profiling is simple. Superior knowledge of rivals offers a legitimate source of competitive advantage. The raw material of competitive advantage consists of offering superior customer value in the firm's chosen market. The definitive characteristic of customer value is the adjective, superior. Customer value is defined relative to rival offerings making competitor knowledge an intrinsic component of corporate strategy. Profiling facilitates this strategic objective in three important ways. First, profiling can reveal strategic weaknesses in rivals that the firm may exploit. Second, the proactive stance of competitor profiling will allow the firm to anticipate the strategic response of their rivals to the firm's planned strategies, the strategies of other competing firms, and changes in the environment. Third, this proactive knowledge will give the firms strategic agility. Offensive strategy can be implemented more quickly in order to exploit opportunities and capitalize on strengths. Similarly, defensive strategy can be employed more deftly in order to counter the threat of rival firms from exploiting the firm's own weaknesses.\nFirms practising systematic and advanced competitor profiling may have a significant advantage. A comprehensive profiling capability is a core competence required for successful competition.\nA common technique is to create detailed profiles on each of the major competitors. These profiles give an in-depth description of the competitor's background, finances, products, markets, facilities, personnel, and strategies. This involves:\n\nBackground\nlocation of offices, plants, and online presences\nhistory – key personalities, dates, events, and trends\nownership, corporate governance, and organizational structure\nFinancials\nP-E ratios, dividend policy, and profitability\nvarious financial ratios, liquidity, and cash flow\nprofit growth profile; method of growth (organic or acquisitive)\nProducts\nproducts offered, depth and breadth of product line, and product portfolio balance\nnew products developed, new product success rate, and R&D strengths\nbrands, the strength of brand portfolio, brand loyalty and brand awareness\npatents and licenses\nquality control conformance\nreverse engineering or deformulation\nMarketing\nsegments served, market shares, customer base, growth rate, and customer loyalty\npromotional mix, promotional budgets, advertising themes, ad agency used, sales force success rate, online promotional strategy\ndistribution channels used (direct & indirect), exclusivity agreements, alliances, and geographical coverage\npricing, discounts, and allowances\nFacilities\nplant capacity, capacity utilization rate, age of plant, plant efficiency, capital investment\nlocation, shipping logistics, and product mix by plant\nPersonnel\nnumber of employees, key employees, and skill sets\nstrength of management, and management style\ncompensation, benefits, and ",
    "links": [
      "Advertising",
      "Ansoff matrix",
      "Babette Bensoussan",
      "Balanced scorecard",
      "Benchmarking",
      "Bowman's Strategy Clock",
      "Brand",
      "Business Model Canvas",
      "Competition (economics)",
      "Competitive advantage",
      "Competitive intelligence",
      "Craig Fleisher",
      "Deformulation",
      "Distribution (business)",
      "Dividend policy",
      "Focus strategy",
      "Growth–share matrix",
      "ISBN (identifier)",
      "Industry information",
      "Kraljic matrix",
      "MECE principle",
      "Management",
      "Managerial grid model",
      "Market Opportunity Navigator",
      "Market segment",
      "Marketing",
      "Marketing management",
      "Marketing plan",
      "Marketing research",
      "Marketing strategies",
      "Mind map",
      "New Product Development",
      "OGSM",
      "PEST analysis",
      "Pareto priority index",
      "Penetration pricing",
      "Porter's five forces analysis",
      "Positioning (marketing)",
      "Price discrimination",
      "Price skimming",
      "Pricing",
      "Product bundling",
      "Product line",
      "Product lining",
      "Promotion (marketing)",
      "Reverse engineering",
      "SWOT analysis",
      "Scenario planning",
      "Search engine optimization",
      "Segmenting-targeting-positioning"
    ],
    "categories": [
      "Category:All articles needing additional references",
      "Category:Articles needing additional references from April 2013",
      "Category:Articles with short description",
      "Category:Business analysis",
      "Category:Competition (economics)",
      "Category:Market research",
      "Category:Marketing strategy",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Chemistry": {
    "title": "Chemistry",
    "url": "https://en.wikipedia.org/wiki/Chemistry",
    "summary": "Chemistry is the scientific study of the properties and behavior of matter. It is a physical science within the natural sciences that studies the chemical elements that make up matter and compounds made of atoms, molecules and ions: their composition, structure, properties, behavior and the changes they undergo during reactions with other substances. Chemistry also addresses the nature of chemical bonds in chemical compounds.\nIn the scope of its subject, chemistry occupies an intermediate position between physics and biology. It is sometimes called the central science because it provides a foundation for understanding both basic and applied scientific disciplines at a fundamental level. For example, chemistry explains aspects of plant growth (botany), the formation of igneous rocks (geology), how atmospheric ozone is formed and how environmental pollutants are degraded (ecology), the properties of the soil on the Moon (cosmochemistry), how medications work (pharmacology), and how to co",
    "content": "Chemistry is the scientific study of the properties and behavior of matter. It is a physical science within the natural sciences that studies the chemical elements that make up matter and compounds made of atoms, molecules and ions: their composition, structure, properties, behavior and the changes they undergo during reactions with other substances. Chemistry also addresses the nature of chemical bonds in chemical compounds.\nIn the scope of its subject, chemistry occupies an intermediate position between physics and biology. It is sometimes called the central science because it provides a foundation for understanding both basic and applied scientific disciplines at a fundamental level. For example, chemistry explains aspects of plant growth (botany), the formation of igneous rocks (geology), how atmospheric ozone is formed and how environmental pollutants are degraded (ecology), the properties of the soil on the Moon (cosmochemistry), how medications work (pharmacology), and how to collect DNA evidence at a crime scene (forensics).\nChemistry has existed under various names since ancient times. It has evolved, and now chemistry encompasses various areas of specialisation, or subdisciplines, that continue to increase in number and interrelate to create further interdisciplinary fields of study. The applications of various fields of chemistry are used frequently for economic purposes in the chemical industry.\n\nEtymology\nThe word chemistry comes from a modification during the Renaissance of the word alchemy, which referred to an earlier set of practices that encompassed elements of chemistry, metallurgy, philosophy, astrology, astronomy, mysticism, and medicine. Alchemy is often associated with the quest to turn lead or other base metals into gold, though alchemists were also interested in many of the questions of modern chemistry.\nThe modern word alchemy in turn is derived from the Arabic word al-kīmīā (الكیمیاء). This may have Egyptian origins since al-kīmīā is derived from the Ancient Greek χημία, which is in turn derived from the word Kemet, which is the ancient name of Egypt in the Egyptian language. Alternately, al-kīmīā may derive from χημεία 'cast together'.\n\nModern principles\nThe current model of atomic structure is the quantum mechanical model. Traditional chemistry starts with the study of elementary particles, atoms, molecules, substances, metals, crystals and other aggregates of matter. Matter can be studied in solid, liquid, gas and plasma states, in isolation or in combination. The interactions, reactions and transformations that are studied in chemistry are usually the result of interactions between atoms, leading to rearrangements of the chemical bonds which hold atoms together. Such behaviors are studied in a chemistry laboratory.\nThe chemistry laboratory stereotypically uses various forms of laboratory glassware. However glassware is not central to chemistry, and a great deal of experimental (as well as applied/industrial) chemistry is done without it.\n\nA chemical reaction is a transformation of some substances into one or more different substances. The basis of such a chemical transformation is the rearrangement of electrons in the chemical bonds between atoms. It can be symbolically depicted through a chemical equation, which usually involves atoms as subjects. The number of atoms on the left and the right in the equation for a chemical transformation is equal. (When the number of atoms on either side is unequal, the transformation is referred to as a nuclear reaction or radioactive decay.) The type of chemical reactions a substance may undergo and the energy changes that may accompany it are constrained by certain basic rules, known as chemical laws.\nEnergy and entropy considerations are invariably important in almost all chemical studies. Chemical substances are classified in terms of their structure, phase, as well as their chemical compositions. They can be analyzed using the tools of chemical analysis, e.g. spectroscopy and chromatography. Scientists engaged in chemical research are known as chemists. Most chemists specialize in one or more sub-disciplines. Several concepts are essential for the study of chemistry; some of them are:\n\nMatter\nIn chemistry, matter is defined as anything that has rest mass and volume (it takes up space) and is made up of particles. The particles that make up matter have rest mass as well – not all particles have rest mass, such as the photon. Matter can be a pure chemical substance or a mixture of substances.\n\nAtom\nThe atom is the basic unit of chemistry. It consists of a dense core called the atomic nucleus surrounded by a space occupied by an electron cloud. The nucleus is made up of positively charged protons and uncharged neutrons (together called nucleons), while the electron cloud consists of negatively charged electrons which orbit the nucleus. In a neutral atom, the negatively charged electrons balance out the positive charge of the protons. The n",
    "links": [
      "4-Hydroxybutanal",
      "Abū al-Rayhān al-Bīrūnī",
      "Acid",
      "Acid dissociation constant",
      "Acid–base reaction",
      "Actinide chemistry",
      "Activation energy",
      "Agricultural chemistry",
      "Agrochemistry",
      "Air (classical element)",
      "Alchemy",
      "Alchemy and chemistry in Islam",
      "Alcohol (chemistry)",
      "Aldehyde",
      "Alessandro Volta",
      "Alkali metals",
      "Alkane stereochemistry",
      "Allotrope",
      "Alloy",
      "Alpha particle",
      "Amateur chemistry",
      "American Chemical Society",
      "American Society for Neurochemistry",
      "Ammonium chloride",
      "Ammonium hydroxide",
      "Amorphous solid",
      "Amount of substance",
      "Analytical chemistry",
      "Ancient Egypt",
      "Ancient Greece",
      "Ancient Greek",
      "Ancient Greek philosophy",
      "Ancient Rome",
      "Anion",
      "Antoine-Laurent de Lavoisier",
      "Antoine Lavoisier",
      "Applied science",
      "Aqueous solution",
      "Arab world",
      "Arabic",
      "Argon",
      "Aristotle",
      "Arrhenius acid",
      "Arrhenius equation",
      "Astrochemistry",
      "Astrology",
      "Astronomy",
      "Atmospheric chemistry",
      "Atom",
      "Atom cluster"
    ],
    "categories": [
      "Category:Articles containing Ancient Egyptian-language text",
      "Category:Articles containing Ancient Greek (to 1453)-language text",
      "Category:Articles containing Arabic-language text",
      "Category:Articles with short description",
      "Category:CS1 errors: ISBN date",
      "Category:Chemistry",
      "Category:Pages using Sister project links with default search",
      "Category:Short description is different from Wikidata",
      "Category:Use dmy dates from November 2020",
      "Category:Webarchive template wayback links"
    ]
  },
  "Analysis (disambiguation)": {
    "title": "Analysis (disambiguation)",
    "url": "https://en.wikipedia.org/wiki/Analysis_(disambiguation)",
    "summary": "Analysis is the process of observing and breaking down a complex topic or substance into smaller parts to gain a better understanding of it.\nAnalysis may also refer to:\n\nAnalysis (journal), a major international journal of philosophy\nAnalysis (radio programme), a half-hour BBC Radio 4 documentary programme\nData analysis\nMarket analysis, the study of the attractiveness and the dynamics of a market within an industry\nMathematical analysis\nComplex analysis\nReal analysis\nPhilosophical analysis\nPolitical feasibility analysis\nPsychoanalysis",
    "content": "Analysis is the process of observing and breaking down a complex topic or substance into smaller parts to gain a better understanding of it.\nAnalysis may also refer to:\n\nAnalysis (journal), a major international journal of philosophy\nAnalysis (radio programme), a half-hour BBC Radio 4 documentary programme\nData analysis\nMarket analysis, the study of the attractiveness and the dynamics of a market within an industry\nMathematical analysis\nComplex analysis\nReal analysis\nPhilosophical analysis\nPolitical feasibility analysis\nPsychoanalysis\n\nSee also\nAnalytical skill\nAnalytic (disambiguation)\nSynthesis (disambiguation)",
    "links": [
      "Analysis",
      "Analysis (journal)",
      "Analysis (radio programme)",
      "Analytic (disambiguation)",
      "Analytical skill",
      "Complex analysis",
      "Data analysis",
      "Market analysis",
      "Mathematical analysis",
      "Philosophical analysis",
      "Political feasibility analysis",
      "Psychoanalysis",
      "Real analysis",
      "Synthesis (disambiguation)",
      "Help:Disambiguation"
    ],
    "categories": [
      "Category:All article disambiguation pages",
      "Category:All disambiguation pages",
      "Category:Disambiguation pages",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Ancient Greek": {
    "title": "Ancient Greek",
    "url": "https://en.wikipedia.org/wiki/Ancient_Greek",
    "summary": "Ancient Greek (Ἑλληνῐκή, Hellēnikḗ; [hellɛːnikɛ́ː]) includes the forms of the Greek language used in ancient Greece and the ancient world from around 1500 BC to 300 BC. It is often roughly divided into the following periods: Mycenaean Greek (c. 1400–1200 BC), Dark Ages (c. 1200–800 BC), the Archaic or Homeric period (c. 800–500 BC), and the Classical period (c. 500–300 BC).\nAncient Greek was the language of Homer and of fifth-century Athenian historians, playwrights, and philosophers. It has contributed many words to English vocabulary and has been a standard subject of study in educational institutions of the Western world since the Renaissance. This article primarily contains information about the Epic and Classical periods of the language, which are the best-attested periods and considered most typical of Ancient Greek.\nFrom the Hellenistic period (c. 300 BC), Ancient Greek was followed by Koine Greek, which is regarded as a separate historical stage, though its earliest form closel",
    "content": "Ancient Greek (Ἑλληνῐκή, Hellēnikḗ; [hellɛːnikɛ́ː]) includes the forms of the Greek language used in ancient Greece and the ancient world from around 1500 BC to 300 BC. It is often roughly divided into the following periods: Mycenaean Greek (c. 1400–1200 BC), Dark Ages (c. 1200–800 BC), the Archaic or Homeric period (c. 800–500 BC), and the Classical period (c. 500–300 BC).\nAncient Greek was the language of Homer and of fifth-century Athenian historians, playwrights, and philosophers. It has contributed many words to English vocabulary and has been a standard subject of study in educational institutions of the Western world since the Renaissance. This article primarily contains information about the Epic and Classical periods of the language, which are the best-attested periods and considered most typical of Ancient Greek.\nFrom the Hellenistic period (c. 300 BC), Ancient Greek was followed by Koine Greek, which is regarded as a separate historical stage, though its earliest form closely resembles Attic Greek, and its latest form approaches Medieval Greek, and Koine may be classified as Ancient Greek in a wider sense – being an ancient rather than medieval form of Greek, though over the centuries increasingly resembling Medieval and Modern Greek.\nAncient Greek comprised several regional dialects, such as Attic, Ionic, Doric, Aeolic, and Arcadocypriot; among them, Attic Greek became the basis of Koine Greek. Just like Koine is often included in Ancient Greek, conversely, Mycenaean Greek is usually treated separately and not always included in Ancient Greek – reflecting the fact that Greek in the first millennium BC is considered prototypical of Ancient Greek.\n\nDialects\nAncient Greek was a pluricentric language, divided into many dialects. The main dialect groups are Attic and Ionic, Aeolic, Arcadocypriot, and Doric, many of them with several subdivisions. Some dialects are found in standardized literary forms in literature, while others are attested only in inscriptions.\nThere are also several historical forms. Homeric Greek is a literary form of Archaic Greek (derived primarily from Ionic and Aeolic) used in the epic poems, the Iliad and the Odyssey, and in later poems by other authors. Homeric Greek had significant differences in grammar and pronunciation from Classical Attic and other Classical-era dialects.\n\nHistory\nThe origins, early form and development of the Hellenic language family are not well understood because of a lack of contemporaneous evidence. Several theories exist about what Hellenic dialect groups may have existed between the divergence of early Greek-like speech from the common Proto-Indo-European language and the Classical period. They have the same general outline but differ in some of the detail. The only attested dialect from this period is Mycenaean Greek, but its relationship to the historical dialects and the historical circumstances of the times imply that the overall groups already existed in some form.\nScholars assume that major Ancient Greek period dialect groups developed not later than 1120 BC, at the time of the Dorian invasions—and that their first appearances as precise alphabetic writing began in the 8th century BC. The invasion would not be \"Dorian\" unless the invaders had some cultural relationship to the historical Dorians. The invasion is known to have displaced population to the later Attic-Ionic regions, who regarded themselves as descendants of the population displaced by or contending with the Dorians.\nThe Greeks of this period believed there were three major divisions of all Greek people – Dorians, Aeolians, and Ionians (including Athenians), each with their own defining and distinctive dialects. Allowing for their oversight of Arcadian, an obscure mountain dialect, and Cypriot, far from the center of Greek scholarship, this division of people and language is quite similar to the results of modern archaeological-linguistic investigation.\nOne standard formulation for the dialects is:\n\nWest Group\nNorthwest Greek\nDoric\nAeolic Group\nAegean/Asiatic Aeolic\nThessalian\nBoeotian\nIonic-Attic Group\nAttic\nIonic\nEuboean and colonies in Italy\nCycladic\nAsiatic Ionic\nArcadocypriot Greek\nArcadian\nCypriot\nWest vs. non-West Greek is the strongest-marked and earliest division, with non-West in subsets of Ionic-Attic (or Attic-Ionic) and Aeolic vs. Arcadocypriot, or Aeolic and Arcado-Cypriot vs. Ionic-Attic. Often non-West is called 'East Greek'.\nArcadocypriot apparently descended more closely from the Mycenaean Greek of the Bronze Age.\nBoeotian Greek had come under a strong Northwest Greek influence, and can in some respects be considered a transitional dialect, as exemplified in the poems of the Boeotian poet Pindar who wrote in Doric with a small Aeolic admixture. Thessalian likewise had come under Northwest Greek influence, though to a lesser degree.\nPamphylian Greek, spoken in a small area on the southwestern coast of Anatolia and little preserved in inscriptions, may be either ",
    "links": [
      "Abonoteichos",
      "Acarnanian League",
      "Accusative case",
      "Achaean Doric Greek",
      "Achaean League",
      "Acute accent",
      "Aegean Sea",
      "Aeolian Islands",
      "Aeolic",
      "Aeolic Greek",
      "Aeolis",
      "Aeschylus",
      "Aesop",
      "Aetolian League",
      "Agora",
      "Agriculture in ancient Greece",
      "Agrigento",
      "Akra (Crimmerian Bosporus)",
      "Akrai",
      "Akrillai",
      "Alcaeus of Mytilene",
      "Alexander the Great",
      "Alfred Rahlfs",
      "Alicudi",
      "Aljaraque",
      "Allophone",
      "Alpha",
      "Alveolar consonant",
      "Amasra",
      "Amphictyonic League",
      "Anapa",
      "Anatolia",
      "Anaxagoras",
      "Anaximander",
      "Anaximenes of Miletus",
      "Ancient Argos",
      "Ancient Corinth",
      "Ancient Greece",
      "Ancient Greece and wine",
      "Ancient Greek accent",
      "Ancient Greek architecture",
      "Ancient Greek art",
      "Ancient Greek astronomy",
      "Ancient Greek calendars",
      "Ancient Greek coinage",
      "Ancient Greek cuisine",
      "Ancient Greek dialects",
      "Ancient Greek folklore",
      "Ancient Greek funeral and burial practices",
      "Ancient Greek grammar"
    ],
    "categories": [
      "Category:9th-century BC establishments in Greece",
      "Category:All Wikipedia articles in need of updating",
      "Category:All articles needing additional references",
      "Category:Ancient Greece",
      "Category:Ancient Greek",
      "Category:Articles containing Ancient Greek (to 1453)-language text",
      "Category:Articles containing Croatian-language text",
      "Category:Articles containing Dutch-language text",
      "Category:Articles containing Greek-language text",
      "Category:Articles containing Latin-language text"
    ]
  },
  "Aristotle": {
    "title": "Aristotle",
    "url": "https://en.wikipedia.org/wiki/Aristotle",
    "summary": "Aristotle (Attic Greek: Ἀριστοτέλης, romanized: Aristotélēs; 384–322 BC) was an Ancient Greek philosopher and polymath. His writings cover a broad range of subjects spanning the natural sciences, philosophy, linguistics, economics, politics, psychology, and the arts. As the founder of the Peripatetic school of philosophy in the Lyceum in Athens, he began the wider Aristotelian tradition that followed, which set the groundwork for the development of modern science.\nLittle is known about Aristotle's life. He was born in the city of Stagira in northern Greece during the Classical period. His father, Nicomachus, died when Aristotle was a child, and he was brought up by a guardian. At around eighteen years old, he joined Plato's Academy in Athens and remained there until the age of thirty seven (c. 347 BC). Shortly after Plato died, Aristotle left Athens and, at the request of Philip II of Macedon, tutored his son Alexander the Great beginning in 343 BC. He established a library in the Lyce",
    "content": "Aristotle (Attic Greek: Ἀριστοτέλης, romanized: Aristotélēs; 384–322 BC) was an Ancient Greek philosopher and polymath. His writings cover a broad range of subjects spanning the natural sciences, philosophy, linguistics, economics, politics, psychology, and the arts. As the founder of the Peripatetic school of philosophy in the Lyceum in Athens, he began the wider Aristotelian tradition that followed, which set the groundwork for the development of modern science.\nLittle is known about Aristotle's life. He was born in the city of Stagira in northern Greece during the Classical period. His father, Nicomachus, died when Aristotle was a child, and he was brought up by a guardian. At around eighteen years old, he joined Plato's Academy in Athens and remained there until the age of thirty seven (c. 347 BC). Shortly after Plato died, Aristotle left Athens and, at the request of Philip II of Macedon, tutored his son Alexander the Great beginning in 343 BC. He established a library in the Lyceum, which helped him to produce many of his hundreds of books on papyrus scrolls.\nThough Aristotle wrote many treatises and dialogues for publication, only around a third of his original output has survived, none of it intended for publication. Aristotle provided a complex synthesis of the various philosophies existing prior to him. His teachings and methods of inquiry have had a significant impact across the world, and remain a subject of contemporary philosophical discussion.\nAristotle's views profoundly shaped medieval scholarship. The influence of his physical science extended from late antiquity and the Early Middle Ages into the Renaissance, and was not replaced systematically until the Enlightenment and theories such as classical mechanics were developed. He influenced Judeo-Islamic philosophies during the Middle Ages, as well as Christian theology, especially the Neoplatonism of the Early Church and the scholastic tradition of the Catholic Church.\nAristotle was revered among medieval Muslim scholars as \"The First Teacher\", and among medieval Christians like Thomas Aquinas as simply \"The Philosopher\", while the poet Dante called him \"the master of those who know\". He has been referred to as the first scientist. His works contain the earliest known systematic study of logic, and were studied by medieval scholars such as Peter Abelard and Jean Buridan. His influence on logic continued well into the 19th century. In addition, his ethics, although always influential, has gained renewed interest with the modern advent of virtue ethics.\n\nLife\nIn general, the details of Aristotle's life are not well-established. The biographies written in ancient times are often speculative and historians only agree on a few salient points. Aristotle was born in 384 BC in Stagira, Chalcidice, about 55 km (34 miles) east of modern-day Thessaloniki. He was the son of Nicomachus, the personal physician of King Amyntas of Macedon, and Phaestis, a woman with origins from Chalcis, Euboea. Nicomachus was said to have belonged to the medical guild of Asclepiadae and was likely responsible for Aristotle's early interest in biology and medicine. Ancient tradition held that Aristotle's family descended from the legendary physician Asclepius and his son Machaon. Both of Aristotle's parents died when he was still at a young age and Proxenus of Atarneus became his guardian. Although little information about Aristotle's childhood has survived, he probably spent some time in the Macedonian capital, making his first connections with the Macedonian monarchy.\n\nAt the age of seventeen or eighteen, Aristotle moved to Athens to continue his education at Plato's Academy. He became distinguished as a researcher and lecturer, earning for himself the nickname \"mind of the school\" by his tutor Plato. In Athens, he probably experienced the Eleusinian Mysteries as he wrote when describing the sights one viewed at the Mysteries, \"to experience is to learn\" (παθεĩν μαθεĩν). Aristotle remained in Athens for nearly twenty years before leaving in 348/47 BC after Plato's death. The traditional story about his departure records that he was disappointed with the academy's direction after control passed to Plato's nephew Speusippus, although it is possible that the anti-Macedonian sentiments in Athens could have also influenced his decision. Aristotle left with Xenocrates to Assos in Asia Minor, where he was invited by his former fellow student Hermias of Atarneus; he stayed there for a few years and left around the time of Hermias' death. While at Assos, Aristotle and his colleague Theophrastus did extensive research in botany and marine biology, which they later continued at the near-by island of Lesbos. During this time, Aristotle married Pythias, Hermias's adoptive daughter and niece, and had a daughter whom they also named Pythias.\n\nIn 343/42 BC, Aristotle was invited to Pella by Philip II of Macedon to become the tutor to his thirteen-year-old son Alexander; a choice perhaps",
    "links": [
      "6123 Aristoteles",
      "A. J. Ayer",
      "A Dialogue Concerning Oratorical Partitions",
      "A General Rhetoric",
      "A History of British Birds",
      "A Theory of Justice",
      "A Treatise Concerning the Principles of Human Knowledge",
      "A Treatise of Human Nature",
      "Abbasid Caliphate",
      "Abbott Handerson Thayer",
      "Abonoteichos",
      "Abstract and concrete",
      "Abstract object theory",
      "Acarnanian League",
      "Accident (philosophy)",
      "Accountability",
      "Achaean League",
      "Achaemenid Empire",
      "Action theory (philosophy)",
      "Active intellect",
      "Adam Müller",
      "Adam Smith",
      "Adaptation",
      "Adaptive Coloration in Animals",
      "Adolf Reinach",
      "Adrastus of Aphrodisias",
      "Aegean Sea",
      "Aelius Aristides",
      "Aeolian Islands",
      "Aeolian islands",
      "Aeolic Greek",
      "Aeolis",
      "Aeschines",
      "Aeschylus",
      "Aesop",
      "Aesthetics",
      "Aether (classical element)",
      "Aetolian League",
      "After Virtue",
      "Age of Enlightenment",
      "Agora",
      "Agrarianism",
      "Agriculture in ancient Greece",
      "Agrigento",
      "Air (classical element)",
      "Akra (Crimmerian Bosporus)",
      "Akrai",
      "Akrasia",
      "Akrillai",
      "Al-Farabi"
    ],
    "categories": [
      "Category:322 BC deaths",
      "Category:384 BC births",
      "Category:4th-century BC Greek mathematicians",
      "Category:4th-century BC Greek writers",
      "Category:4th-century BC philosophers",
      "Category:Acting theorists",
      "Category:Ancient Greek biologists",
      "Category:Ancient Greek cosmologists",
      "Category:Ancient Greek epistemologists",
      "Category:Ancient Greek ethicists"
    ]
  },
  "Analysis of covariance": {
    "title": "Analysis of covariance",
    "url": "https://en.wikipedia.org/wiki/Analysis_of_covariance",
    "summary": "Analysis of covariance (ANCOVA) is a general linear model that blends ANOVA and regression. ANCOVA evaluates whether the means of a dependent variable (DV) are equal across levels of one or more categorical independent variables (IV) and across one or more continuous variables. For example, the categorical variable(s) might describe treatment and the continuous variable(s) might be covariates (CV)'s, typically nuisance variables; or vice versa. Mathematically, ANCOVA decomposes the variance in the DV into variance explained by the CV(s), variance explained by the categorical IV, and residual variance. Intuitively, ANCOVA can be thought of as 'adjusting' the DV by the group means of the CV(s).\nThe ANCOVA model assumes a linear relationship between the response (DV) and covariate (CV):\n\n  \n    \n      \n        \n          y\n          \n            i\n            j\n          \n        \n        =\n        μ\n        +\n        \n          τ\n          \n            i\n          \n        \n        +\n   ",
    "content": "Analysis of covariance (ANCOVA) is a general linear model that blends ANOVA and regression. ANCOVA evaluates whether the means of a dependent variable (DV) are equal across levels of one or more categorical independent variables (IV) and across one or more continuous variables. For example, the categorical variable(s) might describe treatment and the continuous variable(s) might be covariates (CV)'s, typically nuisance variables; or vice versa. Mathematically, ANCOVA decomposes the variance in the DV into variance explained by the CV(s), variance explained by the categorical IV, and residual variance. Intuitively, ANCOVA can be thought of as 'adjusting' the DV by the group means of the CV(s).\nThe ANCOVA model assumes a linear relationship between the response (DV) and covariate (CV):\n\n  \n    \n      \n        \n          y\n          \n            i\n            j\n          \n        \n        =\n        μ\n        +\n        \n          τ\n          \n            i\n          \n        \n        +\n        \n          B\n        \n        (\n        \n          x\n          \n            i\n            j\n          \n        \n        −\n        \n          \n            x\n            ¯\n          \n        \n        )\n        +\n        \n          ϵ\n          \n            i\n            j\n          \n        \n        .\n      \n    \n    {\\displaystyle y_{ij}=\\mu +\\tau _{i}+\\mathrm {B} (x_{ij}-{\\overline {x}})+\\epsilon _{ij}.}\n  \n\nIn this equation, the DV, \n  \n    \n      \n        \n          y\n          \n            i\n            j\n          \n        \n      \n    \n    {\\displaystyle y_{ij}}\n  \n is the jth observation under the ith categorical group; the CV, \n  \n    \n      \n        \n          x\n          \n            i\n            j\n          \n        \n      \n    \n    {\\displaystyle x_{ij}}\n  \n is the jth observation of the covariate under the ith group. Variables in the model that are derived from the observed data are \n  \n    \n      \n        μ\n      \n    \n    {\\displaystyle \\mu }\n  \n (the grand mean) and \n  \n    \n      \n        \n          \n            x\n            ¯\n          \n        \n      \n    \n    {\\displaystyle {\\overline {x}}}\n  \n (the global mean for covariate \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n). The variables to be fitted are \n  \n    \n      \n        \n          τ\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle \\tau _{i}}\n  \n (the effect of the ith level of the categorical IV), \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  \n (the slope of the line) and \n  \n    \n      \n        \n          ϵ\n          \n            i\n            j\n          \n        \n      \n    \n    {\\displaystyle \\epsilon _{ij}}\n  \n (the associated unobserved error term for the jth observation in the ith group).\nUnder this specification, the categorical treatment effects sum to zero \n  \n    \n      \n        \n          (\n          \n            \n              ∑\n              \n                i\n              \n              \n                a\n              \n            \n            \n              τ\n              \n                i\n              \n            \n            =\n            0\n          \n          )\n        \n        .\n      \n    \n    {\\displaystyle \\left(\\sum _{i}^{a}\\tau _{i}=0\\right).}\n  \n The standard assumptions of the linear regression model are also assumed to hold, as discussed below.\n\nExample\nIn an agricultural study, ANCOVA can be used to analyze the effect of different fertilizers (\n  \n    \n      \n        \n          τ\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle \\tau _{i}}\n  \n) on crop yield (\n  \n    \n      \n        \n          y\n          \n            i\n            j\n          \n        \n      \n    \n    {\\displaystyle y_{ij}}\n  \n), while accounting for soil quality (\n  \n    \n      \n        \n          x\n          \n            i\n            j\n          \n        \n      \n    \n    {\\displaystyle x_{ij}}\n  \n) as a covariate. Soil quality, a continuous variable, influences crop yield and may vary across plots, potentially confounding the results.\nThe model adjusts yield measurements for soil quality differences and evaluates whether fertilizer types differ significantly. Mathematically, this can be expressed as:\n\n  \n    \n      \n        \n          y\n          \n            i\n            j\n          \n        \n        =\n        μ\n        +\n        \n          τ\n          \n            i\n          \n        \n        +\n        β\n        (\n        \n          x\n          \n            i\n            j\n          \n        \n        −\n        \n          \n            x\n            ¯\n          \n        \n        )\n        +\n        \n          ϵ\n          \n            i\n            j\n          \n        \n        ,\n      \n    \n    {\\displaystyle y_{ij}=\\mu +\\tau _{i}+\\beta (x_{ij}-{\\overline {x}})+\\epsilon _{ij},}\n  \n\nwhere:\n\n  \n    \n      \n        \n          y\n          \n            i\n            j\n          \n        \n      \n    \n    {\\displaystyle y_{ij}}\n  \n is the crop yield for the \n  ",
    "links": [
      "ANOVA",
      "Accelerated failure time model",
      "Actuarial science",
      "Adaptive clinical trial",
      "Akaike information criterion",
      "Analysis of variance",
      "Ancova (moth)",
      "Anderson–Darling test",
      "Approximation theory",
      "Arithmetic mean",
      "Arithmetic–geometric mean",
      "Asymptotic theory (statistics)",
      "Autocorrelation",
      "Autoregressive conditional heteroskedasticity",
      "Autoregressive–moving-average model",
      "Average absolute deviation",
      "Bar chart",
      "Bayes estimator",
      "Bayes factor",
      "Bayesian experimental design",
      "Bayesian inference",
      "Bayesian information criterion",
      "Bayesian linear regression",
      "Bayesian probability",
      "Bias of an estimator",
      "Binomial regression",
      "Bioinformatics",
      "Biostatistics",
      "Biplot",
      "Blind experiment",
      "Blocking (statistics)",
      "Bootstrapping (statistics)",
      "Box plot",
      "Box–Behnken design",
      "Box–Jenkins method",
      "Breusch–Godfrey test",
      "Calibration curve",
      "Canonical correlation",
      "Cartography",
      "Categorical variable",
      "Census",
      "Central composite design",
      "Central limit theorem",
      "Central tendency",
      "Chebyshev nodes",
      "Chebyshev polynomials",
      "Chemometrics",
      "Chi-squared test",
      "Clinical study design",
      "Clinical trial"
    ],
    "categories": [
      "Category:All articles with unsourced statements",
      "Category:Analysis of variance",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from December 2022",
      "Category:Covariance and correlation",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Astrostatistics": {
    "title": "Astrostatistics",
    "url": "https://en.wikipedia.org/wiki/Astrostatistics",
    "summary": "Astrostatistics is a discipline which spans astrophysics, statistical analysis and data mining. It is used to process the vast amount of data produced by automated scanning of the cosmos, to characterize complex datasets, and to link astronomical data to astrophysical theory. Many branches of statistics are involved in astronomical analysis including nonparametrics, multivariate regression and multivariate classification, time series analysis, and especially Bayesian inference. The field is closely related to astroinformatics.\n\n\n== References ==",
    "content": "Astrostatistics is a discipline which spans astrophysics, statistical analysis and data mining. It is used to process the vast amount of data produced by automated scanning of the cosmos, to characterize complex datasets, and to link astronomical data to astrophysical theory. Many branches of statistics are involved in astronomical analysis including nonparametrics, multivariate regression and multivariate classification, time series analysis, and especially Bayesian inference. The field is closely related to astroinformatics.\n\n\n== References ==",
    "links": [
      "Astroinformatics",
      "Astronomical data",
      "Astrophysics",
      "Automated scanning",
      "Bayesian inference",
      "Data mining",
      "Machine learning",
      "Multivariate classification",
      "Multivariate regression",
      "Nonparametrics",
      "Statistical analysis",
      "Statistics",
      "Theoretical astrophysics",
      "Time series",
      "Talk:Astrostatistics",
      "Wikipedia:Articles with a single source",
      "Wikipedia:Citing sources",
      "Wikipedia:Independent sources",
      "Wikipedia:Neutral point of view",
      "Wikipedia:Stub",
      "Wikipedia:Verifiability",
      "Template:Machine-learning-stub",
      "Template:Statistics-stub",
      "Template talk:Machine-learning-stub",
      "Template talk:Statistics-stub",
      "Help:Maintenance template removal",
      "Help:Referencing for beginners"
    ],
    "categories": [
      "Category:All articles lacking reliable references",
      "Category:All articles needing additional references",
      "Category:All stub articles",
      "Category:Applied statistics",
      "Category:Articles lacking reliable references from September 2024",
      "Category:Articles needing additional references from September 2024",
      "Category:Articles with multiple maintenance issues",
      "Category:Articles with short description",
      "Category:Astrophysics",
      "Category:Data mining"
    ]
  },
  "Asymptotic theory (statistics)": {
    "title": "Asymptotic theory (statistics)",
    "url": "https://en.wikipedia.org/wiki/Asymptotic_theory_(statistics)",
    "summary": "In statistics, asymptotic theory, or large sample theory, is a framework for assessing properties of estimators and statistical tests. Within this framework, it is often assumed that the sample size n may grow indefinitely; the properties of estimators and tests are then evaluated under the limit of n → ∞. In practice, a limit evaluation is considered to be approximately valid for large finite sample sizes too.",
    "content": "In statistics, asymptotic theory, or large sample theory, is a framework for assessing properties of estimators and statistical tests. Within this framework, it is often assumed that the sample size n may grow indefinitely; the properties of estimators and tests are then evaluated under the limit of n → ∞. In practice, a limit evaluation is considered to be approximately valid for large finite sample sizes too.\n\nOverview\nMost statistical problems begin with a dataset of size n. The asymptotic theory proceeds by assuming that it is possible (in principle) to keep collecting additional data, thus that the sample size grows infinitely, i.e. n → ∞. Under the assumption, many results can be obtained that are unavailable for samples of finite size. An example is the weak law of large numbers. The law states that for a sequence of independent and identically distributed (IID) random variables X1, X2, ..., if one value is drawn from each random variable and the average of the first n values is computed as Xn, then the Xn converge in probability to the population mean E[Xi] as n → ∞.\nIn asymptotic theory, the standard approach is n → ∞. For some statistical models, slightly different approaches of asymptotics may be used. For example, with panel data, it is commonly assumed that one dimension in the data remains fixed, whereas the other dimension grows: T = constant and N → ∞, or vice versa.\nBesides the standard approach to asymptotics, other alternative approaches exist:\n\nWithin the local asymptotic normality framework, it is assumed that the value of the \"true parameter\" in the model varies slightly with n, such that the n-th model corresponds to  θn = θ + h/√n . This approach lets us study the regularity of estimators.\nWhen statistical tests are studied for their power to distinguish against the alternatives that are close to the null hypothesis, it is done within the so-called \"local alternatives\" framework: the null hypothesis is H0: θ = θ0 and the alternative is H1: θ = θ0 + h/√n . This approach is especially popular for the unit root tests.\nThere are models where the dimension of the parameter space Θn slowly expands with n, reflecting the fact that the more observations there are, the more structural effects can be feasibly incorporated in the model.\nIn kernel density estimation and kernel regression, an additional parameter is assumed—the bandwidth h. In those models, it is typically taken that h → 0 as n → ∞. The rate of convergence must be chosen carefully, though, usually h ∝ n−1/5.\nIn many cases, highly accurate results for finite samples can be obtained via numerical methods (i.e. computers); even in such cases, though, asymptotic analysis can be useful. This point was made by Small (2010, §1.4), as follows.\n\nA primary goal of asymptotic analysis is to obtain a deeper qualitative understanding of quantitative tools. The conclusions of an asymptotic analysis often supplement the conclusions which can be obtained by numerical methods.\n\nModes of convergence of random variables\nAsymptotic properties\nEstimators\nConsistency\nA sequence of estimates is said to be consistent, if it converges in probability to the true value of the parameter being estimated:\n\n  \n    \n      \n        \n          \n            \n              \n                θ\n                ^\n              \n            \n          \n          \n            n\n          \n        \n         \n        \n          \n            →\n            \n              \n                p\n                \n              \n            \n          \n        \n         \n        \n          θ\n          \n            0\n          \n        \n        .\n      \n    \n    {\\displaystyle {\\hat {\\theta }}_{n}\\ {\\xrightarrow {\\overset {}{p}}}\\ \\theta _{0}.}\n  \n\nThat is, roughly speaking with an infinite amount of data the estimator (the formula for generating the estimates) would almost surely give the correct result for the parameter being estimated.\n\nAsymptotic distribution\nIf it is possible to find sequences of non-random constants {an}, {bn} (possibly depending on the value of θ0), and a non-degenerate distribution G such that\n\n  \n    \n      \n        \n          b\n          \n            n\n          \n        \n        (\n        \n          \n            \n              \n                θ\n                ^\n              \n            \n          \n          \n            n\n          \n        \n        −\n        \n          a\n          \n            n\n          \n        \n        )\n         \n        \n          \n            →\n            \n              d\n            \n          \n        \n         \n        G\n        ,\n      \n    \n    {\\displaystyle b_{n}({\\hat {\\theta }}_{n}-a_{n})\\ {\\xrightarrow {d}}\\ G,}\n  \n\nthen the sequence of estimators \n  \n    \n      \n        \n          \n            \n              \n                \n                  θ\n                  ^\n                \n              \n            \n            \n              n\n            \n          \n        \n      \n    \n    {\\displaystyle \\textstyle {\\ha",
    "links": [
      "Accelerated failure time model",
      "Actuarial science",
      "Adaptive clinical trial",
      "Akaike information criterion",
      "Aleksandr Alekseevich Borovkov",
      "American Mathematical Society",
      "Analysis of covariance",
      "Analysis of variance",
      "Anderson–Darling test",
      "Arithmetic mean",
      "Arithmetic–geometric mean",
      "Asymptotic analysis",
      "Asymptotic distribution",
      "Autocorrelation",
      "Autoregressive conditional heteroskedasticity",
      "Autoregressive–moving-average model",
      "Average absolute deviation",
      "Bar chart",
      "Bayes estimator",
      "Bayes factor",
      "Bayesian inference",
      "Bayesian information criterion",
      "Bayesian linear regression",
      "Bayesian probability",
      "Bias of an estimator",
      "Binomial regression",
      "Bioinformatics",
      "Biostatistics",
      "Biplot",
      "Birkhäuser",
      "Blocking (statistics)",
      "Bootstrapping (statistics)",
      "Box plot",
      "Box–Jenkins method",
      "Breusch–Godfrey test",
      "Cambridge University Press",
      "Canonical correlation",
      "Cartography",
      "Categorical variable",
      "Census",
      "Central limit theorem",
      "Central tendency",
      "Chapman & Hall",
      "Chemometrics",
      "Chi-squared test",
      "Clinical study design",
      "Clinical trial",
      "Cluster analysis",
      "Cluster sampling",
      "Cochran–Mantel–Haenszel statistics"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Asymptotic theory (statistics)",
      "Category:Short description matches Wikidata"
    ]
  },
  "Baseball statistics": {
    "title": "Baseball statistics",
    "url": "https://en.wikipedia.org/wiki/Baseball_statistics",
    "summary": "Baseball statistics collect a variety of metrics used to evaluate player and team performance in the sport of baseball. \nBecause the flow of a baseball game has natural breaks, and player performance is individually measurable, the sport lends itself to easy record-keeping and compiling statistics. Baseball \"stats\" have been recorded since the game's beginnings as a sport in the middle of the nineteenth century, and are widely available through the historical records of leagues such as the National Association of Professional Base Ball Players and the Negro leagues, although the consistency, standards, and calculations are often incomplete or questionable. \nSince the National League (NL) was founded in 1876, statistics in the most elite levels of professional baseball have been kept, with efforts to standardize the stats and their compilation improving during the early 20th century. Such efforts have evolved together with advances in technology ever since. The NL was joined by the Amer",
    "content": "Baseball statistics collect a variety of metrics used to evaluate player and team performance in the sport of baseball. \nBecause the flow of a baseball game has natural breaks, and player performance is individually measurable, the sport lends itself to easy record-keeping and compiling statistics. Baseball \"stats\" have been recorded since the game's beginnings as a sport in the middle of the nineteenth century, and are widely available through the historical records of leagues such as the National Association of Professional Base Ball Players and the Negro leagues, although the consistency, standards, and calculations are often incomplete or questionable. \nSince the National League (NL) was founded in 1876, statistics in the most elite levels of professional baseball have been kept, with efforts to standardize the stats and their compilation improving during the early 20th century. Such efforts have evolved together with advances in technology ever since. The NL was joined by the American League (AL) in 1903; together the two constitute modern Major League Baseball. A number of statistics are defined in the Official Baseball Rules, which task the official scorer with providing a report after each game.\nAdvances in both statistical analysis and technology made possible by the \"PC revolution\" of the 1980s and 1990s have driven teams and fans to evaluate players by an ever more elaborate set of statistics, which hold them to ever-evolving standards. With the advent of these methods, players can be compared across different eras and run scoring environments.\n\nDevelopment\nThe practice of keeping records of player achievements was started in the 19th century by English-American sportswriter Henry Chadwick. Based on his experience with the sport of cricket, Chadwick devised the predecessors to modern-day statistics including batting average, runs scored, and runs allowed.\nTraditionally, statistics such as batting average (the number of hits divided by the number of at bats) and earned run average (the average number of runs allowed by a pitcher per nine innings, less errors and other events out of the pitcher's control) have dominated attention in the statistical world of baseball. However, the recent advent of sabermetrics has created statistics drawing from a greater breadth of player performance measures and playing field variables. Sabermetrics and comparative statistics attempt to provide an improved measure of a player's performance and contributions to his team from year to year, frequently against a statistical performance average.\nComprehensive, historical baseball statistics were difficult for the average fan to access until 1951, when researcher Hy Turkin published The Complete Encyclopedia of Baseball. In 1969, Macmillan Publishing printed its first Baseball Encyclopedia, using a computer to compile statistics for the first time. Known as \"Big Mac\", the encyclopedia became the standard baseball reference until 1988, when Total Baseball was released by Warner Books using more sophisticated technology. The publication of Total Baseball led to the discovery of several \"phantom ballplayers\", such as Lou Proctor, who did not belong in official record books and were removed.\n\nUse\nThroughout modern baseball, a few core statistics have been traditionally referenced – batting average, RBI, and home runs. To this day, a player who leads the league in all of these three statistics earns the \"Triple Crown\". For pitchers, wins, ERA, and strikeouts are the most often-cited statistics, and a pitcher leading his league in these statistics may also be referred to as a \"triple crown\" winner. General managers and baseball scouts have long used the major statistics, among other factors and opinions, to understand player value. Managers, catchers and pitchers use the statistics of batters of opposing teams to develop pitching strategies and set defensive positioning on the field. Managers and batters study opposing pitcher performance and motions in attempting to improve hitting. Scouts use stats when they are looking at a player who they may end up drafting or signing to a contract.\nSome sabermetric statistics have entered the mainstream baseball world that measure a batter's overall performance including on-base plus slugging, commonly referred to as OPS. OPS adds the hitter's on-base percentage (number of times reached base by any means divided by total plate appearances) to their slugging percentage (total bases divided by at-bats).  Some argue that the OPS formula is flawed and that more weight should be shifted towards OBP (on-base percentage). The statistic wOBA (weighted on-base average) attempts to correct for this.\nOPS is also useful when determining a pitcher's level of success. \"Opponent on-base plus slugging\" (OOPS) is becoming a popular tool to evaluate a pitcher's actual performance.  When analyzing a pitcher's statistics, some useful categories include K/9IP (strikeouts per nine innings), K/BB (strikeouts ",
    "links": [
      "16-inch softball",
      "20–20–20 club",
      "20–50 club",
      "3,000-hit club",
      "3,000 strikeout club",
      "300-win club",
      "300 save club",
      "300 strikeout club",
      "30–30 club",
      "40–40 club",
      "500 home run club",
      "50 home run club",
      "600 home run club",
      "Adjusted ERA+",
      "Alan Schwarz",
      "American League",
      "Appeal play",
      "Assist (baseball)",
      "Assist (baseball statistics)",
      "At bat",
      "At bats per home run",
      "Automatic runner",
      "Backstop (baseball)",
      "Balk",
      "Ballpark",
      "Baltimore chop",
      "Base on balls",
      "Base running",
      "Base runs",
      "Baseball",
      "Baseball (ball)",
      "Baseball awards",
      "Baseball bat",
      "Baseball cap",
      "Baseball card",
      "Baseball clothing and equipment",
      "Baseball doughnut",
      "Baseball field",
      "Baseball glove",
      "Baseball park",
      "Baseball positioning",
      "Baseball positions",
      "Baseball rules",
      "Baseball scorekeeping",
      "Baseball stirrups",
      "Baseball uniform",
      "Bases loaded",
      "Bases on balls per 9 innings pitched",
      "Bases on balls per nine innings pitched",
      "Bat flip"
    ],
    "categories": [
      "Category:All articles needing additional references",
      "Category:Articles needing additional references from October 2018",
      "Category:Articles with short description",
      "Category:Baseball statistics",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Bayes' theorem": {
    "title": "Bayes' theorem",
    "url": "https://en.wikipedia.org/wiki/Bayes%27_theorem",
    "summary": "Bayes' theorem (alternatively Bayes' law or Bayes' rule, after Thomas Bayes) gives a mathematical rule for inverting conditional probabilities, allowing one to find the probability of a cause given its effect. For example, Bayes' theorem provides the means to calculate the probability that a patient has a disease given the fact that they tested positive for that disease, using the probability that the test yields a positive result when the disease is present. The theorem was developed in the 18th century by Bayes and independently by Pierre-Simon Laplace.\nOne of Bayes' theorem's many applications is Bayesian inference, an approach to statistical inference, where it is used to invert the probability of observations given a model configuration (i.e., the likelihood function) to obtain the probability of the model configuration given the observations (i.e., the posterior probability).",
    "content": "Bayes' theorem (alternatively Bayes' law or Bayes' rule, after Thomas Bayes) gives a mathematical rule for inverting conditional probabilities, allowing one to find the probability of a cause given its effect. For example, Bayes' theorem provides the means to calculate the probability that a patient has a disease given the fact that they tested positive for that disease, using the probability that the test yields a positive result when the disease is present. The theorem was developed in the 18th century by Bayes and independently by Pierre-Simon Laplace.\nOne of Bayes' theorem's many applications is Bayesian inference, an approach to statistical inference, where it is used to invert the probability of observations given a model configuration (i.e., the likelihood function) to obtain the probability of the model configuration given the observations (i.e., the posterior probability).\n\nHistory\nBayes' theorem is named after Thomas Bayes (), a minister, statistician, and philosopher. Bayes used conditional probability to provide an algorithm (his Proposition 9) that uses evidence to calculate limits on an unknown parameter. His work was published in 1763 as An Essay Towards Solving a Problem in the Doctrine of Chances. Bayes studied how to compute a distribution for the probability parameter of a binomial distribution (in modern terminology). After Bayes's death, his family gave his papers to a friend, the minister, philosopher, and mathematician Richard Price.\nPrice significantly edited the unpublished manuscript for two years before sending it to a friend who read it aloud at the Royal Society on 23 December 1763. Price edited Bayes's major work \"An Essay Towards Solving a Problem in the Doctrine of Chances\" (1763), which appeared in Philosophical Transactions, and contains Bayes' theorem. Price wrote an introduction to the paper that provides some of the philosophical basis of Bayesian statistics and chose one of the two solutions Bayes offered. In 1765, Price was elected a Fellow of the Royal Society in recognition of his work on Bayes's legacy. On 27 April, a letter sent to his friend Benjamin Franklin was read out at the Royal Society, and later published, in which Price applies this work to population and computing 'life-annuities'.\nIndependently of Bayes, Pierre-Simon Laplace used conditional probability to formulate the relation of an updated posterior probability from a prior probability, given evidence. He reproduced and extended Bayes's results in 1774, apparently unaware of Bayes's work, and summarized his results in Théorie analytique des probabilités (1812). The Bayesian interpretation of probability was developed mainly by Laplace.\nAbout 200 years later, Sir Harold Jeffreys put Bayes's algorithm and Laplace's formulation on an axiomatic basis, writing in a 1973 book that Bayes' theorem \"is to the theory of probability what the Pythagorean theorem is to geometry\".\nStephen Stigler used a Bayesian argument to conclude that Bayes' theorem was discovered by Nicholas Saunderson, a blind English mathematician, some time before Bayes, but that is disputed. \nMartyn Hooper and Sharon McGrayne have argued that Richard Price's contribution was substantial:\n\nBy modern standards, we should refer to the Bayes–Price rule. Price discovered Bayes's work, recognized its importance, corrected it, contributed to the article, and found a use for it. The modern convention of employing Bayes's name alone is unfair but so entrenched that anything else makes little sense.\nF. Thomas Bruss reviewed Bayes's \"An essay towards solving a problem in the doctrine of chances\" as communicated by Price. He agrees with Stigler's analysis in many points, but not as far as the question of priority is concerned. Bruss underlines the intuitive part of Bayes's formula and adds independent arguments of Bayes's probable motivation for his work. He concludes that, unless the contrary is really proven, we are entitled to be faithful to the name \"Bayes' Theorem\" or \"Bayes' formula\".\n\nStatement of theorem\nBayes' theorem is stated mathematically as the following equation:\n\nwhere \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n and \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  \n are events and \n  \n    \n      \n        P\n        (\n        B\n        )\n        ≠\n        0\n      \n    \n    {\\displaystyle P(B)\\neq 0}\n  \n.\n\n  \n    \n      \n        P\n        (\n        A\n        |\n        B\n        )\n      \n    \n    {\\displaystyle P(A\\vert B)}\n  \n is a conditional probability: the probability of event \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n occurring given that \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  \n is true. It is also called the posterior probability of \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n given \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  \n.\n\n  \n    \n      \n        P\n        (\n        B\n        |\n        A\n        )\n      \n    \n    {",
    "links": [
      "An Essay Towards Solving a Problem in the Doctrine of Chances",
      "Andrey Kolmogorov",
      "Approximate Bayesian computation",
      "Axiomatic system",
      "Bayes estimator",
      "Bayes factor",
      "Bayesian epistemology",
      "Bayesian estimator",
      "Bayesian hierarchical modeling",
      "Bayesian inference",
      "Bayesian information criterion",
      "Bayesian linear regression",
      "Bayesian model averaging",
      "Bayesian network",
      "Bayesian persuasion",
      "Bayesian probability",
      "Bayesian statistics",
      "Beetle",
      "Benjamin Franklin",
      "Bernstein–von Mises theorem",
      "Binary variable",
      "Binomial distribution",
      "Boy or Girl paradox",
      "Brian Skyrms",
      "Cambridge University Press",
      "Chain rule (probability)",
      "Cheryl Misak",
      "Chromosome 7",
      "Coherence (philosophical gambling strategy)",
      "Conditional density",
      "Conditional expectation",
      "Conditional probability",
      "Conjugate prior",
      "Contingency table",
      "Cox's theorem",
      "Credible interval",
      "Cromwell's rule",
      "Cystic fibrosis",
      "Cystic fibrosis transmembrane conductance regulator",
      "Daphne Koller",
      "Doi (identifier)",
      "Domain of a function",
      "Dominance (genetics)",
      "Edward Arnold (publisher)",
      "Edward N. Zalta",
      "Empirical Bayes method",
      "Encyclopædia Britannica Eleventh Edition",
      "Entomology",
      "Event (probability theory)",
      "Evidence lower bound"
    ],
    "categories": [
      "Category:All articles with unsourced statements",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from April 2025",
      "Category:Articles with unsourced statements from August 2025",
      "Category:Bayesian statistics",
      "Category:Short description is different from Wikidata",
      "Category:Theorems in probability theory",
      "Category:Theorems in statistics",
      "Category:Wikipedia articles incorporating a citation from the 1911 Encyclopaedia Britannica with Wikisource reference",
      "Category:Wikipedia articles incorporating text from the 1911 Encyclopædia Britannica"
    ]
  },
  "Bayesian Statistics": {
    "title": "Bayesian statistics",
    "url": "https://en.wikipedia.org/wiki/Bayesian_statistics",
    "summary": "Bayesian statistics ( BAY-zee-ən or  BAY-zhən) is a theory in the field of statistics based on the Bayesian interpretation of probability, where probability expresses a degree of belief in an event. The degree of belief may be based on prior knowledge about the event, such as the results of previous experiments, or on personal beliefs about the event. This differs from a number of other interpretations of probability, such as the frequentist interpretation, which views probability as the limit of the relative frequency of an event after many trials. More concretely, analysis in Bayesian methods codifies prior knowledge in the form of a prior distribution.\nBayesian statistical methods use Bayes' theorem to compute and update probabilities after obtaining new data. Bayes' theorem describes the conditional probability of an event based on data as well as prior information or beliefs about the event or conditions related to the event. For example, in Bayesian inference, Bayes' theorem can ",
    "content": "Bayesian statistics ( BAY-zee-ən or  BAY-zhən) is a theory in the field of statistics based on the Bayesian interpretation of probability, where probability expresses a degree of belief in an event. The degree of belief may be based on prior knowledge about the event, such as the results of previous experiments, or on personal beliefs about the event. This differs from a number of other interpretations of probability, such as the frequentist interpretation, which views probability as the limit of the relative frequency of an event after many trials. More concretely, analysis in Bayesian methods codifies prior knowledge in the form of a prior distribution.\nBayesian statistical methods use Bayes' theorem to compute and update probabilities after obtaining new data. Bayes' theorem describes the conditional probability of an event based on data as well as prior information or beliefs about the event or conditions related to the event. For example, in Bayesian inference, Bayes' theorem can be used to estimate the parameters of a probability distribution or statistical model. Since Bayesian statistics treats probability as a degree of belief, Bayes' theorem can directly assign a probability distribution that quantifies the belief to the parameter or set of parameters.\nBayesian statistics is named after Thomas Bayes, who formulated a specific case of Bayes' theorem in a paper published in 1763. In several papers spanning from the late 18th to the early 19th centuries, Pierre-Simon Laplace developed the Bayesian interpretation of probability. Laplace used methods now considered Bayesian to solve a number of statistical problems. While many Bayesian methods were developed by later authors, the term \"Bayesian\" was not commonly used to describe these methods until the 1950s. Throughout much of the 20th century, Bayesian methods were viewed unfavorably by many statisticians due to philosophical and practical considerations. Many of these methods required much computation, and most widely used approaches during that time were based on the frequentist interpretation. However, with the advent of powerful computers and new algorithms like Markov chain Monte Carlo, Bayesian methods have gained increasing prominence in statistics in the 21st century.\n\nBayes's theorem\nBayes's theorem is used in Bayesian methods to update probabilities, which are degrees of belief, after obtaining new data. Given two events \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n and \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  \n, the conditional probability of \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n given that \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  \n is true is expressed as follows:\n\n  \n    \n      \n        P\n        (\n        A\n        ∣\n        B\n        )\n        =\n        \n          \n            \n              P\n              (\n              B\n              ∣\n              A\n              )\n              P\n              (\n              A\n              )\n            \n            \n              P\n              (\n              B\n              )\n            \n          \n        \n      \n    \n    {\\displaystyle P(A\\mid B)={\\frac {P(B\\mid A)P(A)}{P(B)}}}\n  \n\nwhere \n  \n    \n      \n        P\n        (\n        B\n        )\n        ≠\n        0\n      \n    \n    {\\displaystyle P(B)\\neq 0}\n  \n. Although Bayes's theorem is a fundamental result of probability theory, it has a specific interpretation in Bayesian statistics. In the above equation, \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n usually represents a proposition (such as the statement that a coin lands on heads fifty percent of the time) and \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  \n represents the evidence, or new data that is to be taken into account (such as the result of a series of coin flips). \n  \n    \n      \n        P\n        (\n        A\n        )\n      \n    \n    {\\displaystyle P(A)}\n  \n is the prior probability of \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n which expresses one's beliefs about \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n before evidence is taken into account. The prior probability may also quantify prior knowledge or information about \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n. \n  \n    \n      \n        P\n        (\n        B\n        ∣\n        A\n        )\n      \n    \n    {\\displaystyle P(B\\mid A)}\n  \n is the likelihood function, which can be interpreted as the probability of the evidence \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  \n given that \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n is true. The likelihood quantifies the extent to which the evidence \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  \n supports the proposition \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n. \n  \n    \n      \n        P\n        (\n        A\n        ∣\n        B\n   ",
    "links": [
      "Adrian Smith (statistician)",
      "Algorithm",
      "Allen B. Downey",
      "An Essay Towards Solving a Problem in the Doctrine of Chances",
      "Andrew Gelman",
      "Approximate Bayesian computation",
      "ArXiv (identifier)",
      "Bayes' theorem",
      "Bayes's theorem",
      "Bayes factor",
      "Bayesian design of experiments",
      "Bayesian epistemology",
      "Bayesian estimator",
      "Bayesian hierarchical modeling",
      "Bayesian inference",
      "Bayesian information criterion",
      "Bayesian linear regression",
      "Bayesian model averaging",
      "Bayesian networks",
      "Bayesian probability",
      "Bernoulli distribution",
      "Bernstein–von Mises theorem",
      "Bibcode (identifier)",
      "Christian Robert",
      "Coherence (philosophical gambling strategy)",
      "Conditional probability",
      "Conjugate prior",
      "Cox's theorem",
      "Credible interval",
      "Cromwell's rule",
      "David Spiegelhalter",
      "Doi (identifier)",
      "Donald Rubin",
      "Empirical Bayes method",
      "Event (probability theory)",
      "Evidence lower bound",
      "Exploratory data analysis",
      "Frequentist inference",
      "Frequentist probability",
      "Hdl (identifier)",
      "ISBN (identifier)",
      "Integral",
      "Integrated nested Laplace approximations",
      "John Carlin (professor)",
      "John K. Kruschke",
      "José-Miguel Bernardo",
      "Laplace's approximation",
      "Law of large numbers",
      "Law of total probability",
      "Likelihood function"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Bayesian statistics",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Algebra of physical space": {
    "title": "Algebra of physical space",
    "url": "https://en.wikipedia.org/wiki/Algebra_of_physical_space",
    "summary": "In physics, the algebra of physical space (APS) is the use of the Clifford or geometric algebra Cl3,0(R) of the three-dimensional Euclidean space as a model for (3+1)-dimensional spacetime, representing a point in spacetime via a paravector (3-dimensional vector plus a 1-dimensional scalar).\nThe Clifford algebra Cl3,0(R) has a faithful representation, generated by Pauli matrices, on the spin representation C2; further, Cl3,0(R) is isomorphic to the even subalgebra Cl[0]3,1(R) of the Clifford algebra Cl3,1(R).\nAPS can be used to construct a compact, unified and geometrical formalism for both classical and quantum mechanics.\nAPS should not be confused with spacetime algebra (STA), which concerns the Clifford algebra Cl1,3(R) of the four-dimensional Minkowski spacetime.",
    "content": "In physics, the algebra of physical space (APS) is the use of the Clifford or geometric algebra Cl3,0(R) of the three-dimensional Euclidean space as a model for (3+1)-dimensional spacetime, representing a point in spacetime via a paravector (3-dimensional vector plus a 1-dimensional scalar).\nThe Clifford algebra Cl3,0(R) has a faithful representation, generated by Pauli matrices, on the spin representation C2; further, Cl3,0(R) is isomorphic to the even subalgebra Cl[0]3,1(R) of the Clifford algebra Cl3,1(R).\nAPS can be used to construct a compact, unified and geometrical formalism for both classical and quantum mechanics.\nAPS should not be confused with spacetime algebra (STA), which concerns the Clifford algebra Cl1,3(R) of the four-dimensional Minkowski spacetime.\n\nSpecial relativity\nSpacetime position paravector\nIn APS, the spacetime position is represented as the paravector\n\n  \n    \n      \n        x\n        =\n        \n          x\n          \n            0\n          \n        \n        +\n        \n          x\n          \n            1\n          \n        \n        \n          \n            e\n          \n          \n            1\n          \n        \n        +\n        \n          x\n          \n            2\n          \n        \n        \n          \n            e\n          \n          \n            2\n          \n        \n        +\n        \n          x\n          \n            3\n          \n        \n        \n          \n            e\n          \n          \n            3\n          \n        \n        ,\n      \n    \n    {\\displaystyle x=x^{0}+x^{1}\\mathbf {e} _{1}+x^{2}\\mathbf {e} _{2}+x^{3}\\mathbf {e} _{3},}\n  \n\nwhere the time is given by the scalar part x0 = t, and e1, e2, e3 is a basis for position space. Throughout, units such that c = 1 are used, called natural units. In the Pauli matrix representation, the unit basis vectors are replaced by the Pauli matrices and the scalar part by the identity matrix. This means that the Pauli matrix representation of the space-time position is\n\n  \n    \n      \n        x\n        →\n        \n          \n            (\n            \n              \n                \n                  \n                    x\n                    \n                      0\n                    \n                  \n                  +\n                  \n                    x\n                    \n                      3\n                    \n                  \n                \n                \n                \n                  \n                    x\n                    \n                      1\n                    \n                  \n                  −\n                  i\n                  \n                    x\n                    \n                      2\n                    \n                  \n                \n              \n              \n                \n                  \n                    x\n                    \n                      1\n                    \n                  \n                  +\n                  i\n                  \n                    x\n                    \n                      2\n                    \n                  \n                \n                \n                \n                  \n                    x\n                    \n                      0\n                    \n                  \n                  −\n                  \n                    x\n                    \n                      3\n                    \n                  \n                \n              \n            \n            )\n          \n        \n      \n    \n    {\\displaystyle x\\rightarrow {\\begin{pmatrix}x^{0}+x^{3}&&x^{1}-ix^{2}\\\\x^{1}+ix^{2}&&x^{0}-x^{3}\\end{pmatrix}}}\n\nLorentz transformations and rotors\nThe restricted Lorentz transformations that preserve the direction of time and include rotations and boosts can be performed by an exponentiation of the spacetime rotation biparavector W \n\n  \n    \n      \n        L\n        =\n        \n          e\n          \n            W\n            \n              /\n            \n            2\n          \n        \n        .\n      \n    \n    {\\displaystyle L=e^{W/2}.}\n  \n\nIn the matrix representation, the Lorentz rotor is seen to form an instance of the SL(2, C) group (special linear group of degree 2 over the complex numbers), which is the double cover of the Lorentz group.  The unimodularity of the Lorentz rotor is translated in the following condition in terms of the product of the Lorentz rotor with its Clifford conjugation\n\n  \n    \n      \n        L\n        \n          \n            \n              L\n              ¯\n            \n          \n        \n        =\n        \n          \n            \n              L\n              ¯\n            \n          \n        \n        L\n        =\n        1.\n      \n    \n    {\\displaystyle L{\\bar {L}}={\\bar {L}}L=1.}\n  \n\nThis Lorentz rotor can be always decomposed in two factors, one Hermitian B = B†, and the other unitary R† = R−1, such that\n\n  \n    \n      \n        L\n        =\n        B\n        R\n        .\n      \n    \n    {\\displaystyle L=BR.}\n  \n\nThe unitary element R is called ",
    "links": [
      "Algebra",
      "Algebraic number",
      "Algebraic structure",
      "Algorithm",
      "Algorithm design",
      "Analysis of algorithms",
      "Analytical mechanics",
      "Applied mathematics",
      "Approximation theory",
      "ArXiv (identifier)",
      "Automata theory",
      "Automated theorem proving",
      "Basis (linear algebra)",
      "Bibcode (identifier)",
      "Bicomplex number",
      "Bioctonion",
      "Biquaternion",
      "Bosonic string theory",
      "Calculus of variations",
      "Cardinal number",
      "Chaos theory",
      "Charged particle",
      "Classical electrodynamics",
      "Classical field theory",
      "Clifford algebra",
      "Clifford analysis",
      "Closed-form expression",
      "Coding theory",
      "Combinatorics",
      "Complex number",
      "Composition algebra",
      "Computable number",
      "Computational geometry",
      "Computational mathematics",
      "Computational number theory",
      "Computational statistics",
      "Computer algebra",
      "Conformal field theory",
      "Constraint programming",
      "Constraint satisfaction problem",
      "Constructible number",
      "Control theory",
      "Cryptography",
      "David Hestenes",
      "Decision theory",
      "Definable number",
      "Definable real number",
      "Derivative",
      "Differential equation",
      "Differential form"
    ],
    "categories": [
      "Category:All articles lacking in-text citations",
      "Category:Articles lacking in-text citations from March 2021",
      "Category:Clifford algebras",
      "Category:Electromagnetism",
      "Category:Geometric algebra",
      "Category:Mathematical physics",
      "Category:Special relativity"
    ]
  },
  "Automated theorem proving": {
    "title": "Automated theorem proving",
    "url": "https://en.wikipedia.org/wiki/Automated_theorem_proving",
    "summary": "Automated theorem proving (also known as ATP or automated deduction) is a subfield of automated reasoning and mathematical logic dealing with proving mathematical theorems by computer programs. Automated reasoning over mathematical proof was a major motivating factor for the development of computer science.",
    "content": "Automated theorem proving (also known as ATP or automated deduction) is a subfield of automated reasoning and mathematical logic dealing with proving mathematical theorems by computer programs. Automated reasoning over mathematical proof was a major motivating factor for the development of computer science.\n\nLogical foundations\nWhile the roots of formalized logic go back to Aristotle, the end of the 19th and early 20th centuries saw the development of modern logic and formalized mathematics. Frege's Begriffsschrift (1879) introduced both a complete propositional calculus and what is essentially modern predicate logic. His Foundations of Arithmetic, published in 1884, expressed (parts of) mathematics in formal logic. This approach was continued by Russell and Whitehead in their influential Principia Mathematica, first published 1910–1913, and with a revised second edition in 1927. Russell and Whitehead thought they could derive all mathematical truth using axioms and inference rules of formal logic, in principle opening up the process to automation. In 1920, Thoralf Skolem simplified a previous result by Leopold Löwenheim, leading to the Löwenheim–Skolem theorem and, in 1930, to the notion of a Herbrand universe and a Herbrand interpretation that allowed (un)satisfiability of first-order formulas (and hence the validity of a theorem) to be reduced to (potentially infinitely many) propositional satisfiability problems.\nIn 1929, Mojżesz Presburger showed that the first-order theory of the natural numbers with addition and equality (now called Presburger arithmetic in his honor) is decidable and gave an algorithm that could determine if a given sentence in the language was true or false.\nHowever, shortly after this positive result, Kurt Gödel published On Formally Undecidable Propositions of Principia Mathematica and Related Systems (1931), showing that in any sufficiently strong axiomatic system, there are true statements that cannot be proved in the system. This topic was further developed in the 1930s by Alonzo Church and Alan Turing, who on the one hand gave two independent but equivalent definitions of computability, and on the other gave concrete examples of undecidable questions.\n\nFirst implementations\nIn 1954, Martin Davis programmed Presburger's algorithm for a JOHNNIAC vacuum-tube computer at the Institute for Advanced Study in Princeton, New Jersey. According to Davis, \"Its great triumph was to prove that the sum of two even numbers is even\". More ambitious was the Logic Theorist in 1956, a deduction system for the propositional logic of the Principia Mathematica, developed by Allen Newell, Herbert A. Simon and J. C. Shaw. Also running on a JOHNNIAC, the Logic Theorist constructed proofs from a small set of propositional axioms and three deduction rules: modus ponens, (propositional) variable substitution, and the replacement of formulas by their definition. The system used heuristic guidance, and managed to prove 38 of the first 52 theorems of the Principia.\nThe \"heuristic\" approach of the Logic Theorist tried to emulate human mathematicians, and could not guarantee that a proof could be found for every valid theorem even in principle. In contrast, other, more systematic algorithms achieved, at least theoretically, completeness for first-order logic. Initial approaches relied on the results of Herbrand and Skolem to convert a first-order formula into successively larger sets of propositional formulae by instantiating variables with terms from the Herbrand universe. The propositional formulas could then be checked for unsatisfiability using a number of methods. Gilmore's program used conversion to disjunctive normal form, a form in which the satisfiability of a formula is obvious.\n\nDecidability of the problem\nDepending on the underlying logic, the problem of deciding the validity of a formula varies from trivial to impossible. For the common case of propositional logic, the problem is decidable but co-NP-complete, and hence only exponential-time algorithms are believed to exist for general proof tasks. For a first-order predicate calculus, Gödel's completeness theorem states that the theorems (provable statements) are exactly the semantically valid well-formed formulas, so the valid formulas are computably enumerable: given unbounded resources, any valid formula can eventually be proven. However, invalid formulas (those that are not entailed by a given theory), cannot always be recognized.\nThe above applies to first-order theories, such as Peano arithmetic. However, for a specific model that may be described by a first-order theory, some statements may be true but undecidable in the theory used to describe the model. For example, by Gödel's incompleteness theorem, we know that any consistent theory whose axioms are true for the natural numbers cannot prove all first-order statements true for the natural numbers, even if the list of axioms is allowed to be infinite enumerable. It follows that an autom",
    "links": [
      "ACL2",
      "ACM Transactions on Programming Languages and Systems",
      "AMD",
      "Abstract logic",
      "Ackermann set theory",
      "Ada (programming language)",
      "Alan Turing",
      "Aleph number",
      "Alfred North Whitehead",
      "Algebraic logic",
      "Allen Newell",
      "Alonzo Church",
      "Alphabet (formal languages)",
      "Alt-Ergo",
      "Andrei Voronkov",
      "Andrei Voronkov (scientist)",
      "Argonne National Laboratory",
      "Argument",
      "Aristotelian logic",
      "Arity",
      "Atomic formula",
      "Atomic sentence",
      "Automata theory",
      "Automated reasoning",
      "Automath",
      "Axiom",
      "Axiom of choice",
      "Axiom schema",
      "Axiomatic system",
      "Axiomatization of Boolean algebras",
      "BSD Licenses",
      "Baden-Württemberg Cooperative State University",
      "Banach–Tarski paradox",
      "Begriffsschrift",
      "Benchmark (computing)",
      "Bertrand Russell",
      "Bijection",
      "Binary decision diagram",
      "Binary operation",
      "Boolean algebra",
      "Boolean algebras canonically defined",
      "Boolean function",
      "CADE ATP System Competition",
      "CARINE",
      "CVC (theorem prover)",
      "Cantor's diagonal argument",
      "Cantor's paradox",
      "Cantor's theorem",
      "Cardinality",
      "Cartesian product"
    ],
    "categories": [
      "Category:All articles needing additional references",
      "Category:All articles with unsourced statements",
      "Category:All pages needing cleanup",
      "Category:Articles needing additional references from April 2010",
      "Category:Articles needing cleanup from December 2023",
      "Category:Articles with sections that need to be turned into prose from December 2023",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from December 2023",
      "Category:Articles with unsourced statements from September 2020",
      "Category:Automated theorem proving"
    ]
  },
  "Axioms of probability": {
    "title": "Probability axioms",
    "url": "https://en.wikipedia.org/wiki/Probability_axioms",
    "summary": "The standard probability axioms are the foundations of probability theory introduced by Russian mathematician Andrey Kolmogorov in 1933. These axioms remain central and have direct contributions to mathematics, the physical sciences, and real-world probability cases.\nThere are several other (equivalent) approaches to formalising probability. Bayesians will often motivate the Kolmogorov axioms by invoking Cox's theorem or the Dutch book arguments instead.",
    "content": "The standard probability axioms are the foundations of probability theory introduced by Russian mathematician Andrey Kolmogorov in 1933. These axioms remain central and have direct contributions to mathematics, the physical sciences, and real-world probability cases.\nThere are several other (equivalent) approaches to formalising probability. Bayesians will often motivate the Kolmogorov axioms by invoking Cox's theorem or the Dutch book arguments instead.\n\nKolmogorov axioms\nThe assumptions as to setting up the axioms can be summarised as follows: Let \n  \n    \n      \n        (\n        Ω\n        ,\n        F\n        ,\n        P\n        )\n      \n    \n    {\\displaystyle (\\Omega ,F,P)}\n  \n be a measure space such that \n  \n    \n      \n        P\n        (\n        E\n        )\n      \n    \n    {\\displaystyle P(E)}\n  \n is the probability of some event \n  \n    \n      \n        E\n      \n    \n    {\\displaystyle E}\n  \n, and \n  \n    \n      \n        P\n        (\n        Ω\n        )\n        =\n        1\n      \n    \n    {\\displaystyle P(\\Omega )=1}\n  \n. Then \n  \n    \n      \n        (\n        Ω\n        ,\n        F\n        ,\n        P\n        )\n      \n    \n    {\\displaystyle (\\Omega ,F,P)}\n  \n is a probability space, with sample space \n  \n    \n      \n        Ω\n      \n    \n    {\\displaystyle \\Omega }\n  \n, event space \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n and probability measure \n  \n    \n      \n        P\n      \n    \n    {\\displaystyle P}\n  \n.\n\nFirst axiom\nThe probability of an event is a non-negative real number:\n\n  \n    \n      \n        P\n        (\n        E\n        )\n        ∈\n        \n          R\n        \n        ,\n        P\n        (\n        E\n        )\n        ≥\n        0\n        \n        ∀\n        E\n        ∈\n        F\n      \n    \n    {\\displaystyle P(E)\\in \\mathbb {R} ,P(E)\\geq 0\\qquad \\forall E\\in F}\n  \n\nwhere \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n is the event space. It follows (when combined with the second axiom) that \n  \n    \n      \n        P\n        (\n        E\n        )\n      \n    \n    {\\displaystyle P(E)}\n  \n is always finite, in contrast with more general measure theory. Theories which assign negative probability relax the first axiom.\n\nSecond axiom\nThis is the assumption of unit measure: that the probability that at least one of the elementary events in the entire sample space will occur is 1.\n\n  \n    \n      \n        P\n        (\n        Ω\n        )\n        =\n        1\n      \n    \n    {\\displaystyle P(\\Omega )=1}\n\nThird axiom\nThis is the assumption of σ-additivity:\n\nAny countable sequence of disjoint sets (synonymous with mutually exclusive events) \n  \n    \n      \n        \n          E\n          \n            1\n          \n        \n        ,\n        \n          E\n          \n            2\n          \n        \n        ,\n        …\n      \n    \n    {\\displaystyle E_{1},E_{2},\\ldots }\n  \n satisfies\n\n  \n    \n      \n        P\n        \n          (\n          \n            \n              ⋃\n              \n                i\n                =\n                1\n              \n              \n                ∞\n              \n            \n            \n              E\n              \n                i\n              \n            \n          \n          )\n        \n        =\n        \n          ∑\n          \n            i\n            =\n            1\n          \n          \n            ∞\n          \n        \n        P\n        (\n        \n          E\n          \n            i\n          \n        \n        )\n        .\n      \n    \n    {\\displaystyle P\\left(\\bigcup _{i=1}^{\\infty }E_{i}\\right)=\\sum _{i=1}^{\\infty }P(E_{i}).}\n  \n\nSome authors consider merely finitely additive probability spaces, in which case one just needs an algebra of sets, rather than a σ-algebra. Quasiprobability distributions in general relax the third axiom.\n\nConsequences\nFrom the Kolmogorov axioms, one can deduce other useful rules for studying probabilities. The proofs of these rules are a very insightful procedure that illustrates the power of the third axiom, and its interaction with the prior two axioms. Four of the immediate corollaries and their proofs are shown below:\n\nMonotonicity\nif\n        \n        \n        A\n        ⊆\n        B\n        \n        \n          then\n        \n        \n        P\n        (\n        A\n        )\n        ≤\n        P\n        (\n        B\n        )\n        .\n      \n    \n    {\\displaystyle \\quad {\\text{if}}\\quad A\\subseteq B\\quad {\\text{then}}\\quad P(A)\\leq P(B).}\n  \n\nIf A is a subset of, or equal to B, then the probability of A is less than, or equal to the probability of B.\n\nProof of monotonicity\nSource:\nIn order to verify the monotonicity property, we set \n  \n    \n      \n        \n          E\n          \n            1\n          \n        \n        =\n        A\n      \n    \n    {\\displaystyle E_{1}=A}\n  \n and \n  \n    \n      \n        \n          E\n          \n            2\n          \n        \n        =\n        B\n        ∖\n        A\n      \n    \n    {\\displaystyle E_{2}=B\\setminus A}\n  \n, where \n  \n    \n      \n        A\n ",
    "links": [
      "Andrey Kolmogorov",
      "Axiom",
      "Bayes' theorem",
      "Bayesian theory",
      "Bernoulli distribution",
      "Bernoulli process",
      "Bernoulli trial",
      "Bibcode (identifier)",
      "Binomial distribution",
      "Boole's inequality",
      "Borel algebra",
      "Collectively exhaustive events",
      "Complement (set theory)",
      "Complementary event",
      "Conditional independence",
      "Conditional probability",
      "Continuous or discrete variable",
      "Countable",
      "Cox's theorem",
      "Determinism",
      "Deterministic system",
      "Disjoint sets",
      "Doi (identifier)",
      "Dutch book argument",
      "Elementary event",
      "Empty set",
      "Event (probability theory)",
      "Expected value",
      "Experiment (probability theory)",
      "Exponential distribution",
      "Field of sets",
      "Finitely additive",
      "Fully probabilistic design",
      "ISBN (identifier)",
      "Inclusion–exclusion principle",
      "Independence (probability theory)",
      "Indeterminism",
      "Intuitive statistics",
      "Joint probability distribution",
      "Law of large numbers",
      "Law of total probability",
      "Marginal distribution",
      "Markov chain",
      "Measure (mathematics)",
      "Measure space",
      "Mizar system",
      "Morris H. DeGroot",
      "Mutual exclusivity",
      "Negative probability",
      "Normal distribution"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1 maint: location missing publisher",
      "Category:Mathematical axioms",
      "Category:Pages displaying short descriptions of redirect targets via Module:Annotated link",
      "Category:Probability theory",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Berry–Esseen theorem": {
    "title": "Berry–Esseen theorem",
    "url": "https://en.wikipedia.org/wiki/Berry%E2%80%93Esseen_theorem",
    "summary": "In probability theory, the central limit theorem states that, under certain circumstances, the probability distribution of the scaled mean of a random sample converges to a normal distribution as the sample size increases to infinity. Under stronger assumptions, the Berry–Esseen theorem, or Berry–Esseen inequality, gives a more quantitative result, because it also specifies the rate at which this convergence takes place by giving a bound on the maximal error of approximation between the normal distribution and the true distribution of the scaled sample mean. The approximation is measured by the Kolmogorov–Smirnov distance. In the case of independent samples, the convergence rate is n−1/2, where n is the sample size, and the constant is estimated in terms of the third absolute normalized moment. It is also possible to give non-uniform bounds which become more strict for more extreme events.",
    "content": "In probability theory, the central limit theorem states that, under certain circumstances, the probability distribution of the scaled mean of a random sample converges to a normal distribution as the sample size increases to infinity. Under stronger assumptions, the Berry–Esseen theorem, or Berry–Esseen inequality, gives a more quantitative result, because it also specifies the rate at which this convergence takes place by giving a bound on the maximal error of approximation between the normal distribution and the true distribution of the scaled sample mean. The approximation is measured by the Kolmogorov–Smirnov distance. In the case of independent samples, the convergence rate is n−1/2, where n is the sample size, and the constant is estimated in terms of the third absolute normalized moment. It is also possible to give non-uniform bounds which become more strict for more extreme events.\n\nStatement of the theorem\nStatements of the theorem vary, as it was independently discovered by two mathematicians, Andrew C. Berry (in 1941) and Carl-Gustav Esseen (1942), who then, along with other authors, refined it repeatedly over subsequent decades.\n\nIdentically distributed summands\nOne version, sacrificing generality somewhat for the sake of clarity, is the following:\n\nThere exists a positive constant C such that if X1, X2, ..., are i.i.d. random variables with E(X1) = 0, E(X12) = σ2 > 0, and E(|X1|3) = ρ < ∞, and if we define\n\n  \n    \n      \n        \n          Y\n          \n            n\n          \n        \n        =\n        \n          \n            \n              \n                X\n                \n                  1\n                \n              \n              +\n              \n                X\n                \n                  2\n                \n              \n              +\n              ⋯\n              +\n              \n                X\n                \n                  n\n                \n              \n            \n            n\n          \n        \n      \n    \n    {\\displaystyle Y_{n}={X_{1}+X_{2}+\\cdots +X_{n} \\over n}}\n  \n\nthe sample mean, with Fn the cumulative distribution function of\n\n  \n    \n      \n        \n          \n            \n              \n                Y\n                \n                  n\n                \n              \n              \n                \n                  n\n                \n              \n            \n            \n              σ\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle {Y_{n}{\\sqrt {n}} \\over {\\sigma }},}\n  \n\nand Φ the cumulative distribution function of the standard normal distribution, then for all x and n,\n\n  \n    \n      \n        \n          |\n          \n            \n              F\n              \n                n\n              \n            \n            (\n            x\n            )\n            −\n            Φ\n            (\n            x\n            )\n          \n          |\n        \n        ≤\n        \n          \n            \n              C\n              ρ\n            \n            \n              \n                σ\n                \n                  3\n                \n              \n              \n                \n                  n\n                \n              \n            \n          \n        \n        .\n         \n         \n         \n         \n        (\n        1\n        )\n      \n    \n    {\\displaystyle \\left|F_{n}(x)-\\Phi (x)\\right|\\leq {C\\rho  \\over \\sigma ^{3}{\\sqrt {n}}}.\\ \\ \\ \\ (1)}\n  \n\nThat is: given a sequence of independent and identically distributed random variables, each having mean zero and positive variance, if additionally the third absolute moment is finite, then the cumulative distribution functions of the standardized sample mean and the standard normal distribution differ (vertically, on a graph) by no more than the specified amount.  Note that the approximation error for all n (and hence the limiting rate of convergence for indefinite n sufficiently large) is bounded by  the order of n−1/2.\nCalculated upper bounds on the constant C have decreased markedly over the years, from the original value of 7.59 by Esseen in 1942. The estimate C < 0.4748 follows from the inequality\n\n  \n    \n      \n        \n          sup\n          \n            x\n            ∈\n            \n              R\n            \n          \n        \n        \n          |\n          \n            \n              F\n              \n                n\n              \n            \n            (\n            x\n            )\n            −\n            Φ\n            (\n            x\n            )\n          \n          |\n        \n        ≤\n        \n          \n            \n              0.33554\n              (\n              ρ\n              +\n              0.415\n              \n                σ\n                \n                  3\n                \n              \n              )\n            \n            \n              \n                σ\n                \n                  3\n                \n              \n              \n                \n                  n\n                \n        ",
    "links": [
      "Andrew C. Berry",
      "Approximation error",
      "Approximation theory",
      "ArXiv (identifier)",
      "Big O notation",
      "Carl-Gustav Esseen",
      "Central limit theorem",
      "Chernoff's inequality",
      "Concentration inequality",
      "Constant (mathematics)",
      "Convergence in distribution",
      "Covariance matrix",
      "Cumulative distribution function",
      "Doi (identifier)",
      "Edgeworth series",
      "Encyclopedia of Mathematics",
      "European Mathematical Society",
      "Expected value",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "Independence (probability theory)",
      "Independent and identically distributed random variables",
      "Irina Shevtsova",
      "JSTOR (identifier)",
      "Kolmogorov–Smirnov test",
      "L2 norm",
      "List of inequalities",
      "List of mathematical theorems",
      "Mathematician",
      "Mean",
      "Moment (mathematics)",
      "Normal distribution",
      "Probability distribution",
      "Probability theory",
      "Rate of convergence",
      "S2CID (identifier)",
      "Sample mean",
      "Skewness",
      "Standard normal distribution",
      "Standard score",
      "Variance",
      "Template:Cite book",
      "Category:CS1 maint: location missing publisher"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1 German-language sources (de)",
      "Category:CS1 maint: location missing publisher",
      "Category:Central limit theorem",
      "Category:Probabilistic inequalities",
      "Category:Short description is different from Wikidata",
      "Category:Theorems in statistics"
    ]
  },
  "Bertrand's paradox (probability)": {
    "title": "Bertrand paradox (probability)",
    "url": "https://en.wikipedia.org/wiki/Bertrand_paradox_(probability)",
    "summary": "The Bertrand paradox is a problem within the classical interpretation of probability theory. Joseph Bertrand introduced it in his work Calcul des probabilités (1889) as an example to show that the principle of indifference may not produce definite, well-defined results for probabilities if it is applied uncritically when the domain of possibilities is infinite.",
    "content": "The Bertrand paradox is a problem within the classical interpretation of probability theory. Joseph Bertrand introduced it in his work Calcul des probabilités (1889) as an example to show that the principle of indifference may not produce definite, well-defined results for probabilities if it is applied uncritically when the domain of possibilities is infinite.\n\nBertrand's formulation of the problem\nThe Bertrand paradox is generally presented as follows: Consider an equilateral triangle that is inscribed in a circle. Suppose a chord of the circle is chosen at random. What is the probability that the chord is longer than a side of the triangle?\nBertrand gave three arguments (each using the principle of indifference), all apparently valid yet yielding different results:\n\n The \"random endpoints\" method: Choose two random points on the circumference of the circle and draw the chord joining them. To calculate the probability in question imagine the triangle rotated so its vertex coincides with one of the chord endpoints. Observe that only if the other chord endpoint lies on the arc between the endpoints of the triangle side opposite the first point, the chord is longer than a side of the triangle. The length of that arc is one third of the circumference of the circle, therefore the probability that a random chord is longer than a side of the inscribed triangle is ⁠1/3⁠.\n The \"random radial point\" method: Choose a radius of the circle, choose a point on the radius and construct the chord through this point and perpendicular to the radius. To calculate the probability in question imagine the triangle rotated so a side is perpendicular to the radius. The chord is longer than a side of the triangle if the chosen point is nearer the center of the circle than the point where the side of the triangle intersects the radius. The side of the triangle bisects the radius, therefore the probability a random chord is longer than a side of the inscribed triangle is ⁠1/2⁠.\n The \"random midpoint\" method: Choose a point anywhere within the circle and construct a chord with the chosen point as its midpoint. The chord is longer than a side of the inscribed triangle if the chosen point falls within a concentric circle of radius ⁠1/2⁠ the radius of the larger circle. The area of the smaller circle is one fourth the area of the larger circle, therefore the probability a random chord is longer than a side of the inscribed triangle is ⁠1/4⁠. \nThese three selection methods differ as to the weight they give to chords which are diameters. This issue can be avoided by \"regularizing\" the problem so as to exclude diameters, without affecting the resulting probabilities. But as presented above, in method 1, each chord can be chosen in exactly one way, regardless of whether or not it is a diameter; in method 2, each diameter can be chosen in two ways, whereas each other chord can be chosen in only one way; and in method 3, each choice of midpoint corresponds to a single chord, except the center of the circle, which is the midpoint of all the diameters.\n\nOther selection methods have been found. In fact, there exists an infinite family of them.\n\nClassical solution\nThe problem's classical solution (presented, for example, in Bertrand's own work) depends on the method by which a chord is chosen \"at random\". The argument is that if the method of random selection is specified, the problem will have a well-defined solution (determined by the principle of indifference). The three solutions presented by Bertrand correspond to different selection methods, and in the absence of further information there is no reason to prefer one over another; accordingly, the problem as stated has no unique solution.\n\nJaynes's solution using the \"maximum ignorance\" principle\nIn his 1973 paper \"The Well-Posed Problem\", Edwin Jaynes proposed a solution to Bertrand's paradox based on the principle of \"maximum ignorance\"—that we should not use any information that is not given in the statement of the problem. Jaynes pointed out that Bertrand's problem does not specify the position or size of the circle and argued that therefore any definite and objective solution must be \"indifferent\" to size and position. In other words: the solution must be both scale and translation invariant.\nTo illustrate: assume that chords are laid at random onto a circle with a diameter of 2, say by throwing straws onto it from far away and converting them to chords by extension/restriction. Now another circle with a smaller diameter (e.g., 1.1) is laid into the larger circle. Then the distribution of the chords on that smaller circle needs to be the same as the restricted distribution of chords on the larger circle (again using extension/restriction of the generating straws). Thus, if the smaller circle is moved around within the larger circle, the restricted distribution should not change. It can be seen very easily that there would be a change for method 3: the chord distribution on the small red ",
    "links": [
      "3Blue1Brown",
      "American Scientist",
      "ArXiv (identifier)",
      "Bertrand's paradox (disambiguation)",
      "Bibcode (identifier)",
      "British Journal for the Philosophy of Science",
      "Chord (geometry)",
      "Classical interpretation",
      "Diameter",
      "Doi (identifier)",
      "Edwin Jaynes",
      "Equilateral triangle",
      "Eric W. Weisstein",
      "Foundations of Physics",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "Inscribed figure",
      "Invariant (mathematics)",
      "JSTOR (identifier)",
      "Joseph Bertrand",
      "Joseph Louis François Bertrand",
      "Mark Kac",
      "Martin Gardner",
      "MathWorld",
      "Numberphile",
      "Perpendicular",
      "Philosophy of Science (journal)",
      "Possibility space",
      "Principle of indifference",
      "Probability distribution",
      "Probability theory",
      "Routledge",
      "S2CID (identifier)",
      "Scaling (geometry)",
      "The Mathematical Gazette",
      "Translation (geometry)",
      "University of Chicago Press"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Eponymous paradoxes",
      "Category:Mathematical paradoxes",
      "Category:Probability theory paradoxes",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Borel algebra": {
    "title": "Borel set",
    "url": "https://en.wikipedia.org/wiki/Borel_set",
    "summary": "In mathematics, the Borel sets included in a topological space are a particular class of \"well-behaved\" subsets of that space.  For example, whereas an arbitrary subset of the real numbers might fail to be Lebesgue measurable, every Borel set of reals is universally measurable.  Which sets are Borel can be specified in a number of equivalent ways.  Borel sets are named after Émile Borel.\nThe most usual definition goes through the notion of a σ-algebra, which is a collection of subsets of a topological space \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n that contains both the empty set and the entire set \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n, and is closed under countable union and countable intersection.\nThen we can define the Borel σ-algebra over \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n to be the smallest σ-algebra containing all open sets of \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n.  A Borel sub",
    "content": "In mathematics, the Borel sets included in a topological space are a particular class of \"well-behaved\" subsets of that space.  For example, whereas an arbitrary subset of the real numbers might fail to be Lebesgue measurable, every Borel set of reals is universally measurable.  Which sets are Borel can be specified in a number of equivalent ways.  Borel sets are named after Émile Borel.\nThe most usual definition goes through the notion of a σ-algebra, which is a collection of subsets of a topological space \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n that contains both the empty set and the entire set \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n, and is closed under countable union and countable intersection.\nThen we can define the Borel σ-algebra over \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n to be the smallest σ-algebra containing all open sets of \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n.  A Borel subset of \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is then simply an element of this σ-algebra.\nBorel sets are important in measure theory, since any measure defined on the open sets of a space, or on the closed sets of a space, must also be defined on all Borel sets of that space. Any measure defined on the Borel sets is called a Borel measure.  Borel sets and the associated Borel hierarchy also play a fundamental role in descriptive set theory.\nIn some contexts, Borel sets are defined to be generated by the compact sets of the topological space, rather than the open sets. The two definitions are equivalent for many well-behaved spaces, including all Hausdorff σ-compact spaces, but can be different in more pathological spaces.\n\nGenerating the Borel algebra\nIn the case that \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is a metric space, the Borel algebra in the first sense may be described generatively as follows.\nFor a collection \n  \n    \n      \n        T\n      \n    \n    {\\displaystyle T}\n  \n of subsets of \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n (that is, for any subset of the power set \n  \n    \n      \n        \n          \n            P\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {P}}}\n  \n\n  \n    \n      \n        (\n        X\n        )\n      \n    \n    {\\displaystyle (X)}\n  \n of \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n), let\n\n  \n    \n      \n        \n          T\n          \n            σ\n          \n        \n      \n    \n    {\\displaystyle T_{\\sigma }}\n  \n be all countable unions of elements of \n  \n    \n      \n        T\n      \n    \n    {\\displaystyle T}\n  \n\n  \n    \n      \n        \n          T\n          \n            δ\n          \n        \n      \n    \n    {\\displaystyle T_{\\delta }}\n  \n be all countable intersections of elements of \n  \n    \n      \n        T\n      \n    \n    {\\displaystyle T}\n  \n\n  \n    \n      \n        \n          T\n          \n            δ\n            σ\n          \n        \n        =\n        (\n        \n          T\n          \n            δ\n          \n        \n        \n          )\n          \n            σ\n          \n        \n        .\n      \n    \n    {\\displaystyle T_{\\delta \\sigma }=(T_{\\delta })_{\\sigma }.}\n  \n\nNow define by transfinite induction a sequence \n  \n    \n      \n        \n          G\n          \n            m\n          \n        \n      \n    \n    {\\displaystyle G^{m}}\n  \n, where \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n  \n is an ordinal number, in the following manner:\n\nFor the base case of the definition, let \n  \n    \n      \n        \n          G\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle G^{0}}\n  \n be the collection of open subsets of \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n.\nIf \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n is not a limit ordinal, then \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n has an immediately preceding ordinal \n  \n    \n      \n        i\n        −\n        1\n      \n    \n    {\\displaystyle i-1}\n  \n. Let \n  \n    \n      \n        \n          G\n          \n            i\n          \n        \n        =\n        [\n        \n          G\n          \n            i\n            −\n            1\n          \n        \n        \n          ]\n          \n            δ\n            σ\n          \n        \n        .\n      \n    \n    {\\displaystyle G^{i}=[G^{i-1}]_{\\delta \\sigma }.}\n  \n\nIf \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n is a limit ordinal, set \n  \n    \n      \n        \n          G\n          \n            i\n          \n        \n        =\n        \n          ⋃\n          \n            j\n            <\n            i\n          \n        \n        \n          G\n          \n            j\n          \n        \n        .\n      \n    \n    {\\displaystyle G^{i}=\\bigcup _{j<i}G^{j}.}\n  \n\nThe claim is that the Borel algebra is \n  \n    \n      \n        \n          G\n          \n            \n              ω\n           ",
    "links": [
      "Absolute continuity",
      "Absolute continuity (measure theory)",
      "Alexander S. Kechris",
      "Almost everywhere",
      "Analytic set",
      "Analytical hierarchy",
      "Arithmetical set",
      "Atom (measure theory)",
      "Atomic measure",
      "Axiom of choice",
      "Baire measure",
      "Baire set",
      "Banach measure",
      "Besov measure",
      "Bochner measurable function",
      "Boldface hierarchy",
      "Borel equivalence relation",
      "Borel hierarchy",
      "Borel isomorphism",
      "Borel measure",
      "Borel regular measure",
      "Brown measure",
      "Brunn–Minkowski theorem",
      "Carathéodory's criterion",
      "Carathéodory's extension theorem",
      "Cardinality",
      "Cardinality of the continuum",
      "Category (mathematics)",
      "Church–Kleene ordinal",
      "Clopen set",
      "Closed set",
      "Coanalytic set",
      "Compact set",
      "Complete measure",
      "Complex measure",
      "Computable set",
      "Computably enumerable set",
      "Content (measure theory)",
      "Convergence almost everywhere",
      "Convergence in distribution",
      "Convergence in measure",
      "Convergence in probability",
      "Convergence of measures",
      "Convergence of random variables",
      "Convex analysis",
      "Convex measure",
      "Countable ordinal",
      "Countable set",
      "Counting measure",
      "Cylinder set"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1 French-language sources (fr)",
      "Category:Descriptive set theory",
      "Category:Module:Interwiki extra: additional interwiki links",
      "Category:Short description is different from Wikidata",
      "Category:Topology",
      "Category:Webarchive template wayback links"
    ]
  },
  "Bosonic string theory": {
    "title": "Bosonic string theory",
    "url": "https://en.wikipedia.org/wiki/Bosonic_string_theory",
    "summary": "Bosonic string theory is the original version of string theory, developed in the late 1960s. It is so called because it contains only bosons in the spectrum.\nIn the 1980s, supersymmetry was discovered in the context of string theory, and a new version of string theory called superstring theory (supersymmetric string theory) became the real focus. Nevertheless, bosonic string theory remains a very useful model to understand many general features of perturbative string theory, and many theoretical difficulties of superstrings can actually already be found in the context of bosonic strings.",
    "content": "Bosonic string theory is the original version of string theory, developed in the late 1960s. It is so called because it contains only bosons in the spectrum.\nIn the 1980s, supersymmetry was discovered in the context of string theory, and a new version of string theory called superstring theory (supersymmetric string theory) became the real focus. Nevertheless, bosonic string theory remains a very useful model to understand many general features of perturbative string theory, and many theoretical difficulties of superstrings can actually already be found in the context of bosonic strings.\n\nProblems\nAlthough bosonic string theory has many attractive features, it falls short as a viable physical model in two significant areas.\nFirst, it predicts only the existence of bosons whereas many physical particles are fermions.\nSecond, it predicts the existence of a mode of the string with imaginary mass, implying that the theory has an instability to a process known as \"tachyon condensation\".\nIn addition, bosonic string theory in a general spacetime dimension displays inconsistencies due to the conformal anomaly. But, as was first noticed by Claud Lovelace, in a spacetime of 26 dimensions (25 dimensions of space and one of time), the critical dimension for the theory, the anomaly cancels. This high dimensionality is not necessarily a problem for string theory, because it can be formulated in such a way that along the 22 excess dimensions spacetime is folded up to form a small torus or other compact manifold. This would leave only the familiar four dimensions of spacetime visible to low energy experiments. The existence of a critical dimension where the anomaly cancels is a general feature of all string theories.\n\nTypes of bosonic strings\nThere are four possible bosonic string theories, depending on whether open strings are allowed and whether strings have a specified orientation. A theory of open strings must also include closed strings, because open strings can be thought of as having their endpoints fixed on a D25-brane that fills all of spacetime. A specific orientation of the string means that only interaction corresponding to an orientable worldsheet are allowed (e.g., two strings can only merge with equal orientation). A sketch of the spectra of the four possible theories is as follows:\n\nNote that all four theories have a negative energy tachyon (\n  \n    \n      \n        \n          M\n          \n            2\n          \n        \n        =\n        −\n        \n          \n            1\n            \n              α\n              ′\n            \n          \n        \n      \n    \n    {\\displaystyle M^{2}=-{\\frac {1}{\\alpha '}}}\n  \n) and a massless graviton.\nThe rest of this article applies to the closed, oriented theory, corresponding to borderless, orientable worldsheets.\n\nMathematics\nPath integral perturbation theory\nBosonic string theory can be said to be defined by the path integral quantization of the Polyakov action:\n\n  \n    \n      \n        \n          I\n          \n            0\n          \n        \n        [\n        g\n        ,\n        X\n        ]\n        =\n        \n          \n            T\n            \n              8\n              π\n            \n          \n        \n        \n          ∫\n          \n            M\n          \n        \n        \n          d\n          \n            2\n          \n        \n        ξ\n        \n          \n            g\n          \n        \n        \n          g\n          \n            m\n            n\n          \n        \n        \n          ∂\n          \n            m\n          \n        \n        \n          x\n          \n            μ\n          \n        \n        \n          ∂\n          \n            n\n          \n        \n        \n          x\n          \n            ν\n          \n        \n        \n          G\n          \n            μ\n            ν\n          \n        \n        (\n        x\n        )\n      \n    \n    {\\displaystyle I_{0}[g,X]={\\frac {T}{8\\pi }}\\int _{M}d^{2}\\xi {\\sqrt {g}}g^{mn}\\partial _{m}x^{\\mu }\\partial _{n}x^{\\nu }G_{\\mu \\nu }(x)}\n  \n\n  \n    \n      \n        \n          x\n          \n            μ\n          \n        \n        (\n        ξ\n        )\n      \n    \n    {\\displaystyle x^{\\mu }(\\xi )}\n  \n is the field on the worldsheet describing the most embedding of the string in 25 +1 spacetime; in the Polyakov formulation, \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n  \n is not to be understood as the induced metric from the embedding, but as an independent dynamical field. \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n is the metric on the target spacetime, which is usually taken to be the Minkowski metric in the perturbative theory. Under a Wick rotation, this is brought to a Euclidean metric \n  \n    \n      \n        \n          G\n          \n            μ\n            ν\n          \n        \n        =\n        \n          δ\n          \n            μ\n            ν\n          \n        \n      \n    \n    {\\displaystyle G_{\\mu \\nu }=\\delta _{\\mu \\nu }}\n  \n. M is the worldsheet as a t",
    "links": [
      "ADE classification",
      "AdS/CFT correspondence",
      "Alan Guth",
      "Alexander Markovich Polyakov",
      "Alexander Zamolodchikov",
      "Alexei Zamolodchikov",
      "Andrei Linde",
      "Andrew J. Hanson",
      "Andrew Strominger",
      "André Neveu",
      "Anomaly (physics)",
      "Anton Kapustin",
      "Arvind Rajaraman",
      "Ashoke Sen",
      "Augusto Sagnotti",
      "Barton Zwiebach",
      "Bibcode (identifier)",
      "Black brane",
      "Black hole",
      "Black string",
      "Bogomol'nyi–Prasad–Sommerfield bound",
      "Boson",
      "Bosons",
      "Brane",
      "Brane cosmology",
      "Brian Greene",
      "Bruno Zumino",
      "Burt Ovrut",
      "Calabi–Yau manifold",
      "Chern–Simons form",
      "Claud Lovelace",
      "Compactification (physics)",
      "Complex manifold",
      "Complex number",
      "Conformal anomaly",
      "Conformal field theory",
      "Conformal structure",
      "Conformal symmetry",
      "Conifold",
      "Correlation function (quantum field theory)",
      "Cosmic string",
      "Cosmological constant",
      "Critical dimension",
      "Cumrun Vafa",
      "D-brane",
      "Daniel Friedan",
      "David Berenstein",
      "David Gross",
      "David Olive",
      "Dedekind eta function"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Short description is different from Wikidata",
      "Category:String theory"
    ]
  },
  "Calculus of variations": {
    "title": "Calculus of variations",
    "url": "https://en.wikipedia.org/wiki/Calculus_of_variations",
    "summary": "The calculus of variations (or variational calculus) is a field of mathematical analysis that uses variations, which are small changes in functions\nand functionals, to find maxima and minima of functionals: mappings from a set of functions to the real numbers. Functionals are often expressed as definite integrals involving functions and their derivatives. Functions that maximize or minimize functionals may be found using the Euler–Lagrange equation of the calculus of variations.\nA simple example of such a problem is to find the curve of shortest length connecting two points. If there are no constraints, the solution is a straight line between the points. However, if the curve is constrained to lie on a surface in space, then the solution is less obvious, and possibly many solutions may exist. Such solutions are known as geodesics. A related problem is posed by Fermat's principle: light follows the path of shortest optical length connecting two points, which depends upon the material of",
    "content": "The calculus of variations (or variational calculus) is a field of mathematical analysis that uses variations, which are small changes in functions\nand functionals, to find maxima and minima of functionals: mappings from a set of functions to the real numbers. Functionals are often expressed as definite integrals involving functions and their derivatives. Functions that maximize or minimize functionals may be found using the Euler–Lagrange equation of the calculus of variations.\nA simple example of such a problem is to find the curve of shortest length connecting two points. If there are no constraints, the solution is a straight line between the points. However, if the curve is constrained to lie on a surface in space, then the solution is less obvious, and possibly many solutions may exist. Such solutions are known as geodesics. A related problem is posed by Fermat's principle: light follows the path of shortest optical length connecting two points, which depends upon the material of the medium. One corresponding concept in mechanics is the principle of least/stationary action.\nMany important problems involve functions of several variables. Solutions of boundary value problems for the Laplace equation satisfy the Dirichlet's principle. Plateau's problem requires finding a surface of minimal area that spans a given contour in space: a solution can often be found by dipping a frame in soapy water. Although such experiments are relatively easy to perform, their mathematical formulation is far from simple: there may be more than one locally minimizing surface, and they may have non-trivial topology.\n\nHistory\nThe calculus of variations began with the work of Isaac Newton, such as with Newton's minimal resistance problem, which he formulated and solved in 1685, and later published in his Principia in 1687, which was the first problem in the field to be formulated and correctly solved, and was also one of the most difficult problems tackled by variational methods prior to the twentieth century. This problem was followed by the brachistochrone curve problem raised by Johann Bernoulli (1696), which was similar to one raised by Galileo Galilei in 1638, but he did not solve the problem explicity nor did he use the methods based on calculus. Bernoulli solved the problem using the principle of least time in the process, but not calculus of variations. In 1697 Newton solved the problem using variational techniques, and as a result, he pioneered the field with his work on the two problems. The problem would immediately occupy the attention of Jacob Bernoulli and the Marquis de l'Hôpital, but Leonhard Euler first elaborated the subject, beginning in 1733. Joseph-Louis Lagrange was influenced by Euler's work to contribute greatly to the theory. After Euler saw the 1755 work of the 19-year-old Lagrange, Euler dropped his own partly geometric approach in favor of Lagrange's purely analytic approach and renamed the subject the calculus of variations in his 1756 lecture Elementa Calculi Variationum.\nAdrien-Marie Legendre (1786) laid down a method, not entirely satisfactory, for the discrimination of maxima and minima. Isaac Newton and Gottfried Leibniz also gave some early attention to the subject. To this discrimination Vincenzo Brunacci (1810), Carl Friedrich Gauss (1829), Siméon Poisson (1831), Mikhail Ostrogradsky (1834), and Carl Jacobi (1837) have been among the contributors. An important general work is that of Pierre Frédéric Sarrus (1842) which was condensed and improved by Augustin-Louis Cauchy (1844). Other valuable treatises and memoirs have been written by Strauch (1849), John Hewitt Jellett (1850), Otto Hesse (1857), Alfred Clebsch (1858), and Lewis Buffett Carll (1885), but perhaps the most important work of the century is that of Karl Weierstrass. His celebrated course on the theory is epoch-making, and it may be asserted that he was the first to place it on a firm and unquestionable foundation. The 20th and the 23rd Hilbert problem published in 1900 encouraged further development.\nIn the 20th century David Hilbert, Oskar Bolza, Gilbert Ames Bliss, Emmy Noether, Leonida Tonelli, Henri Lebesgue and Jacques Hadamard among others made significant contributions. Marston Morse applied calculus of variations in what is now called Morse theory. Lev Pontryagin, Ralph Rockafellar and F. H. Clarke developed new mathematical tools for the calculus of variations in optimal control theory. The dynamic programming of Richard Bellman is an alternative to the calculus of variations.\n\nExtrema\nThe calculus of variations is concerned with the maxima or minima (collectively called extrema) of functionals. A functional maps functions to scalars, so functionals have been described as \"functions of functions.\"  Functionals have extrema with respect to the elements \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n of a given function space defined over a given domain. A functional \n  \n    \n      \n        J\n        [\n   ",
    "links": [
      "Abel's test",
      "Abstract Wiener space",
      "Action (physics)",
      "Adrien-Marie Legendre",
      "Alfred Clebsch",
      "Algebraic interior",
      "Alternating series",
      "Alternating series test",
      "Analytical mechanics",
      "Antiderivative",
      "ArXiv (identifier)",
      "Arc length",
      "Archimedes",
      "Arithmetico–geometric sequence",
      "Augustin-Louis Cauchy",
      "Banach bundle",
      "Banach manifold",
      "Beltrami identity",
      "Bernard Dacorogna",
      "Besov measure",
      "Bibcode (identifier)",
      "Binomial series",
      "Bochner integral",
      "Bochner measurable function",
      "Bochner space",
      "Borel functional calculus",
      "Boundary value problem",
      "Brachistochrone curve",
      "Calculus",
      "Calculus on Euclidean space",
      "Cameron–Martin theorem",
      "Canonical Gaussian cylinder set measure",
      "Carathéodory's theorem (convex hull)",
      "Carl Friedrich Gauss",
      "Carl Gustav Jacob Jacobi",
      "Catenary",
      "Cauchy condensation test",
      "Central tendency",
      "Chain rule",
      "Chaplygin problem",
      "Choquet theory",
      "Classical Wiener measure",
      "Classical Wiener space",
      "Closed convex function",
      "Complex analysis",
      "Concave function",
      "Constant (mathematics)",
      "Continuous function",
      "Continuous functional calculus",
      "Contour integration"
    ],
    "categories": [
      "Category:All articles with specifically marked weasel-worded phrases",
      "Category:Articles with short description",
      "Category:Articles with specifically marked weasel-worded phrases from October 2024",
      "Category:CS1 errors: ISBN date",
      "Category:Calculus of variations",
      "Category:Optimization in vector spaces",
      "Category:Pages using sidebar with the child parameter",
      "Category:Short description matches Wikidata"
    ]
  },
  "Catalog of articles in probability theory": {
    "title": "Catalog of articles in probability theory",
    "url": "https://en.wikipedia.org/wiki/Catalog_of_articles_in_probability_theory",
    "summary": "This page lists articles related to probability theory. In particular, it lists many articles corresponding to specific probability distributions. Such articles are marked here by a code of the form (X:Y), which refers to number of random variables involved and the type of the distribution. For example (2:DC) indicates a distribution with two random variables, discrete or continuous. Other codes are just abbreviations for topics. The list of codes can be found in the table of contents.",
    "content": "This page lists articles related to probability theory. In particular, it lists many articles corresponding to specific probability distributions. Such articles are marked here by a code of the form (X:Y), which refers to number of random variables involved and the type of the distribution. For example (2:DC) indicates a distribution with two random variables, discrete or continuous. Other codes are just abbreviations for topics. The list of codes can be found in the table of contents.\n\nCore probability: selected topics\nProbability theory\n\nBasic notions (bsc)\nInstructive examples (paradoxes) (iex)\nMoments (mnt)\nInequalities (inq)\nMarkov chains, processes, fields, networks (Mar)\nGaussian random variables, vectors, functions (Gau)\nConditioning (cnd)\nSpecific distributions (spd)\nEmpirical measure (emm)\nLimit theorems (lmt)\nLarge deviations (lrd)\nRandom graphs (rgr)\nRandom matrices (rmt)\nStochastic calculus (scl)\nMalliavin calculus (Mal)\nRandom dynamical systems (rds)\nRandom dynamical system / scl\n\nAbsorbing set\nBase flow\nPullback attractor\n\nAnalytic aspects (including measure theoretic) (anl)\nCore probability: other articles, by number and type of random variables\nA single random variable (1:)\nBinary (1:B)\nDiscrete (1:D)\nContinuous (1:C)\nReal-valued, arbitrary (1:R)\nRandom point of a manifold (1:M)\nBertrand's paradox / (1:M)\n\nGeneral (random element of an abstract space) (1:G)\nPitman–Yor process / (1:G)\nRandom compact set / (1:G)\nRandom element / (1:G)\n\nTwo random variables (2:)\nBinary (2:B)\nCoupling / (2:BRG)\nCraps principle / (2:B)\n\nDiscrete (2:D)\nKullback–Leibler divergence / (2:DCR)\nMutual information / (23F:DC)\n\nContinuous (2:C)\nReal-valued, arbitrary (2:R)\nGeneral (random element of an abstract space) (2:G)\nCoupling / (2:BRG)\nLévy–Prokhorov metric / (2:G)\nWasserstein metric / (2:G)\n\nThree random variables (3:)\nBinary (3:B)\nPairwise independence / (3:B) (F:R)\n\nDiscrete (3:D)\nMutual information / (23F:DC)\n\nContinuous (3:C)\nMutual information / (23F:DC)\n\nFinitely many random variables (F:)\nBinary (F:B)\nDiscrete (F:D)\nContinuous (F:C)\nReal-valued, arbitrary (F:R)\nGeneral (random element of an abstract space) (F:G)\nFinite-dimensional distribution / (FU:G)\nHitting time / (FU:G)\nStopped process / (FU:DG)\n\nA large number of random variables (finite but tending to infinity) (L:)\nBinary (L:B)\nRandom walk / (FLS:BD) (U:C)\n\nDiscrete (L:D)\nReal-valued, arbitrary (L:R)\nAn infinite sequence of random variables (S:)\nBinary (S:B)\nDiscrete (S:D)\nContinuous (S:C)\nReal-valued, arbitrary (S:R)\nGeneral (random element of an abstract space) (S:G)\nUncountably many random variables (continuous-time processes etc) (U:)\nDiscrete (U:D)\nContinuous (U:C)\nReal-valued, arbitrary (U:R)\nGeneral (random element of an abstract space) (U:G)\nAround the core\nGeneral aspects (grl)\nFoundations of probability theory (fnd)\nGambling (gmb)\nCoincidence (cnc)\nAlgorithmics (alg)\nBayesian approach (Bay)\nFinancial mathematics (fnc)\nPhysics (phs)\nGenetics (gnt)\nStochastic process (spr)\nGeometric probability (geo)\nEmpirical findings (emp)\nBenford's law\nPareto principle\n\nHistorical (hst)\nMiscellany (msc)\nCounters of articles\n\nHere k(n) means: n links to k articles. (Some articles are linked more than once.)",
    "links": [
      "(a,b,0) class of distributions",
      "Absorbing set (random dynamical systems)",
      "Abstract Wiener space",
      "Adapted process",
      "Additive Markov chain",
      "Algebra of random variables",
      "Algorithmic Lovász local lemma",
      "Allais paradox",
      "Almost surely",
      "An inequality on location and scale parameters",
      "Anderson's theorem",
      "Anomaly time series",
      "Anscombe transform",
      "Arrival theorem",
      "Asymptotic equipartition property",
      "Autoregressive integrated moving average",
      "Autoregressive model",
      "Autoregressive moving average model",
      "Autoregressive–moving-average model",
      "Average",
      "Azuma's inequality",
      "B-convex space",
      "BA model",
      "Bapat–Beg theorem",
      "Barabási–Albert model",
      "Base flow (random dynamical systems)",
      "Bayes' theorem",
      "Bayes factor",
      "Bayesian model comparison",
      "Bayesian network",
      "Bayesian probability",
      "Bayesian programming",
      "Bayesianism",
      "Bean machine",
      "Belief propagation",
      "Benford's law",
      "Bennett's inequality",
      "Berkson's paradox",
      "Bernoulli distribution",
      "Bernoulli process",
      "Bernoulli scheme",
      "Bernoulli trial",
      "Bernstein inequalities (probability theory)",
      "Berry–Esseen theorem",
      "Bertrand's ballot theorem",
      "Bertrand's box paradox",
      "Bertrand's paradox (probability)",
      "Bessel process",
      "Beta distribution",
      "Betting"
    ],
    "categories": [
      "Category:Outlines",
      "Category:Outlines of mathematics and logic",
      "Category:Probability theory",
      "Category:Statistics-related lists"
    ]
  },
  "Central limit theorem": {
    "title": "Central limit theorem",
    "url": "https://en.wikipedia.org/wiki/Central_limit_theorem",
    "summary": "In probability theory, the central limit theorem (CLT) states that, under appropriate conditions, the distribution of a normalized version of the sample mean converges to a standard normal distribution. This holds even if the original variables themselves are not normally distributed. There are several versions of the CLT, each applying in the context of different conditions.\nThe theorem is a key concept in probability theory because it implies that probabilistic and statistical methods that work for normal distributions can be applicable to many problems involving other types of distributions.\nThis theorem has seen many changes during the formal development of probability theory. Previous versions of the theorem date back to 1811, but in its modern form it was only precisely stated as late as 1920.\nIn statistics, the CLT can be stated as: let \n  \n    \n      \n        \n          X\n          \n            1\n          \n        \n        ,\n        \n          X\n          \n            2\n      ",
    "content": "In probability theory, the central limit theorem (CLT) states that, under appropriate conditions, the distribution of a normalized version of the sample mean converges to a standard normal distribution. This holds even if the original variables themselves are not normally distributed. There are several versions of the CLT, each applying in the context of different conditions.\nThe theorem is a key concept in probability theory because it implies that probabilistic and statistical methods that work for normal distributions can be applicable to many problems involving other types of distributions.\nThis theorem has seen many changes during the formal development of probability theory. Previous versions of the theorem date back to 1811, but in its modern form it was only precisely stated as late as 1920.\nIn statistics, the CLT can be stated as: let \n  \n    \n      \n        \n          X\n          \n            1\n          \n        \n        ,\n        \n          X\n          \n            2\n          \n        \n        ,\n        …\n        ,\n        \n          X\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle X_{1},X_{2},\\dots ,X_{n}}\n  \n denote a statistical sample of size \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n from a population with expected value (average) \n  \n    \n      \n        μ\n      \n    \n    {\\displaystyle \\mu }\n  \n and finite positive variance \n  \n    \n      \n        \n          σ\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\sigma ^{2}}\n  \n, and let \n  \n    \n      \n        \n          \n            \n              \n                X\n                ¯\n              \n            \n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle {\\bar {X}}_{n}}\n  \n denote the sample mean (which is itself a random variable). Then the limit as \n  \n    \n      \n        n\n        →\n        ∞\n      \n    \n    {\\displaystyle n\\to \\infty }\n  \n of the distribution of \n  \n    \n      \n        (\n        \n          \n            \n              \n                X\n                ¯\n              \n            \n          \n          \n            n\n          \n        \n        −\n        μ\n        )\n        \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle ({\\bar {X}}_{n}-\\mu ){\\sqrt {n}}}\n  \n is a normal distribution with mean \n  \n    \n      \n        0\n      \n    \n    {\\displaystyle 0}\n  \n and variance \n  \n    \n      \n        \n          σ\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\sigma ^{2}}\n  \n.\nIn other words, suppose that a large sample of observations is obtained, each observation being randomly produced in a way that does not depend on the values of the other observations, and the average (arithmetic mean) of the observed values is computed. If this procedure is performed many times, resulting in a collection of observed averages, the central limit theorem says that if the sample size is large enough, the probability distribution of these averages will closely approximate a normal distribution.\nThe central limit theorem has several variants. In its common form, the random variables must be independent and identically distributed (i.i.d.). This requirement can be weakened; convergence of the mean to the normal distribution also occurs for non-identical distributions or for non-independent observations if they comply with certain conditions.\nThe earliest version of this theorem, that the normal distribution may be used as an approximation to the binomial distribution, is the de Moivre–Laplace theorem.\n\nIndependent sequences\nClassical CLT\nLet \n  \n    \n      \n        \n          {\n          \n            X\n            \n              1\n            \n          \n          ,\n          …\n          ,\n          \n            X\n            \n              n\n            \n          \n        \n      \n      }\n    \n    {\\displaystyle \\{X_{1},\\ldots ,X_{n}}\\}\n  \n be a sequence of i.i.d. random variables having a distribution with expected value given by \n  \n    \n      \n        μ\n      \n    \n    {\\displaystyle \\mu }\n  \n and finite variance given by \n  \n    \n      \n        \n          σ\n          \n            2\n          \n        \n        .\n      \n    \n    {\\displaystyle \\sigma ^{2}.}\n  \n Suppose we are interested in the sample average\n\n  \n    \n      \n        \n          \n            \n              \n                X\n                ¯\n              \n            \n          \n          \n            n\n          \n        \n        ≡\n        \n          \n            \n              \n                X\n                \n                  1\n                \n              \n              +\n              ⋯\n              +\n              \n                X\n                \n                  n\n                \n              \n            \n            n\n          \n        \n        .\n      \n    \n    {\\displaystyle {\\bar {X}}_{n}\\equiv {\\frac {X_{1}+\\cdots +X_{n}}{n}}.}\n  \n\nBy the law of large numbers, the sample averag",
    "links": [
      "Abraham de Moivre",
      "Accelerated failure time model",
      "Actuarial science",
      "Adaptive clinical trial",
      "Akaike information criterion",
      "Alan Turing",
      "Aleksandr Lyapunov",
      "Almost sure convergence",
      "Analysis of covariance",
      "Analysis of variance",
      "Anderson–Darling test",
      "Andrey Kolmogorov",
      "Andrey Markov",
      "Antoni Zygmund",
      "ArXiv (identifier)",
      "Arithmetic mean",
      "Arithmetic–geometric mean",
      "Assaf Naor",
      "Asymptotic distribution",
      "Asymptotic equipartition property",
      "Asymptotic series",
      "Asymptotic theory (statistics)",
      "Augustin-Louis Cauchy",
      "Autocorrelation",
      "Autoregressive conditional heteroskedasticity",
      "Autoregressive–moving-average model",
      "Average absolute deviation",
      "Bar chart",
      "Bates distribution",
      "Bayes estimator",
      "Bayes factor",
      "Bayesian inference",
      "Bayesian information criterion",
      "Bayesian linear regression",
      "Bayesian probability",
      "Benford's law",
      "Berry–Esseen theorem",
      "Bias of an estimator",
      "Bibcode (identifier)",
      "Binomial distribution",
      "Binomial regression",
      "Bioinformatics",
      "Biostatistics",
      "Biplot",
      "Blocking (statistics)",
      "Bootstrapping (statistics)",
      "Boris Vladimirovich Gnedenko",
      "Box plot",
      "Box–Jenkins method",
      "Breusch–Godfrey test"
    ],
    "categories": [
      "Category:All articles with unsourced statements",
      "Category:Articles containing proofs",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from April 2012",
      "Category:Articles with unsourced statements from July 2016",
      "Category:Articles with unsourced statements from June 2012",
      "Category:Asymptotic theory (statistics)",
      "Category:CS1 French-language sources (fr)",
      "Category:CS1 German-language sources (de)",
      "Category:CS1 Russian-language sources (ru)"
    ]
  },
  "Andrey Nikolaevich Kolmogorov": {
    "title": "Andrey Kolmogorov",
    "url": "https://en.wikipedia.org/wiki/Andrey_Kolmogorov",
    "summary": "Andrey Nikolaevich Kolmogorov (Russian: Андре́й Никола́евич Колмого́ров, IPA: [ɐnˈdrʲej nʲɪkɐˈlajɪvʲɪtɕ kəlmɐˈɡorəf] , 25 April 1903 – 20 October 1987) was a Soviet mathematician who played a central role in the creation of modern probability theory. He also contributed to the mathematics of topology, intuitionistic logic, turbulence, classical mechanics, algorithmic information theory and computational complexity.",
    "content": "Andrey Nikolaevich Kolmogorov (Russian: Андре́й Никола́евич Колмого́ров, IPA: [ɐnˈdrʲej nʲɪkɐˈlajɪvʲɪtɕ kəlmɐˈɡorəf] , 25 April 1903 – 20 October 1987) was a Soviet mathematician who played a central role in the creation of modern probability theory. He also contributed to the mathematics of topology, intuitionistic logic, turbulence, classical mechanics, algorithmic information theory and computational complexity.\n\nBiography\nEarly life\nAndrey Kolmogorov was born in Tambov, about 500 kilometers southeast of Moscow, in 1903. His unmarried mother, Maria Yakovlevna Kolmogorova, died giving birth to him. Andrey was raised by two of his aunts in Tunoshna (near Yaroslavl) at the estate of his grandfather, a well-to-do nobleman.\nLittle is known about Andrey's father. He was supposedly named Nikolai Matveyevich Katayev and had been an agronomist. Katayev had been exiled from Saint Petersburg to the Yaroslavl province after his participation in the revolutionary movement against the tsars. He disappeared in 1919 and was presumed to have been killed in the Russian Civil War.\nAndrey Kolmogorov was educated in his aunt Vera's village school, and his earliest literary efforts and mathematical papers were printed in the school journal \"The Swallow of Spring\". Andrey (at the age of five) was the \"editor\" of the mathematical section of this journal. Kolmogorov's interest in mathematics was spurred when he noticed, at the age of six, the regularity in the sum of the series of odd numbers: \n  \n    \n      \n        1\n        =\n        \n          1\n          \n            2\n          \n        \n        ;\n        1\n        +\n        3\n        =\n        \n          2\n          \n            2\n          \n        \n        ;\n        1\n        +\n        3\n        +\n        5\n        =\n        \n          3\n          \n            2\n          \n        \n        ,\n      \n    \n    {\\displaystyle 1=1^{2};1+3=2^{2};1+3+5=3^{2},}\n  \n etc.\nIn 1910, his aunt adopted him, and they moved to Moscow, where he graduated from high school in 1920. Later that same year, Kolmogorov began to study at Moscow State University and at the same time Mendeleev Moscow Institute of Chemistry and Technology. Kolmogorov writes about this time: \"I arrived at Moscow University with a fair knowledge of mathematics. I knew in particular the beginning of set theory. I studied many questions in articles in the Encyclopedia of Brockhaus and Efron, filling out for myself what was presented too concisely in these articles.\"\nKolmogorov gained a reputation for his wide-ranging erudition. While an undergraduate student in college, he attended the seminars of the Russian historian S. V. Bakhrushin, and he published his first research paper on the fifteenth and sixteenth centuries' landholding practices in the Novgorod Republic. During the same period (1921–22), Kolmogorov worked out and proved several results in set theory and in the theory of Fourier series.\n\nAdulthood\nIn 1922, Kolmogorov gained international recognition for constructing a Fourier series that diverges almost everywhere. Around this time, he decided to devote his life to mathematics.\nIn 1925, Kolmogorov graduated from Moscow State University and began to study under the supervision of Nikolai Luzin. He formed a lifelong close friendship with Pavel Alexandrov, a fellow student of Luzin; indeed, several researchers have concluded that the two friends were sexually involved, although neither acknowledged this openly. Kolmogorov (together with Aleksandr Khinchin) became interested in probability theory. Also in 1925, he published his work in intuitionistic logic, \"On the principle of the excluded middle,\" in which he proved that under a certain interpretation all statements of classical formal logic can be formulated as those of intuitionistic logic. In 1929, Kolmogorov earned his Doctor of Philosophy degree from Moscow State University. In 1929, Kolmogorov and Alexandrov during a long travel stayed about a month in an island in lake Sevan in Armenia.\nIn 1930, Kolmogorov went on his first long trip abroad, traveling to Göttingen and Munich and then to Paris. He had various scientific contacts in Göttingen, first with Richard Courant and his students working on limit theorems, where diffusion processes proved to be the limits of discrete random processes, then with Hermann Weyl in intuitionistic logic, and lastly with Edmund Landau in function theory. His pioneering work About the Analytical Methods of Probability Theory was published (in German) in 1931. Also in 1931, he became a professor at Moscow State University.\nIn 1933, Kolmogorov published his book Foundations of the Theory of Probability, laying the modern axiomatic foundations of probability theory and establishing his reputation as the world's leading expert in this field. In 1935, Kolmogorov became the first chairman of the department of probability theory at Moscow State University. Around the same years (1936) Kolmogorov contributed to the field of ecolog",
    "links": [
      "A.P. Yushkevich",
      "Academy of Sciences of the Soviet Union",
      "Adi Shamir",
      "Agronomy",
      "Akiva Yaglom",
      "Albert Shiryaev",
      "Alberto Calderón",
      "Aleksandr Khinchin",
      "Alexander Beilinson",
      "Alexander Obukhov",
      "Algorithmic complexity theory",
      "Algorithmic information theory",
      "Almost everywhere",
      "American Academy of Arts and Sciences",
      "American Philosophical Society",
      "Analysis of algorithms",
      "Anatoli Georgievich Vitushkin",
      "Andrei Monin",
      "Andrei N. Kolmogorov",
      "Andrew Wiles",
      "André Weil",
      "ArXiv (identifier)",
      "Astronomical seeing",
      "Atle Selberg",
      "Avrami equation",
      "Balzan Prize",
      "Barrage balloon",
      "Battle of Moscow",
      "Beta wavelet",
      "Bibcode (identifier)",
      "Biographical Memoirs of Fellows of the Royal Society",
      "Borel–Kolmogorov paradox",
      "Boris Vladimirovich Gnedenko",
      "Brockhaus and Efron Encyclopedic Dictionary",
      "Brouwer–Heyting–Kolmogorov interpretation",
      "Carl Friedrich Gauss",
      "Carl Ludwig Siegel",
      "Chapman–Kolmogorov equation",
      "Charles Fefferman",
      "Classical mechanics",
      "Cold War",
      "Convergence of Fourier series",
      "D. Mendeleev University of Chemical Technology of Russia",
      "David George Kendall",
      "David Mumford",
      "Dennis Sullivan",
      "Diffusion process",
      "Dmitri Mendeleev",
      "Doctor of Philosophy",
      "Doctoral advisor"
    ],
    "categories": [
      "Category:1903 births",
      "Category:1987 deaths",
      "Category:20th-century Russian LGBTQ people",
      "Category:20th-century Russian educators",
      "Category:20th-century Russian mathematicians",
      "Category:Academic staff of Moscow State University",
      "Category:Academicians of the USSR Academy of Pedagogical Sciences",
      "Category:Approximation theorists",
      "Category:Articles containing Russian-language text",
      "Category:Articles with Russian-language sources (ru)"
    ]
  },
  "Automata theory": {
    "title": "Automata theory",
    "url": "https://en.wikipedia.org/wiki/Automata_theory",
    "summary": "Automata theory is the study of abstract machines and automata, as well as the computational problems that can be solved using them. It is a theory in theoretical computer science with close connections to cognitive science and mathematical logic. The word automata comes from the Greek word αὐτόματος, which means \"self-acting, self-willed, self-moving\". An automaton (automata in plural) is an abstract self-propelled computing device which follows a predetermined sequence of operations automatically. An automaton with a finite number of states is called a finite automaton (FA) or finite-state machine (FSM). The figure on the right illustrates a finite-state machine, which is a well-known type of automaton. This automaton consists of states (represented in the figure by circles) and transitions (represented by arrows).  As the automaton sees a symbol of input, it makes a transition (or jump) to another state, according to its transition function, which takes the previous state and curren",
    "content": "Automata theory is the study of abstract machines and automata, as well as the computational problems that can be solved using them. It is a theory in theoretical computer science with close connections to cognitive science and mathematical logic. The word automata comes from the Greek word αὐτόματος, which means \"self-acting, self-willed, self-moving\". An automaton (automata in plural) is an abstract self-propelled computing device which follows a predetermined sequence of operations automatically. An automaton with a finite number of states is called a finite automaton (FA) or finite-state machine (FSM). The figure on the right illustrates a finite-state machine, which is a well-known type of automaton. This automaton consists of states (represented in the figure by circles) and transitions (represented by arrows).  As the automaton sees a symbol of input, it makes a transition (or jump) to another state, according to its transition function, which takes the previous state and current input symbol as its arguments.\nAutomata theory is closely related to formal language theory. In this context, automata are used as finite representations of formal languages that may be infinite. Automata are often classified by the class of formal languages they can recognize, as in the Chomsky hierarchy, which describes a nesting relationship between major classes of automata. Automata play a major role in the theory of computation, compiler construction, artificial intelligence, parsing and formal verification.\n\nHistory\nThe theory of abstract automata was developed in the mid-20th century in connection with finite automata. Automata theory was initially considered a branch of mathematical systems theory, studying the behavior of discrete-parameter systems. Early work in automata theory differed from previous work on systems by using abstract algebra to describe information systems rather than differential calculus to describe material systems. The theory of the finite-state transducer was developed under different names by different research communities. The earlier concept of Turing machine was also included in the discipline along with new forms of infinite-state automata, such as pushdown automata.\n1956 saw the publication of Automata Studies, which collected work by scientists including Claude Shannon, W. Ross Ashby, John von Neumann, Marvin Minsky, Edward F. Moore, and Stephen Cole Kleene. With the publication of this volume, \"automata theory emerged as a relatively autonomous discipline\". The book included Kleene's description of the set of regular events, or regular languages, and a relatively stable measure of complexity in Turing machine programs by Shannon. \nIn the same year, Noam Chomsky described the Chomsky hierarchy, a correspondence between automata and formal grammars, and Ross Ashby published An Introduction to Cybernetics, an accessible textbook explaining automata and information using basic set theory.\nThe study of linear bounded automata led to the Myhill–Nerode theorem, which gives a necessary and sufficient condition for a formal language to be regular, and an exact count of the number of states in a minimal machine for the language. The pumping lemma for regular languages, also useful in regularity proofs, was proven in this period by Michael O. Rabin and Dana Scott, along with the computational equivalence of deterministic and nondeterministic finite automata. \nIn the 1960s, a body of algebraic results known as \"structure theory\" or \"algebraic decomposition theory\" emerged, which dealt with the realization of sequential machines from smaller machines by interconnection. While any finite automaton can be simulated using a  universal gate set, this requires that the simulating circuit contain loops of arbitrary complexity. Structure theory deals with the \"loop-free\" realizability of machines.\nThe theory of computational complexity also took shape in the 1960s. By the end of the decade, automata theory came to be seen as \"the pure mathematics of computer science\".\n\nAutomata\nWhat follows is a general definition of an automaton, which restricts a broader definition of a system to one viewed as acting in discrete time-steps, with its state behavior and outputs defined at each step by unchanging functions of only its state and input.\n\nInformal description\nAn automaton runs when it is given some sequence of inputs in discrete (individual) time steps (or just steps). An automaton processes one input picked from a set of symbols or letters, which is called an input alphabet. The symbols received by the automaton as input at any step are a sequence of symbols called words. An automaton has a set of states. At each moment during a run of the automaton, the automaton is in one of its states. When the automaton receives new input, it moves to another state (or transitions) based on a transition function that takes the previous state and current input symbol as parameters. At the same time, another function call",
    "links": [
      "2-category",
      "ACM Computing Classification System",
      "Abstract algebra",
      "Abstract machine",
      "Algebra of physical space",
      "Algebraic structure",
      "Algorithm",
      "Algorithm design",
      "Algorithmic efficiency",
      "Alphabet (computer science)",
      "Alternating automaton",
      "An Introduction to Cybernetics",
      "Analog automata",
      "Analysis of algorithms",
      "Analytical mechanics",
      "Anil Nerode",
      "Aperiodic finite state automaton",
      "Application security",
      "Applied mathematics",
      "Approximation theory",
      "ArXiv (identifier)",
      "Artificial intelligence",
      "Artificial life",
      "Arto Salomaa",
      "Augmented reality",
      "Automata, Computability and Complexity: Theory and Applications",
      "Automata theory",
      "Automated planning and scheduling",
      "Automated theorem proving",
      "Automaton",
      "Bibcode (identifier)",
      "Boolean differential calculus",
      "Bosonic string theory",
      "Büchi automaton",
      "Calculus of variations",
      "Cambridge University Press",
      "Cartesian closed category",
      "Categories of groupoids",
      "Category (mathematics)",
      "Cellular automata",
      "Chaos theory",
      "Chapman & Hall",
      "Chomsky hierarchy",
      "Clarendon Press",
      "Classical field theory",
      "Claude Shannon",
      "Clifford algebra",
      "Clifford analysis",
      "Coding theory",
      "Cognitive science"
    ],
    "categories": [
      "Category:All articles with unsourced statements",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from August 2025",
      "Category:Automata (computation)",
      "Category:CS1: unfit URL",
      "Category:Short description matches Wikidata",
      "Category:Use dmy dates from May 2019"
    ]
  },
  "Bruno de Finetti": {
    "title": "Bruno de Finetti",
    "url": "https://en.wikipedia.org/wiki/Bruno_de_Finetti",
    "summary": "Bruno de Finetti (13 June 1906 – 20 July 1985) was an Italian probabilist statistician and actuary, noted for the \"operational subjective\" conception of probability. The classic exposition of his distinctive theory is the 1937 \"La prévision: ses lois logiques, ses sources subjectives\", which discussed probability founded on the coherence of betting odds and the consequences of exchangeability.",
    "content": "Bruno de Finetti (13 June 1906 – 20 July 1985) was an Italian probabilist statistician and actuary, noted for the \"operational subjective\" conception of probability. The classic exposition of his distinctive theory is the 1937 \"La prévision: ses lois logiques, ses sources subjectives\", which discussed probability founded on the coherence of betting odds and the consequences of exchangeability.\n\nLife\nDe Finetti was born in Innsbruck, Austria, and studied mathematics at Politecnico di Milano. He graduated in 1927, writing his thesis under the supervision of Giulio Vivanti. After graduation, he worked as an actuary and a statistician at Istituto Nazionale di Statistica (National Institute of Statistics) in Rome and, from 1931, the Trieste insurance company Assicurazioni Generali. In 1936 he won a competition for Chair of Financial Mathematics and Statistics, but was not nominated due to a fascist law barring access to unmarried candidates; he was appointed as ordinary professor at the University of Trieste only in 1950.\nHe published extensively (17 papers in 1930 alone, according to Lindley) and acquired an international reputation in the small world of probability mathematicians. He taught mathematical analysis in Padua and then won a chair in Financial Mathematics at Trieste University (1939). In 1954 he moved to the Sapienza University of Rome, first to another chair in Financial Mathematics and then, from 1961 to 1976, one in the Calculus of Probabilities. De Finetti developed his ideas on subjective probability in the 1920s independently of Frank P. Ramsey. Still, according to the preface of his Theory of Probability, he drew on ideas of Harold Jeffreys, I. J. Good and B. O. Koopman. He also reasoned about the connection of economics and probability, and thought that guiding principles to be Paretian optimum further inspired by \"fairness\" criteria. De Finetti held different social and political beliefs through his life: following fascism during his youth, then moving to Christian socialism and finally adhering to the Radical Party.\nDe Finetti only became known in the Anglo-American statistical world in the 1950s when L. J. Savage, who had independently adopted subjectivism, drew him into it; another great champion was Dennis Lindley. De Finetti died in Rome in 1985.\n\nWork and impact\nDe Finetti emphasized a predictive inference approach to statistics; he proposed a thought experiment along the following lines (described in greater detail at coherence): You must set the price of a promise to pay $1 if there was life on Mars 1 billion years ago, and $0 if there was not, and tomorrow the answer will be revealed. You know that your opponent will be able to choose either to buy such a promise from you at the price you have set, or require you to buy such a promise from your opponent, still at the same price. In other words: you set the odds, but your opponent decides which side of the bet will be yours. The price you set is the \"operational subjective probability\" that you assign to the proposition on which you are betting. This price has to obey the probability axioms if you are not to face certain loss, as you would if you set a price above $1 (or a negative price). By considering bets on more than one event, de Finetti could justify additivity. Prices, or equivalently odds, that do not expose you to certain loss through a Dutch book are called coherent.\nDe Finetti is also noted for de Finetti's theorem on exchangeable sequences of random variables. De Finetti was not the first to study exchangeability, but he brought the subject to greater visibility. He started publishing on exchangeability in the late 1920s, but his 1937 article \"La Prévision\" (see bibliography) is his most famous treatment.\nIn 1929, de Finetti introduced the concept of infinitely divisible probability distributions.\nHe also introduced de Finetti diagrams for graphing genotype frequencies.\nThe 1974 English translation of his book is credited with reviving interest in predictive inference in the Anglophone world and bringing the idea of exchangeability to its attention.\nIn 1961 he was elected as a Fellow of the American Statistical Association.\nThe de Finetti Award, presented annually by the European Association for Decision Making, is named after him. The Department of Mathematics, Statistics and Economics of the University of Trieste is named after him too.\nIn the 21st century quantum extensions of de Finetti's representation theorem have been found to be useful in quantum information, in topics like quantum key distribution and entanglement detection.\n\nBibliography\nSee Works on \n\nBruno de Finetti website\n\nde Finetti in English\n(The following are translations of works originally published in Italian or French.)\n\n\"Probabilism: A Critical Essay on the Theory of Probability and on the Value of Science,\" (translation of 1931 article) in Erkenntnis, volume 31, issue 2–3, September 1989, pp. 169–223. The entire double issue is devoted to de Fin",
    "links": [
      "AFM Smith",
      "Actuary",
      "Allais paradox",
      "Ambiguity aversion",
      "Amos Tversky",
      "Analytic hierarchy process",
      "Analytic network process",
      "Anscombe-Aumann subjective expected utility model",
      "ArXiv (identifier)",
      "Assicurazioni Generali",
      "Austria-Hungary",
      "Bayesian inference",
      "Behavioral economics",
      "Bernard Koopman",
      "Bibcode (identifier)",
      "Bounded rationality",
      "CRC Press",
      "Causal decision theory",
      "Certainty effect",
      "Choice architecture",
      "Christian socialism",
      "Cognitive bias",
      "Coherence (philosophical gambling strategy)",
      "Cost-effectiveness analysis",
      "Cost–benefit analysis",
      "Cost–utility analysis",
      "Daniel Kahneman",
      "David Blackwell",
      "David Schmeidler",
      "De Finetti's theorem",
      "De Finetti diagram",
      "Decision-matrix method",
      "Decision conferencing",
      "Decision curve analysis",
      "Decision field theory",
      "Decision rule",
      "Decision support system",
      "Decision table",
      "Decision theory",
      "Decision tree",
      "Decisional balance sheet",
      "Decisionmaking under deep uncertainty",
      "Decoy effect",
      "Dennis Lindley",
      "Disposition effect",
      "Doi (identifier)",
      "Dutch book",
      "Dutch book theorems",
      "Ellsberg paradox",
      "Emotional choice theory"
    ],
    "categories": [
      "Category:1906 births",
      "Category:1985 deaths",
      "Category:20th-century Italian economists",
      "Category:20th-century Italian mathematicians",
      "Category:Academic staff of the Sapienza University of Rome",
      "Category:Academic staff of the University of Trieste",
      "Category:Articles containing French-language text",
      "Category:Articles containing Italian-language text",
      "Category:Articles with Italian-language sources (it)",
      "Category:Articles with hCards"
    ]
  },
  "Chaos theory": {
    "title": "Chaos theory",
    "url": "https://en.wikipedia.org/wiki/Chaos_theory",
    "summary": "Chaos theory is an interdisciplinary area of scientific study and branch of mathematics. It focuses on underlying patterns and deterministic laws of dynamical systems that are highly sensitive to initial conditions. These were once thought to have completely random states of disorder and irregularities. Chaos theory states that within the apparent randomness of chaotic complex systems, there are underlying patterns, interconnection, constant feedback loops, repetition, self-similarity, fractals and self-organization. The butterfly effect, an underlying principle of chaos, describes how a small change in one state of a deterministic nonlinear system can result in large differences in a later state (meaning there is sensitive dependence on initial conditions). A metaphor for this behavior is that a butterfly flapping its wings in Brazil can cause or prevent a tornado in Texas.\nSmall differences in initial conditions, such as those due to errors in measurements or due to rounding errors i",
    "content": "Chaos theory is an interdisciplinary area of scientific study and branch of mathematics. It focuses on underlying patterns and deterministic laws of dynamical systems that are highly sensitive to initial conditions. These were once thought to have completely random states of disorder and irregularities. Chaos theory states that within the apparent randomness of chaotic complex systems, there are underlying patterns, interconnection, constant feedback loops, repetition, self-similarity, fractals and self-organization. The butterfly effect, an underlying principle of chaos, describes how a small change in one state of a deterministic nonlinear system can result in large differences in a later state (meaning there is sensitive dependence on initial conditions). A metaphor for this behavior is that a butterfly flapping its wings in Brazil can cause or prevent a tornado in Texas.\nSmall differences in initial conditions, such as those due to errors in measurements or due to rounding errors in numerical computation, can yield widely diverging outcomes for such dynamical systems, rendering long-term prediction of their behavior impossible in general. This can happen even though these systems are deterministic, meaning that their future behavior follows a unique evolution and is fully determined by their initial conditions, with no random elements involved. In other words, despite the deterministic nature of these systems, this does not make them predictable. This behavior is known as deterministic chaos, or simply chaos. The theory was summarized by Edward Lorenz as:\n\nChaos: When the present determines the future but the approximate present does not approximately determine the future.\nChaotic behavior exists in many natural systems, including fluid flow, heartbeat irregularities, weather and climate. It also occurs spontaneously in some systems with artificial components, such as road traffic. This behavior can be studied through the analysis of a chaotic mathematical model or through analytical techniques such as recurrence plots and Poincaré maps. Chaos theory has applications in a variety of disciplines, including meteorology, anthropology, sociology, environmental science, computer science, engineering, economics, ecology, and pandemic crisis management. The theory formed the basis for such fields of study as complex dynamical systems, edge of chaos theory and self-assembly processes.\n\nIntroduction\nChaos theory concerns deterministic systems whose behavior can, in principle, be predicted. Chaotic systems are predictable for a while and then 'appear' to become random. The amount of time for which the behavior of a chaotic system can be effectively predicted depends on three things: how much uncertainty can be tolerated in the forecast, how accurately its current state can be measured, and a time scale depending on the dynamics of the system, called the Lyapunov time. Some examples of Lyapunov times are: chaotic electrical circuits, about 1 millisecond; weather systems, a few days (unproven); the inner solar system, 4 to 5 million years. In chaotic systems, the uncertainty in a forecast increases exponentially with elapsed time. Hence, mathematically, doubling the forecast time more than squares the proportional uncertainty in the forecast. This means, in practice, a meaningful prediction cannot be made over an interval of more than two or three times the Lyapunov time. When meaningful predictions cannot be made, the system appears random.\n\nChaotic dynamics\nIn common usage, \"chaos\" means \"a state of disorder\". However, in chaos theory, the term is defined more precisely. Although no universally accepted mathematical definition of chaos exists, a commonly used definition, originally formulated by Robert L. Devaney, says that to classify a dynamical system as chaotic, it must have these properties:\n\nit must be sensitive to initial conditions,\nit must be topologically transitive,\nit must have dense periodic orbits.\nIn some cases, the last two properties above have been shown to actually imply sensitivity to initial conditions. In the discrete-time case, this is true for all continuous maps on metric spaces. In these cases, while it is often the most practically significant property, \"sensitivity to initial conditions\" need not be stated in the definition.\nIf attention is restricted to intervals, the second property implies the other two. An alternative and a generally weaker definition of chaos uses only the first two properties in the above list.\n\nSensitivity to initial conditions\nSensitivity to initial conditions means that each point in a chaotic system is arbitrarily closely approximated by other points that have significantly different future paths or trajectories. Thus, an arbitrarily small change or perturbation of the current trajectory may lead to significantly different future behavior.\nSensitivity to initial conditions is popularly known as the \"butterfly effect\", so-called because of the title of a paper",
    "links": [
      "Adolf Zeising",
      "Aftershock",
      "Airplane",
      "Alan Turing",
      "Albert J. Libchaber",
      "Aleksandr Lyapunov",
      "Allele frequencies",
      "Almost all",
      "American Association for the Advancement of Science",
      "American Mathematical Monthly",
      "American Mathematical Society",
      "Amie Wilkinson",
      "Amplitude death",
      "Andrey Nikolaevich Kolmogorov",
      "Annales Henri Poincaré",
      "Anosov diffeomorphism",
      "Anthropology",
      "ArXiv (identifier)",
      "Aristid Lindenmayer",
      "Arnold's cat map",
      "Arnold tongue",
      "Astrophysics",
      "Asymptotic analysis",
      "Attractor",
      "Audrey Terras",
      "Axiom A",
      "BEAM robotics",
      "BML traffic model",
      "Baker's map",
      "Bak–Tang–Wiesenfeld sandpile",
      "Barnsley fern",
      "Basin of attraction",
      "Benoit Mandelbrot",
      "Bernardo Huberman",
      "Bibcode (identifier)",
      "Bifurcation diagram",
      "Bifurcation theory",
      "Biological evolution",
      "Biology",
      "Boris Chirikov",
      "Bouncing ball dynamics",
      "Box-counting dimension",
      "Brazil",
      "Brosl Hasslacher",
      "Bryna Kra",
      "Butterfly effect",
      "Butterfly effect in popular culture",
      "Camouflage",
      "Canada lynx",
      "Cantor set"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1: long volume value",
      "Category:CS1 Russian-language sources (ru)",
      "Category:Chaos theory",
      "Category:Commons category link from Wikidata",
      "Category:Complex systems theory",
      "Category:Computational fields of study",
      "Category:Free-content attribution",
      "Category:Free content from MDPI",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Ambient space": {
    "title": "Ambient space (mathematics)",
    "url": "https://en.wikipedia.org/wiki/Ambient_space_(mathematics)",
    "summary": "In mathematics, especially in geometry and topology, an ambient space is the space surrounding a mathematical object along with the object itself.  For example, a 1-dimensional line \n  \n    \n      \n        (\n        l\n        )\n      \n    \n    {\\displaystyle (l)}\n  \n may be studied in isolation —in which case the ambient space of \n  \n    \n      \n        l\n      \n    \n    {\\displaystyle l}\n  \n is \n  \n    \n      \n        l\n      \n    \n    {\\displaystyle l}\n  \n, or it may be studied as an object embedded in 2-dimensional Euclidean space \n  \n    \n      \n        (\n        \n          \n            R\n          \n          \n            2\n          \n        \n        )\n      \n    \n    {\\displaystyle (\\mathbb {R} ^{2})}\n  \n—in which case the ambient space of \n  \n    \n      \n        l\n      \n    \n    {\\displaystyle l}\n  \n is \n  \n    \n      \n        \n          \n            R\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{2}}\n  \n, or as an object e",
    "content": "In mathematics, especially in geometry and topology, an ambient space is the space surrounding a mathematical object along with the object itself.  For example, a 1-dimensional line \n  \n    \n      \n        (\n        l\n        )\n      \n    \n    {\\displaystyle (l)}\n  \n may be studied in isolation —in which case the ambient space of \n  \n    \n      \n        l\n      \n    \n    {\\displaystyle l}\n  \n is \n  \n    \n      \n        l\n      \n    \n    {\\displaystyle l}\n  \n, or it may be studied as an object embedded in 2-dimensional Euclidean space \n  \n    \n      \n        (\n        \n          \n            R\n          \n          \n            2\n          \n        \n        )\n      \n    \n    {\\displaystyle (\\mathbb {R} ^{2})}\n  \n—in which case the ambient space of \n  \n    \n      \n        l\n      \n    \n    {\\displaystyle l}\n  \n is \n  \n    \n      \n        \n          \n            R\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{2}}\n  \n, or as an object embedded in 2-dimensional hyperbolic space \n  \n    \n      \n        (\n        \n          \n            H\n          \n          \n            2\n          \n        \n        )\n      \n    \n    {\\displaystyle (\\mathbb {H} ^{2})}\n  \n—in which case the ambient space of \n  \n    \n      \n        l\n      \n    \n    {\\displaystyle l}\n  \n is \n  \n    \n      \n        \n          \n            H\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {H} ^{2}}\n  \n.  To see why this makes a difference, consider the statement \"Parallel lines never intersect.\"  This is true if the ambient space is \n  \n    \n      \n        \n          \n            R\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{2}}\n  \n, but false if the ambient space is \n  \n    \n      \n        \n          \n            H\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {H} ^{2}}\n  \n, because the geometric properties of \n  \n    \n      \n        \n          \n            R\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{2}}\n  \n are different from the geometric properties of \n  \n    \n      \n        \n          \n            H\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {H} ^{2}}\n  \n.  All spaces are subsets of their ambient space.\n\nSee also\nConfiguration space\nGeometric space\nManifold and ambient manifold\nSubmanifolds and Hypersurfaces\nRiemannian manifolds\nRicci curvature\nDifferential form\n\nFurther reading\nSchilders, W. H. A.; ter Maten, E. J. W.; Ciarlet, Philippe G. (2005). Numerical Methods in Electromagnetics. Vol. Special Volume. Elsevier. pp. 120ff. ISBN 0-444-51375-2.\nWiggins, Stephen (1992). Chaotic Transport in Dynamical Systems. Berlin: Springer. pp. 209ff. ISBN 3-540-97522-5.",
    "links": [
      "1 dimension",
      "Ambient manifold",
      "Ambient space (psychology)",
      "Configuration space (mathematics)",
      "Differential form",
      "Elliptical geometry",
      "Elsevier",
      "Euclidean geometry",
      "Euclidean space",
      "Geometric space",
      "Geometry",
      "Hyperbolic geometry",
      "Hyperbolic space",
      "Hypersurface",
      "ISBN (identifier)",
      "Line (mathematics)",
      "Manifold",
      "Mathematical object",
      "Mathematics",
      "Parallel (geometry)",
      "Plane (mathematics)",
      "Ricci curvature",
      "Riemannian manifolds",
      "Stephen Wiggins",
      "Submanifold",
      "Subset",
      "Topology",
      "Wikipedia:Citing sources",
      "Wikipedia:External links",
      "Wikipedia:Further reading",
      "Wikipedia:Stub",
      "Wikipedia:When to cite",
      "Wikipedia:WikiProject Fact and Reference Check",
      "Template:Geometry-stub",
      "Template talk:Geometry-stub",
      "Help:Maintenance template removal"
    ],
    "categories": [
      "Category:All articles lacking in-text citations",
      "Category:All stub articles",
      "Category:Articles lacking in-text citations from May 2024",
      "Category:Articles with short description",
      "Category:CS1: long volume value",
      "Category:Geometry",
      "Category:Geometry stubs",
      "Category:Short description matches Wikidata",
      "Category:Topology"
    ]
  },
  "Augmented matrix": {
    "title": "Augmented matrix",
    "url": "https://en.wikipedia.org/wiki/Augmented_matrix",
    "summary": "In linear algebra, an augmented matrix \n  \n    \n      \n        (\n        A\n        |\n        B\n        )\n      \n    \n    {\\displaystyle (A\\vert B)}\n  \n is a \n  \n    \n      \n        k\n        ×\n        (\n        n\n        +\n        1\n        )\n      \n    \n    {\\displaystyle k\\times (n+1)}\n  \n matrix obtained by appending a \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n-dimensional column vector \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  \n, on the right, as a further column to a \n  \n    \n      \n        k\n        ×\n        n\n      \n    \n    {\\displaystyle k\\times n}\n  \n-dimensional matrix \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n. This is usually done for the purpose of performing the same elementary row operations on the augmented matrix \n  \n    \n      \n        (\n        A\n        |\n        B\n        )\n      \n    \n    {\\displaystyle (A\\vert B)}\n  \n as is done on the original one  \n  \n    \n      \n        A\n      \n    \n    {\\display",
    "content": "In linear algebra, an augmented matrix \n  \n    \n      \n        (\n        A\n        |\n        B\n        )\n      \n    \n    {\\displaystyle (A\\vert B)}\n  \n is a \n  \n    \n      \n        k\n        ×\n        (\n        n\n        +\n        1\n        )\n      \n    \n    {\\displaystyle k\\times (n+1)}\n  \n matrix obtained by appending a \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n-dimensional column vector \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  \n, on the right, as a further column to a \n  \n    \n      \n        k\n        ×\n        n\n      \n    \n    {\\displaystyle k\\times n}\n  \n-dimensional matrix \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n. This is usually done for the purpose of performing the same elementary row operations on the augmented matrix \n  \n    \n      \n        (\n        A\n        |\n        B\n        )\n      \n    \n    {\\displaystyle (A\\vert B)}\n  \n as is done on the original one  \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n when solving a system of linear equations by Gaussian elimination.\nFor example, given the matrices \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n and column vector \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  \n, where\n\n  \n    \n      \n        A\n        =\n        \n          \n            [\n            \n              \n                \n                  1\n                \n                \n                  3\n                \n                \n                  2\n                \n              \n              \n                \n                  2\n                \n                \n                  0\n                \n                \n                  1\n                \n              \n              \n                \n                  5\n                \n                \n                  2\n                \n                \n                  2\n                \n              \n            \n            ]\n          \n        \n        ,\n        \n        B\n        =\n        \n          \n            [\n            \n              \n                \n                  4\n                \n              \n              \n                \n                  3\n                \n              \n              \n                \n                  1\n                \n              \n            \n            ]\n          \n        \n        ,\n      \n    \n    {\\displaystyle A={\\begin{bmatrix}1&3&2\\\\2&0&1\\\\5&2&2\\end{bmatrix}},\\quad B={\\begin{bmatrix}4\\\\3\\\\1\\end{bmatrix}},}\n  \n\nthe augmented matrix \n  \n    \n      \n        (\n        A\n        |\n        B\n        )\n      \n    \n    {\\displaystyle (A\\vert B)}\n  \n is\n\n  \n    \n      \n        (\n        A\n        \n          |\n        \n        B\n        )\n        =\n        \n          [\n          \n            \n              \n                \n                  1\n                \n                \n                  3\n                \n                \n                  2\n                \n                \n                  4\n                \n              \n              \n                \n                  2\n                \n                \n                  0\n                \n                \n                  1\n                \n                \n                  3\n                \n              \n              \n                \n                  5\n                \n                \n                  2\n                \n                \n                  2\n                \n                \n                  1\n                \n              \n            \n          \n          ]\n        \n        .\n      \n    \n    {\\displaystyle (A|B)=\\left[{\\begin{array}{ccc|c}1&3&2&4\\\\2&0&1&3\\\\5&2&2&1\\end{array}}\\right].}\n  \n\nFor a given number \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n of unknowns, the number of solutions to a system of \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n linear equations depends only on the rank of the matrix of coefficients \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n representing the system and the rank of the corresponding augmented matrix \n  \n    \n      \n        (\n        A\n        |\n        B\n        )\n      \n    \n    {\\displaystyle (A\\vert B)}\n  \n where the components of \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  \n consist of the right hand sides of the \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n successive linear equations.  According to the Rouché–Capelli theorem, any system of linear equations\n\n  \n    \n      \n        A\n        X\n        =\n        B\n      \n    \n    {\\displaystyle AX=B}\n  \n\nwhere \n  \n    \n      \n        X\n        =\n        (\n        \n          x\n          \n            1\n          \n        \n        ,\n        …\n        ,\n        \n          x\n          \n            n\n          \n        \n        \n          )\n          \n            T\n          \n        \n      \n    \n    {\\displaystyle X=(x_{1},\\dots ,x_{n})^{T}}\n  \n is the \n  \n    \n      \n        n\n      \n    \n    {\\displa",
    "links": [
      "Adjacency matrix",
      "Adjugate matrix",
      "Alternant matrix",
      "Alternating sign matrix",
      "Anti-diagonal matrix",
      "Arrowhead matrix",
      "Band matrix",
      "Biadjacency matrix",
      "Bidiagonal matrix",
      "Bisymmetric matrix",
      "Block-diagonal matrix",
      "Block matrix",
      "Block tridiagonal matrix",
      "Boolean matrix",
      "Bézout matrix",
      "Cabibbo–Kobayashi–Maskawa matrix",
      "Carleman matrix",
      "Cartan matrix",
      "Cauchy matrix",
      "Centering matrix",
      "Centrosymmetric matrix",
      "Circulant matrix",
      "Coefficient matrix",
      "Coefficients",
      "Cofactor matrix",
      "Commutation matrix",
      "Companion matrix",
      "Complex Hadamard matrix",
      "Conference matrix",
      "Confusion matrix",
      "Convergent matrix",
      "Copositive matrix",
      "Correlation matrix",
      "Covariance matrix",
      "Coxeter matrix",
      "DFT matrix",
      "Defective matrix",
      "Definite matrix",
      "Degree matrix",
      "Density matrix",
      "Design matrix",
      "Diagonal matrix",
      "Diagonalizable matrix",
      "Diagonally dominant matrix",
      "Distance matrix",
      "Doubly stochastic matrix",
      "Dover Publications",
      "Duplication and elimination matrices",
      "Edmonds matrix",
      "Eigenvalues and eigenvectors"
    ],
    "categories": [
      "Category:All articles lacking in-text citations",
      "Category:Articles lacking in-text citations from February 2022",
      "Category:Articles with short description",
      "Category:Matrices (mathematics)",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Banach space": {
    "title": "Banach space",
    "url": "https://en.wikipedia.org/wiki/Banach_space",
    "summary": "In mathematics, more specifically in functional analysis, a Banach space (, Polish pronunciation: [ˈba.nax]) is a complete normed vector space. Thus, a Banach space is a vector space with a metric that allows the computation of vector length and distance between vectors and is complete in the sense that a Cauchy sequence of vectors always converges to a well-defined limit that is within the space.\nBanach spaces are named after the Polish mathematician Stefan Banach, who introduced this concept and studied it systematically in 1920–1922 along with Hans Hahn and Eduard Helly. \nMaurice René Fréchet was the first to use the term \"Banach space\" and Banach in turn then coined the term \"Fréchet space\".\nBanach spaces originally grew out of the study of function spaces by Hilbert, Fréchet, and Riesz earlier in the century. Banach spaces play a central role in functional analysis. In other areas of analysis, the spaces under study are often Banach spaces.",
    "content": "In mathematics, more specifically in functional analysis, a Banach space (, Polish pronunciation: [ˈba.nax]) is a complete normed vector space. Thus, a Banach space is a vector space with a metric that allows the computation of vector length and distance between vectors and is complete in the sense that a Cauchy sequence of vectors always converges to a well-defined limit that is within the space.\nBanach spaces are named after the Polish mathematician Stefan Banach, who introduced this concept and studied it systematically in 1920–1922 along with Hans Hahn and Eduard Helly. \nMaurice René Fréchet was the first to use the term \"Banach space\" and Banach in turn then coined the term \"Fréchet space\".\nBanach spaces originally grew out of the study of function spaces by Hilbert, Fréchet, and Riesz earlier in the century. Banach spaces play a central role in functional analysis. In other areas of analysis, the spaces under study are often Banach spaces.\n\nDefinition\nA Banach space is a complete normed space \n  \n    \n      \n        (\n        X\n        ,\n        ‖\n        \n          ⋅\n        \n        ‖\n        )\n        .\n      \n    \n    {\\displaystyle (X,\\|{\\cdot }\\|).}\n  \n \nA normed space is a pair \n\n  \n    \n      \n        (\n        X\n        ,\n        ‖\n        \n          ⋅\n        \n        ‖\n        )\n      \n    \n    {\\displaystyle (X,\\|{\\cdot }\\|)}\n  \n consisting of a vector space \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n over a scalar field \n  \n    \n      \n        \n          K\n        \n      \n    \n    {\\displaystyle \\mathbb {K} }\n  \n (where \n  \n    \n      \n        \n          K\n        \n      \n    \n    {\\displaystyle \\mathbb {K} }\n  \n is commonly \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n or \n  \n    \n      \n        \n          C\n        \n      \n    \n    {\\displaystyle \\mathbb {C} }\n  \n) together with a distinguished \nnorm \n  \n    \n      \n        ‖\n        \n          ⋅\n        \n        ‖\n        :\n        X\n        →\n        \n          R\n        \n        .\n      \n    \n    {\\displaystyle \\|{\\cdot }\\|:X\\to \\mathbb {R} .}\n  \n Like all norms, this norm induces a translation invariant \ndistance function, called the canonical or (norm) induced metric, defined for all vectors \n  \n    \n      \n        x\n        ,\n        y\n        ∈\n        X\n      \n    \n    {\\displaystyle x,y\\in X}\n  \n by\n\n  \n    \n      \n        d\n        (\n        x\n        ,\n        y\n        )\n        :=\n        ‖\n        y\n        −\n        x\n        ‖\n        =\n        ‖\n        x\n        −\n        y\n        ‖\n        .\n      \n    \n    {\\displaystyle d(x,y):=\\|y-x\\|=\\|x-y\\|.}\n  \n\nThis makes \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n into a metric space \n  \n    \n      \n        (\n        X\n        ,\n        d\n        )\n        .\n      \n    \n    {\\displaystyle (X,d).}\n  \n \nA sequence \n  \n    \n      \n        \n          x\n          \n            1\n          \n        \n        ,\n        \n          x\n          \n            2\n          \n        \n        ,\n        …\n      \n    \n    {\\displaystyle x_{1},x_{2},\\ldots }\n  \n is called Cauchy in \n  \n    \n      \n        (\n        X\n        ,\n        d\n        )\n      \n    \n    {\\displaystyle (X,d)}\n  \n or \n  \n    \n      \n        d\n      \n    \n    {\\displaystyle d}\n  \n-Cauchy or \n  \n    \n      \n        ‖\n        \n          ⋅\n        \n        ‖\n      \n    \n    {\\displaystyle \\|{\\cdot }\\|}\n  \n-Cauchy if for every real \n  \n    \n      \n        r\n        >\n        0\n        ,\n      \n    \n    {\\displaystyle r>0,}\n  \n there exists some index \n  \n    \n      \n        N\n      \n    \n    {\\displaystyle N}\n  \n such that\n\n  \n    \n      \n        d\n        (\n        \n          x\n          \n            n\n          \n        \n        ,\n        \n          x\n          \n            m\n          \n        \n        )\n        =\n        ‖\n        \n          x\n          \n            n\n          \n        \n        −\n        \n          x\n          \n            m\n          \n        \n        ‖\n        <\n        r\n      \n    \n    {\\displaystyle d(x_{n},x_{m})=\\|x_{n}-x_{m}\\|<r}\n  \n\nwhenever \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n  \n and \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n are greater than \n  \n    \n      \n        N\n        .\n      \n    \n    {\\displaystyle N.}\n  \n \nThe normed space \n  \n    \n      \n        (\n        X\n        ,\n        ‖\n        \n          ⋅\n        \n        ‖\n        )\n      \n    \n    {\\displaystyle (X,\\|{\\cdot }\\|)}\n  \n is called a Banach space and the canonical metric \n  \n    \n      \n        d\n      \n    \n    {\\displaystyle d}\n  \n is called a complete metric if \n  \n    \n      \n        (\n        X\n        ,\n        d\n        )\n      \n    \n    {\\displaystyle (X,d)}\n  \n is a complete metric space, which by definition means for every Cauchy sequence \n  \n    \n      \n        \n          x\n          \n            1\n          \n        \n        ,\n        \n          x\n          \n            2\n          \n  ",
    "links": [
      "Absolute continuity",
      "Absolute convergence",
      "Absolute value",
      "Absolutely continuous function",
      "Absolutely convex set",
      "Absorbing set",
      "Abstract Wiener space",
      "Adjoint operator",
      "Affine hull",
      "Affine space",
      "Albert Wilansky",
      "Alexander Grothendieck",
      "Algebra over a field",
      "Algebraic interior",
      "Analysis (mathematics)",
      "Anderson–Kadec theorem",
      "Annals of Mathematics",
      "Antilinear map",
      "Approximation property",
      "ArXiv (identifier)",
      "Asplund space",
      "B-convex space",
      "BK-space",
      "Ba space",
      "Baire category theorem",
      "Baire function",
      "Baire space",
      "Balanced set",
      "Ball (mathematics)",
      "Banach-Saks property",
      "Banach algebra",
      "Banach bundle",
      "Banach disk",
      "Banach lattice",
      "Banach manifold",
      "Banach–Alaoglu theorem",
      "Banach–Mazur compactum",
      "Banach–Mazur distance",
      "Banach–Mazur theorem",
      "Banach–Saks theorem",
      "Banach–Stone theorem",
      "Barrelled set",
      "Barrelled space",
      "Besov space",
      "Bessel's inequality",
      "Bibcode (identifier)",
      "Bidual",
      "Bifunctor",
      "Bijection",
      "Bilinear form"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Banach spaces",
      "Category:CS1 French-language sources (fr)",
      "Category:Commons category link is on Wikidata",
      "Category:Functional analysis",
      "Category:Normed spaces",
      "Category:Pages that use a deprecated format of the math tags",
      "Category:Pages with Polish IPA",
      "Category:Science and technology in Poland",
      "Category:Short description matches Wikidata"
    ]
  },
  "Basic Linear Algebra Subprograms": {
    "title": "Basic Linear Algebra Subprograms",
    "url": "https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms",
    "summary": "Basic Linear Algebra Subprograms (BLAS) is a specification that prescribes a set of low-level routines for performing common linear algebra operations such as vector addition, scalar multiplication, dot products, linear combinations, and matrix multiplication. They are the de facto standard low-level routines for linear algebra libraries; the routines have bindings for both C (\"CBLAS interface\") and Fortran (\"BLAS interface\"). Although the BLAS specification is general, BLAS implementations are often optimized for speed on a particular machine, so using them can bring substantial performance benefits. BLAS implementations will take advantage of special floating point hardware such as vector registers or SIMD instructions.\nIt originated as a Fortran library in 1979 and its interface was standardized by the BLAS Technical (BLAST) Forum, whose latest BLAS report can be found on the netlib website. This Fortran library is known as the reference implementation (sometimes confusingly referre",
    "content": "Basic Linear Algebra Subprograms (BLAS) is a specification that prescribes a set of low-level routines for performing common linear algebra operations such as vector addition, scalar multiplication, dot products, linear combinations, and matrix multiplication. They are the de facto standard low-level routines for linear algebra libraries; the routines have bindings for both C (\"CBLAS interface\") and Fortran (\"BLAS interface\"). Although the BLAS specification is general, BLAS implementations are often optimized for speed on a particular machine, so using them can bring substantial performance benefits. BLAS implementations will take advantage of special floating point hardware such as vector registers or SIMD instructions.\nIt originated as a Fortran library in 1979 and its interface was standardized by the BLAS Technical (BLAST) Forum, whose latest BLAS report can be found on the netlib website. This Fortran library is known as the reference implementation (sometimes confusingly referred to as the BLAS library) and is not optimized for speed but is in the public domain.\nMost libraries that offer linear algebra routines conform to the BLAS interface, allowing library users to develop programs that are indifferent to the BLAS library being used.\nMany BLAS libraries have been developed, targeting various different hardware platforms. Examples includes cuBLAS (NVIDIA GPU, GPGPU), rocBLAS (AMD GPU), and OpenBLAS. Examples of CPU-based BLAS library branches include: OpenBLAS, BLIS (BLAS-like Library Instantiation Software), Arm Performance Libraries, ATLAS, and Intel Math Kernel Library (iMKL). AMD maintains a fork of BLIS that is optimized for the AMD platform. ATLAS is a portable library that automatically optimizes itself for an arbitrary architecture. iMKL is a freeware and proprietary vendor library optimized for x86 and x86-64 with a performance emphasis on Intel processors. OpenBLAS is an open-source library that is hand-optimized for many of the popular architectures. The LINPACK benchmarks rely heavily on the BLAS routine gemm for its performance measurements.\nMany numerical software applications use BLAS-compatible libraries to do linear algebra computations, including LAPACK, LINPACK, Armadillo, GNU Octave, Mathematica, MATLAB, NumPy, R, Julia and Lisp-Stat.\n\nBackground\nWith the advent of numerical programming, sophisticated subroutine libraries became useful.  These libraries would contain subroutines for common high-level mathematical operations such as root finding, matrix inversion, and solving systems of equations. The language of choice was FORTRAN. The most prominent numerical programming library was IBM's Scientific Subroutine Package (SSP).  These subroutine libraries allowed programmers to concentrate on their specific problems and avoid re-implementing well-known algorithms.  The library routines would also be better than average implementations; matrix algorithms, for example, might use full pivoting to get better numerical accuracy. The library routines would also have more efficient routines. For example, a library may include a program to solve a matrix that is upper triangular. The libraries would include single-precision and double-precision versions of some algorithms.\nInitially, these subroutines used hard-coded loops for their low-level operations. For example, if a subroutine needed to perform a matrix multiplication, then the subroutine would have three nested loops. Linear algebra programs have many common low-level operations (the so-called \"kernel\" operations, not related to operating systems). Between 1973 and 1977, several of these kernel operations were identified.  These kernel operations became defined subroutines that math libraries could call.  The kernel calls had advantages over hard-coded loops: the library routine would be more readable, there were fewer chances for bugs, and the kernel implementation could be optimized for speed.  A specification for these kernel operations using scalars and vectors, the level-1 Basic Linear Algebra Subroutines (BLAS), was published in 1979.  BLAS was used to implement the linear algebra subroutine library LINPACK.\nThe BLAS abstraction allows customization for high performance. For example, LINPACK is a general purpose library that can be used on many different machines without modification. LINPACK could use a generic version of BLAS. To gain performance, different machines might use tailored versions of BLAS. As computer architectures became more sophisticated, vector machines appeared. BLAS for a vector machine could use the machine's fast vector operations.  (While vector processors eventually fell out of favor, vector instructions in modern CPUs are essential for optimal performance in BLAS routines.)\nOther machine features became available and could also be exploited.  Consequently, BLAS was augmented from 1984 to 1986 with level-2 kernel operations that concerned vector-matrix operations.  Memory hierarchy was also recognized ",
    "links": [
      "AArch64",
      "ACM Transactions on Mathematical Software",
      "AIX operating system",
      "AMD",
      "AMD64",
      "ARM architecture",
      "Advanced Micro Devices",
      "Amortized analysis",
      "Apple Inc.",
      "Application programming interface",
      "ArXiv (identifier)",
      "Arm",
      "Arm Ltd.",
      "Arm Performance Libraries",
      "Armadillo (C++ library)",
      "Automatically Tuned Linear Algebra Software",
      "BLAS",
      "BLIS (software)",
      "Basis (linear algebra)",
      "Bibcode (identifier)",
      "Bilinear map",
      "Bivector",
      "Block matrix",
      "Boost library",
      "C++",
      "C++ AMP",
      "CPU cache",
      "CUDA",
      "C (programming language)",
      "Cache-oblivious algorithm",
      "Cache memory",
      "Change of basis",
      "Charles F. Van Loan",
      "CiteSeerX (identifier)",
      "Comparison of linear algebra libraries",
      "Comparison of numerical-analysis software",
      "Computing platform",
      "Cramer's rule",
      "Cross-platform",
      "Cross product",
      "D (programming language)",
      "De facto",
      "Determinant",
      "Direct sum of modules",
      "Distributed memory",
      "Doi (identifier)",
      "Dot product",
      "Dual space",
      "Eigen (C++ library)",
      "Eigenvalues and eigenvectors"
    ],
    "categories": [
      "Category:All accuracy disputes",
      "Category:All articles with dead external links",
      "Category:Articles with dead external links from October 2016",
      "Category:Articles with dead external links from September 2023",
      "Category:Articles with disputed statements from January 2015",
      "Category:Articles with permanently dead external links",
      "Category:Articles with short description",
      "Category:Numerical linear algebra",
      "Category:Numerical software",
      "Category:Public-domain software with source code"
    ]
  },
  "Bivector": {
    "title": "Bivector",
    "url": "https://en.wikipedia.org/wiki/Bivector",
    "summary": "In mathematics, a bivector or 2-vector is a quantity in exterior algebra or geometric algebra that extends the idea of scalars and vectors. Considering a scalar as a degree-zero quantity and a vector as a degree-one quantity, a bivector is of degree two. Bivectors have applications in many areas of mathematics and physics. They are related to complex numbers in two dimensions and to both pseudovectors and vector quaternions in three dimensions. They can be used to generate rotations in a space of any number of dimensions, and are a useful tool for classifying such rotations.\nGeometrically, a simple bivector can be interpreted as characterizing a directed plane segment (or oriented plane segment), much as vectors can be thought of as characterizing directed line segments. The bivector a ∧ b has an attitude (or direction) of the plane spanned by a and b, has an area that is a scalar multiple of any reference plane segment with the same attitude (and in geometric algebra, it has a magnitu",
    "content": "In mathematics, a bivector or 2-vector is a quantity in exterior algebra or geometric algebra that extends the idea of scalars and vectors. Considering a scalar as a degree-zero quantity and a vector as a degree-one quantity, a bivector is of degree two. Bivectors have applications in many areas of mathematics and physics. They are related to complex numbers in two dimensions and to both pseudovectors and vector quaternions in three dimensions. They can be used to generate rotations in a space of any number of dimensions, and are a useful tool for classifying such rotations.\nGeometrically, a simple bivector can be interpreted as characterizing a directed plane segment (or oriented plane segment), much as vectors can be thought of as characterizing directed line segments. The bivector a ∧ b has an attitude (or direction) of the plane spanned by a and b, has an area that is a scalar multiple of any reference plane segment with the same attitude (and in geometric algebra, it has a magnitude equal to the area of the parallelogram with edges a and b), and has an orientation being the side of a on which b lies within the plane spanned by a and b. \nIn layman terms, any surface defines the same bivector if it is parallel to the same plane (same attitude), has the same area, and same orientation (see figure).\nBivectors are generated by the exterior product on vectors: given two vectors a and b, their exterior product a ∧ b is a bivector, as is any sum of bivectors. Not all bivectors can be expressed as an exterior product without such summation. More precisely, a bivector that can be expressed as an exterior product is called simple; in up to three dimensions all bivectors are simple, but in higher dimensions this is not the case. The exterior product of two vectors is alternating, so a ∧ a is the zero bivector, and b ∧ a = −a ∧ b, producing the opposite orientation.  Concepts directly related to bivector are rank-2 antisymmetric tensor and skew-symmetric matrix.\n\nHistory\nThe bivector was first defined in 1844 by German mathematician Hermann Grassmann in exterior algebra as the result of the exterior product of two vectors. Just the previous year, in Ireland, William Rowan Hamilton had discovered quaternions. Hamilton coined both vector  and bivector, the latter in his Lectures on Quaternions (1853) as he  introduced biquaternions, which have bivectors  for their vector parts. It was not until English mathematician William Kingdon Clifford in 1888 added the geometric product to Grassmann's algebra, incorporating the ideas of both Hamilton and Grassmann, and founded Clifford algebra, that the bivector of this article arose. Henry Forder used the term bivector to develop exterior algebra in 1941.\nIn the 1890s Josiah Willard Gibbs and Oliver Heaviside developed vector calculus, which included separate cross product and dot products that were derived from quaternion multiplication. The success of vector calculus, and of the book Vector Analysis by Gibbs and Wilson, had the effect that the insights of Hamilton and Clifford were overlooked for a long time, since much of 20th century mathematics and physics was formulated in vector terms. Gibbs used vectors to fill the role of bivectors in three dimensions, and used bivector in Hamilton's sense, a use that has sometimes been copied.\nToday the bivector is largely studied as a topic in geometric algebra, a Clifford algebra over real or complex vector spaces with a quadratic form. Its resurgence was led by David Hestenes who, along with others, applied geometric algebra to a range of new applications in physics.\n\nDerivation\nFor this article, the bivector will be considered only in real geometric algebras, which may be applied in most areas of physics. Also unless otherwise stated, all examples have a Euclidean metric and so a positive-definite quadratic form.\n\nGeometric algebra and the geometric product\nThe bivector arises from the definition of the geometric product over a vector space with an associated quadratic form sometimes called the metric. For vectors a, b and c, the geometric product satisfies the following properties:\n\nAssociativity\n\n  \n    \n      \n        (\n        \n          a\n          b\n        \n        )\n        \n          c\n        \n        =\n        \n          a\n        \n        (\n        \n          b\n          c\n        \n        )\n      \n    \n    {\\displaystyle (\\mathbf {ab} )\\mathbf {c} =\\mathbf {a} (\\mathbf {bc} )}\n  \n\nLeft and right distributivity\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  a\n                \n                (\n                \n                  b\n                \n                +\n                \n                  c\n                \n                )\n              \n              \n                \n                =\n                \n                  a\n                  b\n                \n                +\n                \n                  a\n                  c\n                \n     ",
    "links": [
      "4-current",
      "Alternating multilinear map",
      "Alternatization",
      "Angle",
      "Angle of rotation",
      "Angular momentum",
      "Angular velocity tensor",
      "Anticommutative",
      "Antisymmetric tensor",
      "Associativity",
      "Attitude (geometry)",
      "Axial vector",
      "Axis of rotation",
      "Axis–angle representation",
      "Basic Linear Algebra Subprograms",
      "Basis (linear algebra)",
      "Basis vectors",
      "Bilinear map",
      "Biquaternion",
      "Bivector (complex)",
      "Blade (geometry)",
      "Block matrix",
      "Cambridge University Press",
      "Cartesian coordinate system",
      "Change of basis",
      "Characteristic polynomial",
      "Charge density",
      "CiteSeerX (identifier)",
      "Classification of Clifford algebras",
      "Clifford algebra",
      "Clockwise and counterclockwise",
      "Commutative",
      "Commutator",
      "Comparison of linear algebra libraries",
      "Complex number",
      "Complex numbers",
      "Cramer's rule",
      "Cross product",
      "Curl (mathematics)",
      "Current density",
      "David Hestenes",
      "Definite quadratic form",
      "Del",
      "Determinant",
      "Differential operator",
      "Direct sum of modules",
      "Directed line segment",
      "Direction (geometry)",
      "Distributivity",
      "Divergence"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Clifford algebras",
      "Category:Geometric algebra",
      "Category:Multilinear algebra",
      "Category:Planes (geometry)",
      "Category:Short description is different from Wikidata",
      "Category:Tensors",
      "Category:Vector calculus",
      "Category:Wikipedia articles incorporating a citation from the 1911 Encyclopaedia Britannica with Wikisource reference",
      "Category:Wikipedia articles needing clarification from January 2016"
    ]
  },
  "Block matrix": {
    "title": "Block matrix",
    "url": "https://en.wikipedia.org/wiki/Block_matrix",
    "summary": "In mathematics, a block matrix or a partitioned matrix is a matrix that is interpreted as having been broken into sections called blocks or submatrices.\nIntuitively, a matrix interpreted as a block matrix can be visualized as the original matrix with a collection of horizontal and vertical lines, which break it up, or partition it, into a collection of smaller matrices. For example, the 3x4 matrix presented below is divided by horizontal and vertical lines into four blocks: the top-left 2x3 block, the top-right 2x1 block, the bottom-left 1x3 block, and the bottom-right 1x1 block.\n\n  \n    \n      \n        \n          [\n          \n            \n              \n                \n                  \n                    a\n                    \n                      11\n                    \n                  \n                \n                \n                  \n                    a\n                    \n                      12\n                    \n                  \n                \n               ",
    "content": "In mathematics, a block matrix or a partitioned matrix is a matrix that is interpreted as having been broken into sections called blocks or submatrices.\nIntuitively, a matrix interpreted as a block matrix can be visualized as the original matrix with a collection of horizontal and vertical lines, which break it up, or partition it, into a collection of smaller matrices. For example, the 3x4 matrix presented below is divided by horizontal and vertical lines into four blocks: the top-left 2x3 block, the top-right 2x1 block, the bottom-left 1x3 block, and the bottom-right 1x1 block.\n\n  \n    \n      \n        \n          [\n          \n            \n              \n                \n                  \n                    a\n                    \n                      11\n                    \n                  \n                \n                \n                  \n                    a\n                    \n                      12\n                    \n                  \n                \n                \n                  \n                    a\n                    \n                      13\n                    \n                  \n                \n                \n                  \n                    b\n                    \n                      1\n                    \n                  \n                \n              \n              \n                \n                  \n                    a\n                    \n                      21\n                    \n                  \n                \n                \n                  \n                    a\n                    \n                      22\n                    \n                  \n                \n                \n                  \n                    a\n                    \n                      23\n                    \n                  \n                \n                \n                  \n                    b\n                    \n                      2\n                    \n                  \n                \n              \n              \n                \n                  \n                    c\n                    \n                      1\n                    \n                  \n                \n                \n                  \n                    c\n                    \n                      2\n                    \n                  \n                \n                \n                  \n                    c\n                    \n                      3\n                    \n                  \n                \n                \n                  d\n                \n              \n            \n          \n          ]\n        \n      \n    \n    {\\displaystyle \\left[{\\begin{array}{ccc|c}a_{11}&a_{12}&a_{13}&b_{1}\\\\a_{21}&a_{22}&a_{23}&b_{2}\\\\\\hline c_{1}&c_{2}&c_{3}&d\\end{array}}\\right]}\n  \n\nAny matrix may be interpreted as a block matrix in one or more ways, with each interpretation defined by how its rows and columns are partitioned.\nThis notion can be made more precise for an \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n by \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n  \n matrix \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n  \n by partitioning \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n into a collection \n  \n    \n      \n        \n          rowgroups\n        \n      \n    \n    {\\displaystyle {\\text{rowgroups}}}\n  \n, and then partitioning \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n  \n into a collection \n  \n    \n      \n        \n          colgroups\n        \n      \n    \n    {\\displaystyle {\\text{colgroups}}}\n  \n. The original matrix is then considered as the \"total\" of these groups, in the sense that the \n  \n    \n      \n        (\n        i\n        ,\n        j\n        )\n      \n    \n    {\\displaystyle (i,j)}\n  \n entry of the original matrix corresponds in a 1-to-1 way with some \n  \n    \n      \n        (\n        s\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle (s,t)}\n  \n offset entry of some \n  \n    \n      \n        (\n        x\n        ,\n        y\n        )\n      \n    \n    {\\displaystyle (x,y)}\n  \n, where \n  \n    \n      \n        x\n        ∈\n        \n          rowgroups\n        \n      \n    \n    {\\displaystyle x\\in {\\text{rowgroups}}}\n  \n and \n  \n    \n      \n        y\n        ∈\n        \n          colgroups\n        \n      \n    \n    {\\displaystyle y\\in {\\text{colgroups}}}\n  \n.\nBlock matrix algebra arises in general from biproducts in categories of matrices.\n\nExample\nThe matrix\n\n  \n    \n      \n        \n          P\n        \n        =\n        \n          \n            [\n            \n              \n                \n                  1\n                \n                \n                  2\n                \n                \n                  2\n                \n                \n                  7\n                \n              \n              \n                \n                  1\n                \n                \n                  5\n                \n                \n                  6\n                \n    ",
    "links": [
      "Adjacency matrix",
      "Adjugate matrix",
      "Alternant matrix",
      "Alternating sign matrix",
      "Anti-diagonal matrix",
      "ArXiv (identifier)",
      "Arrowhead matrix",
      "Augmented matrix",
      "Band matrix",
      "Basic Linear Algebra Subprograms",
      "Basis (linear algebra)",
      "Biadjacency matrix",
      "Bibcode (identifier)",
      "Bidiagonal matrix",
      "Bijection",
      "Bilinear map",
      "Biproduct",
      "Bisymmetric matrix",
      "Bivector",
      "Block-diagonal matrix",
      "Block LU decomposition",
      "Block tridiagonal matrix",
      "Boolean matrix",
      "Bézout matrix",
      "Cabibbo–Kobayashi–Maskawa matrix",
      "Carleman matrix",
      "Cartan matrix",
      "Category (mathematics)",
      "Cauchy matrix",
      "Centering matrix",
      "Centrosymmetric matrix",
      "Change of basis",
      "Characteristic polynomial",
      "Circulant matrix",
      "Cofactor matrix",
      "Commutation matrix",
      "Commutativity",
      "Companion matrix",
      "Comparison of linear algebra libraries",
      "Complex Hadamard matrix",
      "Computational fluid dynamics",
      "Conference matrix",
      "Conformable matrix",
      "Confusion matrix",
      "Convergent matrix",
      "Copositive matrix",
      "Correlation matrix",
      "Covariance matrix",
      "Coxeter matrix",
      "Cramer's rule"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Matrices (mathematics)",
      "Category:Short description matches Wikidata",
      "Category:Sparse matrices"
    ]
  },
  "Cartesian geometry": {
    "title": "Analytic geometry",
    "url": "https://en.wikipedia.org/wiki/Analytic_geometry",
    "summary": "In mathematics, analytic geometry, also known as coordinate geometry or Cartesian geometry, is the study of geometry using a coordinate system. This contrasts with synthetic geometry.\nAnalytic geometry is used in physics and engineering, and also in aviation, rocketry, space science, and spaceflight. It is the foundation of most modern fields of geometry, including algebraic, differential, discrete and computational geometry.\nUsually the Cartesian coordinate system is applied to manipulate equations for planes, straight lines, and circles, often in two and sometimes three dimensions. Geometrically, one studies the Euclidean plane (two dimensions) and Euclidean space. As taught in school books, analytic geometry can be explained more simply: it is concerned with defining and representing geometric shapes in a numerical way and extracting numerical information from shapes' numerical definitions and representations. That the algebra of the real numbers can be employed to yield results abo",
    "content": "In mathematics, analytic geometry, also known as coordinate geometry or Cartesian geometry, is the study of geometry using a coordinate system. This contrasts with synthetic geometry.\nAnalytic geometry is used in physics and engineering, and also in aviation, rocketry, space science, and spaceflight. It is the foundation of most modern fields of geometry, including algebraic, differential, discrete and computational geometry.\nUsually the Cartesian coordinate system is applied to manipulate equations for planes, straight lines, and circles, often in two and sometimes three dimensions. Geometrically, one studies the Euclidean plane (two dimensions) and Euclidean space. As taught in school books, analytic geometry can be explained more simply: it is concerned with defining and representing geometric shapes in a numerical way and extracting numerical information from shapes' numerical definitions and representations. That the algebra of the real numbers can be employed to yield results about the linear continuum of geometry relies on the Cantor–Dedekind axiom.\n\nHistory\nAncient Greece\nThe Greek mathematician Menaechmus solved problems and proved theorems by using a method that had a strong resemblance to the use of coordinates and it has sometimes been maintained that he had introduced analytic geometry.\nApollonius of Perga, in On Determinate Section, dealt with problems in a manner that may be called an analytic geometry of one dimension; with the question of finding points on a line that were in a ratio to the others. Apollonius in the Conics further developed a method that is so similar to analytic geometry that his work is sometimes thought to have anticipated the work of Descartes by some 1800 years. His application of reference lines, a diameter and a tangent is essentially no different from our modern use of a coordinate frame, where the distances measured along the diameter from the point of tangency are the abscissas, and the segments parallel to the tangent and intercepted between the axis and the curve are the ordinates. He further developed relations between the abscissas and the corresponding ordinates that are equivalent to rhetorical equations (expressed in words) of curves. However, although Apollonius came close to developing analytic geometry, he did not manage to do so since he did not take into account negative magnitudes and in every case the coordinate system was superimposed upon a given curve a posteriori instead of a priori. That is, equations were determined by curves, but curves were not determined by equations. Coordinates, variables, and equations were subsidiary notions applied to a specific geometric situation.\n\nPersia\nThe 11th-century Persian mathematician Omar Khayyam saw a strong relationship between geometry and algebra and was moving in the right direction when he helped close the gap between numerical and geometric algebra with his geometric solution of the general cubic equations, but the decisive step came later with Descartes. Omar Khayyam is credited with identifying the foundations of algebraic geometry, and his book Treatise on Demonstrations of Problems of Algebra (1070), which laid down the principles of analytic geometry, is part of the body of Persian mathematics that was eventually transmitted to Europe. Because of his thoroughgoing geometrical approach to algebraic equations, Khayyam can be considered a precursor to Descartes in the invention of analytic geometry.\n\nWestern Europe\nAnalytic geometry was independently invented by René Descartes and Pierre de Fermat, although Descartes is sometimes given sole credit. Cartesian geometry, the alternative term used for analytic geometry, is named after Descartes.\nDescartes made significant progress with the methods in an essay titled La Géométrie (Geometry), one of the three accompanying essays (appendices) published in 1637 together with his Discourse on the Method for Rightly Directing One's Reason and Searching for Truth in the Sciences, commonly referred to as Discourse on Method.\nLa Geometrie, written in his native French tongue, and its philosophical principles, provided a foundation for calculus in Europe. Initially the work was not well received, due, in part, to the many gaps in arguments and complicated equations. Only after the translation into Latin and the addition of commentary by van Schooten in 1649 (and further work thereafter) did Descartes's masterpiece receive due recognition.\nPierre de Fermat also pioneered the development of analytic geometry. Although not published in his lifetime, a manuscript form of Ad locos planos et solidos isagoge (Introduction to Plane and Solid Loci) was circulating in Paris in 1637, just prior to the publication of Descartes' Discourse. Clearly written and well received, the Introduction also laid the groundwork for analytical geometry. The key difference between Fermat's and Descartes' treatments is a matter of viewpoint: Fermat always started with an algebraic equation a",
    "links": [
      "Abstract algebra",
      "Aerospace engineering",
      "Affine coordinates",
      "Affine geometry",
      "Affine transformations",
      "Ahmes",
      "Algebra",
      "Algebraic equation",
      "Algebraic geometry",
      "Algebraic number theory",
      "Algebraic topology",
      "Alhazen",
      "Altitude (triangle)",
      "American Mathematical Monthly",
      "Analytic number theory",
      "Ancient Greece",
      "Angle",
      "Apollonius of Perga",
      "Applied geometry",
      "Applied mathematics",
      "Archimedes",
      "Area",
      "Area of a circle",
      "Arithmetic",
      "Arithmetic geometry",
      "Aryabhata",
      "Aviation",
      "Balloonist theory",
      "Baudhayana",
      "Before Common Era",
      "Bernhard Riemann",
      "Blaise Pascal",
      "Brahmagupta",
      "CRC Press",
      "Calculus",
      "Cantor–Dedekind axiom",
      "Carl Benjamin Boyer",
      "Carl Friedrich Gauss",
      "Cartesian circle",
      "Cartesian coordinate system",
      "Cartesian coordinates",
      "Cartesian diver",
      "Cartesian doubt",
      "Cartesian plane",
      "Cartesianism",
      "Category theory",
      "Causal adequacy principle",
      "Christiaan Huygens",
      "Christina, Queen of Sweden",
      "Circle"
    ],
    "categories": [
      "Category:All articles with unsourced statements",
      "Category:Analytic geometry",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from April 2022",
      "Category:Pages using sidebar with the child parameter",
      "Category:Short description matches Wikidata",
      "Category:Webarchive template wayback links"
    ]
  },
  "A Treatise on Electricity and Magnetism": {
    "title": "A Treatise on Electricity and Magnetism",
    "url": "https://en.wikipedia.org/wiki/A_Treatise_on_Electricity_and_Magnetism",
    "summary": "A Treatise on Electricity and Magnetism is a two-volume treatise on electromagnetism written by James Clerk Maxwell in 1873. Maxwell was revising the Treatise for a second edition when he died in 1879. The revision was completed by William Davidson Niven for publication in 1881. A third edition was prepared by J. J. Thomson for publication in 1892.\nThe treatise is said to be notoriously hard to read, containing plenty of ideas but lacking both the clear focus and orderliness that may have allowed it catch on more easily. It was noted by one historian of science that Maxwell's attempt at a comprehensive treatise on all of electrical science tended to bury the important results of his work under \"long accounts of miscellaneous phenomena discussed from several points of view\". He goes on to say that, outside the treatment of the Faraday effect, Maxwell failed to expound on his earlier work, especially the generation of electromagnetic waves and the derivation of the laws governing reflect",
    "content": "A Treatise on Electricity and Magnetism is a two-volume treatise on electromagnetism written by James Clerk Maxwell in 1873. Maxwell was revising the Treatise for a second edition when he died in 1879. The revision was completed by William Davidson Niven for publication in 1881. A third edition was prepared by J. J. Thomson for publication in 1892.\nThe treatise is said to be notoriously hard to read, containing plenty of ideas but lacking both the clear focus and orderliness that may have allowed it catch on more easily. It was noted by one historian of science that Maxwell's attempt at a comprehensive treatise on all of electrical science tended to bury the important results of his work under \"long accounts of miscellaneous phenomena discussed from several points of view\". He goes on to say that, outside the treatment of the Faraday effect, Maxwell failed to expound on his earlier work, especially the generation of electromagnetic waves and the derivation of the laws governing reflection and refraction.\nMaxwell introduced the use of vector fields, and his labels have been perpetuated:\n\nA (vector potential), B (magnetic induction), C (electric current), D (displacement), E (electric field – Maxwell's electromotive intensity), F (mechanical force), H (magnetic field – Maxwell's magnetic force).\nMaxwell's work is considered an exemplar of rhetoric of science:\n\nLagrange's equations appear in the Treatise as the culmination of a long series of rhetorical moves, including (among others) Green's theorem, Gauss's potential theory and Faraday's lines of force – all of which have prepared the reader for the Lagrangian vision of a natural world that is whole and connected: a veritable sea change from Newton's vision.\n\nContents\nPreliminary. On the Measurement of Quantities.\nPart I. Electrostatics. \n\nDescription of Phenomena.\nElementary Mathematical Theory of Electricity.\nOn Electrical Work and Energy in a System of Conductors.\nGeneral Theorems.\nMechanical Action Between Two Electrical Systems.\nPoints and Lines of Equilibrium.\nForms of Equipotential Surfaces and Lines of Flow.\nSimple Cases of Electrification.\nSpherical Harmonics.\nConfocal Surfaces of the Second Degree.\nTheory of Electric Images.\nConjugate Functions in Two Dimensions.\nElectrostatic Instruments.\nPart II. Electrokinematics.\n\nThe Electric Current.\nConduction and Resistance.\nElectromotive Force Between Bodies in Contact.\nElectrolysis.\nElectrolytic Polarization.\nMathematical Theory of the Distribution of Electric Currents.\nConduction in Three Dimensions.\nResistance and Conductivity in Three Dimensions.\nConduction through Heterogeneous Media.\nConduction in Dielectrics.\nMeasurement of the Electric Resistance of Conductors.\nElectric Resistance of Substances.\nPart III. Magnetism\n\nElementary Theory of Magnetism.\nMagnetic Force and Magnetic Induction.\nParticular Forms of Magnets.\nInduced Magnetization.\nMagnetic Problems.\nWeber's Theory of Magnetic Induction.\nMagnetic Measurements.\nTerrestrial Magnetism.\nPart IV. Electromagnetism.\n\nElectromagnetic Force.\nMutual Action of Electric Currents.\nInduction of Electric Currents.\nInduction of a Current on Itself.\nGeneral Equations of Dynamics.\nApplication of Dynamics to Electromagnetism.\nElectrokinetics.\nExploration of the Field by means of the Secondary Circuit.\nGeneral Equations.\nDimensions of Electric Units.\nEnergy and Stress.\nCurrent-Sheets.\nParallel Currents.\nCircular Currents.\nElectromagnetic Instruments.\nElectromagnetic Observations.\nElectrical Measurement of Coefficients of Induction.\nDetermination of Resistance in Electromagnetic Measure.\nComparison of Electrostatic With Electromagnetic Units.\nElectromagnetic Theory of Light.\nMagnetic Action on Light.\nElectric Theory of Magnetism.\nTheories of Action at a distance.\n\nReception\nReviews\nOn April 24, 1873, Nature announced the publication with an extensive description and much praise. When the second edition was published in 1881, George Chrystal wrote the review for Nature.\nPierre Duhem published a critical essay outlining mistakes he found in Maxwell's Treatise. Duhem's book was reviewed in Nature.\n\nComments\nHermann von Helmholtz (1881): \"Now that the mathematical interpretations of Faraday's conceptions regarding the nature of electric and magnetic force has been given by Clerk Maxwell, we see how great a degree of exactness and precision was really hidden behind Faraday's words...it is astonishing in the highest to see what a large number of general theories, the mechanical deduction of which requires the highest powers of mathematical analysis, he has found by a kind of intuition, with the security of instinct, without the help of a single mathematical formula.\"\nOliver Heaviside (1893):”What is Maxwell's theory? The first approximation is to say: There is Maxwell's book as he wrote it; there is his text, and there are his equations: together they make his theory. But when we come to examine it closely, we find that this answer is unsatisfactory. To begin with, it i",
    "links": [
      "A Dynamical Theory of the Electromagnetic Field",
      "A History of the Theories of Aether and Electricity",
      "Action at a distance",
      "Albert Einstein",
      "Alexander Macfarlane",
      "American Civil War",
      "Bibcode (identifier)",
      "Classical Electrodynamics (book)",
      "Coffee table book",
      "Cornell University Press",
      "Doi (identifier)",
      "E. T. Whittaker",
      "Electromagnetic waves",
      "Electromagnetism",
      "England",
      "Faraday effect",
      "Field (physics)",
      "George Chrystal",
      "Green's theorem",
      "Heinrich Hertz",
      "Hermann Helmholtz",
      "Hermann von Helmholtz",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "Internet Archive",
      "Introduction to Electrodynamics",
      "J. J. Thomson",
      "James Clerk Maxwell",
      "L. Pearce Williams",
      "Lagrange's equations",
      "Lines of force",
      "Macmillan & Company",
      "Marconi",
      "Masterpiece",
      "Mathematical physics",
      "Michael Faraday",
      "Nature (journal)",
      "Oliver Heaviside",
      "Oliver Lodge",
      "On Physical Lines of Force",
      "Oxford University Press",
      "Partial differential equation",
      "Pierre Duhem",
      "Potential theory",
      "Princeton University Press",
      "Rhetoric of science",
      "Richard P. Feynman",
      "S2CID (identifier)",
      "Scientific writing",
      "Sea change (idiom)"
    ],
    "categories": [
      "Category:1870s in science",
      "Category:1873 books",
      "Category:Articles that link to Wikisource",
      "Category:Articles with short description",
      "Category:Commons category link from Wikidata",
      "Category:Electromagnetism",
      "Category:Historical physics publications",
      "Category:Physics books",
      "Category:Short description is different from Wikidata",
      "Category:Treatises"
    ]
  },
  "Arthur Cayley": {
    "title": "Arthur Cayley",
    "url": "https://en.wikipedia.org/wiki/Arthur_Cayley",
    "summary": "Arthur Cayley  (; 16 August 1821 – 26 January 1895) was an English mathematician who worked mostly on algebra. He helped found the modern British school of pure mathematics, and was a professor at Trinity College, Cambridge for 35 years.\nHe postulated what is now known as the Cayley–Hamilton theorem—that every square matrix is a root of its own characteristic polynomial, and verified it for matrices of order 2 and 3. He was the first to define the concept of an abstract group, a set with a binary operation satisfying certain laws, as opposed to Évariste Galois' concept of permutation groups. In group theory, Cayley tables, Cayley graphs, and Cayley's theorem are named in his honour, as well as Cayley's formula in combinatorics.",
    "content": "Arthur Cayley  (; 16 August 1821 – 26 January 1895) was an English mathematician who worked mostly on algebra. He helped found the modern British school of pure mathematics, and was a professor at Trinity College, Cambridge for 35 years.\nHe postulated what is now known as the Cayley–Hamilton theorem—that every square matrix is a root of its own characteristic polynomial, and verified it for matrices of order 2 and 3. He was the first to define the concept of an abstract group, a set with a binary operation satisfying certain laws, as opposed to Évariste Galois' concept of permutation groups. In group theory, Cayley tables, Cayley graphs, and Cayley's theorem are named in his honour, as well as Cayley's formula in combinatorics.\n\nEarly life\nArthur Cayley was born in Richmond, London, England, on 16 August 1821. His father, Henry Cayley, was a distant cousin of George Cayley, the aeronautics engineer innovator, and descended from an ancient Yorkshire family. He settled in Saint Petersburg, Russia, as a merchant. His mother was Maria Antonia Doughty, daughter of William Doughty. According to some writers she was Russian, but her father's name indicates an English origin. His brother was the linguist Charles Bagot Cayley. Arthur spent his first eight years in Saint Petersburg. In 1829 his parents were settled permanently at Blackheath, London, where Arthur attended a private school.\nAt age 14, he was sent to King's College School. The young Cayley enjoyed complex maths problems, and the school's master observed indications of his mathematical genius. He advised the father to educate his son not for his own business, as he had intended, but at the University of Cambridge.\n\nEducation\nAt the age of 17 Cayley began residence at Trinity College, Cambridge, where he excelled in Greek, French, German, and Italian, as well as mathematics. The cause of the Analytical Society had now triumphed, and the Cambridge Mathematical Journal had been instituted by Gregory and Robert Leslie Ellis. To this journal, at the age of twenty, Cayley contributed three papers, on subjects that had been suggested by reading the Mécanique analytique of Joseph Louis Lagrange and some of the works of Laplace.\nCayley's tutor at Cambridge was George Peacock and his private coach was William Hopkins. He finished his undergraduate course by winning the place of Senior Wrangler, and the first Smith's prize. His next step was to take the M.A. degree, and win a Fellowship by competitive examination. He continued to reside at Cambridge University for four years; during which time he took some pupils, but his main work was the preparation of 28 memoirs to the  Mathematical Journal.\n\nLaw career\nBecause of the limited tenure of his fellowship it was necessary to choose a profession; like De Morgan, Cayley chose law, and was admitted to Lincoln's Inn, London on 20 April 1846 at the age of 24. He made a specialty of conveyancing. It was while he was a pupil at the bar examination that he went to Dublin to hear William Rowan Hamilton's lectures on quaternions.\nHis friend J. J. Sylvester, his senior by five years at Cambridge, was then an actuary, resident in London; they used to walk together round the courts of Lincoln's Inn, discussing the theory of invariants and covariants. During these fourteen years, Cayley produced between two and three hundred papers.\n\nProfessorship\nAround 1860, Cambridge University's Lucasian Professor of Mathematics (Newton's chair) was supplemented by the new Sadleirian professorship, using funds bequeathed by Lady Sadleir, with the 42-year-old Cayley as its first holder. His duties were \"to explain and teach the principles of pure mathematics and to apply himself to the advancement of that science.\" He gave up a lucrative legal practice for a modest salary, but never regretted the exchange, since it allowed him to devote his energies to the pursuit that he liked best. He at once married and settled down in Cambridge, and (unlike Hamilton) enjoyed a home life of great happiness. Sylvester, his friend from his bachelor days, once expressed his envy of Cayley's peaceful family life, whereas the unmarried Sylvester had to fight the world all his days.\nAt first the Sadleirian professor was paid to lecture over one of the terms of the academic year, but the university financial reform of 1886 freed funds to extend his lectures to two terms. For many years his courses were attended only by a few students who had finished their examination preparation, but after the reform the attendance numbered about fifteen. He generally lectured on his current research topic.\nAs for his duty to the advancement of mathematical science, he published a long and fruitful series of memoirs ranging over all of pure mathematics. He also became the standing referee on the merits of mathematical papers to many societies both at home and abroad.\nIn 1872, he was made an honorary fellow of Trinity College, and three years later an ordinary fellow, a paid positi",
    "links": [
      "A. G. Greenhill",
      "A. S. Besicovitch",
      "Actuary",
      "Adam Sedgwick",
      "Aeronautics",
      "Albert von Kölliker",
      "Albrecht Fröhlich",
      "Alexander Macfarlane",
      "Alexander von Humboldt",
      "Algebra",
      "Algebraic geometry",
      "Analytical Society",
      "Andrew Forsyth",
      "Andrew Wiles",
      "August Kekulé",
      "August Wilhelm von Hofmann",
      "Augustus De Morgan",
      "Augustus Edward Hough Love",
      "Baltimore",
      "Bar examination",
      "Bertrand Russell",
      "Binary function",
      "Blackheath, London",
      "British Association for the Advancement of Science",
      "Bryan John Birch",
      "Cambridge",
      "Cambridge Mathematical Journal",
      "Cambridge University Press",
      "Carl Gegenbaur",
      "Carl Ludwig",
      "Cayley's formula",
      "Cayley's mousetrap",
      "Cayley's nodal cubic surface",
      "Cayley's ruled cubic surface",
      "Cayley's sextic",
      "Cayley's theorem",
      "Cayley's Ω process",
      "Cayley (crater)",
      "Cayley baronets",
      "Cayley diagram",
      "Cayley graph",
      "Cayley numbers",
      "Cayley surface (disambiguation)",
      "Cayley table",
      "Cayley transform",
      "Cayleyan",
      "Cayley–Bacharach theorem",
      "Cayley–Dickson construction",
      "Cayley–Hamilton theorem",
      "Cayley–Klein metric"
    ],
    "categories": [
      "Category:1821 births",
      "Category:1895 deaths",
      "Category:19th-century English mathematicians",
      "Category:Algebraic geometers",
      "Category:Alumni of Trinity College, Cambridge",
      "Category:Articles incorporating Cite DNB template",
      "Category:Articles with hCards",
      "Category:Articles with short description",
      "Category:CS1: long volume value",
      "Category:Cayley family"
    ]
  },
  "Benjamin Peirce": {
    "title": "Benjamin Peirce",
    "url": "https://en.wikipedia.org/wiki/Benjamin_Peirce",
    "summary": "Benjamin Peirce  (; April 4, 1809 – October 6, 1880) was an American mathematician who taught at Harvard University for approximately 50 years. He made contributions to celestial mechanics, statistics, number theory, algebra, and the philosophy of mathematics.",
    "content": "Benjamin Peirce  (; April 4, 1809 – October 6, 1880) was an American mathematician who taught at Harvard University for approximately 50 years. He made contributions to celestial mechanics, statistics, number theory, algebra, and the philosophy of mathematics.\n\nEarly life\nHe was born in Salem, Massachusetts, the son of first cousins Benjamin Peirce (1778–1831), later librarian of Harvard, and Lydia Ropes Nichols Peirce (1781–1868).\nAfter graduating from Harvard University in 1829, he taught mathematics for two years at the Round Hill School in Northampton, and in 1831 was appointed professor of mathematics at Harvard. He added astronomy to his portfolio in 1842, and remained as Harvard professor until his death. In addition, he was instrumental in the development of Harvard's science curriculum, served as the college librarian, and was director of the United States Coast Survey from 1867 to 1874.\nIn 1842, he was elected as a member of the American Philosophical Society. He was elected a Foreign Member of the Royal Society of London in 1852.\n\nResearch\nBenjamin Peirce is often regarded as the earliest American scientist whose research was recognized as world class. He was an apologist for slavery, opining that it should be condoned if it was used to allow an elite to pursue scientific enquiry.\n\nMathematics\nIn number theory, he proved there is no odd perfect number with fewer than four prime factors.\nIn algebra, he was notable for the study of associative algebras. He first introduced the terms idempotent and nilpotent in 1870 to describe elements of these algebras, and he also introduced the Peirce decomposition.\nIn the philosophy of mathematics, he became known for the statement that \"Mathematics is the science that draws necessary conclusions\". Peirce's definition of mathematics was credited by his son, Charles Sanders Peirce, as helping to initiate the consequence-oriented philosophy of pragmatism.  Like George Boole, Peirce believed that mathematics could be used to study logic. These ideas were further developed by his son Charles, who noted that logic also includes the study of faulty reasoning.  In contrast, the later logicist program of Gottlob Frege and Bertrand Russell attempted to base mathematics on logic.\n\nStatistics\nPeirce proposed what came to be known as Peirce's Criterion for the statistical treatment of outliers, that is, of apparently extreme observations. His ideas were further developed by his son Charles.\nPeirce was an expert witness in the Howland will forgery trial, where he was assisted by his son Charles. Their analysis of the questioned signature showed that it resembled another particular handwriting example so closely that the chance of such a match occurring at random, i.e. by pure coincidence, was extremely small.\n\nPrivate life\nHe was devoutly religious, though he seldom published his theological thoughts. Peirce credited God as shaping nature in ways that account for the efficacy of pure mathematics in describing empirical phenomena. Peirce viewed \"mathematics as study of God's work by God's creatures\", according to an encyclopedia. He was an avid juggler of diabolo and wrote about the physics of the game in Analytic Mechanics.\nHe married Sarah Hunt Mills, the daughter of U.S. Senator Elijah Hunt Mills. Peirce and his wife had four sons and one daughter:\n\nJames Mills Peirce (1834–1906), who also taught mathematics at Harvard and succeeded to his father's professorship,\nCharles Sanders Peirce (1839–1914), a famous logician, polymath and philosopher,\nBenjamin Mills Peirce (1844–1870), who worked as a mining engineer before an early death,\nHelen Huntington Peirce Ellis (1845–1923), who married William Rogers Ellis, and\nHerbert Henry Davis Peirce (1849–1916), who pursued a career in the Foreign Service.\n\nEponyms\nThe lunar crater Peirce is named for Peirce, as well as the asteroid 29463 Benjaminpeirce.\nPost-doctoral positions in Harvard University's mathematics department are named in his honor as Benjamin Peirce Fellows and Lecturers.\nThe United States Coast Survey ship USCS Benjamin Peirce, in commission from 1855 to 1868, was named for him.\n\nWorks\nAn Elementary Treatise on Plane and Spherical Trigonometry, Boston: James Munroe and Company. Google Eprints of successive editions 1840–1862.\nPhysical  and Celestial Mechanics, Boston: Little, Brown and Company. Google Eprint of 1855 edition.\nLinear Associative Algebra, lithograph by Peirce 1872. New edition with corrections, notes, and an added 1875 paper by Peirce, plus notes by his son Charles Sanders Peirce, published in the American Journal of Mathematics v. 4, 1881, Johns Hopkins University, pp. 221–226, Google Eprint and as an extract, D. Van Nostrand, 1882, Google Eprint.\n1872: A System of Analytical Mechanics, David van Nostrand & Company, link from Internet Archive\n\nSee also\nBenjamin Osgood Peirce (1854–1914)\nTachytrope, curve in which the law of the velocity is given. Developed by Peirce.\n\nNotes\nReferences\nExternal links\n\nBe",
    "links": [
      "29463 Benjaminpeirce",
      "Alan Tower Waterman",
      "Albert A. Michelson",
      "Albert Benjamin Prescott",
      "Albert Francis Blakeslee",
      "Alexander Dallas Bache",
      "Alexis Caswell",
      "Alfred Romer",
      "Algebra",
      "Alice S. Huang",
      "American Academy of Arts and Sciences",
      "American Association for the Advancement of Science",
      "American Mathematical Monthly",
      "American Philosophical Society",
      "Anna J. Harrison",
      "Anton Julius Carlson",
      "Arthur Amos Noyes",
      "Arthur Compton",
      "Asa Gray",
      "Asaph Hall",
      "Associative algebra",
      "Asteroid",
      "Astronomy",
      "Athelstan Spilhaus",
      "Barbara A. Schaal",
      "Benjamin Apthorp Gould",
      "Benjamin Osgood Peirce",
      "Benjamin Peirce (disambiguation)",
      "Benjamin Peirce (librarian)",
      "Bertrand Russell",
      "Calvin M. Woodward",
      "Cambridge, Massachusetts",
      "Carlile Pollock Patterson",
      "Carroll D. Wright",
      "Celestial mechanics",
      "Charles Augustus Young",
      "Charles Doolittle Walcott",
      "Charles Edwin Bessey",
      "Charles F. Kettering",
      "Charles R. Van Hise",
      "Charles Sanders Peirce",
      "Charles Sedgwick Minot",
      "Charles William Eliot",
      "Chauncey D. Leake",
      "Claire M. Fraser",
      "D. Allan Bromley",
      "Daniel Garrison Brinton",
      "David A. Hamburg",
      "David Baltimore",
      "David Starr Jordan"
    ],
    "categories": [
      "Category:1809 births",
      "Category:1880 deaths",
      "Category:19th-century American mathematicians",
      "Category:American algebraists",
      "Category:American astronomers",
      "Category:American number theorists",
      "Category:American statisticians",
      "Category:Articles with hCards",
      "Category:Articles with short description",
      "Category:Biography with signature"
    ]
  },
  "Algebraic equations": {
    "title": "Algebraic equation",
    "url": "https://en.wikipedia.org/wiki/Algebraic_equation",
    "summary": "In mathematics, an algebraic equation or polynomial equation is an equation of the form \n  \n    \n      \n        P\n        =\n        0\n      \n    \n    {\\displaystyle P=0}\n  \n, where P is a polynomial, usually with rational numbers for coefficients. \nFor example, \n  \n    \n      \n        \n          x\n          \n            5\n          \n        \n        −\n        3\n        x\n        +\n        1\n        =\n        0\n      \n    \n    {\\displaystyle x^{5}-3x+1=0}\n  \n is an algebraic equation with integer coefficients and\n\n  \n    \n      \n        \n          y\n          \n            4\n          \n        \n        +\n        \n          \n            \n              x\n              y\n            \n            2\n          \n        \n        −\n        \n          \n            \n              x\n              \n                3\n              \n            \n            3\n          \n        \n        +\n        x\n        \n          y\n          \n            2\n          \n        \n        +\n        \n          y\n       ",
    "content": "In mathematics, an algebraic equation or polynomial equation is an equation of the form \n  \n    \n      \n        P\n        =\n        0\n      \n    \n    {\\displaystyle P=0}\n  \n, where P is a polynomial, usually with rational numbers for coefficients. \nFor example, \n  \n    \n      \n        \n          x\n          \n            5\n          \n        \n        −\n        3\n        x\n        +\n        1\n        =\n        0\n      \n    \n    {\\displaystyle x^{5}-3x+1=0}\n  \n is an algebraic equation with integer coefficients and\n\n  \n    \n      \n        \n          y\n          \n            4\n          \n        \n        +\n        \n          \n            \n              x\n              y\n            \n            2\n          \n        \n        −\n        \n          \n            \n              x\n              \n                3\n              \n            \n            3\n          \n        \n        +\n        x\n        \n          y\n          \n            2\n          \n        \n        +\n        \n          y\n          \n            2\n          \n        \n        +\n        \n          \n            1\n            7\n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle y^{4}+{\\frac {xy}{2}}-{\\frac {x^{3}}{3}}+xy^{2}+y^{2}+{\\frac {1}{7}}=0}\n  \n\nis a multivariate polynomial equation over the rationals.\nFor many authors, the term algebraic equation refers only to the univariate case, that is polynomial equations that involve only one variable. On the other hand, a polynomial equation may involve several variables (the multivariate case), in which case the term polynomial equation is usually preferred.\nSome but not all polynomial equations with rational coefficients have a solution that is an algebraic expression that can be found using a finite number of operations that involve only those same types of coefficients (that is, can be solved algebraically). This can be done for all such equations of degree one, two, three, or four; but for degree five or more it can only be done for some equations, not all. A large amount of research has been devoted to compute efficiently accurate approximations of the real or complex solutions of a univariate algebraic equation (see Root-finding algorithm) and of the common solutions of several multivariate polynomial equations (see System of polynomial equations).\n\nTerminology\nThe term \"algebraic equation\" dates from the time when the main problem of algebra was to solve univariate polynomial equations. This problem was completely solved during the 19th century; see Fundamental theorem of algebra, Abel–Ruffini theorem and Galois theory.\nSince then, the scope of algebra has been dramatically enlarged. In particular, it includes the study of equations that involve nth roots and, more generally, algebraic expressions. This makes the term algebraic equation ambiguous outside the context of the old problem. So the term polynomial equation is generally preferred when this ambiguity may occur, specially when considering multivariate equations.\n\nHistory\nThe study of algebraic equations is probably as old as mathematics: the Babylonian mathematicians, as early as 2000 BC could solve some kinds of quadratic equations (displayed on Old Babylonian clay tablets).\nUnivariate algebraic equations over the rationals (i.e., with rational coefficients) have a very long history. Ancient mathematicians wanted the solutions in the form of radical expressions, like \n  \n    \n      \n        x\n        =\n        \n          \n            \n              1\n              +\n              \n                \n                  5\n                \n              \n            \n            2\n          \n        \n      \n    \n    {\\displaystyle x={\\frac {1+{\\sqrt {5}}}{2}}}\n  \n for the positive solution of \n  \n    \n      \n        \n          x\n          \n            2\n          \n        \n        −\n        x\n        −\n        1\n        =\n        0\n      \n    \n    {\\displaystyle x^{2}-x-1=0}\n  \n. The ancient Egyptians knew how to solve equations of degree 2 in this manner. The Indian mathematician Brahmagupta (597–668 AD) explicitly described the quadratic formula in his treatise Brāhmasphuṭasiddhānta published in 628 AD, but written in words instead of symbols. In the 9th century Muhammad ibn Musa al-Khwarizmi and other Islamic mathematicians derived the quadratic formula, the general solution of equations of degree 2, and recognized the importance of the discriminant.  During the Renaissance in 1545, Gerolamo Cardano published the solution of  Scipione del Ferro and Niccolò Fontana Tartaglia to equations of degree 3 and that of  Lodovico Ferrari for equations of degree 4. Finally Niels Henrik Abel proved, in 1824, that equations of degree 5 and higher do not have general solutions using radicals. Galois theory, named after Évariste Galois, showed that some equations of at least degree 5 do not even have an idiosyncratic solution in radicals, and gave criteria for deciding if an equation is in fact solvable using radicals.\n\nAreas of study\nThe ",
    "links": [
      "Abel–Ruffini theorem",
      "Algebra",
      "Algebraic expression",
      "Algebraic extension",
      "Algebraic function",
      "Algebraic geometry",
      "Algebraic number",
      "Algebraic number theory",
      "Algebraic solution",
      "Algebraically closed field",
      "Babylonian mathematics",
      "Bezout method",
      "Charles Hermite",
      "Clay tablet",
      "Coefficient",
      "Complex number",
      "Complex numbers",
      "Cramer's theorem (algebraic curves)",
      "Cubic equation",
      "Cubic function",
      "Cyclotomic polynomials",
      "Degree of a polynomial",
      "Descartes method",
      "Diophantine equation",
      "Discriminant",
      "Elementary function",
      "Elliptical function",
      "Encyclopedia of Mathematics",
      "Equation",
      "Equation solving",
      "Eric W. Weisstein",
      "Euler method",
      "European Mathematical Society",
      "Exponentiation",
      "Ferrari method",
      "Field (mathematics)",
      "Field extension",
      "Field theory (mathematics)",
      "First Babylonian dynasty",
      "Fundamental theorem of algebra",
      "Galois group",
      "Galois theory",
      "Gerolamo Cardano",
      "Hyperbolic functions",
      "Imaginary unit",
      "Integer",
      "Integral domain",
      "Intermediate value theorem",
      "Lagrange method",
      "Leonhard Euler"
    ],
    "categories": [
      "Category:All articles lacking in-text citations",
      "Category:Articles lacking in-text citations from June 2023",
      "Category:Articles with short description",
      "Category:Equations",
      "Category:Polynomials",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Arithmetical algebra": {
    "title": "George Peacock",
    "url": "https://en.wikipedia.org/wiki/George_Peacock",
    "summary": "George Peacock FRS (9 April 1791 – 8 November 1858) was an English mathematician and Anglican cleric. He founded what has been called the British algebra of logic.",
    "content": "George Peacock FRS (9 April 1791 – 8 November 1858) was an English mathematician and Anglican cleric. He founded what has been called the British algebra of logic.\n\nEarly life\nPeacock was born on 9 April 1791 at Thornton Hall, Denton, near Darlington, County Durham. His father, Thomas Peacock, was a priest of the Church of England, incumbent and for 50 years curate of the parish of Denton, where he also kept a school. In early life, Peacock did not show any precocity of genius. He was more remarkable for daring feats of climbing than for any special attachment to study. Initially, he received his elementary education from his father and then at Sedbergh School, and at 17 years of age, he was sent to Richmond School under James Tate, a graduate of Cambridge University. At this school he distinguished himself greatly both in classics and in the rather elementary mathematics then required for entrance at Cambridge. In 1809 he became a student of Trinity College, Cambridge.\nIn 1812 Peacock took the rank of Second Wrangler, and the second Smith's prize, the senior wrangler being John Herschel. Two years later, he became a candidate for a fellowship in his college and won it immediately, partly by means of his extensive and accurate knowledge of the classics. A fellowship then meant about £200 a year, tenable for seven years provided the Fellow did not marry meanwhile, and capable of being extended after the seven years provided the Fellow took clerical orders, which Peacock did in 1819.\n\nMathematical career\nThe year after taking a Fellowship, Peacock was appointed a tutor and lecturer of his college, which position he continued to hold for many years. Peacock, in common with many other students of his own standing, was profoundly impressed with the need of reforming Cambridge's position ignoring the differential notation for calculus, and while still an undergraduate formed a league with Babbage and Herschel to adopt measures to bring it about. In 1815 they formed what they called the Analytical Society, the object of which was stated to be to advocate the d 'ism of the Continent versus the dot-age of the university.\nThe first movement on the part of the Analytical Society was to translate from the French the smaller work of Lacroix on the differential and integral calculus; it was published in 1816. At that time the French language had the best manuals, as well as the greatest works on mathematics. Peacock followed up the translation with a volume containing a copious Collection of Examples of the Application of the Differential and Integral Calculus, which was published in 1820. The sale of both books was rapid, and contributed materially to further the object of the Society. In that time, high wranglers of one year became the examiners of the mathematical tripos three or four years afterwards. Peacock was appointed an examiner in 1817, and he did not fail to make use of the position as a powerful lever to advance the cause of reform. In his questions set for the examination the differential notation was for the first time officially employed in Cambridge. The innovation did not escape censure, but he wrote to a friend as follows: \"I assure you that I shall never cease to exert myself to the utmost in the cause of reform, and that I will never decline any office which may increase my power to effect it. I am nearly certain of being nominated to the office of Moderator in the year 1818-1819, and as I am an examiner in virtue of my office, for the next year I shall pursue a course even more decided than hitherto, since I shall feel that men have been prepared for the change, and will then be enabled to have acquired a better system by the publication of improved elementary books. I have considerable influence as a lecturer, and I will not neglect it. It is by silent perseverance only, that we can hope to reduce the many-headed monster of prejudice and make the University answer her character as the loving mother of good learning and science.\" These few sentences give an insight into the character of Peacock: he was an ardent reformer and a few years brought success to the cause of the Analytical Society.\nAnother reform at which Peacock labored was the teaching of algebra. In 1830 he published A Treatise on Algebra which had for its object the placing of algebra on a true scientific basis, adequate for the development which it had received at the hands of the Continental mathematicians. To elevate astronomical science the Astronomical Society of London was founded, and the three reformers Peacock, Babbage and Herschel were again prime movers in the undertaking. Peacock was one of the most zealous promoters of an astronomical observatory at Cambridge, and one of the founders of the Philosophical Society of Cambridge.\nIn 1831 the British Association for the Advancement of Science (prototype of the American, French and Australasian Associations) held its first meeting in the ancient city of York. One of the first re",
    "links": [
      "Adam Sedgwick",
      "Alexander Kirkpatrick",
      "Algebra",
      "Algebra of logic",
      "Allan Shaw",
      "American Philosophical Society",
      "Analytical Society",
      "Andrew Perne",
      "Anglican cleric",
      "Arithmetic",
      "Arthur Cayley",
      "Augustus De Morgan",
      "Charles Babbage",
      "Charles Merivale",
      "Charles Roderick",
      "Charles Stubbs",
      "Church of England",
      "Clergy of the Church of England database",
      "County Durham",
      "Darlington",
      "David Pritchard (priest)",
      "Dean of Ely",
      "Digital data",
      "Division (mathematics)",
      "Duncan Farquharson Gregory",
      "Edmund F. Robertson",
      "Edward Martin (Queens')",
      "Ely, Cambridgeshire",
      "Equivalence relation",
      "Fellow of the Royal Society",
      "Francis Wilford",
      "French language",
      "George Biddell Airy",
      "George Boole",
      "George Gilbert Scott",
      "George Peacock (disambiguation)",
      "George Peacock (mathematician)",
      "Google Books",
      "Harvey Goodwin",
      "Henry Caesar (priest)",
      "Henry Ferne",
      "Hugh Thomas (priest)",
      "Humphrey Tyndall",
      "ISBN (identifier)",
      "Internet Archive",
      "James Tate (headmaster)",
      "James Wood (mathematician)",
      "John Bell (priest)",
      "John Couch Adams",
      "John Frankland"
    ],
    "categories": [
      "Category:1791 births",
      "Category:1858 deaths",
      "Category:19th-century English mathematicians",
      "Category:All articles needing additional references",
      "Category:Articles needing additional references from January 2008",
      "Category:Articles with hCards",
      "Category:Articles with short description",
      "Category:Deans of Ely",
      "Category:Fellows of the Royal Society",
      "Category:International members of the American Philosophical Society"
    ]
  },
  "Abstrakt Algebra": {
    "title": "Abstrakt Algebra",
    "url": "https://en.wikipedia.org/wiki/Abstrakt_Algebra",
    "summary": "Abstrakt Algebra was a Swedish experimental metal band with influences from power metal and doom metal. It was founded by bassist Leif Edling in 1994, shortly after his main project Candlemass split up.\nThey made one album, but Edling had already started working on a second album with a different line-up. However, due to the commercial failure of Abstrakt Algebra, Edling reformed Candlemass while taking with him some of the ideas for that second album, as well as drummer Jejo Perkovic. There, materialised on the Dactylis Glomerata album. And as such Abstrakt Algebra was over. That second album, called Abstrakt Algebra II, was later included as a bonus disc in the 2006 re-release of Dactylis Glomerata.\nMats Levén later appeared as the singer of the band Krux, another band by Edling, which has a similar take on the experimentation Edling started with Abstrakt Algebra.",
    "content": "Abstrakt Algebra was a Swedish experimental metal band with influences from power metal and doom metal. It was founded by bassist Leif Edling in 1994, shortly after his main project Candlemass split up.\nThey made one album, but Edling had already started working on a second album with a different line-up. However, due to the commercial failure of Abstrakt Algebra, Edling reformed Candlemass while taking with him some of the ideas for that second album, as well as drummer Jejo Perkovic. There, materialised on the Dactylis Glomerata album. And as such Abstrakt Algebra was over. That second album, called Abstrakt Algebra II, was later included as a bonus disc in the 2006 re-release of Dactylis Glomerata.\nMats Levén later appeared as the singer of the band Krux, another band by Edling, which has a similar take on the experimentation Edling started with Abstrakt Algebra.\n\nMembers\nDiscography\nAbstrakt Algebra (1995)\nAbstrakt Algebra II (2008)\n\n\n== References ==",
    "links": [
      "Candlemass (band)",
      "Dactylis Glomerata",
      "Doom metal",
      "Experimental metal",
      "Krux",
      "Leif Edling",
      "Mats Levén",
      "Mike Wead",
      "Power metal",
      "Talk:Abstrakt Algebra",
      "Wikipedia:Deletion policy",
      "Wikipedia:Independent sources",
      "Wikipedia:Merging",
      "Wikipedia:Notability (music)",
      "Wikipedia:Redirect",
      "Wikipedia:Reliable sources",
      "Wikipedia:Verifiability",
      "Template:Cite web",
      "Help:Authority control",
      "Help:Maintenance template removal",
      "Help:Referencing for beginners",
      "Category:CS1 maint: archived copy as title"
    ],
    "categories": [
      "Category:1994 establishments in Sweden",
      "Category:All articles needing additional references",
      "Category:All articles with topics of unclear notability",
      "Category:Articles needing additional references from October 2020",
      "Category:Articles with multiple maintenance issues",
      "Category:Articles with short description",
      "Category:Articles with topics of unclear notability from October 2020",
      "Category:CS1 maint: archived copy as title",
      "Category:Music articles with topics of unclear notability",
      "Category:Musical groups established in 1994"
    ]
  },
  "Algebra (Lang)": {
    "title": "Algebra (Lang)",
    "url": "https://en.wikipedia.org/wiki/Algebra_(Lang)",
    "summary": "Algebra is a graduate level textbook on Algebra written by Serge Lang, originally published by Addison-Wesley in 1965.   \nSerge Lang was awarded the Steele Prize for exposition in 1999, the citation stating that Algebra is among his most famous texts. The Mathematical Association of America (MAA) strongly recommends undergraduate mathematics libraries have a copy of Algebra available.",
    "content": "Algebra is a graduate level textbook on Algebra written by Serge Lang, originally published by Addison-Wesley in 1965.   \nSerge Lang was awarded the Steele Prize for exposition in 1999, the citation stating that Algebra is among his most famous texts. The Mathematical Association of America (MAA) strongly recommends undergraduate mathematics libraries have a copy of Algebra available.\n\nTopics\nThe third edition is divided into four parts. The first part, The Basic Objects of Algebra, covers groups, rings, modules, and polynomials. The second part, Algebraic Equations, focuses on field theory and includes a chapter on Noetherian rings and modules. The third part, Linear Algebra and Representations, contains chapters on the tensor product of modules and semi-simplicity. The final part, Homological Algebra, covers general homology theory and finite free resolutions.\n\nAudience and reception\nThe book was designed by Lang to be intended for a one year graduate level course and for readers who have previously studied algebra at an undergraduate level.\nThe book in its latest third edition lists over 10,000 citations on Google Scholar and has been noted as a common reference material for papers in algebra.\nAlgebra received praise from mathematicians Gerry Leversha and Gerry Brandstein in The Mathematical Gazette in its 1967 and 2003 issues respectively.\nProfessor George Bergman of Berkeley wrote Companion to Lang's Algebra, a 222 page book of notes combined into a collection when teaching Berkeley’s basic graduate algebra course from Lang’s book.\n\n\n== References ==",
    "links": [
      "Addison-Wesley",
      "Algebra",
      "Doi (identifier)",
      "Field (mathematics)",
      "George Bergman",
      "Google Scholar",
      "Graduate Texts in Mathematics",
      "Group (mathematics)",
      "Homology (mathematics)",
      "ISSN (identifier)",
      "Leroy P. Steele Prize",
      "Mathematical Association of America",
      "Module (mathematics)",
      "Noetherian module",
      "Noetherian ring",
      "Notices of the American Mathematical Society",
      "Polynomial",
      "Postgraduate education",
      "Resolution (algebra)",
      "Ring (mathematics)",
      "Semi-simplicity",
      "Serge Lang",
      "Springer-Verlag",
      "Tensor product",
      "Wikipedia:Manual of Style/Words to watch",
      "Help:Maintenance template removal"
    ],
    "categories": [
      "Category:2001 non-fiction books",
      "Category:Algebra",
      "Category:All articles with peacock terms",
      "Category:Articles with peacock terms from August 2025",
      "Category:Articles with short description",
      "Category:Graduate Texts in Mathematics",
      "Category:Mathematics textbooks",
      "Category:Short description matches Wikidata"
    ]
  },
  "Algebraic function": {
    "title": "Algebraic function",
    "url": "https://en.wikipedia.org/wiki/Algebraic_function",
    "summary": "In mathematics, an algebraic function is a function that can be defined \nas the root of an irreducible polynomial equation. Algebraic functions are often algebraic expressions using a finite number of terms, involving only the algebraic operations addition, subtraction, multiplication, division, and raising to a fractional power. Examples of such functions are:\n\n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        1\n        \n          /\n        \n        x\n      \n    \n    {\\displaystyle f(x)=1/x}\n  \n\n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        \n          \n            x\n          \n        \n      \n    \n    {\\displaystyle f(x)={\\sqrt {x}}}\n  \n\n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        \n          \n            \n              1\n              +\n              \n                x\n                \n                  3\n                \n              \n            \n            \n              \n                x\n            ",
    "content": "In mathematics, an algebraic function is a function that can be defined \nas the root of an irreducible polynomial equation. Algebraic functions are often algebraic expressions using a finite number of terms, involving only the algebraic operations addition, subtraction, multiplication, division, and raising to a fractional power. Examples of such functions are:\n\n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        1\n        \n          /\n        \n        x\n      \n    \n    {\\displaystyle f(x)=1/x}\n  \n\n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        \n          \n            x\n          \n        \n      \n    \n    {\\displaystyle f(x)={\\sqrt {x}}}\n  \n\n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        \n          \n            \n              1\n              +\n              \n                x\n                \n                  3\n                \n              \n            \n            \n              \n                x\n                \n                  3\n                  \n                    /\n                  \n                  7\n                \n              \n              −\n              \n                \n                  7\n                \n              \n              \n                x\n                \n                  1\n                  \n                    /\n                  \n                  3\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle f(x)={\\frac {\\sqrt {1+x^{3}}}{x^{3/7}-{\\sqrt {7}}x^{1/3}}}}\n  \n\nSome algebraic functions, however, cannot be expressed by such finite expressions (this is the Abel–Ruffini theorem). This is the case, for example, for the Bring radical, which is the function implicitly defined by\n\n  \n    \n      \n        f\n        (\n        x\n        \n          )\n          \n            5\n          \n        \n        +\n        f\n        (\n        x\n        )\n        +\n        x\n        =\n        0\n      \n    \n    {\\displaystyle f(x)^{5}+f(x)+x=0}\n  \n.\nIn more precise terms, an algebraic function of degree n in one variable x is a function \n  \n    \n      \n        y\n        =\n        f\n        (\n        x\n        )\n        ,\n      \n    \n    {\\displaystyle y=f(x),}\n  \n that is continuous in its domain and satisfies a polynomial equation of positive degree\n\n  \n    \n      \n        \n          a\n          \n            n\n          \n        \n        (\n        x\n        )\n        \n          y\n          \n            n\n          \n        \n        +\n        \n          a\n          \n            n\n            −\n            1\n          \n        \n        (\n        x\n        )\n        \n          y\n          \n            n\n            −\n            1\n          \n        \n        +\n        ⋯\n        +\n        \n          a\n          \n            0\n          \n        \n        (\n        x\n        )\n        =\n        0\n      \n    \n    {\\displaystyle a_{n}(x)y^{n}+a_{n-1}(x)y^{n-1}+\\cdots +a_{0}(x)=0}\n  \n\nwhere the coefficients ai(x) are polynomial functions of x, with integer coefficients. It can be shown that the same class of functions is obtained if algebraic numbers are accepted for the coefficients of the ai(x)'s. If transcendental numbers occur in the coefficients the function is, in general, not algebraic, but it is algebraic over the field generated by these coefficients.\nThe value of an algebraic function at a rational number, and more generally, at an algebraic number is always an algebraic number.\nSometimes, coefficients \n  \n    \n      \n        \n          a\n          \n            i\n          \n        \n        (\n        x\n        )\n      \n    \n    {\\displaystyle a_{i}(x)}\n  \n that are polynomial over a ring R are considered, and one then talks about \"functions algebraic over R\".\nA function which is not algebraic is called a transcendental function, as it is for example the case of \n  \n    \n      \n        exp\n        ⁡\n        x\n        ,\n        tan\n        ⁡\n        x\n        ,\n        ln\n        ⁡\n        x\n        ,\n        Γ\n        (\n        x\n        )\n      \n    \n    {\\displaystyle \\exp x,\\tan x,\\ln x,\\Gamma (x)}\n  \n. A composition of transcendental functions can give an algebraic function:  \n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        cos\n        ⁡\n        arcsin\n        ⁡\n        x\n        =\n        \n          \n            1\n            −\n            \n              x\n              \n                2\n              \n            \n          \n        \n      \n    \n    {\\displaystyle f(x)=\\cos \\arcsin x={\\sqrt {1-x^{2}}}}\n  \n.\nAs a polynomial equation of degree n has up to n roots (and exactly n roots over an algebraically closed field, such as the complex numbers), a polynomial equation does not implicitly define a single function, but up to n\nfunctions, sometimes also called branches. Consider for example the equation of the unit circle:\n\n  \n    \n      \n        \n          y\n          \n            2\n          \n        \n        +\n        \n          x\n        ",
    "links": [
      "Abel–Ruffini theorem",
      "Addition",
      "Algebraic closure",
      "Algebraic curve",
      "Algebraic expression",
      "Algebraic number",
      "Algebraic numbers",
      "Algebraic operations",
      "Algebraically closed field",
      "Analytic function",
      "Argument principle",
      "Bartel Leendert van der Waerden",
      "Bijection",
      "Binary relation",
      "Boolean-valued function",
      "Boolean function",
      "Branch cut",
      "Bring radical",
      "Casus irreducibilis",
      "Complex-valued function",
      "Complex analysis",
      "Complex function",
      "Complex numbers",
      "Constant function",
      "Continuous function",
      "Cubic formula",
      "David J. Darling",
      "Degree of a polynomial",
      "Discriminant",
      "Division (mathematics)",
      "Domain of a function",
      "Edward Waring",
      "Elementary function",
      "Eric W. Weisstein",
      "Field (mathematics)",
      "Function (mathematics)",
      "Function composition",
      "Function of a complex variable",
      "Function of a real variable",
      "Function of several complex variables",
      "Function of several real variables",
      "Function space",
      "Functor",
      "Fundamental theorem of Galois theory",
      "Fundamental theorem of algebra",
      "Galois group",
      "Generalized function",
      "Higher-order function",
      "History of the function concept",
      "Holomorphic function"
    ],
    "categories": [
      "Category:Algebraic number theory",
      "Category:All articles lacking in-text citations",
      "Category:Analytic functions",
      "Category:Articles lacking in-text citations from June 2023",
      "Category:Articles with short description",
      "Category:Commons category link from Wikidata",
      "Category:Functions and mappings",
      "Category:Meromorphic functions",
      "Category:Polynomials",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Artin–Wedderburn theorem": {
    "title": "Wedderburn–Artin theorem",
    "url": "https://en.wikipedia.org/wiki/Wedderburn%E2%80%93Artin_theorem",
    "summary": "In algebra, the Wedderburn–Artin theorem is a classification theorem for semisimple rings and semisimple algebras.  The theorem states that an (Artinian) semisimple ring R is isomorphic to a product of finitely many ni-by-ni matrix rings over division rings Di, for some integers ni, both of which are uniquely determined up to permutation of the index i.  In particular, any simple left or right Artinian ring is isomorphic to an n-by-n matrix ring over a division ring D, where both n and D are uniquely determined.",
    "content": "In algebra, the Wedderburn–Artin theorem is a classification theorem for semisimple rings and semisimple algebras.  The theorem states that an (Artinian) semisimple ring R is isomorphic to a product of finitely many ni-by-ni matrix rings over division rings Di, for some integers ni, both of which are uniquely determined up to permutation of the index i.  In particular, any simple left or right Artinian ring is isomorphic to an n-by-n matrix ring over a division ring D, where both n and D are uniquely determined.\n\nTheorem\nLet R be a (Artinian) semisimple ring. Then the Wedderburn–Artin theorem states that R is isomorphic to a product of finitely many ni-by-ni matrix rings \n  \n    \n      \n        \n          M\n          \n            \n              n\n              \n                i\n              \n            \n          \n        \n        (\n        \n          D\n          \n            i\n          \n        \n        )\n      \n    \n    {\\displaystyle M_{n_{i}}(D_{i})}\n  \n over division rings Di, for some integers ni, both of which are uniquely determined up to permutation of the index i. \nThere is also a version of the Wedderburn–Artin theorem for algebras over a field k. If R is a finite-dimensional semisimple k-algebra, then each Di in the above statement is a finite-dimensional division algebra over k.  The center of each Di need not be k; it could be a finite extension of k.\nNote that if R is a finite-dimensional simple algebra over a division ring E, D need not be contained in E.  For example, matrix rings over the complex numbers are finite-dimensional simple algebras over the real numbers.\n\nProof\nThere are various proofs of the Wedderburn–Artin theorem. A common modern one takes the following approach.  \nSuppose the ring \n  \n    \n      \n        R\n      \n    \n    {\\displaystyle R}\n  \n is semisimple. Then the right \n  \n    \n      \n        R\n      \n    \n    {\\displaystyle R}\n  \n-module \n  \n    \n      \n        \n          R\n          \n            R\n          \n        \n      \n    \n    {\\displaystyle R_{R}}\n  \n is isomorphic to a finite direct sum of simple modules (which are the same as minimal right ideals of \n  \n    \n      \n        R\n      \n    \n    {\\displaystyle R}\n  \n).  Write this direct sum as\n\n  \n    \n      \n        \n          R\n          \n            R\n          \n        \n        \n        ≅\n        \n        \n          ⨁\n          \n            i\n            =\n            1\n          \n          \n            m\n          \n        \n        \n          I\n          \n            i\n          \n          \n            ⊕\n            \n              n\n              \n                i\n              \n            \n          \n        \n      \n    \n    {\\displaystyle R_{R}\\;\\cong \\;\\bigoplus _{i=1}^{m}I_{i}^{\\oplus n_{i}}}\n  \n\nwhere the \n  \n    \n      \n        \n          I\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle I_{i}}\n  \n are mutually nonisomorphic simple right \n  \n    \n      \n        R\n      \n    \n    {\\displaystyle R}\n  \n-modules, the ith one appearing with multiplicity \n  \n    \n      \n        \n          n\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle n_{i}}\n  \n.  This gives an isomorphism of endomorphism rings\n\n  \n    \n      \n        \n          E\n          n\n          d\n        \n        (\n        \n          R\n          \n            R\n          \n        \n        )\n        \n        ≅\n        \n        \n          ⨁\n          \n            i\n            =\n            1\n          \n          \n            m\n          \n        \n        \n          E\n          n\n          d\n        \n        \n          \n            (\n          \n        \n        \n          I\n          \n            i\n          \n          \n            ⊕\n            \n              n\n              \n                i\n              \n            \n          \n        \n        \n          \n            )\n          \n        \n      \n    \n    {\\displaystyle \\mathrm {End} (R_{R})\\;\\cong \\;\\bigoplus _{i=1}^{m}\\mathrm {End} {\\big (}I_{i}^{\\oplus n_{i}}{\\big )}}\n  \n\nand we can identify \n  \n    \n      \n        \n          E\n          n\n          d\n        \n        \n          \n            (\n          \n        \n        \n          I\n          \n            i\n          \n          \n            ⊕\n            \n              n\n              \n                i\n              \n            \n          \n        \n        \n          \n            )\n          \n        \n      \n    \n    {\\displaystyle \\mathrm {End} {\\big (}I_{i}^{\\oplus n_{i}}{\\big )}}\n  \n with a ring of matrices\n\n  \n    \n      \n        \n          E\n          n\n          d\n        \n        \n          \n            (\n          \n        \n        \n          I\n          \n            i\n          \n          \n            ⊕\n            \n              n\n              \n                i\n              \n            \n          \n        \n        \n          \n            )\n          \n        \n        \n        ≅\n        \n        \n          M\n          \n            \n              n\n              \n   ",
    "links": [
      "Abhandlungen aus dem Mathematischen Seminar der Universität Hamburg",
      "Algebra",
      "Algebraically closed field",
      "Artinian ring",
      "Brauer group",
      "Center (ring theory)",
      "Central simple algebra",
      "Classification theorem",
      "Complex number",
      "Decomposition of a module",
      "Division algebra",
      "Division ring",
      "Doi (identifier)",
      "Emil Artin",
      "Endomorphism",
      "Field (mathematics)",
      "Finite field extension",
      "Hypercomplex number",
      "ISBN (identifier)",
      "Ideal (ring theory)",
      "JFM (identifier)",
      "JSTOR (identifier)",
      "Jacobson density theorem",
      "Jacobson radical",
      "Joseph Wedderburn",
      "Maschke's theorem",
      "Mathematical proof",
      "Matrix (mathematics)",
      "Matrix ring",
      "Opposite algebra",
      "Proceedings of the London Mathematical Society",
      "Product of rings",
      "Real number",
      "Schur's lemma",
      "Semisimple algebra",
      "Semisimple ring",
      "Simple algebra",
      "Simple module",
      "Simple ring",
      "The American Mathematical Monthly"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Short description is different from Wikidata",
      "Category:Theorems in ring theory"
    ]
  },
  "Characteristic (algebra)": {
    "title": "Characteristic (algebra)",
    "url": "https://en.wikipedia.org/wiki/Characteristic_(algebra)",
    "summary": "In mathematics, the characteristic of a ring R, often denoted char(R), is defined to be the smallest positive number of copies of the ring's multiplicative identity (1) that will sum to the additive identity (0). If no such number exists, the ring is said to have characteristic zero. \nThat is, char(R) is the smallest positive number n such that: \n\n  \n    \n      \n        \n          \n            \n              \n                1\n                +\n                ⋯\n                +\n                1\n              \n              ⏟\n            \n          \n          \n            n\n            \n               summands\n            \n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle \\underbrace {1+\\cdots +1} _{n{\\text{ summands}}}=0}\n  \n\nif such a number n exists, and 0 otherwise.",
    "content": "In mathematics, the characteristic of a ring R, often denoted char(R), is defined to be the smallest positive number of copies of the ring's multiplicative identity (1) that will sum to the additive identity (0). If no such number exists, the ring is said to have characteristic zero. \nThat is, char(R) is the smallest positive number n such that: \n\n  \n    \n      \n        \n          \n            \n              \n                1\n                +\n                ⋯\n                +\n                1\n              \n              ⏟\n            \n          \n          \n            n\n            \n               summands\n            \n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle \\underbrace {1+\\cdots +1} _{n{\\text{ summands}}}=0}\n  \n\nif such a number n exists, and 0 otherwise.\n\nMotivation\nThe special definition of the characteristic zero is motivated by the equivalent definitions characterized in the next section, where the characteristic zero is not required to be considered separately.\nThe characteristic may also be taken to be the exponent of the ring's additive group, that is, the smallest positive integer n such that:\n\n  \n    \n      \n        \n          \n            \n              \n                a\n                +\n                ⋯\n                +\n                a\n              \n              ⏟\n            \n          \n          \n            n\n            \n               summands\n            \n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle \\underbrace {a+\\cdots +a} _{n{\\text{ summands}}}=0}\n  \n\nfor every element a of the ring (again, if n exists; otherwise zero). This definition applies in the more general class of rngs (see Ring (mathematics) § Multiplicative identity and the term \"ring\"); for (unital) rings the two definitions are equivalent due to their distributive law.\n\nEquivalent characterizations\nThe characteristic of a ring R is the natural number n such that n\n  \n    \n      \n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} }\n  \n is the kernel of the unique ring homomorphism from \n  \n    \n      \n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} }\n  \n to R.\nThe characteristic is the natural number n such that R contains a subring isomorphic to the factor ring \n  \n    \n      \n        \n          Z\n        \n        \n          /\n        \n        n\n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} /n\\mathbb {Z} }\n  \n, which is the image of the above homomorphism.\nWhen the non-negative integers {0, 1, 2, 3, ...} are partially ordered by divisibility, then 1 is the smallest and 0 is the largest.  Then the characteristic of a ring is the smallest value of n for which n ⋅ 1 = 0. If nothing \"smaller\" (in this ordering) than 0 will suffice, then the characteristic is 0. This is the appropriate partial ordering because of such facts as that char(A × B) is the least common multiple of char A and char B, and that no ring homomorphism f : A → B exists unless char B divides char A.\nThe characteristic of a ring R is n precisely if the statement ka = 0 for all a ∈ R implies that k is a multiple of n.\n\nCase of rings\nIf R and S are rings and there exists a ring homomorphism R → S, then the characteristic of S divides the characteristic of R. This can sometimes be used to exclude the possibility of certain ring homomorphisms. The only ring with characteristic 1 is the zero ring, which has only a single element 0. If a nontrivial ring R does not have any nontrivial zero divisors, then its characteristic is either 0 or prime. In particular, this applies to all fields, to all integral domains, and to all division rings. Any ring of characteristic zero is infinite.\nThe ring \n  \n    \n      \n        \n          Z\n        \n        \n          /\n        \n        n\n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} /n\\mathbb {Z} }\n  \n of integers modulo n has characteristic n. If R is a subring of S, then R and S have the same characteristic. For example, if p is prime and q(X) is an irreducible polynomial with coefficients in the field \n  \n    \n      \n        \n          \n            F\n          \n          \n            p\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {F} _{p}}\n  \n with p elements, then the quotient ring \n  \n    \n      \n        \n          \n            F\n          \n          \n            p\n          \n        \n        [\n        X\n        ]\n        \n          /\n        \n        (\n        q\n        (\n        X\n        )\n        )\n      \n    \n    {\\displaystyle \\mathbb {F} _{p}[X]/(q(X))}\n  \n is a field of characteristic p. Another example: The field \n  \n    \n      \n        \n          C\n        \n      \n    \n    {\\displaystyle \\mathbb {C} }\n  \n of complex numbers contains \n  \n    \n      \n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} }\n  \n, so the characteristic of \n  \n    \n      \n        \n          C\n        \n      \n    \n    {\\displaystyle \\mathb",
    "links": [
      "Additive group",
      "Additive identity",
      "Algebraic closure",
      "Algebraic number field",
      "Category of rings",
      "Category theory",
      "Chelsea Publishing",
      "Complex number",
      "Distributive law",
      "Division ring",
      "Doi (identifier)",
      "Exponent (group theory)",
      "Factor ring",
      "Field (mathematics)",
      "Field extension",
      "Finite field",
      "Finite ring",
      "Formal power series",
      "Freshman's dream",
      "Frobenius homomorphism",
      "ISBN (identifier)",
      "Identity element",
      "Image (mathematics)",
      "Initial object",
      "Injective",
      "Integral domain",
      "Irreducible polynomial",
      "Kernel (ring theory)",
      "Least common multiple",
      "Linear algebra",
      "Mathematics",
      "Modular arithmetic",
      "Natural number",
      "Nicolas Bourbaki",
      "Ordered field",
      "P-adic field",
      "Partially ordered set",
      "Pearson Education",
      "Prime field",
      "Prime number",
      "Quotient ring",
      "Rational fraction",
      "Rational function",
      "Rational number",
      "Real number",
      "Ring (mathematics)",
      "Ring homomorphism",
      "Ring of mixed characteristic",
      "Rng (algebra)",
      "Subring"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Field (mathematics)",
      "Category:Ring theory",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Al-Khwarizmi": {
    "title": "Al-Khwarizmi",
    "url": "https://en.wikipedia.org/wiki/Al-Khwarizmi",
    "summary": "Muhammad ibn Musa al-Khwarizmi c. 780 – c. 850, or simply al-Khwarizmi, was a mathematician active during the Islamic Golden Age, who produced Arabic-language works in mathematics, astronomy, and geography. Around 820, he worked at the House of Wisdom in Baghdad, the contemporary capital city of the Abbasid Caliphate. One of the most prominent scholars of the period, his works were widely influential on later authors, both in the Islamic world and Europe.\nHis popularizing treatise on algebra, compiled between 813 and 833 as Al-Jabr (The Compendious Book on Calculation by Completion and Balancing), presented the first systematic solution of linear and quadratic equations. One of his achievements in algebra was his demonstration of how to solve quadratic equations by completing the square, for which he provided geometric justifications. Because al-Khwarizmi was the first person to treat algebra as an independent discipline and introduced the methods of \"reduction\" and \"balancing\" (the tr",
    "content": "Muhammad ibn Musa al-Khwarizmi c. 780 – c. 850, or simply al-Khwarizmi, was a mathematician active during the Islamic Golden Age, who produced Arabic-language works in mathematics, astronomy, and geography. Around 820, he worked at the House of Wisdom in Baghdad, the contemporary capital city of the Abbasid Caliphate. One of the most prominent scholars of the period, his works were widely influential on later authors, both in the Islamic world and Europe.\nHis popularizing treatise on algebra, compiled between 813 and 833 as Al-Jabr (The Compendious Book on Calculation by Completion and Balancing), presented the first systematic solution of linear and quadratic equations. One of his achievements in algebra was his demonstration of how to solve quadratic equations by completing the square, for which he provided geometric justifications. Because al-Khwarizmi was the first person to treat algebra as an independent discipline and introduced the methods of \"reduction\" and \"balancing\" (the transposition of subtracted terms to the other side of an equation, that is, the cancellation of like terms on opposite sides of the equation), he has been described as the father or founder of algebra. The English term algebra comes from the short-hand title of his aforementioned treatise (الجبر Al-Jabr,  transl. \"completion\" or \"rejoining\"). His name gave rise to the English terms algorism and algorithm; the Spanish, Italian, and Portuguese terms algoritmo; and the Spanish term guarismo and Portuguese term algarismo, all meaning 'digit'.\nIn the 12th century, Latin translations of al-Khwarizmi's textbook on Indian arithmetic (Algorithmo de Numero Indorum), which codified the various Indian numerals, introduced the decimal-based positional number system to the Western world. Likewise, Al-Jabr, translated into Latin by the English scholar Robert of Chester in 1145, was used until the 16th century as the principal mathematical textbook of European universities.\nAl-Khwarizmi revised Geography, the 2nd-century Greek-language treatise by Ptolemy, listing the longitudes and latitudes of cities and localities. He further produced a set of astronomical tables and wrote about calendric works, as well as the astrolabe and the sundial. Al-Khwarizmi made important contributions to trigonometry, producing accurate sine and cosine tables.\n\nLife\nFew details of al-Khwārizmī's life are known with certainty. Ibn al-Nadim gives his birthplace as Khwarazm, and he is generally thought to have come from this region. He was of Persian stock; his name means 'from Khwarazm', a region that was part of Greater Iran, and is now part of Turkmenistan and Uzbekistan.\nAl-Tabari gives his name as Muḥammad ibn Musá al-Khwārizmī al-Majūsī al-Quṭrubbullī (محمد بن موسى الخوارزميّ المجوسـيّ القطربّـليّ). The epithet al-Qutrubbulli could indicate he might instead have come from Qutrubbul (Qatrabbul), near Baghdad. However, Roshdi Rashed denies this:\n\nThere is no need to be an expert on the period or a philologist to see that al-Tabari's second citation should read \"Muhammad ibn Mūsa al-Khwārizmī and al-Majūsi al-Qutrubbulli,\" and that there are two people (al-Khwārizmī and al-Majūsi al-Qutrubbulli) between whom the letter wa [Arabic 'و' for the conjunction 'and'] has been omitted in an early copy. This would not be worth mentioning if a series of errors concerning the personality of al-Khwārizmī, occasionally even the origins of his knowledge, had not been made. Recently, G.J. Toomer ... with naive confidence constructed an entire fantasy on the error which cannot be denied the merit of amusing the reader.\nOn the other hand, David A. King affirms his nisba to Qutrubul, noting that he was called al-Khwārizmī al-Qutrubbulli because he was born just outside of Baghdad.\nRegarding al-Khwārizmī's religion, Toomer writes:\n\nAnother epithet given to him by al-Ṭabarī, \"al-Majūsī,\" would seem to indicate that he was an adherent of the old Zoroastrian religion. This would still have been possible at that time for a man of Iranian origin, but the pious preface to al-Khwārizmī's Algebra shows that he was an orthodox Muslim, so al-Ṭabarī's epithet could mean no more than that his forebears, and perhaps he in his youth, had been Zoroastrians.\nIbn al-Nadīm's Al-Fihrist includes a short biography on al-Khwārizmī together with a list of his books. Al-Khwārizmī accomplished most of his work between 813 and 833. After the Muslim conquest of Persia, Baghdad had become the centre of scientific studies and trade. Around 820 CE, he was appointed as the astronomer and head of the library of the House of Wisdom. The House of Wisdom was established by the Abbasid Caliph al-Ma'mūn. Al-Khwārizmī studied sciences and mathematics, including the translation of Greek and Sanskrit scientific manuscripts. He was also a historian who is cited by the likes of al-Tabari and Ibn Abi Tahir.\nDuring the reign of al-Wathiq, he is said to have been involved in the first of two embassies to the Khazars. Douglas ",
    "links": [
      "'Abd al-'Aziz al-Wafa'i",
      "'Abd al-Hamīd ibn Turk",
      "11156 Al-Khwarismi",
      "13498 Al Chwarizmi",
      "Abbasid Caliphate",
      "Abd-al-Razzāq Samarqandī",
      "Abd al-Rahman al-Jadiri",
      "Abd al-Rahman al-Sufi",
      "Abd al‐Wajid",
      "Abdullah Ansari",
      "Abolfadl Harawi",
      "Abu'l-Fadl Bayhaqi",
      "Abu'l-Fida",
      "Abu'l-Hasan Isfarayini",
      "Abu'l-Hasan al-Uqlidisi",
      "Abu'l-Hasan ibn Ali al-Qalasadi",
      "Abu'l-Ma'ali Nasrallah",
      "Abu'l Abbas al-Hijazi",
      "Abu-Mahmud Khojandi",
      "Abu 'Ubayd al-Juzjani",
      "Abu Ali Bal'ami",
      "Abu Ali al-Hasan al-Marrakushi",
      "Abu Ali al-Khayyat",
      "Abu Bakr al-Hassar",
      "Abu Dawud al-Sijistani",
      "Abu Hafs Umar al-Nasafi",
      "Abu Hanifa",
      "Abu Hanifa Dinawari",
      "Abu Ishaq al-Kubunani",
      "Abu Ja'far al-Khazin",
      "Abu Kamil",
      "Abu Ma'shar al-Balkhi",
      "Abu Mansur al-Baghdadi",
      "Abu Mansur al-Maturidi",
      "Abu Muhammad al-Hasan al-Hamdani",
      "Abu Muqri Mohammed al-Battiwi",
      "Abu Muslim",
      "Abu Nasr Mansur",
      "Abu Sa'id Abu'l-Khayr",
      "Abu Sahl al-Quhi",
      "Abu Said Gorgani",
      "Abu Saʿīd Gardēzī",
      "Abu Sulayman Sijistani",
      "Abu Zayd al-Balkhi",
      "Abu Zayd al-Dabusi",
      "Abu al-Abbas Iranshahri",
      "Abu al-Barakat al-Nasafi",
      "Abu al-Hasan al-Ahwazi",
      "Abu al-Hassan al-Amiri",
      "Abu al-Jud"
    ],
    "categories": [
      "Category:780s births",
      "Category:850 deaths",
      "Category:8th-century Arabic-language writers",
      "Category:8th-century Iranian astronomers",
      "Category:8th-century astrologers",
      "Category:8th-century people from the Abbasid Caliphate",
      "Category:9th-century Arabic-language writers",
      "Category:9th-century Iranian astronomers",
      "Category:9th-century Iranian mathematicians",
      "Category:9th-century astrologers"
    ]
  },
  "Abstract differential equation": {
    "title": "Abstract differential equation",
    "url": "https://en.wikipedia.org/wiki/Abstract_differential_equation",
    "summary": "In mathematics, an abstract differential equation is a differential equation in which the unknown function and its derivatives take values in some generic abstract space (a Hilbert space, a Banach space, etc.). Equations of this kind arise e.g. in the study of partial differential equations: if to one of the variables is given a privileged position (e.g. time, in heat or wave equations) and all the others are put together, an ordinary \"differential\" equation with respect to the variable which was put in evidence is obtained. Adding boundary conditions can often be translated in terms of considering solutions in some convenient function spaces.\nThe classical abstract differential equation which is most frequently encountered is the equation \n\n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              u\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n   ",
    "content": "In mathematics, an abstract differential equation is a differential equation in which the unknown function and its derivatives take values in some generic abstract space (a Hilbert space, a Banach space, etc.). Equations of this kind arise e.g. in the study of partial differential equations: if to one of the variables is given a privileged position (e.g. time, in heat or wave equations) and all the others are put together, an ordinary \"differential\" equation with respect to the variable which was put in evidence is obtained. Adding boundary conditions can often be translated in terms of considering solutions in some convenient function spaces.\nThe classical abstract differential equation which is most frequently encountered is the equation \n\n  \n    \n      \n        \n          \n            \n              \n                d\n              \n              u\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        A\n        u\n        +\n        f\n      \n    \n    {\\displaystyle {\\frac {\\mathrm {d} u}{\\mathrm {d} t}}=Au+f}\n  \n\nwhere the unknown function \n  \n    \n      \n        u\n        =\n        u\n        (\n        t\n        )\n      \n    \n    {\\displaystyle u=u(t)}\n  \n belongs to some function space \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n, \n  \n    \n      \n        0\n        ≤\n        t\n        ≤\n        T\n        ≤\n        ∞\n      \n    \n    {\\displaystyle 0\\leq t\\leq T\\leq \\infty }\n  \n and \n  \n    \n      \n        A\n        :\n        X\n        →\n        X\n      \n    \n    {\\displaystyle A:X\\to X}\n  \n is an operator (usually a linear operator) acting on this space. An exhaustive treatment of the homogeneous (\n  \n    \n      \n        f\n        =\n        0\n      \n    \n    {\\displaystyle f=0}\n  \n) case with a constant operator is given by the theory of C0-semigroups. Very often, the study of other abstract differential equations amounts (by e.g. reduction to a set of equations of the first order) to the study of this equation.\nThe theory of abstract differential equations has been founded by Einar Hille in several papers and in his book Functional Analysis and Semi-Groups. Other main contributors were Kōsaku Yosida, Ralph Phillips, Isao Miyadera, and Selim Grigorievich Krein.\n\nAbstract Cauchy problem\nDefinition\nLet \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n and \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  \n be two linear operators, with domains \n  \n    \n      \n        D\n        (\n        A\n        )\n      \n    \n    {\\displaystyle D(A)}\n  \n and \n  \n    \n      \n        D\n        (\n        B\n        )\n      \n    \n    {\\displaystyle D(B)}\n  \n, acting in a Banach space \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n. A function \n  \n    \n      \n        u\n        (\n        t\n        )\n        :\n        [\n        0\n        ,\n        T\n        ]\n        →\n        X\n      \n    \n    {\\displaystyle u(t):[0,T]\\to X}\n  \n is said to have strong derivative (or to be Frechet differentiable or simply differentiable) at the point \n  \n    \n      \n        \n          t\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle t_{0}}\n  \n if there exists an element \n  \n    \n      \n        y\n        ∈\n        X\n      \n    \n    {\\displaystyle y\\in X}\n  \n such that\n\n  \n    \n      \n        \n          lim\n          \n            h\n            →\n            0\n          \n        \n        \n          ‖\n          \n            \n              \n                \n                  u\n                  (\n                  \n                    t\n                    \n                      0\n                    \n                  \n                  +\n                  h\n                  )\n                  −\n                  u\n                  (\n                  \n                    t\n                    \n                      0\n                    \n                  \n                  )\n                \n                h\n              \n            \n            −\n            y\n          \n          ‖\n        \n        =\n        0\n      \n    \n    {\\displaystyle \\lim _{h\\to 0}\\left\\|{\\frac {u(t_{0}+h)-u(t_{0})}{h}}-y\\right\\|=0}\n  \n\nand its derivative is \n  \n    \n      \n        \n          u\n          ′\n        \n        (\n        \n          t\n          \n            0\n          \n        \n        )\n        =\n        y\n      \n    \n    {\\displaystyle u'(t_{0})=y}\n  \n.\nA solution of the equation\n\n  \n    \n      \n        B\n        \n          \n            \n              \n                d\n              \n              u\n            \n            \n              \n                d\n              \n              t\n            \n          \n        \n        =\n        A\n        u\n      \n    \n    {\\displaystyle B{\\frac {\\mathrm {d} u}{\\mathrm {d} t}}=Au}\n  \n\nis a function \n  \n    \n      \n        u\n        (\n        t\n        )\n        :\n        [\n        0\n        ,\n        ∞\n        )\n        →\n        D\n       ",
    "links": [
      "Analytic semigroup",
      "Banach space",
      "Bochner integral",
      "Boundary condition",
      "Bounded operator",
      "C0-semigroup",
      "Cauchy problem",
      "Closed operator",
      "Dense set",
      "Differential equation",
      "Einar Hille",
      "Frechet derivative",
      "Function (mathematics)",
      "Function space",
      "Heat equation",
      "ISBN (identifier)",
      "Jacques Hadamard",
      "Kōsaku Yosida",
      "Linear operator",
      "Mathematics",
      "Operator (mathematics)",
      "Partial differential equation",
      "Quasicontraction semigroup",
      "Ralph S. Phillips",
      "Strong operator topology",
      "Wave equation",
      "Well-posed problem"
    ],
    "categories": [
      "Category:Functional analysis"
    ]
  },
  "Autonomous differential equation": {
    "title": "Autonomous system (mathematics)",
    "url": "https://en.wikipedia.org/wiki/Autonomous_system_(mathematics)",
    "summary": "In mathematics, an autonomous system or autonomous differential equation is a system of ordinary differential equations which does not explicitly depend on the independent variable. When the variable is time, they are also called time-invariant systems.\nMany laws in physics, where the independent variable is usually assumed to be time, are expressed as autonomous systems because it is assumed the laws of nature which hold now are identical to those for any point in the past or future.",
    "content": "In mathematics, an autonomous system or autonomous differential equation is a system of ordinary differential equations which does not explicitly depend on the independent variable. When the variable is time, they are also called time-invariant systems.\nMany laws in physics, where the independent variable is usually assumed to be time, are expressed as autonomous systems because it is assumed the laws of nature which hold now are identical to those for any point in the past or future.\n\nDefinition\nAn autonomous system is a system of ordinary differential equations of the form\n\n  \n    \n      \n        \n          \n            d\n            \n              d\n              t\n            \n          \n        \n        x\n        (\n        t\n        )\n        =\n        f\n        (\n        x\n        (\n        t\n        )\n        )\n      \n    \n    {\\displaystyle {\\frac {d}{dt}}x(t)=f(x(t))}\n  \n\nwhere x takes values in n-dimensional Euclidean space; t is often interpreted as time.\nIt is distinguished from systems of differential equations of the form\n\n  \n    \n      \n        \n          \n            d\n            \n              d\n              t\n            \n          \n        \n        x\n        (\n        t\n        )\n        =\n        g\n        (\n        x\n        (\n        t\n        )\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle {\\frac {d}{dt}}x(t)=g(x(t),t)}\n  \n\nin which the law governing the evolution of the system does not depend solely on the system's current state but also the parameter t, again often interpreted as time; such systems are by definition not autonomous.\n\nProperties\nSolutions are invariant under horizontal translations:\nLet \n  \n    \n      \n        \n          x\n          \n            1\n          \n        \n        (\n        t\n        )\n      \n    \n    {\\displaystyle x_{1}(t)}\n  \n be a unique solution of the initial value problem for an autonomous system \n\n  \n    \n      \n        \n          \n            d\n            \n              d\n              t\n            \n          \n        \n        x\n        (\n        t\n        )\n        =\n        f\n        (\n        x\n        (\n        t\n        )\n        )\n        \n        ,\n        \n        x\n        (\n        0\n        )\n        =\n        \n          x\n          \n            0\n          \n        \n        .\n      \n    \n    {\\displaystyle {\\frac {d}{dt}}x(t)=f(x(t))\\,,\\quad x(0)=x_{0}.}\n  \n\nThen \n  \n    \n      \n        \n          x\n          \n            2\n          \n        \n        (\n        t\n        )\n        =\n        \n          x\n          \n            1\n          \n        \n        (\n        t\n        −\n        \n          t\n          \n            0\n          \n        \n        )\n      \n    \n    {\\displaystyle x_{2}(t)=x_{1}(t-t_{0})}\n  \n solves\n\n  \n    \n      \n        \n          \n            d\n            \n              d\n              t\n            \n          \n        \n        x\n        (\n        t\n        )\n        =\n        f\n        (\n        x\n        (\n        t\n        )\n        )\n        \n        ,\n        \n        x\n        (\n        \n          t\n          \n            0\n          \n        \n        )\n        =\n        \n          x\n          \n            0\n          \n        \n        .\n      \n    \n    {\\displaystyle {\\frac {d}{dt}}x(t)=f(x(t))\\,,\\quad x(t_{0})=x_{0}.}\n  \n\nDenoting \n  \n    \n      \n        s\n        =\n        t\n        −\n        \n          t\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle s=t-t_{0}}\n  \n gets \n  \n    \n      \n        \n          x\n          \n            1\n          \n        \n        (\n        s\n        )\n        =\n        \n          x\n          \n            2\n          \n        \n        (\n        t\n        )\n      \n    \n    {\\displaystyle x_{1}(s)=x_{2}(t)}\n  \n and \n  \n    \n      \n        d\n        s\n        =\n        d\n        t\n      \n    \n    {\\displaystyle ds=dt}\n  \n, thus \n\n  \n    \n      \n        \n          \n            d\n            \n              d\n              t\n            \n          \n        \n        \n          x\n          \n            2\n          \n        \n        (\n        t\n        )\n        =\n        \n          \n            d\n            \n              d\n              t\n            \n          \n        \n        \n          x\n          \n            1\n          \n        \n        (\n        t\n        −\n        \n          t\n          \n            0\n          \n        \n        )\n        =\n        \n          \n            d\n            \n              d\n              s\n            \n          \n        \n        \n          x\n          \n            1\n          \n        \n        (\n        s\n        )\n        =\n        f\n        (\n        \n          x\n          \n            1\n          \n        \n        (\n        s\n        )\n        )\n        =\n        f\n        (\n        \n          x\n          \n            2\n          \n        \n        (\n        t\n        )\n        )\n        .\n      \n    \n    {\\displaystyle {\\frac {d}{dt}}x_{2}(t)={\\frac {d}{dt}}x_{1}(t-t_{0})={\\frac {d}{ds}}x_{1}(s",
    "links": [
      "Analytical function",
      "Asymptotic stability",
      "Augustin-Louis Cauchy",
      "Carathéodory's existence theorem",
      "Carl David Tolmé Runge",
      "Cauchy–Kowalevski theorem",
      "Chain rule",
      "Chaos theory",
      "Classical mechanics",
      "Crank–Nicolson method",
      "Delay differential equation",
      "Dependent and independent variables",
      "Difference equation",
      "Differential-algebraic system of equations",
      "Differential equation",
      "Differential operator",
      "Dirac delta function",
      "Division by zero",
      "Doi (identifier)",
      "Equilibrium point",
      "Eqworld",
      "Ernst Leonard Lindelöf",
      "Euclidean space",
      "Euler method",
      "Exact differential equation",
      "Exponential stability",
      "Finite difference method",
      "Finite element method",
      "Finite volume method",
      "Fractional differential equations",
      "GNU Octave",
      "Galerkin method",
      "Gottfried Wilhelm Leibniz",
      "Hamiltonian system",
      "Holonomic function",
      "Homogeneous differential equation",
      "ISBN (identifier)",
      "Independent variable",
      "Initial condition",
      "Initial value problem",
      "Integral",
      "Integral transform",
      "Integrating factor",
      "Integration by substitution",
      "Integro-differential equation",
      "Isaac Newton",
      "Isocline",
      "Jacob Bernoulli",
      "Jet bundle",
      "John Crank"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Dynamical systems",
      "Category:Ordinary differential equations",
      "Category:Short description is different from Wikidata",
      "Category:Wikipedia articles needing clarification from October 2024"
    ]
  },
  "Bernoulli differential equation": {
    "title": "Bernoulli differential equation",
    "url": "https://en.wikipedia.org/wiki/Bernoulli_differential_equation",
    "summary": "In mathematics, an ordinary differential equation is called a Bernoulli differential equation if it is of the form\n\n  \n    \n      \n        \n          y\n          ′\n        \n        +\n        P\n        (\n        x\n        )\n        y\n        =\n        Q\n        (\n        x\n        )\n        \n          y\n          \n            n\n          \n        \n        ,\n      \n    \n    {\\displaystyle y'+P(x)y=Q(x)y^{n},}\n  \n\nwhere \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n is a real number. Some authors allow any real \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n, whereas others require that \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n not be 0 or 1. The equation was first discussed in a work of 1695 by Jacob Bernoulli, after whom it is named. The earliest solution, however, was offered by  Gottfried Leibniz, who published his result in the same year and whose method is the one still used today.\nBernoulli equations are special because they ar",
    "content": "In mathematics, an ordinary differential equation is called a Bernoulli differential equation if it is of the form\n\n  \n    \n      \n        \n          y\n          ′\n        \n        +\n        P\n        (\n        x\n        )\n        y\n        =\n        Q\n        (\n        x\n        )\n        \n          y\n          \n            n\n          \n        \n        ,\n      \n    \n    {\\displaystyle y'+P(x)y=Q(x)y^{n},}\n  \n\nwhere \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n is a real number. Some authors allow any real \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n, whereas others require that \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n not be 0 or 1. The equation was first discussed in a work of 1695 by Jacob Bernoulli, after whom it is named. The earliest solution, however, was offered by  Gottfried Leibniz, who published his result in the same year and whose method is the one still used today.\nBernoulli equations are special because they are nonlinear differential equations with known exact solutions. A notable special case of the Bernoulli equation is the logistic differential equation.\n\nTransformation to a linear differential equation\nWhen \n  \n    \n      \n        n\n        =\n        0\n      \n    \n    {\\displaystyle n=0}\n  \n, the differential equation is linear. When \n  \n    \n      \n        n\n        =\n        1\n      \n    \n    {\\displaystyle n=1}\n  \n, it is separable.  In these cases, standard techniques for solving equations of those forms can be applied.  For \n  \n    \n      \n        n\n        ≠\n        0\n      \n    \n    {\\displaystyle n\\neq 0}\n  \n and \n  \n    \n      \n        n\n        ≠\n        1\n      \n    \n    {\\displaystyle n\\neq 1}\n  \n, the substitution \n  \n    \n      \n        u\n        =\n        \n          y\n          \n            1\n            −\n            n\n          \n        \n      \n    \n    {\\displaystyle u=y^{1-n}}\n  \n reduces any Bernoulli equation to a linear differential equation\n\n  \n    \n      \n        \n          \n            \n              d\n              u\n            \n            \n              d\n              x\n            \n          \n        \n        −\n        (\n        n\n        −\n        1\n        )\n        P\n        (\n        x\n        )\n        u\n        =\n        −\n        (\n        n\n        −\n        1\n        )\n        Q\n        (\n        x\n        )\n        .\n      \n    \n    {\\displaystyle {\\frac {du}{dx}}-(n-1)P(x)u=-(n-1)Q(x).}\n  \n\nFor example, in the case \n  \n    \n      \n        n\n        =\n        2\n      \n    \n    {\\displaystyle n=2}\n  \n, making the substitution \n  \n    \n      \n        u\n        =\n        \n          y\n          \n            −\n            1\n          \n        \n      \n    \n    {\\displaystyle u=y^{-1}}\n  \n in the differential equation \n  \n    \n      \n        \n          \n            \n              d\n              y\n            \n            \n              d\n              x\n            \n          \n        \n        +\n        \n          \n            1\n            x\n          \n        \n        y\n        =\n        x\n        \n          y\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle {\\frac {dy}{dx}}+{\\frac {1}{x}}y=xy^{2}}\n  \n produces the equation \n  \n    \n      \n        \n          \n            \n              d\n              u\n            \n            \n              d\n              x\n            \n          \n        \n        −\n        \n          \n            1\n            x\n          \n        \n        u\n        =\n        −\n        x\n      \n    \n    {\\displaystyle {\\frac {du}{dx}}-{\\frac {1}{x}}u=-x}\n  \n, which is a linear differential equation.\n\nSolution\nLet \n  \n    \n      \n        \n          x\n          \n            0\n          \n        \n        ∈\n        (\n        a\n        ,\n        b\n        )\n      \n    \n    {\\displaystyle x_{0}\\in (a,b)}\n  \n and\n\n  \n    \n      \n        \n          \n            {\n            \n              \n                \n                  z\n                  :\n                  (\n                  a\n                  ,\n                  b\n                  )\n                  →\n                  (\n                  0\n                  ,\n                  ∞\n                  )\n                  ,\n                \n                \n                  \n                    if \n                  \n                  α\n                  ∈\n                  \n                    R\n                  \n                  ∖\n                  {\n                  1\n                  ,\n                  2\n                  }\n                  ,\n                \n              \n              \n                \n                  z\n                  :\n                  (\n                  a\n                  ,\n                  b\n                  )\n                  →\n                  \n                    R\n                  \n                  ∖\n                  {\n                  0\n                  }\n                  ,\n                \n                \n                  \n            ",
    "links": [
      "Acta Eruditorum",
      "American Mathematical Society",
      "Applied mathematics",
      "Astronomy",
      "Asymptotic stability",
      "Augustin-Louis Cauchy",
      "Autonomous differential equation",
      "Biology",
      "Boundary value problem",
      "Carathéodory's existence theorem",
      "Carl David Tolmé Runge",
      "Cauchy problem",
      "Cauchy–Kowalevski theorem",
      "Cengage Learning",
      "Chain rule",
      "Chaos theory",
      "Chemistry",
      "Continuum mechanics",
      "Crank–Nicolson method",
      "Delay differential equation",
      "Dependent and independent variables",
      "Derivative",
      "Difference equation",
      "Differential-algebraic system of equations",
      "Differential equation",
      "Differential operator",
      "Dirac delta function",
      "Dirichlet boundary condition",
      "Dynamical systems",
      "EISSN (identifier)",
      "Economics",
      "Encyclopedia of Mathematics",
      "Engineering",
      "Ernst Lindelöf",
      "Euler method",
      "European Mathematical Society",
      "Exact differential equation",
      "Exponential response formula",
      "Exponential stability",
      "Finite difference method",
      "Finite element method",
      "Finite volume method",
      "Fractional differential equations",
      "Galerkin method",
      "Geology",
      "George Green (mathematician)",
      "Gerald Teschl",
      "Gottfried Leibniz",
      "Gottfried Wilhelm Leibniz",
      "Graduate Studies in Mathematics"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Ordinary differential equations",
      "Category:Short description matches Wikidata"
    ]
  },
  "Carathéodory's existence theorem": {
    "title": "Carathéodory's existence theorem",
    "url": "https://en.wikipedia.org/wiki/Carath%C3%A9odory%27s_existence_theorem",
    "summary": "In mathematics, Carathéodory's existence theorem says that an ordinary differential equation has a solution under relatively mild conditions. It is a generalization of Peano's existence theorem. Peano's theorem requires that the right-hand side of the differential equation be continuous, while Carathéodory's theorem shows existence of solutions (in a more general sense) for some discontinuous equations. The theorem is named after Constantin Carathéodory.",
    "content": "In mathematics, Carathéodory's existence theorem says that an ordinary differential equation has a solution under relatively mild conditions. It is a generalization of Peano's existence theorem. Peano's theorem requires that the right-hand side of the differential equation be continuous, while Carathéodory's theorem shows existence of solutions (in a more general sense) for some discontinuous equations. The theorem is named after Constantin Carathéodory.\n\nIntroduction\nConsider the differential equation\n\n  \n    \n      \n        \n          y\n          ′\n        \n        (\n        t\n        )\n        =\n        f\n        (\n        t\n        ,\n        y\n        (\n        t\n        )\n        )\n      \n    \n    {\\displaystyle y'(t)=f(t,y(t))}\n  \n\nwith initial condition\n\n  \n    \n      \n        y\n        (\n        \n          t\n          \n            0\n          \n        \n        )\n        =\n        \n          y\n          \n            0\n          \n        \n        ,\n      \n    \n    {\\displaystyle y(t_{0})=y_{0},}\n  \n\nwhere the function ƒ is defined on a rectangular domain of the form\n\n  \n    \n      \n        R\n        =\n        {\n        (\n        t\n        ,\n        y\n        )\n        ∈\n        \n          R\n        \n        ×\n        \n          \n            R\n          \n          \n            n\n          \n        \n        \n        :\n        \n        \n          |\n        \n        t\n        −\n        \n          t\n          \n            0\n          \n        \n        \n          |\n        \n        ≤\n        a\n        ,\n        \n          |\n        \n        y\n        −\n        \n          y\n          \n            0\n          \n        \n        \n          |\n        \n        ≤\n        b\n        }\n        .\n      \n    \n    {\\displaystyle R=\\{(t,y)\\in \\mathbf {R} \\times \\mathbf {R} ^{n}\\,:\\,|t-t_{0}|\\leq a,|y-y_{0}|\\leq b\\}.}\n  \n\nPeano's existence theorem states that if ƒ is continuous, then the differential equation has at least one solution in a neighbourhood of the initial condition.\nHowever, it is also possible to consider differential equations with a discontinuous right-hand side, like the equation\n\n  \n    \n      \n        \n          y\n          ′\n        \n        (\n        t\n        )\n        =\n        H\n        (\n        t\n        )\n        ,\n        \n        y\n        (\n        0\n        )\n        =\n        0\n        ,\n      \n    \n    {\\displaystyle y'(t)=H(t),\\quad y(0)=0,}\n  \n\nwhere H denotes the Heaviside function defined by\n\n  \n    \n      \n        H\n        (\n        t\n        )\n        =\n        \n          \n            {\n            \n              \n                \n                  0\n                  ,\n                \n                \n                  \n                    if \n                  \n                  t\n                  ≤\n                  0\n                  ;\n                \n              \n              \n                \n                  1\n                  ,\n                \n                \n                  \n                    if \n                  \n                  t\n                  >\n                  0.\n                \n              \n            \n            \n          \n        \n      \n    \n    {\\displaystyle H(t)={\\begin{cases}0,&{\\text{if }}t\\leq 0;\\\\1,&{\\text{if }}t>0.\\end{cases}}}\n  \n\nIt makes sense to consider the ramp function\n\n  \n    \n      \n        y\n        (\n        t\n        )\n        =\n        \n          ∫\n          \n            0\n          \n          \n            t\n          \n        \n        H\n        (\n        s\n        )\n        \n        \n          d\n        \n        s\n        =\n        \n          \n            {\n            \n              \n                \n                  0\n                  ,\n                \n                \n                  \n                    if \n                  \n                  t\n                  ≤\n                  0\n                  ;\n                \n              \n              \n                \n                  t\n                  ,\n                \n                \n                  \n                    if \n                  \n                  t\n                  >\n                  0\n                \n              \n            \n            \n          \n        \n      \n    \n    {\\displaystyle y(t)=\\int _{0}^{t}H(s)\\,\\mathrm {d} s={\\begin{cases}0,&{\\text{if }}t\\leq 0;\\\\t,&{\\text{if }}t>0\\end{cases}}}\n  \n\nas a solution of the differential equation. Strictly speaking though, it does not satisfy the differential equation at \n  \n    \n      \n        t\n        =\n        0\n      \n    \n    {\\displaystyle t=0}\n  \n, because the function is not differentiable there. This suggests that the idea of a solution be extended to allow for solutions that are not everywhere differentiable, thus motivating the following definition.\nA function y is called a solution in the extended sense of the differential equation \n  \n    \n      \n        \n          y\n          ′\n        \n        =\n        f\n        (\n        t\n        ,\n        y\n        )\n      \n    \n  ",
    "links": [
      "Absolute continuity",
      "Almost everywhere",
      "Applied mathematics",
      "Astronomy",
      "Asymptotic stability",
      "Augustin-Louis Cauchy",
      "Autonomous differential equation",
      "Biology",
      "Boundary value problem",
      "Carathéodory's theorem (disambiguation)",
      "Carl David Tolmé Runge",
      "Cauchy problem",
      "Cauchy–Kowalevski theorem",
      "Chaos theory",
      "Chemistry",
      "Constantin Carathéodory",
      "Continuous function",
      "Continuum mechanics",
      "Crank–Nicolson method",
      "Delay differential equation",
      "Dependent and independent variables",
      "Difference equation",
      "Differential-algebraic system of equations",
      "Differential equation",
      "Differential operator",
      "Dirac delta function",
      "Dirichlet boundary condition",
      "Dynamical systems",
      "Economics",
      "Engineering",
      "Ernst Lindelöf",
      "Euler method",
      "Exact differential equation",
      "Exponential response formula",
      "Exponential stability",
      "Finite difference method",
      "Finite element method",
      "Finite volume method",
      "Fractional differential equations",
      "Galerkin method",
      "Geology",
      "George Green (mathematician)",
      "Gottfried Leibniz",
      "Green's function",
      "Heaviside function",
      "Homogeneous differential equation",
      "ISBN (identifier)",
      "Infinite element method",
      "Initial condition",
      "Integral transform"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Ordinary differential equations",
      "Category:Short description is different from Wikidata",
      "Category:Theorems in mathematical analysis"
    ]
  },
  "Cauchy–Kowalevski theorem": {
    "title": "Cauchy–Kovalevskaya theorem",
    "url": "https://en.wikipedia.org/wiki/Cauchy%E2%80%93Kovalevskaya_theorem",
    "summary": "In mathematics, the Cauchy–Kovalevskaya theorem (also written as the Cauchy–Kowalevski theorem) is the main local existence and uniqueness theorem for analytic partial differential equations associated with Cauchy initial value problems. A special case was proven by Augustin Cauchy (1842), and the full result by Sofya Kovalevskaya (1874).",
    "content": "In mathematics, the Cauchy–Kovalevskaya theorem (also written as the Cauchy–Kowalevski theorem) is the main local existence and uniqueness theorem for analytic partial differential equations associated with Cauchy initial value problems. A special case was proven by Augustin Cauchy (1842), and the full result by Sofya Kovalevskaya (1874).\n\nFirst order Cauchy–Kovalevskaya theorem\nThis theorem is about the existence of solutions to a system of m differential equations in n dimensions when the coefficients are analytic functions. The theorem and its proof are valid for analytic functions of either real or complex variables.\nLet K denote the field of real or of complex numbers, and let V = Km and W = Kn. Let A1, ..., An−1 be analytic functions defined on some neighbourhood of (0, 0) in W × V and taking values in the m × m matrices, and let b be an analytic function with values in V defined on the same neighbourhood. Then there is a neighbourhood of 0 in W on which the quasilinear Cauchy problem\n\n  \n    \n      \n        \n          ∂\n          \n            \n              x\n              \n                n\n              \n            \n          \n        \n        f\n        =\n        \n          A\n          \n            1\n          \n        \n        (\n        x\n        ,\n        f\n        )\n        \n          ∂\n          \n            \n              x\n              \n                1\n              \n            \n          \n        \n        f\n        +\n        ⋯\n        +\n        \n          A\n          \n            n\n            −\n            1\n          \n        \n        (\n        x\n        ,\n        f\n        )\n        \n          ∂\n          \n            \n              x\n              \n                n\n                −\n                1\n              \n            \n          \n        \n        f\n        +\n        b\n        (\n        x\n        ,\n        f\n        )\n      \n    \n    {\\displaystyle \\partial _{x_{n}}f=A_{1}(x,f)\\partial _{x_{1}}f+\\cdots +A_{n-1}(x,f)\\partial _{x_{n-1}}f+b(x,f)}\n  \n\nwith initial condition\n\n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        0\n      \n    \n    {\\displaystyle f(x)=0}\n  \n\non the hypersurface\n\n  \n    \n      \n        \n          x\n          \n            n\n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle x_{n}=0}\n  \n\nhas a unique analytic solution ƒ : W → V near 0.\nLewy's example shows that the theorem is not more generally valid for all smooth functions.\nThe theorem can also be stated in abstract (real or complex) vector spaces. Let V and W be finite-dimensional real or complex vector spaces, with n = dim W. Let A1, ..., An−1 be analytic functions with values in End (V) and b an analytic function with values in V, defined on some neighbourhood of (0, 0) in W × V. In this case, the same result holds.\n\nProof by analytic majorization\nBoth sides of the partial differential equation can be expanded as formal power series and give recurrence relations for the coefficients of the formal power series for f that uniquely determine the coefficients. The Taylor series coefficients of the Ai's and b are majorized in matrix and vector norm by a simple scalar rational analytic function. The corresponding scalar Cauchy problem involving this function instead of the Ai's and b has an explicit local analytic solution. The absolute values of its coefficients majorize the norms of those of the original problem; so the formal power series solution must converge\nwhere the scalar solution converges.\n\nHigher-order Cauchy–Kovalevskaya theorem\nIf F and fj are analytic functions near 0, then the non-linear Cauchy problem\n\n  \n    \n      \n        \n          ∂\n          \n            t\n          \n          \n            k\n          \n        \n        h\n        =\n        F\n        \n          (\n          \n            x\n            ,\n            t\n            ,\n            \n              ∂\n              \n                t\n              \n              \n                j\n              \n            \n            \n            \n              ∂\n              \n                x\n              \n              \n                α\n              \n            \n            h\n          \n          )\n        \n        ,\n        \n           where \n        \n        j\n        <\n        k\n        \n           and \n        \n        \n          |\n        \n        α\n        \n          |\n        \n        +\n        j\n        ≤\n        k\n        ,\n      \n    \n    {\\displaystyle \\partial _{t}^{k}h=F\\left(x,t,\\partial _{t}^{j}\\,\\partial _{x}^{\\alpha }h\\right),{\\text{ where }}j<k{\\text{ and }}|\\alpha |+j\\leq k,}\n  \n\nwith initial conditions\n\n  \n    \n      \n        \n          ∂\n          \n            t\n          \n          \n            j\n          \n        \n        h\n        (\n        x\n        ,\n        0\n        )\n        =\n        \n          f\n          \n            j\n          \n        \n        (\n        x\n        )\n        ,\n        \n        0\n        ≤\n        j\n        <\n        k\n        ,\n      \n    \n  ",
    "links": [
      "Analytic function",
      "Applied mathematics",
      "Astronomy",
      "Asymptotic stability",
      "Augustin-Louis Cauchy",
      "Augustin Cauchy",
      "Autonomous differential equation",
      "Biology",
      "Boundary value problem",
      "Carathéodory's existence theorem",
      "Carl David Tolmé Runge",
      "Cauchy problem",
      "Cauchy–Kovalevskaya–Kashiwara theorem",
      "Cauchy–Kowalevski theorem",
      "Chaos theory",
      "Chemistry",
      "Cohomological",
      "Continuum mechanics",
      "Crank–Nicolson method",
      "D-modules",
      "Delay differential equation",
      "Dependent and independent variables",
      "Derived functor",
      "Difference equation",
      "Differential-algebraic system of equations",
      "Differential equation",
      "Differential operator",
      "Dirac delta function",
      "Dirichlet boundary condition",
      "Doi (identifier)",
      "Dynamical systems",
      "Economics",
      "Encyclopedia of Mathematics",
      "Endomorphism",
      "Engineering",
      "Ernst Lindelöf",
      "Euler method",
      "European Mathematical Society",
      "Exact differential equation",
      "Existence theorem",
      "Exponential response formula",
      "Exponential stability",
      "Field (mathematics)",
      "Finite difference method",
      "Finite element method",
      "Finite volume method",
      "Formal power series",
      "Fractional differential equations",
      "Galerkin method",
      "Geology"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Augustin-Louis Cauchy",
      "Category:Partial differential equations",
      "Category:Short description is different from Wikidata",
      "Category:Theorems in mathematical analysis",
      "Category:Uniqueness theorems"
    ]
  },
  "Computer algebra": {
    "title": "Computer algebra",
    "url": "https://en.wikipedia.org/wiki/Computer_algebra",
    "summary": "In mathematics and computer science, computer algebra, also called symbolic computation or algebraic computation, is a scientific area that refers to the study and development of algorithms and software for manipulating mathematical expressions and other mathematical objects. Although computer algebra could be considered a subfield of scientific computing, they are generally considered as distinct fields because scientific computing is usually based on numerical computation with approximate floating point numbers, while symbolic computation emphasizes exact computation with expressions containing variables that have no given value and are manipulated as symbols.\nSoftware applications that perform symbolic calculations are called computer algebra systems, with the term system alluding to the complexity of the main applications that include, at least, a method to represent mathematical data in a computer, a user programming language (usually different from the language used for the imple",
    "content": "In mathematics and computer science, computer algebra, also called symbolic computation or algebraic computation, is a scientific area that refers to the study and development of algorithms and software for manipulating mathematical expressions and other mathematical objects. Although computer algebra could be considered a subfield of scientific computing, they are generally considered as distinct fields because scientific computing is usually based on numerical computation with approximate floating point numbers, while symbolic computation emphasizes exact computation with expressions containing variables that have no given value and are manipulated as symbols.\nSoftware applications that perform symbolic calculations are called computer algebra systems, with the term system alluding to the complexity of the main applications that include, at least, a method to represent mathematical data in a computer, a user programming language (usually different from the language used for the implementation), a dedicated memory manager, a user interface for the input/output of mathematical expressions, and a large set of routines to perform usual operations, like simplification of expressions, differentiation using the chain rule, polynomial factorization, indefinite integration, etc.\nComputer algebra is widely used to experiment in mathematics and to design the formulas that are used in numerical programs. It is also used for complete scientific computations, when purely numerical methods fail, as in public key cryptography, or for some non-linear problems.\n\nTerminology\nSome authors distinguish computer algebra from symbolic computation, using the latter name to refer to kinds of symbolic computation other than the computation with mathematical formulas. Some authors use symbolic computation for the computer-science aspect of the subject and computer algebra for the mathematical aspect. In some languages, the name of the field is not a direct translation of its English name. Typically, it is called calcul formel in French, which means \"formal computation\". This name reflects the ties this field has with formal methods.\nSymbolic computation has also been referred to, in the past, as symbolic manipulation, algebraic manipulation, symbolic processing, symbolic mathematics, or symbolic algebra, but these terms, which also refer to non-computational manipulation, are no longer used in reference to computer algebra.\n\nScientific community\nThere is no learned society that is specific to computer algebra, but this function is assumed by the special interest group of the Association for Computing Machinery named SIGSAM (Special Interest Group on Symbolic and Algebraic Manipulation).\nThere are several annual conferences on computer algebra, the premier being ISSAC (International Symposium on Symbolic and Algebraic Computation), which is regularly sponsored by SIGSAM.\nThere are several journals specializing in computer algebra, the top one being Journal of Symbolic Computation founded in 1985 by Bruno Buchberger. There are also several other journals that regularly publish articles in computer algebra.\n\nComputer science aspects\nData representation\nAs numerical software is highly efficient for approximate numerical computation, it is common, in computer algebra, to emphasize exact computation with exactly represented data. Such an exact representation implies that, even when the size of the output is small, the intermediate data generated during a computation may grow in an unpredictable way. This behavior is called expression swell. To alleviate this problem, various methods are used in the representation of the data, as well as in the algorithms that manipulate them.\n\nNumbers\nThe usual number systems used in numerical computation are floating point numbers and integers of a fixed, bounded size. Neither of these is convenient for computer algebra, due to expression swell. Therefore, the basic numbers used in computer algebra are the integers of the mathematicians, commonly represented by an unbounded signed sequence of digits in some base of numeration, usually the largest base allowed by the machine word. These integers allow one to define the rational numbers, which are irreducible fractions of two integers.\nProgramming an efficient implementation of the arithmetic operations is a hard task. Therefore, most free computer algebra systems, and some commercial ones such as Mathematica and Maple, use the GMP library, which is thus a de facto standard.\n\nExpressions\nExcept for numbers and variables, every mathematical expression may be viewed as the symbol of an operator followed by a sequence of operands. In computer-algebra software, the expressions are usually represented in this way. This representation is very flexible, and many things that seem not to be mathematical expressions at first glance, may be represented and manipulated as such. For example, an equation is an expression with \"=\" as an operator, and a matrix may be repr",
    "links": [
      "ACM Computing Classification System",
      "ALTRAN",
      "Abstract algebra",
      "Algebra",
      "Algebraic function",
      "Algebraic geometry",
      "Algebraic number theory",
      "Algebraic topology",
      "Algorithm",
      "Algorithm design",
      "Algorithmic efficiency",
      "Analysis of algorithms",
      "Analytic geometry",
      "Analytic number theory",
      "Antiderivatives",
      "Application security",
      "Applied mathematics",
      "Arithmetic",
      "Arithmetic geometry",
      "Artificial intelligence",
      "Association for Computing Machinery",
      "Associative operation",
      "Augmented reality",
      "Automata theory",
      "Automated planning and scheduling",
      "Automated theorem prover",
      "Axiom (computer algebra system)",
      "Betty Holberton",
      "Bibcode (identifier)",
      "Bruno Buchberger",
      "Buchberger's algorithm",
      "Cadabra (computer program)",
      "Calculus",
      "Cambridge Algebra System",
      "Canonical form",
      "Cantor–Zassenhaus algorithm",
      "Casio ClassPad 300",
      "Category theory",
      "Chain rule",
      "CoCoA",
      "Combinatorics",
      "Communication protocol",
      "Commutative algebra",
      "Commutativity",
      "Compiler construction",
      "Complex analysis",
      "Computability theory",
      "Computable function",
      "Computational algebraic geometry",
      "Computational biology"
    ],
    "categories": [
      "Category:All articles covered by WikiProject Wikify",
      "Category:All pages needing cleanup",
      "Category:Articles covered by WikiProject Wikify from May 2020",
      "Category:Articles with excerpts",
      "Category:Articles with short description",
      "Category:Computer algebra",
      "Category:Short description is different from Wikidata",
      "Category:Wikipedia introduction cleanup from May 2020"
    ]
  },
  "Computer algebra system": {
    "title": "Computer algebra system",
    "url": "https://en.wikipedia.org/wiki/Computer_algebra_system",
    "summary": "A computer algebra system (CAS) or symbolic algebra system (SAS) is any mathematical software with the ability to manipulate mathematical expressions in a way similar to the traditional manual computations of mathematicians and scientists. The development of the computer algebra systems in the second half of the 20th century is part of the discipline of \"computer algebra\" or \"symbolic computation\", which has spurred work in algorithms over mathematical objects such as polynomials.\nComputer algebra systems may be divided into two classes: specialized and general-purpose. The specialized ones are devoted to a specific part of mathematics, such as number theory, group theory, or teaching of elementary mathematics.\nGeneral-purpose computer algebra systems aim to be useful to a user working in any scientific field that requires manipulation of mathematical expressions. To be useful, a general-purpose computer algebra system must include various features such as:\n\na user interface allowing a",
    "content": "A computer algebra system (CAS) or symbolic algebra system (SAS) is any mathematical software with the ability to manipulate mathematical expressions in a way similar to the traditional manual computations of mathematicians and scientists. The development of the computer algebra systems in the second half of the 20th century is part of the discipline of \"computer algebra\" or \"symbolic computation\", which has spurred work in algorithms over mathematical objects such as polynomials.\nComputer algebra systems may be divided into two classes: specialized and general-purpose. The specialized ones are devoted to a specific part of mathematics, such as number theory, group theory, or teaching of elementary mathematics.\nGeneral-purpose computer algebra systems aim to be useful to a user working in any scientific field that requires manipulation of mathematical expressions. To be useful, a general-purpose computer algebra system must include various features such as:\n\na user interface allowing a user to enter and display mathematical formulas, typically from a keyboard, menu selections, mouse or stylus.\na programming language and an interpreter (the result of a computation commonly has an unpredictable form and an unpredictable size; therefore user intervention is frequently needed),\na simplifier, which is a rewrite system for simplifying mathematics formulas,\na memory manager, including a garbage collector, needed by the huge size of the intermediate data, which may appear during a computation,\nan arbitrary-precision arithmetic, needed by the huge size of the integers that may occur,\na large library of mathematical algorithms and special functions.\nThe library must not only provide for the needs of the users, but also the needs of the simplifier. For example, the computation of polynomial greatest common divisors is systematically used for the simplification of expressions involving fractions.\nThis large amount of required computer capabilities explains the small number of general-purpose computer algebra systems. Significant systems include Axiom, GAP, Maxima, Magma, Maple, Mathematica, and SageMath.\n\nHistory\nIn the 1950s, while computers were mainly used for numerical computations, there were some research projects into using them for symbolic manipulation. Computer algebra systems began to appear in the 1960s and evolved out of two quite different sources—the requirements of theoretical physicists and research into artificial intelligence.\nA prime example for the first development was the pioneering work conducted by the later Nobel Prize laureate in physics Martinus Veltman, who designed a program for symbolic mathematics, especially high-energy physics, called Schoonschip (Dutch for \"clean ship\") in 1963. Other early systems include FORMAC.\nUsing Lisp as the programming basis, Carl Engelman created MATHLAB in 1964 at MITRE within an artificial-intelligence research environment. Later MATHLAB was made available to users on PDP-6 and PDP-10 systems running TOPS-10 or TENEX in universities. Today it can still be used on SIMH emulations of the PDP-10. MATHLAB (\"mathematical laboratory\") should not be confused with MATLAB (\"matrix laboratory\"), which is a system for numerical computation built 15 years later at the University of New Mexico.\nIn 1987, Hewlett-Packard introduced the first hand-held calculator CAS with the HP-28 series. Other early handheld calculators with symbolic algebra capabilities included the Texas Instruments TI-89 series and TI-92 calculator, and the Casio CFX-9970G.\nThe first popular computer algebra systems were muMATH, Reduce, Derive (based on muMATH), and Macsyma; a copyleft version of Macsyma is called Maxima. Reduce became free software in 2008. Commercial systems include Mathematica and Maple, which are commonly used by research mathematicians, scientists, and engineers. Freely available alternatives include SageMath (which can act as a front-end to several other free and nonfree CAS). Other significant systems include Axiom, GAP, Maxima and Magma.\nThe movement to web-based applications in the early 2000s saw the release of WolframAlpha, an online search engine and CAS which includes the capabilities of Mathematica.\nMore recently, computer algebra systems have been implemented using artificial neural networks, though as of 2020 they are not commercially available.\n\nSymbolic manipulations\nThe symbolic manipulations supported typically include:\n\nsimplification to a smaller expression or some standard form, including automatic simplification with assumptions and simplification with constraints\nsubstitution of symbols or numeric values for certain expressions\nchange of form of expressions: expanding products and powers, partial and full factorization, rewriting as partial fractions, constraint satisfaction, rewriting trigonometric functions as exponentials, transforming logic expressions, etc.\npartial and total differentiation\nsome indefinite and definite integration (see symbolic integratio",
    "links": [
      "ACT (test)",
      "ALTRAN",
      "AP Calculus",
      "AP Chemistry",
      "AP Physics",
      "AP Statistics",
      "Algebraic modeling language",
      "Algebraic number",
      "Algorithm",
      "Antidifferentiation",
      "Application programming interface",
      "Applied mathematics",
      "ArXiv (identifier)",
      "Arbitrary-precision",
      "Arbitrary-precision arithmetic",
      "Artificial intelligence",
      "Artificial neural networks",
      "Automated theorem proving",
      "Automatic programming",
      "Axiom (computer algebra system)",
      "Berlekamp's algorithm",
      "Bessel function",
      "Bioinformatics",
      "Buchberger's algorithm",
      "CFX-9970G",
      "Cadabra (computer program)",
      "Cambridge Algebra System",
      "Canonical form",
      "Cantor–Zassenhaus algorithm",
      "Carl Engelman",
      "Casio",
      "Casio ClassPad 300",
      "Chinese remainder theorem",
      "Closed-form solution",
      "CoCoA",
      "College Board",
      "Columbus, Ohio",
      "Comparison of numerical-analysis software",
      "Complex number",
      "Computational chemistry",
      "Computational physics",
      "Computer-generated imagery",
      "Computer algebra",
      "Computer graphics",
      "Constraint-logic programming",
      "Constraint satisfaction",
      "Copyleft",
      "Cylindrical algebraic decomposition",
      "Derivatives of the incomplete gamma function",
      "Derive (computer algebra system)"
    ],
    "categories": [
      "Category:Algebra education",
      "Category:Articles with short description",
      "Category:Computer algebra systems",
      "Category:Short description is different from Wikidata",
      "Category:Use dmy dates from April 2019",
      "Category:Webarchive template wayback links"
    ]
  },
  "Continuous function": {
    "title": "Continuous function",
    "url": "https://en.wikipedia.org/wiki/Continuous_function",
    "summary": "In mathematics, a continuous function is a function such that a small variation of the argument induces a small variation of the value of the function. This implies there are no abrupt changes in value, known as discontinuities. More precisely, a function is continuous if arbitrarily small changes in its value can be assured by restricting to sufficiently small changes of its argument. A discontinuous function is a function that is not continuous. Until the 19th century, mathematicians largely relied on intuitive notions of continuity and considered only continuous functions. The epsilon–delta definition of a limit was introduced to formalize the definition of continuity.\nContinuity is one of the core concepts of calculus and mathematical analysis, where arguments and values of functions are real and complex numbers. The concept has been generalized to functions between metric spaces and between topological spaces. The latter are the most general continuous functions, and their definit",
    "content": "In mathematics, a continuous function is a function such that a small variation of the argument induces a small variation of the value of the function. This implies there are no abrupt changes in value, known as discontinuities. More precisely, a function is continuous if arbitrarily small changes in its value can be assured by restricting to sufficiently small changes of its argument. A discontinuous function is a function that is not continuous. Until the 19th century, mathematicians largely relied on intuitive notions of continuity and considered only continuous functions. The epsilon–delta definition of a limit was introduced to formalize the definition of continuity.\nContinuity is one of the core concepts of calculus and mathematical analysis, where arguments and values of functions are real and complex numbers. The concept has been generalized to functions between metric spaces and between topological spaces. The latter are the most general continuous functions, and their definition is the basis of topology.\nA stronger form of continuity is uniform continuity. In order theory, especially in domain theory, a related concept of continuity is Scott continuity.\nAs an example, the function H(t) denoting the height of a growing flower at time t would be considered continuous. In contrast, the function M(t) denoting the amount of money in a bank account at time t would be considered discontinuous since it \"jumps\" at each point in time when money is deposited or withdrawn.\n\nHistory\nA form of the epsilon–delta definition of continuity was first given by Bernard Bolzano in 1817. Augustin-Louis Cauchy defined continuity of \n  \n    \n      \n        y\n        =\n        f\n        (\n        x\n        )\n      \n    \n    {\\displaystyle y=f(x)}\n  \n as follows: an infinitely small increment \n  \n    \n      \n        α\n      \n    \n    {\\displaystyle \\alpha }\n  \n of the independent variable x always produces an infinitely small change \n  \n    \n      \n        f\n        (\n        x\n        +\n        α\n        )\n        −\n        f\n        (\n        x\n        )\n      \n    \n    {\\displaystyle f(x+\\alpha )-f(x)}\n  \n of the dependent variable y (see e.g. Cours d'Analyse, p. 34). Cauchy defined infinitely small quantities in terms of variable quantities, and his definition of continuity closely parallels the infinitesimal definition used today (see microcontinuity). The formal definition and the distinction between pointwise continuity and uniform continuity were first given by Bolzano in the 1830s, but the work wasn't published until the 1930s. Like Bolzano, Karl Weierstrass denied continuity of a function at a point c unless it was defined at and on both sides of c, but Édouard Goursat allowed the function to be defined only at and on one side of c, and Camille Jordan allowed it even if the function was defined only at c. All three of those nonequivalent definitions of pointwise continuity are still in use. Eduard Heine provided the first published definition of uniform continuity in 1872, but based these ideas on lectures given by Peter Gustav Lejeune Dirichlet in 1854.\n\nReal functions\nDefinition\nA real function that is a function from real numbers to real numbers can be represented by a graph in the Cartesian plane; such a function is continuous if, roughly speaking, the graph is a single unbroken curve whose domain is the entire real line. A more mathematically rigorous definition is given below.\nContinuity of real functions is usually defined in terms of limits. A function f with variable x is continuous at the real number c, if the limit of \n  \n    \n      \n        f\n        (\n        x\n        )\n        ,\n      \n    \n    {\\displaystyle f(x),}\n  \n as x tends to c, is equal to \n  \n    \n      \n        f\n        (\n        c\n        )\n        .\n      \n    \n    {\\displaystyle f(c).}\n  \n\nThere are several different definitions of the (global) continuity of a function, which depend on the nature of its domain. \nA function is continuous on an open interval if the interval is contained in the function's domain and the function is continuous at every interval point. A function that is continuous on the interval \n  \n    \n      \n        (\n        −\n        ∞\n        ,\n        +\n        ∞\n        )\n      \n    \n    {\\displaystyle (-\\infty ,+\\infty )}\n  \n (the whole real line) is often called simply a continuous function; one also says that such a function is continuous everywhere. For example, all polynomial functions are continuous everywhere.\nA function is continuous on a semi-open or a closed interval; if the interval is contained in the domain of the function, the function is continuous at every interior point of the interval, and the value of the function at each endpoint that belongs to the interval is the limit of the values of the function when the variable tends to the endpoint from the interior of the interval. For example, the function \n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        \n          \n         ",
    "links": [
      "(ε, δ)-definition of limit",
      "0 (number)",
      "Abel's test",
      "Absolute continuity",
      "Absolute value",
      "Adequality",
      "Algebraic function",
      "Almost everywhere",
      "Alternating series",
      "Alternating series test",
      "Analytic function",
      "Antiderivative",
      "Approximate continuity",
      "Approximate limit",
      "Approximately continuous",
      "Arc length",
      "Argument of a function",
      "Arithmetico-geometric sequence",
      "Arithmetico–geometric sequence",
      "Asymptote",
      "Augustin-Louis Cauchy",
      "Axiom of countable choice",
      "Basis (topology)",
      "Bernard Bolzano",
      "Bernoulli number",
      "Bijection",
      "Bijective",
      "Binary relation",
      "Binomial series",
      "Binomial theorem",
      "Blumberg theorem",
      "Boolean-valued function",
      "Boolean function",
      "Bounded linear operator",
      "Brook Taylor",
      "Calculus",
      "Calculus of variations",
      "Calculus on Euclidean space",
      "Cambridge University Press",
      "Camille Jordan",
      "Cartesian coordinate system",
      "Category (mathematics)",
      "Category theory",
      "Cauchy",
      "Cauchy condensation test",
      "Cauchy sequence",
      "Chain rule",
      "Characterizations of the category of topological spaces",
      "CiteSeerX (identifier)",
      "Class (mathematics)"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Calculus",
      "Category:Commons category link is on Wikidata",
      "Category:Pages using sidebar with the child parameter",
      "Category:Short description is different from Wikidata",
      "Category:Theory of continuous functions",
      "Category:Types of functions"
    ]
  },
  "Complex number": {
    "title": "Complex number",
    "url": "https://en.wikipedia.org/wiki/Complex_number",
    "summary": "In mathematics, a complex number is an element of a number system that extends the real numbers with a specific element denoted i, called the imaginary unit and satisfying the equation \n  \n    \n      \n        \n          i\n          \n            2\n          \n        \n        =\n        −\n        1\n      \n    \n    {\\displaystyle i^{2}=-1}\n  \n; every complex number can be expressed in the form \n  \n    \n      \n        a\n        +\n        b\n        i\n      \n    \n    {\\displaystyle a+bi}\n  \n, where a and b are real numbers. Because no real number satisfies the above equation, i was called an imaginary number by René Descartes. For the complex number \n  \n    \n      \n        a\n        +\n        b\n        i\n      \n    \n    {\\displaystyle a+bi}\n  \n, a is called the real part, and b is called the imaginary part. The set of complex numbers is denoted by either of the symbols \n  \n    \n      \n        \n          C\n        \n      \n    \n    {\\displaystyle \\mathbb {C} }\n  \n or C. Despite the historical n",
    "content": "In mathematics, a complex number is an element of a number system that extends the real numbers with a specific element denoted i, called the imaginary unit and satisfying the equation \n  \n    \n      \n        \n          i\n          \n            2\n          \n        \n        =\n        −\n        1\n      \n    \n    {\\displaystyle i^{2}=-1}\n  \n; every complex number can be expressed in the form \n  \n    \n      \n        a\n        +\n        b\n        i\n      \n    \n    {\\displaystyle a+bi}\n  \n, where a and b are real numbers. Because no real number satisfies the above equation, i was called an imaginary number by René Descartes. For the complex number \n  \n    \n      \n        a\n        +\n        b\n        i\n      \n    \n    {\\displaystyle a+bi}\n  \n, a is called the real part, and b is called the imaginary part. The set of complex numbers is denoted by either of the symbols \n  \n    \n      \n        \n          C\n        \n      \n    \n    {\\displaystyle \\mathbb {C} }\n  \n or C. Despite the historical nomenclature, \"imaginary\" complex numbers have a mathematical existence as firm as that of the real numbers, and they are fundamental tools in the scientific description of the natural world.\nComplex numbers allow solutions to all polynomial equations, even those that have no solutions in real numbers. More precisely, the fundamental theorem of algebra asserts that every non-constant polynomial equation with real or complex coefficients has a solution which is a complex number. For example, the equation\n\n  \n    \n      \n        (\n        x\n        +\n        1\n        \n          )\n          \n            2\n          \n        \n        =\n        −\n        9\n      \n    \n    {\\displaystyle (x+1)^{2}=-9}\n  \n\nhas no real solution, because the square of a real number cannot be negative, but has the two nonreal complex solutions \n  \n    \n      \n        −\n        1\n        +\n        3\n        i\n      \n    \n    {\\displaystyle -1+3i}\n  \n and \n  \n    \n      \n        −\n        1\n        −\n        3\n        i\n      \n    \n    {\\displaystyle -1-3i}\n  \n.\nAddition, subtraction and multiplication of complex numbers can be naturally defined by using the rule \n  \n    \n      \n        \n          i\n          \n            2\n          \n        \n        =\n        −\n        1\n      \n    \n    {\\displaystyle i^{2}=-1}\n  \n along with the associative, commutative, and distributive laws. Every nonzero complex number has a multiplicative inverse. This makes the complex numbers a field with the real numbers as a subfield. Because of these properties, ⁠\n  \n    \n      \n        a\n        +\n        b\n        i\n        =\n        a\n        +\n        i\n        b\n      \n    \n    {\\displaystyle a+bi=a+ib}\n  \n⁠, and which form is written depends upon convention and style considerations.\nThe complex numbers also form a real vector space of dimension two, with \n  \n    \n      \n        {\n        1\n        ,\n        i\n        }\n      \n    \n    {\\displaystyle \\{1,i\\}}\n  \n as a standard basis. This standard basis makes the complex numbers a Cartesian plane, called the complex plane. This allows a geometric interpretation of the complex numbers and their operations, and conversely some geometric objects and operations can be expressed in terms of complex numbers. For example, the real numbers form the real line, which is pictured as the horizontal axis of the complex plane, while real multiples of \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n are the vertical axis. A complex number can also be defined by its geometric polar coordinates: the radius is called the absolute value of the complex number, while the angle from the positive real axis is called the argument of the complex number. The complex numbers of absolute value one form the unit circle. Adding a fixed complex number to all complex numbers defines a translation in the complex plane, and multiplying by a fixed complex number is a similarity centered at the origin (dilating by the absolute value, and rotating by the argument). The operation of complex conjugation is the reflection symmetry with respect to the real axis. \nThe complex numbers form a rich structure that is simultaneously an algebraically closed field, a commutative algebra over the reals, and a Euclidean vector space of dimension two.\n\nDefinition and basic operations\nA complex number is an expression of the form a + bi, where a and b are real numbers, and i is an abstract symbol, the so-called imaginary unit, whose meaning will be explained further below. For example, 2 + 3i is a complex number.\nFor a complex number a + bi, the real number a is called its real part, and the real number b (not the complex number bi) is its imaginary part. The real part of a complex number z is denoted Re(z), \n  \n    \n      \n        \n          \n            R\n            e\n          \n        \n        (\n        z\n        )\n      \n    \n    {\\displaystyle {\\mathcal {Re}}(z)}\n  \n, or \n  \n    \n      \n        \n          \n            R\n          \n        \n        (\n  ",
    "links": [
      "(ε, δ)-definition of limit",
      "AD",
      "Abraham de Moivre",
      "Absolute value",
      "Abstract algebra",
      "Addison-Wesley",
      "Addition",
      "Aequationes Mathematicae",
      "Affine transformation",
      "Algebra (ring theory)",
      "Algebra of physical space",
      "Algebraic closure",
      "Algebraic extension",
      "Algebraic number",
      "Algebraic number theory",
      "Algebraic solution",
      "Algebraically closed",
      "Algebraically closed field",
      "Alternating current",
      "American Institute of Electrical Engineers",
      "American Mathematical Monthly",
      "Amplitude",
      "Amplitude modulation",
      "Analytic continuation",
      "Analytic function",
      "Analytic number theory",
      "Analytic signal",
      "Angle notation",
      "Angular frequency",
      "Applied mathematics",
      "Arctan",
      "Arg (mathematics)",
      "Argand diagram",
      "Argument (complex analysis)",
      "Argumentum a fortiori",
      "Ars Magna (Cardano book)",
      "Associative law",
      "Augustin-Louis Cauchy",
      "Automorphism",
      "Axiom of choice",
      "BIBO stability",
      "Base (topology)",
      "Bernhard Riemann",
      "Bicomplex number",
      "Bijective",
      "Bioctonion",
      "Biquaternion",
      "Blackboard bold",
      "C. V. Mourey",
      "Capacitor"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1: unfit URL",
      "Category:CS1 Danish-language sources (da)",
      "Category:CS1 French-language sources (fr)",
      "Category:CS1 German-language sources (de)",
      "Category:CS1 Latin-language sources (la)",
      "Category:CS1 errors: ISBN date",
      "Category:Commons category link is on Wikidata",
      "Category:Complex numbers",
      "Category:Composition algebras"
    ]
  },
  "Complex numbers": {
    "title": "Complex number",
    "url": "https://en.wikipedia.org/wiki/Complex_number",
    "summary": "In mathematics, a complex number is an element of a number system that extends the real numbers with a specific element denoted i, called the imaginary unit and satisfying the equation \n  \n    \n      \n        \n          i\n          \n            2\n          \n        \n        =\n        −\n        1\n      \n    \n    {\\displaystyle i^{2}=-1}\n  \n; every complex number can be expressed in the form \n  \n    \n      \n        a\n        +\n        b\n        i\n      \n    \n    {\\displaystyle a+bi}\n  \n, where a and b are real numbers. Because no real number satisfies the above equation, i was called an imaginary number by René Descartes. For the complex number \n  \n    \n      \n        a\n        +\n        b\n        i\n      \n    \n    {\\displaystyle a+bi}\n  \n, a is called the real part, and b is called the imaginary part. The set of complex numbers is denoted by either of the symbols \n  \n    \n      \n        \n          C\n        \n      \n    \n    {\\displaystyle \\mathbb {C} }\n  \n or C. Despite the historical n",
    "content": "In mathematics, a complex number is an element of a number system that extends the real numbers with a specific element denoted i, called the imaginary unit and satisfying the equation \n  \n    \n      \n        \n          i\n          \n            2\n          \n        \n        =\n        −\n        1\n      \n    \n    {\\displaystyle i^{2}=-1}\n  \n; every complex number can be expressed in the form \n  \n    \n      \n        a\n        +\n        b\n        i\n      \n    \n    {\\displaystyle a+bi}\n  \n, where a and b are real numbers. Because no real number satisfies the above equation, i was called an imaginary number by René Descartes. For the complex number \n  \n    \n      \n        a\n        +\n        b\n        i\n      \n    \n    {\\displaystyle a+bi}\n  \n, a is called the real part, and b is called the imaginary part. The set of complex numbers is denoted by either of the symbols \n  \n    \n      \n        \n          C\n        \n      \n    \n    {\\displaystyle \\mathbb {C} }\n  \n or C. Despite the historical nomenclature, \"imaginary\" complex numbers have a mathematical existence as firm as that of the real numbers, and they are fundamental tools in the scientific description of the natural world.\nComplex numbers allow solutions to all polynomial equations, even those that have no solutions in real numbers. More precisely, the fundamental theorem of algebra asserts that every non-constant polynomial equation with real or complex coefficients has a solution which is a complex number. For example, the equation\n\n  \n    \n      \n        (\n        x\n        +\n        1\n        \n          )\n          \n            2\n          \n        \n        =\n        −\n        9\n      \n    \n    {\\displaystyle (x+1)^{2}=-9}\n  \n\nhas no real solution, because the square of a real number cannot be negative, but has the two nonreal complex solutions \n  \n    \n      \n        −\n        1\n        +\n        3\n        i\n      \n    \n    {\\displaystyle -1+3i}\n  \n and \n  \n    \n      \n        −\n        1\n        −\n        3\n        i\n      \n    \n    {\\displaystyle -1-3i}\n  \n.\nAddition, subtraction and multiplication of complex numbers can be naturally defined by using the rule \n  \n    \n      \n        \n          i\n          \n            2\n          \n        \n        =\n        −\n        1\n      \n    \n    {\\displaystyle i^{2}=-1}\n  \n along with the associative, commutative, and distributive laws. Every nonzero complex number has a multiplicative inverse. This makes the complex numbers a field with the real numbers as a subfield. Because of these properties, ⁠\n  \n    \n      \n        a\n        +\n        b\n        i\n        =\n        a\n        +\n        i\n        b\n      \n    \n    {\\displaystyle a+bi=a+ib}\n  \n⁠, and which form is written depends upon convention and style considerations.\nThe complex numbers also form a real vector space of dimension two, with \n  \n    \n      \n        {\n        1\n        ,\n        i\n        }\n      \n    \n    {\\displaystyle \\{1,i\\}}\n  \n as a standard basis. This standard basis makes the complex numbers a Cartesian plane, called the complex plane. This allows a geometric interpretation of the complex numbers and their operations, and conversely some geometric objects and operations can be expressed in terms of complex numbers. For example, the real numbers form the real line, which is pictured as the horizontal axis of the complex plane, while real multiples of \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n are the vertical axis. A complex number can also be defined by its geometric polar coordinates: the radius is called the absolute value of the complex number, while the angle from the positive real axis is called the argument of the complex number. The complex numbers of absolute value one form the unit circle. Adding a fixed complex number to all complex numbers defines a translation in the complex plane, and multiplying by a fixed complex number is a similarity centered at the origin (dilating by the absolute value, and rotating by the argument). The operation of complex conjugation is the reflection symmetry with respect to the real axis. \nThe complex numbers form a rich structure that is simultaneously an algebraically closed field, a commutative algebra over the reals, and a Euclidean vector space of dimension two.\n\nDefinition and basic operations\nA complex number is an expression of the form a + bi, where a and b are real numbers, and i is an abstract symbol, the so-called imaginary unit, whose meaning will be explained further below. For example, 2 + 3i is a complex number.\nFor a complex number a + bi, the real number a is called its real part, and the real number b (not the complex number bi) is its imaginary part. The real part of a complex number z is denoted Re(z), \n  \n    \n      \n        \n          \n            R\n            e\n          \n        \n        (\n        z\n        )\n      \n    \n    {\\displaystyle {\\mathcal {Re}}(z)}\n  \n, or \n  \n    \n      \n        \n          \n            R\n          \n        \n        (\n  ",
    "links": [
      "(ε, δ)-definition of limit",
      "AD",
      "Abraham de Moivre",
      "Absolute value",
      "Abstract algebra",
      "Addison-Wesley",
      "Addition",
      "Aequationes Mathematicae",
      "Affine transformation",
      "Algebra (ring theory)",
      "Algebra of physical space",
      "Algebraic closure",
      "Algebraic extension",
      "Algebraic number",
      "Algebraic number theory",
      "Algebraic solution",
      "Algebraically closed",
      "Algebraically closed field",
      "Alternating current",
      "American Institute of Electrical Engineers",
      "American Mathematical Monthly",
      "Amplitude",
      "Amplitude modulation",
      "Analytic continuation",
      "Analytic function",
      "Analytic number theory",
      "Analytic signal",
      "Angle notation",
      "Angular frequency",
      "Applied mathematics",
      "Arctan",
      "Arg (mathematics)",
      "Argand diagram",
      "Argument (complex analysis)",
      "Argumentum a fortiori",
      "Ars Magna (Cardano book)",
      "Associative law",
      "Augustin-Louis Cauchy",
      "Automorphism",
      "Axiom of choice",
      "BIBO stability",
      "Base (topology)",
      "Bernhard Riemann",
      "Bicomplex number",
      "Bijective",
      "Bioctonion",
      "Biquaternion",
      "Blackboard bold",
      "C. V. Mourey",
      "Capacitor"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1: unfit URL",
      "Category:CS1 Danish-language sources (da)",
      "Category:CS1 French-language sources (fr)",
      "Category:CS1 German-language sources (de)",
      "Category:CS1 Latin-language sources (la)",
      "Category:CS1 errors: ISBN date",
      "Category:Commons category link is on Wikidata",
      "Category:Complex numbers",
      "Category:Composition algebras"
    ]
  },
  "A Course of Modern Analysis": {
    "title": "A Course of Modern Analysis",
    "url": "https://en.wikipedia.org/wiki/A_Course_of_Modern_Analysis",
    "summary": "A Course of Modern Analysis: an introduction to the general theory of infinite processes and of analytic functions; with an account of the principal transcendental functions (colloquially known as Whittaker and Watson) is a landmark textbook on mathematical analysis written by Edmund T. Whittaker and George N. Watson, first published by Cambridge University Press in 1915. The first edition was Whittaker's alone, but later editions were co-authored with Watson.",
    "content": "A Course of Modern Analysis: an introduction to the general theory of infinite processes and of analytic functions; with an account of the principal transcendental functions (colloquially known as Whittaker and Watson) is a landmark textbook on mathematical analysis written by Edmund T. Whittaker and George N. Watson, first published by Cambridge University Press in 1915. The first edition was Whittaker's alone, but later editions were co-authored with Watson.\n\nHistory\nIts first, second, third, and the fourth edition were published in 1902, 1915, 1920, and 1927, respectively. Since then, it has continuously been reprinted and is still in print today. A revised, expanded and digitally reset fifth edition, edited by Victor H. Moll, was published in 2021.\nThe book is notable for being the standard reference and textbook for a generation of Cambridge mathematicians including Littlewood and Godfrey H. Hardy. Mary L. Cartwright studied it as preparation for her final honours on the advice of fellow student Vernon C. Morton, later Professor of Mathematics at Aberystwyth University. But its reach was much further than just the Cambridge school; André Weil in his obituary of the French mathematician Jean Delsarte noted that Delsarte always had a copy on his desk. In 1941, the book was included among a \"selected list\" of mathematical analysis books for use in universities in an article for that purpose published by American Mathematical Monthly.\n\nNotable features\nSome idiosyncratic but interesting problems from an older era of the Cambridge Mathematical Tripos are in the exercises.\nThe book was one of the earliest to use decimal numbering for its sections, an innovation the authors attribute to Giuseppe Peano.\n\nContents\nBelow are the contents of the fourth edition:\n\nPart I. The Process of Analysis\n\nPart II. The Transcendental Functions\n\nReception\nReviews of the first edition\nGeorge B. Mathews, in a 1903 review article published in The Mathematical Gazette opens by saying the book is \"sure of a favorable reception\" because of its \"attractive account of some of the most valuable and interesting results of recent analysis\". He notes that Part I deals mainly with infinite series, focusing on power series and Fourier expansions while including the \"elements of\" complex integration and the theory of residues. Part II, in contrast, has chapters on the gamma function, Legendre functions, the hypergeometric series, Bessel functions, elliptic functions, and mathematical physics.\nArthur S. Hathaway, in another 1903 review published in the Journal of the American Chemical Society,  notes that the book centers around complex analysis, but that topics such as infinite series are \"considered in all their phases\" along with \"all those important series and functions\" developed by mathematicians such as Joseph Fourier, Friedrich Bessel, Joseph-Louis Lagrange, Adrien-Marie Legendre, Pierre-Simon Laplace, Carl Friedrich Gauss, Niels Henrik Abel, and others in their respective studies of \"practice problems\". He goes on to say it \"is a useful book for those who wish to make use of the most advanced developments of mathematical analysis in theoretical investigations of physical and chemical questions.\"\nIn a third review of the first edition, Maxime Bôcher, in a 1904 review published in the Bulletin of the American Mathematical Society notes that while the book falls short of the \"rigor\" of French, German, and Italian writers, it is a \"gratifying sign of progress to find in an English book such an attempt at rigorous treatment as is here made\". He notes that important parts of the book were otherwise non-existent in the English language.\n\nSee also\nBateman Manuscript Project\n\nReferences\nFurther reading\nJourdain, Philip E. B. (1916-01-01). \"(1) A Course of Pure Mathematics. By G. H. Hardy. Cambridge University Press, 1908. Pp. xvi, 428. Cloth, 12s. net. (2) A Course of Pure Mathematics. By G. H. Hardy. Second edition. Cambridge University Press, 1914. Pp. xii, 443. Cloth, 12s. net. (3) A Course of Modern Analysis: An Introduction to the General Theory of Infinite Processes and of Analytic Functions; with an Account of the Principal Transcendental Functions. By E. T. Whittaker. Cambridge University Press, 1902. Pp. xvi, 378. Cloth, 12s. 6d. net. (4) A Course of Modern Analysis: An Introduction to the General Theory of Infinite Processes and of Analytic Functions; with an Account of the Principal Transcendental Functions. Second edition, completely revised. By E. T. Whittaker and G. N. Watson. Cambridge University Press, 1915. Pp. viii, 560. Cloth, 18s. net\". VI. Critical Notices. Mind (review). XXV (4): 525–533. doi:10.1093/mind/XXV.4.525. ISSN 0026-4423. JSTOR 2248860. (9 pages)\nNeville, Eric Harold (1921). \"Review of A Course of Modern Analysis\". The Mathematical Gazette (review). 10 (152): 283. doi:10.2307/3604927. ISSN 0025-5572. JSTOR 3604927. (1 page)\nWrinch, Dorothy Maud (1921). \"Review of A Course of Modern Analysis. Third Edition\". Sc",
    "links": [
      "A History of the Theories of Aether and Electricity",
      "Aberystwyth University",
      "Adrien-Marie Legendre",
      "American Mathematical Monthly",
      "American Mathematical Society",
      "Analytical Dynamics of Particles and Rigid Bodies",
      "André Weil",
      "Arthur Stafford Hathaway",
      "Astronomy",
      "At the University Press",
      "Automorphic function",
      "Bateman Manuscript Project",
      "Bessel functions",
      "Bibcode (identifier)",
      "Bibliography of E. T. Whittaker",
      "Bulletin of the American Mathematical Society",
      "Cambridge Mathematical Tripos",
      "Cambridge University Press",
      "Carl Friedrich Gauss",
      "Complex analysis",
      "Complex integration",
      "Confluent hypergeometric function",
      "Decimal book section numbering",
      "Digitally reset (typesetting)",
      "Doi (identifier)",
      "Dorothy Maud Wrinch",
      "Edmund Frederick Robertson",
      "Edmund T. Whittaker",
      "Edmund Taylor Whittaker",
      "Edward Copson",
      "Electromagnetism",
      "Elliptic function",
      "Eric Harold Neville",
      "Fellow of the Royal Society",
      "Fellow of the Royal Society of Edinburgh",
      "Fourier expansion",
      "Friedrich Bessel",
      "Gamma function",
      "General relativity",
      "George Ballard Mathews",
      "George N. Watson",
      "George Neville Watson",
      "Giuseppe Peano",
      "Godfrey H. Hardy",
      "Harmonic function",
      "Hdl (identifier)",
      "History of science",
      "Hypergeometric series",
      "ISBN (identifier)",
      "ISSN (identifier)"
    ],
    "categories": [
      "Category:1902 non-fiction books",
      "Category:Articles with short description",
      "Category:Books by E. T. Whittaker",
      "Category:CS1 interwiki-linked names",
      "Category:Cambridge University Press books",
      "Category:Complex analysis",
      "Category:Mathematical analysis",
      "Category:Mathematics textbooks",
      "Category:Short description is different from Wikidata",
      "Category:Use British English from November 2020"
    ]
  },
  "Aerospace engineering": {
    "title": "Aerospace engineering",
    "url": "https://en.wikipedia.org/wiki/Aerospace_engineering",
    "summary": "Aerospace engineering is the primary field of engineering concerned with the development of aircraft and spacecraft.  It has two major and overlapping branches: aeronautical engineering and astronautical engineering.  Avionics engineering is similar, but deals with the electronics side of aerospace engineering.\n\"Aeronautical engineering\" was the original term for the field. As flight technology advanced to include vehicles operating in outer space, the broader term \"aerospace engineering\" has come into use.  Aerospace engineering, particularly the astronautics branch, is often colloquially referred to as \"rocket science\".",
    "content": "Aerospace engineering is the primary field of engineering concerned with the development of aircraft and spacecraft.  It has two major and overlapping branches: aeronautical engineering and astronautical engineering.  Avionics engineering is similar, but deals with the electronics side of aerospace engineering.\n\"Aeronautical engineering\" was the original term for the field. As flight technology advanced to include vehicles operating in outer space, the broader term \"aerospace engineering\" has come into use.  Aerospace engineering, particularly the astronautics branch, is often colloquially referred to as \"rocket science\".\n\nOverview\nFlight vehicles are subjected to demanding conditions such as those caused by changes in atmospheric pressure and temperature, with structural loads applied upon vehicle components. Consequently, they are usually the products of various technological and engineering disciplines including aerodynamics, air propulsion, avionics, materials science, structural analysis and manufacturing. The interaction between these technologies is known as aerospace engineering. Because of the complexity and number of disciplines involved, aerospace engineering is carried out by teams of engineers, each having their own specialized area of expertise.\n\nHistory\nThe origin of aerospace engineering can be traced back to the aviation pioneers around the late 19th to early 20th centuries, although the work of Sir George Cayley dates from the last decade of the 18th to the mid-19th century. One of the most important people in the history of aeronautics and a pioneer in aeronautical engineering, Cayley is credited as the first person to separate the forces of lift and drag, which affect any atmospheric flight vehicle.\nEarly knowledge of aeronautical engineering was largely empirical, with some concepts and skills imported from other branches of engineering. Some key elements, like fluid dynamics, were understood by 18th-century scientists.\nIn December 1903, the Wright Brothers performed the first sustained, controlled flight of a powered, heavier-than-air aircraft, lasting 12 seconds. The 1910s saw the development of aeronautical engineering through the design of World War I military aircraft.\n\nWorld War I\nIn 1914, Robert Goddard was granted two U.S. patents for rockets using solid fuel, liquid fuel, multiple propellant charges, and multi-stage designs. This would set the stage for future applications in multi-stage propulsion systems for outer space.\nOn March 3, 1915, the U.S. Congress established the first aeronautical research administration, known as the National Advisory Committee for Aeronautics, or NACA. It was the first government-sponsored organization to support aviation research. Though intended as an advisory board upon inception, the Langley Aeronautical Laboratory became its first sponsored research and testing facility in 1920.\nBetween World Wars I and II, great leaps were made in the field, accelerated by the advent of mainstream civil aviation. Notable airplanes of this era include the Curtiss JN 4, Farman F.60 Goliath, and Fokker Trimotor. Notable military airplanes of this period include the Mitsubishi A6M Zero, Supermarine Spitfire and Messerschmitt Bf 109 from Japan, United Kingdom, and Germany respectively. A significant development came with the first operational Jet engine-powered airplane, the Messerschmitt Me 262 which entered service in 1944 towards the end of the Second World War.\nThe first definition of aerospace engineering appeared in February 1958, considering the Earth's atmosphere and outer space as a single realm, thereby encompassing both aircraft (aero) and spacecraft (space) under the newly coined term aerospace.\n\nCold War\nIn response to the USSR launching the first satellite, Sputnik, into space on October 4, 1957, U.S. aerospace engineers launched the first American satellite on January 31, 1958. The National Aeronautics and Space Administration was founded in 1958 after the Sputnik crisis. In 1969, Apollo 11, the first human space mission to the Moon, took place. It saw three astronauts enter orbit around the Moon, with two, Neil Armstrong and Buzz Aldrin, visiting the lunar surface. The third astronaut, Michael Collins, stayed in orbit to rendezvous with Armstrong and Aldrin after their visit.\n\nAn important innovation came on January 30, 1970, when the Boeing 747 made its first commercial flight from New York to London. This aircraft made history and became known as the \"Jumbo Jet\" or \"Queen of the Skies\" due to its ability to hold up to 480 passengers.\n\n1976: First passenger supersonic aircraft\nAnother significant development came in 1976, with the development of the first passenger supersonic aircraft, the Concorde. The development of this aircraft was agreed upon by the French and British on November 29, 1962.\nOn December 21, 1988, the Antonov An-225 Mriya cargo aircraft commenced its first flight. It holds the records for the world's heaviest aircraft, heaviest",
    "links": [
      "Academic certificate",
      "Academic degree",
      "Academic tenure",
      "Acoustical engineering",
      "Ad eundem degree",
      "Aeroacoustics",
      "Aerodynamics",
      "Aeroelastic flutter",
      "Aeroelasticity",
      "Aeronautics",
      "Aerospace",
      "Aerospace bearing",
      "Agricultural engineering",
      "Air propulsion",
      "Airbus A380",
      "Aircraft",
      "Aircraft structures",
      "American Helicopter Society International",
      "American Institute of Aeronautics and Astronautics",
      "Antonov An-225 Mriya",
      "Apollo 11",
      "Apollo 13",
      "Apsis",
      "Architectural engineering",
      "Argument of periapsis",
      "Arthur David Hall III",
      "Artificial intelligence engineering",
      "Artist diploma",
      "Associate degree",
      "Astrodynamics",
      "Astronaut",
      "Astronautics",
      "Atmospheric pressure",
      "Audio engineer",
      "Automation engineering",
      "Automotive engineering",
      "Avionics",
      "Bachelor's degree",
      "Bachelor of Engineering",
      "Bachelor of Science",
      "Barbara Grosz",
      "Barycenter",
      "Benjamin S. Blanchard",
      "Bi-elliptic transfer",
      "Biochemical engineering",
      "Bioinformatics",
      "Biological engineering",
      "Biological systems engineering",
      "Biomaterial",
      "Biomechanical engineering"
    ],
    "categories": [
      "Category:Aerospace engineering",
      "Category:Aircraft maintenance",
      "Category:Articles with short description",
      "Category:CS1 maint: location missing publisher",
      "Category:Commons category link from Wikidata",
      "Category:Short description matches Wikidata",
      "Category:Webarchive template wayback links"
    ]
  },
  "Algebraically closed field": {
    "title": "Algebraically closed field",
    "url": "https://en.wikipedia.org/wiki/Algebraically_closed_field",
    "summary": "In mathematics, a field F is algebraically closed if every non-constant polynomial with coefficients in F has a root in F. In other words, a field is algebraically closed if the fundamental theorem of algebra holds for it.  For example, the field of real numbers is not algebraically closed because the polynomial \n  \n    \n      \n        \n          x\n          \n            2\n          \n        \n        +\n        1\n      \n    \n    {\\displaystyle x^{2}+1}\n  \n has no real roots, while the field of complex numbers is algebraically closed.\nEvery field \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n is contained in an algebraically closed field \n  \n    \n      \n        C\n        ,\n      \n    \n    {\\displaystyle C,}\n  \n and the roots in \n  \n    \n      \n        C\n      \n    \n    {\\displaystyle C}\n  \n of the polynomials with coefficients in \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n form an algebraically closed field called an algebraic closure of \n  \n    \n    ",
    "content": "In mathematics, a field F is algebraically closed if every non-constant polynomial with coefficients in F has a root in F. In other words, a field is algebraically closed if the fundamental theorem of algebra holds for it.  For example, the field of real numbers is not algebraically closed because the polynomial \n  \n    \n      \n        \n          x\n          \n            2\n          \n        \n        +\n        1\n      \n    \n    {\\displaystyle x^{2}+1}\n  \n has no real roots, while the field of complex numbers is algebraically closed.\nEvery field \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n is contained in an algebraically closed field \n  \n    \n      \n        C\n        ,\n      \n    \n    {\\displaystyle C,}\n  \n and the roots in \n  \n    \n      \n        C\n      \n    \n    {\\displaystyle C}\n  \n of the polynomials with coefficients in \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n form an algebraically closed field called an algebraic closure of \n  \n    \n      \n        K\n        .\n      \n    \n    {\\displaystyle K.}\n  \n Given two algebraic closures of \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n there are isomorphisms between them that fix the elements of \n  \n    \n      \n        K\n        .\n      \n    \n    {\\displaystyle K.}\n  \n\nAlgebraically closed fields appear in the following chain of class inclusions:\n\nrngs ⊃ rings ⊃ commutative rings ⊃  integral domains ⊃ integrally closed domains ⊃ GCD domains ⊃ unique factorization domains ⊃ principal ideal domains ⊃ euclidean domains ⊃ fields ⊃ algebraically closed fields\n\nExamples\nAs an example, the field of real numbers is not algebraically closed, because the polynomial equation \n  \n    \n      \n        \n          x\n          \n            2\n          \n        \n        +\n        1\n        =\n        0\n      \n    \n    {\\displaystyle x^{2}+1=0}\n  \n has no solution in real numbers, even though all its coefficients (1 and 0) are real.  The same argument proves that no subfield of the real field is algebraically closed; in particular, the field of rational numbers is not algebraically closed. By contrast, the fundamental theorem of algebra states that the field of complex numbers is algebraically closed. Another example of an algebraically closed field is the field of (complex) algebraic numbers.\nNo finite field F is algebraically closed, because if a1, a2, ..., an are the elements of F, then the polynomial (x − a1)(x − a2) ⋯ (x − an) + 1\nhas no zero in F. However, the union of all finite fields of a fixed characteristic p (p prime) is an algebraically closed field, which is, in fact, the algebraic closure of the field \n  \n    \n      \n        \n          \n            F\n          \n          \n            p\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {F} _{p}}\n  \n with p elements.\nThe field \n  \n    \n      \n        \n          C\n        \n        (\n        x\n        )\n      \n    \n    {\\displaystyle \\mathbb {C} (x)}\n  \n of rational functions with complex coefficients is not closed; for example, the polynomial \n  \n    \n      \n        \n          y\n          \n            2\n          \n        \n        −\n        x\n      \n    \n    {\\displaystyle y^{2}-x}\n  \n has roots \n  \n    \n      \n        ±\n        \n          \n            x\n          \n        \n      \n    \n    {\\displaystyle \\pm {\\sqrt {x}}}\n  \n, which are not elements of \n  \n    \n      \n        \n          C\n        \n        (\n        x\n        )\n      \n    \n    {\\displaystyle \\mathbb {C} (x)}\n  \n.\n\nEquivalent properties\nGiven a field F, the assertion \"F is algebraically closed\" is equivalent to other assertions:\n\nThe only irreducible polynomials are those of degree one\nThe field F is algebraically closed if and only if the only irreducible polynomials in the polynomial ring F[x] are those of degree one.\nThe assertion \"the polynomials of degree one are irreducible\" is trivially true for any field. If F is algebraically closed and p(x) is an irreducible polynomial of F[x], then it has some root a and therefore p(x) is a multiple of x − a. Since p(x) is irreducible, this means that p(x) = k(x − a), for some k ∈ F \\ {0} . On the other hand, if F is not algebraically closed, then there is some non-constant polynomial p(x) in F[x] without roots in F. Let q(x) be some irreducible factor of p(x). Since p(x) has no roots in F, q(x) also has no roots in F. Therefore, q(x) has degree greater than one, since every first degree polynomial has one root in F.\n\nEvery polynomial is a product of first degree polynomials\nThe field F is algebraically closed if and only if every polynomial p(x) of degree n ≥ 1, with coefficients in F, splits into linear factors. In other words, there are elements k, x1, x2, ..., xn of the field F such that p(x) = k(x − x1)(x − x2) ⋯ (x − xn).\nIf F has this property, then clearly every non-constant polynomial in F[x] has some root in F; in other words, F is algebraically closed. On the other hand, that the property stated here holds for F if F is algebraically",
    "links": [
      "Algebraic closure",
      "Algebraic extension",
      "Algebraic number",
      "Bartel Leendert van der Waerden",
      "Characteristic (algebra)",
      "Characteristic polynomial",
      "Coefficient",
      "Commutative ring",
      "Companion matrix",
      "Complex number",
      "Coprime polynomials",
      "Degree of a field extension",
      "Doi (identifier)",
      "Eigenvector",
      "Endomorphism",
      "Essentially unique",
      "Euclidean domain",
      "Factorization",
      "Field (mathematics)",
      "Finite extension",
      "Finite field",
      "First-order logic",
      "Fundamental theorem of algebra",
      "GCD domain",
      "Graduate Texts in Mathematics",
      "Greatest common divisor",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "Ideal (ring theory)",
      "Integral domain",
      "Integrally closed domain",
      "Irreducible polynomial",
      "Jon Barwise",
      "Linear map",
      "MR (identifier)",
      "Mathematical Intelligencer",
      "Mathematics",
      "Minimal polynomial (field theory)",
      "Partial fraction decomposition",
      "Polynomial",
      "Polynomial ring",
      "Principal ideal domain",
      "Pseudo algebraically closed field",
      "Quadratically closed field",
      "Quantifier elimination",
      "Quasi-algebraically closed field",
      "Quotient ring",
      "Rational function",
      "Rational number",
      "Real closed field"
    ],
    "categories": [
      "Category:All articles lacking in-text citations",
      "Category:Articles lacking in-text citations from September 2021",
      "Category:Articles with short description",
      "Category:Field (mathematics)",
      "Category:Short description is different from Wikidata",
      "Category:Use dmy dates from October 2020"
    ]
  },
  "Analyticity of holomorphic functions": {
    "title": "Analyticity of holomorphic functions",
    "url": "https://en.wikipedia.org/wiki/Analyticity_of_holomorphic_functions",
    "summary": "In complex analysis, a complex-valued function \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n of a complex variable \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n  \n:\n\nis said to be holomorphic at a point \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n if it is differentiable at every point within some open disk centered at \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n, and\nis said to be analytic at \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n if in some open disk centered at \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n it can be expanded as a convergent power series \n  \n    \n      \n        f\n        (\n        z\n        )\n        =\n        \n          ∑\n          \n            n\n            =\n            0\n          \n          \n            ∞\n          \n        \n        \n          c\n          \n            n\n          \n        \n        (\n        z\n        −\n        a\n        \n          )\n",
    "content": "In complex analysis, a complex-valued function \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n of a complex variable \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n  \n:\n\nis said to be holomorphic at a point \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n if it is differentiable at every point within some open disk centered at \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n, and\nis said to be analytic at \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n if in some open disk centered at \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n it can be expanded as a convergent power series \n  \n    \n      \n        f\n        (\n        z\n        )\n        =\n        \n          ∑\n          \n            n\n            =\n            0\n          \n          \n            ∞\n          \n        \n        \n          c\n          \n            n\n          \n        \n        (\n        z\n        −\n        a\n        \n          )\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle f(z)=\\sum _{n=0}^{\\infty }c_{n}(z-a)^{n}}\n  \n (this implies that the radius of convergence is positive).\nOne of the most important theorems of complex analysis is that holomorphic functions are analytic and vice versa.  Among the corollaries of this theorem are\n\nthe identity theorem that two holomorphic functions that agree at every point of an infinite set \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n with an accumulation point inside the intersection of their domains also agree everywhere in every connected open subset of their domains that contains the set \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n, and\nthe fact that, since power series are infinitely differentiable, so are holomorphic functions (this is in contrast to the case of real differentiable functions), and\nthe fact that the radius of convergence is always the distance from the center \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n to the nearest non-removable singularity; if there are no singularities (i.e., if \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n is an entire function), then the radius of convergence is infinite.  Strictly speaking, this is not a corollary of the theorem but rather a by-product of the proof.\nno bump function on the complex plane can be entire.  In particular, on any connected open subset of the complex plane, there can be no bump function defined on that set which is holomorphic on the set.  This has important ramifications for the study of complex manifolds, as it precludes the use of partitions of unity.  In contrast the partition of unity is a tool which can be used on any real manifold.\n\nProof\nThe argument, first given by Cauchy, hinges on Cauchy's integral formula and the power series expansion of the expression\n\n  \n    \n      \n        \n          \n            1\n            \n              w\n              −\n              z\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle {\\frac {1}{w-z}}.}\n  \n\nLet \n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n  \n be an open disk centered at \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n and suppose \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n is differentiable everywhere within an open neighborhood containing the closure of \n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n  \n.  Let \n  \n    \n      \n        C\n      \n    \n    {\\displaystyle C}\n  \n be the positively oriented (i.e., counterclockwise) circle which is the boundary of \n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n  \n and let \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n  \n be a point in \n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n  \n.  Starting with Cauchy's integral formula, we have\n\n  \n    \n      \n        \n          \n            \n              \n                f\n                (\n                z\n                )\n              \n              \n                \n                \n\n                \n                =\n                \n                  \n                    1\n                    \n                      2\n                      π\n                      i\n                    \n                  \n                \n                \n                  ∫\n                  \n                    C\n                  \n                \n                \n                  \n                    \n                      f\n                      (\n                      w\n                      )\n                    \n                    \n                      w\n                      −\n                      z\n                    \n                  \n                \n                \n                \n                  d\n                \n                w\n              \n            \n            \n              \n              \n                \n                \n\n                \n           ",
    "links": [
      "Accumulation point",
      "Analytic continuation",
      "Analytic function",
      "Antiderivative (complex analysis)",
      "Argument principle",
      "Augustin-Louis Cauchy",
      "Bernhard Riemann",
      "Bump function",
      "Carl Friedrich Gauss",
      "Cauchy's integral formula",
      "Cauchy's integral theorem",
      "Cauchy–Riemann equations",
      "Complex analysis",
      "Complex conjugate",
      "Complex manifold",
      "Complex number",
      "Complex plane",
      "Conformal map",
      "Connected set",
      "Convergent series",
      "Converges uniformly",
      "Differentiable function",
      "Distance",
      "Domain of a function",
      "Entire function",
      "Essential singularity",
      "Euler's formula",
      "Formal power series",
      "Function (mathematics)",
      "Geometric function theory",
      "Holomorphic function",
      "Identity theorem",
      "Imaginary number",
      "Infinite set",
      "Infinitely differentiable",
      "Intersection",
      "Isolated singularity",
      "Karl Weierstrass",
      "Laurent series",
      "Leonhard Euler",
      "Liouville's theorem (complex analysis)",
      "Mathematical analysis",
      "Mathematical singularity",
      "Meromorphic function",
      "Open disk",
      "Open neighborhood",
      "Partitions of unity",
      "Picard theorem",
      "PlanetMath",
      "Power series"
    ],
    "categories": [
      "Category:Analytic functions",
      "Category:Article proofs",
      "Category:Articles with short description",
      "Category:Short description matches Wikidata",
      "Category:Theorems in complex analysis"
    ]
  },
  "Antiderivative (complex analysis)": {
    "title": "Antiderivative (complex analysis)",
    "url": "https://en.wikipedia.org/wiki/Antiderivative_(complex_analysis)",
    "summary": "In complex analysis, a branch of mathematics, the antiderivative, or primitive, of a complex-valued function g is a function whose complex derivative is g. More precisely, given an open set \n  \n    \n      \n        U\n      \n    \n    {\\displaystyle U}\n  \n in the complex plane and a function \n  \n    \n      \n        g\n        :\n        U\n        →\n        \n          C\n        \n        ,\n      \n    \n    {\\displaystyle g:U\\to \\mathbb {C} ,}\n  \n the antiderivative of \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n  \n is a function \n  \n    \n      \n        f\n        :\n        U\n        →\n        \n          C\n        \n      \n    \n    {\\displaystyle f:U\\to \\mathbb {C} }\n  \n that satisfies \n  \n    \n      \n        \n          \n            \n              d\n              f\n            \n            \n              d\n              z\n            \n          \n        \n        =\n        g\n      \n    \n    {\\displaystyle {\\frac {df}{dz}}=g}\n  \n.\nAs such, this concept is the complex-variable versio",
    "content": "In complex analysis, a branch of mathematics, the antiderivative, or primitive, of a complex-valued function g is a function whose complex derivative is g. More precisely, given an open set \n  \n    \n      \n        U\n      \n    \n    {\\displaystyle U}\n  \n in the complex plane and a function \n  \n    \n      \n        g\n        :\n        U\n        →\n        \n          C\n        \n        ,\n      \n    \n    {\\displaystyle g:U\\to \\mathbb {C} ,}\n  \n the antiderivative of \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n  \n is a function \n  \n    \n      \n        f\n        :\n        U\n        →\n        \n          C\n        \n      \n    \n    {\\displaystyle f:U\\to \\mathbb {C} }\n  \n that satisfies \n  \n    \n      \n        \n          \n            \n              d\n              f\n            \n            \n              d\n              z\n            \n          \n        \n        =\n        g\n      \n    \n    {\\displaystyle {\\frac {df}{dz}}=g}\n  \n.\nAs such, this concept is the complex-variable version of the antiderivative of a real-valued function.\n\nUniqueness\nThe derivative of a constant function is the zero function. Therefore, any constant function is an antiderivative of the zero function. If \n  \n    \n      \n        U\n      \n    \n    {\\displaystyle U}\n  \n is a connected set, then the constant functions are the only antiderivatives of the zero function. Otherwise, a function is an antiderivative of the zero function if and only if it is constant on each connected component of \n  \n    \n      \n        U\n      \n    \n    {\\displaystyle U}\n  \n (those constants need not be equal).\nThis observation implies that if a function \n  \n    \n      \n        g\n        :\n        U\n        →\n        \n          C\n        \n      \n    \n    {\\displaystyle g:U\\to \\mathbb {C} }\n  \n has an antiderivative, then that antiderivative is unique up to addition of a function which is constant on each connected component of \n  \n    \n      \n        U\n      \n    \n    {\\displaystyle U}\n  \n.\n\nExistence\nBy Cauchy's integral formula, which shows that a differentiable function is in fact infinitely differentiable, a function \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n must itself be differentiable if it has an antiderivative \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n, because if \n  \n    \n      \n        \n          F\n          ′\n        \n        =\n        f\n      \n    \n    {\\displaystyle F'=f}\n  \n then \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n is differentiable and so \n  \n    \n      \n        \n          F\n          ″\n        \n        =\n        \n          f\n          ′\n        \n      \n    \n    {\\displaystyle F''=f'}\n  \n exists.\nOne can characterize the existence of antiderivatives via path integrals in the complex plane, much like the case of functions of a real variable. Perhaps not surprisingly, g has an antiderivative f if and only if, for every γ path from a to b, the path integral\n\n  \n    \n      \n        \n          ∫\n          \n            γ\n          \n        \n        g\n        (\n        ζ\n        )\n        \n        d\n        ζ\n        =\n        f\n        (\n        b\n        )\n        −\n        f\n        (\n        a\n        )\n        .\n      \n    \n    {\\displaystyle \\int _{\\gamma }g(\\zeta )\\,d\\zeta =f(b)-f(a).}\n  \n\nEquivalently,\n\n  \n    \n      \n        \n          ∮\n          \n            γ\n          \n        \n        g\n        (\n        ζ\n        )\n        \n        d\n        ζ\n        =\n        0\n        ,\n      \n    \n    {\\displaystyle \\oint _{\\gamma }g(\\zeta )\\,d\\zeta =0,}\n  \n\nfor any closed path γ.\nHowever, this formal similarity notwithstanding, possessing a complex-antiderivative is a much more restrictive condition than its real counterpart. While it is possible for a discontinuous real function to have an anti-derivative, anti-derivatives can fail to exist even for holomorphic functions of a complex variable. For example, consider the reciprocal function, g(z) = 1/z which is holomorphic on the punctured plane C\\{0}. A direct calculation shows that the integral of g along any circle enclosing the origin is non-zero. So g fails the condition cited above. This is similar to the existence of potential functions for conservative vector fields, in that Green's theorem is only able to guarantee path independence when the function in question is defined on a simply connected region, as in the case of the Cauchy integral theorem.\nIn fact, holomorphy is characterized by having an antiderivative locally, that is, g is holomorphic if for every z in its domain, there is some neighborhood U of z such that g has an antiderivative on U. Furthermore, holomorphy is a necessary condition for a function to have an antiderivative, since the derivative of any holomorphic function is holomorphic.\nVarious versions of Cauchy integral theorem, an underpinning result of Cauchy function theory, which makes heavy use of path integrals, gives sufficient conditions under which, for a holomorphic g,\n\n  \n    \n      \n   ",
    "links": [
      "Analytic continuation",
      "Analytic function",
      "Analyticity of holomorphic functions",
      "Antiderivative",
      "Argument principle",
      "Augustin-Louis Cauchy",
      "Bernhard Riemann",
      "Carl Friedrich Gauss",
      "Cauchy's integral formula",
      "Cauchy's integral theorem",
      "Cauchy integral theorem",
      "Cauchy–Riemann equations",
      "Chain rule",
      "Complex analysis",
      "Complex conjugate",
      "Complex derivative",
      "Complex manifold",
      "Complex number",
      "Complex plane",
      "Conformal map",
      "Connected set",
      "Conservative vector field",
      "David O. Tall",
      "Entire function",
      "Eric W. Weisstein",
      "Essential singularity",
      "Euler's formula",
      "Formal power series",
      "Function (mathematics)",
      "Fundamental theorem of calculus",
      "Geometric function theory",
      "Green's theorem",
      "Holomorphic function",
      "ISBN (identifier)",
      "Imaginary number",
      "Isolated singularity",
      "Karl Weierstrass",
      "Laurent series",
      "Leonhard Euler",
      "Line integral",
      "Liouville's theorem (complex analysis)",
      "MathWorld",
      "Mathematical analysis",
      "Mathematics",
      "Meromorphic function",
      "Open set",
      "Path (topology)",
      "Picard theorem",
      "Quasiconformal mapping",
      "Real number"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Complex analysis",
      "Category:Short description matches Wikidata"
    ]
  },
  "Arc (geometry)": {
    "title": "Curve",
    "url": "https://en.wikipedia.org/wiki/Curve",
    "summary": "In mathematics, a curve (also called a curved line in older texts) is an object similar to a line, but that does not have to be straight.\nIntuitively, a curve may be thought of as the trace left by a moving point. This is the definition that appeared more than 2000 years ago in Euclid's Elements: \"The [curved] line is […] the first species of quantity, which has only one dimension, namely length, without any width nor depth, and is nothing else than the flow or run of the point which […] will leave from its imaginary moving some vestige in length, exempt of any width.\"\nThis definition of a curve has been formalized in modern mathematics as: A curve is the image of an interval to a topological space by a continuous function. In some contexts, the function that defines the curve is called a parametrization, and the curve is a parametric curve. In this article, these curves are sometimes called topological curves to distinguish them from more constrained curves such as differentiable curv",
    "content": "In mathematics, a curve (also called a curved line in older texts) is an object similar to a line, but that does not have to be straight.\nIntuitively, a curve may be thought of as the trace left by a moving point. This is the definition that appeared more than 2000 years ago in Euclid's Elements: \"The [curved] line is […] the first species of quantity, which has only one dimension, namely length, without any width nor depth, and is nothing else than the flow or run of the point which […] will leave from its imaginary moving some vestige in length, exempt of any width.\"\nThis definition of a curve has been formalized in modern mathematics as: A curve is the image of an interval to a topological space by a continuous function. In some contexts, the function that defines the curve is called a parametrization, and the curve is a parametric curve. In this article, these curves are sometimes called topological curves to distinguish them from more constrained curves such as differentiable curves. This definition encompasses most curves that are studied in mathematics; notable exceptions are level curves (which are unions of curves and isolated points), and algebraic curves (see below). Level curves and algebraic curves are sometimes called implicit curves, since they are generally defined by implicit equations.\nNevertheless, the class of topological curves is very broad, and contains some curves that do not look as one may expect for a curve, or even cannot be drawn. This is the case of space-filling curves and fractal curves. For ensuring more regularity, the function that defines a curve is often supposed to be differentiable, and the curve is then said to be a differentiable curve.\nA plane algebraic curve is the zero set of a polynomial in two indeterminates. More generally, an algebraic curve is the zero set of a finite set of polynomials, which satisfies the further condition of being an algebraic variety of dimension one. If the coefficients of the polynomials belong to a field k, the curve is said to be defined over k. In the common case of a real algebraic curve, where k is the field of real numbers, an algebraic curve is a finite union of topological curves. When complex zeros are considered, one has a complex algebraic curve, which, from the topological point of view, is not a curve, but a surface, and is often called a Riemann surface. Although not being curves in the common sense, algebraic curves defined over other fields have been widely studied. In particular, algebraic curves over a finite field are widely used in modern cryptography.\n\nHistory\nInterest in curves began long before they were the subject of mathematical study.  This can be seen in numerous examples of their decorative use in art and on everyday objects dating back to prehistoric times. Curves, or at least their graphical representations, are simple to create, for example with a stick on the sand on a beach.\nHistorically, the term line was used in place of the more modern term curve. Hence the terms straight line and right line were used to distinguish what are today called lines from curved lines. For example, in Book I of Euclid's Elements, a line is defined as a \"breadthless length\" (Def. 2), while a straight line is defined as \"a line that lies evenly with the points on itself\" (Def. 4). Euclid's idea of a line is perhaps clarified by the statement \"The extremities of a line are points,\" (Def. 3). Later commentators further classified lines according to various schemes. For example:\n\nComposite lines (lines forming an angle)\nIncomposite lines\nDeterminate (lines that do not extend indefinitely, such as the circle)\nIndeterminate (lines that extend indefinitely, such as the straight line and the parabola)\n\nThe Greek geometers had studied many other kinds of curves. One reason was their interest in solving geometrical problems that could not be solved using standard compass and straightedge construction.\nThese curves include:\n\nThe conic sections, studied in depth by Apollonius of Perga\nThe cissoid of Diocles, studied by Diocles and used as a method to double the cube.\nThe conchoid of Nicomedes, studied by Nicomedes as a method to both double the cube and to trisect an angle.\nThe Archimedean spiral, studied by Archimedes as a method to trisect an angle and square the circle.\nThe spiric sections, sections of tori studied by Perseus as sections of cones had been studied by Apollonius.\n\nA fundamental advance in the theory of curves was the introduction of analytic geometry by René Descartes in the seventeenth century. This enabled a curve to be described using an equation rather than an elaborate geometrical construction. This not only allowed new curves to be defined and studied, but it enabled a formal distinction to be made between algebraic curves that can be defined using polynomial equations, and transcendental curves that cannot. Previously, curves had been described as \"geometrical\" or \"mechanical\" according to how they were, or supp",
    "links": [
      "310 helix",
      "Algebraic curve",
      "Algebraic geometry",
      "Algebraic varieties",
      "Algebraic variety",
      "Algebraically closed field",
      "Alpha helix",
      "American Mathematical Society",
      "Analytic geometry",
      "Angle trisection",
      "Apollonius of Perga",
      "Arc (projective geometry)",
      "Arc length",
      "Archimedean spiral",
      "Archimedes",
      "Astronomy",
      "Atlas (topology)",
      "Beta helix",
      "Bijection",
      "Boerdijk–Coxeter helix",
      "Brachistochrone",
      "Bézout's theorem",
      "Calculus of variations",
      "Catenary",
      "Chart (topology)",
      "Circle",
      "Circular arc",
      "Cissoid of Diocles",
      "Classical mechanics",
      "Closed set",
      "Collagen helix",
      "Compass and straightedge",
      "Complete intersection",
      "Complex number",
      "Conchoid of Nicomedes",
      "Conic section",
      "Connected component (topology)",
      "Connected set",
      "Connected space",
      "Continuous function",
      "Continuous function (topology)",
      "Continuously differentiable",
      "Coordinate curve",
      "Cotes's spiral",
      "Crinkled arc",
      "Cryptography",
      "Cubic curve",
      "Curvature",
      "Curve (disambiguation)",
      "Curve fitting"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1 errors: ISBN date",
      "Category:Commons category link is on Wikidata",
      "Category:Curves",
      "Category:General topology",
      "Category:Metric geometry",
      "Category:Short description matches Wikidata",
      "Category:Topology",
      "Category:Wikipedia articles needing clarification from May 2019"
    ]
  },
  "Bounded function": {
    "title": "Bounded function",
    "url": "https://en.wikipedia.org/wiki/Bounded_function",
    "summary": "In mathematics, a function \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n defined on some set \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n with real or complex values is called bounded if the set of its values (its image) is bounded. In other words, there exists a real number \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n  \n such that \n\n  \n    \n      \n        \n          |\n        \n        f\n        (\n        x\n        )\n        \n          |\n        \n        ≤\n        M\n      \n    \n    {\\displaystyle |f(x)|\\leq M}\n  \n\nfor all \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n in \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n. A function that is not bounded is said to be unbounded.\nIf \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n is real-valued and \n  \n    \n      \n        f\n        (\n        x\n        )\n        ≤\n        A\n      \n    \n    {\\displaystyle f(x)\\leq A}\n  \n for all \n  \n    \n     ",
    "content": "In mathematics, a function \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n defined on some set \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n with real or complex values is called bounded if the set of its values (its image) is bounded. In other words, there exists a real number \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n  \n such that \n\n  \n    \n      \n        \n          |\n        \n        f\n        (\n        x\n        )\n        \n          |\n        \n        ≤\n        M\n      \n    \n    {\\displaystyle |f(x)|\\leq M}\n  \n\nfor all \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n in \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n. A function that is not bounded is said to be unbounded.\nIf \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n is real-valued and \n  \n    \n      \n        f\n        (\n        x\n        )\n        ≤\n        A\n      \n    \n    {\\displaystyle f(x)\\leq A}\n  \n for all \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n in \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n, then the function is said to be bounded (from) above by \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n. If \n  \n    \n      \n        f\n        (\n        x\n        )\n        ≥\n        B\n      \n    \n    {\\displaystyle f(x)\\geq B}\n  \n for all \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n in \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n, then the function is said to be bounded (from) below by \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  \n. A real-valued function is bounded if and only if it is bounded from above and below.\nAn important special case is a bounded sequence, where \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is taken to be the set \n  \n    \n      \n        \n          N\n        \n      \n    \n    {\\displaystyle \\mathbb {N} }\n  \n of natural numbers. Thus a sequence \n  \n    \n      \n        f\n        =\n        (\n        \n          a\n          \n            0\n          \n        \n        ,\n        \n          a\n          \n            1\n          \n        \n        ,\n        \n          a\n          \n            2\n          \n        \n        ,\n        …\n        )\n      \n    \n    {\\displaystyle f=(a_{0},a_{1},a_{2},\\ldots )}\n  \n is bounded if there exists a real number \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n  \n such that\n\n  \n    \n      \n        \n          |\n        \n        \n          a\n          \n            n\n          \n        \n        \n          |\n        \n        ≤\n        M\n      \n    \n    {\\displaystyle |a_{n}|\\leq M}\n  \n\nfor every natural number \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n. The set of all bounded sequences forms the sequence space \n  \n    \n      \n        \n          l\n          \n            ∞\n          \n        \n      \n    \n    {\\displaystyle l^{\\infty }}\n  \n.\nThe definition of boundedness can be generalized to functions \n  \n    \n      \n        f\n        :\n        X\n        →\n        Y\n      \n    \n    {\\displaystyle f:X\\rightarrow Y}\n  \n taking values in a more general space \n  \n    \n      \n        Y\n      \n    \n    {\\displaystyle Y}\n  \n by requiring that the image \n  \n    \n      \n        f\n        (\n        X\n        )\n      \n    \n    {\\displaystyle f(X)}\n  \n is a bounded set in \n  \n    \n      \n        Y\n      \n    \n    {\\displaystyle Y}\n  \n.\n\nRelated notions\nWeaker than boundedness is local boundedness. A family of bounded functions may be uniformly bounded. \nA bounded operator \n  \n    \n      \n        T\n        :\n        X\n        →\n        Y\n      \n    \n    {\\displaystyle T:X\\rightarrow Y}\n  \n is not a bounded function in the sense of this page's definition (unless \n  \n    \n      \n        T\n        =\n        0\n      \n    \n    {\\displaystyle T=0}\n  \n), but has the weaker property of preserving boundedness; bounded sets \n  \n    \n      \n        M\n        ⊆\n        X\n      \n    \n    {\\displaystyle M\\subseteq X}\n  \n are mapped to bounded sets \n  \n    \n      \n        T\n        (\n        M\n        )\n        ⊆\n        Y\n      \n    \n    {\\displaystyle T(M)\\subseteq Y}\n  \n. This definition can be extended to any function \n  \n    \n      \n        f\n        :\n        X\n        →\n        Y\n      \n    \n    {\\displaystyle f:X\\rightarrow Y}\n  \n if \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n and \n  \n    \n      \n        Y\n      \n    \n    {\\displaystyle Y}\n  \n allow for the concept of a bounded set. Boundedness can also be determined by looking at a graph.\n\nExamples\nThe sine function \n  \n    \n      \n        sin\n        :\n        \n          R\n        \n        →\n        \n          R\n        \n      \n    \n    {\\displaystyle \\sin :\\mathbb {R} \\rightarrow \\mathbb {R} }\n  \n is bounded since \n  \n    \n      \n        \n          |\n        \n        sin\n        ⁡\n        (\n        x\n        )\n        \n          |\n        \n        ≤\n        1\n      \n    \n    {\\displaystyle |\\sin(x)",
    "links": [
      "*-algebra",
      "Almost everywhere",
      "Babenko–Beckner inequality",
      "Banach space",
      "Bessel's inequality",
      "Bochner space",
      "Bounded operator",
      "Bounded set",
      "Boundedness theorem",
      "Brunn–Minkowski theorem",
      "C*-algebra",
      "Cauchy–Schwarz inequality",
      "Chebyshev's inequality",
      "Chebyshev distance",
      "Clarkson's inequalities",
      "Compact space",
      "Complex number",
      "Continuous function",
      "Convergence almost everywhere",
      "Convergence in measure",
      "Entire function",
      "Essential infimum and essential supremum",
      "Euclidean distance",
      "For all",
      "Fourier analysis",
      "Function (mathematics)",
      "Function space",
      "Hanner's inequalities",
      "Hausdorff–Young inequality",
      "Hilbert space",
      "Hölder's inequality",
      "ISBN (identifier)",
      "Image (mathematics)",
      "Infimum and supremum",
      "Integrable function",
      "Integral transform",
      "Inverse trigonometric function",
      "Irrational number",
      "Isoperimetric inequality",
      "L-infinity",
      "L1 space",
      "L2 space",
      "Lebesgue integration",
      "Lebesgue measure",
      "Liouville's theorem (complex analysis)",
      "Local boundedness",
      "Locally integrable function",
      "Lorentz space",
      "Lp space",
      "Marcinkiewicz interpolation theorem"
    ],
    "categories": [
      "Category:All articles needing additional references",
      "Category:All articles with unsourced statements",
      "Category:Articles needing additional references from September 2021",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from September 2021",
      "Category:Complex analysis",
      "Category:Real analysis",
      "Category:Short description is different from Wikidata",
      "Category:Types of functions"
    ]
  },
  "Cauchy's integral formula": {
    "title": "Cauchy's integral formula",
    "url": "https://en.wikipedia.org/wiki/Cauchy%27s_integral_formula",
    "summary": "In mathematics, Cauchy's integral formula, named after Augustin-Louis Cauchy, is a central statement in complex analysis. It expresses the fact that a holomorphic function defined on a disk is completely determined by its values on the boundary of the disk, and it provides integral formulas for all derivatives of a holomorphic function. Cauchy's formula shows that, in complex analysis, \"differentiation is equivalent to integration\": complex differentiation, like integration, behaves well under uniform limits – a result that does not hold in real analysis.",
    "content": "In mathematics, Cauchy's integral formula, named after Augustin-Louis Cauchy, is a central statement in complex analysis. It expresses the fact that a holomorphic function defined on a disk is completely determined by its values on the boundary of the disk, and it provides integral formulas for all derivatives of a holomorphic function. Cauchy's formula shows that, in complex analysis, \"differentiation is equivalent to integration\": complex differentiation, like integration, behaves well under uniform limits – a result that does not hold in real analysis.\n\nTheorem\nLet U be an open subset of the complex plane C, and suppose the closed disk D defined as\n\n  \n    \n      \n        D\n        =\n        \n          \n            {\n          \n        \n        z\n        :\n        \n          |\n        \n        z\n        −\n        \n          z\n          \n            0\n          \n        \n        \n          |\n        \n        ≤\n        r\n        \n          \n            }\n          \n        \n      \n    \n    {\\displaystyle D={\\bigl \\{}z:|z-z_{0}|\\leq r{\\bigr \\}}}\n  \n\nis completely contained in U.  Let f : U → C be a holomorphic function, and let γ be the circle, oriented counterclockwise, forming the boundary of D. Then for every a in the interior of D,\n\n  \n    \n      \n        f\n        (\n        a\n        )\n        =\n        \n          \n            1\n            \n              2\n              π\n              i\n            \n          \n        \n        \n          ∮\n          \n            γ\n          \n        \n        \n          \n            \n              f\n              (\n              z\n              )\n            \n            \n              z\n              −\n              a\n            \n          \n        \n        \n        d\n        z\n        .\n        \n      \n    \n    {\\displaystyle f(a)={\\frac {1}{2\\pi i}}\\oint _{\\gamma }{\\frac {f(z)}{z-a}}\\,dz.\\,}\n  \n\nThe proof of this statement uses the Cauchy integral theorem and like that theorem, it only requires f to be complex differentiable.  Since \n  \n    \n      \n        1\n        \n          /\n        \n        (\n        z\n        −\n        a\n        )\n      \n    \n    {\\displaystyle 1/(z-a)}\n  \n can be expanded as a power series in the variable \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n\n  \n    \n      \n        \n          \n            1\n            \n              z\n              −\n              a\n            \n          \n        \n        =\n        \n          \n            \n              1\n              +\n              \n                \n                  a\n                  z\n                \n              \n              +\n              \n                \n                  (\n                  \n                    \n                      a\n                      z\n                    \n                  \n                  )\n                \n                \n                  2\n                \n              \n              +\n              ⋯\n            \n            z\n          \n        \n      \n    \n    {\\displaystyle {\\frac {1}{z-a}}={\\frac {1+{\\frac {a}{z}}+\\left({\\frac {a}{z}}\\right)^{2}+\\cdots }{z}}}\n  \n\nit follows that holomorphic functions are analytic, i.e. they can be expanded as convergent power series.\nIn particular f is actually infinitely differentiable, with\n\n  \n    \n      \n        \n          f\n          \n            (\n            n\n            )\n          \n        \n        (\n        a\n        )\n        =\n        \n          \n            \n              n\n              !\n            \n            \n              2\n              π\n              i\n            \n          \n        \n        \n          ∮\n          \n            γ\n          \n        \n        \n          \n            \n              f\n              (\n              z\n              )\n            \n            \n              \n                (\n                \n                  z\n                  −\n                  a\n                \n                )\n              \n              \n                n\n                +\n                1\n              \n            \n          \n        \n        \n        d\n        z\n        .\n      \n    \n    {\\displaystyle f^{(n)}(a)={\\frac {n!}{2\\pi i}}\\oint _{\\gamma }{\\frac {f(z)}{\\left(z-a\\right)^{n+1}}}\\,dz.}\n  \n\nThis formula is sometimes referred to as Cauchy's differentiation formula.\nThe theorem stated above can be generalized. The circle γ can be replaced by any closed rectifiable curve in U which has winding number one about a. Moreover, as for the Cauchy integral theorem, it is sufficient to require that f be holomorphic in the open region enclosed by the path and continuous on its closure.\nNote that not every continuous function on the boundary can be used to produce a function inside the boundary that fits the given boundary function. For instance, if we put the function  f(z) = ⁠1/z⁠, defined for |z| = 1, into the Cauchy integral formula, we get zero for all points inside the circle. In fact, giving just the real part on the boundary of a holomorphic function is enough",
    "links": [
      "Absolute value",
      "Analytic continuation",
      "Analytic function",
      "Analyticity of holomorphic functions",
      "Antiderivative (complex analysis)",
      "Argument principle",
      "Augustin-Louis Cauchy",
      "Ball (mathematics)",
      "Bernhard Riemann",
      "Bivector",
      "Bochner–Martinelli formula",
      "Boundary (topology)",
      "Carl Friedrich Gauss",
      "Cartesian product",
      "Cauchy's estimate",
      "Cauchy's integral theorem",
      "Cauchy formula for repeated integration",
      "Cauchy integral theorem",
      "Cauchy principal value",
      "Cauchy–Goursat theorem",
      "Cauchy–Riemann equations",
      "Cauchy–Riemann operator",
      "Circle",
      "Closure (topology)",
      "Complex analysis",
      "Complex conjugate",
      "Complex differentiable",
      "Complex manifold",
      "Complex number",
      "Complex plane",
      "Conformal map",
      "Continuously differentiable function",
      "Contour integration",
      "Convolution",
      "Curl (mathematics)",
      "Curve orientation",
      "Dimitrie Pompeiu",
      "Distribution (mathematics)",
      "Distributional derivative",
      "Divergence",
      "Divergence theorem",
      "Dominated convergence theorem",
      "Edward Charles Titchmarsh",
      "Encyclopedia of Mathematics",
      "Entire function",
      "Eric W. Weisstein",
      "Essential singularity",
      "Euler's formula",
      "European Mathematical Society",
      "Formal power series"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Augustin-Louis Cauchy",
      "Category:Short description matches Wikidata",
      "Category:Theorems in complex analysis"
    ]
  },
  "Cauchy's integral theorem": {
    "title": "Cauchy's integral theorem",
    "url": "https://en.wikipedia.org/wiki/Cauchy%27s_integral_theorem",
    "summary": "In mathematics, the Cauchy integral theorem (also known as the Cauchy–Goursat theorem) in complex analysis, named after Augustin-Louis Cauchy (and Édouard Goursat), is an important statement about line integrals for holomorphic functions in the complex plane. Essentially, it says that if \n  \n    \n      \n        f\n        (\n        z\n        )\n      \n    \n    {\\displaystyle f(z)}\n  \n is holomorphic in a simply connected domain Ω, then for any simply closed contour \n  \n    \n      \n        C\n      \n    \n    {\\displaystyle C}\n  \n in Ω, that contour integral is zero. \n\n  \n    \n      \n        \n          ∫\n          \n            C\n          \n        \n        f\n        (\n        z\n        )\n        \n        d\n        z\n        =\n        0.\n      \n    \n    {\\displaystyle \\int _{C}f(z)\\,dz=0.}",
    "content": "In mathematics, the Cauchy integral theorem (also known as the Cauchy–Goursat theorem) in complex analysis, named after Augustin-Louis Cauchy (and Édouard Goursat), is an important statement about line integrals for holomorphic functions in the complex plane. Essentially, it says that if \n  \n    \n      \n        f\n        (\n        z\n        )\n      \n    \n    {\\displaystyle f(z)}\n  \n is holomorphic in a simply connected domain Ω, then for any simply closed contour \n  \n    \n      \n        C\n      \n    \n    {\\displaystyle C}\n  \n in Ω, that contour integral is zero. \n\n  \n    \n      \n        \n          ∫\n          \n            C\n          \n        \n        f\n        (\n        z\n        )\n        \n        d\n        z\n        =\n        0.\n      \n    \n    {\\displaystyle \\int _{C}f(z)\\,dz=0.}\n\nStatement\nFundamental theorem for complex line integrals\nIf f(z) is a holomorphic function on an open region U, and \n  \n    \n      \n        γ\n      \n    \n    {\\displaystyle \\gamma }\n  \n is a curve in U from \n  \n    \n      \n        \n          z\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle z_{0}}\n  \n to \n  \n    \n      \n        \n          z\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle z_{1}}\n  \n then,\n\n  \n    \n      \n        \n          ∫\n          \n            γ\n          \n        \n        \n          f\n          ′\n        \n        (\n        z\n        )\n        \n        d\n        z\n        =\n        f\n        (\n        \n          z\n          \n            1\n          \n        \n        )\n        −\n        f\n        (\n        \n          z\n          \n            0\n          \n        \n        )\n        .\n      \n    \n    {\\displaystyle \\int _{\\gamma }f'(z)\\,dz=f(z_{1})-f(z_{0}).}\n  \n\nAlso, when f(z) has a single-valued antiderivative in an open region U, then the path integral \n  \n    \n      \n        \n          ∫\n          \n            γ\n          \n        \n        f\n        (\n        z\n        )\n        \n        d\n        z\n      \n    \n    {\\textstyle \\int _{\\gamma }f(z)\\,dz}\n  \n is path independent for all paths in U.\n\nFormulation on simply connected regions\nLet \n  \n    \n      \n        U\n        ⊆\n        \n          C\n        \n      \n    \n    {\\displaystyle U\\subseteq \\mathbb {C} }\n  \n be a simply connected open set, and let \n  \n    \n      \n        f\n        :\n        U\n        →\n        \n          C\n        \n      \n    \n    {\\displaystyle f:U\\to \\mathbb {C} }\n  \n be a holomorphic function. Let \n  \n    \n      \n        γ\n        :\n        [\n        a\n        ,\n        b\n        ]\n        →\n        U\n      \n    \n    {\\displaystyle \\gamma :[a,b]\\to U}\n  \n be a smooth closed curve. Then:\n\n  \n    \n      \n        \n          ∫\n          \n            γ\n          \n        \n        f\n        (\n        z\n        )\n        \n        d\n        z\n        =\n        0.\n      \n    \n    {\\displaystyle \\int _{\\gamma }f(z)\\,dz=0.}\n  \n\n(The condition that \n  \n    \n      \n        U\n      \n    \n    {\\displaystyle U}\n  \n be simply connected means that \n  \n    \n      \n        U\n      \n    \n    {\\displaystyle U}\n  \n has no \"holes\", or in other words, that the fundamental group of \n  \n    \n      \n        U\n      \n    \n    {\\displaystyle U}\n  \n is trivial.)\n\nGeneral formulation\nLet \n  \n    \n      \n        U\n        ⊆\n        \n          C\n        \n      \n    \n    {\\displaystyle U\\subseteq \\mathbb {C} }\n  \n be an open set, and let \n  \n    \n      \n        f\n        :\n        U\n        →\n        \n          C\n        \n      \n    \n    {\\displaystyle f:U\\to \\mathbb {C} }\n  \n be a holomorphic function. Let \n  \n    \n      \n        γ\n        :\n        [\n        a\n        ,\n        b\n        ]\n        →\n        U\n      \n    \n    {\\displaystyle \\gamma :[a,b]\\to U}\n  \n be a smooth closed curve. If  \n  \n    \n      \n        γ\n      \n    \n    {\\displaystyle \\gamma }\n  \n is homotopic to a constant curve, then:\n\n  \n    \n      \n        \n          ∫\n          \n            γ\n          \n        \n        f\n        (\n        z\n        )\n        \n        d\n        z\n        =\n        0.\n      \n    \n    {\\displaystyle \\int _{\\gamma }f(z)\\,dz=0.}\n  \nwhere z є U\n(Recall that a curve is homotopic to a constant curve if there exists a smooth homotopy (within \n  \n    \n      \n        U\n      \n    \n    {\\displaystyle U}\n  \n) from the curve to the constant curve. Intuitively, this means that one can shrink the curve into a point without exiting the space.) The first version is a special case of this because on a simply connected set, every closed curve is homotopic to a constant curve.\n\nMain example\nIn both cases, it is important to remember that the curve \n  \n    \n      \n        γ\n      \n    \n    {\\displaystyle \\gamma }\n  \n does not surround any \"holes\" in the domain, or else the theorem does not apply. A famous example is the following curve: \n\n  \n    \n      \n        γ\n        (\n        t\n        )\n        =\n        \n          e\n          \n            i\n            t\n          \n        \n        \n        t\n        ∈\n        \n         ",
    "links": [
      "Analytic continuation",
      "Analytic function",
      "Analyticity of holomorphic functions",
      "Antiderivative (complex analysis)",
      "Argument principle",
      "Augustin-Louis Cauchy",
      "Bernhard Riemann",
      "Bibcode (identifier)",
      "Cambridge University Press",
      "Carl Friedrich Gauss",
      "Cauchy's integral formula",
      "Cauchy formula for repeated integration",
      "Cauchy–Riemann equations",
      "Closure (topology)",
      "Complex analysis",
      "Complex antiderivative",
      "Complex conjugate",
      "Complex manifold",
      "Complex number",
      "Complex plane",
      "Conformal map",
      "Doi (identifier)",
      "Domain (mathematical analysis)",
      "Encyclopedia of Mathematics",
      "Entire function",
      "Eric W. Weisstein",
      "Essential singularity",
      "Euler's formula",
      "European Mathematical Society",
      "Formal power series",
      "Fundamental group",
      "Fundamental theorem of calculus",
      "Geometric function theory",
      "Green's theorem",
      "Holomorphic function",
      "Homotopy",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "Imaginary number",
      "Infinitely differentiable",
      "Isolated singularity",
      "Jordan curve theorem",
      "Karl Weierstrass",
      "Kunihiko Kodaira",
      "Lars Ahlfors",
      "Laurent series",
      "Leonhard Euler",
      "Line integral",
      "Liouville's theorem (complex analysis)",
      "MathWorld"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Augustin-Louis Cauchy",
      "Category:Short description is different from Wikidata",
      "Category:Theorems in complex analysis"
    ]
  },
  "Cauchy integral theorem": {
    "title": "Cauchy's integral theorem",
    "url": "https://en.wikipedia.org/wiki/Cauchy%27s_integral_theorem",
    "summary": "In mathematics, the Cauchy integral theorem (also known as the Cauchy–Goursat theorem) in complex analysis, named after Augustin-Louis Cauchy (and Édouard Goursat), is an important statement about line integrals for holomorphic functions in the complex plane. Essentially, it says that if \n  \n    \n      \n        f\n        (\n        z\n        )\n      \n    \n    {\\displaystyle f(z)}\n  \n is holomorphic in a simply connected domain Ω, then for any simply closed contour \n  \n    \n      \n        C\n      \n    \n    {\\displaystyle C}\n  \n in Ω, that contour integral is zero. \n\n  \n    \n      \n        \n          ∫\n          \n            C\n          \n        \n        f\n        (\n        z\n        )\n        \n        d\n        z\n        =\n        0.\n      \n    \n    {\\displaystyle \\int _{C}f(z)\\,dz=0.}",
    "content": "In mathematics, the Cauchy integral theorem (also known as the Cauchy–Goursat theorem) in complex analysis, named after Augustin-Louis Cauchy (and Édouard Goursat), is an important statement about line integrals for holomorphic functions in the complex plane. Essentially, it says that if \n  \n    \n      \n        f\n        (\n        z\n        )\n      \n    \n    {\\displaystyle f(z)}\n  \n is holomorphic in a simply connected domain Ω, then for any simply closed contour \n  \n    \n      \n        C\n      \n    \n    {\\displaystyle C}\n  \n in Ω, that contour integral is zero. \n\n  \n    \n      \n        \n          ∫\n          \n            C\n          \n        \n        f\n        (\n        z\n        )\n        \n        d\n        z\n        =\n        0.\n      \n    \n    {\\displaystyle \\int _{C}f(z)\\,dz=0.}\n\nStatement\nFundamental theorem for complex line integrals\nIf f(z) is a holomorphic function on an open region U, and \n  \n    \n      \n        γ\n      \n    \n    {\\displaystyle \\gamma }\n  \n is a curve in U from \n  \n    \n      \n        \n          z\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle z_{0}}\n  \n to \n  \n    \n      \n        \n          z\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle z_{1}}\n  \n then,\n\n  \n    \n      \n        \n          ∫\n          \n            γ\n          \n        \n        \n          f\n          ′\n        \n        (\n        z\n        )\n        \n        d\n        z\n        =\n        f\n        (\n        \n          z\n          \n            1\n          \n        \n        )\n        −\n        f\n        (\n        \n          z\n          \n            0\n          \n        \n        )\n        .\n      \n    \n    {\\displaystyle \\int _{\\gamma }f'(z)\\,dz=f(z_{1})-f(z_{0}).}\n  \n\nAlso, when f(z) has a single-valued antiderivative in an open region U, then the path integral \n  \n    \n      \n        \n          ∫\n          \n            γ\n          \n        \n        f\n        (\n        z\n        )\n        \n        d\n        z\n      \n    \n    {\\textstyle \\int _{\\gamma }f(z)\\,dz}\n  \n is path independent for all paths in U.\n\nFormulation on simply connected regions\nLet \n  \n    \n      \n        U\n        ⊆\n        \n          C\n        \n      \n    \n    {\\displaystyle U\\subseteq \\mathbb {C} }\n  \n be a simply connected open set, and let \n  \n    \n      \n        f\n        :\n        U\n        →\n        \n          C\n        \n      \n    \n    {\\displaystyle f:U\\to \\mathbb {C} }\n  \n be a holomorphic function. Let \n  \n    \n      \n        γ\n        :\n        [\n        a\n        ,\n        b\n        ]\n        →\n        U\n      \n    \n    {\\displaystyle \\gamma :[a,b]\\to U}\n  \n be a smooth closed curve. Then:\n\n  \n    \n      \n        \n          ∫\n          \n            γ\n          \n        \n        f\n        (\n        z\n        )\n        \n        d\n        z\n        =\n        0.\n      \n    \n    {\\displaystyle \\int _{\\gamma }f(z)\\,dz=0.}\n  \n\n(The condition that \n  \n    \n      \n        U\n      \n    \n    {\\displaystyle U}\n  \n be simply connected means that \n  \n    \n      \n        U\n      \n    \n    {\\displaystyle U}\n  \n has no \"holes\", or in other words, that the fundamental group of \n  \n    \n      \n        U\n      \n    \n    {\\displaystyle U}\n  \n is trivial.)\n\nGeneral formulation\nLet \n  \n    \n      \n        U\n        ⊆\n        \n          C\n        \n      \n    \n    {\\displaystyle U\\subseteq \\mathbb {C} }\n  \n be an open set, and let \n  \n    \n      \n        f\n        :\n        U\n        →\n        \n          C\n        \n      \n    \n    {\\displaystyle f:U\\to \\mathbb {C} }\n  \n be a holomorphic function. Let \n  \n    \n      \n        γ\n        :\n        [\n        a\n        ,\n        b\n        ]\n        →\n        U\n      \n    \n    {\\displaystyle \\gamma :[a,b]\\to U}\n  \n be a smooth closed curve. If  \n  \n    \n      \n        γ\n      \n    \n    {\\displaystyle \\gamma }\n  \n is homotopic to a constant curve, then:\n\n  \n    \n      \n        \n          ∫\n          \n            γ\n          \n        \n        f\n        (\n        z\n        )\n        \n        d\n        z\n        =\n        0.\n      \n    \n    {\\displaystyle \\int _{\\gamma }f(z)\\,dz=0.}\n  \nwhere z є U\n(Recall that a curve is homotopic to a constant curve if there exists a smooth homotopy (within \n  \n    \n      \n        U\n      \n    \n    {\\displaystyle U}\n  \n) from the curve to the constant curve. Intuitively, this means that one can shrink the curve into a point without exiting the space.) The first version is a special case of this because on a simply connected set, every closed curve is homotopic to a constant curve.\n\nMain example\nIn both cases, it is important to remember that the curve \n  \n    \n      \n        γ\n      \n    \n    {\\displaystyle \\gamma }\n  \n does not surround any \"holes\" in the domain, or else the theorem does not apply. A famous example is the following curve: \n\n  \n    \n      \n        γ\n        (\n        t\n        )\n        =\n        \n          e\n          \n            i\n            t\n          \n        \n        \n        t\n        ∈\n        \n         ",
    "links": [
      "Analytic continuation",
      "Analytic function",
      "Analyticity of holomorphic functions",
      "Antiderivative (complex analysis)",
      "Argument principle",
      "Augustin-Louis Cauchy",
      "Bernhard Riemann",
      "Bibcode (identifier)",
      "Cambridge University Press",
      "Carl Friedrich Gauss",
      "Cauchy's integral formula",
      "Cauchy formula for repeated integration",
      "Cauchy–Riemann equations",
      "Closure (topology)",
      "Complex analysis",
      "Complex antiderivative",
      "Complex conjugate",
      "Complex manifold",
      "Complex number",
      "Complex plane",
      "Conformal map",
      "Doi (identifier)",
      "Domain (mathematical analysis)",
      "Encyclopedia of Mathematics",
      "Entire function",
      "Eric W. Weisstein",
      "Essential singularity",
      "Euler's formula",
      "European Mathematical Society",
      "Formal power series",
      "Fundamental group",
      "Fundamental theorem of calculus",
      "Geometric function theory",
      "Green's theorem",
      "Holomorphic function",
      "Homotopy",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "Imaginary number",
      "Infinitely differentiable",
      "Isolated singularity",
      "Jordan curve theorem",
      "Karl Weierstrass",
      "Kunihiko Kodaira",
      "Lars Ahlfors",
      "Laurent series",
      "Leonhard Euler",
      "Line integral",
      "Liouville's theorem (complex analysis)",
      "MathWorld"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Augustin-Louis Cauchy",
      "Category:Short description is different from Wikidata",
      "Category:Theorems in complex analysis"
    ]
  },
  "Cauchy–Riemann equations": {
    "title": "Cauchy–Riemann equations",
    "url": "https://en.wikipedia.org/wiki/Cauchy%E2%80%93Riemann_equations",
    "summary": "In the field of complex analysis in mathematics, the Cauchy–Riemann equations, named after Augustin Cauchy and Bernhard Riemann, consist of a system of two partial differential equations which form a necessary and sufficient condition for a complex function of a complex variable to be complex differentiable. \nThese equations are \n\nand\n\nwhere u(x, y) and v(x, y) are real bivariate differentiable functions.\nTypically, u and v are respectively the real and imaginary parts of a complex-valued function f(x + iy) = f(x, y) = u(x, y) + iv(x, y) of a single complex variable z = x + iy where x and y are real variables; u and v are real differentiable functions of the real variables. Then f is complex differentiable at a complex point if and only if the partial derivatives of u and v satisfy the Cauchy–Riemann equations at that point.\nA holomorphic function is a complex function that is differentiable at every point of some open subset of the complex plane \n  \n    \n      \n        \n          C\n  ",
    "content": "In the field of complex analysis in mathematics, the Cauchy–Riemann equations, named after Augustin Cauchy and Bernhard Riemann, consist of a system of two partial differential equations which form a necessary and sufficient condition for a complex function of a complex variable to be complex differentiable. \nThese equations are \n\nand\n\nwhere u(x, y) and v(x, y) are real bivariate differentiable functions.\nTypically, u and v are respectively the real and imaginary parts of a complex-valued function f(x + iy) = f(x, y) = u(x, y) + iv(x, y) of a single complex variable z = x + iy where x and y are real variables; u and v are real differentiable functions of the real variables. Then f is complex differentiable at a complex point if and only if the partial derivatives of u and v satisfy the Cauchy–Riemann equations at that point.\nA holomorphic function is a complex function that is differentiable at every point of some open subset of the complex plane \n  \n    \n      \n        \n          C\n        \n      \n    \n    {\\displaystyle \\mathbb {C} }\n  \n. It has been proved that holomorphic functions are analytic and analytic complex functions are complex-differentiable. In particular, holomorphic functions are infinitely complex-differentiable.\nThis equivalence between differentiability and analyticity is the starting point of all complex analysis.\n\nHistory\nThe Cauchy–Riemann equations first appeared in the work of Jean le Rond d'Alembert. Later, Leonhard Euler connected this system to the analytic functions. Cauchy then used these equations to construct his theory of functions. Riemann's dissertation on the theory of functions appeared in 1851.\n\nSimple example\nSuppose that \n  \n    \n      \n        z\n        =\n        x\n        +\n        i\n        y\n      \n    \n    {\\displaystyle z=x+iy}\n  \n. The complex-valued function \n  \n    \n      \n        f\n        (\n        z\n        )\n        =\n        \n          z\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle f(z)=z^{2}}\n  \n is differentiable at any point z in the complex plane. \n\n  \n    \n      \n        f\n        (\n        z\n        )\n        =\n        (\n        x\n        +\n        i\n        y\n        \n          )\n          \n            2\n          \n        \n        =\n        \n          x\n          \n            2\n          \n        \n        −\n        \n          y\n          \n            2\n          \n        \n        +\n        2\n        i\n        x\n        y\n      \n    \n    {\\displaystyle f(z)=(x+iy)^{2}=x^{2}-y^{2}+2ixy}\n  \n\nThe real part \n  \n    \n      \n        u\n        (\n        x\n        ,\n        y\n        )\n      \n    \n    {\\displaystyle u(x,y)}\n  \n and the imaginary part \n  \n    \n      \n        v\n        (\n        x\n        ,\n        y\n        )\n      \n    \n    {\\displaystyle v(x,y)}\n  \n are\n\n  \n    \n      \n        \n          \n            \n              \n                u\n                (\n                x\n                ,\n                y\n                )\n              \n              \n                \n                =\n                \n                  x\n                  \n                    2\n                  \n                \n                −\n                \n                  y\n                  \n                    2\n                  \n                \n              \n            \n            \n              \n                v\n                (\n                x\n                ,\n                y\n                )\n              \n              \n                \n                =\n                2\n                x\n                y\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}u(x,y)&=x^{2}-y^{2}\\\\v(x,y)&=2xy\\end{aligned}}}\n  \n\nand their partial derivatives are\n\n  \n    \n      \n        \n          u\n          \n            x\n          \n        \n        =\n        2\n        x\n        ;\n        \n        \n          u\n          \n            y\n          \n        \n        =\n        −\n        2\n        y\n        ;\n        \n        \n          v\n          \n            x\n          \n        \n        =\n        2\n        y\n        ;\n        \n        \n          v\n          \n            y\n          \n        \n        =\n        2\n        x\n      \n    \n    {\\displaystyle u_{x}=2x;\\quad u_{y}=-2y;\\quad v_{x}=2y;\\quad v_{y}=2x}\n  \n\nWe see that indeed the Cauchy–Riemann equations are satisfied, \n  \n    \n      \n        \n          u\n          \n            x\n          \n        \n        =\n        \n          v\n          \n            y\n          \n        \n      \n    \n    {\\displaystyle u_{x}=v_{y}}\n  \n and \n  \n    \n      \n        \n          u\n          \n            y\n          \n        \n        =\n        −\n        \n          v\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle u_{y}=-v_{x}}\n  \n.\n\nInterpretation and reformulation\nThe Cauchy-Riemann equations are one way of looking at the condition for a function to be differentiable in the sense of complex analysis: in other words, they encaps",
    "links": [
      "Almost everywhere",
      "Analytic continuation",
      "Analytic function",
      "Analytic functions",
      "Analyticity of holomorphic functions",
      "Angle",
      "Antiderivative (complex analysis)",
      "Argument principle",
      "Augustin-Louis Cauchy",
      "Augustin Cauchy",
      "Bernhard Riemann",
      "Bäcklund transform",
      "CR manifold",
      "Carl Friedrich Gauss",
      "Cauchy's integral formula",
      "Cauchy's integral theorem",
      "Cauchy integral formula",
      "Cauchy integral theorem",
      "Cauchy–Goursat theorem",
      "Clifford algebra",
      "Closed and exact differential forms",
      "Closure (topology)",
      "Codifferential",
      "Complex-valued function",
      "Complex analysis",
      "Complex conjugate",
      "Complex differentiable",
      "Complex function",
      "Complex manifold",
      "Complex number",
      "Complex plane",
      "Conformal map",
      "Conformal mapping",
      "Conjugate harmonic functions",
      "Conservative vector field",
      "Continuous function",
      "Continuously differentiable",
      "Contour plot",
      "Coordinate system",
      "Critical point (mathematics)",
      "Curl (mathematics)",
      "Differentiable",
      "Differentiable function",
      "Differential calculus",
      "Differential form",
      "Dirac operator",
      "Divergence",
      "Divergence theorem",
      "Doi (identifier)",
      "Dot product"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Augustin-Louis Cauchy",
      "Category:Bernhard Riemann",
      "Category:CS1 German-language sources (de)",
      "Category:CS1 errors: ISBN date",
      "Category:Complex analysis",
      "Category:Eponymous equations of mathematics",
      "Category:Harmonic functions",
      "Category:Partial differential equations",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Complex Hilbert space": {
    "title": "Hilbert space",
    "url": "https://en.wikipedia.org/wiki/Hilbert_space",
    "summary": "In mathematics, a Hilbert space is a real or complex inner product space that is also a complete metric space with respect to the metric induced by the inner product. It generalizes the notion of Euclidean space. The inner product allows lengths and angles to be defined. Furthermore, completeness means that there are enough limits in the space to allow the techniques of calculus to be used. A Hilbert space is a special case of a Banach space.\nHilbert spaces were studied beginning in the first decade of the 20th century by David Hilbert, Erhard Schmidt, and Frigyes Riesz. They are indispensable tools in the theories of partial differential equations, quantum mechanics, Fourier analysis (which includes applications to signal processing and heat transfer), and ergodic theory (which forms the mathematical underpinning of thermodynamics). John von Neumann coined the term Hilbert space for the abstract concept that underlies many of these diverse applications. The success of Hilbert space me",
    "content": "In mathematics, a Hilbert space is a real or complex inner product space that is also a complete metric space with respect to the metric induced by the inner product. It generalizes the notion of Euclidean space. The inner product allows lengths and angles to be defined. Furthermore, completeness means that there are enough limits in the space to allow the techniques of calculus to be used. A Hilbert space is a special case of a Banach space.\nHilbert spaces were studied beginning in the first decade of the 20th century by David Hilbert, Erhard Schmidt, and Frigyes Riesz. They are indispensable tools in the theories of partial differential equations, quantum mechanics, Fourier analysis (which includes applications to signal processing and heat transfer), and ergodic theory (which forms the mathematical underpinning of thermodynamics). John von Neumann coined the term Hilbert space for the abstract concept that underlies many of these diverse applications. The success of Hilbert space methods ushered in a very fruitful era for functional analysis. Apart from the classical Euclidean vector spaces, examples of Hilbert spaces include spaces of square-integrable functions, spaces of sequences, Sobolev spaces consisting of generalized functions, and Hardy spaces of holomorphic functions.\nGeometric intuition plays an important role in many aspects of Hilbert space theory. Exact analogs of the Pythagorean theorem and parallelogram law hold in a Hilbert space. At a deeper level, perpendicular projection onto a linear subspace plays a significant role in optimization problems and other aspects of the theory. An element of a Hilbert space can be uniquely specified by its coordinates with respect to an orthonormal basis, in analogy with Cartesian coordinates in classical geometry. When this basis is countably infinite, it allows identifying the Hilbert space with the space of the infinite sequences that are square-summable. The latter space is often in the older literature referred to as the Hilbert space.\n\nDefinition and illustration\nMotivating example: Euclidean vector space\nOne of the most familiar examples of a Hilbert space is the Euclidean vector space consisting of three-dimensional vectors, denoted by R3, and equipped with the dot product. The dot product takes two vectors x and y, and produces a real number x ⋅ y. If x and y are represented in Cartesian coordinates, then the dot product is defined by\n\n  \n    \n      \n        \n          \n            (\n            \n              \n                \n                  \n                    x\n                    \n                      1\n                    \n                  \n                \n              \n              \n                \n                  \n                    x\n                    \n                      2\n                    \n                  \n                \n              \n              \n                \n                  \n                    x\n                    \n                      3\n                    \n                  \n                \n              \n            \n            )\n          \n        \n        ⋅\n        \n          \n            (\n            \n              \n                \n                  \n                    y\n                    \n                      1\n                    \n                  \n                \n              \n              \n                \n                  \n                    y\n                    \n                      2\n                    \n                  \n                \n              \n              \n                \n                  \n                    y\n                    \n                      3\n                    \n                  \n                \n              \n            \n            )\n          \n        \n        =\n        \n          x\n          \n            1\n          \n        \n        \n          y\n          \n            1\n          \n        \n        +\n        \n          x\n          \n            2\n          \n        \n        \n          y\n          \n            2\n          \n        \n        +\n        \n          x\n          \n            3\n          \n        \n        \n          y\n          \n            3\n          \n        \n        \n        .\n      \n    \n    {\\displaystyle {\\begin{pmatrix}x_{1}\\\\x_{2}\\\\x_{3}\\end{pmatrix}}\\cdot {\\begin{pmatrix}y_{1}\\\\y_{2}\\\\y_{3}\\end{pmatrix}}=x_{1}y_{1}+x_{2}y_{2}+x_{3}y_{3}\\,.}\n  \n\nThe dot product satisfies the properties\n\nIt is symmetric in x and y: x ⋅ y = y ⋅ x.\nIt is linear in its first argument: (ax1 + bx2) ⋅ y = a(x1 ⋅ y) + b(x2 ⋅ y) for any scalars a, b, and vectors x1, x2, and y.\nIt is positive definite: for all vectors x, x ⋅ x ≥ 0 , with equality if and only if x = 0.\nAn operation on pairs of vectors that, like the dot product, satisfies these three properties is known as a (real) inner product. A vector space equipped with such an inner product is known as a (real) inner product space. Every finite-dimensional inner product space is also a Hilb",
    "links": [
      "*-algebra",
      "Abramowitz and Stegun",
      "Absolute continuity",
      "Absolute convergence",
      "Absolute value",
      "Absolutely convex set",
      "Absorbing set",
      "Abstract Wiener space",
      "Adjoint operator",
      "Affine hull",
      "Affine space",
      "Alaoglu's theorem",
      "Alexander Holevo",
      "Algebraic interior",
      "Almost everywhere",
      "American Mathematical Monthly",
      "American Mathematical Society",
      "Analysis of variance",
      "Anderson–Kadec theorem",
      "Andrey Kolmogorov",
      "Antilinear map",
      "Applied mathematics",
      "Approximation property",
      "Arthur Wightman",
      "Asher Peres",
      "Asplund space",
      "Atiyah–Singer index theorem",
      "Atomic orbital",
      "August Ferdinand Möbius",
      "B-convex space",
      "BK-space",
      "Ba space",
      "Babenko–Beckner inequality",
      "Balanced set",
      "Banach algebra",
      "Banach bundle",
      "Banach lattice",
      "Banach manifold",
      "Banach space",
      "Banach spaces",
      "Banach–Alaoglu theorem",
      "Banach–Mazur compactum",
      "Banach–Mazur distance",
      "Banach–Mazur theorem",
      "Banach–Saks theorem",
      "Barrelled space",
      "Barry Simon",
      "Basis (linear algebra)",
      "Bergman kernel",
      "Bergman space"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1 maint: ignored ISBN errors",
      "Category:Commons category link from Wikidata",
      "Category:David Hilbert",
      "Category:Functional analysis",
      "Category:Good articles",
      "Category:Hilbert spaces",
      "Category:Linear algebra",
      "Category:Operator theory",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Connected space": {
    "title": "Connected space",
    "url": "https://en.wikipedia.org/wiki/Connected_space",
    "summary": "In topology and related branches of mathematics, a connected space is a topological space that cannot be represented as the union of two or more disjoint non-empty open subsets. Connectedness is one of the principal topological properties that distinguish topological spaces.\nA subset of a topological space \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is a connected set if it is a connected space when viewed as a subspace of \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n.\nSome related but stronger conditions are path connected, simply connected, and \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n-connected. Another related notion is locally connected, which neither implies nor follows from connectedness.",
    "content": "In topology and related branches of mathematics, a connected space is a topological space that cannot be represented as the union of two or more disjoint non-empty open subsets. Connectedness is one of the principal topological properties that distinguish topological spaces.\nA subset of a topological space \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is a connected set if it is a connected space when viewed as a subspace of \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n.\nSome related but stronger conditions are path connected, simply connected, and \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n-connected. Another related notion is locally connected, which neither implies nor follows from connectedness.\n\nFormal definition\nA topological space \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is said to be disconnected if it is the union of two disjoint non-empty open sets. Otherwise, \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is said to be connected.  A subset of a topological space is said to be connected if it is connected under its subspace topology. Some authors exclude the empty set (with its unique topology) as a connected space, but this article does not follow that practice.\nFor a topological space \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n the following conditions are equivalent:\n\n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is connected, that is, it cannot be divided into two disjoint non-empty open sets.\nThe only subsets of \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n which are both open and closed (clopen sets) are \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n and the empty set.\nThe only subsets of \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n with empty boundary are \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n and the empty set.\n\n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n cannot be written as the union of two non-empty separated sets (sets for which each is disjoint from the other's closure).\nAll continuous functions from \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n to \n  \n    \n      \n        {\n        0\n        ,\n        1\n        }\n      \n    \n    {\\displaystyle \\{0,1\\}}\n  \n are constant, where \n  \n    \n      \n        {\n        0\n        ,\n        1\n        }\n      \n    \n    {\\displaystyle \\{0,1\\}}\n  \n is the two-point space endowed with the discrete topology.\nHistorically this modern formulation of the notion of connectedness (in terms of no partition of \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n into two separated sets) first appeared (independently) with N.J. Lennes, Frigyes Riesz, and Felix Hausdorff at the beginning of the 20th century. See (Wilder 1978) for details.\n\nConnected components\nGiven some point \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n in a topological space \n  \n    \n      \n        X\n        ,\n      \n    \n    {\\displaystyle X,}\n  \n the union of any collection of connected subsets such that each contains \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n will once again be a connected subset. \nThe connected component of a point \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n in \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is the union of all connected subsets of \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n that contain \n  \n    \n      \n        x\n        ;\n      \n    \n    {\\displaystyle x;}\n  \n it is the unique largest (with respect to \n  \n    \n      \n        ⊆\n      \n    \n    {\\displaystyle \\subseteq }\n  \n) connected subset of \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n that contains \n  \n    \n      \n        x\n        .\n      \n    \n    {\\displaystyle x.}\n  \n \nThe maximal connected subsets (ordered by inclusion \n  \n    \n      \n        ⊆\n      \n    \n    {\\displaystyle \\subseteq }\n  \n) of a non-empty topological space are called the connected components of the space.\nThe components of any topological space \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n form a partition of \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n: they are disjoint, non-empty and their union is the whole space.\nEvery component is a closed subset of the original space. It follows that, in the case where their number is finite, each component is also an open subset. However, if their number is infinite, this might not be the case; for instance, the connected components of the set of the rational numbers are the one-point sets (singletons), which are not open. Proof: Any two distinct rational numbers \n  \n    \n      \n        \n          q\n          \n            1\n          \n        \n        <\n        \n          q\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle q_{1}<q_{2}}\n  \n are in different ",
    "links": [
      "Algebraic topology",
      "Annulus (mathematics)",
      "Banach fixed-point theorem",
      "Banach space",
      "Base (topology)",
      "Betti number",
      "Boundary (topology)",
      "Bundle (mathematics)",
      "CW complex",
      "Cantor set",
      "Charles Weibel",
      "Chern class",
      "Clopen",
      "Clopen set",
      "Closed set",
      "Closed subset",
      "Closure (topology)",
      "Cobordism",
      "Cohomology",
      "Comb space",
      "Combinatorial topology",
      "Compact space",
      "Connected component (graph theory)",
      "Connectedness locus",
      "Continuity (topology)",
      "Continuous function",
      "Continuum (topology)",
      "Contractible space",
      "Convex set",
      "Cycle graph",
      "De Rham cohomology",
      "Differential topology",
      "Digital topology",
      "Discrete topological space",
      "Discrete topology",
      "Discrete two-point space",
      "Discrete valuation ring",
      "Disjoint set",
      "Disjoint sets",
      "Disjoint union",
      "Disk (mathematics)",
      "Doi (identifier)",
      "Domain (mathematical analysis)",
      "Empty set",
      "Encyclopedia of Mathematics",
      "Equivalence class",
      "Equivalence relation",
      "Eric W. Weisstein",
      "Euclidean space",
      "Euclidean topology"
    ],
    "categories": [
      "Category:All Wikipedia articles written in American English",
      "Category:All articles lacking reliable references",
      "Category:Articles lacking reliable references from December 2024",
      "Category:Articles with short description",
      "Category:General topology",
      "Category:Pages displaying short descriptions of redirect targets via Module:Annotated link",
      "Category:Properties of topological spaces",
      "Category:Short description is different from Wikidata",
      "Category:Use American English from March 2019"
    ]
  },
  "Cauchy": {
    "title": "Augustin-Louis Cauchy",
    "url": "https://en.wikipedia.org/wiki/Augustin-Louis_Cauchy",
    "summary": "Baron Augustin-Louis Cauchy  (UK:   KOH-shee,    KOW-shee, US:  koh-SHEE; French: [oɡystɛ̃ lwi  koʃi]; 21 August 1789 – 23 May 1857) was a French mathematician, engineer, and physicist. He was one of the first to rigorously state and prove the key theorems of calculus (thereby creating real analysis), pioneered the field complex analysis, and the study of permutation groups in abstract algebra. Cauchy also contributed to a number of topics in mathematical physics, notably continuum mechanics.\nA profound mathematician, Cauchy had a great influence over his contemporaries and successors; Hans Freudenthal stated:\n\n\"More concepts and theorems have been named for Cauchy than for any other mathematician (in elasticity alone there are sixteen concepts and theorems named for Cauchy).\"\nCauchy was a prolific worker; he wrote approximately eight hundred research articles and five complete textbooks on a variety of topics in the fields of mathematics and mathematical physics.",
    "content": "Baron Augustin-Louis Cauchy  (UK:   KOH-shee,    KOW-shee, US:  koh-SHEE; French: [oɡystɛ̃ lwi  koʃi]; 21 August 1789 – 23 May 1857) was a French mathematician, engineer, and physicist. He was one of the first to rigorously state and prove the key theorems of calculus (thereby creating real analysis), pioneered the field complex analysis, and the study of permutation groups in abstract algebra. Cauchy also contributed to a number of topics in mathematical physics, notably continuum mechanics.\nA profound mathematician, Cauchy had a great influence over his contemporaries and successors; Hans Freudenthal stated:\n\n\"More concepts and theorems have been named for Cauchy than for any other mathematician (in elasticity alone there are sixteen concepts and theorems named for Cauchy).\"\nCauchy was a prolific worker; he wrote approximately eight hundred research articles and five complete textbooks on a variety of topics in the fields of mathematics and mathematical physics.\n\nBiography\nYouth and education\nCauchy was the son of Louis François Cauchy (1760–1848) and Marie-Madeleine Desestre. Cauchy had two brothers: Alexandre Laurent Cauchy (1792–1857), who became a president of a division of the court of appeal in 1847 and a judge of the court of cassation in 1849, and Eugene François Cauchy (1802–1877), a publicist who also wrote several mathematical works. From his childhood he was good at math.\nCauchy married Aloise de Bure in 1818. She was a close relative of the publisher who published most of Cauchy's works. They had two daughters, Marie Françoise Alicia (1819) and Marie Mathilde (1823).\nCauchy's father was a highly ranked official in the Parisian police of the \nAncien Régime, but lost this position due to the French Revolution (14 July 1789), which broke out one month before Augustin-Louis was born. The Cauchy family survived the revolution and the following Reign of Terror during 1793–94 by escaping to Arcueil, where Cauchy received his first education, from his father. After the execution of Robespierre in 1794, it was safe for the family to return to Paris. There, Louis-François Cauchy found a bureaucratic job in 1800, and quickly advanced his career. When Napoleon came to power in 1799, Louis-François Cauchy was further promoted, and became Secretary-General of the Senate, working directly under Laplace (who is now better known for his work on mathematical physics). The mathematician Lagrange was also a friend of the Cauchy family.\nOn Lagrange's advice, Augustin-Louis was enrolled in the École Centrale du Panthéon, the best secondary school of Paris at that time, in the fall of 1802. Most of the curriculum consisted of classical languages; the ambitious Cauchy, being a brilliant student, won many prizes in Latin and the humanities. In spite of these successes, Cauchy chose an engineering career, and prepared himself for the entrance examination to the École Polytechnique.\nIn 1805, he placed second of 293 applicants on this exam and was admitted. One of the main purposes of this school was to give future civil and military engineers a high-level scientific and mathematical education. The school functioned under military discipline, which caused Cauchy some problems in adapting. Nevertheless, he completed the course in 1807, at age 18, and went on to the École des Ponts et Chaussées (School for Bridges and Roads). He graduated in civil engineering, with the highest honors.\n\nEngineering days\nAfter finishing school in 1810, Cauchy accepted a job as a junior engineer in Cherbourg, where Napoleon intended to build a naval base. Here Cauchy stayed for three years, and was assigned the Ourcq Canal project and the Saint-Cloud Bridge project, and worked at the Harbor of Cherbourg. Although he had an extremely busy managerial job, he still found time to prepare three mathematical manuscripts, which he submitted to the Première Classe (First Class) of the Institut de France. Cauchy's first two manuscripts (on polyhedra) were accepted; the third one (on directrices of conic sections) was rejected.\nIn September 1812, at 23 years old, Cauchy returned to Paris after becoming ill from overwork. Another reason for his return to the capital was that he was losing interest in his engineering job, being more and more attracted to the abstract beauty of mathematics; in Paris, he would have a much better chance to find a mathematics related position. When his health improved in 1813, Cauchy chose not to return to Cherbourg. Although he formally kept his engineering position, he was transferred from the payroll of the Ministry of the Marine to the Ministry of the Interior. The next three years Cauchy was mainly on unpaid sick leave; he spent his time fruitfully, working on mathematics (on the related topics of symmetric functions, the symmetric group and the theory of higher-order algebraic equations). He attempted admission to the First Class of the Institut de France but failed on three different occasions between 1813 and 1815. ",
    "links": [
      "Abraham Robinson",
      "Absolute convergence",
      "Abstract algebra",
      "Académie des Sciences",
      "Adequality",
      "Alexandre Borovik",
      "American Academy of Arts and Sciences",
      "American English",
      "American Philosophical Society",
      "Analyse des Infiniment Petits pour l'Intelligence des Lignes Courbes",
      "Analytic function",
      "Ancien Régime",
      "ArXiv (identifier)",
      "Arcueil",
      "Argument principle",
      "Augustin-Jean Fresnel",
      "Baron",
      "Bibliothèque du Roi",
      "British English",
      "Bureau des Longitudes",
      "Calculus",
      "Canal de l'Ourcq",
      "Catholic Encyclopedia",
      "Cauchy's convergence test",
      "Cauchy's equation",
      "Cauchy's functional equation",
      "Cauchy's integral formula",
      "Cauchy's integral theorem",
      "Cauchy's radical test",
      "Cauchy's theorem (geometry)",
      "Cauchy's theorem (group theory)",
      "Cauchy (crater)",
      "Cauchy (disambiguation)",
      "Cauchy argument principle",
      "Cauchy boundary condition",
      "Cauchy condensation test",
      "Cauchy determinant",
      "Cauchy distribution",
      "Cauchy formula for repeated integration",
      "Cauchy horizon",
      "Cauchy momentum equation",
      "Cauchy principal value",
      "Cauchy problem",
      "Cauchy product",
      "Cauchy sequence",
      "Cauchy stress tensor",
      "Cauchy surface",
      "Cauchy–Binet formula",
      "Cauchy–Euler equation",
      "Cauchy–Frobenius lemma"
    ],
    "categories": [
      "Category:1789 births",
      "Category:1857 deaths",
      "Category:19th-century French mathematicians",
      "Category:Academic staff of the University of Turin",
      "Category:Articles incorporating a citation from the 1913 Catholic Encyclopedia with Wikisource reference",
      "Category:Articles with Internet Archive links",
      "Category:Articles with hCards",
      "Category:Articles with short description",
      "Category:Augustin-Louis Cauchy",
      "Category:CS1: long volume value"
    ]
  },
  "Complexity theory (disambiguation)": {
    "title": "Complexity theory",
    "url": "https://en.wikipedia.org/wiki/Complexity_theory",
    "summary": "Complexity theory may refer to:",
    "content": "Complexity theory may refer to:\n\nScience and technology\nComputational complexity theory, a field in theoretical computer science and mathematics\nComplex systems theory, the study of the complexity in context of complex systems\nAssembly theory, a way of characterizing extraterrestrial molecular complexity to assess the probability of the presence of life\n\nOther uses\nComplexity economics, the application of complexity theory to economics\nComplexity theory and organizations, the application of complexity theory to strategy\n\nSee also\nComputational complexity\nComplexity (disambiguation)\nSystems theory\nSystems thinking\nComplex adaptive system, a special case of complex systems\nComplex network",
    "links": [
      "Assembly theory",
      "Complex adaptive system",
      "Complex network",
      "Complex systems",
      "Complexity (disambiguation)",
      "Complexity economics",
      "Complexity theory and organizations",
      "Computational complexity",
      "Computational complexity theory",
      "Systems theory",
      "Systems thinking",
      "Help:Disambiguation"
    ],
    "categories": [
      "Category:All article disambiguation pages",
      "Category:All disambiguation pages",
      "Category:Disambiguation pages",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Arzelà–Ascoli theorem": {
    "title": "Arzelà–Ascoli theorem",
    "url": "https://en.wikipedia.org/wiki/Arzel%C3%A0%E2%80%93Ascoli_theorem",
    "summary": "The Arzelà–Ascoli theorem is a fundamental result of mathematical analysis giving necessary and sufficient conditions to decide whether every sequence of a given family of real-valued continuous functions defined on a closed and bounded interval has a uniformly convergent subsequence.  The main condition is the equicontinuity of the family of functions. The theorem is the basis of many proofs in mathematics, including that of the Peano existence theorem in the theory of ordinary differential equations, Montel's theorem in complex analysis, and the Peter–Weyl theorem in harmonic analysis and various results concerning compactness of integral operators.\nThe notion of equicontinuity was introduced in the late 19th century by the Italian mathematicians Cesare Arzelà and Giulio Ascoli. A weak form of the theorem was proven by Ascoli (1883–1884), who established the sufficient condition for compactness, and by Arzelà (1895), who established the necessary condition and gave the first clear pr",
    "content": "The Arzelà–Ascoli theorem is a fundamental result of mathematical analysis giving necessary and sufficient conditions to decide whether every sequence of a given family of real-valued continuous functions defined on a closed and bounded interval has a uniformly convergent subsequence.  The main condition is the equicontinuity of the family of functions. The theorem is the basis of many proofs in mathematics, including that of the Peano existence theorem in the theory of ordinary differential equations, Montel's theorem in complex analysis, and the Peter–Weyl theorem in harmonic analysis and various results concerning compactness of integral operators.\nThe notion of equicontinuity was introduced in the late 19th century by the Italian mathematicians Cesare Arzelà and Giulio Ascoli. A weak form of the theorem was proven by Ascoli (1883–1884), who established the sufficient condition for compactness, and by Arzelà (1895), who established the necessary condition and gave the first clear presentation of the result.  A further generalization of the theorem was proven by Fréchet (1906), to sets of real-valued continuous functions with domain a compact metric space (Dunford & Schwartz 1958, p. 382).  Modern formulations of the theorem allow for the domain to be compact Hausdorff and for the range to be an arbitrary metric space.  More general formulations of the theorem exist that give necessary and sufficient conditions for a family of functions from a compactly generated Hausdorff space into a uniform space to be compact in the compact-open topology; see Kelley (1991, page 234).\n\nStatement and first consequences\nBy definition, a sequence \n  \n    \n      \n        {\n        \n          f\n          \n            n\n          \n        \n        \n          }\n          \n            n\n            ∈\n            \n              N\n            \n          \n        \n      \n    \n    {\\displaystyle \\{f_{n}\\}_{n\\in \\mathbb {N} }}\n  \n of continuous functions on an interval I = [a, b] is uniformly bounded if there is a number M such that\n\n  \n    \n      \n        \n          |\n          \n            \n              f\n              \n                n\n              \n            \n            (\n            x\n            )\n          \n          |\n        \n        ≤\n        M\n      \n    \n    {\\displaystyle \\left|f_{n}(x)\\right|\\leq M}\n  \n\nfor every function  fn  belonging to the sequence, and every x ∈ [a, b].  (Here, M  must be independent of n and x.)\nThe sequence is said to be uniformly equicontinuous if, for every ε > 0, there exists a δ > 0 such that\n\n  \n    \n      \n        \n          |\n          \n            \n              f\n              \n                n\n              \n            \n            (\n            x\n            )\n            −\n            \n              f\n              \n                n\n              \n            \n            (\n            y\n            )\n          \n          |\n        \n        <\n        ε\n      \n    \n    {\\displaystyle \\left|f_{n}(x)-f_{n}(y)\\right|<\\varepsilon }\n  \n\nwhenever |x − y| < δ  for all functions  fn  in the sequence. (Here, δ may depend on ε, but not x, y or n.)\nOne version of the theorem can be stated as follows:\n\nConsider a sequence of real-valued continuous functions { fn }n ∈ N defined on a closed and bounded interval [a, b] of the real line. If this sequence is uniformly bounded and uniformly equicontinuous, then there exists a subsequence { fnk }k ∈ N that converges uniformly.\nThe converse is also true, in the sense that if every subsequence of { fn } itself has a uniformly convergent subsequence, then { fn } is uniformly bounded and equicontinuous.\n\nImmediate examples\nDifferentiable functions\nThe hypotheses of the theorem are satisfied by a uniformly bounded sequence { fn } of differentiable functions with uniformly bounded derivatives. Indeed, uniform boundedness of the derivatives implies by the mean value theorem that for all x and y,\n\n  \n    \n      \n        \n          |\n          \n            \n              f\n              \n                n\n              \n            \n            (\n            x\n            )\n            −\n            \n              f\n              \n                n\n              \n            \n            (\n            y\n            )\n          \n          |\n        \n        ≤\n        K\n        \n          |\n        \n        x\n        −\n        y\n        \n          |\n        \n        ,\n      \n    \n    {\\displaystyle \\left|f_{n}(x)-f_{n}(y)\\right|\\leq K|x-y|,}\n  \n\nwhere K is the supremum of the derivatives of functions in the sequence and is independent of n.  So, given ε > 0, let δ = ⁠ε/2K⁠ to verify the definition of equicontinuity of the sequence.  This proves the following corollary:\n\nLet {fn}  be a uniformly bounded sequence of real-valued differentiable functions on [a, b] such that the derivatives {fn′}  are uniformly bounded. Then there exists a subsequence {fnk}  that converges uniformly on [a, b].\nIf, in addition, the sequence of second derivatives is also unifor",
    "links": [
      "Adjoint operator",
      "Approximation property",
      "ArXiv (identifier)",
      "Balanced set",
      "Banach algebra",
      "Banach space",
      "Banach–Alaoglu theorem",
      "Banach–Mazur distance",
      "Barrelled space",
      "Besov space",
      "Bolzano–Weierstrass theorem",
      "Bounded operator",
      "Bounded set",
      "C*-algebra",
      "Calculus of variations",
      "Cauchy's integral formula",
      "Cesare Arzelà",
      "Choquet theory",
      "Closed graph theorem (functional analysis)",
      "Closed set",
      "Compact-open topology",
      "Compact Hausdorff space",
      "Compact operator",
      "Compact set",
      "Compact space",
      "Compactly generated space",
      "Complete metric space",
      "Complete topological vector space",
      "Complex analysis",
      "Continuous function",
      "Continuous functions on a compact Hausdorff space",
      "Continuously differentiable function",
      "Derivative",
      "Diagonalization argument",
      "Distribution (mathematics)",
      "Doi (identifier)",
      "Dual space",
      "Equicontinuity",
      "Equicontinuous",
      "Euclidean space",
      "Filter (set theory)",
      "Fréchet space",
      "Fréchet–Kolmogorov theorem",
      "Functional analysis",
      "Functional calculus",
      "Gelfand–Naimark theorem",
      "Generalized function",
      "Giulio Ascoli",
      "Glossary of functional analysis",
      "Group algebra of a locally compact group"
    ],
    "categories": [
      "Category:Articles containing proofs",
      "Category:Articles with short description",
      "Category:Compactness theorems",
      "Category:Short description is different from Wikidata",
      "Category:Theorems in functional analysis",
      "Category:Theorems in real analysis",
      "Category:Theory of continuous functions",
      "Category:Topology of function spaces",
      "Category:Wikipedia articles incorporating text from PlanetMath"
    ]
  },
  "Bolzano–Weierstrass theorem": {
    "title": "Bolzano–Weierstrass theorem",
    "url": "https://en.wikipedia.org/wiki/Bolzano%E2%80%93Weierstrass_theorem",
    "summary": "In mathematics, specifically in real analysis, the Bolzano–Weierstrass theorem, named after Bernard Bolzano and Karl Weierstrass, is a fundamental result about convergence in a finite-dimensional Euclidean space \n  \n    \n      \n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{n}}\n  \n. The theorem states that each infinite bounded sequence in \n  \n    \n      \n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{n}}\n  \n has a convergent subsequence. An equivalent formulation is that a subset of \n  \n    \n      \n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{n}}\n  \n is sequentially compact if and only if it is closed and bounded. The theorem is sometimes called the sequential compactness theorem.",
    "content": "In mathematics, specifically in real analysis, the Bolzano–Weierstrass theorem, named after Bernard Bolzano and Karl Weierstrass, is a fundamental result about convergence in a finite-dimensional Euclidean space \n  \n    \n      \n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{n}}\n  \n. The theorem states that each infinite bounded sequence in \n  \n    \n      \n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{n}}\n  \n has a convergent subsequence. An equivalent formulation is that a subset of \n  \n    \n      \n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{n}}\n  \n is sequentially compact if and only if it is closed and bounded. The theorem is sometimes called the sequential compactness theorem.\n\nHistory and significance\nThe Bolzano–Weierstrass theorem is named after mathematicians Bernard Bolzano and Karl Weierstrass.  It was actually first proved by Bolzano in 1817 as a lemma in the proof of the intermediate value theorem.  Some fifty years later the result was identified as significant in its own right, and proven again by Weierstrass. It has since become an essential theorem of analysis.\n\nProof\nFirst we prove the theorem for \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n (set of all real numbers), in which case the ordering on \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n can be put to good use. Indeed, we have the following result:\nLemma: Every infinite sequence \n  \n    \n      \n        (\n        \n          x\n          \n            n\n          \n        \n        )\n      \n    \n    {\\displaystyle (x_{n})}\n  \n in \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n has an infinite monotone subsequence (a subsequence that is either non-decreasing or non-increasing).\nProof: Let us call a positive integer-valued index \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n of a sequence a \"peak\" of the sequence when \n  \n    \n      \n        \n          x\n          \n            m\n          \n        \n        ≤\n        \n          x\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle x_{m}\\leq x_{n}}\n  \n for every \n  \n    \n      \n        m\n        >\n        n\n      \n    \n    {\\displaystyle m>n}\n  \n. Suppose first that the sequence has infinitely many peaks, which means there is a subsequence with the following indices \n  \n    \n      \n        \n          n\n          \n            1\n          \n        \n        <\n        \n          n\n          \n            2\n          \n        \n        <\n        \n          n\n          \n            3\n          \n        \n        <\n        ⋯\n        <\n        \n          n\n          \n            j\n          \n        \n        <\n        …\n      \n    \n    {\\displaystyle n_{1}<n_{2}<n_{3}<\\dots <n_{j}<\\dots }\n  \n and the following terms \n  \n    \n      \n        \n          x\n          \n            \n              n\n              \n                1\n              \n            \n          \n        \n        ≥\n        \n          x\n          \n            \n              n\n              \n                2\n              \n            \n          \n        \n        ≥\n        \n          x\n          \n            \n              n\n              \n                3\n              \n            \n          \n        \n        ≥\n        ⋯\n        ≥\n        \n          x\n          \n            \n              n\n              \n                j\n              \n            \n          \n        \n        ≥\n        …\n      \n    \n    {\\displaystyle x_{n_{1}}\\geq x_{n_{2}}\\geq x_{n_{3}}\\geq \\dots \\geq x_{n_{j}}\\geq \\dots }\n  \n. So, the infinite sequence \n  \n    \n      \n        (\n        \n          x\n          \n            n\n          \n        \n        )\n      \n    \n    {\\displaystyle (x_{n})}\n  \n in \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n has a monotone (non-increasing) subsequence, which is \n  \n    \n      \n        (\n        \n          x\n          \n            \n              n\n              \n                j\n              \n            \n          \n        \n        )\n      \n    \n    {\\displaystyle (x_{n_{j}})}\n  \n. But suppose now that there are only finitely many peaks, let \n  \n    \n      \n        N\n      \n    \n    {\\displaystyle N}\n  \n be the final peak if one exists (let \n  \n    \n      \n        N\n        =\n        0\n      \n    \n    {\\displaystyle N=0}\n  \n otherwise) and let the first index of a new subsequence \n  \n    \n      \n        (\n        \n          x\n          \n            \n              n\n              \n                j\n              \n            \n          \n        \n        )\n      \n    \n    {\\displaystyle (x_{n_{j}})}\n  \n be set to \n  \n    \n      \n        ",
    "links": [
      "Accumulation point",
      "Bernard Bolzano",
      "Bounded sequence",
      "Bounded set",
      "Closed set",
      "Compact space",
      "Completeness of the real numbers",
      "Convergence proof techniques",
      "Economic equilibrium",
      "Ekeland's variational principle",
      "Empty set",
      "Encyclopedia of Mathematics",
      "Euclidean space",
      "European Mathematical Society",
      "General topology",
      "Heine–Borel theorem",
      "ISBN (identifier)",
      "If and only if",
      "Index set",
      "Intermediate value theorem",
      "Karl Weierstrass",
      "Lemma (mathematics)",
      "Limit of a sequence",
      "Mathematics",
      "Matrix (mathematics)",
      "Metrizable space",
      "Monotone convergence theorem",
      "Monotone sequence",
      "Nested intervals",
      "Non-decreasing",
      "Non-increasing",
      "Pareto efficiency",
      "Preference relation",
      "Real analysis",
      "Real number",
      "Robert G. Bartle",
      "Sequentially compact",
      "Sequentially compact space",
      "Subsequence",
      "Subset",
      "Subspace topology"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Compactness theorems",
      "Category:Short description is different from Wikidata",
      "Category:Theorems about real number sequences"
    ]
  },
  "Boundary (topology)": {
    "title": "Boundary (topology)",
    "url": "https://en.wikipedia.org/wiki/Boundary_(topology)",
    "summary": "In topology and mathematics in general, the boundary of a subset S of a topological space X is the set of points in the closure of S not belonging to the interior of S. An element of the boundary of S is called a boundary point of S. The term boundary operation refers to finding or taking the boundary of a set.  Notations used for boundary of a set S include \n  \n    \n      \n        bd\n        ⁡\n        (\n        S\n        )\n        ,\n        fr\n        ⁡\n        (\n        S\n        )\n        ,\n      \n    \n    {\\displaystyle \\operatorname {bd} (S),\\operatorname {fr} (S),}\n  \n  and \n  \n    \n      \n        ∂\n        S\n      \n    \n    {\\displaystyle \\partial S}\n  \n.\nSome authors (for example Willard, in General Topology) use the term frontier instead of boundary in an attempt to avoid confusion with a different definition used in algebraic topology and the theory of manifolds.  Despite widespread acceptance of the meaning of the terms boundary and frontier, they have sometimes been used to",
    "content": "In topology and mathematics in general, the boundary of a subset S of a topological space X is the set of points in the closure of S not belonging to the interior of S. An element of the boundary of S is called a boundary point of S. The term boundary operation refers to finding or taking the boundary of a set.  Notations used for boundary of a set S include \n  \n    \n      \n        bd\n        ⁡\n        (\n        S\n        )\n        ,\n        fr\n        ⁡\n        (\n        S\n        )\n        ,\n      \n    \n    {\\displaystyle \\operatorname {bd} (S),\\operatorname {fr} (S),}\n  \n  and \n  \n    \n      \n        ∂\n        S\n      \n    \n    {\\displaystyle \\partial S}\n  \n.\nSome authors (for example Willard, in General Topology) use the term frontier instead of boundary in an attempt to avoid confusion with a different definition used in algebraic topology and the theory of manifolds.  Despite widespread acceptance of the meaning of the terms boundary and frontier, they have sometimes been used to refer to other sets.  For example, Metric Spaces by E. T. Copson uses the term boundary to refer to Hausdorff's border, which is defined as the intersection of a set with its boundary. Hausdorff also introduced the term residue, which is defined as the intersection of a set with the closure of the border of its complement.\n\nDefinitions\nThere are several equivalent definitions for the boundary of a subset \n  \n    \n      \n        S\n        ⊆\n        X\n      \n    \n    {\\displaystyle S\\subseteq X}\n  \n of a topological space \n  \n    \n      \n        X\n        ,\n      \n    \n    {\\displaystyle X,}\n  \n which will be denoted by \n  \n    \n      \n        \n          ∂\n          \n            X\n          \n        \n        S\n        ,\n      \n    \n    {\\displaystyle \\partial _{X}S,}\n  \n \n  \n    \n      \n        \n          Bd\n          \n            X\n          \n        \n        ⁡\n        S\n        ,\n      \n    \n    {\\displaystyle \\operatorname {Bd} _{X}S,}\n  \n or simply \n  \n    \n      \n        ∂\n        S\n      \n    \n    {\\displaystyle \\partial S}\n  \n if \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is understood:\n\nIt is the closure of \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n minus the interior of \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n in \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n:  \n  \n    \n      \n        ∂\n        S\n         \n        :=\n         \n        \n          \n            S\n            ¯\n          \n        \n        ∖\n        \n          int\n          \n            X\n          \n        \n        ⁡\n        S\n      \n    \n    {\\displaystyle \\partial S~:=~{\\overline {S}}\\setminus \\operatorname {int} _{X}S}\n  \n\nwhere \n  \n    \n      \n        \n          \n            S\n            ¯\n          \n        \n        =\n        \n          cl\n          \n            X\n          \n        \n        ⁡\n        S\n      \n    \n    {\\displaystyle {\\overline {S}}=\\operatorname {cl} _{X}S}\n  \n denotes the closure of \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n in \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n and \n  \n    \n      \n        \n          int\n          \n            X\n          \n        \n        ⁡\n        S\n      \n    \n    {\\displaystyle \\operatorname {int} _{X}S}\n  \n denotes the topological interior of \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n in \n  \n    \n      \n        X\n        .\n      \n    \n    {\\displaystyle X.}\n  \n\nIt is the intersection of the closure of \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n with the closure of its complement: \n  \n    \n      \n        ∂\n        S\n         \n        :=\n         \n        \n          \n            S\n            ¯\n          \n        \n        ∩\n        \n          \n            \n              (\n              X\n              ∖\n              S\n              )\n            \n            ¯\n          \n        \n      \n    \n    {\\displaystyle \\partial S~:=~{\\overline {S}}\\cap {\\overline {(X\\setminus S)}}}\n  \n\nIt is the set of points \n  \n    \n      \n        p\n        ∈\n        X\n      \n    \n    {\\displaystyle p\\in X}\n  \n such that every neighborhood of \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n contains at least one point of \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n and at least one point not of \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n: \n  \n    \n      \n        ∂\n        S\n         \n        :=\n         \n        {\n        p\n        ∈\n        X\n        :\n        \n           for every neighborhood \n        \n        O\n        \n           of \n        \n        p\n        ,\n         \n        O\n        ∩\n        S\n        ≠\n        ∅\n        \n        \n           and \n        \n        \n        O\n        ∩\n        (\n        X\n        ∖\n        S\n        )\n        ≠\n        ∅\n        }\n        .\n      \n    \n    {\\displaystyle \\partial S~:=~\\{p\\in X:{\\text{ for every neighborhood }}O{\\text{ of }}p,\\ O\\cap S\\neq \\varnothing ",
    "links": [
      "Accumulation point",
      "Algebraic topology",
      "Baire space",
      "Banach fixed-point theorem",
      "Basis (topology)",
      "Betti number",
      "Boundary of a locally closed subset",
      "Boundary of a manifold",
      "Bounding point",
      "Bundle (mathematics)",
      "CW complex",
      "Chern class",
      "Clopen set",
      "Closed set",
      "Closure (topology)",
      "Cobordism",
      "Cohomology",
      "Combinatorial topology",
      "Compact space",
      "Complement (set theory)",
      "Complete metric space",
      "Connected space",
      "Continuity (topology)",
      "Continuum (topology)",
      "De Rham cohomology",
      "Dense set",
      "Dense subset",
      "Differential topology",
      "Digital topology",
      "Euclidean metric",
      "Euclidean topology",
      "Euler characteristic",
      "Felix Hausdorff",
      "Fundamental group",
      "General topology",
      "Geometric topology",
      "Hausdorff space",
      "Homology (mathematics)",
      "Homotopy",
      "Homotopy group",
      "ISBN (identifier)",
      "Idempotence",
      "Interior (topology)",
      "Interior point",
      "Invariance of domain",
      "Isolated point",
      "Klein bottle",
      "Lebesgue's density theorem",
      "List of algebraic topology topics",
      "List of general topology topics"
    ],
    "categories": [
      "Category:All articles lacking in-text citations",
      "Category:Articles lacking in-text citations from March 2013",
      "Category:Articles with short description",
      "Category:CS1 errors: ISBN date",
      "Category:General topology",
      "Category:Pages displaying short descriptions of redirect targets via Module:Annotated link",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Bounded set": {
    "title": "Bounded set",
    "url": "https://en.wikipedia.org/wiki/Bounded_set",
    "summary": "In mathematical analysis and related areas of mathematics, a set is called bounded if all of its points are within a certain distance of each other. Conversely, a set which is not bounded is called unbounded. The word \"bounded\" makes no sense in a general topological space without a corresponding metric.\nBoundary is a distinct concept; for example, a circle (not to be confused with a disk) in isolation is a boundaryless bounded set, while the half plane is unbounded yet has a boundary.\nA bounded set is not necessarily a closed set and vice versa. For example, a subset S of a 2-dimensional real space R2 constrained by two parabolic curves x2 + 1 and x2 − 1 defined in a Cartesian coordinate system is closed by the curves but not bounded (so unbounded).",
    "content": "In mathematical analysis and related areas of mathematics, a set is called bounded if all of its points are within a certain distance of each other. Conversely, a set which is not bounded is called unbounded. The word \"bounded\" makes no sense in a general topological space without a corresponding metric.\nBoundary is a distinct concept; for example, a circle (not to be confused with a disk) in isolation is a boundaryless bounded set, while the half plane is unbounded yet has a boundary.\nA bounded set is not necessarily a closed set and vice versa. For example, a subset S of a 2-dimensional real space R2 constrained by two parabolic curves x2 + 1 and x2 − 1 defined in a Cartesian coordinate system is closed by the curves but not bounded (so unbounded).\n\nDefinition in the real numbers\nA set S of real numbers is called bounded from above if there exists some real number k (not necessarily in S) such that k ≥  s for all s in S. The number k is called an upper bound of S. The terms bounded from below and lower bound are similarly defined.\nA set S is bounded if it has both upper and lower bounds. Therefore, a set of real numbers is bounded if it is contained in a finite interval.\n\nDefinition in a metric space\nA subset S of a metric space (M, d) is bounded if there exists r > 0 such that for all s and t in S, we have d(s, t) < r. The metric space (M, d) is a bounded metric space (or d is a bounded metric) if M is bounded as a subset of itself.\n\nTotal boundedness implies boundedness. For subsets of Rn the two are equivalent.\nA metric space is compact if and only if it is complete and totally bounded.\nA subset of Euclidean space Rn is compact if and only if it is closed and bounded. This is also called the Heine-Borel theorem.\n\nBoundedness in topological vector spaces\nIn topological vector spaces, a different definition for bounded sets exists which is sometimes called von Neumann boundedness. If the topology of the topological vector space is induced by a metric which is homogeneous, as in the case of a metric induced by the norm of normed vector spaces, then the two definitions coincide.\n\nBoundedness in order theory\nA set of real numbers is bounded if and only if it has an upper and lower bound. This definition is extendable to subsets of any partially ordered set. Note that this more general concept of boundedness does not correspond to a notion of \"size\". \nA subset S of a partially ordered set P is called bounded above if there is an element k in P such that k ≥ s for all s in S. The element k is called an upper bound of S. The concepts of bounded below and lower bound are defined similarly.  (See also upper and lower bounds.)\nA subset S of a partially ordered set P is called bounded if it has both an upper and a lower bound, or equivalently, if it is contained in an interval. Note that this is not just a property of the set S but also one of the set S as subset of P.\nA bounded poset P (that is, by itself, not as subset) is one that has a least element and a greatest element. Note that this concept of boundedness has nothing to do with finite size, and that a subset S of a bounded poset P with as order the restriction of the order on P is not necessarily a bounded poset.\nA subset S of Rn is bounded with respect to the Euclidean distance if and only if it bounded as subset of Rn with the product order. However, S may be bounded as subset of Rn with the lexicographical order, but not with respect to the Euclidean distance.\nA class of ordinal numbers is said to be unbounded, or cofinal, when given any ordinal, there is always some element of the class greater than it. Thus in this case \"unbounded\" does not mean unbounded by itself but unbounded as a subclass of the class of all ordinal numbers.\n\nSee also\nBounded domain\nBounded function\nLocal boundedness\nOrder theory\nTotally bounded\n\nReferences\nBartle, Robert G.; Sherbert, Donald R. (1982). Introduction to Real Analysis. New York: John Wiley & Sons. ISBN 0-471-05944-7.\nRichtmyer, Robert D. (1978). Principles of Advanced Mathematical Physics. New York: Springer. ISBN 0-387-08873-3.",
    "links": [
      "Approach space",
      "Artist's impression",
      "Baire category theorem",
      "Ball (mathematics)",
      "Banach fixed-point theorem",
      "Binary relation",
      "Bing metrization theorem",
      "Borel set",
      "Boundary (topology)",
      "Bounded domain",
      "Bounded function",
      "Bounded set (topological vector space)",
      "Cantor space",
      "Cartesian coordinate system",
      "Category of metric spaces",
      "Cauchy sequence",
      "Cauchy space",
      "Chebyshev distance",
      "Circle",
      "Closed set",
      "Coarse structure",
      "Cofinal (mathematics)",
      "Compact space",
      "Complete metric space",
      "Contraction mapping",
      "Convex metric space",
      "Cosmic space",
      "Delone set",
      "Diameter of a set",
      "Dilation (metric space)",
      "Discrete space",
      "Disk (mathematics)",
      "Distance set",
      "Diversity (mathematics)",
      "Doubling space",
      "Equicontinuity",
      "Equivalence of metrics",
      "Euclidean distance",
      "Euclidean space",
      "Functional analysis",
      "General topology",
      "Generalised metric",
      "Greatest element",
      "Gromov product",
      "Gromov–Hausdorff convergence",
      "Half plane",
      "Hausdorff distance",
      "Heine-Borel theorem",
      "Homogeneous metric",
      "Hyperbolic metric space"
    ],
    "categories": [
      "Category:All articles lacking in-text citations",
      "Category:Articles lacking in-text citations from November 2023",
      "Category:Articles with short description",
      "Category:Functional analysis",
      "Category:Mathematical analysis",
      "Category:Order theory",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Bump function": {
    "title": "Bump function",
    "url": "https://en.wikipedia.org/wiki/Bump_function",
    "summary": "In real analysis, a bump function (also called a test function) is a function \n  \n    \n      \n        f\n        :\n        \n          \n            R\n          \n          \n            n\n          \n        \n        →\n        \n          R\n        \n      \n    \n    {\\displaystyle f:\\mathbb {R} ^{n}\\to \\mathbb {R} }\n  \n on a Euclidean space \n  \n    \n      \n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{n}}\n  \n which is both smooth (in the sense of having continuous derivatives of all orders) and has bounded support.  The set of all bump functions with domain \n  \n    \n      \n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{n}}\n  \n forms a vector space, denoted \n  \n    \n      \n        \n          \n            C\n          \n          \n            0\n          \n          \n            ∞\n          \n        \n        (\n        \n    ",
    "content": "In real analysis, a bump function (also called a test function) is a function \n  \n    \n      \n        f\n        :\n        \n          \n            R\n          \n          \n            n\n          \n        \n        →\n        \n          R\n        \n      \n    \n    {\\displaystyle f:\\mathbb {R} ^{n}\\to \\mathbb {R} }\n  \n on a Euclidean space \n  \n    \n      \n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{n}}\n  \n which is both smooth (in the sense of having continuous derivatives of all orders) and has bounded support.  The set of all bump functions with domain \n  \n    \n      \n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{n}}\n  \n forms a vector space, denoted \n  \n    \n      \n        \n          \n            C\n          \n          \n            0\n          \n          \n            ∞\n          \n        \n        (\n        \n          \n            R\n          \n          \n            n\n          \n        \n        )\n      \n    \n    {\\displaystyle \\mathrm {C} _{0}^{\\infty }(\\mathbb {R} ^{n})}\n  \n or \n  \n    \n      \n        \n          \n            C\n          \n          \n            \n              c\n            \n          \n          \n            ∞\n          \n        \n        (\n        \n          \n            R\n          \n          \n            n\n          \n        \n        )\n        .\n      \n    \n    {\\displaystyle \\mathrm {C} _{\\mathrm {c} }^{\\infty }(\\mathbb {R} ^{n}).}\n  \n  The dual space of this space endowed with a suitable topology is the space of distributions.\n\nExamples\nThe function \n  \n    \n      \n        Ψ\n        :\n        \n          R\n        \n        →\n        \n          R\n        \n      \n    \n    {\\displaystyle \\Psi :\\mathbb {R} \\to \\mathbb {R} }\n  \n given by\n\n  \n    \n      \n        Ψ\n        (\n        x\n        )\n        =\n        \n          \n            {\n            \n              \n                \n                  exp\n                  ⁡\n                  \n                    (\n                    \n                      \n                        1\n                        \n                          \n                            x\n                            \n                              2\n                            \n                          \n                          −\n                          1\n                        \n                      \n                    \n                    )\n                  \n                  ,\n                \n                \n                  \n                     if \n                  \n                  \n                    |\n                  \n                  x\n                  \n                    |\n                  \n                  <\n                  1\n                  ,\n                \n              \n              \n                \n                  0\n                  ,\n                \n                \n                  \n                     if \n                  \n                  \n                    |\n                  \n                  x\n                  \n                    |\n                  \n                  ≥\n                  1\n                  ,\n                \n              \n            \n            \n          \n        \n      \n    \n    {\\displaystyle \\Psi (x)={\\begin{cases}\\exp \\left({\\frac {1}{x^{2}-1}}\\right),&{\\text{ if }}|x|<1,\\\\0,&{\\text{ if }}|x|\\geq 1,\\end{cases}}}\n  \n\nis an example of a bump function in one dimension. Note that the support of this function is the closed interval \n  \n    \n      \n        [\n        −\n        1\n        ,\n        1\n        ]\n      \n    \n    {\\displaystyle [-1,1]}\n  \n. In fact, by definition of support, we have that \n  \n    \n      \n        supp\n        ⁡\n        (\n        Ψ\n        )\n        :=\n        \n          \n            \n              {\n              x\n              ∈\n              \n                R\n              \n              :\n              Ψ\n              (\n              x\n              )\n              ≠\n              0\n              }\n            \n            ¯\n          \n        \n        =\n        \n          \n            \n              (\n              −\n              1\n              ,\n              1\n              )\n            \n            ¯\n          \n        \n      \n    \n    {\\displaystyle \\operatorname {supp} (\\Psi ):={\\overline {\\{x\\in \\mathbb {R} :\\Psi (x)\\neq 0\\}}}={\\overline {(-1,1)}}}\n  \n, where the closure is taken with respect the Euclidean topology of the real line. The proof of smoothness follows along the same lines as for the related function discussed in the Non-analytic smooth function article. This function can be interpreted as the Gaussian function \n  \n    \n      \n        exp\n        ⁡\n        \n          (\n          \n            −\n            \n              y\n              \n                2\n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\exp \\left(-y^{2}\\right",
    "links": [
      "Absolute value",
      "Analytic function",
      "Bounded set",
      "Compact set",
      "Complex plane",
      "Continuous function",
      "Convolution",
      "Cover (topology)",
      "Cutoff function",
      "Delay differential equation",
      "Derivative",
      "Differentiable function",
      "Differential operator",
      "Distribution (mathematics)",
      "Doi (identifier)",
      "Domain of a function",
      "Dual space",
      "Euclidean metric",
      "Euclidean norm",
      "Euclidean space",
      "Fourier transform",
      "Function (mathematics)",
      "Gaussian function",
      "Graduate Texts in Mathematics",
      "Hyperbolic functions",
      "ISBN (identifier)",
      "Identity theorem",
      "Indicator function",
      "Jet Nestruev",
      "Laplacian of the indicator",
      "Liouville's theorem (complex analysis)",
      "Mollifier",
      "Non-analytic smooth function",
      "OCLC (identifier)",
      "Open set",
      "Paley–Wiener theorem",
      "Partitions of unity",
      "Real analysis",
      "Real number",
      "Saddle-point method",
      "Schwartz space",
      "Set (mathematics)",
      "Smooth function",
      "Springer Nature",
      "Steven G. Johnson",
      "Support (mathematics)",
      "Supremum",
      "Test functions",
      "Topological space",
      "Unit interval"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Pages displaying short descriptions of redirect targets via Module:Annotated link",
      "Category:Schwartz distributions",
      "Category:Short description is different from Wikidata",
      "Category:Smooth functions"
    ]
  },
  "Cauchy integral formula": {
    "title": "Cauchy's integral formula",
    "url": "https://en.wikipedia.org/wiki/Cauchy%27s_integral_formula",
    "summary": "In mathematics, Cauchy's integral formula, named after Augustin-Louis Cauchy, is a central statement in complex analysis. It expresses the fact that a holomorphic function defined on a disk is completely determined by its values on the boundary of the disk, and it provides integral formulas for all derivatives of a holomorphic function. Cauchy's formula shows that, in complex analysis, \"differentiation is equivalent to integration\": complex differentiation, like integration, behaves well under uniform limits – a result that does not hold in real analysis.",
    "content": "In mathematics, Cauchy's integral formula, named after Augustin-Louis Cauchy, is a central statement in complex analysis. It expresses the fact that a holomorphic function defined on a disk is completely determined by its values on the boundary of the disk, and it provides integral formulas for all derivatives of a holomorphic function. Cauchy's formula shows that, in complex analysis, \"differentiation is equivalent to integration\": complex differentiation, like integration, behaves well under uniform limits – a result that does not hold in real analysis.\n\nTheorem\nLet U be an open subset of the complex plane C, and suppose the closed disk D defined as\n\n  \n    \n      \n        D\n        =\n        \n          \n            {\n          \n        \n        z\n        :\n        \n          |\n        \n        z\n        −\n        \n          z\n          \n            0\n          \n        \n        \n          |\n        \n        ≤\n        r\n        \n          \n            }\n          \n        \n      \n    \n    {\\displaystyle D={\\bigl \\{}z:|z-z_{0}|\\leq r{\\bigr \\}}}\n  \n\nis completely contained in U.  Let f : U → C be a holomorphic function, and let γ be the circle, oriented counterclockwise, forming the boundary of D. Then for every a in the interior of D,\n\n  \n    \n      \n        f\n        (\n        a\n        )\n        =\n        \n          \n            1\n            \n              2\n              π\n              i\n            \n          \n        \n        \n          ∮\n          \n            γ\n          \n        \n        \n          \n            \n              f\n              (\n              z\n              )\n            \n            \n              z\n              −\n              a\n            \n          \n        \n        \n        d\n        z\n        .\n        \n      \n    \n    {\\displaystyle f(a)={\\frac {1}{2\\pi i}}\\oint _{\\gamma }{\\frac {f(z)}{z-a}}\\,dz.\\,}\n  \n\nThe proof of this statement uses the Cauchy integral theorem and like that theorem, it only requires f to be complex differentiable.  Since \n  \n    \n      \n        1\n        \n          /\n        \n        (\n        z\n        −\n        a\n        )\n      \n    \n    {\\displaystyle 1/(z-a)}\n  \n can be expanded as a power series in the variable \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n\n  \n    \n      \n        \n          \n            1\n            \n              z\n              −\n              a\n            \n          \n        \n        =\n        \n          \n            \n              1\n              +\n              \n                \n                  a\n                  z\n                \n              \n              +\n              \n                \n                  (\n                  \n                    \n                      a\n                      z\n                    \n                  \n                  )\n                \n                \n                  2\n                \n              \n              +\n              ⋯\n            \n            z\n          \n        \n      \n    \n    {\\displaystyle {\\frac {1}{z-a}}={\\frac {1+{\\frac {a}{z}}+\\left({\\frac {a}{z}}\\right)^{2}+\\cdots }{z}}}\n  \n\nit follows that holomorphic functions are analytic, i.e. they can be expanded as convergent power series.\nIn particular f is actually infinitely differentiable, with\n\n  \n    \n      \n        \n          f\n          \n            (\n            n\n            )\n          \n        \n        (\n        a\n        )\n        =\n        \n          \n            \n              n\n              !\n            \n            \n              2\n              π\n              i\n            \n          \n        \n        \n          ∮\n          \n            γ\n          \n        \n        \n          \n            \n              f\n              (\n              z\n              )\n            \n            \n              \n                (\n                \n                  z\n                  −\n                  a\n                \n                )\n              \n              \n                n\n                +\n                1\n              \n            \n          \n        \n        \n        d\n        z\n        .\n      \n    \n    {\\displaystyle f^{(n)}(a)={\\frac {n!}{2\\pi i}}\\oint _{\\gamma }{\\frac {f(z)}{\\left(z-a\\right)^{n+1}}}\\,dz.}\n  \n\nThis formula is sometimes referred to as Cauchy's differentiation formula.\nThe theorem stated above can be generalized. The circle γ can be replaced by any closed rectifiable curve in U which has winding number one about a. Moreover, as for the Cauchy integral theorem, it is sufficient to require that f be holomorphic in the open region enclosed by the path and continuous on its closure.\nNote that not every continuous function on the boundary can be used to produce a function inside the boundary that fits the given boundary function. For instance, if we put the function  f(z) = ⁠1/z⁠, defined for |z| = 1, into the Cauchy integral formula, we get zero for all points inside the circle. In fact, giving just the real part on the boundary of a holomorphic function is enough",
    "links": [
      "Absolute value",
      "Analytic continuation",
      "Analytic function",
      "Analyticity of holomorphic functions",
      "Antiderivative (complex analysis)",
      "Argument principle",
      "Augustin-Louis Cauchy",
      "Ball (mathematics)",
      "Bernhard Riemann",
      "Bivector",
      "Bochner–Martinelli formula",
      "Boundary (topology)",
      "Carl Friedrich Gauss",
      "Cartesian product",
      "Cauchy's estimate",
      "Cauchy's integral theorem",
      "Cauchy formula for repeated integration",
      "Cauchy integral theorem",
      "Cauchy principal value",
      "Cauchy–Goursat theorem",
      "Cauchy–Riemann equations",
      "Cauchy–Riemann operator",
      "Circle",
      "Closure (topology)",
      "Complex analysis",
      "Complex conjugate",
      "Complex differentiable",
      "Complex manifold",
      "Complex number",
      "Complex plane",
      "Conformal map",
      "Continuously differentiable function",
      "Contour integration",
      "Convolution",
      "Curl (mathematics)",
      "Curve orientation",
      "Dimitrie Pompeiu",
      "Distribution (mathematics)",
      "Distributional derivative",
      "Divergence",
      "Divergence theorem",
      "Dominated convergence theorem",
      "Edward Charles Titchmarsh",
      "Encyclopedia of Mathematics",
      "Entire function",
      "Eric W. Weisstein",
      "Essential singularity",
      "Euler's formula",
      "European Mathematical Society",
      "Formal power series"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Augustin-Louis Cauchy",
      "Category:Short description matches Wikidata",
      "Category:Theorems in complex analysis"
    ]
  },
  "Cauchy sequence": {
    "title": "Cauchy sequence",
    "url": "https://en.wikipedia.org/wiki/Cauchy_sequence",
    "summary": "In mathematics, a Cauchy sequence is a sequence whose elements become arbitrarily close to each other as the sequence progresses. More precisely, given any small positive distance, all excluding a finite number of elements of the sequence are less than that given distance from each other. Cauchy sequences are named after Augustin-Louis Cauchy; they may occasionally be known as fundamental sequences.\nIt is not sufficient for each term to become arbitrarily close to the preceding term. For instance, in the sequence of square roots of natural numbers:\n\n  \n    \n      \n        \n          a\n          \n            n\n          \n        \n        =\n        \n          \n            n\n          \n        \n        ,\n      \n    \n    {\\displaystyle a_{n}={\\sqrt {n}},}\n  \n\nthe consecutive terms become arbitrarily close to each other – their differences\n\n  \n    \n      \n        \n          a\n          \n            n\n            +\n            1\n          \n        \n        −\n        \n          a\n          \n ",
    "content": "In mathematics, a Cauchy sequence is a sequence whose elements become arbitrarily close to each other as the sequence progresses. More precisely, given any small positive distance, all excluding a finite number of elements of the sequence are less than that given distance from each other. Cauchy sequences are named after Augustin-Louis Cauchy; they may occasionally be known as fundamental sequences.\nIt is not sufficient for each term to become arbitrarily close to the preceding term. For instance, in the sequence of square roots of natural numbers:\n\n  \n    \n      \n        \n          a\n          \n            n\n          \n        \n        =\n        \n          \n            n\n          \n        \n        ,\n      \n    \n    {\\displaystyle a_{n}={\\sqrt {n}},}\n  \n\nthe consecutive terms become arbitrarily close to each other – their differences\n\n  \n    \n      \n        \n          a\n          \n            n\n            +\n            1\n          \n        \n        −\n        \n          a\n          \n            n\n          \n        \n        =\n        \n          \n            n\n            +\n            1\n          \n        \n        −\n        \n          \n            n\n          \n        \n        =\n        \n          \n            1\n            \n              \n                \n                  n\n                  +\n                  1\n                \n              \n              +\n              \n                \n                  n\n                \n              \n            \n          \n        \n        <\n        \n          \n            1\n            \n              2\n              \n                \n                  n\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle a_{n+1}-a_{n}={\\sqrt {n+1}}-{\\sqrt {n}}={\\frac {1}{{\\sqrt {n+1}}+{\\sqrt {n}}}}<{\\frac {1}{2{\\sqrt {n}}}}}\n  \n\ntend to zero as the index n grows. However, with growing values of n, the terms \n  \n    \n      \n        \n          a\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle a_{n}}\n  \n become arbitrarily large. So, for any index n and distance d, there exists an index m big enough such that \n  \n    \n      \n        \n          a\n          \n            m\n          \n        \n        −\n        \n          a\n          \n            n\n          \n        \n        >\n        d\n        .\n      \n    \n    {\\displaystyle a_{m}-a_{n}>d.}\n  \n  As a result, no matter how far one goes, the remaining terms of the sequence never get close to each other; hence the sequence is not Cauchy.\nThe utility of Cauchy sequences lies in the fact that in a complete metric space (one where all such sequences are known to converge to a limit), the criterion for convergence depends only on the terms of the sequence itself, as opposed to the definition of convergence, which uses the limit value as well as the terms. This is often exploited in algorithms, both theoretical and applied,  where an iterative process can be shown relatively easily to produce a Cauchy sequence, consisting of the iterates, thus fulfilling a logical condition, such as termination. \nGeneralizations of Cauchy sequences in more abstract uniform spaces exist in the form of Cauchy filters and Cauchy nets.\n\nIn real numbers\nA sequence\n\n  \n    \n      \n        \n          x\n          \n            1\n          \n        \n        ,\n        \n          x\n          \n            2\n          \n        \n        ,\n        \n          x\n          \n            3\n          \n        \n        ,\n        …\n      \n    \n    {\\displaystyle x_{1},x_{2},x_{3},\\ldots }\n  \n\nof real numbers is called a Cauchy sequence if for every positive real number \n  \n    \n      \n        ε\n        ,\n      \n    \n    {\\displaystyle \\varepsilon ,}\n  \n there is a positive integer N such that for all natural numbers \n  \n    \n      \n        m\n        ,\n        n\n        >\n        N\n        ,\n      \n    \n    {\\displaystyle m,n>N,}\n  \n\n  \n    \n      \n        \n          |\n        \n        \n          x\n          \n            m\n          \n        \n        −\n        \n          x\n          \n            n\n          \n        \n        \n          |\n        \n        <\n        ε\n        ,\n      \n    \n    {\\displaystyle |x_{m}-x_{n}|<\\varepsilon ,}\n  \n\nwhere the vertical bars denote the absolute value.  In a similar way one can define Cauchy sequences of rational or complex numbers.  Cauchy formulated such a condition by requiring \n  \n    \n      \n        \n          x\n          \n            m\n          \n        \n        −\n        \n          x\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle x_{m}-x_{n}}\n  \n to be infinitesimal for every pair of infinite m, n.\nFor any real number r, the sequence of truncated decimal expansions of r forms a Cauchy sequence.  For example, when \n  \n    \n      \n        r\n        =\n        π\n        ,\n      \n    \n    {\\displaystyle r=\\pi ,}\n  \n this sequence is (3, 3.1, 3.14, 3.141, ...).  The mth and nth terms differ by at most \n  \n    \n      \n        \n          10\n   ",
    "links": [
      "1/2 + 1/4 + 1/8 + 1/16 + ⋯",
      "1/2 − 1/4 + 1/8 − 1/16 + ⋯",
      "1/4 + 1/16 + 1/64 + 1/256 + ⋯",
      "1 + 1 + 1 + 1 + ⋯",
      "1 + 2 + 3 + 4 + ⋯",
      "1 + 2 + 4 + 8 + ⋯",
      "1 − 1 + 2 − 6 + 24 − 120 + ⋯",
      "1 − 2 + 3 − 4 + ⋯",
      "1 − 2 + 4 − 8 + ⋯",
      "Absolute convergence",
      "Absolute difference",
      "Absolute value",
      "Adequality",
      "Algebraic geometry",
      "Algorithm",
      "Alternating series",
      "Anne Sjerp Troelstra",
      "Approach space",
      "ArXiv (identifier)",
      "Arithmetic progression",
      "Augustin-Louis Cauchy",
      "Baire category theorem",
      "Ball (mathematics)",
      "Banach fixed-point theorem",
      "Banach space",
      "Bing metrization theorem",
      "Bolzano–Weierstrass theorem",
      "Borel set",
      "Bounded function",
      "Bounded set",
      "Canonical form",
      "Cantor space",
      "Category (mathematics)",
      "Category of metric spaces",
      "Cauchy filter",
      "Cauchy net",
      "Cauchy space",
      "Chebyshev distance",
      "Coarse structure",
      "Cofinal (mathematics)",
      "Complete metric space",
      "Complete sequence",
      "Completion (metric space)",
      "Complex number",
      "Conditional convergence",
      "Construction of the real numbers",
      "Contraction mapping",
      "Convergence (mathematics)",
      "Convergent series",
      "Convex metric space"
    ],
    "categories": [
      "Category:Abstract algebra",
      "Category:Articles with short description",
      "Category:Augustin-Louis Cauchy",
      "Category:Convergence (mathematics)",
      "Category:Metric geometry",
      "Category:Sequences and series",
      "Category:Short description is different from Wikidata",
      "Category:Topology",
      "Category:Use shortened footnotes from November 2022"
    ]
  },
  "Complete metric space": {
    "title": "Complete metric space",
    "url": "https://en.wikipedia.org/wiki/Complete_metric_space",
    "summary": "In mathematical analysis, a metric space M is called complete (or a Cauchy space) if every Cauchy sequence of points in M has a limit that is also in M.\nIntuitively, a space is complete if there are no \"points missing\" from it (inside or at the boundary). For instance, the set of rational numbers is not complete, because e.g. \n  \n    \n      \n        \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle {\\sqrt {2}}}\n  \n is \"missing\" from it, even though one can construct a Cauchy sequence of rational numbers that converges to it (see further examples below). It is always possible to \"fill all the holes\", leading to the completion of a given space, as explained below.",
    "content": "In mathematical analysis, a metric space M is called complete (or a Cauchy space) if every Cauchy sequence of points in M has a limit that is also in M.\nIntuitively, a space is complete if there are no \"points missing\" from it (inside or at the boundary). For instance, the set of rational numbers is not complete, because e.g. \n  \n    \n      \n        \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle {\\sqrt {2}}}\n  \n is \"missing\" from it, even though one can construct a Cauchy sequence of rational numbers that converges to it (see further examples below). It is always possible to \"fill all the holes\", leading to the completion of a given space, as explained below.\n\nDefinition\nCauchy sequence\nA sequence \n  \n    \n      \n        \n          x\n          \n            1\n          \n        \n        ,\n        \n          x\n          \n            2\n          \n        \n        ,\n        \n          x\n          \n            3\n          \n        \n        ,\n        …\n      \n    \n    {\\displaystyle x_{1},x_{2},x_{3},\\ldots }\n  \n of elements from \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n of a metric space \n  \n    \n      \n        (\n        X\n        ,\n        d\n        )\n      \n    \n    {\\displaystyle (X,d)}\n  \n is called Cauchy if for every positive real number \n  \n    \n      \n        r\n        >\n        0\n      \n    \n    {\\displaystyle r>0}\n  \n there is a positive integer \n  \n    \n      \n        N\n      \n    \n    {\\displaystyle N}\n  \n such that for all positive integers \n  \n    \n      \n        m\n        ,\n        n\n        >\n        N\n        ,\n      \n    \n    {\\displaystyle m,n>N,}\n  \n \n  \n    \n      \n        d\n        (\n        \n          x\n          \n            m\n          \n        \n        ,\n        \n          x\n          \n            n\n          \n        \n        )\n        <\n        r\n        .\n      \n    \n    {\\displaystyle d(x_{m},x_{n})<r.}\n  \n \nComplete space\nA metric space \n  \n    \n      \n        (\n        X\n        ,\n        d\n        )\n      \n    \n    {\\displaystyle (X,d)}\n  \n is complete if any of the following equivalent conditions are satisfied:\n\nEvery Cauchy sequence in \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n converges in \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n (that is, has a limit that is also in \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n).\nEvery decreasing sequence of non-empty closed subsets of \n  \n    \n      \n        X\n        ,\n      \n    \n    {\\displaystyle X,}\n  \n with diameters tending to 0, has a non-empty intersection: if \n  \n    \n      \n        \n          F\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle F_{n}}\n  \n is closed and non-empty, \n  \n    \n      \n        \n          F\n          \n            n\n            +\n            1\n          \n        \n        ⊆\n        \n          F\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle F_{n+1}\\subseteq F_{n}}\n  \n for every \n  \n    \n      \n        n\n        ,\n      \n    \n    {\\displaystyle n,}\n  \n and \n  \n    \n      \n        diam\n        ⁡\n        \n          (\n          \n            F\n            \n              n\n            \n          \n          )\n        \n        →\n        0\n        ,\n      \n    \n    {\\displaystyle \\operatorname {diam} \\left(F_{n}\\right)\\to 0,}\n  \n then there is a unique point \n  \n    \n      \n        x\n        ∈\n        X\n      \n    \n    {\\displaystyle x\\in X}\n  \n common to all sets \n  \n    \n      \n        \n          F\n          \n            n\n          \n        \n        .\n      \n    \n    {\\displaystyle F_{n}.}\n\nExamples\nThe space \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n of rational numbers, with the standard metric given by the absolute value of the difference, is not complete. \nConsider for instance the sequence defined by \n\n  \n    \n      \n        \n          x\n          \n            1\n          \n        \n        =\n        1\n        \n      \n    \n    {\\displaystyle x_{1}=1\\;}\n  \n and \n  \n    \n      \n        \n        \n          x\n          \n            n\n            +\n            1\n          \n        \n        =\n        \n          \n            \n              x\n              \n                n\n              \n            \n            2\n          \n        \n        +\n        \n          \n            1\n            \n              x\n              \n                n\n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\;x_{n+1}={\\frac {x_{n}}{2}}+{\\frac {1}{x_{n}}}.}\n  \n\nThis is a Cauchy sequence of rational numbers, but it does not converge towards any rational limit: If the sequence did have a limit \n  \n    \n      \n        x\n        ,\n      \n    \n    {\\displaystyle x,}\n  \n then by solving \n  \n    \n      \n        x\n        =\n        \n          \n            x\n            2\n          \n        \n        +\n        \n          \n            1\n            x\n          \n        \n      \n    \n    {\\displ",
    "links": [
      "Absolute value",
      "Approach space",
      "Baire category theorem",
      "Baire space",
      "Ball (mathematics)",
      "Banach fixed-point theorem",
      "Banach space",
      "Bing metrization theorem",
      "Borel set",
      "Bounded function",
      "Bounded set",
      "Cantor space",
      "Category of metric spaces",
      "Cauchy sequence",
      "Cauchy space",
      "Chebyshev distance",
      "Closed interval",
      "Closed subset",
      "Coarse structure",
      "Compact convergence",
      "Compact space",
      "Complete topological vector space",
      "Complete uniform space",
      "Completely metrizable space",
      "Completely uniformizable space",
      "Completion (algebra)",
      "Complex number",
      "Construction of the real numbers",
      "Continuous function (topology)",
      "Continuous functions on a compact Hausdorff space",
      "Contraction mapping",
      "Convex metric space",
      "Cosmic space",
      "Countable",
      "Decimal expansion",
      "Delone set",
      "Dense subspace",
      "Diameter of a set",
      "Dilation (metric space)",
      "Dimension (vector space)",
      "Discrete space",
      "Distance set",
      "Distinct (mathematics)",
      "Diversity (mathematics)",
      "Doubling space",
      "Ekeland's variational principle",
      "Empty set",
      "Equicontinuity",
      "Equivalence class",
      "Equivalence of metrics"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Metric geometry",
      "Category:Pages displaying short descriptions of redirect targets via Module:Annotated link",
      "Category:Short description is different from Wikidata",
      "Category:Topology",
      "Category:Uniform spaces"
    ]
  },
  "Complex-valued function": {
    "title": "Complex analysis",
    "url": "https://en.wikipedia.org/wiki/Complex_analysis",
    "summary": "Complex analysis, traditionally known as the theory of functions of a complex variable, is the branch of mathematical analysis that investigates functions of complex numbers. It is helpful in many branches of mathematics, including algebraic geometry, number theory, analytic combinatorics, and applied mathematics, as well as in physics, including the branches of hydrodynamics, thermodynamics, quantum mechanics, and twistor theory. By extension, use of complex analysis also has applications in engineering fields such as nuclear, aerospace, mechanical and electrical engineering.\nAs a differentiable function of a complex variable is equal to the sum function given by its Taylor series (that is, it is analytic), complex analysis is particularly concerned with analytic functions of a complex variable, that is, holomorphic functions. \nThe concept can be extended to functions of several complex variables.\nComplex analysis is contrasted with real analysis, which deals with the study of real nu",
    "content": "Complex analysis, traditionally known as the theory of functions of a complex variable, is the branch of mathematical analysis that investigates functions of complex numbers. It is helpful in many branches of mathematics, including algebraic geometry, number theory, analytic combinatorics, and applied mathematics, as well as in physics, including the branches of hydrodynamics, thermodynamics, quantum mechanics, and twistor theory. By extension, use of complex analysis also has applications in engineering fields such as nuclear, aerospace, mechanical and electrical engineering.\nAs a differentiable function of a complex variable is equal to the sum function given by its Taylor series (that is, it is analytic), complex analysis is particularly concerned with analytic functions of a complex variable, that is, holomorphic functions. \nThe concept can be extended to functions of several complex variables.\nComplex analysis is contrasted with real analysis, which deals with the study of real numbers and functions of a real variable.\n\nHistory\nComplex analysis is one of the classical branches in mathematics, with roots in the 18th century and just prior. Important mathematicians associated with complex numbers include Euler, Gauss, Riemann, Cauchy, Weierstrass, and many more in the 20th century. Complex analysis, in particular the theory of conformal mappings, has many physical applications and is also used throughout analytic number theory. In modern times, it has become very popular through a new boost from complex dynamics and the pictures of fractals produced by iterating holomorphic functions.  Another important application of complex analysis is in string theory which examines conformal invariants in quantum field theory.\n\nComplex functions\nA complex function is a function from complex numbers to complex numbers. In other words, it is a function that has a (not necessarily proper) subset of the complex numbers as a domain and the complex numbers as a codomain. Complex functions are generally assumed to have a domain that contains a nonempty open subset of the complex plane.\nFor any complex function, the values \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n  \n from the domain and their images \n  \n    \n      \n        f\n        (\n        z\n        )\n      \n    \n    {\\displaystyle f(z)}\n  \n in the range may be separated into real and imaginary parts:\n\n  \n    \n      \n        z\n        =\n        x\n        +\n        i\n        y\n        \n        \n           and \n        \n        \n        f\n        (\n        z\n        )\n        =\n        f\n        (\n        x\n        +\n        i\n        y\n        )\n        =\n        u\n        (\n        x\n        ,\n        y\n        )\n        +\n        i\n        v\n        (\n        x\n        ,\n        y\n        )\n        ,\n      \n    \n    {\\displaystyle z=x+iy\\quad {\\text{ and }}\\quad f(z)=f(x+iy)=u(x,y)+iv(x,y),}\n  \n\nwhere \n  \n    \n      \n        x\n        ,\n        y\n        ,\n        u\n        (\n        x\n        ,\n        y\n        )\n        ,\n        v\n        (\n        x\n        ,\n        y\n        )\n      \n    \n    {\\displaystyle x,y,u(x,y),v(x,y)}\n  \n are all real-valued.\nIn other words, a complex function \n  \n    \n      \n        f\n        :\n        \n          C\n        \n        →\n        \n          C\n        \n      \n    \n    {\\displaystyle f:\\mathbb {C} \\to \\mathbb {C} }\n  \n may be decomposed into\n\n  \n    \n      \n        u\n        :\n        \n          \n            R\n          \n          \n            2\n          \n        \n        →\n        \n          R\n        \n        \n      \n    \n    {\\displaystyle u:\\mathbb {R} ^{2}\\to \\mathbb {R} \\quad }\n  \n and \n  \n    \n      \n        \n        v\n        :\n        \n          \n            R\n          \n          \n            2\n          \n        \n        →\n        \n          R\n        \n        ,\n      \n    \n    {\\displaystyle \\quad v:\\mathbb {R} ^{2}\\to \\mathbb {R} ,}\n  \n\ni.e., into two real-valued functions (\n  \n    \n      \n        u\n      \n    \n    {\\displaystyle u}\n  \n, \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n  \n) of two real variables (\n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n, \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n).\nSimilarly, any complex-valued function f on an arbitrary set X (is isomorphic to, and therefore, in that sense, it) can be considered as an ordered pair of two real-valued functions: (Re f, Im f) or, alternatively, as a vector-valued function from X into \n  \n    \n      \n        \n          \n            R\n          \n          \n            2\n          \n        \n        .\n      \n    \n    {\\displaystyle \\mathbb {R} ^{2}.}\n  \n\nSome properties of complex-valued functions (such as continuity) are nothing more than the corresponding properties of vector valued functions of two real variables. Other concepts of complex analysis, such as differentiability, are direct generalizations of the similar concepts for real functions, but may have very different prope",
    "links": [
      "A Course of Modern Analysis",
      "Absolute value",
      "Aerospace engineering",
      "Aleksei Ivanovich Markushevich",
      "Aleksei Sveshnikov",
      "Algebraic geometry",
      "Algebraically closed field",
      "Analytic combinatorics",
      "Analytic continuation",
      "Analytic function",
      "Analytic number theory",
      "Analyticity of holomorphic functions",
      "Andrew Forsyth",
      "Andrey Nikolayevich Tikhonov",
      "Angle",
      "Antiderivative (complex analysis)",
      "Applied mathematics",
      "Arc (geometry)",
      "Argument (complex analysis)",
      "Argument principle",
      "Athanassios S. Fokas",
      "Augustin-Louis Cauchy",
      "Bernhard Riemann",
      "Bounded function",
      "Brightness",
      "Calculus",
      "Calculus of variations",
      "Carl Friedrich Gauss",
      "Cauchy",
      "Cauchy's integral formula",
      "Cauchy's integral theorem",
      "Cauchy integral theorem",
      "Cauchy–Riemann conditions",
      "Cauchy–Riemann equations",
      "Codomain",
      "Complex Hilbert space",
      "Complex conjugate",
      "Complex dynamics",
      "Complex geometry",
      "Complex logarithm",
      "Complex manifold",
      "Complex number",
      "Complex numbers",
      "Complex plane",
      "Complexity theory (disambiguation)",
      "Conformal map",
      "Conformal mapping",
      "Conformality",
      "Connected space",
      "Constantin Carathéodory"
    ],
    "categories": [
      "Category:All articles lacking in-text citations",
      "Category:Articles lacking in-text citations from March 2021",
      "Category:Articles with excerpts",
      "Category:Articles with short description",
      "Category:Complex analysis",
      "Category:Complex numbers",
      "Category:Pages using Sister project links with hidden wikidata",
      "Category:Short description matches Wikidata"
    ]
  },
  "Convergent series": {
    "title": "Convergent series",
    "url": "https://en.wikipedia.org/wiki/Convergent_series",
    "summary": "In mathematics, a series is the sum of the terms of an infinite sequence of numbers. More precisely, an infinite sequence \n  \n    \n      \n        (\n        \n          a\n          \n            1\n          \n        \n        ,\n        \n          a\n          \n            2\n          \n        \n        ,\n        \n          a\n          \n            3\n          \n        \n        ,\n        …\n        )\n      \n    \n    {\\displaystyle (a_{1},a_{2},a_{3},\\ldots )}\n  \n defines a series S that is denoted \n\n  \n    \n      \n        S\n        =\n        \n          a\n          \n            1\n          \n        \n        +\n        \n          a\n          \n            2\n          \n        \n        +\n        \n          a\n          \n            3\n          \n        \n        +\n        ⋯\n        =\n        \n          ∑\n          \n            k\n            =\n            1\n          \n          \n            ∞\n          \n        \n        \n          a\n          \n            k\n          \n        \n        .\n      \n    \n  ",
    "content": "In mathematics, a series is the sum of the terms of an infinite sequence of numbers. More precisely, an infinite sequence \n  \n    \n      \n        (\n        \n          a\n          \n            1\n          \n        \n        ,\n        \n          a\n          \n            2\n          \n        \n        ,\n        \n          a\n          \n            3\n          \n        \n        ,\n        …\n        )\n      \n    \n    {\\displaystyle (a_{1},a_{2},a_{3},\\ldots )}\n  \n defines a series S that is denoted \n\n  \n    \n      \n        S\n        =\n        \n          a\n          \n            1\n          \n        \n        +\n        \n          a\n          \n            2\n          \n        \n        +\n        \n          a\n          \n            3\n          \n        \n        +\n        ⋯\n        =\n        \n          ∑\n          \n            k\n            =\n            1\n          \n          \n            ∞\n          \n        \n        \n          a\n          \n            k\n          \n        \n        .\n      \n    \n    {\\displaystyle S=a_{1}+a_{2}+a_{3}+\\cdots =\\sum _{k=1}^{\\infty }a_{k}.}\n  \n\nThe nth partial sum Sn is the sum of the first n terms of the sequence; that is,\n\n  \n    \n      \n        \n          S\n          \n            n\n          \n        \n        =\n        \n          a\n          \n            1\n          \n        \n        +\n        \n          a\n          \n            2\n          \n        \n        +\n        ⋯\n        +\n        \n          a\n          \n            n\n          \n        \n        =\n        \n          ∑\n          \n            k\n            =\n            1\n          \n          \n            n\n          \n        \n        \n          a\n          \n            k\n          \n        \n        .\n      \n    \n    {\\displaystyle S_{n}=a_{1}+a_{2}+\\cdots +a_{n}=\\sum _{k=1}^{n}a_{k}.}\n  \n\nA series is convergent (or converges) if and only if the sequence \n  \n    \n      \n        (\n        \n          S\n          \n            1\n          \n        \n        ,\n        \n          S\n          \n            2\n          \n        \n        ,\n        \n          S\n          \n            3\n          \n        \n        ,\n        …\n        )\n      \n    \n    {\\displaystyle (S_{1},S_{2},S_{3},\\dots )}\n  \n of its partial sums tends to a limit; that means that, when adding one \n  \n    \n      \n        \n          a\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle a_{k}}\n  \n after the other in the order given by the indices, one gets partial sums that become closer and closer to a given number. More precisely, a series converges, if and only if there exists a number \n  \n    \n      \n        ℓ\n      \n    \n    {\\displaystyle \\ell }\n  \n such that for every arbitrarily small positive number \n  \n    \n      \n        ε\n      \n    \n    {\\displaystyle \\varepsilon }\n  \n, there is a (sufficiently large) integer \n  \n    \n      \n        N\n      \n    \n    {\\displaystyle N}\n  \n such that for all \n  \n    \n      \n        n\n        ≥\n        N\n      \n    \n    {\\displaystyle n\\geq N}\n  \n,\n\n  \n    \n      \n        \n          |\n          \n            \n              S\n              \n                n\n              \n            \n            −\n            ℓ\n          \n          |\n        \n        <\n        ε\n        .\n      \n    \n    {\\displaystyle \\left|S_{n}-\\ell \\right|<\\varepsilon .}\n  \n\nIf the series is convergent, the (necessarily unique) number \n  \n    \n      \n        ℓ\n      \n    \n    {\\displaystyle \\ell }\n  \n is called the sum of the series.\nThe same notation \n\n  \n    \n      \n        \n          ∑\n          \n            k\n            =\n            1\n          \n          \n            ∞\n          \n        \n        \n          a\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle \\sum _{k=1}^{\\infty }a_{k}}\n  \n\nis used for the series, and, if it is convergent, to its sum. This convention is similar to that which is used for addition: a + b denotes the operation of adding a and b as well as the result of this addition, which is called the sum of a and b.\nAny series that is not convergent is said to be divergent or to diverge.\n\nExamples of convergent and divergent series\nThe reciprocals of the positive integers produce a divergent series (harmonic series):\n\n  \n    \n      \n        \n          \n            1\n            1\n          \n        \n        +\n        \n          \n            1\n            2\n          \n        \n        +\n        \n          \n            1\n            3\n          \n        \n        +\n        \n          \n            1\n            4\n          \n        \n        +\n        \n          \n            1\n            5\n          \n        \n        +\n        \n          \n            1\n            6\n          \n        \n        +\n        ⋯\n        →\n        ∞\n        .\n      \n    \n    {\\displaystyle {1 \\over 1}+{1 \\over 2}+{1 \\over 3}+{1 \\over 4}+{1 \\over 5}+{1 \\over 6}+\\cdots \\rightarrow \\infty .}\n  \n\nAlternating the signs of the reciprocals of positive integers produces a convergent series (alternating harmonic series):\n\n  \n    ",
    "links": [
      "1/2 + 1/4 + 1/8 + 1/16 + ⋯",
      "1/2 − 1/4 + 1/8 − 1/16 + ⋯",
      "1/4 + 1/16 + 1/64 + 1/256 + ⋯",
      "1 + 1 + 1 + 1 + ⋯",
      "1 + 2 + 3 + 4 + ⋯",
      "1 + 2 + 4 + 8 + ⋯",
      "1 − 1 + 2 − 6 + 24 − 120 + ⋯",
      "1 − 2 + 3 − 4 + ⋯",
      "1 − 2 + 4 − 8 + ⋯",
      "Abel's test",
      "Absolute convergence",
      "Absolutely convergent",
      "Agnew's theorem",
      "Alternating harmonic series",
      "Alternating series",
      "Alternating series test",
      "Arithmetic progression",
      "Basel problem",
      "Cauchy's convergence test",
      "Cauchy condensation test",
      "Cauchy sequence",
      "Complete sequence",
      "Complex number",
      "Conditional convergence",
      "Conditionally convergent",
      "Convergence (disambiguation)",
      "Convergence tests",
      "Convergent Series (short story collection)",
      "Cube (algebra)",
      "Decreasing",
      "Direct comparison test",
      "Dirichlet's test",
      "Dirichlet series",
      "Divergence of the sum of the reciprocals of the primes",
      "Divergent series",
      "E (mathematical constant)",
      "Encyclopedia of Mathematics",
      "European Mathematical Society",
      "Exponential function",
      "Factorial",
      "Fibonacci number",
      "Fibonacci sequence",
      "Figurate number",
      "Formal power series",
      "Fourier series",
      "Generalized hypergeometric series",
      "Generating series",
      "Geometric progression",
      "Geometric series",
      "Grandi's series"
    ],
    "categories": [
      "Category:All articles lacking in-text citations",
      "Category:Articles lacking in-text citations from July 2025",
      "Category:Articles with short description",
      "Category:Convergence (mathematics)",
      "Category:Series (mathematics)",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Darboux integral": {
    "title": "Darboux integral",
    "url": "https://en.wikipedia.org/wiki/Darboux_integral",
    "summary": "In real analysis, the Darboux integral is constructed using Darboux sums and is one possible definition of the integral of a function. Darboux integrals are equivalent to Riemann integrals, meaning that a function is Darboux-integrable if and only if it is Riemann-integrable, and the values of the two integrals, if they exist, are equal. The definition of the Darboux integral has the advantage of being easier to apply in computations or proofs than that of the Riemann integral. Consequently, introductory textbooks on calculus and real analysis often develop Riemann integration using the Darboux integral, rather than the true Riemann integral.  Moreover, the definition is readily extended to defining Riemann–Stieltjes integration.  Darboux integrals are named after their inventor, Gaston Darboux (1842–1917).",
    "content": "In real analysis, the Darboux integral is constructed using Darboux sums and is one possible definition of the integral of a function. Darboux integrals are equivalent to Riemann integrals, meaning that a function is Darboux-integrable if and only if it is Riemann-integrable, and the values of the two integrals, if they exist, are equal. The definition of the Darboux integral has the advantage of being easier to apply in computations or proofs than that of the Riemann integral. Consequently, introductory textbooks on calculus and real analysis often develop Riemann integration using the Darboux integral, rather than the true Riemann integral.  Moreover, the definition is readily extended to defining Riemann–Stieltjes integration.  Darboux integrals are named after their inventor, Gaston Darboux (1842–1917).\n\nDefinition\nThe definition of the Darboux integral considers upper and lower (Darboux) integrals, which exist for any bounded real-valued function \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n on the interval \n  \n    \n      \n        [\n        a\n        ,\n        b\n        ]\n        .\n      \n    \n    {\\displaystyle [a,b].}\n  \n The Darboux integral exists if and only if the upper and lower integrals are equal.  The upper and lower integrals are in turn the infimum and supremum, respectively, of upper and lower (Darboux) sums which over- and underestimate, respectively, the \"area under the curve.\" In particular, for a given partition of the interval of integration, the upper and lower sums add together the areas of rectangular slices whose heights are the supremum and infimum, respectively, of f in each subinterval of the partition.  These ideas are made precise below:\n\nDarboux sums\nA partition of an interval \n  \n    \n      \n        [\n        a\n        ,\n        b\n        ]\n      \n    \n    {\\displaystyle [a,b]}\n  \n is a finite sequence of values \n  \n    \n      \n        \n          x\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle x_{i}}\n  \n such that\n\n  \n    \n      \n        a\n        =\n        \n          x\n          \n            0\n          \n        \n        <\n        \n          x\n          \n            1\n          \n        \n        <\n        ⋯\n        <\n        \n          x\n          \n            n\n          \n        \n        =\n        b\n        .\n      \n    \n    {\\displaystyle a=x_{0}<x_{1}<\\cdots <x_{n}=b.}\n  \n\nEach interval \n  \n    \n      \n        [\n        \n          x\n          \n            i\n            −\n            1\n          \n        \n        ,\n        \n          x\n          \n            i\n          \n        \n        ]\n      \n    \n    {\\displaystyle [x_{i-1},x_{i}]}\n  \n is called a subinterval of the partition. Let \n  \n    \n      \n        f\n        :\n        [\n        a\n        ,\n        b\n        ]\n        →\n        \n          R\n        \n      \n    \n    {\\displaystyle f:[a,b]\\to \\mathbb {R} }\n  \n be a bounded function, and let\n\n  \n    \n      \n        P\n        =\n        (\n        \n          x\n          \n            0\n          \n        \n        ,\n        …\n        ,\n        \n          x\n          \n            n\n          \n        \n        )\n      \n    \n    {\\displaystyle P=(x_{0},\\ldots ,x_{n})}\n  \n\nbe a partition of \n  \n    \n      \n        [\n        a\n        ,\n        b\n        ]\n      \n    \n    {\\displaystyle [a,b]}\n  \n. Let\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  M\n                  \n                    i\n                  \n                \n                =\n                \n                  sup\n                  \n                    x\n                    ∈\n                    [\n                    \n                      x\n                      \n                        i\n                        −\n                        1\n                      \n                    \n                    ,\n                    \n                      x\n                      \n                        i\n                      \n                    \n                    ]\n                  \n                \n                f\n                (\n                x\n                )\n                ,\n              \n            \n            \n              \n                \n                  m\n                  \n                    i\n                  \n                \n                =\n                \n                  inf\n                  \n                    x\n                    ∈\n                    [\n                    \n                      x\n                      \n                        i\n                        −\n                        1\n                      \n                    \n                    ,\n                    \n                      x\n                      \n                        i\n                      \n                    \n                    ]\n                  \n                \n                f\n                (\n                x\n                )\n                .\n              \n            ",
    "links": [
      "Basel problem",
      "Bochner integral",
      "Bose–Einstein integral",
      "Bounded function",
      "Burkill integral",
      "Calculus",
      "Common integrals in quantum field theory",
      "Complete Fermi–Dirac integral",
      "Contour integration",
      "Daniell integral",
      "Dense subset",
      "Dirichlet function",
      "Dirichlet integral",
      "Disc integration",
      "Encyclopedia of Mathematics",
      "Euler substitution",
      "Euler–Maclaurin formula",
      "European Mathematical Society",
      "Frullani integral",
      "Function (mathematics)",
      "Gabriel's horn",
      "Gaston Darboux",
      "Gaussian integral",
      "Haar measure",
      "Hellinger integral",
      "Henstock–Kurzweil integral",
      "ISBN (identifier)",
      "Improper integral",
      "Incomplete Fermi–Dirac integral",
      "Infimum and supremum",
      "Integer",
      "Integral",
      "Integral of inverse functions",
      "Integration Bee",
      "Integration by partial fractions",
      "Integration by parts",
      "Integration by reduction formulae",
      "Integration by substitution",
      "Integration using Euler's formula",
      "Integration using parametric derivatives",
      "Interval (mathematics)",
      "Itô calculus",
      "Khinchin integral",
      "Kolmogorov integral",
      "Laplace's method",
      "Laplace transform",
      "Lebesgue integration",
      "Lebesgue–Stieltjes integration",
      "Leibniz integral rule",
      "Lipschitz continuous"
    ],
    "categories": [
      "Category:All articles needing additional references",
      "Category:All articles with dead YouTube links",
      "Category:Articles needing additional references from February 2013",
      "Category:Articles with dead YouTube links from February 2022",
      "Category:Articles with short description",
      "Category:Definitions of mathematical integration",
      "Category:Short description matches Wikidata"
    ]
  },
  "Derivative": {
    "title": "Derivative",
    "url": "https://en.wikipedia.org/wiki/Derivative",
    "summary": "In mathematics, the derivative is a fundamental tool that quantifies the sensitivity to change of a function's output with respect to its input. The derivative of a function of a single variable at a chosen input value, when it exists, is the slope of the tangent line to the graph of the function at that point. The tangent line is the best linear approximation of the function near that input value. For this reason, the derivative is often described as the instantaneous rate of change, the ratio of the instantaneous change in the dependent variable to that of the independent variable. The process of finding a derivative is called differentiation.\nThere are multiple different notations for differentiation. Leibniz notation, named after Gottfried Wilhelm Leibniz, is represented as the ratio of two differentials, whereas prime notation is written by adding a prime mark. Higher order notations represent repeated differentiation, and they are usually denoted in Leibniz notation by adding sup",
    "content": "In mathematics, the derivative is a fundamental tool that quantifies the sensitivity to change of a function's output with respect to its input. The derivative of a function of a single variable at a chosen input value, when it exists, is the slope of the tangent line to the graph of the function at that point. The tangent line is the best linear approximation of the function near that input value. For this reason, the derivative is often described as the instantaneous rate of change, the ratio of the instantaneous change in the dependent variable to that of the independent variable. The process of finding a derivative is called differentiation.\nThere are multiple different notations for differentiation. Leibniz notation, named after Gottfried Wilhelm Leibniz, is represented as the ratio of two differentials, whereas prime notation is written by adding a prime mark. Higher order notations represent repeated differentiation, and they are usually denoted in Leibniz notation by adding superscripts to the differentials, and in prime notation by adding additional prime marks. The higher order derivatives can be applied in physics; for example, while the first derivative of the position of a moving object with respect to time is the object's velocity, how the position changes as time advances, the second derivative is the object's acceleration, how the velocity changes as time advances.\nDerivatives can be generalized to functions of several real variables. In this case, the derivative is reinterpreted as a linear transformation whose graph is (after an appropriate translation) the best linear approximation to the graph of the original function. The Jacobian matrix is the matrix that represents this linear transformation with respect to the basis given by the choice of independent and dependent variables.  It can be calculated in terms of the partial derivatives with respect to the independent variables.  For a real-valued function of several variables, the Jacobian matrix reduces to the gradient vector.\n\nDefinition\nAs a limit\nA function of a real variable \n  \n    \n      \n        f\n        (\n        x\n        )\n      \n    \n    {\\displaystyle f(x)}\n  \n is differentiable at a point \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n of its domain, if its domain contains an open interval containing ⁠\n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n⁠, and the limit\n\n  \n    \n      \n        L\n        =\n        \n          lim\n          \n            h\n            →\n            0\n          \n        \n        \n          \n            \n              f\n              (\n              a\n              +\n              h\n              )\n              −\n              f\n              (\n              a\n              )\n            \n            h\n          \n        \n      \n    \n    {\\displaystyle L=\\lim _{h\\to 0}{\\frac {f(a+h)-f(a)}{h}}}\n  \n\nexists.  This means that, for every positive real number ⁠\n  \n    \n      \n        ε\n      \n    \n    {\\displaystyle \\varepsilon }\n  \n⁠, there exists a positive real number \n  \n    \n      \n        δ\n      \n    \n    {\\displaystyle \\delta }\n  \n such that, for every \n  \n    \n      \n        h\n      \n    \n    {\\displaystyle h}\n  \n such that \n  \n    \n      \n        \n          |\n        \n        h\n        \n          |\n        \n        <\n        δ\n      \n    \n    {\\displaystyle |h|<\\delta }\n  \n and \n  \n    \n      \n        h\n        ≠\n        0\n      \n    \n    {\\displaystyle h\\neq 0}\n  \n then \n  \n    \n      \n        f\n        (\n        a\n        +\n        h\n        )\n      \n    \n    {\\displaystyle f(a+h)}\n  \n is defined, and \n\n  \n    \n      \n        \n          |\n          \n            L\n            −\n            \n              \n                \n                  f\n                  (\n                  a\n                  +\n                  h\n                  )\n                  −\n                  f\n                  (\n                  a\n                  )\n                \n                h\n              \n            \n          \n          |\n        \n        <\n        ε\n        ,\n      \n    \n    {\\displaystyle \\left|L-{\\frac {f(a+h)-f(a)}{h}}\\right|<\\varepsilon ,}\n  \n\nwhere the vertical bars denote the absolute value. This is an example of the (ε, δ)-definition of limit.\nIf the function \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n is differentiable at ⁠\n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n⁠, that is if the limit \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  \n exists, then this limit is called the derivative of \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n at \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n. Multiple notations for the derivative exist. The derivative of \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n at \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n can be denoted ⁠\n  \n    \n      \n        \n          f\n          ′\n        \n        (\n        a\n ",
    "links": [
      "(ε, δ)-definition of limit",
      "Abel's test",
      "Absolute value",
      "Acceleration",
      "Adequality",
      "Almost everywhere",
      "Alternating series",
      "Alternating series test",
      "Antiderivative",
      "ArXiv (identifier)",
      "Arc length",
      "Arithmetic derivative",
      "Arithmetico-geometric sequence",
      "Arithmetico–geometric sequence",
      "Banach space",
      "Bernoulli number",
      "Bibcode (identifier)",
      "Binomial series",
      "Binomial theorem",
      "Brook Taylor",
      "CRC Press",
      "Calculus",
      "Calculus Made Easy",
      "Calculus of variations",
      "Calculus on Euclidean space",
      "Canadian Mathematical Bulletin",
      "Cauchy condensation test",
      "Cauchy–Riemann equations",
      "Chain rule",
      "Colin Maclaurin",
      "Complex analysis",
      "Complex function",
      "Complex number",
      "Concave function",
      "Constant function",
      "Constant of integration",
      "Continuous function",
      "Contour integral",
      "Contour integration",
      "Convergence tests",
      "Covariant derivative",
      "Curl (mathematics)",
      "Curvature",
      "Dependent and independent variables",
      "Derivation (differential algebra)",
      "Derivative (disambiguation)",
      "Differentiability class",
      "Differentiable",
      "Differentiable function",
      "Differential (infinitesimal)"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1 Czech-language sources (cs)",
      "Category:Change",
      "Category:Differential calculus",
      "Category:Functions and mappings",
      "Category:Good articles",
      "Category:Linear operators in calculus",
      "Category:Mathematical analysis",
      "Category:Pages using multiple image with auto scaled images",
      "Category:Pages using sidebar with the child parameter"
    ]
  },
  "Differentiable function": {
    "title": "Differentiable function",
    "url": "https://en.wikipedia.org/wiki/Differentiable_function",
    "summary": "In mathematics, a differentiable function of one real variable is a function whose derivative exists at each point in its domain. In other words, the graph of a differentiable function has a non-vertical tangent line at each interior point in its domain. A differentiable function is smooth (the function is locally well approximated as a linear function at each interior point) and does not contain any break, angle, or cusp.\nIf x0 is an interior point in the domain of a function f, then f is said to be differentiable at x0 if the derivative \n  \n    \n      \n        \n          f\n          ′\n        \n        (\n        \n          x\n          \n            0\n          \n        \n        )\n      \n    \n    {\\displaystyle f'(x_{0})}\n  \n exists. In other words, the graph of f has a non-vertical tangent line at the point (x0, f(x0)). f is said to be differentiable on U if it is differentiable at every point of U. f is said to be continuously differentiable if its derivative is also a continuous func",
    "content": "In mathematics, a differentiable function of one real variable is a function whose derivative exists at each point in its domain. In other words, the graph of a differentiable function has a non-vertical tangent line at each interior point in its domain. A differentiable function is smooth (the function is locally well approximated as a linear function at each interior point) and does not contain any break, angle, or cusp.\nIf x0 is an interior point in the domain of a function f, then f is said to be differentiable at x0 if the derivative \n  \n    \n      \n        \n          f\n          ′\n        \n        (\n        \n          x\n          \n            0\n          \n        \n        )\n      \n    \n    {\\displaystyle f'(x_{0})}\n  \n exists. In other words, the graph of f has a non-vertical tangent line at the point (x0, f(x0)). f is said to be differentiable on U if it is differentiable at every point of U. f is said to be continuously differentiable if its derivative is also a continuous function over the domain of the function \n  \n    \n      \n        f\n      \n    \n    {\\textstyle f}\n  \n. Generally speaking, f is said to be of class \n  \n    \n      \n        \n          C\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle C^{k}}\n  \n if its first \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n derivatives \n  \n    \n      \n        \n          f\n          \n            ′\n          \n        \n        (\n        x\n        )\n        ,\n        \n          f\n          \n            ′\n            ′\n          \n        \n        (\n        x\n        )\n        ,\n        …\n        ,\n        \n          f\n          \n            (\n            k\n            )\n          \n        \n        (\n        x\n        )\n      \n    \n    {\\textstyle f^{\\prime }(x),f^{\\prime \\prime }(x),\\ldots ,f^{(k)}(x)}\n  \n exist and are continuous over the domain of the function \n  \n    \n      \n        f\n      \n    \n    {\\textstyle f}\n  \n.\nFor a multivariable function, as shown here, the differentiability of it is something more complex than the existence of the partial derivatives of it.\n\nDifferentiability of real functions of one variable\nA function \n  \n    \n      \n        f\n        :\n        U\n        →\n        \n          R\n        \n      \n    \n    {\\displaystyle f:U\\to \\mathbb {R} }\n  \n, defined on an open set \n  \n    \n      \n        U\n        ⊂\n        \n          R\n        \n      \n    \n    {\\textstyle U\\subset \\mathbb {R} }\n  \n, is said to be differentiable at \n  \n    \n      \n        a\n        ∈\n        U\n      \n    \n    {\\displaystyle a\\in U}\n  \n if the derivative\n\n  \n    \n      \n        \n          f\n          ′\n        \n        (\n        a\n        )\n        =\n        \n          lim\n          \n            h\n            →\n            0\n          \n        \n        \n          \n            \n              f\n              (\n              a\n              +\n              h\n              )\n              −\n              f\n              (\n              a\n              )\n            \n            h\n          \n        \n        =\n        \n          lim\n          \n            x\n            →\n            a\n          \n        \n        \n          \n            \n              f\n              (\n              x\n              )\n              −\n              f\n              (\n              a\n              )\n            \n            \n              x\n              −\n              a\n            \n          \n        \n      \n    \n    {\\displaystyle f'(a)=\\lim _{h\\to 0}{\\frac {f(a+h)-f(a)}{h}}=\\lim _{x\\to a}{\\frac {f(x)-f(a)}{x-a}}}\n  \n\nexists. This implies that the function is continuous at a.\nThis function f is said to be differentiable on U if it is differentiable at every point of U. In this case, the derivative of f is thus a function from U into \n  \n    \n      \n        \n          R\n        \n        .\n      \n    \n    {\\displaystyle \\mathbb {R} .}\n  \n \nA continuous function is not necessarily differentiable, but a differentiable function is necessarily continuous (at every point where it is differentiable) as is shown below (in the section Differentiability and continuity). A function is said to be continuously differentiable if its derivative is also a continuous function; there exist functions that are differentiable but not continuously differentiable (an example is given in the section Differentiability classes).\n\nSemi-differentiability\nThe above definition can be extended to define the derivative at boundary points. The derivative of a function \n  \n    \n      \n        f\n        :\n        A\n        →\n        \n          R\n        \n      \n    \n    {\\textstyle f:A\\to \\mathbb {R} }\n  \n defined on a closed subset \n  \n    \n      \n        A\n        ⊊\n        \n          R\n        \n      \n    \n    {\\textstyle A\\subsetneq \\mathbb {R} }\n  \n of the real numbers, evaluated at a boundary point \n  \n    \n      \n        c\n      \n    \n    {\\textstyle c}\n  \n, can be defined as the following one-sided limit, where the argument \n  \n    \n      \n        x\n      \n    \n  ",
    "links": [
      "Absolute value",
      "Almost everywhere",
      "Analytic function",
      "Automatic differentiation",
      "Boundary (topology)",
      "Classification of discontinuities",
      "Complex analysis",
      "Complex number",
      "Computational learning theory",
      "Continuous function",
      "Cusp (singularity)",
      "Darboux's theorem (analysis)",
      "Derivative",
      "Differentiable manifold",
      "Differentiable programming",
      "Differentiation rules",
      "Directional derivative",
      "Doi (identifier)",
      "Domain of a function",
      "Flux (machine-learning framework)",
      "Function (mathematics)",
      "Function of several real variables",
      "Fundamental increment lemma",
      "Generalizations of the derivative",
      "Graph of a function",
      "Graphcore",
      "Holomorphic function",
      "Inductive bias",
      "Information geometry",
      "Intermediate value theorem",
      "JAX (software)",
      "Jacobian matrix",
      "Jump discontinuity",
      "Keras",
      "Linear function",
      "Linear map",
      "Mathematics",
      "Meagre set",
      "Memristor",
      "MindSpore",
      "Multivariable calculus",
      "Neighbourhood (mathematics)",
      "Neuromorphic computing",
      "Partial derivative",
      "Pattern recognition",
      "PyTorch",
      "Real-valued function",
      "Real number",
      "Ricci calculus",
      "Scikit-learn"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Multivariable calculus",
      "Category:Short description is different from Wikidata",
      "Category:Smooth functions"
    ]
  },
  "Differential calculus": {
    "title": "Differential calculus",
    "url": "https://en.wikipedia.org/wiki/Differential_calculus",
    "summary": "In mathematics, differential calculus is a subfield of calculus that studies the rates at which quantities change. It is one of the two traditional divisions of calculus, the other being integral calculus—the study of the area beneath a curve.\nThe primary objects of study in differential calculus are the derivative of a function, related notions such as the differential, and their applications. The derivative of a function at a chosen input value describes the rate of change of the function near that input value. The process of finding a derivative is called differentiation. Geometrically, the derivative at a point is the slope of the tangent line to the graph of the function at that point, provided that the derivative exists and is defined at that point. For a real-valued function of a single real variable, the derivative of a function at a point generally determines the best linear approximation to the function at that point.\nDifferential calculus and integral calculus are connected ",
    "content": "In mathematics, differential calculus is a subfield of calculus that studies the rates at which quantities change. It is one of the two traditional divisions of calculus, the other being integral calculus—the study of the area beneath a curve.\nThe primary objects of study in differential calculus are the derivative of a function, related notions such as the differential, and their applications. The derivative of a function at a chosen input value describes the rate of change of the function near that input value. The process of finding a derivative is called differentiation. Geometrically, the derivative at a point is the slope of the tangent line to the graph of the function at that point, provided that the derivative exists and is defined at that point. For a real-valued function of a single real variable, the derivative of a function at a point generally determines the best linear approximation to the function at that point.\nDifferential calculus and integral calculus are connected by the fundamental theorem of calculus. This states that differentiation is the reverse process to integration.\nDifferentiation has applications in nearly all quantitative disciplines. In physics, the derivative of the displacement of a moving body with respect to time is the velocity of the body, and the derivative of the velocity with respect to time is acceleration. The derivative of the momentum of a body with respect to time equals the force applied to the body; rearranging this derivative statement leads to the famous F = ma equation associated with Newton's second law of motion. The reaction rate of a chemical reaction is a derivative. In operations research, derivatives determine the most efficient ways to transport materials and design factories.\nDerivatives are frequently used to find the maxima and minima of a function. Equations involving derivatives are called differential equations and are fundamental in describing natural phenomena. Derivatives and their generalizations appear in many fields of mathematics, such as complex analysis, functional analysis, differential geometry, measure theory, and abstract algebra.\n\nDerivative\nThe derivative of \n  \n    \n      \n        f\n        (\n        x\n        )\n      \n    \n    {\\displaystyle f(x)}\n  \n at the point \n  \n    \n      \n        x\n        =\n        a\n      \n    \n    {\\displaystyle x=a}\n  \n is the slope of the tangent to \n  \n    \n      \n        (\n        a\n        ,\n        f\n        (\n        a\n        )\n        )\n      \n    \n    {\\displaystyle (a,f(a))}\n  \n. In order to gain an intuition for this, one must first be familiar with finding the slope of a linear equation, written in the form \n  \n    \n      \n        y\n        =\n        m\n        x\n        +\n        b\n      \n    \n    {\\displaystyle y=mx+b}\n  \n. The slope of an equation is its steepness. It can be found by picking any two points and dividing the change in \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n by the change in \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n, meaning that \n  \n    \n      \n        \n          slope \n        \n        =\n        \n          \n            \n              \n                 change in \n              \n              y\n            \n            \n              \n                change in \n              \n              x\n            \n          \n        \n      \n    \n    {\\displaystyle {\\text{slope }}={\\frac {{\\text{ change in }}y}{{\\text{change in }}x}}}\n  \n. For, the graph of \n  \n    \n      \n        y\n        =\n        −\n        2\n        x\n        +\n        13\n      \n    \n    {\\displaystyle y=-2x+13}\n  \n has a slope of \n  \n    \n      \n        −\n        2\n      \n    \n    {\\displaystyle -2}\n  \n, as shown in the diagram below:\n\n  \n    \n      \n        \n          \n            \n              \n                change in \n              \n              y\n            \n            \n              \n                change in \n              \n              x\n            \n          \n        \n        =\n        \n          \n            \n              −\n              6\n            \n            \n              +\n              3\n            \n          \n        \n        =\n        −\n        2\n      \n    \n    {\\displaystyle {\\frac {{\\text{change in }}y}{{\\text{change in }}x}}={\\frac {-6}{+3}}=-2}\n  \n\nFor brevity, \n  \n    \n      \n        \n          \n            \n              \n                change in \n              \n              y\n            \n            \n              \n                change in \n              \n              x\n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {{\\text{change in }}y}{{\\text{change in }}x}}}\n  \n is often written as \n  \n    \n      \n        \n          \n            \n              Δ\n              y\n            \n            \n              Δ\n              x\n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {\\Delta y}{\\Delta x}}}\n  \n, with \n  \n    \n      \n        Δ\n      \n    \n    {\\displaystyle \\Delta }\n  \n being",
    "links": [
      "Abel's test",
      "Absolute continuity",
      "Abstract algebra",
      "Acceleration",
      "Alternating series",
      "Alternating series test",
      "Analytic function",
      "Ancient Greece",
      "Antiderivative",
      "Apollonius of Perga",
      "Archimedes",
      "Archimedes Palimpsest",
      "Arithmetico–geometric sequence",
      "Augustin Louis Cauchy",
      "Bernhard Riemann",
      "Bhāskara II",
      "Binomial series",
      "Blaise Pascal",
      "Calculus",
      "Calculus of variations",
      "Calculus on Euclidean space",
      "Cauchy condensation test",
      "Cavalieri's principle",
      "Chain rule",
      "Chemical reaction",
      "Christiaan Huygens",
      "Circle",
      "Closed interval",
      "Complex analysis",
      "Complex plane",
      "Constant (mathematics)",
      "Continuous function",
      "Continuously differentiable",
      "Contour integration",
      "Convergence tests",
      "Critical point (mathematics)",
      "Curl (mathematics)",
      "Derivative",
      "Differentiability",
      "Differentiable function",
      "Differential (infinitesimal)",
      "Differential (mathematics)",
      "Differential equation",
      "Differential equations",
      "Differential geometry",
      "Differential of a function",
      "Differentiation rules",
      "Dirac delta function",
      "Direct comparison test",
      "Directional derivative"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Calculus",
      "Category:Differential calculus",
      "Category:Pages using Sister project links with default search",
      "Category:Pages using sidebar with the child parameter",
      "Category:Short description is different from Wikidata",
      "Category:Webarchive template wayback links"
    ]
  },
  "Differential equation": {
    "title": "Differential equation",
    "url": "https://en.wikipedia.org/wiki/Differential_equation",
    "summary": "In mathematics, a differential equation is an equation that relates one or more unknown functions and their derivatives. In applications, the functions generally represent physical quantities, the derivatives represent their rates of change, and the differential equation defines a relationship between the two. Such relations are common in mathematical models and scientific laws; therefore, differential equations play a prominent role in many disciplines including engineering, physics, economics, and biology.\nThe study of differential equations consists mainly of the study of their solutions (the set of functions that satisfy each equation), and of the properties of their solutions. Only the simplest differential equations are solvable by explicit formulas; however, many properties of solutions of a given differential equation may be determined without computing them exactly.\nOften when a closed-form expression for the solutions is not available, solutions may be approximated numericall",
    "content": "In mathematics, a differential equation is an equation that relates one or more unknown functions and their derivatives. In applications, the functions generally represent physical quantities, the derivatives represent their rates of change, and the differential equation defines a relationship between the two. Such relations are common in mathematical models and scientific laws; therefore, differential equations play a prominent role in many disciplines including engineering, physics, economics, and biology.\nThe study of differential equations consists mainly of the study of their solutions (the set of functions that satisfy each equation), and of the properties of their solutions. Only the simplest differential equations are solvable by explicit formulas; however, many properties of solutions of a given differential equation may be determined without computing them exactly.\nOften when a closed-form expression for the solutions is not available, solutions may be approximated numerically using computers, and many numerical methods have been developed to determine solutions with a given degree of accuracy. The theory of dynamical systems analyzes the qualitative aspects of solutions, such as their average behavior over a long time interval.\n\nHistory\nDifferential equations came into existence with the invention of calculus by Isaac Newton and Gottfried Leibniz. In Chapter 2 of his 1671 work Methodus fluxionum et Serierum Infinitarum, Newton listed three kinds of differential equations:\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      d\n                      y\n                    \n                    \n                      d\n                      x\n                    \n                  \n                \n              \n              \n                \n                =\n                f\n                (\n                x\n                )\n              \n            \n            \n              \n                \n                  \n                    \n                      d\n                      y\n                    \n                    \n                      d\n                      x\n                    \n                  \n                \n              \n              \n                \n                =\n                f\n                (\n                x\n                ,\n                y\n                )\n              \n            \n            \n              \n                \n                  x\n                  \n                    1\n                  \n                \n                \n                  \n                    \n                      ∂\n                      y\n                    \n                    \n                      ∂\n                      \n                        x\n                        \n                          1\n                        \n                      \n                    \n                  \n                \n              \n              \n                \n                +\n                \n                  x\n                  \n                    2\n                  \n                \n                \n                  \n                    \n                      ∂\n                      y\n                    \n                    \n                      ∂\n                      \n                        x\n                        \n                          2\n                        \n                      \n                    \n                  \n                \n                =\n                y\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}{\\frac {dy}{dx}}&=f(x)\\\\[4pt]{\\frac {dy}{dx}}&=f(x,y)\\\\[4pt]x_{1}{\\frac {\\partial y}{\\partial x_{1}}}&+x_{2}{\\frac {\\partial y}{\\partial x_{2}}}=y\\end{aligned}}}\n  \n\nIn all these cases, y is an unknown function of x (or of x1 and x2), and f is a given function.\nHe solves these examples and others using infinite series and discusses the non-uniqueness of solutions.\nJacob Bernoulli proposed the Bernoulli differential equation in 1695. This is an ordinary differential equation of the form\n\n  \n    \n      \n        \n          y\n          ′\n        \n        +\n        P\n        (\n        x\n        )\n        y\n        =\n        Q\n        (\n        x\n        )\n        \n          y\n          \n            n\n          \n        \n        \n      \n    \n    {\\displaystyle y'+P(x)y=Q(x)y^{n}\\,}\n  \n\nfor which the following year Leibniz obtained solutions by simplifying it.\nHistorically, the problem of a vibrating string such as that of a musical instrument was studied by Jean le Rond d'Alembert, Leonhard Euler, Daniel Bernoulli, and Joseph-Louis Lagrange. In 1746, d’Alembert discovered the one-dimensional wave equation, and within ten years Euler discovered the three-dimensional wave equation.\nThe Euler–Lagrange equation was developed in the 1750s by Euler and Lagrange in connection with their studies of the tautochrone ",
    "links": [
      "Abstract algebra",
      "Abstract differential equation",
      "Acta Eruditorum",
      "Algebra",
      "Algebraic equations",
      "Algebraic geometry",
      "Algebraic number theory",
      "Algebraic topology",
      "American Journal of Physics",
      "American Mathematical Society",
      "Analytic geometry",
      "Analytic number theory",
      "Antiderivative",
      "Applied mathematics",
      "Arithmetic",
      "Arithmetic geometry",
      "Astronomy",
      "Asymptotic stability",
      "Augustin-Louis Cauchy",
      "Autonomous differential equation",
      "Autonomous system (mathematics)",
      "Bernoulli differential equation",
      "Bibcode (identifier)",
      "Bill Schelter",
      "Biology",
      "Black–Scholes",
      "Boundary value problem",
      "Calculus",
      "Calculus of variations",
      "Carathéodory's existence theorem",
      "Carl David Tolmé Runge",
      "Category theory",
      "Cauchy problem",
      "Cauchy–Kowalevski theorem",
      "Chaos theory",
      "Chemistry",
      "Classical mechanics",
      "Closed-form expression",
      "Combinatorics",
      "Commutative algebra",
      "Complex analysis",
      "Complex system",
      "Computational complexity theory",
      "Computational mathematics",
      "Computer algebra",
      "Computer algebra system",
      "Computer model",
      "Computer science",
      "Continuous function",
      "Continuum mechanics"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1 French-language sources (fr)",
      "Category:Commons category link is on Wikidata",
      "Category:Differential equations",
      "Category:Short description is different from Wikidata",
      "Category:Webarchive template wayback links"
    ]
  },
  "Differential geometry": {
    "title": "Differential geometry",
    "url": "https://en.wikipedia.org/wiki/Differential_geometry",
    "summary": "Differential geometry is a mathematical discipline that studies the geometry of smooth shapes and smooth spaces, otherwise known as smooth manifolds. It uses the techniques of single variable calculus, vector calculus, linear algebra and multilinear algebra. The field has its origins in the study of spherical geometry as far back as antiquity. It also relates to astronomy, the geodesy of the Earth, and later  the study of hyperbolic geometry by Lobachevsky. The simplest examples of smooth spaces are the plane and space curves and surfaces in the three-dimensional Euclidean space, and the study of these shapes formed the basis for development of modern differential geometry during the 18th and 19th centuries.\nSince the late 19th century, differential geometry has grown into a field concerned more generally with geometric structures on differentiable manifolds. A geometric structure is one which defines some notion of size, distance, shape, volume, or other rigidifying structure. For exa",
    "content": "Differential geometry is a mathematical discipline that studies the geometry of smooth shapes and smooth spaces, otherwise known as smooth manifolds. It uses the techniques of single variable calculus, vector calculus, linear algebra and multilinear algebra. The field has its origins in the study of spherical geometry as far back as antiquity. It also relates to astronomy, the geodesy of the Earth, and later  the study of hyperbolic geometry by Lobachevsky. The simplest examples of smooth spaces are the plane and space curves and surfaces in the three-dimensional Euclidean space, and the study of these shapes formed the basis for development of modern differential geometry during the 18th and 19th centuries.\nSince the late 19th century, differential geometry has grown into a field concerned more generally with geometric structures on differentiable manifolds. A geometric structure is one which defines some notion of size, distance, shape, volume, or other rigidifying structure. For example, in Riemannian geometry distances and angles are specified, in symplectic geometry volumes may be computed, in conformal geometry only angles are specified, and in gauge theory certain fields are given over the space. Differential geometry is closely related to, and is sometimes taken to include, differential topology, which concerns itself with properties of differentiable manifolds that do not rely on any additional geometric structure (see that article for more discussion on the distinction between the two subjects). Differential geometry is also related to the geometric aspects of the theory of differential equations, otherwise known as geometric analysis.\nDifferential geometry finds applications throughout mathematics and the natural sciences. Most prominently the language of differential geometry was used by Albert Einstein in his theory of general relativity, and subsequently by physicists in the development of quantum field theory and the standard model of particle physics. Outside of physics, differential geometry finds applications in chemistry, economics, engineering, control theory, computer graphics and computer vision, and recently in machine learning.\n\nHistory and development\nThe history and development of differential geometry as a subject begins at least as far back as classical antiquity. It is intimately linked to the development of geometry more generally, of the notion of space and shape, and of topology, especially the study of manifolds. In this section we focus primarily on the history of the application of infinitesimal methods to geometry, and later to the ideas of tangent spaces, and eventually the development of the modern formalism of the subject in terms of tensors and tensor fields.\n\nClassical antiquity until the Renaissance (300 BC – 1600 AD)\nThe study of differential geometry, or at least the study of the geometry of smooth shapes, can be traced back at least to classical antiquity. In particular, much was known about the geometry of the Earth, a spherical geometry, in the time of the ancient Greek mathematicians. Famously, Eratosthenes calculated the circumference of the Earth around 200 BC, and around 150 AD Ptolemy in his Geography introduced the stereographic projection for the purposes of mapping the shape of the Earth. Implicitly throughout this time principles that form the foundation of differential geometry and calculus were used in geodesy, although in a much simplified form. Namely, as far back as Euclid's Elements it was understood that a straight line could be defined by its property of providing the shortest distance between two points, and applying this same principle to the surface of the Earth leads to the conclusion that great circles, which are only locally similar to straight lines in a flat plane, provide the shortest path between two points on the Earth's surface. Indeed, the measurements of distance along such geodesic paths by Eratosthenes and others can be considered a rudimentary measure of arclength of curves, a concept which did not see a rigorous definition in terms of calculus until the 1600s.\nAround this time there were only minimal overt applications of the theory of infinitesimals to the study of geometry, a precursor to the modern calculus-based study of the subject. In Euclid's Elements the notion of tangency of a line to a circle is discussed, and Archimedes applied the method of exhaustion to compute the areas of smooth shapes such as the circle, and the volumes of smooth three-dimensional solids such as the sphere, cones, and cylinders.\nThere was little development in the theory of differential geometry between antiquity and the beginning of the Renaissance. Before the development of calculus by Newton and Leibniz, the most significant development in the understanding of differential geometry came from Gerardus Mercator's development of the Mercator projection as a way of mapping the Earth. Mercator had an understanding of the advantages and pitfalls o",
    "links": [
      "Absolute differential calculus",
      "Abstract algebra",
      "Abstract index notation",
      "Adjoint bundle",
      "Affine bundle",
      "Affine connection",
      "Affine differential geometry",
      "Affine geometry",
      "Ahmes",
      "Albert Einstein",
      "Alexis Clairaut",
      "Algebra",
      "Algebraic geometry",
      "Algebraic number theory",
      "Algebraic topology",
      "Alhazen",
      "Almost-contact manifold",
      "Almost complex manifold",
      "Almost complex structure",
      "Almost flat manifold",
      "Almost symplectic manifold",
      "Altitude (triangle)",
      "Ambient space",
      "Analyse des Infiniment Petits pour l'Intelligence des Lignes Courbes",
      "Analysis Situs (paper)",
      "Analysis on fractals",
      "Analytic geometry",
      "Analytic number theory",
      "Analytical mechanics",
      "Ancient Greek",
      "Angle",
      "Angular momentum",
      "Annulus (mathematics)",
      "Antisymmetric tensor",
      "Apollonius of Perga",
      "Applied mathematics",
      "ArXiv (identifier)",
      "Arc length",
      "Archimedes",
      "Arclength",
      "Area",
      "Area of a circle",
      "Arithmetic",
      "Arithmetic geometry",
      "Aryabhata",
      "Associated bundle",
      "Astronomy",
      "Atiyah–Singer index theorem",
      "Atlas (topology)",
      "Augustin-Louis Cauchy"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1 French-language sources (fr)",
      "Category:Differential geometry",
      "Category:Geometry processing",
      "Category:Pages using Sister project links with hidden wikidata",
      "Category:Pages using sidebar with the child parameter",
      "Category:Short description matches Wikidata",
      "Category:Webarchive template wayback links"
    ]
  },
  "Completeness (order theory)": {
    "title": "Completeness (order theory)",
    "url": "https://en.wikipedia.org/wiki/Completeness_(order_theory)",
    "summary": "In the mathematical area of order theory, completeness properties assert the existence of certain infima or suprema of a given partially ordered set (poset). The most familiar example is the completeness of the real numbers. A special use of the term refers to complete partial orders or complete lattices. However, many other interesting notions of completeness exist.\nThe motivation for considering completeness properties derives from the great importance of suprema (least upper bounds, joins, \"\n  \n    \n      \n        ∨\n      \n    \n    {\\displaystyle \\vee }\n  \n\") and infima (greatest lower bounds, meets, \"\n  \n    \n      \n        ∧\n      \n    \n    {\\displaystyle \\wedge }\n  \n\") to the theory of partial orders. Finding a supremum means to single out one distinguished least element from the set of upper bounds. On the one hand, these special elements often embody certain concrete properties that are interesting for the given application (such as being the least common multiple of a set of n",
    "content": "In the mathematical area of order theory, completeness properties assert the existence of certain infima or suprema of a given partially ordered set (poset). The most familiar example is the completeness of the real numbers. A special use of the term refers to complete partial orders or complete lattices. However, many other interesting notions of completeness exist.\nThe motivation for considering completeness properties derives from the great importance of suprema (least upper bounds, joins, \"\n  \n    \n      \n        ∨\n      \n    \n    {\\displaystyle \\vee }\n  \n\") and infima (greatest lower bounds, meets, \"\n  \n    \n      \n        ∧\n      \n    \n    {\\displaystyle \\wedge }\n  \n\") to the theory of partial orders. Finding a supremum means to single out one distinguished least element from the set of upper bounds. On the one hand, these special elements often embody certain concrete properties that are interesting for the given application (such as being the least common multiple of a set of numbers or the union of a collection of sets). On the other hand, the knowledge that certain types of subsets are guaranteed to have suprema or infima enables us to consider the evaluation of these elements as total operations on a partially ordered set. For this reason, posets with certain completeness properties can often be described as algebraic structures of a certain kind. In addition, studying the properties of the newly obtained operations yields further interesting subjects.\n\nTypes of completeness properties\nAll completeness properties are described along a similar scheme: one describes a certain class of subsets of a partially ordered set that are required to have a supremum or required to have an infimum. Hence every completeness property has its dual, obtained by inverting the order-dependent definitions in the given statement. Some of the notions are usually not dualized while others may be self-dual (i.e. equivalent to their dual statements).\n\nLeast and greatest elements\nThe easiest example of a supremum is the empty one, i.e. the supremum of the empty set. By definition, this is the least element among all elements that are greater than each member of the empty set. But this is just the least element of the whole poset, if it has one, since the empty subset of a poset P is conventionally considered to be both bounded from above and from below, with every element of P being both an upper and lower bound of the empty subset. Other common names for the least element are bottom and zero (0). The dual notion, the empty lower bound, is the greatest element, top, or unit (1).\nPosets that have a bottom are sometimes called pointed, while posets with a top are called unital or topped. An order that has both a least and a greatest element is bounded. However, this should not be confused with the notion of bounded completeness given below.\n\nFinite completeness\nFurther simple completeness conditions arise from the consideration of all non-empty finite sets. An order in which all non-empty finite sets have both a supremum and an infimum is called a lattice. It suffices to require that all suprema and infima of two elements exist to obtain all non-empty finite ones; a straightforward induction argument shows that every finite non-empty supremum/infimum can be decomposed into a finite number of binary suprema/infima. Thus the central operations of lattices are binary suprema \n  \n    \n      \n        ∨\n      \n    \n    {\\displaystyle \\vee }\n  \n and infima \n  \n    \n      \n        ∧\n      \n    \n    {\\displaystyle \\wedge }\n  \n. It is in this context that the terms meet for \n  \n    \n      \n        ∧\n      \n    \n    {\\displaystyle \\wedge }\n  \n and join for \n  \n    \n      \n        ∨\n      \n    \n    {\\displaystyle \\vee }\n  \n are most common.\nA poset in which only non-empty finite suprema are known to exist is therefore called a join-semilattice. The dual notion is meet-semilattice.\n\nFurther completeness conditions\nThe strongest form of completeness is the existence of all suprema and all infima. The posets with this property are the complete lattices. However, using the given order, one can restrict to further classes of (possibly infinite) subsets, that do not yield this strong completeness at once.\nIf all directed subsets of a poset have a supremum, then the order is a directed-complete partial order (dcpo). These are especially important in domain theory. The seldom-considered dual notion to a dcpo is the filtered-complete poset. Dcpos with a least element (\"pointed dcpos\") are one of the possible meanings of the phrase complete partial order (cpo).\nIf every subset that has some upper bound has also a least upper bound, then the respective poset is called bounded complete. The term is used widely with this definition that focuses on suprema and there is no common name for the dual property. However, bounded completeness can be expressed in terms of other completeness conditions that are easily dualized (see below). Although concepts w",
    "links": [
      "Alexandrov topology",
      "Algebraic structure",
      "Antichain",
      "Antisymmetric relation",
      "Asymmetric relation",
      "Axiom of choice",
      "Banach lattice",
      "Better-quasi-ordering",
      "Binary relation",
      "Boolean algebra (structure)",
      "Boolean prime ideal theorem",
      "Bounded complete",
      "Bounded lattice",
      "Cantor's isomorphism theorem",
      "Cantor–Bernstein theorem",
      "Categorical formulation of order theory",
      "Category theory",
      "Chain-complete partial order",
      "Chain complete",
      "Class (set theory)",
      "Cofinal (mathematics)",
      "Cofinality",
      "Comparability",
      "Comparability graph",
      "Complemented lattice",
      "Complete lattice",
      "Complete partial order",
      "Completely distributive lattice",
      "Completeness of the real numbers",
      "Completion (order theory)",
      "Composition of relations",
      "Connected relation",
      "Converse relation",
      "Covering relation",
      "Cyclic order",
      "Dense order",
      "Dilworth's theorem",
      "Directed complete partial order",
      "Directed set",
      "Distributive lattice",
      "Distributivity (order theory)",
      "Domain theory",
      "Duality (order theory)",
      "Dushnik–Miller theorem",
      "Empty set",
      "Equivalence relation",
      "Eulerian poset",
      "Filter (mathematics)",
      "Finite set",
      "Foundational relation"
    ],
    "categories": [
      "Category:All articles lacking in-text citations",
      "Category:Articles lacking in-text citations from June 2025",
      "Category:Articles with short description",
      "Category:Order theory",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Construction of the real numbers": {
    "title": "Construction of the real numbers",
    "url": "https://en.wikipedia.org/wiki/Construction_of_the_real_numbers",
    "summary": "In mathematics, there are several equivalent ways of defining the real numbers. One of them is that they form a complete ordered field that does not contain any smaller complete ordered field. Such a definition does not prove that such a complete ordered field exists, and the existence proof consists of constructing a mathematical structure that satisfies the definition.\nThe article presents several such constructions. They are equivalent in the sense that, given the result of any two such constructions, there is a unique isomorphism of ordered field between them. This results from the above definition and is independent of particular constructions. These isomorphisms allow identifying the results of the constructions, and, in practice, to forget which construction has been chosen.",
    "content": "In mathematics, there are several equivalent ways of defining the real numbers. One of them is that they form a complete ordered field that does not contain any smaller complete ordered field. Such a definition does not prove that such a complete ordered field exists, and the existence proof consists of constructing a mathematical structure that satisfies the definition.\nThe article presents several such constructions. They are equivalent in the sense that, given the result of any two such constructions, there is a unique isomorphism of ordered field between them. This results from the above definition and is independent of particular constructions. These isomorphisms allow identifying the results of the constructions, and, in practice, to forget which construction has been chosen.\n\nAxiomatic definitions\nAn axiomatic definition of the real numbers consists of defining them as the elements of  a complete ordered field. This means the following: The real numbers form a set, commonly denoted \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n, containing two distinguished  elements denoted 0 and 1, and on which are defined  two binary operations and one binary relation; the operations are called addition and multiplication of real numbers and denoted respectively with + and ×; the binary relation is inequality, denoted \n  \n    \n      \n        ≤\n        .\n      \n    \n    {\\displaystyle \\leq .}\n  \n Moreover, the following properties called axioms must be satisfied.\nThe existence of such a structure is a theorem, which is proved by constructing such a structure. A consequence of the axioms is that this structure is unique up to an isomorphism, and thus, the real numbers can be used and manipulated, without referring to the method of construction.\n\nAxioms\nR\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n is a field under addition and multiplication. In other words,\nFor all x, y, and z in \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n, x + (y + z) = (x + y) + z and x × (y × z) = (x × y) × z. (associativity of addition and multiplication)\nFor all x and y in \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n, x + y = y + x and x × y = y × x. (commutativity of addition and multiplication)\nFor all x, y, and z in \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n, x × (y + z) = (x × y) + (x × z). (distributivity of multiplication over addition)\nFor all x in \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n, x + 0 = x. (existence of additive identity)\n0 is not equal to 1, and for all x in \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n, x × 1 = x. (existence of multiplicative identity)\nFor every x in \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n, there exists an element −x in \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n, such that x + (−x) = 0. (existence of additive inverses)\nFor every x ≠ 0 in \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n, there exists an element x−1 in \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n, such that x × x−1 = 1. (existence of multiplicative inverses)\n\n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n is totally ordered for \n  \n    \n      \n        ≤\n      \n    \n    {\\displaystyle \\leq }\n  \n. In other words,\nFor all x in \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n, x ≤ x. (reflexivity)\nFor all x and y in \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n, if x ≤ y and y ≤ x, then x = y. (antisymmetry)\nFor all x, y, and z in \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n, if x ≤ y and y ≤ z, then x ≤ z. (transitivity)\nFor all x and y in \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n, x ≤ y or y ≤ x. (totality)\nAddition and multiplication are compatible with the order. In other words,\nFor all x, y and z in \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n, if x ≤ y, then x + z ≤ y + z. (preservation of order under addition)\nFor all x and y in \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n, if 0 ≤ x and 0 ≤ y, then 0 ≤ x × y (preservation of order under multiplication)\nThe order ≤ is complete in the following sense: every non-empty subset of \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n that is bounded above has a least upper bound. In other words,\nIf A is a ",
    "links": [
      "0.999...",
      "Abelian group",
      "Addition",
      "Advances in Mathematics",
      "Alfred Tarski",
      "Antisymmetric relation",
      "ArXiv (identifier)",
      "Archimedean group",
      "Archimedean property",
      "Associativity",
      "Asymmetric relation",
      "Automated theorem proving",
      "Axiom",
      "Axiom of choice",
      "Axiomatic method",
      "Axiomatization",
      "Bijection",
      "Binary operation",
      "Binary relation",
      "Charles Méray",
      "Commutative operation",
      "Complement (set theory)",
      "Complete ordered field",
      "Completion (topology)",
      "Constructivism (mathematics)",
      "Decidability of first-order theories of the real numbers",
      "Decimal notation",
      "Dedekind-complete",
      "Dedekind cut",
      "Dense order",
      "Distributivity",
      "Divisible group",
      "Division (mathematics)",
      "Doi (identifier)",
      "Embedding",
      "Equivalence class",
      "Equivalence relation",
      "Eudoxus of Cnidus",
      "Extended real number",
      "Field (mathematics)",
      "Georg Cantor",
      "Greatest element",
      "Hyperinteger",
      "Hyperreal number",
      "ISBN (identifier)",
      "Identity element",
      "If and only if",
      "Infinitesimal",
      "Infix operator",
      "Injective"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Constructivism (mathematics)",
      "Category:Pages displaying short descriptions of redirect targets via Module:Annotated link",
      "Category:Real numbers",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Decision theory": {
    "title": "Decision theory",
    "url": "https://en.wikipedia.org/wiki/Decision_theory",
    "summary": "Decision theory or the theory of rational choice is a branch of probability, economics, and analytic philosophy that uses expected utility and probability to model how individuals would behave rationally under uncertainty. It differs from the cognitive and behavioral sciences in that it is mainly prescriptive and concerned with identifying optimal decisions for a rational agent, rather than describing how people actually make decisions. Despite this, the field is important to the study of real human behavior by social scientists, as it lays the foundations to mathematically model and analyze individuals in fields such as sociology, economics, criminology, cognitive science, moral philosophy and political science.",
    "content": "Decision theory or the theory of rational choice is a branch of probability, economics, and analytic philosophy that uses expected utility and probability to model how individuals would behave rationally under uncertainty. It differs from the cognitive and behavioral sciences in that it is mainly prescriptive and concerned with identifying optimal decisions for a rational agent, rather than describing how people actually make decisions. Despite this, the field is important to the study of real human behavior by social scientists, as it lays the foundations to mathematically model and analyze individuals in fields such as sociology, economics, criminology, cognitive science, moral philosophy and political science.\n\nHistory\nThe roots of decision theory lie in probability theory, developed by Blaise Pascal and Pierre de Fermat in the 17th century, which was later refined by others like Christiaan Huygens. These developments provided a framework for understanding risk and uncertainty, which are central to decision-making.\nIn the 18th century, Daniel Bernoulli introduced the concept of \"expected utility\" in the context of gambling, which was later formalized by John von Neumann and Oskar Morgenstern in the 1940s. Their work on Game Theory and Expected Utility Theory helped establish a rational basis for decision-making under uncertainty.\nAfter World War II, decision theory expanded into economics, particularly with the work of economists like Milton Friedman and others, who applied it to market behavior and consumer choice theory. This era also saw the development of Bayesian decision theory, which incorporates Bayesian probability into decision-making models.\nBy the late 20th century, scholars like Daniel Kahneman and Amos Tversky challenged the assumptions of rational decision-making. Their work in behavioral economics highlighted cognitive biases and heuristics that influence real-world decisions, leading to the development of prospect theory, which modified expected utility theory by accounting for psychological factors.\n\nBranches\nNormative decision theory is concerned with identification of optimal decisions where optimality is often determined by considering an ideal decision maker who is able to calculate with perfect accuracy and is in some sense fully rational. The practical application of this prescriptive approach (how people ought to make decisions) is called decision analysis and is aimed at finding tools, methodologies, and software (decision support systems) to help people make better decisions.\nIn contrast, descriptive decision theory is concerned with describing observed behaviors often under the assumption that those making decisions are behaving under some consistent rules. These rules may, for instance, have a procedural framework (e.g. Amos Tversky's elimination by aspects model) or an axiomatic framework (e.g. stochastic transitivity axioms), reconciling the Von Neumann-Morgenstern axioms with behavioral violations of the expected utility hypothesis, or they may explicitly give a functional form for time-inconsistent utility functions (e.g. Laibson's quasi-hyperbolic discounting).\nPrescriptive decision theory is concerned with predictions about behavior that positive decision theory produces to allow for further tests of the kind of decision-making that occurs in practice. In recent decades, there has also been increasing interest in \"behavioral decision theory\", contributing to a re-evaluation of what useful decision-making requires.\n\nTypes of decisions\nChoice under uncertainty\nThe area of choice under uncertainty represents the heart of decision theory. Known from the 17th century (Blaise Pascal invoked it in his famous wager, which is contained in his Pensées, published in 1670), the idea of expected value is that, when faced with a number of actions, each of which could give rise to more than one possible outcome with different probabilities, the rational procedure is to identify all possible outcomes, determine their values (positive or negative) and the probabilities that will result from each course of action, and multiply the two to give an \"expected value\", or the average expectation for an outcome; the action to be chosen should be the one that gives rise to the highest total expected value. In 1738, Daniel Bernoulli published an influential paper entitled Exposition of a New Theory on the Measurement of Risk, in which he uses the St. Petersburg paradox to show that expected value theory must be normatively wrong. He gives an example in which a Dutch merchant is trying to decide whether to insure a cargo being sent from Amsterdam to St. Petersburg in winter. In his solution, he defines a utility function and computes expected utility rather than expected financial value.\nIn the 20th century, interest was reignited by Abraham Wald's 1939 paper pointing out that the two central procedures of sampling-distribution-based statistical-theory, namely hypothesis testing and parameter esti",
    "links": [
      "AFM Smith",
      "Abilene paradox",
      "Abraham Wald",
      "Adam Smith",
      "Admissible decision rule",
      "Adrian Smith (academic)",
      "Agent-based computational economics",
      "Agricultural economics",
      "Alan Greenspan",
      "Alexander Lerner",
      "Alexey Lyapunov",
      "Alfred Marshall",
      "Alfred Radcliffe-Brown",
      "Algebra",
      "Algebra of physical space",
      "Algebraic structure",
      "Algorithm",
      "Algorithm design",
      "Allais paradox",
      "Allenna Leonard",
      "Amartya Sen",
      "Ambiguity aversion",
      "American School (economics)",
      "Amos Tversky",
      "Analysis of algorithms",
      "Analytic hierarchy process",
      "Analytic network process",
      "Analytic philosophy",
      "Analytical mechanics",
      "Anchoring (cognitive bias)",
      "Ancient economic thought",
      "Annals of Mathematical Statistics",
      "Anscombe-Aumann subjective expected utility model",
      "Anthony Wilden",
      "Antoine Augustin Cournot",
      "Applied economics",
      "Applied mathematics",
      "Apportionment paradox",
      "Approximation theory",
      "Areas of mathematics",
      "Argument from free will",
      "Arrow's impossibility theorem",
      "Arrow information paradox",
      "Arthur Cecil Pigou",
      "Artificial intelligence",
      "Attention economy",
      "Austrian School",
      "Automata theory",
      "Automated theorem proving",
      "Axiom"
    ],
    "categories": [
      "Category:All articles needing additional references",
      "Category:All articles with specifically marked weasel-worded phrases",
      "Category:All articles with unsourced statements",
      "Category:Articles needing additional references from April 2025",
      "Category:Articles with excerpts",
      "Category:Articles with short description",
      "Category:Articles with specifically marked weasel-worded phrases from February 2025",
      "Category:Articles with unsourced statements from April 2025",
      "Category:Control theory",
      "Category:Decision theory"
    ]
  },
  "Abstract logic": {
    "title": "Abstract logic",
    "url": "https://en.wikipedia.org/wiki/Abstract_logic",
    "summary": "In mathematical logic, an abstract logic is a formal system consisting of a class of sentences and a satisfaction relation with specific properties related to occurrence, expansion, isomorphism, renaming and quantification.\nBased on Lindström's characterization, first-order logic is, up to equivalence, the only abstract logic that is countably compact and has Löwenheim number ω.",
    "content": "In mathematical logic, an abstract logic is a formal system consisting of a class of sentences and a satisfaction relation with specific properties related to occurrence, expansion, isomorphism, renaming and quantification.\nBased on Lindström's characterization, first-order logic is, up to equivalence, the only abstract logic that is countably compact and has Löwenheim number ω.\n\nSee also\nAbstract algebraic logic – Study of the algebraization of deductive systems, based on the Lindenbaum–Tarski algebra\nAbstract model theory\nLöwenheim number – Smallest cardinal number for which a weak downward Löwenheim–Skolem theorem holds\nLindström's theorem – Theorem in mathematical logic\nUniversal logic – Subfield of logic that studies the features common to all logical systems\n\n\n== References ==",
    "links": [
      "Abstract algebraic logic",
      "Abstract logic (disambiguation)",
      "Abstract model theory",
      "Ackermann set theory",
      "Aleph number",
      "Algebraic logic",
      "Alphabet (formal languages)",
      "Argument",
      "Arity",
      "Atomic formula",
      "Atomic sentence",
      "Automata theory",
      "Automated theorem proving",
      "Axiom",
      "Axiom of choice",
      "Axiom schema",
      "Axiomatic system",
      "Axiomatization of Boolean algebras",
      "Banach–Tarski paradox",
      "Bijection",
      "Binary operation",
      "Boolean algebra",
      "Boolean algebras canonically defined",
      "Boolean function",
      "Cantor's diagonal argument",
      "Cantor's paradox",
      "Cantor's theorem",
      "Cardinality",
      "Cartesian product",
      "Categorical theory",
      "Category (mathematics)",
      "Category of sets",
      "Category theory",
      "Chen Chung Chang",
      "Church encoding",
      "Church–Turing thesis",
      "Class (set theory)",
      "Classical logic",
      "Codomain",
      "Compactness theorem",
      "Complement (set theory)",
      "Complete theory",
      "Computability theory",
      "Computable function",
      "Computable set",
      "Computably enumerable set",
      "Concrete category",
      "Conservative extension",
      "Consistency",
      "Constructible universe"
    ],
    "categories": [
      "Category:All stub articles",
      "Category:Articles with short description",
      "Category:Mathematical logic",
      "Category:Mathematical logic stubs",
      "Category:Short description matches Wikidata"
    ]
  },
  "Ackermann set theory": {
    "title": "Ackermann set theory",
    "url": "https://en.wikipedia.org/wiki/Ackermann_set_theory",
    "summary": "In mathematics and logic, Ackermann set theory (AST, also known as \n  \n    \n      \n        \n          A\n          \n            ∗\n          \n        \n        \n          /\n        \n        V\n      \n    \n    {\\displaystyle A^{*}/V}\n  \n) is an axiomatic set theory proposed by Wilhelm Ackermann in 1956.\nAST differs from Zermelo–Fraenkel set theory (ZF) in that it allows proper classes, that is, objects that are not sets, including a class of all sets.\nIt replaces several of the standard ZF axioms for constructing new sets with a principle known as Ackermann's schema. Intuitively, the schema allows a new set to be constructed if it can be defined by a formula which does not refer to the class of all sets.\nIn its use of classes, AST differs from other alternative set theories such as Morse–Kelley set theory and Von Neumann–Bernays–Gödel set theory in that a class may be an element of another class.\nWilliam N. Reinhardt established in 1970 that AST is effectively equivalent in strength to ZF, ",
    "content": "In mathematics and logic, Ackermann set theory (AST, also known as \n  \n    \n      \n        \n          A\n          \n            ∗\n          \n        \n        \n          /\n        \n        V\n      \n    \n    {\\displaystyle A^{*}/V}\n  \n) is an axiomatic set theory proposed by Wilhelm Ackermann in 1956.\nAST differs from Zermelo–Fraenkel set theory (ZF) in that it allows proper classes, that is, objects that are not sets, including a class of all sets.\nIt replaces several of the standard ZF axioms for constructing new sets with a principle known as Ackermann's schema. Intuitively, the schema allows a new set to be constructed if it can be defined by a formula which does not refer to the class of all sets.\nIn its use of classes, AST differs from other alternative set theories such as Morse–Kelley set theory and Von Neumann–Bernays–Gödel set theory in that a class may be an element of another class.\nWilliam N. Reinhardt established in 1970 that AST is effectively equivalent in strength to ZF, putting it on equal foundations. In particular, AST is consistent if and only if ZF is consistent.\n\nPreliminaries\nAST is formulated in first-order logic. The language \n  \n    \n      \n        \n          L\n          \n            {\n            ∈\n            ,\n            V\n            }\n          \n        \n      \n    \n    {\\displaystyle L_{\\{\\in ,V\\}}}\n  \n of AST contains one binary relation \n  \n    \n      \n        ∈\n      \n    \n    {\\displaystyle \\in }\n  \n denoting set membership and one constant \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n denoting the class of all sets. Ackermann used a predicate \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n  \n instead of \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n; this is equivalent as each of \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n  \n and \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n can be defined in terms of the other.\nWe will refer to elements of \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n as sets, and general objects as classes. A class that is not a set is called a proper class.\n\nAxioms\nThe following formulation is due to Reinhardt.\nThe five axioms include two axiom schemas.\nAckermann's original formulation included only the first four of these, omitting the axiom of regularity.\n\n1. Axiom of extensionality\nIf two classes have the same elements, then they are equal.\n\n  \n    \n      \n        ∀\n        x\n        \n        (\n        x\n        ∈\n        A\n        ↔\n        x\n        ∈\n        B\n        )\n        →\n        A\n        =\n        B\n        .\n      \n    \n    {\\displaystyle \\forall x\\;(x\\in A\\leftrightarrow x\\in B)\\to A=B.}\n  \n\nThis axiom is identical to the axiom of extensionality found in many other set theories, including ZF.\n\n2. Heredity\nAny element or a subset of a set is a set.\n\n  \n    \n      \n        (\n        x\n        ∈\n        y\n        ∨\n        x\n        ⊆\n        y\n        )\n        ∧\n        y\n        ∈\n        V\n        →\n        x\n        ∈\n        V\n        .\n      \n    \n    {\\displaystyle (x\\in y\\lor x\\subseteq y)\\land y\\in V\\to x\\in V.}\n\n3. Comprehension schema\nFor any property, we can form the class of sets satisfying that property. Formally, for any formula \n  \n    \n      \n        ϕ\n      \n    \n    {\\displaystyle \\phi }\n  \n where \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is not free:\n\n  \n    \n      \n        ∃\n        X\n        \n        ∀\n        x\n        \n        (\n        x\n        ∈\n        X\n        ↔\n        x\n        ∈\n        V\n        ∧\n        ϕ\n        )\n        .\n      \n    \n    {\\displaystyle \\exists X\\;\\forall x\\;(x\\in X\\leftrightarrow x\\in V\\land \\phi ).}\n  \n\nThat is, the only restriction is that comprehension is restricted to objects in \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n. But the resulting object is not necessarily a set.\n\n4. Ackermann's schema\nFor any formula \n  \n    \n      \n        ϕ\n      \n    \n    {\\displaystyle \\phi }\n  \n with free variables \n  \n    \n      \n        \n          a\n          \n            1\n          \n        \n        ,\n        …\n        ,\n        \n          a\n          \n            n\n          \n        \n        ,\n        x\n      \n    \n    {\\displaystyle a_{1},\\ldots ,a_{n},x}\n  \n and no occurrences of \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n:\n\n  \n    \n      \n        \n          a\n          \n            1\n          \n        \n        ,\n        …\n        ,\n        \n          a\n          \n            n\n          \n        \n        ∈\n        V\n        ∧\n        ∀\n        x\n        \n        (\n        ϕ\n        →\n        x\n        ∈\n        V\n        )\n        →\n        ∃\n        X\n        \n          ∈\n        \n        V\n        \n        ∀\n        x\n        \n        (\n        x\n        ∈\n        X\n        ↔\n        ϕ\n        )\n        .\n      \n    \n    {\\displaystyle a_{1},\\ldots ,a_{n}\\in V\\land \\forall x\\;(\\phi \\to x\\in V)\\to \\exists X{\\in }V\\;\\forall x",
    "links": [
      "Abraham Fraenkel",
      "Ackermann (disambiguation)",
      "Akihiro Kanamori",
      "Axiom of extensionality",
      "Axiom of regularity",
      "Axiom schema",
      "Azriel Levy",
      "Azriel Lévy",
      "Binary relation",
      "Category theory",
      "Class (set theory)",
      "Conservative extension",
      "Consistency",
      "Constant (mathematics)",
      "Doi (identifier)",
      "Equiconsistency",
      "First-order logic",
      "Formal language",
      "Foundations of mathematics",
      "Free variable",
      "ISBN (identifier)",
      "If and only if",
      "Interpretability",
      "JSTOR (identifier)",
      "List of alternative set theories",
      "Logic",
      "Mathematics",
      "Morse–Kelley set theory",
      "Power set",
      "Quantifier (logic)",
      "Reflection principle",
      "S2CID (identifier)",
      "Set membership",
      "Set theory",
      "Von Neumann universe",
      "Von Neumann–Bernays–Gödel set theory",
      "Wilhelm Ackermann",
      "Yehoshua Bar-Hillel",
      "Zermelo set theory",
      "Zermelo–Fraenkel set theory"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Short description matches Wikidata",
      "Category:Systems of set theory"
    ]
  },
  "Algebra of sets": {
    "title": "Algebra of sets",
    "url": "https://en.wikipedia.org/wiki/Algebra_of_sets",
    "summary": "In mathematics, the algebra of sets, not to be confused with the mathematical structure of an algebra of sets, defines the properties and laws of sets, the set-theoretic operations of union, intersection, and complementation and the relations of set equality and set inclusion. It also provides systematic procedures for evaluating expressions, and performing calculations, involving these operations and relations.\nAny set of sets closed under the set-theoretic operations forms a Boolean algebra with the join operator being union, the meet operator being intersection, the complement operator being set complement, the bottom being ⁠\n  \n    \n      \n        ∅\n      \n    \n    {\\displaystyle \\varnothing }\n  \n⁠ and the top being the universe set under consideration.",
    "content": "In mathematics, the algebra of sets, not to be confused with the mathematical structure of an algebra of sets, defines the properties and laws of sets, the set-theoretic operations of union, intersection, and complementation and the relations of set equality and set inclusion. It also provides systematic procedures for evaluating expressions, and performing calculations, involving these operations and relations.\nAny set of sets closed under the set-theoretic operations forms a Boolean algebra with the join operator being union, the meet operator being intersection, the complement operator being set complement, the bottom being ⁠\n  \n    \n      \n        ∅\n      \n    \n    {\\displaystyle \\varnothing }\n  \n⁠ and the top being the universe set under consideration.\n\nFundamentals\nThe algebra of sets is the set-theoretic analogue of the algebra of numbers. Just as arithmetic addition and multiplication are associative and commutative, so are set union and intersection; just as the arithmetic relation \"less than or equal\" is reflexive, antisymmetric and transitive, so is the set relation of \"subset\".\nIt is the algebra of the set-theoretic operations of union, intersection and complementation, and the relations of equality and inclusion.  For a basic introduction to sets see the article on sets, for a fuller account see naive set theory, and for a full rigorous axiomatic treatment see axiomatic set theory.\n\nFundamental properties of set algebra\nThe binary operations of set union (⁠\n  \n    \n      \n        ∪\n      \n    \n    {\\displaystyle \\cup }\n  \n⁠) and intersection (⁠\n  \n    \n      \n        ∩\n      \n    \n    {\\displaystyle \\cap }\n  \n⁠) satisfy many identities. Several of these identities or \"laws\" have well established names.\n\nCommutative property:\n⁠\n  \n    \n      \n        A\n        ∪\n        B\n        =\n        B\n        ∪\n        A\n      \n    \n    {\\displaystyle A\\cup B=B\\cup A}\n  \n⁠\n⁠\n  \n    \n      \n        A\n        ∩\n        B\n        =\n        B\n        ∩\n        A\n      \n    \n    {\\displaystyle A\\cap B=B\\cap A}\n  \n⁠\nAssociative property:\n⁠\n  \n    \n      \n        (\n        A\n        ∪\n        B\n        )\n        ∪\n        C\n        =\n        A\n        ∪\n        (\n        B\n        ∪\n        C\n        )\n      \n    \n    {\\displaystyle (A\\cup B)\\cup C=A\\cup (B\\cup C)}\n  \n⁠\n⁠\n  \n    \n      \n        (\n        A\n        ∩\n        B\n        )\n        ∩\n        C\n        =\n        A\n        ∩\n        (\n        B\n        ∩\n        C\n        )\n      \n    \n    {\\displaystyle (A\\cap B)\\cap C=A\\cap (B\\cap C)}\n  \n⁠\nDistributive property:\n⁠\n  \n    \n      \n        A\n        ∪\n        (\n        B\n        ∩\n        C\n        )\n        =\n        (\n        A\n        ∪\n        B\n        )\n        ∩\n        (\n        A\n        ∪\n        C\n        )\n      \n    \n    {\\displaystyle A\\cup (B\\cap C)=(A\\cup B)\\cap (A\\cup C)}\n  \n⁠\n⁠\n  \n    \n      \n        A\n        ∩\n        (\n        B\n        ∪\n        C\n        )\n        =\n        (\n        A\n        ∩\n        B\n        )\n        ∪\n        (\n        A\n        ∩\n        C\n        )\n      \n    \n    {\\displaystyle A\\cap (B\\cup C)=(A\\cap B)\\cup (A\\cap C)}\n  \n⁠\nThe union and intersection of sets may be seen as analogous to the addition and multiplication of numbers. Like addition and multiplication, the operations of union and intersection are commutative and associative, and intersection distributes over union.  However, unlike addition and multiplication, union also distributes over intersection.\nTwo additional pairs of properties involve the special sets called the empty set ⁠\n  \n    \n      \n        ∅\n      \n    \n    {\\displaystyle \\varnothing }\n  \n⁠ and the universe set ⁠\n  \n    \n      \n        \n          U\n        \n      \n    \n    {\\displaystyle {\\boldsymbol {U}}}\n  \n⁠; together with the complement operator (⁠\n  \n    \n      \n        \n          A\n          \n            ∁\n          \n        \n      \n    \n    {\\displaystyle A^{\\complement }}\n  \n⁠ denotes the complement of ⁠\n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n⁠. This can also be written as ⁠\n  \n    \n      \n        \n          A\n          ′\n        \n      \n    \n    {\\displaystyle A'}\n  \n⁠, read as \"A prime\").  The empty set has no members, and the universe set has all possible members (in a particular context).\n\nIdentity:\n⁠\n  \n    \n      \n        A\n        ∪\n        ∅\n        =\n        A\n      \n    \n    {\\displaystyle A\\cup \\varnothing =A}\n  \n⁠\n⁠\n  \n    \n      \n        A\n        ∩\n        \n          U\n        \n        =\n        A\n      \n    \n    {\\displaystyle A\\cap {\\boldsymbol {U}}=A}\n  \n⁠\nComplement:\n⁠\n  \n    \n      \n        A\n        ∪\n        \n          A\n          \n            ∁\n          \n        \n        =\n        \n          U\n        \n      \n    \n    {\\displaystyle A\\cup A^{\\complement }={\\boldsymbol {U}}}\n  \n⁠\n⁠\n  \n    \n      \n        A\n        ∩\n        \n          A\n          \n            ∁\n          \n        \n        =\n        ∅\n      \n    \n    {\\displaystyle A\\cap A^{\\complement }=\\varnothing }\n  \n⁠\nThe i",
    "links": [
      "Abraham Fraenkel",
      "Absorption law",
      "Abstract logic",
      "Ackermann set theory",
      "Addition",
      "Aleph number",
      "Algebraic logic",
      "Almost",
      "Alphabet (formal languages)",
      "Alternative set theory",
      "Amorphous set",
      "Antisymmetric relation",
      "Argument",
      "Arity",
      "Associative property",
      "Associativity",
      "Atomic formula",
      "Atomic sentence",
      "Automata theory",
      "Automated theorem proving",
      "Axiom",
      "Axiom of adjunction",
      "Axiom of choice",
      "Axiom of constructibility",
      "Axiom of countable choice",
      "Axiom of dependent choice",
      "Axiom of determinacy",
      "Axiom of extensionality",
      "Axiom of global choice",
      "Axiom of infinity",
      "Axiom of limitation of size",
      "Axiom of pairing",
      "Axiom of power set",
      "Axiom of projective determinacy",
      "Axiom of regularity",
      "Axiom of union",
      "Axiom schema",
      "Axiom schema of replacement",
      "Axiom schema of specification",
      "Axiomatic set theory",
      "Axiomatic system",
      "Axiomatization of Boolean algebras",
      "Banach–Tarski paradox",
      "Bertrand Russell",
      "Bijection",
      "Binary operation",
      "Binary relation",
      "Boolean algebra",
      "Boolean algebra (structure)",
      "Boolean algebras canonically defined"
    ],
    "categories": [
      "Category:All articles lacking in-text citations",
      "Category:Articles lacking in-text citations from April 2023",
      "Category:Articles with short description",
      "Category:Basic concepts in set theory",
      "Category:Operations on sets",
      "Category:Short description is different from Wikidata",
      "Category:Wikipedia articles needing clarification from August 2013"
    ]
  },
  "Alternative set theory": {
    "title": "List of alternative set theories",
    "url": "https://en.wikipedia.org/wiki/List_of_alternative_set_theories",
    "summary": "In mathematical logic, an alternative set theory is any of the alternative mathematical approaches to the concept of set and any alternative to the de facto standard set theory described in axiomatic set theory by the axioms of Zermelo–Fraenkel set theory.",
    "content": "In mathematical logic, an alternative set theory is any of the alternative mathematical approaches to the concept of set and any alternative to the de facto standard set theory described in axiomatic set theory by the axioms of Zermelo–Fraenkel set theory.\n\nAlternative set theories\nAlternative set theories include:\n\nVopěnka's alternative set theory\nVon Neumann–Bernays–Gödel set theory\nMorse–Kelley set theory\nTarski–Grothendieck set theory\nAckermann set theory\nType theory\nNew Foundations\nPositive set theory\nInternal set theory\nPocket set theory\nNaive set theory\nS (set theory)\nDouble extension set theory\nKripke–Platek set theory\nKripke–Platek set theory with urelements\nScott–Potter set theory\nConstructive set theory\nZermelo set theory\nGeneral set theory\nMac Lane set theory\n\nSee also\nNon-well-founded set theory\nList of first-order theories § Set theories\n\n\n== Notes ==",
    "links": [
      "Abraham Fraenkel",
      "Ackermann set theory",
      "Almost",
      "Alternative set theory",
      "Amorphous set",
      "Axiom",
      "Axiom of adjunction",
      "Axiom of choice",
      "Axiom of constructibility",
      "Axiom of countable choice",
      "Axiom of dependent choice",
      "Axiom of determinacy",
      "Axiom of extensionality",
      "Axiom of global choice",
      "Axiom of infinity",
      "Axiom of limitation of size",
      "Axiom of pairing",
      "Axiom of power set",
      "Axiom of projective determinacy",
      "Axiom of regularity",
      "Axiom of union",
      "Axiom schema",
      "Axiom schema of replacement",
      "Axiom schema of specification",
      "Axiomatic set theory",
      "Bertrand Russell",
      "Bijection",
      "Burali-Forti paradox",
      "Cantor's diagonal argument",
      "Cantor's theorem",
      "Cardinal number",
      "Cardinality",
      "Cartesian product",
      "Class (set theory)",
      "Complement (set theory)",
      "Computable set",
      "Constructible universe",
      "Constructive set theory",
      "Continuum hypothesis",
      "Countable set",
      "De Morgan's laws",
      "Dedekind-infinite set",
      "Disjoint union",
      "Double extension set theory",
      "Element (mathematics)",
      "Empty set",
      "Ernst Zermelo",
      "Family of sets",
      "Filter (set theory)",
      "Finite set"
    ],
    "categories": [
      "Category:All articles needing additional references",
      "Category:Articles needing additional references from September 2023",
      "Category:Articles with short description",
      "Category:Mathematics-related lists",
      "Category:Short description matches Wikidata",
      "Category:Systems of set theory"
    ]
  },
  "Amorphous set": {
    "title": "Amorphous set",
    "url": "https://en.wikipedia.org/wiki/Amorphous_set",
    "summary": "In set theory, an amorphous set is an infinite set which is not the disjoint union of two infinite subsets.",
    "content": "In set theory, an amorphous set is an infinite set which is not the disjoint union of two infinite subsets.\n\nExistence\nAmorphous sets cannot exist if the axiom of choice is assumed.  Fraenkel constructed a permutation model of Zermelo–Fraenkel with Atoms in which the set of atoms is an amorphous set. This is already sufficient for proving the consistency of the existence of an amorphous set with Zermelo–Fraenkel set theory with atoms. After Cohen's initial work on forcing in 1963, proofs of the consistency of amorphous sets with Zermelo–Fraenkel set theory were obtained.\n\nAdditional properties\nEvery amorphous set is Dedekind-finite, meaning that it has no bijection to a proper subset of itself. To see this, suppose that \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n is a set that does have a bijection \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n to a proper subset. For each natural number \n  \n    \n      \n        i\n        ≥\n        0\n      \n    \n    {\\displaystyle i\\geq 0}\n  \n\ndefine \n  \n    \n      \n        \n          S\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle S_{i}}\n  \n to be the set of elements that belong to the image of the \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n-fold composition of f with itself but not to the image of the \n  \n    \n      \n        (\n        i\n        +\n        1\n        )\n      \n    \n    {\\displaystyle (i+1)}\n  \n-fold composition.\nThen each \n  \n    \n      \n        \n          S\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle S_{i}}\n  \n is non-empty, so the union of the sets \n  \n    \n      \n        \n          S\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle S_{i}}\n  \n with even indices would be an infinite set whose complement in \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n is also infinite, showing that \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n cannot be amorphous. However, the converse is not necessarily true: it is consistent for there to exist infinite Dedekind-finite sets that are not amorphous.\nNo amorphous set can be linearly ordered. Because the image of an amorphous set is itself either amorphous or finite, it follows that every function from an amorphous set to a linearly ordered set has only a finite image.\nThe cofinite filter on an amorphous set is an ultrafilter. This is because the complement of each infinite subset must not be infinite, so every subset is either finite or cofinite.\n\nVariations\nIf \n  \n    \n      \n        Π\n      \n    \n    {\\displaystyle \\Pi }\n  \n is a partition of an amorphous set into finite subsets, then there must be exactly one integer \n  \n    \n      \n        n\n        (\n        Π\n        )\n      \n    \n    {\\displaystyle n(\\Pi )}\n  \n such that \n  \n    \n      \n        Π\n      \n    \n    {\\displaystyle \\Pi }\n  \n has infinitely many subsets of size \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n; for, if every size was used finitely many times, or if more than one size was used infinitely many times, this information could be used to coarsen the partition and split \n  \n    \n      \n        Π\n      \n    \n    {\\displaystyle \\Pi }\n  \n into two infinite subsets. If an amorphous set has the additional property that, for every partition \n  \n    \n      \n        Π\n      \n    \n    {\\displaystyle \\Pi }\n  \n, \n  \n    \n      \n        n\n        (\n        Π\n        )\n        =\n        1\n      \n    \n    {\\displaystyle n(\\Pi )=1}\n  \n, then it is called strictly amorphous or strongly amorphous, and if there is a finite upper bound on \n  \n    \n      \n        n\n        (\n        Π\n        )\n      \n    \n    {\\displaystyle n(\\Pi )}\n  \n then the set is called bounded amorphous. It is consistent with ZF that amorphous sets exist and are all bounded, or that they exist and are all unbounded.\n\n\n== References ==",
    "links": [
      "Abraham Fraenkel",
      "Almost",
      "Alternative set theory",
      "Axiom",
      "Axiom of adjunction",
      "Axiom of choice",
      "Axiom of constructibility",
      "Axiom of countable choice",
      "Axiom of dependent choice",
      "Axiom of determinacy",
      "Axiom of extensionality",
      "Axiom of global choice",
      "Axiom of infinity",
      "Axiom of limitation of size",
      "Axiom of pairing",
      "Axiom of power set",
      "Axiom of projective determinacy",
      "Axiom of regularity",
      "Axiom of union",
      "Axiom schema",
      "Axiom schema of replacement",
      "Axiom schema of specification",
      "Azriel Lévy",
      "Bertrand Russell",
      "Bijection",
      "Burali-Forti paradox",
      "Cantor's diagonal argument",
      "Cantor's theorem",
      "Cardinal number",
      "Cardinality",
      "Cartesian product",
      "Class (set theory)",
      "Cofinite filter",
      "Complement (set theory)",
      "Computable set",
      "Constructible universe",
      "Continuum hypothesis",
      "Countable set",
      "De Morgan's laws",
      "Dedekind-infinite set",
      "Disjoint union",
      "Doi (identifier)",
      "Element (mathematics)",
      "Empty set",
      "Ernst Zermelo",
      "Family of sets",
      "Filter (set theory)",
      "Finite set",
      "Forcing (mathematics)",
      "Fuzzy set"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Axiom of choice",
      "Category:Cardinal numbers",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Atomic formula": {
    "title": "Atomic formula",
    "url": "https://en.wikipedia.org/wiki/Atomic_formula",
    "summary": "In mathematical logic, an atomic formula (also known as an atom or a prime formula) is a formula with no deeper propositional structure, that is, a formula that contains no logical connectives or equivalently a formula that has no strict subformulas. Atoms are thus the simplest well-formed formulas of the logic. Compound formulas are formed by combining the atomic formulas using the logical connectives.\nThe precise form of atomic formulas depends on the logic under consideration; for propositional logic, for example, a propositional variable is often more briefly referred to as an \"atomic formula\", but, more precisely, a propositional variable is not an atomic formula but a formal expression that denotes an atomic formula. For predicate logic, the atoms are predicate symbols together with their arguments, each argument being a term.  In model theory, atomic formulas are merely strings of symbols with a given signature, which may or may not be satisfiable with respect to a given model.",
    "content": "In mathematical logic, an atomic formula (also known as an atom or a prime formula) is a formula with no deeper propositional structure, that is, a formula that contains no logical connectives or equivalently a formula that has no strict subformulas. Atoms are thus the simplest well-formed formulas of the logic. Compound formulas are formed by combining the atomic formulas using the logical connectives.\nThe precise form of atomic formulas depends on the logic under consideration; for propositional logic, for example, a propositional variable is often more briefly referred to as an \"atomic formula\", but, more precisely, a propositional variable is not an atomic formula but a formal expression that denotes an atomic formula. For predicate logic, the atoms are predicate symbols together with their arguments, each argument being a term.  In model theory, atomic formulas are merely strings of symbols with a given signature, which may or may not be satisfiable with respect to a given model.\n\nAtomic formula in first-order logic\nThe well-formed terms and propositions of ordinary first-order logic have the following syntax:\nTerms:\n\n  \n    \n      \n        t\n        ≡\n        c\n        ∣\n        x\n        ∣\n        f\n        (\n        \n          t\n          \n            1\n          \n        \n        ,\n        …\n        ,\n        \n          t\n          \n            n\n          \n        \n        )\n      \n    \n    {\\displaystyle t\\equiv c\\mid x\\mid f(t_{1},\\dotsc ,t_{n})}\n  \n,\nthat is, a term is recursively defined to be a constant c (a named object from the domain of discourse), or a variable x (ranging over the objects in the domain of discourse), or an n-ary function f whose arguments are terms tk. Functions map tuples of objects to objects.\nPropositions:\n\n  \n    \n      \n        A\n        ,\n        B\n        ,\n        .\n        .\n        .\n        ≡\n        P\n        (\n        \n          t\n          \n            1\n          \n        \n        ,\n        …\n        ,\n        \n          t\n          \n            n\n          \n        \n        )\n        ∣\n        A\n        ∧\n        B\n        ∣\n        ⊤\n        ∣\n        A\n        ∨\n        B\n        ∣\n        ⊥\n        ∣\n        A\n        ⊃\n        B\n        ∣\n        ∀\n        x\n        .\n         \n        A\n        ∣\n        ∃\n        x\n        .\n         \n        A\n      \n    \n    {\\displaystyle A,B,...\\equiv P(t_{1},\\dotsc ,t_{n})\\mid A\\wedge B\\mid \\top \\mid A\\vee B\\mid \\bot \\mid A\\supset B\\mid \\forall x.\\ A\\mid \\exists x.\\ A}\n  \n,\nthat is, a proposition is recursively defined to be an n-ary predicate P whose arguments are terms tk, or an expression composed of logical connectives (and, or) and quantifiers (for-all, there-exists) used with other propositions.\nAn atomic formula or atom is simply a predicate applied to a tuple of terms; that is, an atomic formula is a formula of the form P (t1 ,…, tn) for P a predicate, and the tn terms.\nAll other well-formed formulae are obtained by composing atoms with logical connectives and quantifiers.\nFor example, the formula ∀x. P (x) ∧ ∃y. Q (y, f (x)) ∨ ∃z. R (z) contains the atoms\n\n  \n    \n      \n        P\n        (\n        x\n        )\n      \n    \n    {\\displaystyle P(x)}\n  \n\n  \n    \n      \n        Q\n        (\n        y\n        ,\n        f\n        (\n        x\n        )\n        )\n      \n    \n    {\\displaystyle Q(y,f(x))}\n  \n\n  \n    \n      \n        R\n        (\n        z\n        )\n      \n    \n    {\\displaystyle R(z)}\n  \n.\nAs there are no quantifiers appearing in an atomic formula, all occurrences of variable symbols in an atomic formula are free.\n\nSee also\nIn model theory, structures assign an interpretation to the atomic formulas.\nIn proof theory, polarity assignment for atomic formulas is an essential component of focusing.\nAtomic sentence\n\nReferences\nFurther reading\nHinman, P. (2005). Fundamentals of Mathematical Logic. A K Peters. ISBN 1-56881-262-0.",
    "links": [
      "Abstract logic",
      "Ackermann set theory",
      "Aleph number",
      "Algebraic logic",
      "Alphabet (formal languages)",
      "Argument",
      "Arity",
      "Atomic sentence",
      "Automata theory",
      "Automated theorem proving",
      "Axiom",
      "Axiom of choice",
      "Axiom schema",
      "Axiomatic system",
      "Axiomatization of Boolean algebras",
      "Banach–Tarski paradox",
      "Bijection",
      "Binary operation",
      "Boolean algebra",
      "Boolean algebras canonically defined",
      "Boolean function",
      "Cantor's diagonal argument",
      "Cantor's paradox",
      "Cantor's theorem",
      "Cardinality",
      "Cartesian product",
      "Categorical theory",
      "Category (mathematics)",
      "Category of sets",
      "Category theory",
      "Chemical formula",
      "Church encoding",
      "Church–Turing thesis",
      "Class (set theory)",
      "Classical logic",
      "Codomain",
      "Compactness theorem",
      "Complement (set theory)",
      "Complete theory",
      "Computability theory",
      "Computable function",
      "Computable set",
      "Computably enumerable set",
      "Computational linguistics",
      "Concrete category",
      "Conservative extension",
      "Consistency",
      "Constructible universe",
      "Construction of the real numbers",
      "Constructive set theory"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Logical expressions",
      "Category:Predicate logic",
      "Category:Short description matches Wikidata"
    ]
  },
  "Axiom of limitation of size": {
    "title": "Axiom of limitation of size",
    "url": "https://en.wikipedia.org/wiki/Axiom_of_limitation_of_size",
    "summary": "In set theory, the axiom of limitation of size was proposed by John von Neumann in his 1925 axiom system for sets and classes. It formalizes the limitation of size principle, which avoids the paradoxes encountered in earlier formulations of set theory by recognizing that some classes are too big to be sets. Von Neumann realized that the paradoxes are caused by permitting these big classes to be members of a class. A class that is a member of a class is a set; a class that is not a set is a proper class. Every class is a subclass of V, the class of all sets. The axiom of limitation of size says that a class is a set if and only if it is smaller than V—that is, there is no function mapping it onto V. Usually, this axiom is stated in the equivalent form: A class is a proper class if and only if there is a function that maps it onto V.\nVon Neumann's axiom implies the axioms of replacement, separation, union, and global choice. It is equivalent to the combination of replacement, union, and ",
    "content": "In set theory, the axiom of limitation of size was proposed by John von Neumann in his 1925 axiom system for sets and classes. It formalizes the limitation of size principle, which avoids the paradoxes encountered in earlier formulations of set theory by recognizing that some classes are too big to be sets. Von Neumann realized that the paradoxes are caused by permitting these big classes to be members of a class. A class that is a member of a class is a set; a class that is not a set is a proper class. Every class is a subclass of V, the class of all sets. The axiom of limitation of size says that a class is a set if and only if it is smaller than V—that is, there is no function mapping it onto V. Usually, this axiom is stated in the equivalent form: A class is a proper class if and only if there is a function that maps it onto V.\nVon Neumann's axiom implies the axioms of replacement, separation, union, and global choice. It is equivalent to the combination of replacement, union, and global choice in Von Neumann–Bernays–Gödel set theory (NBG) and Morse–Kelley set theory. Later expositions of class theories—such as those of Paul Bernays, Kurt Gödel, and John L. Kelley—use replacement, union, and a choice axiom equivalent to global choice rather than von Neumann's axiom. In 1930, Ernst Zermelo defined models of set theory satisfying the axiom of limitation of size.\nAbraham Fraenkel and Azriel Lévy have stated that the axiom of limitation of size does not capture all of the \"limitation of size doctrine\" because it does not imply the power set axiom. Michael Hallett has argued that the limitation of size doctrine does not justify the power set axiom and that \"von Neumann's explicit assumption [of the smallness of power-sets] seems preferable to Zermelo's, Fraenkel's, and Lévy's obscurely hidden implicit assumption of the smallness of power-sets.\"\n\nFormal statement\nThe usual version of the axiom of limitation of size—a class is a proper class if and only if there is a function that maps it onto V —is expressed in the formal language of set theory as:\n\n  \n    \n      \n        \n          \n            \n              \n                ∀\n                C\n                \n                  \n                    [\n                  \n                \n                ¬\n                ∃\n                D\n                \n                  (\n                  \n                    C\n                    ∈\n                    D\n                  \n                  )\n                \n                \n                ⟺\n                \n                ∃\n                F\n                \n                  \n                    [\n                  \n                \n              \n              \n                \n                ∀\n                y\n                \n                  \n                    (\n                  \n                \n                ∃\n                D\n                (\n                y\n                ∈\n                D\n                )\n                \n                ⟹\n                \n                ∃\n                x\n                [\n                \n                x\n                ∈\n                C\n                ∧\n                (\n                x\n                ,\n                y\n                )\n                ∈\n                F\n                \n                ]\n                \n                  \n                    )\n                  \n                \n              \n            \n            \n              \n              \n                \n                \n                ∧\n                \n                ∀\n                x\n                ∀\n                y\n                ∀\n                z\n                \n                  \n                    (\n                  \n                \n                \n                [\n                \n                (\n                x\n                ,\n                y\n                )\n                ∈\n                F\n                ∧\n                (\n                x\n                ,\n                z\n                )\n                ∈\n                F\n                \n                ]\n                \n                ⟹\n                \n                y\n                =\n                z\n                \n                  \n                    )\n                  \n                \n                \n                \n                  \n                    ]\n                  \n                \n                \n                \n                  \n                    ]\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}\\forall C{\\Bigl [}\\lnot \\exists D\\left(C\\in D\\right)\\iff \\exists F{\\bigl [}&\\,\\forall y{\\bigl (}\\exists D(y\\in D)\\implies \\exists x[\\,x\\in C\\land (x,y)\\in F\\,]{\\bigr )}\\\\&\\,\\land \\,\\forall x\\forall y\\forall z{\\bigl (}\\,[\\,(x,y)\\in F\\land (x,z)\\in F\\,]\\implies y=z{\\bigr )}\\,{\\bigr ]}\\,{\\Bigr ]}\\end{aligned}}}\n  \n\nGödel introduced the conve",
    "links": [
      "Abraham Fraenkel",
      "Akihiro Kanamori",
      "Aleph number",
      "Alfred Tarski",
      "Almost",
      "Alternative set theory",
      "American Mathematical Monthly",
      "Amorphous set",
      "Axiom",
      "Axiom of adjunction",
      "Axiom of choice",
      "Axiom of constructibility",
      "Axiom of countable choice",
      "Axiom of dependent choice",
      "Axiom of determinacy",
      "Axiom of extensionality",
      "Axiom of global choice",
      "Axiom of infinity",
      "Axiom of pairing",
      "Axiom of power set",
      "Axiom of projective determinacy",
      "Axiom of regularity",
      "Axiom of replacement",
      "Axiom of separation",
      "Axiom of union",
      "Axiom schema",
      "Axiom schema of replacement",
      "Axiom schema of specification",
      "Axiom system",
      "Azriel Lévy",
      "Bertrand Russell",
      "Bibcode (identifier)",
      "Bijection",
      "Burali-Forte paradox",
      "Burali-Forti paradox",
      "Cantor's diagonal argument",
      "Cantor's theorem",
      "Cardinal number",
      "Cardinality",
      "Cartesian product",
      "Categorical (model theory)",
      "Choice function",
      "Class (set theory)",
      "Cofinality",
      "Complement (set theory)",
      "Composite function",
      "Computable set",
      "Constructible universe",
      "Constructivism (mathematics)",
      "Continuum hypothesis"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Axioms of set theory",
      "Category:CS1 errors: ISBN date",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Axiom of pairing": {
    "title": "Axiom of pairing",
    "url": "https://en.wikipedia.org/wiki/Axiom_of_pairing",
    "summary": "In axiomatic set theory and the branches of logic, mathematics, and computer science that use it, the axiom of pairing is one of the axioms of Zermelo–Fraenkel set theory. It was introduced by Zermelo (1908) as a special case of his axiom of elementary sets.",
    "content": "In axiomatic set theory and the branches of logic, mathematics, and computer science that use it, the axiom of pairing is one of the axioms of Zermelo–Fraenkel set theory. It was introduced by Zermelo (1908) as a special case of his axiom of elementary sets.\n\nFormal statement\nIn the formal language of the Zermelo–Fraenkel axioms, the axiom reads:\n\n  \n    \n      \n        ∀\n        A\n        \n        ∀\n        B\n        \n        ∃\n        C\n        \n        ∀\n        D\n        \n        [\n        D\n        ∈\n        C\n        \n        ⟺\n        \n        (\n        D\n        =\n        A\n        ∨\n        D\n        =\n        B\n        )\n        ]\n      \n    \n    {\\displaystyle \\forall A\\,\\forall B\\,\\exists C\\,\\forall D\\,[D\\in C\\iff (D=A\\lor D=B)]}\n  \n\nIn words:\n\nGiven any object A and any object B, there is a set C such that, given any object D, D is a member of C if and only if D is equal to A or D is equal to B.\n\nConsequences\nAs noted, what the axiom is saying is that, given two objects A and B, we can find a set C whose members are exactly A and B.\nWe can use the axiom of extensionality to show that this set C is unique. We call the set C the pair of A and B, and denote it {A,B}. Thus the essence of the axiom is:\n\nAny two objects have a pair.\nThe set {A,A} is abbreviated {A}, called the singleton containing A. Note that a singleton is a special case of a pair. Being able to construct a singleton is necessary, for example, to show the non-existence of the infinitely descending chains \n  \n    \n      \n        x\n        =\n        {\n        x\n        }\n      \n    \n    {\\displaystyle x=\\{x\\}}\n  \n from the Axiom of regularity.\nThe axiom of pairing also allows for the definition of ordered pairs. For any objects \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n and \n  \n    \n      \n        b\n      \n    \n    {\\displaystyle b}\n  \n, the ordered pair is defined by the following:\n\n  \n    \n      \n        (\n        a\n        ,\n        b\n        )\n        =\n        {\n        {\n        a\n        }\n        ,\n        {\n        a\n        ,\n        b\n        }\n        }\n        .\n        \n      \n    \n    {\\displaystyle (a,b)=\\{\\{a\\},\\{a,b\\}\\}.\\,}\n  \n\nNote that this definition satisfies the condition\n\n  \n    \n      \n        (\n        a\n        ,\n        b\n        )\n        =\n        (\n        c\n        ,\n        d\n        )\n        \n        ⟺\n        \n        a\n        =\n        c\n        ∧\n        b\n        =\n        d\n        .\n      \n    \n    {\\displaystyle (a,b)=(c,d)\\iff a=c\\land b=d.}\n  \n\nOrdered n-tuples can be defined recursively as follows:\n\n  \n    \n      \n        (\n        \n          a\n          \n            1\n          \n        \n        ,\n        …\n        ,\n        \n          a\n          \n            n\n          \n        \n        )\n        =\n        (\n        (\n        \n          a\n          \n            1\n          \n        \n        ,\n        …\n        ,\n        \n          a\n          \n            n\n            −\n            1\n          \n        \n        )\n        ,\n        \n          a\n          \n            n\n          \n        \n        )\n        .\n        \n      \n    \n    {\\displaystyle (a_{1},\\ldots ,a_{n})=((a_{1},\\ldots ,a_{n-1}),a_{n}).\\!}\n\nAlternatives\nNon-independence\nThe axiom of pairing is generally considered uncontroversial, and it or an equivalent appears in just about any axiomatization of set theory. Nevertheless, in the standard formulation of the Zermelo–Fraenkel set theory, the axiom of pairing follows from the axiom schema of replacement applied to any given set with two or more elements, and thus it is sometimes omitted. The existence of such a set with two elements, such as { {}, { {} } }, can be deduced either from the axiom of empty set and the axiom of power set or from the axiom of infinity.\nIn the absence of some of the stronger ZFC axioms, the axiom of pairing can still, without loss, be introduced in weaker forms.\n\nWeaker\nIn the presence of standard forms of the axiom schema of separation we can replace the axiom of pairing by its weaker version:\n\n  \n    \n      \n        ∀\n        A\n        ∀\n        B\n        ∃\n        C\n        ∀\n        D\n        (\n        (\n        D\n        =\n        A\n        ∨\n        D\n        =\n        B\n        )\n        ⇒\n        D\n        ∈\n        C\n        )\n      \n    \n    {\\displaystyle \\forall A\\forall B\\exists C\\forall D((D=A\\lor D=B)\\Rightarrow D\\in C)}\n  \n.\nThis weak axiom of pairing implies that any given objects \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n and \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  \n are members of some set \n  \n    \n      \n        C\n      \n    \n    {\\displaystyle C}\n  \n. Using the axiom schema of separation we can construct the set whose members are exactly \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n and \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  \n.\nAnother axiom which implies the axiom of pairing in the presence of the axiom of empty set is th",
    "links": [
      "Abraham Fraenkel",
      "Almost",
      "Alternative set theory",
      "Amorphous set",
      "Axiom",
      "Axiom of adjunction",
      "Axiom of choice",
      "Axiom of constructibility",
      "Axiom of countable choice",
      "Axiom of dependent choice",
      "Axiom of determinacy",
      "Axiom of elementary sets",
      "Axiom of empty set",
      "Axiom of extensionality",
      "Axiom of global choice",
      "Axiom of infinity",
      "Axiom of limitation of size",
      "Axiom of power set",
      "Axiom of projective determinacy",
      "Axiom of regularity",
      "Axiom of union",
      "Axiom schema",
      "Axiom schema of replacement",
      "Axiom schema of separation",
      "Axiom schema of specification",
      "Axiomatic set theory",
      "Axiomatization",
      "Bertrand Russell",
      "Bijection",
      "Burali-Forti paradox",
      "Cantor's diagonal argument",
      "Cantor's theorem",
      "Cardinal number",
      "Cardinality",
      "Cartesian product",
      "Class (set theory)",
      "Complement (set theory)",
      "Computable set",
      "Computer science",
      "Constructible universe",
      "Continuum hypothesis",
      "Countable set",
      "De Morgan's laws",
      "Dedekind-infinite set",
      "Disjoint union",
      "Doi (identifier)",
      "Element (mathematics)",
      "Empty set",
      "Equal (math)",
      "Ernst Zermelo"
    ],
    "categories": [
      "Category:All articles lacking in-text citations",
      "Category:Articles lacking in-text citations from March 2013",
      "Category:Articles with short description",
      "Category:Axioms of set theory",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Axiom of power set": {
    "title": "Axiom of power set",
    "url": "https://en.wikipedia.org/wiki/Axiom_of_power_set",
    "summary": "In mathematics, the axiom of power set is one of the Zermelo–Fraenkel axioms of axiomatic set theory. It guarantees for every set \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n the existence of a set \n  \n    \n      \n        \n          \n            P\n          \n        \n        (\n        x\n        )\n      \n    \n    {\\displaystyle {\\mathcal {P}}(x)}\n  \n, the power set of \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n, consisting precisely of the subsets of \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n. By the axiom of extensionality, the set \n  \n    \n      \n        \n          \n            P\n          \n        \n        (\n        x\n        )\n      \n    \n    {\\displaystyle {\\mathcal {P}}(x)}\n  \n is unique.\nThe axiom of power set appears in most axiomatizations of set theory. It is generally considered uncontroversial, although constructive set theory prefers a weaker version to resolve concerns about predicativity.",
    "content": "In mathematics, the axiom of power set is one of the Zermelo–Fraenkel axioms of axiomatic set theory. It guarantees for every set \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n the existence of a set \n  \n    \n      \n        \n          \n            P\n          \n        \n        (\n        x\n        )\n      \n    \n    {\\displaystyle {\\mathcal {P}}(x)}\n  \n, the power set of \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n, consisting precisely of the subsets of \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n. By the axiom of extensionality, the set \n  \n    \n      \n        \n          \n            P\n          \n        \n        (\n        x\n        )\n      \n    \n    {\\displaystyle {\\mathcal {P}}(x)}\n  \n is unique.\nThe axiom of power set appears in most axiomatizations of set theory. It is generally considered uncontroversial, although constructive set theory prefers a weaker version to resolve concerns about predicativity.\n\nFormal statement\nThe subset relation \n  \n    \n      \n        ⊆\n      \n    \n    {\\displaystyle \\subseteq }\n  \n is not a primitive notion in formal set theory and is not used in the formal language of the Zermelo–Fraenkel axioms. Rather, the subset relation \n  \n    \n      \n        ⊆\n      \n    \n    {\\displaystyle \\subseteq }\n  \n is defined in terms of set membership, \n  \n    \n      \n        ∈\n      \n    \n    {\\displaystyle \\in }\n  \n. Given this, in the formal language of the Zermelo–Fraenkel axioms, the axiom of power set reads:\n\n  \n    \n      \n        ∀\n        x\n        \n        ∃\n        y\n        \n        ∀\n        z\n        \n        [\n        z\n        ∈\n        y\n        \n        ⟺\n        \n        ∀\n        w\n        \n        (\n        w\n        ∈\n        z\n        ⇒\n        w\n        ∈\n        x\n        )\n        ]\n      \n    \n    {\\displaystyle \\forall x\\,\\exists y\\,\\forall z\\,[z\\in y\\iff \\forall w\\,(w\\in z\\Rightarrow w\\in x)]}\n  \n\nwhere y is the power set of x, z is any element of y, w is any member of z.\nIn English, this says:\n\nGiven any set x, there is a set y such that, given any set z, this set z is a member of y if and only if every element of z is also an element of x.\n\nConsequences\nThe power set axiom allows a simple definition of the Cartesian product of two sets \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n and \n  \n    \n      \n        Y\n      \n    \n    {\\displaystyle Y}\n  \n:\n\n  \n    \n      \n        X\n        ×\n        Y\n        =\n        {\n        (\n        x\n        ,\n        y\n        )\n        :\n        x\n        ∈\n        X\n        ∧\n        y\n        ∈\n        Y\n        }\n        .\n      \n    \n    {\\displaystyle X\\times Y=\\{(x,y):x\\in X\\land y\\in Y\\}.}\n  \n\nNotice that\n\n  \n    \n      \n        x\n        ,\n        y\n        ∈\n        X\n        ∪\n        Y\n      \n    \n    {\\displaystyle x,y\\in X\\cup Y}\n  \n\n  \n    \n      \n        {\n        x\n        }\n        ,\n        {\n        x\n        ,\n        y\n        }\n        ∈\n        \n          \n            P\n          \n        \n        (\n        X\n        ∪\n        Y\n        )\n      \n    \n    {\\displaystyle \\{x\\},\\{x,y\\}\\in {\\mathcal {P}}(X\\cup Y)}\n  \n\nand, for example, considering a model using the Kuratowski ordered pair,\n\n  \n    \n      \n        (\n        x\n        ,\n        y\n        )\n        =\n        {\n        {\n        x\n        }\n        ,\n        {\n        x\n        ,\n        y\n        }\n        }\n        ∈\n        \n          \n            P\n          \n        \n        (\n        \n          \n            P\n          \n        \n        (\n        X\n        ∪\n        Y\n        )\n        )\n      \n    \n    {\\displaystyle (x,y)=\\{\\{x\\},\\{x,y\\}\\}\\in {\\mathcal {P}}({\\mathcal {P}}(X\\cup Y))}\n  \n\nand thus the Cartesian product is a set since\n\n  \n    \n      \n        X\n        ×\n        Y\n        ⊆\n        \n          \n            P\n          \n        \n        (\n        \n          \n            P\n          \n        \n        (\n        X\n        ∪\n        Y\n        )\n        )\n        .\n      \n    \n    {\\displaystyle X\\times Y\\subseteq {\\mathcal {P}}({\\mathcal {P}}(X\\cup Y)).}\n  \n\nOne may define the Cartesian product of any finite collection of sets recursively:\n\n  \n    \n      \n        \n          X\n          \n            1\n          \n        \n        ×\n        ⋯\n        ×\n        \n          X\n          \n            n\n          \n        \n        =\n        (\n        \n          X\n          \n            1\n          \n        \n        ×\n        ⋯\n        ×\n        \n          X\n          \n            n\n            −\n            1\n          \n        \n        )\n        ×\n        \n          X\n          \n            n\n          \n        \n        .\n      \n    \n    {\\displaystyle X_{1}\\times \\cdots \\times X_{n}=(X_{1}\\times \\cdots \\times X_{n-1})\\times X_{n}.}\n  \n\nThe existence of the Cartesian product can be proved without using the power set axiom, as in the case of the Kripke–Platek set theory.\n\nLimitations\nThe power set axiom does not specify what subsets of a set exist, only that there is",
    "links": [
      "Abraham Fraenkel",
      "Almost",
      "Alternative set theory",
      "Amorphous set",
      "Axiom",
      "Axiom of adjunction",
      "Axiom of choice",
      "Axiom of constructibility",
      "Axiom of countable choice",
      "Axiom of dependent choice",
      "Axiom of determinacy",
      "Axiom of extensionality",
      "Axiom of global choice",
      "Axiom of infinity",
      "Axiom of limitation of size",
      "Axiom of pairing",
      "Axiom of projective determinacy",
      "Axiom of regularity",
      "Axiom of union",
      "Axiom schema",
      "Axiom schema of replacement",
      "Axiom schema of specification",
      "Axiomatic set theory",
      "Bertrand Russell",
      "Bijection",
      "Burali-Forti paradox",
      "Cantor's diagonal argument",
      "Cantor's theorem",
      "Cardinal number",
      "Cardinality",
      "Cartesian product",
      "Class (set theory)",
      "Complement (set theory)",
      "Computable set",
      "Constructible universe",
      "Constructive set theory",
      "Continuum hypothesis",
      "Countable set",
      "De Morgan's laws",
      "Dedekind-infinite set",
      "Disjoint union",
      "Element (mathematics)",
      "Empty set",
      "Ernst Zermelo",
      "Existential quantification",
      "Family of sets",
      "Filter (set theory)",
      "Finite set",
      "Forcing (mathematics)",
      "Formal language"
    ],
    "categories": [
      "Category:All articles lacking in-text citations",
      "Category:Articles lacking in-text citations from May 2020",
      "Category:Articles with short description",
      "Category:Axioms of set theory",
      "Category:Short description is different from Wikidata",
      "Category:Wikipedia articles incorporating text from PlanetMath"
    ]
  },
  "Aleph number": {
    "title": "Aleph number",
    "url": "https://en.wikipedia.org/wiki/Aleph_number",
    "summary": "In mathematics, particularly in set theory, the aleph numbers are a sequence of numbers used to represent the cardinality (or size) of infinite sets. They were introduced by the mathematician Georg Cantor and are named after the symbol he used to denote them, the Hebrew letter aleph (ℵ).\nThe smallest cardinality of an infinite set is that of the natural numbers, denoted by \n  \n    \n      \n        \n          ℵ\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\aleph _{0}}\n  \n (read aleph-nought, aleph-zero, or aleph-null); the next larger cardinality of a well-ordered set is \n  \n    \n      \n        \n          ℵ\n          \n            1\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\aleph _{1},}\n  \n then \n  \n    \n      \n        \n          ℵ\n          \n            2\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\aleph _{2},}\n  \n then \n  \n    \n      \n        \n          ℵ\n          \n            3\n          \n        \n        ,\n      \n  ",
    "content": "In mathematics, particularly in set theory, the aleph numbers are a sequence of numbers used to represent the cardinality (or size) of infinite sets. They were introduced by the mathematician Georg Cantor and are named after the symbol he used to denote them, the Hebrew letter aleph (ℵ).\nThe smallest cardinality of an infinite set is that of the natural numbers, denoted by \n  \n    \n      \n        \n          ℵ\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\aleph _{0}}\n  \n (read aleph-nought, aleph-zero, or aleph-null); the next larger cardinality of a well-ordered set is \n  \n    \n      \n        \n          ℵ\n          \n            1\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\aleph _{1},}\n  \n then \n  \n    \n      \n        \n          ℵ\n          \n            2\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\aleph _{2},}\n  \n then \n  \n    \n      \n        \n          ℵ\n          \n            3\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\aleph _{3},}\n  \n and so on. Continuing in this manner, it is possible to define an infinite cardinal number \n  \n    \n      \n        \n          ℵ\n          \n            α\n          \n        \n      \n    \n    {\\displaystyle \\aleph _{\\alpha }}\n  \n for every ordinal number \n  \n    \n      \n        α\n        ,\n      \n    \n    {\\displaystyle \\alpha ,}\n  \n as described below.\nThe concept and notation are due to Georg Cantor,\nwho defined the notion of cardinality and realized that infinite sets can have different cardinalities.\nThe aleph numbers differ from the infinity (\n  \n    \n      \n        ∞\n      \n    \n    {\\displaystyle \\infty }\n  \n) commonly found in algebra and calculus, in that the alephs measure the sizes of sets, while infinity is commonly defined either as an extreme limit of the real number line (applied to a function or sequence that \"diverges to infinity\" or \"increases without bound\"), or as an extreme point of the extended real number line.\n\nAleph-zero\nℵ\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\aleph _{0}}\n  \n (aleph-nought, aleph-zero, or aleph-null) is the cardinality of the set of all natural numbers, and is an infinite cardinal. The set of all finite ordinals, called \n  \n    \n      \n        ω\n      \n    \n    {\\displaystyle \\omega }\n  \n or \n  \n    \n      \n        \n          ω\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\omega _{0}}\n  \n (where \n  \n    \n      \n        ω\n      \n    \n    {\\displaystyle \\omega }\n  \n is the lowercase Greek letter omega), also has cardinality \n  \n    \n      \n        \n          ℵ\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\aleph _{0}}\n  \n. A set has cardinality \n  \n    \n      \n        \n          ℵ\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\aleph _{0}}\n  \n if and only if it is countably infinite, that is, there is a bijection (one-to-one correspondence) between it and the natural numbers. Examples of such sets are\n\nthe set of natural numbers, irrespective of including or excluding zero,\nthe set of all integers,\nany infinite subset of the integers, such as the set of all square numbers or the set of all prime numbers,\nthe set of all rational numbers,\nthe set of all constructible numbers (in the geometric sense),\nthe set of all algebraic numbers,\nthe set of all computable numbers,\nthe set of all computable functions,\nthe set of all binary strings of finite length, and\nthe set of all finite subsets of any given countably infinite set.\nAmong the countably infinite sets are certain infinite ordinals, including for example \n  \n    \n      \n        ω\n      \n    \n    {\\displaystyle \\omega }\n  \n, \n  \n    \n      \n        ω\n        +\n        1\n      \n    \n    {\\displaystyle \\omega +1}\n  \n, \n  \n    \n      \n        ω\n        ⋅\n        2\n      \n    \n    {\\displaystyle \\omega \\cdot 2}\n  \n, \n  \n    \n      \n        \n          ω\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\omega ^{2}}\n  \n, \n  \n    \n      \n        \n          ω\n          \n            ω\n          \n        \n      \n    \n    {\\displaystyle \\omega ^{\\omega }}\n  \n, and \n  \n    \n      \n        \n          ε\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\varepsilon _{0}}\n  \n. For example, the sequence (with order type \n  \n    \n      \n        ω\n        ⋅\n        2\n      \n    \n    {\\displaystyle \\omega \\cdot 2}\n  \n) of all positive odd integers followed by all positive even integers \n  \n    \n      \n        {\n        1\n        ,\n        3\n        ,\n        5\n        ,\n        7\n        ,\n        9\n        ,\n        ⋯\n        ;\n        2\n        ,\n        4\n        ,\n        6\n        ,\n        8\n        ,\n        10\n        ,\n        ⋯\n        }\n      \n    \n    {\\displaystyle \\{1,3,5,7,9,\\cdots ;2,4,6,8,10,\\cdots \\}}\n  \n is an ordering of the set (with cardinality \n  \n    \n      \n        \n          ℵ\n          \n            0\n          \n      ",
    "links": [
      "Abstract logic",
      "Ackermann set theory",
      "Alef (disambiguation)",
      "Aleph",
      "Aleph (disambiguation)",
      "Aleph One (disambiguation)",
      "Algebraic logic",
      "Algebraic number",
      "Alphabet (formal languages)",
      "American Mathematical Society",
      "ArXiv (identifier)",
      "Argument",
      "Arity",
      "Atomic formula",
      "Atomic sentence",
      "Automata theory",
      "Automated theorem proving",
      "Axiom",
      "Axiom of choice",
      "Axiom of countable choice",
      "Axiom schema",
      "Axiomatic system",
      "Axiomatization of Boolean algebras",
      "Banach–Tarski paradox",
      "Beth number",
      "Bijection",
      "Binary operation",
      "Boolean algebra",
      "Boolean algebras canonically defined",
      "Boolean function",
      "Borel hierarchy",
      "Burali-Forti paradox",
      "Cantor's diagonal argument",
      "Cantor's paradox",
      "Cantor's theorem",
      "Cardinal and Ordinal Numbers",
      "Cardinal number",
      "Cardinality",
      "Cardinality of the continuum",
      "Cartesian product",
      "Categorical theory",
      "Category (mathematics)",
      "Category of sets",
      "Category theory",
      "Church encoding",
      "Church–Turing thesis",
      "Class (set theory)",
      "Classical logic",
      "Codomain",
      "Cofinality"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Cardinal numbers",
      "Category:Hebrew alphabet",
      "Category:Infinity",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Aristotelian logic": {
    "title": "Term logic",
    "url": "https://en.wikipedia.org/wiki/Term_logic",
    "summary": "In logic and formal semantics, term logic, also known as traditional logic, syllogistic logic or Aristotelian logic, is a loose name for an approach to formal logic that began with Aristotle and was developed further in ancient history mostly by his followers, the Peripatetics. It was revived after the third century CE by Porphyry's Isagoge. \nTerm logic revived in medieval times, first in Islamic logic by Alpharabius in the tenth century, and later in Christian Europe in the twelfth century with the advent of new logic, remaining dominant until the advent of predicate logic in the late nineteenth century. \nHowever, even if eclipsed by newer logical systems, term logic still plays a significant role in the study of logic. Rather than radically breaking with term logic, modern logics typically expand it.",
    "content": "In logic and formal semantics, term logic, also known as traditional logic, syllogistic logic or Aristotelian logic, is a loose name for an approach to formal logic that began with Aristotle and was developed further in ancient history mostly by his followers, the Peripatetics. It was revived after the third century CE by Porphyry's Isagoge. \nTerm logic revived in medieval times, first in Islamic logic by Alpharabius in the tenth century, and later in Christian Europe in the twelfth century with the advent of new logic, remaining dominant until the advent of predicate logic in the late nineteenth century. \nHowever, even if eclipsed by newer logical systems, term logic still plays a significant role in the study of logic. Rather than radically breaking with term logic, modern logics typically expand it.\n\nAristotle's system\nAristotle's logical work is collected in the six texts that are collectively known as the Organon. Two of these texts in particular, namely the Prior Analytics and On Interpretation, contain the heart of Aristotle's treatment of judgements and formal inference, and it is principally this part of Aristotle's works that is about term logic. Modern work on Aristotle's logic builds on the tradition started in 1951 with the establishment by Jan Lukasiewicz of a revolutionary paradigm. Lukasiewicz's approach was reinvigorated in the early 1970s by John Corcoran and Timothy Smiley – which informs modern translations of Prior Analytics by Robin Smith in 1989 and Gisela Striker in 2009.\nThe Prior Analytics represents the first formal study of logic, where logic is understood as the study of arguments. An argument is a series of true or false statements which lead to a true or false conclusion. In the Prior Analytics, Aristotle identifies valid and invalid forms of arguments called syllogisms. A syllogism is an argument that consists of at least three sentences: at least two premises and a conclusion. Although Aristotle does not call them \"categorical sentences\", tradition does; he deals with them briefly in the Analytics and more extensively in On Interpretation. Each proposition (statement that is a thought of the kind expressible by a declarative sentence) of a syllogism is a categorical sentence which has a subject and a predicate connected by a verb. The usual way of connecting the subject and predicate of a categorical sentence as Aristotle does in On Interpretation is by using a linking verb e.g. P is S. However, in the Prior Analytics Aristotle rejects the usual form in favour of three of his inventions: \n\nP belongs to S\nP is predicated of S\nP is said of S\nAristotle does not explain why he introduces these innovative expressions but scholars conjecture that the reason may have been that it facilitates the use of letters instead of terms avoiding the ambiguity that results in Greek when letters are used with the linking verb. In his formulation of syllogistic propositions, instead of the copula (\"All/some... are/are not...\"), Aristotle uses the expression, \"... belongs to/does not belong to all/some...\" or \"... is said/is not said of all/some...\" There are four different types of categorical sentences: universal affirmative (A), universal negative (E), particular affirmative (I) and particular negative (O).\n\nA\t-\tA belongs to every B\nE - A belongs to no B\nI\t-\tA belongs to some B\nO\t-\tA does not belong to some B\nA method of symbolization that originated and was used in the Middle Ages greatly simplifies the study of the Prior Analytics.\nFollowing this tradition then, let:\n\na = belongs to every\ne = belongs to no\ni = belongs to some\no = does not belong to some\nCategorical sentences may then be abbreviated as follows:\n\nAaB = A belongs to every B (Every B is A)\nAeB = A belongs to no B (No B is A)\nAiB = A belongs to some B (Some B is A)\nAoB = A does not belong to some B (Some B is not A)\nFrom the viewpoint of modern logic, only a few types of sentences can be represented in this way.\n\nBasics\nThe fundamental assumption behind the theory is that the formal model of propositions are composed of two logical symbols called terms – hence the name \"two-term theory\" or \"term logic\" – and that the reasoning process is in turn built from propositions:\n\nThe term is a part of speech representing something, but which is not true or false in its own right, such as \"man\" or \"mortal\". As originally conceived, all terms would be drawn from one of ten categories enumerated by Aristotle in his Organon, classifying all objects and qualities within the domain of logical discourse.\nThe formal model of proposition consists of two terms, one of which, the \"predicate\", is \"affirmed\" or \"denied\" of the other, the \"subject\", and which is capable of truth or falsity.\nThe syllogism is an inference in which one proposition (the \"conclusion\") follows of necessity from two other propositions (the \"premises\").\nA proposition may be universal or particular, and it may be affirmative or negative. Traditionally, the four kinds of propos",
    "links": [
      "A. N. Whitehead",
      "A Greek–English Lexicon",
      "A History of Philosophy (Copleston)",
      "Abstract entity",
      "Abstract logic",
      "Accident (philosophy)",
      "Ackermann set theory",
      "Active intellect",
      "Akrasia",
      "Aleph number",
      "Algebraic logic",
      "Alphabet (formal languages)",
      "Alpharabius",
      "Alternative semantics",
      "Ambiguity",
      "Anagnorisis",
      "Anaphora (linguistics)",
      "Ancient history",
      "Antecedent-contained deletion",
      "Antiperistasis",
      "Apodicticity",
      "Arete",
      "Argument",
      "Aristotelian ethics",
      "Aristotelian physics",
      "Aristotelian realist philosophy of mathematics",
      "Aristotelianism",
      "Aristotle",
      "Aristotle's biology",
      "Aristotle's logic",
      "Aristotle's theory of universals",
      "Aristotle's views on women",
      "Aristotle's wheel paradox",
      "Arity",
      "Arthur Prior",
      "Artificial language",
      "Atomic formula",
      "Atomic sentence",
      "Automata theory",
      "Automated theorem proving",
      "Autonomy of syntax",
      "Axiom",
      "Axiom of choice",
      "Axiom schema",
      "Axiomatic system",
      "Axiomatization of Boolean algebras",
      "Banach–Tarski paradox",
      "Baroco",
      "Begriffsschrift",
      "Bertrand Russell"
    ],
    "categories": [
      "Category:All articles needing rewrite",
      "Category:All articles with unsourced statements",
      "Category:Articles containing Ancient Greek (to 1453)-language text",
      "Category:Articles with Internet Encyclopedia of Philosophy links",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from July 2022",
      "Category:Commons category link from Wikidata",
      "Category:Concepts in epistemology",
      "Category:Concepts in logic",
      "Category:Concepts in metaphysics"
    ]
  },
  "Argument": {
    "title": "Argument",
    "url": "https://en.wikipedia.org/wiki/Argument",
    "summary": "An argument is a series of sentences, statements, or propositions some of which are called premises and one is the conclusion. The purpose of an argument is to give reasons for one's conclusion via justification, explanation, and/or persuasion.\nArguments are intended to determine or show the degree of truth or acceptability of another statement called a conclusion. The process of crafting or delivering arguments, argumentation, can be studied from three main perspectives: the logical, the dialectical and the rhetorical perspective.\nIn logic, an argument is usually expressed not in natural language but in a symbolic formal language, and it can be defined as any group of propositions of which one is claimed to follow from the others through deductively valid inferences that preserve truth from the premises to the conclusion. This logical perspective on argument is relevant for scientific fields such as mathematics and computer science. Logic is the study of the forms of reasoning in argu",
    "content": "An argument is a series of sentences, statements, or propositions some of which are called premises and one is the conclusion. The purpose of an argument is to give reasons for one's conclusion via justification, explanation, and/or persuasion.\nArguments are intended to determine or show the degree of truth or acceptability of another statement called a conclusion. The process of crafting or delivering arguments, argumentation, can be studied from three main perspectives: the logical, the dialectical and the rhetorical perspective.\nIn logic, an argument is usually expressed not in natural language but in a symbolic formal language, and it can be defined as any group of propositions of which one is claimed to follow from the others through deductively valid inferences that preserve truth from the premises to the conclusion. This logical perspective on argument is relevant for scientific fields such as mathematics and computer science. Logic is the study of the forms of reasoning in arguments and the development of standards and criteria to evaluate arguments. Deductive arguments can be valid, and the valid ones can be sound: in a valid argument, premises necessitate the conclusion, even if one or more of the premises is false and the conclusion is false; in a sound argument, true premises necessitate a true conclusion. Inductive arguments, by contrast, can have different degrees of logical strength: the stronger or more cogent the argument, the greater the probability that the conclusion is true, the weaker the argument, the lesser that probability. The standards for evaluating non-deductive arguments may rest on different or additional criteria than truth—for example, the persuasiveness of so-called \"indispensability claims\" in transcendental arguments, the quality of hypotheses in retroduction, or even the disclosure of new possibilities for thinking and acting.\nIn dialectics, and also in a more colloquial sense, an argument can be conceived as a social and verbal means of trying to resolve, or at least contend with, a conflict or difference of opinion that has arisen or exists between two or more parties. For the rhetorical perspective, the argument is constitutively linked with the context, in particular with the time and place in which the argument is located. From this perspective, the argument is evaluated not just by two parties (as in a dialectical approach) but also by an audience. In both dialectic and rhetoric, arguments are used not through formal but through natural language. Since classical antiquity, philosophers and rhetoricians have developed lists of argument types in which premises and conclusions are connected in informal and defeasible ways.\n\nEtymology\nThe Latin root arguere (to make bright, enlighten, make known, prove, etc.) is from Proto-Indo-European argu-yo-, suffixed form of arg- (to shine; white).\n\nFormal and informal\nInformal arguments as studied in informal logic, are presented in ordinary language and are intended for everyday discourse. Formal arguments are studied in formal logic (historically called symbolic logic, more commonly referred to as mathematical logic today) and are expressed in a formal language. Informal logic emphasizes the study of argumentation; formal logic emphasizes implication and inference. Informal arguments are sometimes implicit. The rational structure—the relationship of claims, premises, warrants, relations of implication, and conclusion—is not always spelled out and immediately visible and must be made explicit by analysis.\n\nStandard logical account of argument types\nThere are several kinds of arguments in logic, the best known of which are \"deductive\" and \"inductive.\" An argument has one or more premises but only one conclusion. Each premise and the conclusion are truth bearers or \"truth-candidates\", each capable of being either true or false (but not both). These truth values bear on the terminology used with arguments.\n\nDeductive arguments\nA deductive argument asserts that the truth of the conclusion is a logical consequence of the premises: if the premises are true, the conclusion must be true. It would be self-contradictory to assert the premises and deny the conclusion because the negation of the conclusion is contradictory to the truth of the premises. Based on the premises, the conclusion follows necessarily (with certainty). Given premises that A=B and B=C, then the conclusion follows necessarily that A=C. Deductive arguments are sometimes referred to as \"truth-preserving\" arguments. For example, consider the argument that because bats can fly (premise=true), and all flying creatures are birds (premise=false), therefore bats are birds (conclusion=false). If we assume the premises are true, the conclusion follows necessarily, and it is a valid argument.\n\nValidity\nIn terms of validity, deductive arguments may be either valid or invalid. An argument is valid, if and only if (iff) it is impossible in all possible worlds for the premises to be",
    "links": [
      "Abductive reasoning",
      "Abstract logic",
      "Accident (fallacy)",
      "Ackermann set theory",
      "Ad hominem",
      "Ad nauseam",
      "Affirmative conclusion from a negative premise",
      "Affirming a disjunct",
      "Affirming the consequent",
      "Aleph number",
      "Algebraic logic",
      "Alphabet (formal languages)",
      "Ambiguity",
      "Analogy",
      "Anecdotal evidence",
      "Animistic fallacy",
      "Antithesis",
      "Appeal to accomplishment",
      "Appeal to consequences",
      "Appeal to emotion",
      "Appeal to fear",
      "Appeal to flattery",
      "Appeal to loyalty",
      "Appeal to motive",
      "Appeal to nature",
      "Appeal to novelty",
      "Appeal to pity",
      "Appeal to ridicule",
      "Appeal to spite",
      "Appeal to the law",
      "Appeal to the stone",
      "Appeal to tradition",
      "Argument (disambiguation)",
      "Argument form",
      "Argument from analogy",
      "Argument from anecdote",
      "Argument from authority",
      "Argument from fallacy",
      "Argument from silence",
      "Argument map",
      "Argument mining",
      "Argument scheme",
      "Argument to moderation",
      "Argumentation",
      "Argumentation scheme",
      "Argumentum ad baculum",
      "Argumentum ad crumenam",
      "Argumentum ad lazarum",
      "Argumentum ad populum",
      "Arity"
    ],
    "categories": [
      "Category:All articles with dead external links",
      "Category:All articles with unsourced statements",
      "Category:Arguments",
      "Category:Articles with Internet Encyclopedia of Philosophy links",
      "Category:Articles with dead external links from June 2022",
      "Category:Articles with permanently dead external links",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from September 2023",
      "Category:Commons category link is on Wikidata",
      "Category:Critical thinking skills"
    ]
  },
  "Antecedent (logic)": {
    "title": "Antecedent (logic)",
    "url": "https://en.wikipedia.org/wiki/Antecedent_(logic)",
    "summary": "An antecedent is the first half of a hypothetical proposition, whenever the if-clause precedes the then-clause. In some contexts the antecedent is called the protasis.\nExamples:\n\nIf \n  \n    \n      \n        P\n      \n    \n    {\\displaystyle P}\n  \n, then \n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n  \n.\nThis is a nonlogical formulation of a hypothetical proposition. In this case, the antecedent is P, and the consequent is Q. In the implication \"\n  \n    \n      \n        ϕ\n      \n    \n    {\\displaystyle \\phi }\n  \n implies \n  \n    \n      \n        ψ\n      \n    \n    {\\displaystyle \\psi }\n  \n\", \n  \n    \n      \n        ϕ\n      \n    \n    {\\displaystyle \\phi }\n  \n is called the antecedent and \n  \n    \n      \n        ψ\n      \n    \n    {\\displaystyle \\psi }\n  \n is called the consequent. Antecedent and consequent are connected via logical connective to form a proposition. \n\nIf \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is a man, then \n  \n    \n      \n        X\n      ",
    "content": "An antecedent is the first half of a hypothetical proposition, whenever the if-clause precedes the then-clause. In some contexts the antecedent is called the protasis.\nExamples:\n\nIf \n  \n    \n      \n        P\n      \n    \n    {\\displaystyle P}\n  \n, then \n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n  \n.\nThis is a nonlogical formulation of a hypothetical proposition. In this case, the antecedent is P, and the consequent is Q. In the implication \"\n  \n    \n      \n        ϕ\n      \n    \n    {\\displaystyle \\phi }\n  \n implies \n  \n    \n      \n        ψ\n      \n    \n    {\\displaystyle \\psi }\n  \n\", \n  \n    \n      \n        ϕ\n      \n    \n    {\\displaystyle \\phi }\n  \n is called the antecedent and \n  \n    \n      \n        ψ\n      \n    \n    {\\displaystyle \\psi }\n  \n is called the consequent. Antecedent and consequent are connected via logical connective to form a proposition. \n\nIf \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is a man, then \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is mortal.\n\"\n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is a man\" is the antecedent for this proposition while \"\n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is mortal\" is the consequent of the proposition.\n\nIf men have walked on the Moon, then I am the king of France.\nHere, \"men have walked on the Moon\" is the antecedent and \"I am the king of France\" is the consequent.\nLet \n  \n    \n      \n        y\n        =\n        x\n        +\n        1\n      \n    \n    {\\displaystyle y=x+1}\n  \n.\n\nIf \n  \n    \n      \n        x\n        =\n        1\n      \n    \n    {\\displaystyle x=1}\n  \n then \n  \n    \n      \n        y\n        =\n        2\n      \n    \n    {\\displaystyle y=2}\n  \n,.\n\"\n  \n    \n      \n        x\n        =\n        1\n      \n    \n    {\\displaystyle x=1}\n  \n\" is the antecedent and \"\n  \n    \n      \n        y\n        =\n        2\n      \n    \n    {\\displaystyle y=2}\n  \n\" is the consequent of this hypothetical proposition.\n\nSee also\nConsequent\nAffirming the consequent (fallacy)\nDenying the antecedent (fallacy)\nNecessity and sufficiency\n\n\n== References ==",
    "links": [
      "Affirming the consequent",
      "Conditional sentence",
      "Consequent",
      "Denying the antecedent",
      "Hypothetical",
      "Logic",
      "Logical connective",
      "Material conditional",
      "Necessity and sufficiency",
      "Proposition",
      "Statement (logic)",
      "Wikipedia:Stub",
      "Template:Logic-stub",
      "Template talk:Logic-stub"
    ],
    "categories": [
      "Category:All stub articles",
      "Category:Articles with short description",
      "Category:Conditionals",
      "Category:Logic stubs",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Automatic theorem prover": {
    "title": "Automated theorem proving",
    "url": "https://en.wikipedia.org/wiki/Automated_theorem_proving",
    "summary": "Automated theorem proving (also known as ATP or automated deduction) is a subfield of automated reasoning and mathematical logic dealing with proving mathematical theorems by computer programs. Automated reasoning over mathematical proof was a major motivating factor for the development of computer science.",
    "content": "Automated theorem proving (also known as ATP or automated deduction) is a subfield of automated reasoning and mathematical logic dealing with proving mathematical theorems by computer programs. Automated reasoning over mathematical proof was a major motivating factor for the development of computer science.\n\nLogical foundations\nWhile the roots of formalized logic go back to Aristotle, the end of the 19th and early 20th centuries saw the development of modern logic and formalized mathematics. Frege's Begriffsschrift (1879) introduced both a complete propositional calculus and what is essentially modern predicate logic. His Foundations of Arithmetic, published in 1884, expressed (parts of) mathematics in formal logic. This approach was continued by Russell and Whitehead in their influential Principia Mathematica, first published 1910–1913, and with a revised second edition in 1927. Russell and Whitehead thought they could derive all mathematical truth using axioms and inference rules of formal logic, in principle opening up the process to automation. In 1920, Thoralf Skolem simplified a previous result by Leopold Löwenheim, leading to the Löwenheim–Skolem theorem and, in 1930, to the notion of a Herbrand universe and a Herbrand interpretation that allowed (un)satisfiability of first-order formulas (and hence the validity of a theorem) to be reduced to (potentially infinitely many) propositional satisfiability problems.\nIn 1929, Mojżesz Presburger showed that the first-order theory of the natural numbers with addition and equality (now called Presburger arithmetic in his honor) is decidable and gave an algorithm that could determine if a given sentence in the language was true or false.\nHowever, shortly after this positive result, Kurt Gödel published On Formally Undecidable Propositions of Principia Mathematica and Related Systems (1931), showing that in any sufficiently strong axiomatic system, there are true statements that cannot be proved in the system. This topic was further developed in the 1930s by Alonzo Church and Alan Turing, who on the one hand gave two independent but equivalent definitions of computability, and on the other gave concrete examples of undecidable questions.\n\nFirst implementations\nIn 1954, Martin Davis programmed Presburger's algorithm for a JOHNNIAC vacuum-tube computer at the Institute for Advanced Study in Princeton, New Jersey. According to Davis, \"Its great triumph was to prove that the sum of two even numbers is even\". More ambitious was the Logic Theorist in 1956, a deduction system for the propositional logic of the Principia Mathematica, developed by Allen Newell, Herbert A. Simon and J. C. Shaw. Also running on a JOHNNIAC, the Logic Theorist constructed proofs from a small set of propositional axioms and three deduction rules: modus ponens, (propositional) variable substitution, and the replacement of formulas by their definition. The system used heuristic guidance, and managed to prove 38 of the first 52 theorems of the Principia.\nThe \"heuristic\" approach of the Logic Theorist tried to emulate human mathematicians, and could not guarantee that a proof could be found for every valid theorem even in principle. In contrast, other, more systematic algorithms achieved, at least theoretically, completeness for first-order logic. Initial approaches relied on the results of Herbrand and Skolem to convert a first-order formula into successively larger sets of propositional formulae by instantiating variables with terms from the Herbrand universe. The propositional formulas could then be checked for unsatisfiability using a number of methods. Gilmore's program used conversion to disjunctive normal form, a form in which the satisfiability of a formula is obvious.\n\nDecidability of the problem\nDepending on the underlying logic, the problem of deciding the validity of a formula varies from trivial to impossible. For the common case of propositional logic, the problem is decidable but co-NP-complete, and hence only exponential-time algorithms are believed to exist for general proof tasks. For a first-order predicate calculus, Gödel's completeness theorem states that the theorems (provable statements) are exactly the semantically valid well-formed formulas, so the valid formulas are computably enumerable: given unbounded resources, any valid formula can eventually be proven. However, invalid formulas (those that are not entailed by a given theory), cannot always be recognized.\nThe above applies to first-order theories, such as Peano arithmetic. However, for a specific model that may be described by a first-order theory, some statements may be true but undecidable in the theory used to describe the model. For example, by Gödel's incompleteness theorem, we know that any consistent theory whose axioms are true for the natural numbers cannot prove all first-order statements true for the natural numbers, even if the list of axioms is allowed to be infinite enumerable. It follows that an autom",
    "links": [
      "ACL2",
      "ACM Transactions on Programming Languages and Systems",
      "AMD",
      "Abstract logic",
      "Ackermann set theory",
      "Ada (programming language)",
      "Alan Turing",
      "Aleph number",
      "Alfred North Whitehead",
      "Algebraic logic",
      "Allen Newell",
      "Alonzo Church",
      "Alphabet (formal languages)",
      "Alt-Ergo",
      "Andrei Voronkov",
      "Andrei Voronkov (scientist)",
      "Argonne National Laboratory",
      "Argument",
      "Aristotelian logic",
      "Arity",
      "Atomic formula",
      "Atomic sentence",
      "Automata theory",
      "Automated reasoning",
      "Automath",
      "Axiom",
      "Axiom of choice",
      "Axiom schema",
      "Axiomatic system",
      "Axiomatization of Boolean algebras",
      "BSD Licenses",
      "Baden-Württemberg Cooperative State University",
      "Banach–Tarski paradox",
      "Begriffsschrift",
      "Benchmark (computing)",
      "Bertrand Russell",
      "Bijection",
      "Binary decision diagram",
      "Binary operation",
      "Boolean algebra",
      "Boolean algebras canonically defined",
      "Boolean function",
      "CADE ATP System Competition",
      "CARINE",
      "CVC (theorem prover)",
      "Cantor's diagonal argument",
      "Cantor's paradox",
      "Cantor's theorem",
      "Cardinality",
      "Cartesian product"
    ],
    "categories": [
      "Category:All articles needing additional references",
      "Category:All articles with unsourced statements",
      "Category:All pages needing cleanup",
      "Category:Articles needing additional references from April 2010",
      "Category:Articles needing cleanup from December 2023",
      "Category:Articles with sections that need to be turned into prose from December 2023",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from December 2023",
      "Category:Articles with unsourced statements from September 2020",
      "Category:Automated theorem proving"
    ]
  },
  "Argumentation theory": {
    "title": "Argumentation theory",
    "url": "https://en.wikipedia.org/wiki/Argumentation_theory",
    "summary": "Argumentation theory is the interdisciplinary study of how conclusions can be supported or undermined by premises through logical reasoning. With historical origins in logic, dialectic, and rhetoric, argumentation theory includes the arts and sciences of civil debate, dialogue, conversation, and persuasion. It studies rules of inference, logic, and procedural rules in both artificial and real-world settings.\nArgumentation includes various forms of dialogue such as deliberation and negotiation which are concerned with collaborative decision-making procedures. It also encompasses eristic dialogue, the branch of social debate in which victory over an opponent is the primary goal, and didactic dialogue used for teaching. This discipline also studies the means by which people can express and rationally resolve or at least manage their disagreements.\nArgumentation is a daily occurrence, such as in public debate, science, and law. For example in law, in courts by the judge, the parties and th",
    "content": "Argumentation theory is the interdisciplinary study of how conclusions can be supported or undermined by premises through logical reasoning. With historical origins in logic, dialectic, and rhetoric, argumentation theory includes the arts and sciences of civil debate, dialogue, conversation, and persuasion. It studies rules of inference, logic, and procedural rules in both artificial and real-world settings.\nArgumentation includes various forms of dialogue such as deliberation and negotiation which are concerned with collaborative decision-making procedures. It also encompasses eristic dialogue, the branch of social debate in which victory over an opponent is the primary goal, and didactic dialogue used for teaching. This discipline also studies the means by which people can express and rationally resolve or at least manage their disagreements.\nArgumentation is a daily occurrence, such as in public debate, science, and law. For example in law, in courts by the judge, the parties and the prosecutor, in presenting and testing the validity of evidences. Also, argumentation scholars study the post hoc rationalizations by which organizational actors try to justify decisions they have made irrationally.\nArgumentation is one of four rhetorical modes (also known as modes of discourse), along with exposition, description, and narration.\n\nKey components of argumentation\nSome key components of argumentation are:\n\nUnderstanding and identifying arguments, either explicit or implied, and the goals of the participants in the different types of dialogue.\nIdentifying the premises from which conclusions are derived.\nEstablishing the \"burden of proof\" – determining who made the initial claim and is thus responsible for providing evidence why their position merits acceptance.\nFor the one carrying the \"burden of proof\", the advocate, to marshal evidence for their position in order to convince or force the opponent's acceptance.  The method by which this is accomplished is producing valid, sound, and cogent arguments, devoid of weaknesses, and not easily attacked.\nIn a debate, fulfillment of the burden of proof creates a burden of rejoinder. One must try to identify faulty reasoning in the opponent's argument, to attack the reasons/premises of the argument, to provide counterexamples if possible, to identify any fallacies, and to show why a valid conclusion cannot be derived from the reasons provided for their argument.\nFor example, consider the following exchange, illustrating the No true Scotsman fallacy:\n\nArgument: \"No Scotsman puts sugar on his porridge.\"\nReply: \"But my friend Angus, who is a Scotsman, likes sugar with his porridge.\"\nRebuttal: \"Well perhaps, but no true Scotsman puts sugar on his porridge.\"\nIn this dialogue, the proposer first offers a premise, the premise is challenged by the interlocutor, and so the proposer offers a modification of the premise, which is designed only to evade the challenge provided.\n\nInternal structure of arguments\nTypically an argument has an internal structure, comprising the following:\n\na set of assumptions or premises,\na method of reasoning or deduction, and\na conclusion or point.\nAn argument has one or more premises and one conclusion.\nOften classical logic is used as the method of reasoning so that the conclusion follows logically from the assumptions or support. One challenge is that if the set of assumptions is inconsistent then anything can follow logically from inconsistency. Therefore, it is common to insist that the set of assumptions be consistent. It is also good practice to require the set of assumptions to be the minimal set, with respect to set inclusion, necessary to infer the consequent.  Such arguments are called MINCON arguments, short for minimal consistent.  Such argumentation has been applied to the fields of law and medicine.\nA non-classical approach to argumentation investigates abstract arguments, where 'argument' is considered a primitive term, so no internal structure of arguments is taken into account.\n\nTypes of dialogue\nIn its most common form, argumentation involves an individual and an interlocutor or opponent engaged in dialogue, each contending differing positions and trying to persuade each other, but there are various types of dialogue:\n\nPersuasion dialogue aims to resolve conflicting points of view of different positions.\nNegotiation aims to resolve conflicts of interests by cooperation and dealmaking.\nInquiry aims to resolve general ignorance by the growth of knowledge.\nDeliberation aims to resolve a need to take action by reaching a decision.\nInformation seeking aims to reduce one party's ignorance by requesting information from another party that is in a position to know something.\nEristic aims to resolve a situation of antagonism through verbal fighting.\n\nArgumentation and the grounds of knowledge\nArgumentation theory had its origins in foundationalism, a theory of knowledge (epistemology) in the field of philosophy. It sought to find the grounds ",
    "links": [
      "A Dialogue Concerning Oratorical Partitions",
      "A General Rhetoric",
      "Abductive reasoning",
      "Absolutists",
      "Ad nauseam",
      "Adam Smith",
      "Aelius Aristides",
      "Aeschines",
      "Aesthetic interpretation",
      "Alfred North Whitehead",
      "Ambiguity",
      "Analytic philosophy",
      "Analytic–synthetic distinction",
      "Ancient Indian rhetoric",
      "Antecedent (logic)",
      "Antinomy",
      "Antiphon (orator)",
      "Apologetics",
      "Appellate court",
      "ArXiv (identifier)",
      "Argument",
      "Argument map",
      "Argument mapping",
      "Argument mining",
      "Argument technology",
      "Argumentation framework",
      "Argumentation scheme",
      "Argumentum a fortiori",
      "Aristotelian rhetoric",
      "Aristotle",
      "Ars dictaminis",
      "Artificial intelligence",
      "Asiatic style",
      "Aspasia",
      "Attic orators",
      "Atticism",
      "Augustine of Hippo",
      "Axiom of Choice",
      "BERT (language model)",
      "Ballot box",
      "Barrister",
      "Begriffsschrift",
      "Bertrand Russell",
      "Biological evolution",
      "Byzantine rhetoric",
      "Calliope",
      "Captatio benevolentiae",
      "Case law",
      "Charles Arthur Willard",
      "Chatbot"
    ],
    "categories": [
      "Category:All articles needing additional references",
      "Category:All articles with unsourced statements",
      "Category:Articles needing additional references from June 2023",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from April 2020",
      "Category:Articles with unsourced statements from December 2021",
      "Category:CS1 errors: ISBN date",
      "Category:CS1 errors: missing periodical",
      "Category:Debating",
      "Category:Informal arguments"
    ]
  },
  "Action theory (philosophy)": {
    "title": "Action theory (philosophy)",
    "url": "https://en.wikipedia.org/wiki/Action_theory_(philosophy)",
    "summary": "Action theory or theory of action is an area in philosophy concerned with theories about the processes causing willful human bodily movements of a more or less complex kind. This area of thought involves epistemology, ethics, metaphysics, jurisprudence, and philosophy of mind, and has attracted the strong interest of philosophers ever since Aristotle's Nicomachean Ethics (Third Book). With the advent of psychology and later neuroscience, many theories of action are now subject to empirical testing.\nPhilosophical action theory, or the philosophy of action, should not be confused with sociological theories of social action, such as the action theory established by Talcott Parsons.  Nor should it be confused with activity theory.",
    "content": "Action theory or theory of action is an area in philosophy concerned with theories about the processes causing willful human bodily movements of a more or less complex kind. This area of thought involves epistemology, ethics, metaphysics, jurisprudence, and philosophy of mind, and has attracted the strong interest of philosophers ever since Aristotle's Nicomachean Ethics (Third Book). With the advent of psychology and later neuroscience, many theories of action are now subject to empirical testing.\nPhilosophical action theory, or the philosophy of action, should not be confused with sociological theories of social action, such as the action theory established by Talcott Parsons.  Nor should it be confused with activity theory.\n\nOverview\nBasic action theory typically describes action as intentional behavior caused by an agent in a particular situation. The agent's desires and beliefs (e.g. a person wanting a glass of water and believing that the clear liquid in the cup in front of them is water) lead to bodily behavior (e.g. reaching across for the glass). In the simple theory (see Donald Davidson), the desire and belief jointly cause the action. Michael Bratman has raised problems for such a view and argued that we should take the concept of intention as basic and not analyzable into beliefs and desires.\nAristotle held that a thorough explanation must give an account of both the efficient cause, the agent, and the final cause, the intention.\nIn some theories a desire plus a belief about the means of satisfying that desire are always what is behind an action. Agents aim, in acting, to maximize the satisfaction of their desires. Such a theory of prospective rationality underlies much of economics and other social sciences within the more sophisticated framework of rational choice. However, many theories of action argue that rationality extends far beyond calculating the best means to achieve one's ends. For instance, a belief that I ought to do X, in some theories, can directly cause me to do X without my having to want to do X (i.e. have a desire to do X). Rationality, in such theories, also involves responding correctly to the reasons an agent perceives, not just acting on wants.\nWhile action theorists generally employ the language of causality in their theories of what the nature of action is, the issue of what causal determination comes to has been central to controversies about the nature of free will.\nConceptual discussions also revolve around a precise definition of action in philosophy. Scholars may disagree on which bodily movements fall under this category, e.g. whether thinking should be analysed as action, and how complex actions involving several steps to be taken and diverse intended consequences are to be summarised or decomposed.\n\nSee also\nPraxeology\nFree will\nHumeanism § Theory of action\nCybernetics\n\nReferences\nFurther reading\nMaurice Blondel (1893). L'Action - Essai d'une critique de la vie et d'une science de la pratique\nG. E. M. Anscombe (1957). Intention, Basil Blackwell, Oxford.\nJames Sommerville (1968). Total Commitment, Blondel's L'Action, Corpus Books.\nMichel Crozier, & Erhard Friedberg (1980). Actors and Systems Chicago: [University of Chicago Press].\nDonald Davidson (1980). Essays on Actions and Events, Clarendon Press, Oxford.\nJonathan Dancy & Constantine Sandis (eds.) (2015). Philosophy of Action: An Anthology, Wiley-Blackwell, Oxford.\nJennifer Hornsby (1980). Actions, Routledge, London.\nLilian O'Brien (2014). Philosophy of Action, Palgrave, Basingstoke.\nChristine Korsgaard (2008). The Constitution of Agency, Oxford University Press, Oxford.\nAlfred R. Mele (ed.) (1997). The Philosophy of Action, Oxford University Press, Oxford.\nJohn Hyman & Helen Steward (eds.) (2004). Agency and Action, Cambridge University Press, Cambridge.\nAnton Leist (ed.) (2007). Action in Context, Walter de Gruyter, Berlin.\nTimothy O'Connor & Constantine Sandis (eds.) (2010). A Companion to the Philosophy of Action, Wiley-Blackwell, Oxford.\nSarah Paul (2020). The Philosophy of Action: A Contemporary Introduction, London, Routledge.\nPeter Šajda et al. (eds.) (2012). Affectivity, Agency and Intersubjectivity, L'Harmattan, Paris.\nConstantine Sandis (ed.) (2009). New Essays on the Explanation of Action, Palgrave Macmillan, Basingstoke.\nConstantine Sandis (ed.) (2019). Philosophy of Action from Suarez to Anscombe, London, Routledge.\nMichael Thompson (2012). Life and Action: Elementary Structures of Practice and Practical Thought, Boston, MA, Harvard University Press.\nLawrence H. Davis (1979). Theory of Action, Prentice-Hall, (Foundations of Philosophy Series), Englewood Cliffs, NJ.\n\nExternal links\nZalta, Edward N. (ed.). \"Action\". Stanford Encyclopedia of Philosophy.\n\"Thomas Reid's Theory of Action\". Internet Encyclopedia of Philosophy.",
    "links": [
      "A Treatise Concerning the Principles of Human Knowledge",
      "Abhidharma",
      "Absolute idealism",
      "Abstract and concrete",
      "Abstract object theory",
      "Academic Skepticism",
      "Achintya Bheda Abheda",
      "Action (philosophy)",
      "Action theory (sociology)",
      "Activity theory",
      "Advaita Vedanta",
      "Aesthetic emotions",
      "Aesthetics",
      "African philosophy",
      "Africana philosophy",
      "Agency (philosophy)",
      "Agency (psychology)",
      "Agency (sociology)",
      "Agriculturalism",
      "Ajñana",
      "Al-Ghazali",
      "Al-Kindi",
      "Al-Nijat",
      "Alexius Meinong",
      "Alfred North Whitehead",
      "Alvin Plantinga",
      "American philosophy",
      "Analytic philosophy",
      "Analytical Marxism",
      "Analytical feminism",
      "Anarchism",
      "Ancient Egyptian philosophy",
      "Ancient Greek philosophy",
      "Ancient Roman philosophy",
      "Ancient philosophy",
      "Anekantavada",
      "Anima mundi",
      "Anti-realism",
      "Antihumanism",
      "Applied ethics",
      "Applied philosophy",
      "Aristotelianism",
      "Aristotle",
      "Arthur Schopenhauer",
      "Atomism",
      "Augustinianism",
      "Australian philosophy",
      "Averroes",
      "Averroism",
      "Avicenna"
    ],
    "categories": [
      "Category:Action (philosophy)",
      "Category:All articles lacking in-text citations",
      "Category:Articles lacking in-text citations from February 2018",
      "Category:Articles with Internet Encyclopedia of Philosophy links",
      "Category:Articles with short description",
      "Category:Epistemological theories",
      "Category:Free will",
      "Category:Metaphysics of mind",
      "Category:Neuroscience",
      "Category:Ontology"
    ]
  },
  "Adjacency matrix": {
    "title": "Adjacency matrix",
    "url": "https://en.wikipedia.org/wiki/Adjacency_matrix",
    "summary": "In graph theory and computer science, an adjacency matrix is a square matrix used to represent a finite graph. The elements of the matrix indicate whether pairs of vertices are adjacent or not within the graph.\nIn the special case of a finite simple graph, the adjacency matrix is a (0,1)-matrix with zeros on its diagonal. If the graph is undirected (i.e. all of its edges are bidirectional), the adjacency matrix is symmetric. \nThe relationship between a graph and the eigenvalues and eigenvectors of its adjacency matrix is studied in spectral graph theory.\nThe adjacency matrix of a graph should be distinguished from its incidence matrix, a different matrix representation whose elements indicate whether vertex–edge pairs are incident or not, and its degree matrix, which contains information about the degree of each vertex.",
    "content": "In graph theory and computer science, an adjacency matrix is a square matrix used to represent a finite graph. The elements of the matrix indicate whether pairs of vertices are adjacent or not within the graph.\nIn the special case of a finite simple graph, the adjacency matrix is a (0,1)-matrix with zeros on its diagonal. If the graph is undirected (i.e. all of its edges are bidirectional), the adjacency matrix is symmetric. \nThe relationship between a graph and the eigenvalues and eigenvectors of its adjacency matrix is studied in spectral graph theory.\nThe adjacency matrix of a graph should be distinguished from its incidence matrix, a different matrix representation whose elements indicate whether vertex–edge pairs are incident or not, and its degree matrix, which contains information about the degree of each vertex.\n\nDefinition\nFor a simple graph with vertex set U = {u1, ..., un}, the adjacency matrix is a square n × n matrix A such that its element Aij is 1 when there is an edge from vertex ui to vertex uj, and 0 when there is no edge. The diagonal elements of the matrix are all 0, since edges from a vertex to itself (loops) are not allowed in simple graphs. It is also sometimes useful in algebraic graph theory to replace the nonzero elements with algebraic variables. The same concept can be extended to multigraphs and graphs with loops by storing the number of edges between each two vertices in the corresponding matrix element, and by allowing nonzero diagonal elements. Loops may be counted either once (as a single edge) or twice (as two vertex-edge incidences), as long as a consistent convention is followed. Undirected graphs often use the latter convention of counting loops twice, whereas directed graphs typically use the former convention.\n\nOf a bipartite graph\nThe adjacency matrix A of a bipartite graph whose two parts have r and s vertices can be written in the form \n\n  \n    \n      \n        A\n        =\n        \n          \n            (\n            \n              \n                \n                  \n                    0\n                    \n                      r\n                      ,\n                      r\n                    \n                  \n                \n                \n                  B\n                \n              \n              \n                \n                  \n                    B\n                    \n                      \n                        T\n                      \n                    \n                  \n                \n                \n                  \n                    0\n                    \n                      s\n                      ,\n                      s\n                    \n                  \n                \n              \n            \n            )\n          \n        \n        ,\n      \n    \n    {\\displaystyle A={\\begin{pmatrix}0_{r,r}&B\\\\B^{\\mathsf {T}}&0_{s,s}\\end{pmatrix}},}\n  \n\nwhere B is an r × s matrix, and 0r,r and 0s,s represent the r × r and s × s zero matrices. In this case, the smaller matrix B uniquely represents the graph, and the remaining parts of A can be discarded as redundant. B is sometimes called the biadjacency matrix.\nFormally, let G = (U, V, E) be a bipartite graph with parts U = {u1, ..., ur}, V = {v1, ..., vs} and edges E. The biadjacency matrix is the r × s 0–1 matrix B in which bi,j = 1 if and only if (ui, vj) ∈ E.\nIf G is a bipartite multigraph or weighted graph, then the elements bi,j are taken to be the number of edges between the vertices or the weight of the edge (ui, vj), respectively.\n\nVariations\nAn (a, b, c)-adjacency matrix A of a simple graph has Ai,j = a if (i, j) is an edge, b if it is not, and c on the diagonal. The Seidel adjacency matrix is a (−1, 1, 0)-adjacency matrix. This matrix is used in studying strongly regular graphs and two-graphs.\nThe distance matrix has in position (i, j) the distance between vertices vi and vj. The distance is the length of a shortest path connecting the vertices. Unless lengths of edges are explicitly provided, the length of a path is the number of edges in it. The distance matrix resembles a high power of the adjacency matrix, but instead of telling only whether or not two vertices are connected (i.e., the connection matrix, which contains Boolean values), it gives the exact distance between them.\n\nExamples\nUndirected graphs\nThe convention followed here (for undirected graphs) is that each edge adds 1 to the appropriate cell in the matrix, and each loop (an edge from a vertex to itself) adds 2 to the appropriate cell on the diagonal in the matrix. This allows the degree of a vertex to be easily found by taking the sum of the values in either its respective row or column in the adjacency matrix.\n\nDirected graphs\nThe adjacency matrix of a directed graph can be asymmetric. One can define the adjacency matrix of a directed graph either such that \n\na non-zero element Aij indicates an edge from i to j or\nit indicates an edge from j to i.\nThe former definition is commonly used in gr",
    "links": [
      "(0,1)-matrix",
      "Adjacency list",
      "Adjugate matrix",
      "Algebraic graph theory",
      "Alternant matrix",
      "Alternating sign matrix",
      "Anti-diagonal matrix",
      "Array data structure",
      "Arrowhead matrix",
      "Augmented matrix",
      "Band matrix",
      "Base64",
      "Biadjacency matrix",
      "Bibcode (identifier)",
      "Bidiagonal matrix",
      "Bipartite graph",
      "Bisymmetric matrix",
      "Block-diagonal matrix",
      "Block matrix",
      "Block tridiagonal matrix",
      "Boolean algebra",
      "Boolean matrix",
      "Brendan McKay (mathematician)",
      "Bézout matrix",
      "Cabibbo–Kobayashi–Maskawa matrix",
      "Carleman matrix",
      "Cartan matrix",
      "Cauchy matrix",
      "Cayley graph",
      "Centering matrix",
      "Centrosymmetric matrix",
      "Characteristic polynomial",
      "Charles E. Leiserson",
      "Circulant matrix",
      "Clifford Stein",
      "Cofactor matrix",
      "Commutation matrix",
      "Companion matrix",
      "Complete graph",
      "Complex Hadamard matrix",
      "Computer science",
      "Conference matrix",
      "Confusion matrix",
      "Connectivity (graph theory)",
      "Convergent matrix",
      "Copositive matrix",
      "Correlation matrix",
      "Covariance matrix",
      "Coxeter matrix",
      "DFT matrix"
    ],
    "categories": [
      "Category:Algebraic graph theory",
      "Category:Articles with short description",
      "Category:Commons category link from Wikidata",
      "Category:Graph data structures",
      "Category:Matrices (mathematics)",
      "Category:Short description matches Wikidata"
    ]
  },
  "Algebraic graph theory": {
    "title": "Algebraic graph theory",
    "url": "https://en.wikipedia.org/wiki/Algebraic_graph_theory",
    "summary": "Algebraic graph theory is a branch of mathematics in which algebraic methods are applied to problems about graphs. This is in contrast to geometric, combinatoric, or algorithmic approaches.  There are three main branches of algebraic graph theory, involving the use of linear algebra, the use of group theory, and the study of graph invariants.",
    "content": "Algebraic graph theory is a branch of mathematics in which algebraic methods are applied to problems about graphs. This is in contrast to geometric, combinatoric, or algorithmic approaches.  There are three main branches of algebraic graph theory, involving the use of linear algebra, the use of group theory, and the study of graph invariants.\n\nBranches of algebraic graph theory\nUsing linear algebra\nThe first branch of algebraic graph theory involves the study of graphs in connection with linear algebra. Especially, it studies the spectrum of the adjacency matrix, or the Laplacian matrix of a graph (this part of algebraic graph theory is also called spectral graph theory).  For the Petersen graph, for example, the spectrum of the adjacency matrix is (−2, −2, −2, −2, 1, 1, 1, 1, 1, 3). Several theorems relate properties of the spectrum to other graph properties.  As a simple example, a connected graph with diameter D will have at least D+1 distinct values in its spectrum. Aspects of graph spectra have been used in analysing the synchronizability of networks.\n\nUsing group theory\nThe second branch of algebraic graph theory involves the study of graphs in connection to group theory, particularly automorphism groups and geometric group theory. The focus is placed on various families of graphs based on symmetry (such as symmetric graphs, vertex-transitive graphs, edge-transitive graphs, distance-transitive graphs, distance-regular graphs, and strongly regular graphs), and on the inclusion relationships between these families. Certain of such categories of graphs are sparse enough that lists of graphs can be drawn up. By Frucht's theorem, all groups can be represented as the automorphism group of a connected graph (indeed, of a cubic graph). Another connection with group theory is that, given any group, symmetrical graphs known as Cayley graphs can be generated, and these have properties related to the structure of the group.\n\nThis second branch of algebraic graph theory is related to the first, since the symmetry properties of a graph are reflected in its spectrum. In particular, the spectrum of a highly symmetrical graph, such as the Petersen graph, has few distinct values (the Petersen graph has 3, which is the minimum possible, given its diameter). For Cayley graphs, the spectrum can be related directly to the structure of the group, in particular to its irreducible characters.\n\nStudying graph invariants\nFinally, the third branch of algebraic graph theory concerns algebraic properties of invariants of graphs, and especially the chromatic polynomial, the Tutte polynomial and knot invariants. The chromatic polynomial of a graph, for example, counts the number of its proper vertex colorings.  For the Petersen graph, this polynomial is \n  \n    \n      \n        t\n        (\n        t\n        −\n        1\n        )\n        (\n        t\n        −\n        2\n        )\n        (\n        \n          t\n          \n            7\n          \n        \n        −\n        12\n        \n          t\n          \n            6\n          \n        \n        +\n        67\n        \n          t\n          \n            5\n          \n        \n        −\n        230\n        \n          t\n          \n            4\n          \n        \n        +\n        529\n        \n          t\n          \n            3\n          \n        \n        −\n        814\n        \n          t\n          \n            2\n          \n        \n        +\n        775\n        t\n        −\n        352\n        )\n      \n    \n    {\\displaystyle t(t-1)(t-2)(t^{7}-12t^{6}+67t^{5}-230t^{4}+529t^{3}-814t^{2}+775t-352)}\n  \n. In particular, this means that the Petersen graph cannot be properly colored with one or two colors, but can be colored in 120 different ways with 3 colors.  Much work in this area of algebraic graph theory was motivated by attempts to prove the four color theorem. However, there are still many open problems, such as characterizing graphs which have the same chromatic polynomial, and determining which polynomials are chromatic.\n\nSee also\nSpectral graph theory\nAlgebraic combinatorics\nAlgebraic connectivity\nDulmage–Mendelsohn decomposition\nGraph property\nAdjacency matrix\n\nReferences\nExternal links\n Media related to Algebraic graph theory at Wikimedia Commons",
    "links": [
      "Adjacency matrix",
      "Algebra",
      "Algebraic combinatorics",
      "Algebraic connectivity",
      "Algorithmic graph theory",
      "Alternating group",
      "Asymmetric graph",
      "Biregular graph",
      "Cayley graph",
      "Character theory",
      "Chris Godsil",
      "Chromatic polynomial",
      "Combinatorics",
      "Connectivity (graph theory)",
      "Cubic graph",
      "Diameter (graph theory)",
      "Distance-regular graph",
      "Distance-transitive graph",
      "Doi (identifier)",
      "Dulmage–Mendelsohn decomposition",
      "Edge-transitive graph",
      "Eigendecomposition of a matrix",
      "Foster census",
      "Four color theorem",
      "Frucht's theorem",
      "Geometric graph theory",
      "Geometric group theory",
      "Gordon Royle",
      "Graph (discrete mathematics)",
      "Graph automorphism",
      "Graph coloring",
      "Graph property",
      "Graph theory",
      "Group (mathematics)",
      "Group theory",
      "Half-transitive graph",
      "ISBN (identifier)",
      "Knot invariant",
      "Laplacian matrix",
      "Linear algebra",
      "Martin Grötschel",
      "Mathematics",
      "Network theory",
      "Petersen graph",
      "R. Frucht",
      "Regular graph",
      "Semi-symmetric graph",
      "Skew-symmetric graph",
      "Spectral graph theory",
      "Strongly regular graph"
    ],
    "categories": [
      "Category:Algebraic graph theory",
      "Category:Articles with short description",
      "Category:Commons category link from Wikidata",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Biological pathway": {
    "title": "Biological pathway",
    "url": "https://en.wikipedia.org/wiki/Biological_pathway",
    "summary": "In cell biology, a biological pathway is a series of interactions among molecules in a cell that leads to a certain product or a change in the cell. Such a pathway can trigger the assembly of new molecules, such as a fat or   protein. Pathways can also turn genes on and off, or spur a cell to move. Some of the most common biological pathways are involved in metabolism, the regulation of gene expression and the transmission of signals. Pathways play a key role in advanced studies of genomics.",
    "content": "In cell biology, a biological pathway is a series of interactions among molecules in a cell that leads to a certain product or a change in the cell. Such a pathway can trigger the assembly of new molecules, such as a fat or   protein. Pathways can also turn genes on and off, or spur a cell to move. Some of the most common biological pathways are involved in metabolism, the regulation of gene expression and the transmission of signals. Pathways play a key role in advanced studies of genomics.\n\nTypes of biological pathways\nMost common types of biological pathways:\n\nMetabolic pathway\nGenetic pathway\nSignal transduction pathway\n\nNeuroanatomy\nIn neuroanatomy, a neural pathway is the connection formed by axons that project from neurons to make synapses onto neurons in another location, to enable neurotransmission (the sending of a signal from one region of the nervous system to another).\n\nPathways databases\nKEGG Pathway database is a popular pathway search database highly used by biologists.\nWikiPathways is a community curated pathway database using the \"wiki\" concept. All pathways have an open license and can be freely used.\nReactome  is a free and manually curated online database of biological pathways.\nNCI-Nature Pathway Interaction Database is a free biomedical database of human cellular signaling pathways (new official name: NCI Nature Pathway Interaction Database: Pathway, synonym: PID).\nPhosphoSitePlus is a database of observed post-translational modifications in human and mouse proteins; an online systems biology resource providing comprehensive information and tools for the study of protein post-translational modifications (PTMs) including phosphorylation, ubiquitination, acetylation and methylation.\nBioCyc database collection is an assortment of organism specific Pathway/Genome Databases.\nHuman Protein Reference Database is a centralized platform to visually depict and integrate information pertaining to domain architecture, post-translational modifications, interaction networks and disease association for each protein in the human proteome (the last release was #9 in 2010).\nPANTHER (Protein ANalysis THrough Evolutionary Relationships) is a large curated biological database of gene/protein families and their functionally related subfamilies that can be used to classify and identify the function of gene products.\nTRANSFAC (TRANScription FACtor database) is a manually curated database of eukaryotic transcription factors, their genomic binding sites and DNA binding profiles (provided by geneXplain GmbH).\nMiRTarBase is a curated database of MicroRNA-Target Interactions.\nDrugBank is a comprehensive, high-quality, freely accessible, online database containing information on drugs and drug targets.\nesyN is a network viewer and builder that allows to import pathways from the biomodels database or from biogrid, flybase pombase and see what drugs interact with the proteins in your network.\nComparative Toxicogenomics Database (CTD) is a public website and research tool that curates scientific data describing relationships between chemicals/drugs, genes/proteins, diseases, taxa, phenotypes, GO annotations, pathways, and interaction modules; CTD illuminates how environmental chemicals affect human health.\nPathway Commons is a project and database that uses BioPAX language to convert, integrate and query other biological pathway and interaction databases.\n\nSee also\nProteostasis\nCysteine metabolism\nPathway analysis\n\n\n== Sources ==",
    "links": [
      "Axons",
      "BioCyc database collection",
      "BioPAX",
      "Cell (biology)",
      "Cell biology",
      "Cell signaling",
      "Comparative Toxicogenomics Database",
      "Cysteine metabolism",
      "DrugBank",
      "EsyN",
      "Fat",
      "Gene",
      "Genetic pathway",
      "Genomics",
      "Human Protein Reference Database",
      "ISBN (identifier)",
      "KEGG",
      "Metabolic pathway",
      "Metabolism",
      "MiRTarBase",
      "NCI-Nature Pathway Interaction Database",
      "Neural pathway",
      "Neurons",
      "Neurotransmission",
      "PANTHER",
      "Pathway Commons",
      "Pathway analysis",
      "PhosphoSitePlus",
      "Protein",
      "Proteostasis",
      "Reactome",
      "Regulation of gene expression",
      "Signal transduction pathway",
      "Synapses",
      "Systems biology",
      "TRANSFAC",
      "WikiPathways"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Molecular biology",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Chemical graph theory": {
    "title": "Chemical graph theory",
    "url": "https://en.wikipedia.org/wiki/Chemical_graph_theory",
    "summary": "Chemical graph theory is the topology branch of mathematical chemistry which applies graph theory to mathematical modelling of chemical phenomena.\nThe pioneers of chemical graph theory are Alexandru Balaban, Ante Graovac, Iván Gutman, Haruo Hosoya, Milan Randić and Nenad Trinajstić (also Harry Wiener and others).\nIn 1988, it was reported that several hundred researchers worked in this area, producing about 500 articles annually. A number of monographs have been written in the area, including the two-volume comprehensive text by Trinajstić, Chemical Graph Theory, that summarized the field up to mid-1980s.\nThe adherents of the theory maintain that the properties of a chemical graph (i.e., a graph-theoretical representation of a molecule) give valuable insights into the chemical phenomena. Others contend that graphs play only a fringe role in chemical research. One variant of the theory is the representation of materials as infinite Euclidean graphs, particularly crystals by periodic grap",
    "content": "Chemical graph theory is the topology branch of mathematical chemistry which applies graph theory to mathematical modelling of chemical phenomena.\nThe pioneers of chemical graph theory are Alexandru Balaban, Ante Graovac, Iván Gutman, Haruo Hosoya, Milan Randić and Nenad Trinajstić (also Harry Wiener and others).\nIn 1988, it was reported that several hundred researchers worked in this area, producing about 500 articles annually. A number of monographs have been written in the area, including the two-volume comprehensive text by Trinajstić, Chemical Graph Theory, that summarized the field up to mid-1980s.\nThe adherents of the theory maintain that the properties of a chemical graph (i.e., a graph-theoretical representation of a molecule) give valuable insights into the chemical phenomena. Others contend that graphs play only a fringe role in chemical research. One variant of the theory is the representation of materials as infinite Euclidean graphs, particularly crystals by periodic graphs.\n\nSee also\nChemical graph generator\nMolecule mining\nMATH/CHEM/COMP\nTopological index\n\n\n== References ==",
    "links": [
      "Alexandru Balaban",
      "Ante Graovac",
      "Chemical graph",
      "Chemical graph generator",
      "Euclidean graph",
      "Graph theory",
      "Handbook of Combinatorics",
      "Haruo Hosoya",
      "ISBN (identifier)",
      "Iván Gutman",
      "László Lovász",
      "MATH/CHEM/COMP",
      "Martin Grötschel",
      "Mathematical chemistry",
      "Mathematical modelling",
      "Milan Randić",
      "Molecule",
      "Molecule mining",
      "Nenad Trinajstić",
      "Periodic Graphs (Crystallography)",
      "Ronald Graham",
      "SIAM Review",
      "Theoretical chemistry",
      "Topological index",
      "Topology (chemistry)",
      "Wayback Machine",
      "Wiener index",
      "Wikipedia:Stub",
      "Template:Theoretical-chem-stub",
      "Template talk:Theoretical-chem-stub"
    ],
    "categories": [
      "Category:All stub articles",
      "Category:Application-specific graphs",
      "Category:Articles with short description",
      "Category:Mathematical chemistry",
      "Category:Short description matches Wikidata",
      "Category:Theoretical chemistry",
      "Category:Theoretical chemistry stubs",
      "Category:Webarchive template wayback links"
    ]
  },
  "Circle packing theorem": {
    "title": "Circle packing theorem",
    "url": "https://en.wikipedia.org/wiki/Circle_packing_theorem",
    "summary": "The circle packing theorem (also known as the Koebe–Andreev–Thurston theorem) describes the possible tangency relations between circles in the plane whose interiors are disjoint.   A circle packing is a connected collection of circles (in general, on any Riemann surface) whose interiors are disjoint. The intersection graph of a circle packing is the graph having a vertex for each circle, and an edge for every pair of circles that are tangent. If the circle packing is on the plane, or, equivalently, on the sphere, then its intersection graph is called a coin graph; more generally, intersection graphs of interior-disjoint geometric objects are called tangency graphs or contact graphs. Coin graphs are always connected, simple, and planar. The circle packing theorem states that these are the only requirements for a graph to be a coin graph:\nCircle packing theorem: For every finite connected simple planar graph G there is a circle packing in the plane whose intersection graph is (isomorphic",
    "content": "The circle packing theorem (also known as the Koebe–Andreev–Thurston theorem) describes the possible tangency relations between circles in the plane whose interiors are disjoint.   A circle packing is a connected collection of circles (in general, on any Riemann surface) whose interiors are disjoint. The intersection graph of a circle packing is the graph having a vertex for each circle, and an edge for every pair of circles that are tangent. If the circle packing is on the plane, or, equivalently, on the sphere, then its intersection graph is called a coin graph; more generally, intersection graphs of interior-disjoint geometric objects are called tangency graphs or contact graphs. Coin graphs are always connected, simple, and planar. The circle packing theorem states that these are the only requirements for a graph to be a coin graph:\nCircle packing theorem: For every finite connected simple planar graph G there is a circle packing in the plane whose intersection graph is (isomorphic to) G.\n\nUniqueness\nA maximal planar graph G is a finite simple planar graph to which no more edges can be added while preserving planarity. Such a graph always has a unique planar embedding, in which every face of the embedding (including the outer face) is a triangle. In other words, every maximal planar graph G is the 1-skeleton of a simplicial complex which is homeomorphic to the sphere.  The circle packing theorem guarantees the existence of a circle packing with finitely many circles whose intersection graph is isomorphic to G.  As the following theorem states more formally, every maximal planar graph can have at most one packing.\nKoebe–Andreev–Thurston theorem: If G is a finite maximal planar graph, then the circle packing whose tangency graph is isomorphic to G is unique, up to Möbius transformations and reflections in lines.\nThurston observes that this uniqueness is a consequence of the Mostow rigidity theorem. To see this, let G be represented by a circle packing. Then the plane in which the circles are packed may be viewed as the boundary of a halfspace model for three-dimensional hyperbolic space; with this view, each circle is the boundary of a plane within the hyperbolic space. One can define a set of disjoint planes in this way from the circles of the packing, and a second set of disjoint planes defined by the circles that circumscribe each triangular gap between three of the circles in the packing. These two sets of planes meet at right angles, and form the generators of a reflection group whose fundamental domain can be viewed as a hyperbolic manifold. By Mostow rigidity, the hyperbolic structure of this domain is uniquely determined, up to isometry of the hyperbolic space; these isometries, when viewed in terms of their actions on the Euclidean plane on the boundary of the half-plane model, translate to Möbius transformations.\nThere is also a more elementary proof of the same uniqueness property, based on existence of a maximum value in any finite set and on the observation that, in the triangle connecting the centers of three mutually tangent circles, the angle formed at the center of one of the circles is monotone decreasing in its radius and monotone increasing in the two other radii. Given two packings for the same graph \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n, one may apply reflections and Möbius transformations to make the outer circles in these two packings correspond to each other and have the same radii. Then, let \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n  \n be an interior vertex of \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n for which the circles in the two packings have sizes that are as far apart as possible: that is, choose \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n  \n to maximize the ratio \n  \n    \n      \n        \n          r\n          \n            1\n          \n        \n        \n          /\n        \n        \n          r\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle r_{1}/r_{2}}\n  \n of the radii of its circles in the two packings. For each triangular face of \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n containing \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n  \n, it follows that the angle at the center of the circle for \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n  \n in the first packing is less than or equal to the angle in the second packing, with equality possible only when the other two circles forming the triangle have the same ratio \n  \n    \n      \n        \n          r\n          \n            1\n          \n        \n        \n          /\n        \n        \n          r\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle r_{1}/r_{2}}\n  \n of radii in the two packings. But the sum of the angles of all of these triangles surrounding the center of the triangle must be \n  \n    \n      \n        2\n        π\n      \n    \n    {",
    "links": [
      "Angle",
      "Angular resolution (graph drawing)",
      "Ann. Probab.",
      "Apollonian gasket",
      "Apollonian sphere packing",
      "ArXiv (identifier)",
      "Arnold Emch",
      "Bernhard Riemann",
      "Bibcode (identifier)",
      "Bin packing problem",
      "Bojan Mohar",
      "Brouwer fixed point theorem",
      "Burton Rodin",
      "Circle packing",
      "Circle packing in a circle",
      "Circle packing in a square",
      "Circle packing in an equilateral triangle",
      "Circle packing in an isosceles right triangle",
      "Circumscribed circle",
      "CiteSeerX (identifier)",
      "Close-packing of equal spheres",
      "Compact space",
      "Computational Geometry (journal)",
      "Conformal map",
      "Connectivity (graph theory)",
      "Contact graph",
      "Continuous function",
      "Convex function",
      "Convex polyhedron",
      "Conway puzzle",
      "Cover time",
      "Curvature",
      "Dennis Sullivan",
      "Dirichlet problem",
      "Disk (mathematics)",
      "Doi (identifier)",
      "Doyle spiral",
      "Dual graph",
      "E. M. Andreev",
      "Ed Scheinerman",
      "Edge (graph theory)",
      "Eigenvalue",
      "Ellipsoid packing",
      "End (graph theory)",
      "Finite sphere packing",
      "Fixed point (mathematics)",
      "Ford circle",
      "Fundamental domain",
      "Fáry's theorem",
      "Gary Miller (professor)"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1 French-language sources (fr)",
      "Category:Circle packing",
      "Category:Short description is different from Wikidata",
      "Category:Statements about planar graphs",
      "Category:Theorems about circles",
      "Category:Use mdy dates from August 2024"
    ]
  },
  "Asymptotic analysis": {
    "title": "Asymptotic analysis",
    "url": "https://en.wikipedia.org/wiki/Asymptotic_analysis",
    "summary": "In mathematical analysis, asymptotic analysis, also known as asymptotics, is a method of describing limiting behavior.\nAs an illustration, suppose that we are interested in the properties of a function f (n) as n becomes very large. If f(n) = n2 + 3n, then as n becomes very large, the term 3n becomes insignificant compared to n2. The function f(n) is said to be \"asymptotically equivalent to n2, as n → ∞\". This is often written symbolically as f (n) ~ n2, which is read as \"f(n) is asymptotic to n2\".\nAn example of an important asymptotic result is the prime number theorem. Let π(x) denote the prime-counting function (which is not directly related to the constant pi), i.e. π(x) is the number of prime numbers that are less than or equal to x. Then the theorem states that\n\n  \n    \n      \n        π\n        (\n        x\n        )\n        ∼\n        \n          \n            x\n            \n              ln\n              ⁡\n              x\n            \n          \n        \n        .\n      \n    \n    {",
    "content": "In mathematical analysis, asymptotic analysis, also known as asymptotics, is a method of describing limiting behavior.\nAs an illustration, suppose that we are interested in the properties of a function f (n) as n becomes very large. If f(n) = n2 + 3n, then as n becomes very large, the term 3n becomes insignificant compared to n2. The function f(n) is said to be \"asymptotically equivalent to n2, as n → ∞\". This is often written symbolically as f (n) ~ n2, which is read as \"f(n) is asymptotic to n2\".\nAn example of an important asymptotic result is the prime number theorem. Let π(x) denote the prime-counting function (which is not directly related to the constant pi), i.e. π(x) is the number of prime numbers that are less than or equal to x. Then the theorem states that\n\n  \n    \n      \n        π\n        (\n        x\n        )\n        ∼\n        \n          \n            x\n            \n              ln\n              ⁡\n              x\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\pi (x)\\sim {\\frac {x}{\\ln x}}.}\n\nDefinition\nFormally, given functions f (x) and g(x), we define a binary relation\n\n  \n    \n      \n        f\n        (\n        x\n        )\n        ∼\n        g\n        (\n        x\n        )\n        \n        (\n        \n          as \n        \n        x\n        →\n        ∞\n        )\n      \n    \n    {\\displaystyle f(x)\\sim g(x)\\quad ({\\text{as }}x\\to \\infty )}\n  \n\nif and only if (de Bruijn 1981, §1.4)\n\n  \n    \n      \n        \n          lim\n          \n            x\n            →\n            ∞\n          \n        \n        \n          \n            \n              f\n              (\n              x\n              )\n            \n            \n              g\n              (\n              x\n              )\n            \n          \n        \n        =\n        1.\n      \n    \n    {\\displaystyle \\lim _{x\\to \\infty }{\\frac {f(x)}{g(x)}}=1.}\n  \n\nThe symbol ~ is the tilde. The relation is an equivalence relation on the set of functions of x; the functions f and g are said to be asymptotically equivalent. The domain of f and g can be any set for which the limit is defined: e.g. real numbers, complex numbers, positive integers.\nThe same notation is also used for other ways of passing to a limit: e.g. x → 0, x ↓ 0, |x| → 0. The way of passing to the limit is often not stated explicitly, if it is clear from the context.\nAlthough the above definition is common in the literature, it is problematic if g(x) is zero infinitely often as x goes to the limiting value. For that reason, some authors use an alternative definition. The alternative definition, in little-o notation, is that f ~ g if and only if\n\n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        g\n        (\n        x\n        )\n        (\n        1\n        +\n        o\n        (\n        1\n        )\n        )\n        .\n      \n    \n    {\\displaystyle f(x)=g(x)(1+o(1)).}\n  \n\nThis definition is equivalent to the prior definition if g(x) is not zero in some neighbourhood of the limiting value.\n\nProperties\nIf \n  \n    \n      \n        f\n        ∼\n        g\n      \n    \n    {\\displaystyle f\\sim g}\n  \n and \n  \n    \n      \n        a\n        ∼\n        b\n      \n    \n    {\\displaystyle a\\sim b}\n  \n, then, under some mild conditions, the following hold:\n\n  \n    \n      \n        \n          f\n          \n            r\n          \n        \n        ∼\n        \n          g\n          \n            r\n          \n        \n      \n    \n    {\\displaystyle f^{r}\\sim g^{r}}\n  \n, for every real r\n\n  \n    \n      \n        log\n        ⁡\n        (\n        f\n        )\n        ∼\n        log\n        ⁡\n        (\n        g\n        )\n      \n    \n    {\\displaystyle \\log(f)\\sim \\log(g)}\n  \n if \n  \n    \n      \n        lim\n        g\n        ≠\n        1\n      \n    \n    {\\displaystyle \\lim g\\neq 1}\n  \n\n  \n    \n      \n        f\n        ×\n        a\n        ∼\n        g\n        ×\n        b\n      \n    \n    {\\displaystyle f\\times a\\sim g\\times b}\n  \n\n  \n    \n      \n        f\n        \n          /\n        \n        a\n        ∼\n        g\n        \n          /\n        \n        b\n      \n    \n    {\\displaystyle f/a\\sim g/b}\n  \n\nSuch properties allow asymptotically equivalent functions to be freely exchanged in many algebraic expressions.\nAlso, if we further have \n  \n    \n      \n        g\n        ∼\n        h\n      \n    \n    {\\displaystyle g\\sim h}\n  \n, then, because the asymptote is a transitive relation, then we also have \n  \n    \n      \n        f\n        ∼\n        h\n      \n    \n    {\\displaystyle f\\sim h}\n  \n.\n\nExamples of asymptotic formulas\nFactorial \n  \n    \n      \n        n\n        !\n        ∼\n        \n          \n            2\n            π\n            n\n          \n        \n        \n          \n            (\n            \n              \n                n\n                e\n              \n            \n            )\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle n!\\sim {\\sqrt {2\\pi n}}\\left({\\frac {n}{e}}\\right)^{n}}\n  \n —this is Stirling's approximation\nPartition ",
    "links": [
      "Abuse of notation",
      "Accident analysis",
      "Airy function",
      "American Mathematical Society",
      "Analysis of algorithms",
      "Applied mathematics",
      "Approximation theory",
      "Asymptote",
      "Asymptotic",
      "Asymptotic computational complexity",
      "Asymptotic density",
      "Asymptotic distribution",
      "Asymptotic expansion",
      "Asymptotic scale",
      "Asymptotic theory (statistics)",
      "Asymptotology",
      "Big O notation",
      "Binary relation",
      "Birkhäuser",
      "Boundary layer",
      "Cambridge University Press",
      "Complex plane",
      "Computer science",
      "Deviance (statistics)",
      "Dimensional analysis",
      "Domain of a function",
      "Double factorial",
      "Dover Publications",
      "Edgeworth series",
      "Encyclopedia of Mathematics",
      "Equation",
      "Equivalence relation",
      "Error function",
      "European Mathematical Society",
      "Expected value",
      "Exponential integral",
      "Factorial",
      "Feynman graphs",
      "Formal power series",
      "Gamma function",
      "Geometry",
      "Hankel functions",
      "IOS Press",
      "ISBN (identifier)",
      "If and only if",
      "Laplace's method",
      "Leading-order term",
      "Length scale",
      "Likelihood-ratio test",
      "Limit (mathematics)"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Asymptotic analysis",
      "Category:Pages displaying short descriptions of redirect targets via Module:Annotated link",
      "Category:Series (mathematics)",
      "Category:Short description is different from Wikidata",
      "Category:Wikipedia articles needing clarification from July 2021"
    ]
  },
  "Bijective proof": {
    "title": "Bijective proof",
    "url": "https://en.wikipedia.org/wiki/Bijective_proof",
    "summary": "In combinatorics, bijective proof is a proof technique for proving that two sets have equally many elements, or that the sets in two combinatorial classes have equal size, by finding a bijective function that maps one set one-to-one onto the other. This technique can be useful as a way of finding a formula for the number of elements of certain sets, by corresponding them with other sets that are easier to count. Additionally, the nature of the bijection itself often provides powerful insights into each or both of the sets.",
    "content": "In combinatorics, bijective proof is a proof technique for proving that two sets have equally many elements, or that the sets in two combinatorial classes have equal size, by finding a bijective function that maps one set one-to-one onto the other. This technique can be useful as a way of finding a formula for the number of elements of certain sets, by corresponding them with other sets that are easier to count. Additionally, the nature of the bijection itself often provides powerful insights into each or both of the sets.\n\nBasic examples\nProving the symmetry of the binomial coefficients\nThe symmetry of the binomial coefficients states that\n\n  \n    \n      \n        \n          \n            \n              (\n            \n            \n              n\n              k\n            \n            \n              )\n            \n          \n        \n        =\n        \n          \n            \n              (\n            \n            \n              n\n              \n                n\n                −\n                k\n              \n            \n            \n              )\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle {n \\choose k}={n \\choose n-k}.}\n  \n\nThis means that there are exactly as many combinations of k things in a set of size n as there are combinations of n − k things in a set of size n.\nThe key idea of the bijective proof may be understood from a simple example: selecting k children to be rewarded with ice cream cones, out of a group of n children, has exactly the same effect as choosing instead the n − k children to be denied ice cream cones.\n\nOther examples\nProblems that admit bijective proofs are not limited to binomial coefficient identities. As the complexity of the problem increases, a bijective proof can become very sophisticated. This technique is particularly useful in areas of discrete mathematics such as combinatorics, graph theory, and number theory.\nThe most classical examples of bijective proofs in combinatorics include:\n\nPrüfer sequence, giving a proof of Cayley's formula for the number of labeled trees.\nRobinson-Schensted algorithm, giving a proof of Burnside's formula for the symmetric group.\nConjugation of Young diagrams, giving a proof of a classical result on the number of certain integer partitions.\nBijective proofs of the pentagonal number theorem.\nBijective proofs of the formula for the Catalan numbers.\n\nSee also\nBinomial theorem\nSchröder–Bernstein theorem\nDouble counting (proof technique)\nCombinatorial principles\nCombinatorial proof\nCategorification\n\nReferences\nFurther reading\nLoehr, Nicholas A. (2011).  Bijective Combinatorics.  CRC Press.  ISBN 143984884X,  ISBN 978-1439848845.\n\nExternal links\n\"Division by three\" – by Doyle and Conway.\n\"A direct bijective proof of the hook-length formula\" –  by Novelli, Pak and Stoyanovsky.\n\"Bijective census and random generation of Eulerian planar maps with prescribed vertex degrees\" –  by Gilles Schaeffer.\n\"Kathy O'Hara's Constructive Proof of the Unimodality of the Gaussian Polynomials\" – by Doron Zeilberger.\n\"Partition Bijections, a Survey\" – by Igor Pak.\nGarsia-Milne Involution Principle – from MathWorld.",
    "links": [
      "Bijective function",
      "Binomial theorem",
      "Catalan number",
      "Categorification",
      "Cayley's formula",
      "Combination",
      "Combinatorial class",
      "Combinatorial principles",
      "Combinatorial proof",
      "Combinatorics",
      "Discrete mathematics",
      "Doron Zeilberger",
      "Double counting (proof technique)",
      "Graph theory",
      "ISBN (identifier)",
      "Igor Pak",
      "Integer partition",
      "John Horton Conway",
      "Labeled tree",
      "MathWorld",
      "Mathematical proof",
      "Number theory",
      "Pentagonal number theorem",
      "Prüfer sequence",
      "Robinson-Schensted algorithm",
      "Schröder–Bernstein theorem",
      "Symmetric group",
      "William Burnside",
      "Young diagram"
    ],
    "categories": [
      "Category:Articles containing proofs",
      "Category:Articles with short description",
      "Category:Enumerative combinatorics",
      "Category:Mathematical proofs",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Boolean algebras": {
    "title": "Boolean algebra (structure)",
    "url": "https://en.wikipedia.org/wiki/Boolean_algebra_(structure)",
    "summary": "In abstract algebra, a Boolean algebra or Boolean lattice is a complemented distributive lattice. This type of algebraic structure captures essential properties of both set operations and logic operations. A Boolean algebra can be seen as a generalization of a power set algebra or a field of sets, or its elements can be viewed as generalized truth values. It is also a special case of a De Morgan algebra and a Kleene algebra (with involution).\nEvery Boolean algebra gives rise to a Boolean ring, and vice versa, with ring multiplication corresponding to conjunction or meet ∧, and ring addition to exclusive disjunction or symmetric difference (not disjunction ∨). However, the theory of Boolean rings has an inherent asymmetry between the two operators, while the axioms and theorems of Boolean algebra express the symmetry of the theory described by the duality principle.",
    "content": "In abstract algebra, a Boolean algebra or Boolean lattice is a complemented distributive lattice. This type of algebraic structure captures essential properties of both set operations and logic operations. A Boolean algebra can be seen as a generalization of a power set algebra or a field of sets, or its elements can be viewed as generalized truth values. It is also a special case of a De Morgan algebra and a Kleene algebra (with involution).\nEvery Boolean algebra gives rise to a Boolean ring, and vice versa, with ring multiplication corresponding to conjunction or meet ∧, and ring addition to exclusive disjunction or symmetric difference (not disjunction ∨). However, the theory of Boolean rings has an inherent asymmetry between the two operators, while the axioms and theorems of Boolean algebra express the symmetry of the theory described by the duality principle.\n\nHistory\nThe term \"Boolean algebra\" honors George Boole (1815–1864), a self-educated English mathematician. He introduced the algebraic system initially in a small pamphlet, The Mathematical Analysis of Logic, published in 1847 in response to an ongoing public controversy between Augustus De Morgan and William Hamilton, and later as a more substantial book, The Laws of Thought, published in 1854. Boole's formulation differs from that described above in some important respects. For example, conjunction and disjunction in Boole were not a dual pair of operations. Boolean algebra emerged in the 1860s, in papers written by William Jevons and Charles Sanders Peirce. The first systematic presentation of Boolean algebra and distributive lattices is owed to the 1890 Vorlesungen of Ernst Schröder. The first extensive treatment of Boolean algebra in English is A. N. Whitehead's 1898 Universal Algebra. Boolean algebra as an axiomatic algebraic structure in the modern axiomatic sense begins with a 1904 paper by Edward V. Huntington. Boolean algebra came of age as serious mathematics with the work of Marshall Stone in the 1930s, and with Garrett Birkhoff's 1940 Lattice Theory. In the 1960s, Paul Cohen, Dana Scott, and others found deep new results in mathematical logic and axiomatic set theory using offshoots of Boolean algebra, namely forcing and Boolean-valued models.\n\nDefinition\nA Boolean algebra is a set A, equipped with two binary operations ∧ (called \"meet\" or \"and\"), ∨ (called \"join\" or \"or\"), a unary operation ¬ (called \"complement\" or \"not\") and two elements 0 and 1 in A (called \"bottom\" and \"top\", or \"least\" and \"greatest\" element, also denoted by the symbols ⊥ and ⊤, respectively), such that for all elements a, b and c of A, the following axioms hold:\n\nNote, however, that the absorption law and even the associativity law can be excluded from the set of axioms as they can be derived from the other axioms (see Proven properties).\nA Boolean algebra with only one element is called a trivial Boolean algebra or a degenerate Boolean algebra. (In older works, some authors required 0 and 1 to be distinct elements in order to exclude this case.)\nIt follows from the last three pairs of axioms above (identity, distributivity and complements), or from the absorption axiom, that\n\na = b ∧ a     if and only if     a ∨ b = b.\nThe relation ≤ defined by a ≤ b if these equivalent conditions hold, is a partial order with least element 0 and greatest element 1. The meet a ∧ b and the join a ∨ b of two elements coincide with their infimum and supremum, respectively, with respect to ≤.\nThe first four pairs of axioms constitute a definition of a bounded lattice.\nIt follows from the first five pairs of axioms that any complement is unique.\nThe set of axioms is self-dual in the sense that if one exchanges ∨ with ∧ and 0 with 1 in an axiom, the result is again an axiom. Therefore, by applying this operation to a Boolean algebra (or Boolean lattice), one obtains another Boolean algebra with the same elements; it is called its dual.\n\nExamples\nThe simplest non-trivial Boolean algebra, the two-element Boolean algebra, has only two elements, 0 and 1, and is defined by the rules:\n\nIt has applications in logic, interpreting 0 as false, 1 as true, ∧ as and, ∨ as or, and ¬ as not. Expressions involving variables and the Boolean operations represent statement forms, and two such expressions can be shown to be equal using the above axioms if and only if the corresponding statement forms are logically equivalent.\nThe two-element Boolean algebra is also used for circuit design in electrical engineering; here 0 and 1 represent the two different states of one bit in a digital circuit, typically high and low voltage. Circuits are described by expressions containing variables, and two such expressions are equal for all values of the variables if and only if the corresponding circuits have the same input–output behavior. Furthermore, every possible input–output behavior can be modeled by a suitable Boolean expression.\nThe two-element Boolean algebra is also important in the general theory of B",
    "links": [
      "2-valued morphism",
      "A.N. Whitehead",
      "A. N. Whitehead",
      "Abelian group",
      "Absorption law",
      "Abstract algebra",
      "Abstract rewriting system",
      "Alexandrov topology",
      "Alfred North Whitehead",
      "Alfred Tarski",
      "Algebra of sets",
      "Algebra over a field",
      "Algebraic structure",
      "Algebraic system",
      "Antichain",
      "Antisymmetric relation",
      "Argonne National Laboratory",
      "Artificial Intelligence (journal)",
      "Associative algebra",
      "Associativity",
      "Asymmetric relation",
      "Augustus De Morgan",
      "Automated theorem proving",
      "Axiom",
      "Axiom of choice",
      "Axiomatic set theory",
      "Banach lattice",
      "Better-quasi-ordering",
      "Bialgebra",
      "Bijection",
      "Binary operation",
      "Binary relation",
      "Bit",
      "Boolean-valued function",
      "Boolean-valued model",
      "Boolean algebra",
      "Boolean algebras canonically defined",
      "Boolean domain",
      "Boolean function",
      "Boolean logic",
      "Boolean prime ideal theorem",
      "Boolean ring",
      "Bounded lattice",
      "Brute force search",
      "Canonical form (Boolean algebra)",
      "Cantor's isomorphism theorem",
      "Cantor–Bernstein theorem",
      "Category theory",
      "Central idempotent",
      "Chain-complete partial order"
    ],
    "categories": [
      "Category:Algebraic structures",
      "Category:All articles lacking in-text citations",
      "Category:All articles with unsourced statements",
      "Category:Articles lacking in-text citations from July 2013",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from July 2020",
      "Category:Boolean algebra",
      "Category:CS1 errors: ISBN date",
      "Category:Ockham algebras",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Cauchy's theorem (geometry)": {
    "title": "Cauchy's theorem (geometry)",
    "url": "https://en.wikipedia.org/wiki/Cauchy%27s_theorem_(geometry)",
    "summary": "Cauchy's theorem is a theorem in geometry, named after Augustin Cauchy. It states that \nconvex polytopes in three dimensions with congruent corresponding faces must be congruent to each other. That is, any polyhedral net formed by unfolding the faces of the polyhedron onto a flat surface, together with gluing instructions describing which faces should be connected to each other, uniquely determines the shape of the original polyhedron. For instance, if six squares are connected in the pattern of a cube, then they must form a cube: there is no convex polyhedron with six square faces connected in the same way that does not have the same shape.\nThis is a fundamental result in rigidity theory: one consequence of the theorem is that, if one makes a physical model of a convex polyhedron by connecting together rigid plates for each of the polyhedron faces with flexible hinges along the polyhedron edges, then this ensemble of plates and hinges will necessarily form a rigid structure.",
    "content": "Cauchy's theorem is a theorem in geometry, named after Augustin Cauchy. It states that \nconvex polytopes in three dimensions with congruent corresponding faces must be congruent to each other. That is, any polyhedral net formed by unfolding the faces of the polyhedron onto a flat surface, together with gluing instructions describing which faces should be connected to each other, uniquely determines the shape of the original polyhedron. For instance, if six squares are connected in the pattern of a cube, then they must form a cube: there is no convex polyhedron with six square faces connected in the same way that does not have the same shape.\nThis is a fundamental result in rigidity theory: one consequence of the theorem is that, if one makes a physical model of a convex polyhedron by connecting together rigid plates for each of the polyhedron faces with flexible hinges along the polyhedron edges, then this ensemble of plates and hinges will necessarily form a rigid structure.\n\nStatement\nLet P and Q be combinatorially equivalent 3-dimensional convex polytopes; that is, they are convex polytopes with isomorphic face lattices.  Suppose further that each pair of corresponding faces from P and Q are congruent to each other, i.e. equal up to a rigid motion.  Then P and Q are themselves congruent.\nTo see that convexity is necessary, consider a regular icosahedron. One can \"push in\" a vertex to create a nonconvex polyhedron that is still combinatorially equivalent to the regular icosahedron; that is, one can take five faces of the icosahedron meeting at a vertex, which form the sides of a pentagonal pyramid, and reflect the pyramid with respect to its base.\n\nHistory\nThe result originated in Euclid's Elements, where solids are called equal if the same holds for their faces.  This version of the result was proved by Cauchy in 1813 based on earlier work by Lagrange. An error in Cauchy's proof of the main lemma was corrected by Ernst Steinitz, Isaac Jacob Schoenberg, and Aleksandr Danilovich Aleksandrov. The corrected proof of Cauchy is so short and elegant, that it is considered to be one of the Proofs from THE BOOK.\n\nGeneralizations and related results\nThe result does not hold on a plane or for non-convex polyhedra in \n  \n    \n      \n        \n          \n            R\n          \n          \n            3\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{3}}\n  \n: there exist non-convex flexible polyhedra that have one or more degrees of freedom of movement that preserve the shapes of their faces. In particular, the Bricard octahedra are self-intersecting flexible surfaces discovered by a French mathematician Raoul Bricard in 1897. The Connelly sphere, a flexible non-convex polyhedron homeomorphic to a 2-sphere, was discovered by Robert Connelly in 1977.\nAlthough originally proven by Cauchy in three dimensions, the theorem was extended to dimensions higher than 3 by Alexandrov (1950).\nCauchy's rigidity theorem is a corollary from Cauchy's theorem stating that a convex polytope cannot be deformed so that its faces remain rigid.\nIn 1974, Herman Gluck showed that in a certain precise sense almost all simply connected closed surfaces are rigid.\nDehn's rigidity theorem is an extension of the Cauchy rigidity theorem to infinitesimal rigidity.  This result was obtained by Dehn in 1916.\nAlexandrov's uniqueness theorem is a result by Alexandrov (1950), generalizing Cauchy's theorem by showing that convex polyhedra are uniquely described by the metric spaces of geodesics on their surface. The analogous uniqueness theorem for smooth surfaces was proved by Cohn-Vossen in 1927. Pogorelov's uniqueness theorem is a result by Pogorelov generalizing both of these results and applying to general convex surfaces.\n\nSee also\nSchönhardt polyhedron\n\nReferences\n\nA. L. Cauchy, \"Recherche sur les polyèdres – premier mémoire\", Journal de l'École Polytechnique 9 (1813), 66–86.\nMax Dehn, \"Über die Starrheit konvexer Polyeder\" (in German), Math. Ann. 77 (1916), 466–473.\nAleksandr Danilovich Aleksandrov, Convex polyhedra, GTI, Moscow, 1950.  English translation:  Springer, Berlin, 2005.\nJames J. Stoker, \"Geometrical problems concerning polyhedra in the large\", Comm. Pure Appl. Math. 21 (1968), 119–168.\nRobert Connelly, \"Rigidity\", in Handbook of Convex Geometry, vol. A, 223–271, North-Holland, Amsterdam, 1993.",
    "links": [
      "Aleksandr Danilovich Aleksandrov",
      "Aleksei Pogorelov",
      "Alexandrov's uniqueness theorem",
      "Augustin-Louis Cauchy",
      "Bricard octahedron",
      "Closed surface",
      "Communications on Pure and Applied Mathematics",
      "Congruence (geometry)",
      "Convex Polyhedra (book)",
      "Convex polyhedron",
      "Convex polytope",
      "Doi (identifier)",
      "English language",
      "Ernst Steinitz",
      "Euclid",
      "Euclid's Elements",
      "Face lattice",
      "Flexible polyhedra",
      "Geodesic",
      "Geometry",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "Icosahedron",
      "Isaac Jacob Schoenberg",
      "JSTOR (identifier)",
      "James J. Stoker",
      "Joseph Louis Lagrange",
      "Max Dehn",
      "Metric space",
      "Net (polyhedron)",
      "Pentagonal pyramid",
      "Proofs from THE BOOK",
      "Raoul Bricard",
      "Regular icosahedron",
      "Rigidity theory (structural)",
      "Robert Connelly",
      "S2CID (identifier)",
      "Schönhardt polyhedron",
      "Simply connected space",
      "Stefan Cohn-Vossen"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Augustin-Louis Cauchy",
      "Category:Euclidean geometry",
      "Category:Mathematics of rigidity",
      "Category:Polytopes",
      "Category:Short description is different from Wikidata",
      "Category:Theorems about polyhedron",
      "Category:Theorems in convex geometry",
      "Category:Theorems in discrete geometry"
    ]
  },
  "Abraham ibn Ezra": {
    "title": "Abraham ibn Ezra",
    "url": "https://en.wikipedia.org/wiki/Abraham_ibn_Ezra",
    "summary": "Abraham ben Meir Ibn Ezra (Hebrew: ר׳ אַבְרָהָם בֶּן מֵאִיר אִבְּן עֶזְרָא, romanized: ʾAḇrāhām ben Mēʾir ʾiḇən ʾEzrāʾ, often abbreviated as ראב״ע; Arabic: إبراهيم المجيد ابن عزرا Ibrāhim al-Mājid ibn Ezra; also known as Abenezra or simply ibn Ezra, 1089 / 1092 – 27 January 1164 / 23 January 1167) was one of the most distinguished Jewish biblical commentators and philosophers of the Middle Ages. He was born in Tudela, Taifa of Zaragoza (now Navarre).",
    "content": "Abraham ben Meir Ibn Ezra (Hebrew: ר׳ אַבְרָהָם בֶּן מֵאִיר אִבְּן עֶזְרָא, romanized: ʾAḇrāhām ben Mēʾir ʾiḇən ʾEzrāʾ, often abbreviated as ראב״ע; Arabic: إبراهيم المجيد ابن عزرا Ibrāhim al-Mājid ibn Ezra; also known as Abenezra or simply ibn Ezra, 1089 / 1092 – 27 January 1164 / 23 January 1167) was one of the most distinguished Jewish biblical commentators and philosophers of the Middle Ages. He was born in Tudela, Taifa of Zaragoza (now Navarre).\n\nBiography\nAbraham Ibn Ezra was born in Tudela, one of the oldest and most important Jewish communities in Navarre. At the time, the town was under the rule of the emirs of the Muslim Taifa of Zaragoza. However, when he later moved to Córdoba, he claimed it was his birthplace. Ultimately, most scholars agree that his place of birth was Tudela.\nFrom outside sources, little is known of ibn Ezra's family; however, he wrote of a marriage to a wife who produced five children. While it is believed four died early, the last-born, Isaac, became an influential poet and a later convert to Islam in 1140. His son's conversion was deeply troubling for ibn Ezra, leading him to pen many poems reacting to the event for years afterward.\nIbn Ezra was a close friend of Judah Halevi, who was approximately 14 years older. When ibn Ezra moved to Córdoba as a young man, Halevi followed him. This trend continued when the two began their lives as wanderers in 1137. Halevi died in 1141, but Ibn Ezra continued travelling for three decades, reaching as far as Baghdad. During his travels, he composed secular poetry of the lands he traveled through and rationalist Torah commentaries (for which he would be best remembered).\nHe appears to have been unrelated to the contemporary scholar Moses ibn Ezra.\n\nWorks\nIn Spain, Ibn Ezra had already gained the reputation of a distinguished poet and thinker. However, apart from his poems, the vast majority of his work was composed after 1140. Written in Hebrew, as opposed to earlier thinkers' use of Judeo-Arabic, these works covering Hebrew grammar, Biblical exegesis, and scientific theory were tinged with the work of Arab scholars he had studied in Spain.\nBeginning many of his writings in Italy, Ibn Ezra also worked extensively to translate the works of grammarian and biblical exegetist Judah ben David Hayyuj from their original Judeo-Arabic to Hebrew. Published as early as 1140, these translations became some of the first expositions of Hebrew grammar to be written in Hebrew.\nWhile publishing translations, Ibn Ezra also began to publish biblical commentaries. Using many of the techniques outlined by Hayyuj, Ibn Ezra would publish his first biblical commentary on Ecclesiastes in 1140. He would continue to publish such commentaries over mainly works from Ketuvim and Nevi'im throughout his journey. He managed to publish a short commentary over the entire Pentateuch while living in Lucca in 1145. This brief commentary would be amended into more extended portions beginning in 1155 with the publication of his expanded commentary on Genesis.\nBesides his Torah commentaries, ibn Ezra also published many works in Hebrew on Islamic science. In doing so, he continued spreading the knowledge he had gained in Spain to the Jews throughout the areas he visited and lived. This can be seen particularly in the works he published while living in France. Many of the works he published relate to astrology and the use of the astrolabe.\n\nInfluence on biblical criticism and philosophy of religion\nIn his commentary, Ibn Ezra adhered to the literal sense of the texts, avoiding Rabbinic allegory and Kabbalistic interpretation. He exercised an independent criticism that, according to some writers, exhibits a marked tendency toward rationalism. In addition, he sharply criticized those who blended the simplistic and logical explanation with Midrash, maintaining that such interpretations were never intended to supplant the plain understanding.\n\nIndeed, Ibn Ezra is claimed by proponents of higher biblical criticism of the Torah as one of its earliest pioneers. Baruch Spinoza, in concluding that Moses did not author the Torah and that the Torah and other protocanonical books were written or redacted by somebody else, cites Ibn Ezra's commentary on Deuteronomy. In his commentary, ibn Ezra examines Deuteronomy 1:1 and expresses concern over the unusual phrasing that describes Moses as being \"beyond the Jordan.\" This wording suggests that the writer was situated in the land of Canaan, which is located west of the Jordan River, even though Moses and the Children of Israel had not yet crossed the Jordan at that point in the Biblical narrative. Relating this inconsistency to others in the Torah, Ibn Ezra stated, \"If you can grasp the mystery behind the following problematic passages: 1) The final twelve verses of this book [i.e., Deuteronomy 34:1–12, describing the death of Moses], 2) 'Moshe wrote [this song on the same day, and taught it to the children of Israel]' [Deuteronomy 31:22]; 3) '",
    "links": [
      "Aaron ben Jacob ha-Kohen",
      "Aaron of Canterbury",
      "Aaron of York",
      "Abba Mari",
      "Abenezra (crater)",
      "Abraham Isaac Kook",
      "Abraham Saba",
      "Abraham bar Hiyya",
      "Abraham ben David",
      "Abraham ben Isaac of Narbonne",
      "Abraham ben Joseph of Orleans",
      "Abraham ben Nathan",
      "Abraham ibn Daud",
      "Abraham of Montpellier",
      "Aharon HaLevi",
      "Alexander Suslin",
      "American Federation of Astrologers",
      "Anger in Judaism",
      "Arabic language",
      "Arabs",
      "Aristobulus of Alexandria",
      "Asher ben Jehiel",
      "Asher ben Meshullam",
      "Astrolabe",
      "Astrology",
      "Astrology in Judaism",
      "Austria",
      "Avempace",
      "Avigdor Cohen of Vienna",
      "Azriel of Gerona",
      "Baghdad",
      "Bahya ben Asher",
      "Bahya ibn Paquda",
      "Baruch Spinoza",
      "Baruch ben Isaac",
      "Benjamin ben Abraham Anaw",
      "Berechiah de Nicole",
      "Boethusians",
      "Book of Genesis",
      "Book of Isaiah",
      "Brethren of Purity",
      "Béziers",
      "Cabul",
      "Catalonia",
      "Chabad philosophy",
      "Chaim Paltiel",
      "Chambers Biographical Dictionary",
      "Chananel ben Chushiel",
      "Conservative Judaism",
      "Conversion to Islam"
    ],
    "categories": [
      "Category:1080s births",
      "Category:1167 deaths",
      "Category:12th-century rabbis in al-Andalus",
      "Category:All articles with unsourced statements",
      "Category:Articles containing Arabic-language text",
      "Category:Articles containing Hebrew-language text",
      "Category:Articles with hCards",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from December 2024",
      "Category:Astrologers from Al-Andalus"
    ]
  },
  "Catalan number": {
    "title": "Catalan number",
    "url": "https://en.wikipedia.org/wiki/Catalan_number",
    "summary": "The Catalan numbers are a sequence of natural numbers that occur in various counting problems, often involving recursively defined objects. They are named after Eugène Catalan, though they were previously discovered in the 1730s by Minggatu.\nThe n-th Catalan number can be expressed directly in terms of the central binomial coefficients by\n\n  \n    \n      \n        \n          C\n          \n            n\n          \n        \n        =\n        \n          \n            1\n            \n              n\n              +\n              1\n            \n          \n        \n        \n          \n            \n              (\n            \n            \n              \n                2\n                n\n              \n              n\n            \n            \n              )\n            \n          \n        \n        =\n        \n          \n            \n              (\n              2\n              n\n              )\n              !\n            \n            \n              (\n              n\n              +\n          ",
    "content": "The Catalan numbers are a sequence of natural numbers that occur in various counting problems, often involving recursively defined objects. They are named after Eugène Catalan, though they were previously discovered in the 1730s by Minggatu.\nThe n-th Catalan number can be expressed directly in terms of the central binomial coefficients by\n\n  \n    \n      \n        \n          C\n          \n            n\n          \n        \n        =\n        \n          \n            1\n            \n              n\n              +\n              1\n            \n          \n        \n        \n          \n            \n              (\n            \n            \n              \n                2\n                n\n              \n              n\n            \n            \n              )\n            \n          \n        \n        =\n        \n          \n            \n              (\n              2\n              n\n              )\n              !\n            \n            \n              (\n              n\n              +\n              1\n              )\n              !\n              \n              n\n              !\n            \n          \n        \n        \n        \n          for \n        \n        n\n        ≥\n        0.\n      \n    \n    {\\displaystyle C_{n}={\\frac {1}{n+1}}{2n \\choose n}={\\frac {(2n)!}{(n+1)!\\,n!}}\\qquad {\\text{for }}n\\geq 0.}\n  \n\nThe first Catalan numbers for n = 0, 1, 2, 3, ... are\n\n1, 1, 2, 5, 14, 42, 132, 429, 1430, 4862, 16796, 58786, ... (sequence A000108 in the OEIS).\n\nProperties\nAn alternative expression for Cn is\n\n  \n    \n      \n        \n          C\n          \n            n\n          \n        \n        =\n        \n          \n            \n              (\n            \n            \n              \n                2\n                n\n              \n              n\n            \n            \n              )\n            \n          \n        \n        −\n        \n          \n            \n              (\n            \n            \n              \n                2\n                n\n              \n              \n                n\n                +\n                1\n              \n            \n            \n              )\n            \n          \n        \n      \n    \n    {\\displaystyle C_{n}={2n \\choose n}-{2n \\choose n+1}}\n  \n for \n  \n    \n      \n        n\n        ≥\n        0\n        \n        ,\n      \n    \n    {\\displaystyle n\\geq 0\\,,}\n  \n\nwhich is equivalent to the expression given above because \n  \n    \n      \n        \n          \n            \n              \n                (\n              \n              \n                \n                  2\n                  n\n                \n                \n                  n\n                  +\n                  1\n                \n              \n              \n                )\n              \n            \n          \n        \n        =\n        \n          \n            \n              n\n              \n                n\n                +\n                1\n              \n            \n          \n        \n        \n          \n            \n              \n                (\n              \n              \n                \n                  2\n                  n\n                \n                n\n              \n              \n                )\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\tbinom {2n}{n+1}}={\\tfrac {n}{n+1}}{\\tbinom {2n}{n}}}\n  \n.  This expression shows that Cn is an integer, which is not immediately obvious from the first formula given.  This expression forms the basis for a proof of the correctness of the formula.\nAnother alternative expression is\n\n  \n    \n      \n        \n          C\n          \n            n\n          \n        \n        =\n        \n          \n            1\n            \n              2\n              n\n              +\n              1\n            \n          \n        \n        \n          \n            \n              (\n            \n            \n              \n                2\n                n\n                +\n                1\n              \n              n\n            \n            \n              )\n            \n          \n        \n        \n        ,\n      \n    \n    {\\displaystyle C_{n}={\\frac {1}{2n+1}}{2n+1 \\choose n}\\,,}\n  \n\nwhich can be directly interpreted in terms of the cycle lemma; see below.\nThe Catalan numbers satisfy the recurrence relations\n\n  \n    \n      \n        \n          C\n          \n            0\n          \n        \n        =\n        1\n        \n        \n          and\n        \n        \n        \n          C\n          \n            n\n          \n        \n        =\n        \n          ∑\n          \n            i\n            =\n            1\n          \n          \n            n\n          \n        \n        \n          C\n          \n            i\n            −\n            1\n          \n        \n        \n          C\n          \n            n\n            −\n            i\n          \n        \n        \n        \n          for \n        \n        n\n        >\n        0\n      \n    \n    {\\displaystyle C_{0}=1\\quad {\\text{and}}\\quad C_{n}=\\sum _{i=1}^{n}C_{i-1}C_{n-i}\\quad {\\",
    "links": [
      "A fortiori argument",
      "Abundant number",
      "Achilles number",
      "Additive persistence",
      "Aliquot sequence",
      "Almost perfect number",
      "Almost prime",
      "Amenable number",
      "American Mathematical Society",
      "Amicable numbers",
      "ArXiv (identifier)",
      "Arithmetic dynamics",
      "Arithmetic function",
      "Arithmetic number",
      "Aronson's sequence",
      "Associahedron",
      "Associativity",
      "Automorphic number",
      "Ban number",
      "Bell number",
      "Bertrand's ballot theorem",
      "Betrothed numbers",
      "Bibcode (identifier)",
      "Bijective proof",
      "Binary number",
      "Binary operator",
      "Binary tree",
      "Binomial series",
      "Binomial transform",
      "Blum integer",
      "Bracket",
      "Cake number",
      "Cambridge University Press",
      "Carmichael number",
      "Catalan's constant",
      "Catalan's triangle",
      "Catalan pseudoprime",
      "Catalan–Mersenne number",
      "Centered cube number",
      "Centered decagonal number",
      "Centered dodecahedral number",
      "Centered heptagonal number",
      "Centered hexagonal number",
      "Centered icosahedral number",
      "Centered nonagonal number",
      "Centered octagonal number",
      "Centered octahedral number",
      "Centered pentagonal number",
      "Centered polygonal number",
      "Centered polyhedral number"
    ],
    "categories": [
      "Category:All Wikipedia articles written in American English",
      "Category:Articles containing proofs",
      "Category:Articles with short description",
      "Category:Enumerative combinatorics",
      "Category:Eponymous numbers in mathematics",
      "Category:Factorial and binomial topics",
      "Category:Integer sequences",
      "Category:Short description matches Wikidata",
      "Category:Use American English from March 2019"
    ]
  },
  "Active-set method": {
    "title": "Active-set method",
    "url": "https://en.wikipedia.org/wiki/Active-set_method",
    "summary": "In mathematical optimization, the active-set method is an algorithm used to identify the active constraints in a set of inequality constraints. The active constraints are then expressed as equality constraints,  thereby transforming an inequality-constrained problem into a simpler equality-constrained subproblem.\nAn optimization problem is defined using an objective function to minimize or maximize, and a set of constraints\n\n  \n    \n      \n        \n          g\n          \n            1\n          \n        \n        (\n        x\n        )\n        ≥\n        0\n        ,\n        …\n        ,\n        \n          g\n          \n            k\n          \n        \n        (\n        x\n        )\n        ≥\n        0\n      \n    \n    {\\displaystyle g_{1}(x)\\geq 0,\\dots ,g_{k}(x)\\geq 0}\n  \n\nthat define the feasible region, that is, the set of all x to search for the optimal solution. Given a point \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n in the feasible region, a constraint \n\n  \n    \n ",
    "content": "In mathematical optimization, the active-set method is an algorithm used to identify the active constraints in a set of inequality constraints. The active constraints are then expressed as equality constraints,  thereby transforming an inequality-constrained problem into a simpler equality-constrained subproblem.\nAn optimization problem is defined using an objective function to minimize or maximize, and a set of constraints\n\n  \n    \n      \n        \n          g\n          \n            1\n          \n        \n        (\n        x\n        )\n        ≥\n        0\n        ,\n        …\n        ,\n        \n          g\n          \n            k\n          \n        \n        (\n        x\n        )\n        ≥\n        0\n      \n    \n    {\\displaystyle g_{1}(x)\\geq 0,\\dots ,g_{k}(x)\\geq 0}\n  \n\nthat define the feasible region, that is, the set of all x to search for the optimal solution. Given a point \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n in the feasible region, a constraint \n\n  \n    \n      \n        \n          g\n          \n            i\n          \n        \n        (\n        x\n        )\n        ≥\n        0\n      \n    \n    {\\displaystyle g_{i}(x)\\geq 0}\n  \n\nis called active at \n  \n    \n      \n        \n          x\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle x_{0}}\n  \n if \n  \n    \n      \n        \n          g\n          \n            i\n          \n        \n        (\n        \n          x\n          \n            0\n          \n        \n        )\n        =\n        0\n      \n    \n    {\\displaystyle g_{i}(x_{0})=0}\n  \n, and inactive at \n  \n    \n      \n        \n          x\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle x_{0}}\n  \n if \n  \n    \n      \n        \n          g\n          \n            i\n          \n        \n        (\n        \n          x\n          \n            0\n          \n        \n        )\n        >\n        0.\n      \n    \n    {\\displaystyle g_{i}(x_{0})>0.}\n  \n Equality constraints are always active. The active set at \n  \n    \n      \n        \n          x\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle x_{0}}\n  \n is made up of those constraints \n  \n    \n      \n        \n          g\n          \n            i\n          \n        \n        (\n        \n          x\n          \n            0\n          \n        \n        )\n      \n    \n    {\\displaystyle g_{i}(x_{0})}\n  \n that are active at the current point (Nocedal & Wright 2006, p. 308).\nThe active set is particularly important in optimization theory, as it determines which constraints will influence the final result of optimization. For example, in solving the linear programming problem, the active set gives the hyperplanes that intersect at the solution point. In quadratic programming, as the solution is not necessarily on one of the edges of the bounding polygon, an estimation of the active set gives us a subset of inequalities to watch while searching the solution, which reduces the complexity of the search.\n\nActive-set methods\nIn general an active-set algorithm has the following structure:\n\nFind a feasible starting point\nrepeat until \"optimal enough\"\nsolve the equality problem defined by the active set (approximately)\ncompute the Lagrange multipliers of the active set\nremove a subset of the constraints with negative Lagrange multipliers\nsearch for infeasible constraints among the inactive constraints and add them to the problem\nend repeat\nThe motivations for this is that near the optimum usually only a small number of all constraints are binding and the solve step usually takes superlinear time in the amount of constraints. Thus repeated solving of a series equality constrained problem, which drop constraints which are not violated when improving but are in the way of improvement (negative lagrange multipliers) and adding of those constraints which the current solution violates can converge against the true solution. The optima of the last problem can often provide an initial guess in case the equality constrained problem solver needs an initial value.\nMethods that can be described as active-set methods include:\n\nSuccessive linear programming (SLP)\nSequential quadratic programming (SQP)\nSequential linear-quadratic programming (SLQP)\nReduced gradient method (RG)\nGeneralized reduced gradient method (GRG)\n\nPerformance\nConsider the problem of Linearly Constrained Convex Quadratic Programming. Under reasonable assumptions (the problem is feasible, the system of constraints is regular at every point, and the quadratic objective is strongly convex),  the active-set method terminates after finitely many steps, and yields a global solution to the problem. Theoretically, the active-set method may perform a number of iterations exponential in m, like the simplex method. However, its practical behaviour is typically much better.\n\nReferences\nBibliography\nMurty, K. G. (1988). Linear complementarity, linear and nonlinear programming. Sigma Series in Applied Mathematics. Vol. 3. Berlin: Heldermann Verlag",
    "links": [
      "Constraint (mathematics)",
      "Feasible region",
      "Frank–Wolfe algorithm",
      "Generalized Reduced Gradient",
      "Hyperplane",
      "ISBN (identifier)",
      "Inequality (mathematics)",
      "Lagrange multipliers",
      "Linear programming",
      "MR (identifier)",
      "Optimization (mathematics)",
      "Quadratic programming",
      "Sequential linear-quadratic programming",
      "Sequential quadratic programming",
      "Simplex method",
      "Springer-Verlag",
      "Successive linear programming",
      "The Active Set"
    ],
    "categories": [
      "Category:Optimization algorithms and methods"
    ]
  },
  "Approximation algorithm": {
    "title": "Approximation algorithm",
    "url": "https://en.wikipedia.org/wiki/Approximation_algorithm",
    "summary": "In computer science and operations research, approximation algorithms are efficient algorithms that find approximate solutions to optimization problems (in particular NP-hard problems) with provable guarantees on the distance of the returned solution to the optimal one. Approximation algorithms naturally arise in the field of theoretical computer science as a consequence of the widely believed P ≠ NP conjecture. Under this conjecture, a wide class of optimization problems cannot be solved exactly in polynomial time. The field of approximation algorithms, therefore, tries to understand how closely it is possible to approximate optimal solutions to such problems in polynomial time. In an overwhelming majority of the cases, the guarantee of such algorithms is a multiplicative one expressed as an approximation ratio or approximation factor i.e., the optimal solution is always guaranteed to be within a (predetermined) multiplicative factor of the returned solution. However, there are also m",
    "content": "In computer science and operations research, approximation algorithms are efficient algorithms that find approximate solutions to optimization problems (in particular NP-hard problems) with provable guarantees on the distance of the returned solution to the optimal one. Approximation algorithms naturally arise in the field of theoretical computer science as a consequence of the widely believed P ≠ NP conjecture. Under this conjecture, a wide class of optimization problems cannot be solved exactly in polynomial time. The field of approximation algorithms, therefore, tries to understand how closely it is possible to approximate optimal solutions to such problems in polynomial time. In an overwhelming majority of the cases, the guarantee of such algorithms is a multiplicative one expressed as an approximation ratio or approximation factor i.e., the optimal solution is always guaranteed to be within a (predetermined) multiplicative factor of the returned solution. However, there are also many approximation algorithms that provide an additive guarantee on the quality of the returned solution. A notable example of an approximation algorithm that provides both is the classic approximation algorithm of Lenstra, Shmoys and Tardos for scheduling on unrelated parallel machines.\nThe design and analysis of approximation algorithms crucially involves a mathematical proof certifying the quality of the returned solutions in the worst case. This distinguishes them from heuristics such as annealing or genetic algorithms, which find reasonably good solutions on some inputs, but provide no clear indication at the outset on when they may succeed or fail.\nThere is widespread interest in theoretical computer science to better understand the limits to which we can approximate certain famous optimization problems. For example, one of the long-standing open questions in computer science is to determine whether there is an algorithm that outperforms the 2-approximation for the Steiner Forest problem by Agrawal et al. The desire to understand hard optimization problems from the perspective of approximability is motivated by the discovery of surprising mathematical connections and broadly applicable techniques to design algorithms for hard optimization problems. One well-known example of the former is the Goemans–Williamson algorithm for maximum cut, which solves a graph theoretic problem using high dimensional geometry.\n\nIntroduction\nA simple example of an approximation algorithm is one for the minimum vertex cover problem, where the goal is to choose the smallest set of vertices such that every edge in the input graph contains at least one chosen vertex. One way to find a vertex cover is to repeat the following process: find an uncovered edge, add both its endpoints to the cover, and remove all edges incident to either vertex from the graph. As any vertex cover of the input graph must use a distinct vertex to cover each edge that was considered in the process (since it forms a matching), the vertex cover produced, therefore, is at most twice as large as the optimal one. In other words, this is a constant-factor approximation algorithm with an approximation factor of 2. Under the recent unique games conjecture, this factor is even the best possible one.\nNP-hard problems vary greatly in their approximability; some, such as the knapsack problem, can be approximated within a multiplicative factor \n  \n    \n      \n        1\n        +\n        ϵ\n      \n    \n    {\\displaystyle 1+\\epsilon }\n  \n, for any fixed \n  \n    \n      \n        ϵ\n        >\n        0\n      \n    \n    {\\displaystyle \\epsilon >0}\n  \n, and therefore produce solutions arbitrarily close to the optimum (such a family of approximation algorithms is called a polynomial-time approximation scheme or PTAS). Others are impossible to approximate within any constant, or even polynomial, factor unless P = NP, as in the case of the maximum clique problem. Therefore, an important benefit of studying approximation algorithms is a fine-grained classification of the difficulty of various NP-hard problems beyond the one afforded by the theory of NP-completeness. In other words, although NP-complete problems may be equivalent (under polynomial-time reductions) to each other from the perspective of exact solutions, the corresponding optimization problems behave very differently from the perspective of approximate solutions.\n\nAlgorithm design techniques\nBy now there are several established techniques to design approximation algorithms. These include the following ones.\n\nGreedy algorithm\nLocal search\nEnumeration and dynamic programming (which is also often used for parameterized approximations)\nSolving a convex programming relaxation to get a fractional solution. Then converting this fractional solution into a feasible solution by some appropriate rounding. The popular relaxations include the following.\nLinear programming relaxations\nSemidefinite programming relaxations\nPrimal-dual methods\nDual fit",
    "links": [
      "APX",
      "Active-set method",
      "Affine scaling",
      "Algorithm",
      "Approximation",
      "Approximation-preserving reduction",
      "Approximation Algorithms for NP-Hard problems",
      "ArXiv (identifier)",
      "Augmented Lagrangian method",
      "Barrier function",
      "Bellman–Ford algorithm",
      "Berndt–Hall–Hall–Hausman algorithm",
      "Borůvka's algorithm",
      "Branch and bound",
      "Branch and cut",
      "Broyden–Fletcher–Goldfarb–Shanno algorithm",
      "Cambridge University Press",
      "Charles E. Leiserson",
      "CiteSeerX (identifier)",
      "Clifford Stein",
      "Clique problem",
      "Combinatorial optimization",
      "Comparison of optimization software",
      "Computer science",
      "Constant-factor approximation algorithm",
      "Convex minimization",
      "Convex optimization",
      "Convex programming",
      "Criss-cross algorithm",
      "Cutting-plane method",
      "David P. Williamson",
      "David S. Johnson",
      "David Shmoys",
      "Davidon–Fletcher–Powell formula",
      "Dijkstra's algorithm",
      "Dinic's algorithm",
      "Doi (identifier)",
      "Domination analysis",
      "Dorit S. Hochbaum",
      "Dynamic programming",
      "Edmonds–Karp algorithm",
      "Ellipsoid method",
      "Euclidean traveling salesman problem",
      "Evolutionary algorithm",
      "Exact algorithm",
      "Exchange algorithm",
      "Fixed-parameter algorithm",
      "Flow network",
      "Floyd–Warshall algorithm",
      "Ford–Fulkerson algorithm"
    ],
    "categories": [
      "Category:All articles lacking in-text citations",
      "Category:Approximation algorithms",
      "Category:Articles lacking in-text citations from April 2009",
      "Category:Articles with short description",
      "Category:CS1 maint: multiple names: authors list",
      "Category:Computational complexity theory",
      "Category:Short description matches Wikidata"
    ]
  },
  "Argument of a function": {
    "title": "Argument of a function",
    "url": "https://en.wikipedia.org/wiki/Argument_of_a_function",
    "summary": "In mathematics, an argument of a function is a value provided to obtain the function's result. It is also called an independent variable.\nFor example, the binary function \n  \n    \n      \n        f\n        (\n        x\n        ,\n        y\n        )\n        =\n        \n          x\n          \n            2\n          \n        \n        +\n        \n          y\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle f(x,y)=x^{2}+y^{2}}\n  \n has two arguments, \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n and \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n, in an ordered pair \n  \n    \n      \n        (\n        x\n        ,\n        y\n        )\n      \n    \n    {\\displaystyle (x,y)}\n  \n. The hypergeometric function is an example of a four-argument function. The number of arguments that a function takes is called the arity of the function. A function that takes a single argument as input, such as \n  \n    \n      \n        f\n        (\n        x\n        ",
    "content": "In mathematics, an argument of a function is a value provided to obtain the function's result. It is also called an independent variable.\nFor example, the binary function \n  \n    \n      \n        f\n        (\n        x\n        ,\n        y\n        )\n        =\n        \n          x\n          \n            2\n          \n        \n        +\n        \n          y\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle f(x,y)=x^{2}+y^{2}}\n  \n has two arguments, \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n and \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n, in an ordered pair \n  \n    \n      \n        (\n        x\n        ,\n        y\n        )\n      \n    \n    {\\displaystyle (x,y)}\n  \n. The hypergeometric function is an example of a four-argument function. The number of arguments that a function takes is called the arity of the function. A function that takes a single argument as input, such as \n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        \n          x\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle f(x)=x^{2}}\n  \n, is called a unary function. A function of two or more variables is considered to have a domain consisting of ordered pairs or tuples of argument values. The argument of a circular function is an angle. The argument of a hyperbolic function is a hyperbolic angle.\nA mathematical function has one or more arguments in the form of independent variables designated in the definition, which can also contain parameters. The independent variables are mentioned in the list of arguments that the function takes, whereas the parameters are not. For example, in the logarithmic function \n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        \n          log\n          \n            b\n          \n        \n        ⁡\n        (\n        x\n        )\n        ,\n      \n    \n    {\\displaystyle f(x)=\\log _{b}(x),}\n  \n the base \n  \n    \n      \n        b\n      \n    \n    {\\displaystyle b}\n  \n is considered a parameter. \nSometimes, subscripts can be used to denote arguments. For example, we can use subscripts to denote the arguments with respect to which partial derivatives are taken.\nThe use of the term \"argument\" in this sense developed from astronomy, which historically used tables to determine the spatial positions of planets from their positions in the sky (ephemerides). These tables were organized according to measured angles called arguments, literally \"that which elucidates something else.\"\n\nSee also\nDomain of a function – Mathematical concept\nFunction prototype – Declaration of a function's name and type signature but not body\nParameter (computer programming) – Variable that represents an argument to a function\nPropositional function – Expression in propositional calculus\nType signature – Defines the inputs and outputs for a function, subroutine or method\nValue (mathematics) – Notion in mathematics\n\nReferences\nExternal links\nWeisstein, Eric W. \"Argument\". MathWorld.\nArgument at PlanetMath.",
    "links": [
      "Abstract logic",
      "Ackermann set theory",
      "Aleph number",
      "Algebraic logic",
      "Alphabet (formal languages)",
      "Angle",
      "Argument",
      "Argument (complex analysis)",
      "Argument (computer programming)",
      "Arity",
      "Astronomy",
      "Atomic formula",
      "Atomic sentence",
      "Automata theory",
      "Automated theorem proving",
      "Axiom",
      "Axiom of choice",
      "Axiom schema",
      "Axiomatic system",
      "Axiomatization of Boolean algebras",
      "Banach–Tarski paradox",
      "Base of a logarithm",
      "Bijection",
      "Binary function",
      "Binary operation",
      "Boolean algebra",
      "Boolean algebras canonically defined",
      "Boolean function",
      "Cantor's diagonal argument",
      "Cantor's paradox",
      "Cantor's theorem",
      "Cardinality",
      "Cartesian product",
      "Categorical theory",
      "Category (mathematics)",
      "Category of sets",
      "Category theory",
      "Church encoding",
      "Church–Turing thesis",
      "Circular function",
      "Class (set theory)",
      "Classical logic",
      "Codomain",
      "Compactness theorem",
      "Complement (set theory)",
      "Complete theory",
      "Computability theory",
      "Computable function",
      "Computable set",
      "Computably enumerable set"
    ],
    "categories": [
      "Category:All stub articles",
      "Category:Articles with short description",
      "Category:Elementary mathematics",
      "Category:Mathematics stubs",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Asset pricing": {
    "title": "Asset pricing",
    "url": "https://en.wikipedia.org/wiki/Asset_pricing",
    "summary": "In financial economics, asset pricing refers to a formal treatment and development of two interrelated pricing principles, outlined below, together with the resultant models. There have been many models developed for different situations, but correspondingly, these stem from either general equilibrium asset pricing or rational asset pricing, the latter corresponding to risk neutral pricing.\nInvestment theory, which is near synonymous, encompasses the body of knowledge used to support the decision-making process of choosing investments, and the asset pricing models are then applied in determining the asset-specific required rate of return on the investment in question, and for hedging.",
    "content": "In financial economics, asset pricing refers to a formal treatment and development of two interrelated pricing principles, outlined below, together with the resultant models. There have been many models developed for different situations, but correspondingly, these stem from either general equilibrium asset pricing or rational asset pricing, the latter corresponding to risk neutral pricing.\nInvestment theory, which is near synonymous, encompasses the body of knowledge used to support the decision-making process of choosing investments, and the asset pricing models are then applied in determining the asset-specific required rate of return on the investment in question, and for hedging.\n\nGeneral equilibrium asset pricing\nUnder general equilibrium theory prices are determined through market pricing by supply and demand. \n \nHere asset prices jointly satisfy the requirement that the quantities of each asset supplied and the quantities demanded must be equal at that price - so called market clearing. These models are born out of modern portfolio theory, with the capital asset pricing model (CAPM) as the prototypical result. Prices here are determined with reference to macroeconomic variables–for the CAPM, the \"overall market\"; for the CCAPM, overall wealth– such that individual preferences are subsumed.\nThese models aim at modeling the statistically derived probability distribution of the market prices of \"all\" securities at a given future investment horizon; they are thus of \"large dimension\". See § Risk and portfolio management: the P world under Mathematical finance. General equilibrium pricing is then used when evaluating diverse portfolios, creating one asset price for many assets.\nCalculating an investment or share value here, entails:\n(i) a financial forecast for the business or project in question; \n(ii) where the output cashflows are then discounted at the rate returned by the model selected; this rate in turn reflecting the \"riskiness\" - i.e. the idiosyncratic, or undiversifiable risk - of these cashflows;\n(iii) these present values are then aggregated, returning the value in question. \nSee: Financial modeling § Accounting, and Valuation using discounted cash flows. \n(Note that an alternate, although less common approach, is to apply a \"fundamental valuation\" method, such as the T-model, which instead relies on accounting information, attempting to model return based on the company's expected financial performance.)\n\nRational pricing\nUnder Rational pricing, derivative prices are calculated such that they are arbitrage-free with respect to more fundamental (equilibrium determined) securities prices;\nfor an overview of the logic see Rational pricing  § Pricing derivatives.\nIn general this approach does not group assets but rather creates a unique risk price for each asset; these models are then of \"low dimension\".\nFor further discussion, see § Derivatives pricing: the Q world under Mathematical finance.\nCalculating option prices, and their \"Greeks\", i.e. sensitivities, combines:\n(i) a model of the underlying price behavior, or \"process\" - i.e. the asset pricing model selected, with its parameters having been calibrated to observed prices;\nand \n(ii) a mathematical method which returns the premium (or sensitivity) as the expected value of option payoffs over the range of prices of the underlying. \nSee Valuation of options § Pricing models.\nThe classical model here is Black–Scholes which describes the dynamics of a market including derivatives (with its option pricing formula); leading more generally to martingale pricing, as well as the above listed models. Black–Scholes assumes a log-normal process; the other models will, for example, incorporate features such as mean reversion, or will be \"volatility surface aware\", applying local volatility or stochastic volatility.\nRational pricing is also applied to fixed income instruments such as bonds (that consist of just one asset), as well as to interest rate modeling in general, where yield curves must be arbitrage free with respect to the prices of individual instruments.\nSee Rational pricing  § Fixed income securities, Bootstrapping (finance), and Multi-curve framework.\nFor discussion as to how the models listed above are applied to options on these instruments, and other interest rate derivatives, see short-rate model and Heath–Jarrow–Morton framework.\n\nInterrelationship\nThese principles are interrelated \n\nthrough the fundamental theorem of asset pricing.\nHere, \"in the absence of arbitrage, the market imposes a probability distribution, called a risk-neutral or equilibrium measure, on the set of possible market scenarios, and... this probability measure determines market prices via discounted expectation\".\nCorrespondingly, this essentially means that one may make financial decisions using the risk neutral probability distribution consistent with (i.e. solved for) observed equilibrium prices. See Financial economics  § Arbitrage-free pricing and equilibrium.\nR",
    "links": [
      "Arbitrage",
      "Arbitrage pricing theory",
      "Arrow–Debreu model",
      "Bank of England",
      "Binomial options pricing model",
      "Binomial probability",
      "Black model",
      "Black–Derman–Toy model",
      "Black–Karasinski model",
      "Black–Scholes model",
      "Bootstrapping (finance)",
      "Brace-Gatarek-Musiela model",
      "Capital asset pricing model",
      "Carhart four-factor model",
      "Cash flow forecast",
      "Chen model",
      "Cheyette model",
      "Constant elasticity of variance model",
      "Consumption-based capital asset pricing model",
      "Contingent claim analysis",
      "Corporate finance",
      "Cox–Ingersoll–Ross model",
      "Decision-making",
      "Derivative (finance)",
      "Digital textbook",
      "Doi (identifier)",
      "Expected value",
      "Fama–French three-factor model",
      "Financial economics",
      "Financial forecast",
      "Financial modeling",
      "Frank Fabozzi",
      "Fundamental theorem of asset pricing",
      "Garman–Kohlhagen model",
      "General equilibrium theory",
      "Greeks (finance)",
      "Hal Varian",
      "Heath–Jarrow–Morton framework",
      "Heston model",
      "Ho–Lee model",
      "Hull–White model",
      "ISBN (identifier)",
      "Idiosyncratic risk",
      "Interest rate derivative",
      "Intertemporal CAPM",
      "Investment",
      "JSTOR (identifier)",
      "John H. Cochrane",
      "Journal of Investment Management",
      "Kalotay–Williams–Fabozzi model"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Asset",
      "Category:Finance theories",
      "Category:Financial economics",
      "Category:Financial models",
      "Category:Pricing",
      "Category:Short description is different from Wikidata",
      "Category:Webarchive template wayback links"
    ]
  },
  "Barrier function": {
    "title": "Barrier function",
    "url": "https://en.wikipedia.org/wiki/Barrier_function",
    "summary": "In constrained optimization, a field of mathematics,  a barrier function is a continuous function whose value increases to infinity as its argument approaches the boundary of the feasible region of an optimization problem. Such functions are used to replace inequality constraints by a penalizing term in the objective function that is easier to handle. A barrier function is also called an interior penalty function, as it is a penalty function that forces the solution to remain within the interior of the feasible region.\nThe two most common types of barrier functions are inverse barrier functions and logarithmic barrier functions. Resumption of interest in logarithmic barrier functions was motivated by their connection with primal-dual interior point methods.",
    "content": "In constrained optimization, a field of mathematics,  a barrier function is a continuous function whose value increases to infinity as its argument approaches the boundary of the feasible region of an optimization problem. Such functions are used to replace inequality constraints by a penalizing term in the objective function that is easier to handle. A barrier function is also called an interior penalty function, as it is a penalty function that forces the solution to remain within the interior of the feasible region.\nThe two most common types of barrier functions are inverse barrier functions and logarithmic barrier functions. Resumption of interest in logarithmic barrier functions was motivated by their connection with primal-dual interior point methods.\n\nMotivation\nConsider the following constrained optimization problem:\n\nminimize f(x)\nsubject to x ≤ b\nwhere b is some constant. If one wishes to remove the inequality constraint, the problem can be reformulated as\n\nminimize f(x) + c(x),\nwhere c(x) = ∞ if x > b, and zero otherwise.\nThis problem is equivalent to the first. It gets rid of the inequality, but introduces the issue that the penalty function c, and therefore the objective function f(x) + c(x), is discontinuous, preventing the use of calculus to solve it.\nA barrier function, now, is a continuous approximation g to c that tends to infinity as x approaches b from above. Using such a function, a new optimization problem is formulated, viz.\n\nminimize f(x) + μ g(x)\nwhere μ > 0 is a free parameter. This problem is not equivalent to the original, but as μ approaches zero, it becomes an ever-better approximation.\n\nLogarithmic barrier function\nFor logarithmic barrier functions, \n  \n    \n      \n        g\n        (\n        x\n        ,\n        b\n        )\n      \n    \n    {\\displaystyle g(x,b)}\n  \n is defined as \n  \n    \n      \n        −\n        log\n        ⁡\n        (\n        b\n        −\n        x\n        )\n      \n    \n    {\\displaystyle -\\log(b-x)}\n  \n when \n  \n    \n      \n        x\n        <\n        b\n      \n    \n    {\\displaystyle x<b}\n  \n and \n  \n    \n      \n        ∞\n      \n    \n    {\\displaystyle \\infty }\n  \n otherwise (in one dimension; see below for a definition in higher dimensions). This essentially relies on the fact that \n  \n    \n      \n        log\n        ⁡\n        t\n      \n    \n    {\\displaystyle \\log t}\n  \n tends to negative infinity as \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  \n tends to 0.\nThis introduces a gradient to the function being optimized which favors less extreme values of \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n (in this case values lower than \n  \n    \n      \n        b\n      \n    \n    {\\displaystyle b}\n  \n), while having relatively low impact on the function away from these extremes.\nLogarithmic barrier functions may be favored over less computationally expensive inverse barrier functions depending on the function being optimized.\n\nHigher dimensions\nExtending to higher dimensions is simple, provided each dimension is independent. For each variable \n  \n    \n      \n        \n          x\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle x_{i}}\n  \n which should be limited to be strictly lower than \n  \n    \n      \n        \n          b\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle b_{i}}\n  \n, add \n  \n    \n      \n        −\n        log\n        ⁡\n        (\n        \n          b\n          \n            i\n          \n        \n        −\n        \n          x\n          \n            i\n          \n        \n        )\n      \n    \n    {\\displaystyle -\\log(b_{i}-x_{i})}\n  \n.\n\nFormal definition\nMinimize \n  \n    \n      \n        \n          \n            c\n          \n          \n            T\n          \n        \n        x\n      \n    \n    {\\displaystyle \\mathbf {c} ^{T}x}\n  \n subject to \n  \n    \n      \n        \n          \n            a\n          \n          \n            i\n          \n          \n            T\n          \n        \n        x\n        ≤\n        \n          b\n          \n            i\n          \n        \n        ,\n        i\n        =\n        1\n        ,\n        …\n        ,\n        m\n      \n    \n    {\\displaystyle \\mathbf {a} _{i}^{T}x\\leq b_{i},i=1,\\ldots ,m}\n  \n\nAssume strictly feasible: \n  \n    \n      \n        {\n        \n          x\n        \n        \n          |\n        \n        A\n        x\n        <\n        b\n        }\n        ≠\n        ∅\n      \n    \n    {\\displaystyle \\{\\mathbf {x} |Ax<b\\}\\neq \\emptyset }\n  \n\nDefine logarithmic barrier \n  \n    \n      \n        g\n        (\n        x\n        )\n        =\n        \n          \n            {\n            \n              \n                \n                  \n                    ∑\n                    \n                      i\n                      =\n                      1\n                    \n                    \n                      m\n                    \n                  \n                  −\n                  log\n                  ⁡\n                  (\n           ",
    "links": [
      "Active-set method",
      "Affine scaling",
      "Approximation algorithm",
      "Augmented Lagrangian method",
      "Barrier certificate",
      "Barrier methods",
      "Bellman–Ford algorithm",
      "Berndt–Hall–Hall–Hausman algorithm",
      "Borůvka's algorithm",
      "Branch and bound",
      "Branch and cut",
      "Broyden–Fletcher–Goldfarb–Shanno algorithm",
      "Calculus",
      "Candidate solution",
      "Combinatorial optimization",
      "Comparison of optimization software",
      "Constraint (mathematics)",
      "Continuous function",
      "Convex minimization",
      "Convex optimization",
      "Criss-cross algorithm",
      "Cutting-plane method",
      "Davidon–Fletcher–Powell formula",
      "Dijkstra's algorithm",
      "Dinic's algorithm",
      "Discontinuous function",
      "Dynamic programming",
      "Edmonds–Karp algorithm",
      "Ellipsoid method",
      "Evolutionary algorithm",
      "Exchange algorithm",
      "Flow network",
      "Floyd–Warshall algorithm",
      "Ford–Fulkerson algorithm",
      "Frank–Wolfe algorithm",
      "Function (mathematics)",
      "Gauss–Newton algorithm",
      "Golden-section search",
      "Gradient",
      "Gradient descent",
      "Graph algorithm",
      "Greedy algorithm",
      "Hessian matrix",
      "Heuristic algorithm",
      "Hill climbing",
      "ISBN (identifier)",
      "Integer programming",
      "Interior point method",
      "Inverse barrier function",
      "Inverse barrier functions"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Constraint programming",
      "Category:Convex optimization",
      "Category:Short description matches Wikidata",
      "Category:Types of functions"
    ]
  },
  "Bayesian optimization": {
    "title": "Bayesian optimization",
    "url": "https://en.wikipedia.org/wiki/Bayesian_optimization",
    "summary": "Bayesian optimization is a sequential design strategy for global optimization of black-box functions, that does not assume any functional forms. It is usually employed to optimize expensive-to-evaluate functions. With the rise of artificial intelligence innovation in the 21st century, Bayesian optimizations have found prominent use in machine learning problems for optimizing hyperparameter values.",
    "content": "Bayesian optimization is a sequential design strategy for global optimization of black-box functions, that does not assume any functional forms. It is usually employed to optimize expensive-to-evaluate functions. With the rise of artificial intelligence innovation in the 21st century, Bayesian optimizations have found prominent use in machine learning problems for optimizing hyperparameter values.\n\nHistory\nThe term is generally attributed to Jonas Mockus and is coined in his work from a series of publications on global optimization in the 1970s and 1980s.\n\nEarly mathematics foundations\nFrom 1960s to 1980s\nThe earliest idea of Bayesian optimization sprang in 1964, from a paper by American applied mathematician Harold J. Kushner, “A New Method of Locating the Maximum Point of an Arbitrary Multipeak Curve in the Presence of Noise”. Although not directly proposing Bayesian optimization, in this paper, he first proposed a new method of locating the maximum point of an arbitrary multipeak curve in a noisy environment. This method provided an important theoretical foundation for subsequent Bayesian optimization.\nBy the 1980s, the framework we now use for Bayesian optimization was explicitly established. In 1978, the Lithuanian scientist Jonas Mockus, in his paper “The Application of Bayesian Methods for Seeking the Extremum”, discussed how to use Bayesian methods to find the extreme value of a function under various uncertain conditions. In his paper, Mockus first proposed the Expected Improvement principle (EI), which is one of the core sampling strategies of Bayesian optimization. This criterion balances exploration while optimizing the function efficiently by maximizing the expected improvement. Because of the usefulness and profound impact of this principle, Jonas Mockus is widely regarded as the founder of Bayesian optimization. Although Expected Improvement principle (EI) is one of the earliest proposed core sampling strategies for Bayesian optimization, it is not the only one, with the development of modern society, we also have Probability of Improvement (PI), or Upper Confidence Bound (UCB) and so on.\n\nFrom theory to practice\nIn the 1990s, Bayesian optimization began to gradually transition from pure theory to real-world applications. In 1998, Donald R. Jones and his coworkers published a paper titled “Gaussian Optimization”. In this paper, they proposed the Gaussian Process (GP) and elaborated on the Expected Improvement principle (EI) proposed by Jonas Mockus in 1978. Through the efforts of Donald R. Jones and his colleagues, Bayesian Optimization began to shine in the fields like computers science and engineering. However, the computational complexity of Bayesian optimization for the computing power at that time still affected its development to a large extent.\nIn the 21st century, with the gradual rise of artificial intelligence and bionic robots, Bayesian optimization has been widely used in machine learning and deep learning, and has become an important tool for Hyperparameter Tuning. Companies such as Google, Facebook and OpenAI have added Bayesian optimization to their deep learning frameworks to improve search efficiency. However, Bayesian optimization still faces many challenges, for example, because of the use of Gaussian Process as a proxy model for optimization, when there is a lot of data, the training of Gaussian Process will be very slow and the computational cost is very high. This makes it difficult for this optimization method to work well in more complex drug development and medical experiments.\n\nStrategy\nBayesian optimization is used on problems of the form \n  \n    \n      \n        \n          max\n          \n            x\n            ∈\n            X\n          \n        \n        f\n        (\n        x\n        )\n      \n    \n    {\\textstyle \\max _{x\\in X}f(x)}\n  \n, with \n  \n    \n      \n        X\n      \n    \n    {\\textstyle X}\n  \n being the set of all possible parameters \n  \n    \n      \n        x\n      \n    \n    {\\textstyle x}\n  \n, typically with less than or equal to 20 dimensions for optimal usage (\n  \n    \n      \n        X\n        →\n        \n          \n            R\n          \n          \n            d\n          \n        \n        ∣\n        d\n        ≤\n        20\n      \n    \n    {\\textstyle X\\rightarrow \\mathbb {R} ^{d}\\mid d\\leq 20}\n  \n), and whose membership can easily be evaluated. Bayesian optimization is particularly advantageous for problems where \n  \n    \n      \n        f\n        (\n        x\n        )\n      \n    \n    {\\textstyle f(x)}\n  \n is difficult to evaluate due to its computational cost. The objective function, \n  \n    \n      \n        f\n      \n    \n    {\\textstyle f}\n  \n, is continuous and takes the form of some unknown structure, referred to as a \"black box\". Upon its evaluation, only \n  \n    \n      \n        f\n        (\n        x\n        )\n      \n    \n    {\\textstyle f(x)}\n  \n is observed and its derivatives are not evaluated.\nSince the objective function is unknown, the Bayesi",
    "links": [
      "Active-set method",
      "Active learning (machine learning)",
      "Affine scaling",
      "Approximation algorithm",
      "ArXiv (identifier)",
      "Artificial intelligence",
      "Augmented Lagrangian method",
      "Automated machine learning",
      "Barrier function",
      "Bayesian experimental design",
      "Bellman–Ford algorithm",
      "Berndt–Hall–Hall–Hausman algorithm",
      "Black box",
      "Borůvka's algorithm",
      "Branch and bound",
      "Branch and cut",
      "Broyden–Fletcher–Goldfarb–Shanno algorithm",
      "Combinatorial optimization",
      "Comparison of optimization software",
      "Computer graphics",
      "Convex minimization",
      "Convex optimization",
      "Criss-cross algorithm",
      "Cutting-plane method",
      "Davidon–Fletcher–Powell formula",
      "Deep learning",
      "Derivative",
      "Dijkstra's algorithm",
      "Dimension",
      "Dinic's algorithm",
      "Doi (identifier)",
      "Dynamic programming",
      "Edmonds–Karp algorithm",
      "Ellipsoid method",
      "Evolutionary algorithm",
      "Exchange algorithm",
      "Exploration–exploitation dilemma",
      "Flow network",
      "Floyd–Warshall algorithm",
      "Ford–Fulkerson algorithm",
      "Frank–Wolfe algorithm",
      "Function (mathematics)",
      "Gaussian process",
      "Gauss–Newton algorithm",
      "Global optimization",
      "Golden-section search",
      "Gradient",
      "Gradient descent",
      "Graph algorithm",
      "Greedy algorithm"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Machine learning",
      "Category:Sequential experiments",
      "Category:Sequential methods",
      "Category:Short description is different from Wikidata",
      "Category:Stochastic optimization",
      "Category:Webarchive template wayback links"
    ]
  },
  "Bellman equation": {
    "title": "Bellman equation",
    "url": "https://en.wikipedia.org/wiki/Bellman_equation",
    "summary": "A Bellman equation, named after Richard E. Bellman,  is a technique in dynamic programming which breaks a optimization problem into a sequence of simpler subproblems, as Bellman's “principle of optimality\" prescribes. It is a necessary condition for optimality. The \"value\" of a decision problem at a certain point in time is written in terms of the payoff from some initial choices and the \"value\" of the remaining decision problem that results from those initial choices. The equation applies to algebraic structures with a total ordering; for algebraic structures with a partial ordering, the generic Bellman's equation can be used.\nThe Bellman equation was first applied to engineering control theory and to other topics in applied mathematics, and subsequently became an important tool in economic theory; though the basic concepts of dynamic programming are prefigured in John von Neumann and Oskar Morgenstern's Theory of Games and Economic Behavior and Abraham Wald's sequential analysis. The",
    "content": "A Bellman equation, named after Richard E. Bellman,  is a technique in dynamic programming which breaks a optimization problem into a sequence of simpler subproblems, as Bellman's “principle of optimality\" prescribes. It is a necessary condition for optimality. The \"value\" of a decision problem at a certain point in time is written in terms of the payoff from some initial choices and the \"value\" of the remaining decision problem that results from those initial choices. The equation applies to algebraic structures with a total ordering; for algebraic structures with a partial ordering, the generic Bellman's equation can be used.\nThe Bellman equation was first applied to engineering control theory and to other topics in applied mathematics, and subsequently became an important tool in economic theory; though the basic concepts of dynamic programming are prefigured in John von Neumann and Oskar Morgenstern's Theory of Games and Economic Behavior and Abraham Wald's sequential analysis. The term \"Bellman equation\" usually refers to the dynamic programming equation (DPE) associated with discrete-time optimization problems. In continuous-time optimization problems, the analogous equation is a partial differential equation that is called the Hamilton–Jacobi–Bellman equation.\nIn discrete time any multi-stage optimization problem can be solved by analyzing the appropriate Bellman equation. The appropriate Bellman equation can be found by introducing new state variables (state augmentation). However, the resulting augmented-state multi-stage optimization problem has a higher dimensional state space than the original multi-stage optimization problem - an issue that can potentially render the augmented problem intractable due to the “curse of dimensionality”. Alternatively, it has been shown that if the cost function of the multi-stage optimization problem satisfies a \"backward separable\" structure, then the appropriate Bellman equation can be found without state augmentation.\n\nAnalytical concepts in dynamic programming\nTo understand the Bellman equation, several underlying concepts must be understood. First, any optimization problem has some objective: minimizing travel time, minimizing cost, maximizing profits, maximizing utility, etc. The mathematical function that describes this objective is called the objective function.\nDynamic programming breaks a multi-period planning problem into simpler steps at different points in time. Therefore, it requires keeping track of how the decision situation is evolving over time. The information about the current situation that is needed to make a correct decision is called the \"state\". For example, to decide how much to consume and spend at each point in time, people would need to know (among other things) their initial wealth. Therefore, wealth \n  \n    \n      \n        (\n        W\n        )\n      \n    \n    {\\displaystyle (W)}\n  \n would be one of their state variables, but there would probably be others.\nThe variables chosen at any given point in time are often called the control variables. For instance, given their current wealth, people might decide how much to consume now. Choosing the control variables now may be equivalent to choosing the next state; more generally, the next state is affected by other factors in addition to the current control. For example, in the simplest case, today's wealth (the state) and consumption (the control) might exactly determine tomorrow's wealth (the new state), though typically other factors will affect tomorrow's wealth too.\nThe dynamic programming approach describes the optimal plan by finding a rule that tells what the controls should be, given any possible value of the state. For example, if consumption (c) depends only on wealth (W), we would seek a rule  \n  \n    \n      \n        c\n        (\n        W\n        )\n      \n    \n    {\\displaystyle c(W)}\n  \n that gives consumption as a function of wealth. Such a rule, determining the controls as a function of the states, is called a policy function.\nFinally, by definition, the optimal decision rule is the one that achieves the best possible value of the objective. For example, if someone chooses consumption, given wealth, in order to maximize happiness (assuming happiness H can be represented by a mathematical function, such as a utility function and is something defined by wealth), then each level of wealth will be associated with some highest possible level of happiness, \n  \n    \n      \n        H\n        (\n        W\n        )\n      \n    \n    {\\displaystyle H(W)}\n  \n. The best possible value of the objective, written as a function of the state, is called the value function.\nBellman showed that a dynamic optimization problem in discrete time can be stated in a recursive, step-by-step form known as backward induction by writing down the relationship between the value function in one period and the value function in the next period. The relationship between these two value functions is called the \"B",
    "links": [
      "Abraham Wald",
      "ArXiv (identifier)",
      "Artificial neural network",
      "Asset pricing",
      "Autonomous system (mathematics)",
      "Avinash Dixit",
      "Backward induction",
      "Backwards induction",
      "Bellman pseudospectral method",
      "Bibcode (identifier)",
      "Capital budgeting",
      "Closed-form expression",
      "Control theory",
      "Control variable (programming)",
      "Curse of dimensionality",
      "Difference equation",
      "Differential equation",
      "Dimitri Bertsekas",
      "Discount factor",
      "Discrete-time",
      "Discrete time",
      "Doi (identifier)",
      "Dynamic optimization",
      "Dynamic programming",
      "Econometrica",
      "Economic growth",
      "Economic theory",
      "Edmund S. Phelps",
      "Edward Prescott",
      "Envelope theorem",
      "Euler–Lagrange equation",
      "Ex-post",
      "Factor of production",
      "Fiscal policy",
      "Functional equation",
      "Game theory",
      "Hamiltonian (control theory)",
      "Hamilton–Jacobi–Bellman equation",
      "ICAPM",
      "ISBN (identifier)",
      "Industrial organization",
      "Investment",
      "JSTOR (identifier)",
      "John Tsitsiklis",
      "John von Neumann",
      "Labor economics",
      "Lars Ljungqvist",
      "Loss function",
      "Markov decision process",
      "Markov process"
    ],
    "categories": [
      "Category:All articles lacking in-text citations",
      "Category:All articles with unsourced statements",
      "Category:Articles lacking in-text citations from April 2018",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from December 2023",
      "Category:Control theory",
      "Category:Dynamic programming",
      "Category:Equations",
      "Category:Short description matches Wikidata",
      "Category:Webarchive template wayback links"
    ]
  },
  "Bellman–Ford algorithm": {
    "title": "Bellman–Ford algorithm",
    "url": "https://en.wikipedia.org/wiki/Bellman%E2%80%93Ford_algorithm",
    "summary": "The Bellman–Ford algorithm is an algorithm that computes shortest paths from a single source vertex to all of the other vertices in a weighted digraph.\nIt is slower than Dijkstra's algorithm for the same problem, but more versatile, as it is capable of handling graphs in which some of the edge weights are negative numbers. The algorithm was first proposed by Alfonso Shimbel (1955), but is instead named after Richard Bellman and Lester Ford Jr., who published it in 1958 and 1956, respectively. Edward F. Moore also published a variation of the algorithm in 1959, and for this reason it is also sometimes called the Bellman–Ford–Moore algorithm.\nNegative edge weights are found in various applications of graphs. This is why this algorithm is useful.\nIf a graph contains a \"negative cycle\" (i.e. a cycle whose edges sum to a negative value) that is reachable from the source, then there is no cheapest path: any path that has a point on the negative cycle can be made cheaper by one more walk arou",
    "content": "The Bellman–Ford algorithm is an algorithm that computes shortest paths from a single source vertex to all of the other vertices in a weighted digraph.\nIt is slower than Dijkstra's algorithm for the same problem, but more versatile, as it is capable of handling graphs in which some of the edge weights are negative numbers. The algorithm was first proposed by Alfonso Shimbel (1955), but is instead named after Richard Bellman and Lester Ford Jr., who published it in 1958 and 1956, respectively. Edward F. Moore also published a variation of the algorithm in 1959, and for this reason it is also sometimes called the Bellman–Ford–Moore algorithm.\nNegative edge weights are found in various applications of graphs. This is why this algorithm is useful.\nIf a graph contains a \"negative cycle\" (i.e. a cycle whose edges sum to a negative value) that is reachable from the source, then there is no cheapest path: any path that has a point on the negative cycle can be made cheaper by one more walk around the negative cycle. In such a case, the Bellman–Ford algorithm can detect and report the negative cycle.\n\nAlgorithm\nLike Dijkstra's algorithm, Bellman–Ford proceeds by relaxation, in which approximations to the correct distance are replaced by better ones until they eventually reach the solution. In both algorithms, the approximate distance to each vertex is always an overestimate of the true distance, and is replaced by the minimum of its old value and the length of a newly found path.\nHowever, Dijkstra's algorithm uses a priority queue to greedily select the closest vertex that has not yet been processed, and performs this relaxation process on all of its outgoing edges; by contrast, the Bellman–Ford algorithm simply relaxes all the edges, and does this \n  \n    \n      \n        \n          |\n        \n        V\n        \n          |\n        \n        −\n        1\n      \n    \n    {\\displaystyle |V|-1}\n  \n times, where \n  \n    \n      \n        \n          |\n        \n        V\n        \n          |\n        \n      \n    \n    {\\displaystyle |V|}\n  \n is the number of vertices in the graph.\nIn each of these repetitions, the number of vertices with correctly calculated distances grows, from which it follows that eventually all vertices will have their correct distances. This method allows the Bellman–Ford algorithm to be applied to a wider class of inputs than Dijkstra's algorithm. The intermediate answers and the choices among equally short paths depend on the order of edges relaxed, but the final distances remain the same.\nBellman–Ford runs in \n  \n    \n      \n        O\n        (\n        \n          |\n        \n        V\n        \n          |\n        \n        ⋅\n        \n          |\n        \n        E\n        \n          |\n        \n        )\n      \n    \n    {\\displaystyle O(|V|\\cdot |E|)}\n  \n time, where \n  \n    \n      \n        \n          |\n        \n        V\n        \n          |\n        \n      \n    \n    {\\displaystyle |V|}\n  \n and \n  \n    \n      \n        \n          |\n        \n        E\n        \n          |\n        \n      \n    \n    {\\displaystyle |E|}\n  \n are the number of vertices and edges respectively.\n\nfunction BellmanFord(list vertices, list edges, vertex source) is\n\n    // This implementation takes in a graph, represented as\n    // lists of vertices (represented as integers [0..n-1]) and\n    // edges, and fills two arrays (distance and predecessor)\n    // holding the shortest path from the source to each vertex\n\n    distance := list of size n\n    predecessor := list of size n\n\n    // Step 1: initialize graph\n    for each vertex v in vertices do\n        // Initialize the distance to all vertices to infinity\n        distance[v] := inf\n        // And having a null predecessor\n        predecessor[v] := null\n    \n    // The distance from the source to itself is zero\n    distance[source] := 0\n\n    // Step 2: relax edges repeatedly\n    repeat |V|−1 times:\n        for each edge (u, v) with weight w in edges do\n            if distance[u] + w < distance[v] then\n                distance[v] := distance[u] + w\n                predecessor[v] := u\n\n    // Step 3: check for negative-weight cycles\n    for each edge (u, v) with weight w in edges do\n        if distance[u] + w < distance[v] then\n            predecessor[v] := u\n            // A negative cycle exists;\n            // find a vertex on the cycle\n            visited := list of size n initialized with false\n            visited[v] := true\n            while not visited[u] do\n                visited[u] := true\n                u := predecessor[u]\n            // u is a vertex in a negative cycle,\n            // find the cycle itself\n            ncycle := [u]\n            v := predecessor[u]\n            while v != u do\n                ncycle := concatenate([v], ncycle)\n                v := predecessor[v]\n            error \"Graph contains a negative-weight cycle\", ncycle\n    return distance, predecessor\n\nSimply put, the algorithm initializes the distance to the source to 0 and all other nodes to infinity.",
    "links": [
      "A* search algorithm",
      "Algorithm",
      "Alpha–beta pruning",
      "ArXiv (identifier)",
      "Autonomous system (Internet)",
      "B*",
      "Beam search",
      "Best, worst and average case",
      "Best-first search",
      "Bidirectional search",
      "Big O notation",
      "Borůvka's algorithm",
      "Breadth-first search",
      "Charles E. Leiserson",
      "Clifford Stein",
      "Cycle (graph theory)",
      "Cycle detection",
      "D*",
      "D. R. Fulkerson",
      "David Eppstein",
      "Dense graph",
      "Depth-first search",
      "Dijkstra's algorithm",
      "Distance-vector routing protocol",
      "Doi (identifier)",
      "Edward F. Moore",
      "Expected value",
      "Flow network",
      "Floyd–Warshall algorithm",
      "Fringe search",
      "Georgetown University",
      "Graph (data structure)",
      "Graph traversal",
      "Greedy algorithm",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "Introduction to Algorithms",
      "Iterative deepening A*",
      "Iterative deepening depth-first search",
      "Johnson's algorithm",
      "Jon Kleinberg",
      "Jump point search",
      "Kruskal's algorithm",
      "L. R. Ford Jr.",
      "Lexicographic breadth-first search",
      "Lifelong Planning A*",
      "List of algorithms",
      "MR (identifier)",
      "Mathematical induction",
      "Minimum-cost flow problem"
    ],
    "categories": [
      "Category:Articles with example C code",
      "Category:Articles with example pseudocode",
      "Category:Articles with short description",
      "Category:Dynamic programming",
      "Category:Graph algorithms",
      "Category:Graph distance",
      "Category:Polynomial-time problems",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Berndt–Hall–Hall–Hausman algorithm": {
    "title": "Berndt–Hall–Hall–Hausman algorithm",
    "url": "https://en.wikipedia.org/wiki/Berndt%E2%80%93Hall%E2%80%93Hall%E2%80%93Hausman_algorithm",
    "summary": "The Berndt–Hall–Hall–Hausman (BHHH) algorithm is a numerical optimization algorithm similar to the Newton–Raphson algorithm, but it replaces the observed negative Hessian matrix with the outer product of the gradient. This approximation is based on the information matrix equality and therefore only valid while maximizing a likelihood function. The BHHH algorithm is named after the four originators: Ernst R. Berndt, Bronwyn Hall, Robert Hall, and Jerry Hausman.",
    "content": "The Berndt–Hall–Hall–Hausman (BHHH) algorithm is a numerical optimization algorithm similar to the Newton–Raphson algorithm, but it replaces the observed negative Hessian matrix with the outer product of the gradient. This approximation is based on the information matrix equality and therefore only valid while maximizing a likelihood function. The BHHH algorithm is named after the four originators: Ernst R. Berndt, Bronwyn Hall, Robert Hall, and Jerry Hausman.\n\nUsage\nIf a nonlinear model is fitted to the data one often needs to estimate coefficients through optimization. A number of optimization algorithms have the following general structure. Suppose that the function to be optimized is Q(β). Then the algorithms are iterative, defining a sequence of approximations, βk given by\n\n  \n    \n      \n        \n          β\n          \n            k\n            +\n            1\n          \n        \n        =\n        \n          β\n          \n            k\n          \n        \n        −\n        \n          λ\n          \n            k\n          \n        \n        \n          A\n          \n            k\n          \n        \n        \n          \n            \n              ∂\n              Q\n            \n            \n              ∂\n              β\n            \n          \n        \n        (\n        \n          β\n          \n            k\n          \n        \n        )\n        ,\n      \n    \n    {\\displaystyle \\beta _{k+1}=\\beta _{k}-\\lambda _{k}A_{k}{\\frac {\\partial Q}{\\partial \\beta }}(\\beta _{k}),}\n  \n,\nwhere \n  \n    \n      \n        \n          β\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle \\beta _{k}}\n  \n is the parameter estimate at step k, and \n  \n    \n      \n        \n          λ\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle \\lambda _{k}}\n  \n is a parameter (called step size) which partly determines the particular algorithm. For the BHHH algorithm λk is determined by calculations within a given iterative step, involving a line-search until a point βk+1 is found satisfying certain criteria. In addition, for the BHHH algorithm, Q has the form\n\n  \n    \n      \n        Q\n        =\n        \n          ∑\n          \n            i\n            =\n            1\n          \n          \n            N\n          \n        \n        \n          Q\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle Q=\\sum _{i=1}^{N}Q_{i}}\n  \n\nand A is calculated using\n\n  \n    \n      \n        \n          A\n          \n            k\n          \n        \n        =\n        \n          \n            [\n            \n              \n                ∑\n                \n                  i\n                  =\n                  1\n                \n                \n                  N\n                \n              \n              \n                \n                  \n                    ∂\n                    ln\n                    ⁡\n                    \n                      Q\n                      \n                        i\n                      \n                    \n                  \n                  \n                    ∂\n                    β\n                  \n                \n              \n              (\n              \n                β\n                \n                  k\n                \n              \n              )\n              \n                \n                  \n                    ∂\n                    ln\n                    ⁡\n                    \n                      Q\n                      \n                        i\n                      \n                    \n                  \n                  \n                    ∂\n                    β\n                  \n                \n              \n              (\n              \n                β\n                \n                  k\n                \n              \n              \n                )\n                ′\n              \n            \n            ]\n          \n          \n            −\n            1\n          \n        \n        .\n      \n    \n    {\\displaystyle A_{k}=\\left[\\sum _{i=1}^{N}{\\frac {\\partial \\ln Q_{i}}{\\partial \\beta }}(\\beta _{k}){\\frac {\\partial \\ln Q_{i}}{\\partial \\beta }}(\\beta _{k})'\\right]^{-1}.}\n  \n\nIn other cases, e.g. Newton–Raphson, \n  \n    \n      \n        \n          A\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle A_{k}}\n  \n can have other forms. The BHHH algorithm has the advantage that, if certain conditions apply, convergence of the iterative procedure is guaranteed.\n\nSee also\nDavidon–Fletcher–Powell (DFP) algorithm\nBroyden–Fletcher–Goldfarb–Shanno (BFGS) algorithm\n\nReferences\nFurther reading\nV. Martin, S. Hurn, and D. Harris, Econometric Modelling with Time Series, Chapter 3 'Numerical Estimation Methods'. Cambridge University Press, 2015.\nAmemiya, Takeshi (1985). Advanced Econometrics. Cambridge: Harvard University Press. pp. 137–138. ISBN 0-674-00560-0.\nGill, P.; Murray, W.; Wright, M. (1981). Practical Optimization. London: Harcourt Brace.\nGourieroux, Christian; Monfort, Alain (1995). \"Gr",
    "links": [
      "Active-set method",
      "Affine scaling",
      "Algorithm",
      "Approximation algorithm",
      "Augmented Lagrangian method",
      "Barrier function",
      "Bellman–Ford algorithm",
      "Borůvka's algorithm",
      "Branch and bound",
      "Branch and cut",
      "Bronwyn Hall",
      "Broyden–Fletcher–Goldfarb–Shanno algorithm",
      "Coefficient",
      "Combinatorial optimization",
      "Comparison of optimization software",
      "Convex minimization",
      "Convex optimization",
      "Criss-cross algorithm",
      "Cutting-plane method",
      "Data",
      "Davidon–Fletcher–Powell algorithm",
      "Davidon–Fletcher–Powell formula",
      "Dijkstra's algorithm",
      "Dinic's algorithm",
      "Doi (identifier)",
      "Dynamic programming",
      "Edmonds–Karp algorithm",
      "Ellipsoid method",
      "Ernst R. Berndt",
      "Evolutionary algorithm",
      "Exchange algorithm",
      "Fisher information",
      "Flow network",
      "Floyd–Warshall algorithm",
      "Ford–Fulkerson algorithm",
      "Frank–Wolfe algorithm",
      "Function (mathematics)",
      "Gauss–Newton algorithm",
      "Golden-section search",
      "Gradient",
      "Gradient descent",
      "Graph algorithm",
      "Greedy algorithm",
      "Hessian matrix",
      "Heuristic algorithm",
      "Hill climbing",
      "ISBN (identifier)",
      "Integer programming",
      "Iterative method",
      "Jerry Hausman"
    ],
    "categories": [
      "Category:All articles with unsourced statements",
      "Category:Articles with unsourced statements from March 2013",
      "Category:Estimation methods",
      "Category:Optimization algorithms and methods"
    ]
  },
  "Biological systems engineering": {
    "title": "Biological systems engineering",
    "url": "https://en.wikipedia.org/wiki/Biological_systems_engineering",
    "summary": "Biological systems engineering or biosystems engineering is a broad-based engineering discipline with particular emphasis on non-medical biology. It can be thought of as a subset of the broader notion of biological engineering or bio-technology though not in the respects that pertain to biomedical engineering as biosystems engineering tends to focus less on medical applications than on agriculture, ecosystems, and food science. The discipline focuses broadly on environmentally sound and sustainable engineering solutions to meet societies' ecologically related needs. Biosystems engineering integrates the expertise of fundamental engineering fields with expertise from non-engineering disciplines.",
    "content": "Biological systems engineering or biosystems engineering is a broad-based engineering discipline with particular emphasis on non-medical biology. It can be thought of as a subset of the broader notion of biological engineering or bio-technology though not in the respects that pertain to biomedical engineering as biosystems engineering tends to focus less on medical applications than on agriculture, ecosystems, and food science. The discipline focuses broadly on environmentally sound and sustainable engineering solutions to meet societies' ecologically related needs. Biosystems engineering integrates the expertise of fundamental engineering fields with expertise from non-engineering disciplines.\n\nBackground and organization\nMany college and university biological engineering departments have a history of being grounded in agricultural engineering and have only in the past two decades or so changed their names to reflect the movement towards more diverse biological based engineering programs.  This major is sometimes called agricultural and biological engineering, biological and environmental engineering, etc., in different universities, generally reflecting interests of local employment opportunities.\nSince biological engineering covers a wide spectrum, many departments now offer specialization options. Depending on the department and the specialization options offered within each program, curricula may overlap with other related fields. There are a number of different titles for BSE-related departments at various universities.  The professional societies commonly associated with many Biological Engineering programs include the American Society of Agricultural and Biological Engineers (ASABE) and the  Institute of Biological Engineering (IBE), which generally encompasses BSE.  Some program also participate in the Biomedical Engineering Society (BMES)  and the American Institute of Chemical Engineers (AIChE).\nA biological systems engineer has a background in what both environmental engineers and biologists do, thus bridging the gap between engineering and the (non-medical) biological sciences – although this is variable across academic institutions.   For this reason, biological systems engineers are becoming integral parts of many environmental engineering firms, federal agencies, and biotechnology industries.  A biological systems engineer will often address the solution to a problem from the perspective of employing living systems to enact change.  For example, biological treatment methodologies can be applied to provide access to clean drinking water  or for sequestration of carbon dioxide.\n\nSpecializations\nLand and water resources engineering\nFood engineering and bioprocess engineering\nMachinery systems engineering\nNatural resources and environmental engineering\nBiomedical engineering\n\nAcademic programs in agricultural and biological systems engineering\nBelow is a listing of known academic programs that offer bachelor's degrees (B.S. or B.S.E.) in what ABET and/or ASABE terms \"agricultural engineering\", \"biological systems engineering\", \"biological engineering\", or similarly named programs.  ABET accredits college and university programs in the disciplines of applied science, computing, engineering, and engineering technology. ASABE defines accredited programs within the scope of  Ag/Bio Engineering.\n\nNorth America\nCentral and South America\nEurope\nAsia\nAfrica\nSee also\nReferences\nFurther reading\n2003, Dennis R. Heldman (ed), Encyclopedia of agricultural, food, and biological engineering.\n2002, Teruyuki Nagamune, Tai Hyun Park & Mark R. Marten (ed), Biological Systems Engineering, Washington, D.C. : American Chemical Society, 320 pages.\n2012, Paige Brown Jarreau, What is Biological Engineering, http://www.scilogs.com/from_the_lab_bench/what-is-biological-engineering-ibe-2012/ Archived 2016-08-10 at the Wayback Machine\n\nExternal links\nUC San Diego, Department of Bioengineering, UCSD BE part of University of California, San Diego",
    "links": [
      "ABET",
      "Aarhus University",
      "Aerospace engineering",
      "Agricultural engineering",
      "Agriculture",
      "Alanya Alaaddin Keykubat University",
      "American Society of Agricultural and Biological Engineers",
      "Animal Science",
      "Aquaculture engineering",
      "Arthur David Hall III",
      "Auburn University",
      "Aydın Adnan Menderes University",
      "Barbara Grosz",
      "Belgium",
      "Benjamin S. Blanchard",
      "Bilecik Şeyh Edebali University",
      "Bingöl University",
      "Biochemistry",
      "Biological engineering",
      "Biology",
      "Biomedical engineering",
      "Bioprocess engineering",
      "Biotechnology",
      "Bursa Uludağ University",
      "Business process",
      "CalPoly San Louis Obispo",
      "California State University, Bakersfield",
      "Carbon sequestration",
      "Chemical engineering",
      "Chemistry",
      "Civil engineering",
      "Clemson University",
      "Cognitive systems engineering",
      "Colorado State University",
      "Computer engineering",
      "Configuration management",
      "Control engineering",
      "Cornell University",
      "Dalhousie University",
      "Decision-making",
      "Denmark",
      "Derek Hitchins",
      "Design review",
      "Düzce University",
      "Earth systems engineering and management",
      "Ecological engineering",
      "Ecology",
      "Electrical engineering",
      "Engineering",
      "Enterprise systems engineering"
    ],
    "categories": [
      "Category:All articles with unsourced statements",
      "Category:Articles with unsourced statements from February 2009",
      "Category:Biological engineering",
      "Category:Biological systems",
      "Category:Systems biology",
      "Category:Systems engineering",
      "Category:Webarchive template wayback links"
    ]
  },
  "Borůvka's algorithm": {
    "title": "Borůvka's algorithm",
    "url": "https://en.wikipedia.org/wiki/Bor%C5%AFvka%27s_algorithm",
    "summary": "Borůvka's algorithm is a greedy algorithm for finding a minimum spanning tree in a graph,\nor a minimum spanning forest in the case of a graph that is not connected.\nIt was first published in 1926 by Otakar Borůvka as a method of constructing an efficient electricity network for Moravia.\nThe algorithm was rediscovered by Choquet in 1938; again by Florek,  Łukasiewicz, Perkal, Steinhaus, and Zubrzycki in 1951; and again by Georges Sollin in 1965. This algorithm is frequently called Sollin's algorithm, especially in the parallel computing literature.\nThe algorithm begins by finding the minimum-weight edge incident to each vertex of the graph, and adding all of those edges to the forest.\nThen, it repeats a similar process of finding the minimum-weight edge from each tree constructed so far to a different tree, and adding all of those edges to the forest.\nEach repetition of this process reduces the number of trees, within each connected component of the graph, to at most half of this former",
    "content": "Borůvka's algorithm is a greedy algorithm for finding a minimum spanning tree in a graph,\nor a minimum spanning forest in the case of a graph that is not connected.\nIt was first published in 1926 by Otakar Borůvka as a method of constructing an efficient electricity network for Moravia.\nThe algorithm was rediscovered by Choquet in 1938; again by Florek,  Łukasiewicz, Perkal, Steinhaus, and Zubrzycki in 1951; and again by Georges Sollin in 1965. This algorithm is frequently called Sollin's algorithm, especially in the parallel computing literature.\nThe algorithm begins by finding the minimum-weight edge incident to each vertex of the graph, and adding all of those edges to the forest.\nThen, it repeats a similar process of finding the minimum-weight edge from each tree constructed so far to a different tree, and adding all of those edges to the forest.\nEach repetition of this process reduces the number of trees, within each connected component of the graph, to at most half of this former value,\nso after logarithmically many repetitions the process finishes. When it does, the set of edges it has added forms the minimum spanning forest.\n\nPseudocode\nThe following pseudocode illustrates a basic implementation of Borůvka's algorithm.\nIn the conditional clauses, every edge uv is considered cheaper than \"None\".  The purpose of the completed variable is to determine whether the forest F is yet a spanning forest.\nIf edges do not have distinct weights, then a consistent tie-breaking rule must be used, e.g. based on some total order on vertices or edges.\nThis can be achieved by representing vertices as integers and comparing them directly; comparing their memory addresses; etc.\nA tie-breaking rule is necessary to ensure that the created graph is indeed a forest, that is, it does not contain cycles. For example, consider a triangle graph with nodes {a,b,c} and all edges of weight 1. Then a cycle could be created if we select ab as the minimal weight edge for {a}, bc for {b}, and ca for {c}.\nA tie-breaking rule which orders edges first by source, then by destination, will prevent creation of a cycle, resulting in the minimal spanning tree {ab, bc}.\n\nalgorithm Borůvka is\n    input: A weighted undirected graph G = (V, E).\n    output: F, a minimum spanning forest of G.\n\n    Initialize a forest F to (V, E′) where E′ = {}.\n\n    completed := false\n    while not completed do\n        Find the connected components of F and assign to each vertex its component\n        Initialize the cheapest edge for each component to \"None\"\n        for each edge uv in E, where u and v are in different components of F:\n            let wx be the cheapest edge for the component of u\n            if is-preferred-over(uv, wx) then\n                Set uv as the cheapest edge for the component of u\n            let yz be the cheapest edge for the component of v\n            if is-preferred-over(uv, yz) then\n                Set uv as the cheapest edge for the component of v\n        if all components have cheapest edge set to \"None\" then\n            // no more trees can be merged -- we are finished\n            completed := true\n        else\n            completed := false\n            for each component whose cheapest edge is not \"None\" do\n                Add its cheapest edge to E'\n\nfunction is-preferred-over(edge1, edge2) is\n    return (edge2 is \"None\") or\n           (weight(edge1) < weight(edge2)) or\n           (weight(edge1) = weight(edge2) and tie-breaking-rule(edge1, edge2))\n\nfunction tie-breaking-rule(edge1, edge2) is\n    The tie-breaking rule; returns true if and only if edge1\n    is preferred over edge2 in the case of a tie.\n\nAs an optimization, one could remove from G each edge that is found to connect two vertices in the same component, so that it does not contribute to the time for searching for cheapest edges in later components.\n\nComplexity\nBorůvka's algorithm can be shown to take O(log V) iterations of the outer loop until it terminates, and therefore to run in time O(E log V), where E is the number of edges, and V is the number of vertices in G (assuming E ≥ V). In planar graphs, and more generally in families of graphs closed under graph minor operations, it can be made to run in linear time, by removing all but the cheapest edge between each pair of components after each stage of the algorithm.\n\nExample\nOther algorithms\nOther algorithms for this problem include Prim's algorithm and Kruskal's algorithm. Fast parallel algorithms can be obtained by combining Prim's algorithm with Borůvka's.\nA faster randomized minimum spanning tree algorithm based in part on Borůvka's algorithm due to Karger, Klein, and Tarjan runs in expected O(E) time.  The best known (deterministic) minimum spanning tree algorithm by Bernard Chazelle is also based in part on Borůvka's and runs in O(E α(E,V)) time, where α is the inverse Ackermann function. These randomized and deterministic algorithms combine steps of Borůvka's algorithm, reducing the number of components that ",
    "links": [
      "A* search algorithm",
      "Ackermann function",
      "Alpha–beta pruning",
      "B*",
      "Beam search",
      "Bellman–Ford algorithm",
      "Bernard Chazelle",
      "Best, worst and average case",
      "Best-first search",
      "Bidirectional search",
      "Big O notation",
      "Breadth-first search",
      "CiteSeerX (identifier)",
      "Component (graph theory)",
      "D*",
      "David Eppstein",
      "Depth-first search",
      "Dijkstra's algorithm",
      "Discrete Mathematics (journal)",
      "Doi (identifier)",
      "Electricity network",
      "Floyd–Warshall algorithm",
      "Fringe search",
      "Graph (abstract data type)",
      "Graph minor",
      "Graph traversal",
      "Greedy algorithm",
      "Gustave Choquet",
      "Hdl (identifier)",
      "Hugo Steinhaus",
      "Iterative deepening A*",
      "Iterative deepening depth-first search",
      "Jan Łukasiewicz",
      "Jaroslav Nešetřil",
      "Johnson's algorithm",
      "Jorge Urrutia Galicia",
      "Julian Perkal",
      "Jump point search",
      "Jörg-Rüdiger Sack",
      "Kazimierz Florek",
      "Kruskal's algorithm",
      "Lexicographic breadth-first search",
      "Lifelong Planning A*",
      "List of algorithms",
      "MR (identifier)",
      "Memory address",
      "Minimum spanning tree",
      "Monte Carlo tree search",
      "Moravia",
      "Otakar Borůvka"
    ],
    "categories": [
      "Category:Articles with example pseudocode",
      "Category:Articles with short description",
      "Category:CS1 Czech-language sources (cs)",
      "Category:CS1 French-language sources (fr)",
      "Category:CS1 German-language sources (de)",
      "Category:Graph algorithms",
      "Category:Short description is different from Wikidata",
      "Category:Spanning tree"
    ]
  },
  "Broyden–Fletcher–Goldfarb–Shanno algorithm": {
    "title": "Broyden–Fletcher–Goldfarb–Shanno algorithm",
    "url": "https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm",
    "summary": "In numerical optimization, the Broyden–Fletcher–Goldfarb–Shanno (BFGS) algorithm is an iterative method for solving unconstrained nonlinear optimization problems. Like the related Davidon–Fletcher–Powell method, BFGS determines the descent direction by preconditioning the gradient with curvature information. It does so by gradually improving an approximation to the Hessian matrix of the loss function, obtained only from gradient evaluations (or approximate gradient evaluations) via a generalized secant method.\nSince the updates of the BFGS curvature matrix do not require matrix inversion, its computational complexity is only \n  \n    \n      \n        \n          \n            O\n          \n        \n        (\n        \n          n\n          \n            2\n          \n        \n        )\n      \n    \n    {\\displaystyle {\\mathcal {O}}(n^{2})}\n  \n, compared to \n  \n    \n      \n        \n          \n            O\n          \n        \n        (\n        \n          n\n          \n            3\n          \n   ",
    "content": "In numerical optimization, the Broyden–Fletcher–Goldfarb–Shanno (BFGS) algorithm is an iterative method for solving unconstrained nonlinear optimization problems. Like the related Davidon–Fletcher–Powell method, BFGS determines the descent direction by preconditioning the gradient with curvature information. It does so by gradually improving an approximation to the Hessian matrix of the loss function, obtained only from gradient evaluations (or approximate gradient evaluations) via a generalized secant method.\nSince the updates of the BFGS curvature matrix do not require matrix inversion, its computational complexity is only \n  \n    \n      \n        \n          \n            O\n          \n        \n        (\n        \n          n\n          \n            2\n          \n        \n        )\n      \n    \n    {\\displaystyle {\\mathcal {O}}(n^{2})}\n  \n, compared to \n  \n    \n      \n        \n          \n            O\n          \n        \n        (\n        \n          n\n          \n            3\n          \n        \n        )\n      \n    \n    {\\displaystyle {\\mathcal {O}}(n^{3})}\n  \n in Newton's method. Also in common use is L-BFGS, which is a limited-memory version of BFGS that is particularly suited to problems with very large numbers of variables (e.g., >1000). The BFGS-B variant handles simple box constraints. The BFGS matrix also admits a compact representation, which makes it better suited for large constrained problems.\nThe algorithm is named after Charles George Broyden, Roger Fletcher, Donald Goldfarb and David Shanno.\n\nRationale\nThe optimization problem is to minimize \n  \n    \n      \n        f\n        (\n        \n          x\n        \n        )\n      \n    \n    {\\displaystyle f(\\mathbf {x} )}\n  \n, where \n  \n    \n      \n        \n          x\n        \n      \n    \n    {\\displaystyle \\mathbf {x} }\n  \n is a vector in \n  \n    \n      \n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{n}}\n  \n, and \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n is a differentiable scalar function. There are no constraints on the values that \n  \n    \n      \n        \n          x\n        \n      \n    \n    {\\displaystyle \\mathbf {x} }\n  \n can take.\nThe algorithm begins at an initial estimate \n  \n    \n      \n        \n          \n            x\n          \n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {x} _{0}}\n  \n for the optimal value and proceeds iteratively to get a better estimate at each stage.\nThe search direction pk at stage k is given by the solution of the analogue of the Newton equation:\n\n  \n    \n      \n        \n          B\n          \n            k\n          \n        \n        \n          \n            p\n          \n          \n            k\n          \n        \n        =\n        −\n        ∇\n        f\n        (\n        \n          \n            x\n          \n          \n            k\n          \n        \n        )\n        ,\n      \n    \n    {\\displaystyle B_{k}\\mathbf {p} _{k}=-\\nabla f(\\mathbf {x} _{k}),}\n  \n\nwhere \n  \n    \n      \n        \n          B\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle B_{k}}\n  \n is an approximation to the Hessian matrix at \n  \n    \n      \n        \n          \n            x\n          \n          \n            k\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {x} _{k}}\n  \n, which is updated iteratively at each stage, and \n  \n    \n      \n        ∇\n        f\n        (\n        \n          \n            x\n          \n          \n            k\n          \n        \n        )\n      \n    \n    {\\displaystyle \\nabla f(\\mathbf {x} _{k})}\n  \n is the gradient of the function evaluated at xk.  A line search in the direction pk is then used to find the next point xk+1 by minimizing \n  \n    \n      \n        f\n        (\n        \n          \n            x\n          \n          \n            k\n          \n        \n        +\n        γ\n        \n          \n            p\n          \n          \n            k\n          \n        \n        )\n      \n    \n    {\\displaystyle f(\\mathbf {x} _{k}+\\gamma \\mathbf {p} _{k})}\n  \n over the scalar \n  \n    \n      \n        γ\n        >\n        0.\n      \n    \n    {\\displaystyle \\gamma >0.}\n  \n\nThe quasi-Newton condition imposed on the update of \n  \n    \n      \n        \n          B\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle B_{k}}\n  \n is\n\n  \n    \n      \n        \n          B\n          \n            k\n            +\n            1\n          \n        \n        (\n        \n          \n            x\n          \n          \n            k\n            +\n            1\n          \n        \n        −\n        \n          \n            x\n          \n          \n            k\n          \n        \n        )\n        =\n        ∇\n        f\n        (\n        \n          \n            x\n          \n          \n            k\n            +\n            1\n          \n        \n        )\n        −\n        ∇\n        f\n        (\n        \n          \n            x\n          \n       ",
    "links": [
      "ALGLIB",
      "Active-set method",
      "Affine scaling",
      "Approximation algorithm",
      "Artelys Knitro",
      "Augmented Lagrangian method",
      "BHHH algorithm",
      "Barrier function",
      "Bellman–Ford algorithm",
      "Berndt–Hall–Hall–Hausman algorithm",
      "Borůvka's algorithm",
      "Branch and bound",
      "Branch and cut",
      "Bunchofuckingoofs",
      "Charles George Broyden",
      "CiteSeerX (identifier)",
      "Claude Lemaréchal",
      "Claudia Sagastizábal",
      "Combinatorial optimization",
      "Compact quasi-Newton representation",
      "Comparison of optimization software",
      "Computational complexity of mathematical operations",
      "Confidence interval",
      "Convex minimization",
      "Convex optimization",
      "Credible interval",
      "Criss-cross algorithm",
      "Cutting-plane method",
      "David G. Luenberger",
      "David Shanno",
      "Davidon–Fletcher–Powell formula",
      "Descent direction",
      "Dijkstra's algorithm",
      "Dinic's algorithm",
      "Doi (identifier)",
      "Donald Goldfarb",
      "Dynamic programming",
      "Edmonds–Karp algorithm",
      "Ellipsoid method",
      "Evolutionary algorithm",
      "Exchange algorithm",
      "Flow network",
      "Floyd–Warshall algorithm",
      "Ford–Fulkerson algorithm",
      "Frank–Wolfe algorithm",
      "Function (mathematics)",
      "GNU Octave",
      "GNU Scientific Library",
      "Gauss–Newton algorithm",
      "Golden-section search"
    ],
    "categories": [
      "Category:All articles needing additional references",
      "Category:All articles with unsourced statements",
      "Category:Articles needing additional references from March 2016",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from May 2021",
      "Category:Optimization algorithms and methods",
      "Category:Short description matches Wikidata"
    ]
  },
  "Abramowitz and Stegun": {
    "title": "Abramowitz and Stegun",
    "url": "https://en.wikipedia.org/wiki/Abramowitz_and_Stegun",
    "summary": "Abramowitz and Stegun (AS) is the informal name of a 1964 mathematical reference work edited by Milton Abramowitz and Irene Stegun of the United States National Bureau of Standards (NBS), now the National Institute of Standards and Technology (NIST). Its full title is Handbook of Mathematical Functions with Formulas, Graphs, and Mathematical Tables.  A digital successor to the Handbook was released as the \"Digital Library of Mathematical Functions\" (DLMF) on 11 May 2010, along with a printed version, the NIST Handbook of Mathematical Functions, published by Cambridge University Press.",
    "content": "Abramowitz and Stegun (AS) is the informal name of a 1964 mathematical reference work edited by Milton Abramowitz and Irene Stegun of the United States National Bureau of Standards (NBS), now the National Institute of Standards and Technology (NIST). Its full title is Handbook of Mathematical Functions with Formulas, Graphs, and Mathematical Tables.  A digital successor to the Handbook was released as the \"Digital Library of Mathematical Functions\" (DLMF) on 11 May 2010, along with a printed version, the NIST Handbook of Mathematical Functions, published by Cambridge University Press.\n\nOverview\nSince it was first published in 1964, the 1046-page Handbook has been one of the most comprehensive sources of information on special functions, containing definitions, identities, approximations, plots, and tables of values of numerous functions used in virtually all fields of applied mathematics. The notation used in the Handbook is the de facto standard for much of applied mathematics today.\nAt the time of its publication, the Handbook was an essential resource for practitioners. Nowadays, scientific calculators, numerical analysis software packages, and computer algebra systems have replaced the function tables, but the Handbook remains an important reference source. The foreword discusses a meeting in 1954 in which it was agreed that \"the advent of high-speed computing equipment changed the task of table making but definitely did not remove the need for tables\".\n\nMore than 1,000 pages long, the Handbook of Mathematical Functions was first published in 1964 and reprinted many times, with yet another reprint in 1999. Its influence on science and engineering is evidenced by its popularity. In fact, when New Scientist magazine recently asked some of the world's leading scientists what single book they would want if stranded on a desert island, one distinguished British physicist said he would take the Handbook.\nThe Handbook is likely the most widely distributed and most cited NIST technical publication of all time. Government sales exceed 150,000 copies, and an estimated three times as many have been reprinted and sold by commercial publishers since 1965. During the mid-1990s, the book was cited every 1.5 hours of each working day. And its influence will persist as it is currently being updated in digital format by NIST.\n\nThe chapters are:\n\nMathematical Constants\nPhysical Constants and Conversion Factors\nElementary Analytical Methods\nElementary Transcendental Functions\nExponential Integral and Related Functions\nGamma Function and Related Functions\nError Function and Fresnel Integrals\nLegendre Functions\nBessel Functions of Integral Order\nBessel Functions of Fractional Order\nIntegrals of Bessel Functions\nStruve Functions and Related Functions\nConfluent Hypergeometric Functions\nCoulomb Wave Functions\nHypergeometric Functions\nJacobian Elliptic Functions and Theta Functions\nElliptic Integrals\nWeierstrass Elliptic and Related Functions\nParabolic Cylinder Functions\nMathieu Functions\nSpheroidal Wave Functions\nOrthogonal Polynomials\nBernoulli and Euler Polynomials, Riemann Zeta Function\nCombinatorial Analysis\nNumerical Interpolation, Differentiation, and Integration\nProbability Functions\nMiscellaneous Functions\nScales of Notation\nLaplace Transforms\n\nEditions\nBecause the Handbook is the work of U.S. federal government employees acting in their official capacity, it is not protected by copyright in the United States. While it could be ordered from the Government Printing Office, it has also been reprinted by commercial publishers, most notably Dover Publications (ISBN 0-486-61272-4), and can be legally viewed on and downloaded from the web.\nWhile there was only one edition of the work, it went through many print runs including a growing number of corrections.\nOriginal NBS edition:\n\n1st printing: June 1964; errata:\n2nd printing with corrections: November 1964; errata:\n3rd printing with corrections: March 1965; errata:\n4th printing with corrections: December 1965; errata:\n5th printing with corrections: August 1966\n6th printing with corrections: November 1967\n7th printing with corrections: May 1968\n8th printing with corrections: 1969\n9th printing with corrections: November 1970\n10th printing with corrections: December 1972\nReprint edition by Dover Publications:\n\n1st printing: 1965\n?\n9th printing with additional corrections (based on 10th printing of NBS edition with corrections)\n\nRelated projects\nMichael Danos and Johann Rafelski edited the Pocketbook of Mathematical Functions, published by Verlag Harri Deutsch in 1984. The book is an abridged version of Abramowitz's and Stegun's Handbook, retaining most of the formulas (except for the first and the two last original chapters, which were dropped), but reducing the numerical tables to a minimum, which, by this time, could be easily calculated with scientific pocket calculators. The references were removed as well. Most known errata were incorporated, the physical constants updated",
    "links": [
      "Analysis (mathematics)",
      "Applied mathematics",
      "BINAS",
      "Bateman Manuscript Project",
      "Bernoulli polynomials",
      "Bessel function",
      "Boole's rule",
      "Bronshtein and Semendyayev",
      "CODEN (identifier)",
      "CRC Press",
      "CRC Standard Mathematical Tables",
      "Cambridge University Press",
      "Combinatorial analysis",
      "Common logarithm",
      "Computer algebra system",
      "Confluent hypergeometric function",
      "Copyright status of work by the U.S. government",
      "Coulomb wave function",
      "Daniel Shanks",
      "De facto",
      "Digital Library of Mathematical Functions",
      "Doi (identifier)",
      "Dover Publications",
      "EISSN (identifier)",
      "Elliptic integral",
      "Errata",
      "Error Function",
      "Exponential integral",
      "Federal government of the United States",
      "Frank Olver",
      "Frank William John Olver",
      "Fresnel integral",
      "Gamma function",
      "Gradshteyn and Ryzhik",
      "Handbook",
      "Hypergeometric functions",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "Irene A. Stegun",
      "Irene Ann Stegun",
      "Irene Stegun",
      "JSTOR (identifier)",
      "Jacobi elliptic functions",
      "Jacobian elliptic function",
      "Jahnke and Emde",
      "James Harold Davenport",
      "Johann Rafelski",
      "John William Wrench, Jr.",
      "LCCN (identifier)",
      "Laplace Transform"
    ],
    "categories": [
      "Category:1964 non-fiction books",
      "Category:Articles with short description",
      "Category:Mathematical tables",
      "Category:Mathematics handbooks",
      "Category:Numerical analysis",
      "Category:Reference works in the public domain",
      "Category:Short description is different from Wikidata",
      "Category:Special functions",
      "Category:Use dmy dates from December 2021",
      "Category:Use list-defined references from December 2021"
    ]
  },
  "Additive group": {
    "title": "Additive group",
    "url": "https://en.wikipedia.org/wiki/Additive_group",
    "summary": "An additive group is a group of which the group operation is to be thought of as addition in some sense.  It is usually abelian, and typically written using the symbol + for its binary operation.\nThis terminology is widely used with structures equipped with several operations for specifying the structure obtained by forgetting the other operations. Examples include the additive group of the integers, of a vector space and of a ring. This is particularly useful with rings and fields to distinguish the additive underlying group from the multiplicative group of the invertible elements.\nIn older terminology, an additive subgroup of a ring has also been known as a modul or module (not to be confused with a module).\n\n\n== References ==",
    "content": "An additive group is a group of which the group operation is to be thought of as addition in some sense.  It is usually abelian, and typically written using the symbol + for its binary operation.\nThis terminology is widely used with structures equipped with several operations for specifying the structure obtained by forgetting the other operations. Examples include the additive group of the integers, of a vector space and of a ring. This is particularly useful with rings and fields to distinguish the additive underlying group from the multiplicative group of the invertible elements.\nIn older terminology, an additive subgroup of a ring has also been known as a modul or module (not to be confused with a module).\n\n\n== References ==",
    "links": [
      "Abelian group",
      "Field (mathematics)",
      "Group (mathematics)",
      "Group theory",
      "ISBN (identifier)",
      "Integers",
      "Module (mathematics)",
      "Multiplicative group",
      "Ring (mathematics)",
      "Unit (ring theory)",
      "Vector space",
      "Wikipedia:Stub",
      "Template:Group-theory-stub",
      "Template talk:Group-theory-stub"
    ],
    "categories": [
      "Category:Algebraic structures",
      "Category:All stub articles",
      "Category:Articles with short description",
      "Category:Group theory",
      "Category:Group theory stubs",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Affine group": {
    "title": "Affine group",
    "url": "https://en.wikipedia.org/wiki/Affine_group",
    "summary": "In mathematics, the affine group or general affine group of any affine space is the group of all invertible affine transformations from the space into itself.  In the case of a Euclidean space (where the associated field of scalars is the real numbers), the affine group consists of those functions from the space to itself such that the image of every line is a line.\nOver any field, the affine group may be viewed as a matrix group in a natural way.  If the associated field of scalars is the real or complex field, then the affine group is a Lie group.",
    "content": "In mathematics, the affine group or general affine group of any affine space is the group of all invertible affine transformations from the space into itself.  In the case of a Euclidean space (where the associated field of scalars is the real numbers), the affine group consists of those functions from the space to itself such that the image of every line is a line.\nOver any field, the affine group may be viewed as a matrix group in a natural way.  If the associated field of scalars is the real or complex field, then the affine group is a Lie group.\n\nRelation to general linear group\nConstruction from general linear group\nConcretely, given a vector space V, it has an underlying affine space A obtained by \"forgetting\" the origin, with V acting by translations, and the affine group of A can be described concretely as the semidirect product of V by GL(V), the general linear group of V:\n\n  \n    \n      \n        Aff\n        ⁡\n        (\n        V\n        )\n        =\n        V\n        ⋊\n        GL\n        ⁡\n        (\n        V\n        )\n      \n    \n    {\\displaystyle \\operatorname {Aff} (V)=V\\rtimes \\operatorname {GL} (V)}\n  \n\nThe action of GL(V) on V is the natural one (linear transformations are automorphisms), so this defines a semidirect product.\nIn terms of matrices, one writes:\n\n  \n    \n      \n        Aff\n        ⁡\n        (\n        n\n        ,\n        K\n        )\n        =\n        \n          K\n          \n            n\n          \n        \n        ⋊\n        GL\n        ⁡\n        (\n        n\n        ,\n        K\n        )\n      \n    \n    {\\displaystyle \\operatorname {Aff} (n,K)=K^{n}\\rtimes \\operatorname {GL} (n,K)}\n  \n\nwhere here the natural action of GL(n, K) on Kn is matrix multiplication of a vector.\n\nStabilizer of a point\nGiven the affine group of an affine space A, the stabilizer of a point p is isomorphic to the general linear group of the same dimension (so the stabilizer of a point in Aff(2, R) is isomorphic to GL(2, R)); formally, it is the general linear group of the vector space (A, p): recall that if one fixes a point, an affine space becomes a vector space.\nAll these subgroups are conjugate, where conjugation is given by translation from p to q (which is uniquely defined), however, no particular subgroup is a natural choice, since no point is special – this corresponds to the multiple choices of transverse subgroup, or splitting of the short exact sequence\n\n  \n    \n      \n        1\n        →\n        V\n        →\n        V\n        ⋊\n        GL\n        ⁡\n        (\n        V\n        )\n        →\n        GL\n        ⁡\n        (\n        V\n        )\n        →\n        1\n        \n        .\n      \n    \n    {\\displaystyle 1\\to V\\to V\\rtimes \\operatorname {GL} (V)\\to \\operatorname {GL} (V)\\to 1\\,.}\n  \n\nIn the case that the affine group was constructed by starting with a vector space, the subgroup that stabilizes the origin (of the vector space) is the original GL(V).\n\nMatrix representation\nRepresenting the affine group as a semidirect product of V by GL(V), then by construction of the semidirect product, the elements are pairs (v, M), where v is a vector in V and M is a linear transform in GL(V), and multiplication is given by\n\n  \n    \n      \n        (\n        v\n        ,\n        M\n        )\n        ⋅\n        (\n        w\n        ,\n        N\n        )\n        =\n        (\n        v\n        +\n        M\n        w\n        ,\n        M\n        N\n        )\n        \n        .\n      \n    \n    {\\displaystyle (v,M)\\cdot (w,N)=(v+Mw,MN)\\,.}\n  \n\nThis can be represented as the (n + 1) × (n + 1) block matrix\n\n  \n    \n      \n        \n          (\n          \n            \n              \n                \n                  M\n                \n                \n                  v\n                \n              \n              \n                \n                  0\n                \n                \n                  1\n                \n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\left({\\begin{array}{c|c}M&v\\\\\\hline 0&1\\end{array}}\\right)}\n  \n\nwhere M is an n × n matrix over K, v an n × 1 column vector, 0 is a 1 × n row of zeros, and 1 is the 1 × 1 identity block matrix.\nFormally, Aff(V) is naturally isomorphic to a subgroup of GL(V ⊕ K), with V embedded as the affine plane {(v, 1) | v ∈ V}, namely the stabilizer of this affine plane; the above matrix formulation is the (transpose of the) realization of this, with the n × n and 1 × 1 blocks corresponding to the direct sum decomposition V ⊕ K.\nA similar representation is any (n + 1) × (n + 1) matrix in which the entries in each column sum to 1. The similarity P for passing from the above kind to this kind is the (n + 1) × (n + 1) identity matrix with the bottom row replaced by a row of all ones.\nEach of these two classes of matrices is closed under matrix multiplication.\nThe simplest paradigm may well be the case n = 1, that is, the upper triangular 2 × 2 matrices representing the affine group in one dimension. It is a two-parameter non-Abelian Li",
    "links": [
      "Affine Coxeter group",
      "Affine coordinate system",
      "Affine plane",
      "Affine space",
      "Affine transformation",
      "American Mathematical Monthly",
      "Block matrix",
      "Cambridge University Press",
      "Coordinate axes",
      "Doi (identifier)",
      "Eigenvalue",
      "Euclidean plane",
      "Euclidean space",
      "Fixed point (mathematics)",
      "General linear group",
      "Group (mathematics)",
      "Group action (mathematics)",
      "Group extension",
      "Group representation",
      "Holomorph (mathematics)",
      "Hyperplane",
      "Hyperplane at infinity",
      "ISBN (identifier)",
      "Identity matrix",
      "Isometry",
      "Jordan normal form",
      "Lattice (group)",
      "Lie group",
      "Lorentz group",
      "Marcel Berger",
      "Mathematics",
      "Matrix multiplication",
      "Matrix similarity",
      "Non-abelian group",
      "Orthogonal group",
      "Perpendicular",
      "Poincaré group",
      "Projective geometry",
      "Projectivity",
      "Real number",
      "Roger Lyndon",
      "Scaling (geometry)",
      "Semidirect product",
      "Shear mapping",
      "Short exact sequence",
      "Similarity (geometry)",
      "Special linear group",
      "Subgroup",
      "Theory of relativity",
      "Translation (geometry)"
    ],
    "categories": [
      "Category:Affine geometry",
      "Category:Articles with short description",
      "Category:Group theory",
      "Category:Lie groups",
      "Category:Short description matches Wikidata"
    ]
  },
  "Affine plane (incidence geometry)": {
    "title": "Affine plane (incidence geometry)",
    "url": "https://en.wikipedia.org/wiki/Affine_plane_(incidence_geometry)",
    "summary": "In geometry, an affine plane is a system of points and lines that satisfy the following axioms:\n\nAny two distinct points lie on a unique line.\nGiven any line and any point not on that line there is a unique line which contains the point and does not meet the given line. (Playfair's axiom)\nThere exist four points such that no three are collinear (points not on a single line).\nIn an affine plane, two lines are called parallel if they are equal or disjoint. Using this definition, Playfair's axiom above can be replaced by:\n\nGiven a point and a line, there is a unique line which contains the point and is parallel to the line.\nParallelism is an equivalence relation on the lines of an affine plane.\nSince no concepts other than those involving the relationship between points and lines are involved in the axioms, an affine plane is an object of study belonging to incidence geometry. They are non-degenerate linear spaces satisfying Playfair's axiom.\nThe familiar Euclidean plane is an affine plan",
    "content": "In geometry, an affine plane is a system of points and lines that satisfy the following axioms:\n\nAny two distinct points lie on a unique line.\nGiven any line and any point not on that line there is a unique line which contains the point and does not meet the given line. (Playfair's axiom)\nThere exist four points such that no three are collinear (points not on a single line).\nIn an affine plane, two lines are called parallel if they are equal or disjoint. Using this definition, Playfair's axiom above can be replaced by:\n\nGiven a point and a line, there is a unique line which contains the point and is parallel to the line.\nParallelism is an equivalence relation on the lines of an affine plane.\nSince no concepts other than those involving the relationship between points and lines are involved in the axioms, an affine plane is an object of study belonging to incidence geometry. They are non-degenerate linear spaces satisfying Playfair's axiom.\nThe familiar Euclidean plane is an affine plane. There are many finite and infinite affine planes. As well as affine planes over fields (and division rings), there are also many non-Desarguesian planes, not derived from coordinates in a division ring, satisfying these axioms. The Moulton plane is an example of one of these.\n\nFinite affine planes\nIf the number of points in an affine plane is finite, then if one line of the plane contains n points then:\n\neach line contains n points,\neach point is contained in n + 1 lines,\nthere are n2 points in all, and\nthere is a total of n2 + n lines.\nThe number n is called the order of the affine plane.\nAll known finite affine planes have orders that are prime or prime power integers. The smallest affine plane (of order 2) is obtained by removing a line and the three points on that line from the Fano plane. A similar construction, starting from the projective plane of order 3, produces the affine plane of order 3 sometimes called the Hesse configuration. An affine plane of order n exists if and only if a projective plane of order n exists (however, the definition of order in these two cases is not the same). Thus, there is no affine plane of order 6 or order 10 since there are no projective planes of those orders. The Bruck–Ryser–Chowla theorem provides further limitations on the order of a projective plane, and thus, the order of an affine plane.\nThe n2 + n lines of an affine plane of order n fall into n + 1 equivalence classes of n lines apiece under the equivalence relation of parallelism. These classes are called parallel classes of lines. The lines in any parallel class form a partition the points of the affine plane. Each of the n + 1 lines that pass through a single point lies in a different parallel class.\nThe parallel class structure of an affine plane of order n may be used to construct a set of n − 1 mutually orthogonal latin squares. Only the incidence relations are needed for this construction.\n\nRelation with projective planes\nAn affine plane can be obtained from any projective plane by removing a line and all the points on it, and conversely any affine plane can be used to construct a projective plane by adding a line at infinity, each of whose points is that point at infinity where an equivalence class of parallel lines meets.\nIf the projective plane is non-Desarguesian, the removal of different lines could result in non-isomorphic affine planes. For instance, there are exactly four projective planes of order nine, and seven affine planes of order nine. There is only one affine plane corresponding to the Desarguesian plane of order nine since the collineation group of that projective plane acts transitively on the lines of the plane. Each of the three non-Desarguesian planes of order nine have collineation groups having two orbits on the lines, producing two non-isomorphic affine planes of order nine, depending on which orbit the line to be removed is selected from.\n\nAffine translation planes\nA line l in a projective plane Π is a translation line if the group of elations with axis l acts transitively on the points of the affine plane obtained by removing l from the plane Π. A projective plane with a translation line is called a translation plane and the affine plane obtained by removing the translation line is called an affine translation plane. While in general it is often easier to work with projective planes, in this context the affine planes are preferred and several authors simply use the term translation plane to mean affine translation plane.\nAn alternate view of affine translation planes can be obtained as follows: Let V be a 2n-dimensional vector space over a field F. A spread of V is a set S of n-dimensional subspaces of V that partition the non-zero vectors of V. The members of S are called the components of the spread and if Vi and Vj are distinct components then Vi ⊕ Vj = V. Let A be the incidence structure whose points are the vectors of V and whose lines are the cosets of components, that is, sets of the for",
    "links": [
      "Affine plane",
      "Affine space",
      "American Mathematical Society",
      "Bruck–Ryser–Chowla theorem",
      "Characteristic (field)",
      "Collineation",
      "Desarguesian plane",
      "Disjoint sets",
      "Division ring",
      "Doi (identifier)",
      "Equivalence relation",
      "Euclidean plane",
      "Fano plane",
      "Field (mathematics)",
      "Geometry",
      "Group action (mathematics)",
      "Hesse configuration",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "Incidence geometry",
      "Incidence matrix",
      "Incidence structure",
      "JSTOR (identifier)",
      "Line at infinity",
      "Linear code",
      "Linear space (geometry)",
      "MR (identifier)",
      "Moulton plane",
      "Mutually orthogonal latin square",
      "Non-Desarguesian plane",
      "Peter Cameron (mathematician)",
      "Playfair's axiom",
      "Point at infinity",
      "Projective plane",
      "Projective space",
      "Reed-Muller Code",
      "Transactions of the American Mathematical Society",
      "Transitive (group action)",
      "Transitive property",
      "Translation (geometry)",
      "Translation plane",
      "Vector space"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Incidence geometry",
      "Category:Planes (geometry)",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Centre (geometry)": {
    "title": "Centre (geometry)",
    "url": "https://en.wikipedia.org/wiki/Centre_(geometry)",
    "summary": "In geometry, a centre  (Commonwealth English) or center (American English) (from Ancient Greek  κέντρον (kéntron) 'pointy object') of an object is a point in some sense in the middle of the object. According to the specific definition of centre taken into consideration, an object might have no centre. If geometry is regarded as the study of isometry groups, then a centre is a fixed point of all the isometries that move the object onto itself.",
    "content": "In geometry, a centre  (Commonwealth English) or center (American English) (from Ancient Greek  κέντρον (kéntron) 'pointy object') of an object is a point in some sense in the middle of the object. According to the specific definition of centre taken into consideration, an object might have no centre. If geometry is regarded as the study of isometry groups, then a centre is a fixed point of all the isometries that move the object onto itself.\n\nCircles, spheres, and segments\nThe centre of a circle is the point equidistant from the points on the edge. Similarly the centre of a sphere is the point equidistant from the points on the surface, and the centre of a line segment is the midpoint of the two ends.\n\nSymmetric objects\nFor objects with several symmetries, the centre of symmetry is the point left unchanged by the symmetric actions. So the centre of a square, rectangle, rhombus or parallelogram is where the diagonals intersect, this is (among other properties) the fixed point of rotational symmetries. Similarly the centre of an ellipse or a hyperbola is where the axes intersect.\n\nTriangles\nSeveral special points of a triangle are often described as triangle centres:\n\nthe circumcentre, which is the centre of the circle that passes through all three vertices;\nthe centroid or centre of mass, the point on which the triangle would balance if it had uniform density;\nthe incentre, the centre of the circle that is internally tangent to all three sides of the triangle;\nthe orthocentre, the intersection of the triangle's three altitudes; and\nthe nine-point centre, the centre of the circle that passes through nine key points of the triangle.\nFor an equilateral triangle, these are the same point, which lies at the intersection of the three axes of symmetry of the triangle, one third of the distance from its base to its apex.\nA strict definition of a triangle centre is a point whose trilinear coordinates are f(a,b,c) : f(b,c,a) : f(c,a,b) where f is a function of the lengths of the three sides of the triangle, a, b, c such that:\n\nf is homogeneous in a, b, c; i.e., f(ta,tb,tc)=thf(a,b,c) for some real power h; thus the position of a centre is independent of scale.\nf is symmetric in its last two arguments; i.e., f(a,b,c)= f(a,c,b); thus position of a centre in a mirror-image triangle is the mirror-image of its position in the original triangle.\nThis strict definition excludes pairs of bicentric points such as the Brocard points (which are interchanged by a mirror-image reflection). As of 2020, the Encyclopedia of Triangle Centers lists over 39,000 different triangle centres.\n\nTangential polygons and cyclic polygons\nA tangential polygon has each of its sides tangent to a particular circle, called the incircle or inscribed circle. The centre of the incircle, called the incentre, can be considered a centre of the polygon.\nA cyclic polygon has each of its vertices on a particular circle, called the circumcircle or circumscribed circle. The centre of the circumcircle, called the circumcentre, can be considered a centre of the polygon.\nIf a polygon is both tangential and cyclic, it is called bicentric. (All triangles are bicentric, for example.) The incentre and circumcentre of a bicentric polygon are not in general the same point.\n\nGeneral polygons\nThe centre of a general polygon can be defined in several different ways. The \"vertex centroid\" comes from considering the polygon as being empty but having equal masses at its vertices. The \"side centroid\" comes from considering the sides to have constant mass per unit length. The usual centre, called just the centroid (centre of area) comes from considering the surface of the polygon as having constant density. These three points are in general not all the same point.\n\nProjective conics\nIn projective geometry every line has a point at infinity or \"figurative point\" where it crosses all the lines that are parallel to it. The ellipse, parabola, and hyperbola of Euclidean geometry are called conics in projective geometry and may be constructed as Steiner conics from a projectivity that is not a perspectivity. A symmetry of the projective plane with a given conic relates every point or pole to a line called its polar. The concept of centre in projective geometry uses this relation. The following assertions are from G. B. Halsted.\n\nThe harmonic conjugate of a point at infinity with respect to the end points of a finite sect is the 'centre' of that sect.\nThe pole of the straight at infinity with respect to a certain conic is the 'centre' of the conic.\nThe polar of any figurative point is on the centre of the conic and is called a 'diameter'.\nThe centre of any ellipse is within it, for its polar does not meet the curve, and so there are no tangents from it to the curve. The centre of a parabola is the contact point of the figurative straight.\nThe centre of a hyperbola lies without the curve, since the figurative straight crosses the curve. The tangents from the centre to the hyperbola ar",
    "links": [
      "Altitude (geometry)",
      "American English",
      "Ancient Greek language",
      "Bicentric polygon",
      "Brocard point",
      "Centerpoint (geometry)",
      "Centre of mass",
      "Centre of symmetry",
      "Centroid",
      "Chebyshev centre",
      "Circle",
      "Circumcentre",
      "Circumcircle",
      "Clark Kimberling",
      "Cyclic polygon",
      "Ellipse",
      "Encyclopedia of Triangle Centers",
      "English in the Commonwealth of Nations",
      "Equidistant",
      "Equilateral triangle",
      "Fixed points of isometry groups in Euclidean space",
      "G. B. Halsted",
      "Geometry",
      "Hyperbola",
      "Incentre",
      "Incircle",
      "Instantaneous centre of rotation",
      "Isometry group",
      "Midpoint",
      "Nine-point centre",
      "Orthocentre",
      "Parallelogram",
      "Point (geometry)",
      "Point at infinity",
      "Pole and polar",
      "Polygon",
      "Projective geometry",
      "Projective harmonic conjugate",
      "Quadrilateral",
      "Rectangle",
      "Rhombus",
      "Shape",
      "Sphere",
      "Square (geometry)",
      "Steiner conic",
      "Symmetries",
      "Tangent",
      "Tangential polygon",
      "Triangle centre",
      "Trilinear coordinate"
    ],
    "categories": [
      "Category:All articles needing additional references",
      "Category:Articles needing additional references from September 2023",
      "Category:Articles with short description",
      "Category:Elementary geometry",
      "Category:Geometric centers",
      "Category:Short description is different from Wikidata",
      "Category:Use Oxford spelling from September 2023",
      "Category:Webarchive template wayback links"
    ]
  },
  "Ceva's Theorem": {
    "title": "Ceva's theorem",
    "url": "https://en.wikipedia.org/wiki/Ceva%27s_theorem",
    "summary": "In Euclidean geometry, Ceva's theorem is a theorem about triangles. Given a triangle △ABC, let the lines AO, BO, CO be drawn from the vertices to a common point O (not on one of the sides of △ABC), to meet opposite sides at D, E, F respectively. (The segments AD, BE, CF are known as cevians.) Then, using signed lengths of segments,\n\n  \n    \n      \n        \n          \n            \n              \n                A\n                F\n              \n              ¯\n            \n            \n              \n                F\n                B\n              \n              ¯\n            \n          \n        \n        ⋅\n        \n          \n            \n              \n                B\n                D\n              \n              ¯\n            \n            \n              \n                D\n                C\n              \n              ¯\n            \n          \n        \n        ⋅\n        \n          \n            \n              \n                C\n                E\n              \n              ¯\n   ",
    "content": "In Euclidean geometry, Ceva's theorem is a theorem about triangles. Given a triangle △ABC, let the lines AO, BO, CO be drawn from the vertices to a common point O (not on one of the sides of △ABC), to meet opposite sides at D, E, F respectively. (The segments AD, BE, CF are known as cevians.) Then, using signed lengths of segments,\n\n  \n    \n      \n        \n          \n            \n              \n                A\n                F\n              \n              ¯\n            \n            \n              \n                F\n                B\n              \n              ¯\n            \n          \n        \n        ⋅\n        \n          \n            \n              \n                B\n                D\n              \n              ¯\n            \n            \n              \n                D\n                C\n              \n              ¯\n            \n          \n        \n        ⋅\n        \n          \n            \n              \n                C\n                E\n              \n              ¯\n            \n            \n              \n                E\n                A\n              \n              ¯\n            \n          \n        \n        =\n        1.\n      \n    \n    {\\displaystyle {\\frac {\\overline {AF}}{\\overline {FB}}}\\cdot {\\frac {\\overline {BD}}{\\overline {DC}}}\\cdot {\\frac {\\overline {CE}}{\\overline {EA}}}=1.}\n  \n\nIn other words, the length XY is taken to be positive or negative according to whether X is to the left or right of Y in some fixed orientation of the line. For example, AF / FB is defined as having positive value when F is between A and B and negative otherwise.\nCeva's theorem is a theorem of affine geometry, in the sense that it may be stated and proved without using the concepts of angles, areas, and lengths (except for the ratio of the lengths of two line segments that are collinear). It is therefore true for triangles in any affine plane over any field.\nA slightly adapted converse is also true: If points D, E, F are chosen on BC, AC, AB respectively so that \n\n  \n    \n      \n        \n          \n            \n              \n                A\n                F\n              \n              ¯\n            \n            \n              \n                F\n                B\n              \n              ¯\n            \n          \n        \n        ⋅\n        \n          \n            \n              \n                B\n                D\n              \n              ¯\n            \n            \n              \n                D\n                C\n              \n              ¯\n            \n          \n        \n        ⋅\n        \n          \n            \n              \n                C\n                E\n              \n              ¯\n            \n            \n              \n                E\n                A\n              \n              ¯\n            \n          \n        \n        =\n        1\n        ,\n      \n    \n    {\\displaystyle {\\frac {\\overline {AF}}{\\overline {FB}}}\\cdot {\\frac {\\overline {BD}}{\\overline {DC}}}\\cdot {\\frac {\\overline {CE}}{\\overline {EA}}}=1,}\n  \n\nthen AD, BE, CF are concurrent, or all three parallel. The converse is often included as part of the theorem.\nThe theorem is often attributed to Giovanni Ceva, who published it in his 1678 work De lineis rectis. But it was proven much earlier by Yusuf Al-Mu'taman ibn Hűd, an eleventh-century king of Zaragoza. Ibn Hűd's work, however, had fallen into oblivion, and was rediscovered only in 1985.\nAssociated with the figures are several terms derived from Ceva's name: cevian (the lines AD, BE, CF are the cevians of O), cevian triangle (the triangle △DEF is the cevian triangle of O); cevian nest, anticevian triangle, Ceva conjugate.  (Ceva is pronounced Chay'va; cevian is pronounced chev'ian.)\nThe theorem is very similar to Menelaus' theorem in that their equations differ only in sign. By re-writing each in terms of cross-ratios, the two theorems may be seen as projective duals.\n\nProofs\nSeveral proofs of the theorem have been created. \nTwo proofs are given in the following. \nThe first one is very elementary, using only basic properties of triangle areas. However, several cases have to be considered, depending on the position of the point O. \nThe second proof uses barycentric coordinates and vectors, but is somehow more natural and not case dependent. Moreover, it works in any affine plane over any field.\n\nUsing triangle areas\nFirst, the sign of the left-hand side is positive since either all three of the ratios are positive, the case where O is inside the triangle (upper diagram), or one is positive and the other two are negative, the case O is outside the triangle (lower diagram shows one case).\nTo check the magnitude, note that the area of a triangle of a given height is proportional to its base. So \n\n  \n    \n      \n        \n          \n            \n              \n                |\n              \n              △\n              B\n              O\n              D\n              \n                |\n              \n            \n            \n              \n              ",
    "links": [
      "Affine geometry",
      "Affine plane",
      "Affine space",
      "Alfred S. Posamentier",
      "Barycentric coordinates (mathematics)",
      "Center of mass",
      "Ceva (disambiguation)",
      "Cevian",
      "Circumcevian triangle",
      "Collinearity",
      "Concurrent lines",
      "Constant curvature",
      "Cross-ratio",
      "Cut-the-knot",
      "Doi (identifier)",
      "Duality (projective geometry)",
      "Encyclopedia of Mathematics",
      "Eric W. Weisstein",
      "Euclidean geometry",
      "European Mathematical Society",
      "Facet (mathematics)",
      "Field (mathematics)",
      "Giovanni Ceva",
      "Hyperbolic geometry",
      "ISBN (identifier)",
      "If and only if",
      "JSTOR (identifier)",
      "Left-hand side",
      "Line (geometry)",
      "Line segment",
      "Mass distribution",
      "MathWorld",
      "Median (geometry)",
      "Menelaus' theorem",
      "Menelaus's theorem",
      "Parallel (geometry)",
      "Plane (geometry)",
      "Polygon",
      "Projective geometry",
      "Routh's theorem",
      "S2CID (identifier)",
      "Simplex",
      "Stewart's theorem",
      "Theorem",
      "Triangle",
      "Vector (geometry)",
      "Vertex (geometry)",
      "Wolfram Demonstrations Project",
      "Yusuf al-Mu'taman ibn Hud",
      "Zaragoza"
    ],
    "categories": [
      "Category:Affine geometry",
      "Category:All Wikipedia articles needing clarification",
      "Category:Articles containing proofs",
      "Category:Articles with short description",
      "Category:Euclidean plane geometry",
      "Category:Short description is different from Wikidata",
      "Category:Theorems about triangles",
      "Category:Wikipedia articles needing clarification from December 2024"
    ]
  },
  "Computational geometry": {
    "title": "Computational geometry",
    "url": "https://en.wikipedia.org/wiki/Computational_geometry",
    "summary": "Computational geometry is a branch of computer science devoted to the study of algorithms that can be stated in terms of geometry. Some purely geometrical problems arise out of the study of computational geometric algorithms, and such problems are also considered to be part of computational geometry. While modern computational geometry is a recent development, it is one of the oldest fields of computing with a history stretching back to antiquity.\nComputational complexity is central to computational geometry, with great practical significance if algorithms are used on very large datasets containing tens or hundreds of millions of points. For such sets, the difference between O(n2) and O(n log n) may be the difference between days and seconds of computation.\nThe main impetus for the development of computational geometry as a discipline was progress in computer graphics and computer-aided design and manufacturing (CAD/CAM), but many problems in computational geometry are classical in nat",
    "content": "Computational geometry is a branch of computer science devoted to the study of algorithms that can be stated in terms of geometry. Some purely geometrical problems arise out of the study of computational geometric algorithms, and such problems are also considered to be part of computational geometry. While modern computational geometry is a recent development, it is one of the oldest fields of computing with a history stretching back to antiquity.\nComputational complexity is central to computational geometry, with great practical significance if algorithms are used on very large datasets containing tens or hundreds of millions of points. For such sets, the difference between O(n2) and O(n log n) may be the difference between days and seconds of computation.\nThe main impetus for the development of computational geometry as a discipline was progress in computer graphics and computer-aided design and manufacturing (CAD/CAM), but many problems in computational geometry are classical in nature, and may come from mathematical visualization.\nOther important applications of computational geometry include robotics (motion planning and visibility problems), geographic information systems (GIS) (geometrical location and search, route planning), integrated circuit design (IC geometry design and verification), computer-aided engineering (CAE) (mesh generation), and computer vision (3D reconstruction).\nThe main branches of computational geometry are:\n\nCombinatorial computational geometry, also called algorithmic geometry, which deals with geometric objects as discrete entities. A groundlaying book in the subject by Preparata and Shamos dates the first use of the term \"computational geometry\" in this sense by 1975.\nNumerical computational geometry, also called machine geometry, computer-aided geometric design (CAGD), or geometric modeling, which deals primarily with representing real-world objects in forms suitable for computer computations in CAD/CAM systems. This branch may be seen as a further development of descriptive geometry and is often considered a branch of computer graphics or CAD. The term \"computational geometry\" in this meaning has been in use since 1971.\nAlthough most algorithms of computational geometry have been developed (and are being developed) for electronic computers, some algorithms were developed for unconventional computers (e.g. optical computers )\n\nCombinatorial computational geometry\nThe primary goal of research in combinatorial computational geometry is to develop efficient algorithms and data structures for solving problems stated in terms of basic geometrical objects: points, line segments, polygons, polyhedra, etc.\nSome of these problems seem so simple that they were not regarded as problems at all until the advent of computers. Consider, for example, the closest pair problem:\n\nGiven n points in the plane, find the two with the smallest distance from each other.\nOne could compute the distances between all the pairs of points, of which there are n(n − 1)/2, then pick the pair with the smallest distance. This brute-force algorithm takes O(n2) time; i.e. its execution time is proportional to the square of the number of points. A classic result in computational geometry was the formulation of an algorithm that takes O(n log n). Randomized algorithms that take O(n) expected time, as well as a deterministic algorithm that takes O(n log log n) time, have also been discovered.\n\nProblem classes\nThe core problems in computational geometry may be classified in different ways, according to various criteria. The following general classes may be distinguished.\n\nStatic problem\nIn the problems of this category, some input is given and the corresponding output needs to be constructed or found. Some fundamental problems of this type are:\n\nConvex hull: Given a set of points, find the smallest convex polyhedron/polygon containing all the points.\nLine segment intersection: Find the intersections between a given set of line segments.\nDelaunay triangulation\nVoronoi diagram: Given a set of points, partition the space according to which points are closest to the given points.\nLinear programming\nClosest pair of points: Given a set of points, find the two with the smallest distance from each other.\nFarthest pair of points\nLargest empty circle: Given a set of points, find a largest circle with its center inside of their convex hull and enclosing none of them.\nEuclidean shortest path: Connect two points in a Euclidean space (with polyhedral obstacles) by a shortest path.\nPolygon triangulation: Given a polygon, partition its interior into triangles\nMesh generation\nBoolean operations on polygons\nThe computational complexity for this class of problems is estimated by the time and space (computer memory) required to solve a given problem instance.\n\nGeometric query problems\nIn geometric query problems, commonly known as geometric search problems, the input consists of two parts: the search space part and the query part, whi",
    "links": [
      "3D reconstruction",
      "ACM Computing Classification System",
      "ACM Computing Surveys",
      "ACM Transactions on Graphics",
      "Acta Informatica",
      "Advances in Geometry",
      "Affine transformation",
      "Algebra of physical space",
      "Algebraic structure",
      "Algorithm",
      "Algorithm design",
      "Algorithmic efficiency",
      "Algorithmica",
      "Amortized analysis",
      "Analysis of algorithms",
      "Analytical mechanics",
      "Antipodal point",
      "Application security",
      "Applied mathematics",
      "Approximation theory",
      "Ars Combinatoria (journal)",
      "Artificial intelligence",
      "Augmented reality",
      "Automata theory",
      "Automated planning and scheduling",
      "Automated theorem proving",
      "Bentley–Ottmann algorithm",
      "Big O notation",
      "Boolean operations on polygons",
      "Bosonic string theory",
      "Bowyer–Watson algorithm",
      "Brute-force search",
      "Bézier curve",
      "Calculus of variations",
      "Chan's algorithm",
      "Chaos theory",
      "Chew's second algorithm",
      "Classical field theory",
      "Clifford algebra",
      "Clifford analysis",
      "Closest pair of points",
      "Closest pair problem",
      "Coding theory",
      "Collision detection",
      "Combinatorics",
      "Communication protocol",
      "Communications of the ACM",
      "Compiler construction",
      "Computability theory",
      "Computational Geometry (journal)"
    ],
    "categories": [
      "Category:Articles with excerpts",
      "Category:Articles with hAudio microformats",
      "Category:Articles with short description",
      "Category:Computational fields of study",
      "Category:Computational geometry",
      "Category:Geometry processing",
      "Category:Short description matches Wikidata",
      "Category:Spoken articles"
    ]
  },
  "Congruence (geometry)": {
    "title": "Congruence (geometry)",
    "url": "https://en.wikipedia.org/wiki/Congruence_(geometry)",
    "summary": "In geometry, two figures or objects are congruent if they have the same shape and size, or if one has the same shape and size as the mirror image of the other.\nMore formally, two sets of points are called congruent if, and only if, one can be transformed into the other by an isometry, i.e., a combination of rigid motions, namely a translation, a rotation, and a reflection. This means that either object can be repositioned and reflected (but not resized) so as to coincide precisely with the other object. Therefore, two distinct plane figures on a piece of paper are congruent if they can be cut out and then matched up completely. Turning the paper over is permitted.\n\nIn elementary geometry the word congruent is often used as follows.  The word equal is often used in place of congruent for these objects.\n\nTwo line segments are congruent if they have the same length.\nTwo angles are congruent if they have the same measure.\nTwo circles are congruent if they have the same diameter.\nIn this se",
    "content": "In geometry, two figures or objects are congruent if they have the same shape and size, or if one has the same shape and size as the mirror image of the other.\nMore formally, two sets of points are called congruent if, and only if, one can be transformed into the other by an isometry, i.e., a combination of rigid motions, namely a translation, a rotation, and a reflection. This means that either object can be repositioned and reflected (but not resized) so as to coincide precisely with the other object. Therefore, two distinct plane figures on a piece of paper are congruent if they can be cut out and then matched up completely. Turning the paper over is permitted.\n\nIn elementary geometry the word congruent is often used as follows.  The word equal is often used in place of congruent for these objects.\n\nTwo line segments are congruent if they have the same length.\nTwo angles are congruent if they have the same measure.\nTwo circles are congruent if they have the same diameter.\nIn this sense, the sentence \"two plane figures are congruent\" implies that their corresponding characteristics are congruent (or equal) including not just their corresponding sides and angles, but also their corresponding diagonals, perimeters, and areas.\nThe related concept of similarity applies if the objects have the same shape but do not necessarily have the same size. (Most definitions consider congruence to be a form of similarity, although a minority require that the objects have different sizes in order to qualify as similar.)\n\nDetermining congruence of polygons\nFor two polygons to be congruent, they must have an equal number of sides (and hence an equal number—the same number—of vertices). Two polygons with n sides are congruent if and only if they each have numerically identical sequences (even if clockwise for one polygon and counterclockwise for the other) side-angle-side-angle-... for n sides and n angles.\nCongruence of polygons can be established graphically as follows:\n\nFirst, match and label the corresponding vertices of the two figures.\nSecond, draw a vector from one of the vertices of one of the figures to the corresponding vertex of the other figure. Translate the first figure by this vector so that these two vertices match.\nThird, rotate the translated figure about the matched vertex until one pair of corresponding sides matches.\nFourth, reflect the rotated figure about this matched side until the figures match.\nIf at any time the step cannot be completed, the polygons are not congruent.\n\nCongruence of triangles\nTwo triangles are congruent if their corresponding sides are equal in length, and their corresponding angles are equal in measure.\nSymbolically, we write the congruency and incongruency of two triangles △ABC and △A′B′C′ as follows:\n\n  \n    \n      \n        A\n        B\n        C\n        ≅\n        \n          A\n          ′\n        \n        \n          B\n          ′\n        \n        \n          C\n          ′\n        \n      \n    \n    {\\displaystyle ABC\\cong A'B'C'}\n  \n\n  \n    \n      \n        A\n        B\n        C\n        ≆\n        \n          A\n          ′\n        \n        \n          B\n          ′\n        \n        \n          C\n          ′\n        \n      \n    \n    {\\displaystyle ABC\\ncong A'B'C'}\n  \n\nIn many cases it is sufficient to establish the equality of three corresponding parts and use one of the following results to deduce the congruence of the two triangles.\n\nDetermining congruence\nSufficient evidence for congruence between two triangles in Euclidean space can be shown through the following comparisons:\n\nSAS (side-angle-side): If two pairs of sides of two triangles are equal in length, and the included angles are equal in measurement, then the triangles are congruent.\nSSS (side-side-side): If three pairs of sides of two triangles are equal in length, then the triangles are congruent.\nASA (angle-side-angle): If two pairs of angles of two triangles are equal in measurement, and the included sides are equal in length, then the triangles are congruent.\nThe ASA postulate is attributed to Thales of Miletus. In most systems of axioms, the three criteria – SAS, SSS and ASA – are established as theorems. In the School Mathematics Study Group system SAS is taken as one (#15) of 22 postulates.\n\nAAS (angle-angle-side): If two pairs of angles of two triangles are equal in measurement, and a pair of corresponding non-included sides are equal in length, then the triangles are congruent. AAS is equivalent to an ASA condition, by the fact that if any two angles are given, so is the third angle, since their sum should be 180°. ASA and AAS are sometimes combined into a single condition, AAcorrS – any two angles and a corresponding side.\nRHS (right-angle-hypotenuse-side), also known as  HL (hypotenuse-leg): If two right-angled triangles have their hypotenuses equal in length, and a pair of other sides are equal in length, then the triangles are congruent.\n\nSide-side-angle\nThe SSA condition (side-side-angle) which specifies two si",
    "links": [
      "Acronym",
      "Ambiguous case",
      "American Mathematical Monthly",
      "Analytic geometry",
      "Angle",
      "Antonio Coronel",
      "ArXiv (identifier)",
      "Area",
      "Circle",
      "Corresponding sides",
      "Cube",
      "Cut-the-Knot",
      "Distance",
      "Doi (identifier)",
      "Eccentricity (mathematics)",
      "Edge (geometry)",
      "Equality (mathematics)",
      "Equivalence relation",
      "Euclidean distance",
      "Euclidean geometry",
      "Euclidean group",
      "Euclidean plane isometry",
      "Euclidean space",
      "Face (geometry)",
      "Geometry",
      "Hatch mark",
      "Hyperbolic geometry",
      "ISBN (identifier)",
      "Invariant (mathematics)",
      "Isometry",
      "Line segment",
      "Mirror image",
      "Parabola",
      "Perimeter",
      "Plane figure",
      "Point (geometry)",
      "Polygon",
      "Polyhedra",
      "Polyhedron",
      "Pythagorean theorem",
      "Rectangular hyperbola",
      "Reflection (mathematics)",
      "Rigid motion",
      "Rotation",
      "S2CID (identifier)",
      "School Mathematics Study Group",
      "Shape",
      "Similarity (geometry)",
      "Size",
      "Solution of triangles"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1 maint: bot: original URL status unknown",
      "Category:Commons category link is on Wikidata",
      "Category:Equivalence (mathematics)",
      "Category:Euclidean geometry",
      "Category:Short description is different from Wikidata",
      "Category:Wikipedia indefinitely semi-protected pages"
    ]
  },
  "Convex geometry": {
    "title": "Convex geometry",
    "url": "https://en.wikipedia.org/wiki/Convex_geometry",
    "summary": "In mathematics, convex geometry is the branch of geometry studying convex sets, mainly in Euclidean space. Convex sets occur naturally in many areas: computational geometry, convex analysis, discrete geometry, functional analysis, geometry of numbers, integral geometry, linear programming, probability theory, game theory, etc.",
    "content": "In mathematics, convex geometry is the branch of geometry studying convex sets, mainly in Euclidean space. Convex sets occur naturally in many areas: computational geometry, convex analysis, discrete geometry, functional analysis, geometry of numbers, integral geometry, linear programming, probability theory, game theory, etc.\n\nClassification\nAccording to the Mathematics Subject Classification MSC2010, the mathematical discipline Convex and Discrete Geometry includes three major branches:\n\ngeneral convexity\npolytopes and polyhedra\ndiscrete geometry\n(though only portions of the latter two are included in convex geometry).\nGeneral convexity is further subdivided as follows:  \n\naxiomatic and generalized convexity\nconvex sets without dimension restrictions\nconvex sets in topological vector spaces\nconvex sets in 2 dimensions (including convex curves)\nconvex sets in 3 dimensions (including convex surfaces)\nconvex sets in n dimensions (including convex hypersurfaces)\nfinite-dimensional Banach spaces\nrandom convex sets and integral geometry\nasymptotic theory of convex bodies\napproximation by convex sets\nvariants of convex sets (star-shaped, (m, n)-convex, etc.)\nHelly-type theorems and geometric transversal theory\nother problems of combinatorial convexity\nlength, area, volume\nmixed volumes and related topics\nvaluations on convex bodies\ninequalities and extremum problems\nconvex functions and convex programs\nspherical and hyperbolic convexity\n\nHistorical note\nConvex geometry is a relatively young mathematical discipline. Although the first known contributions to convex geometry date back to antiquity and can be traced in the works of Euclid and Archimedes, it became an  independent branch of mathematics at the turn of the 20th century, mainly due to the works of Hermann Brunn and Hermann Minkowski in dimensions two and three. A big part of their results was soon generalized to spaces of higher dimensions, and in 1934 T. Bonnesen and W. Fenchel gave a comprehensive survey of convex geometry in Euclidean space Rn. Further development of convex geometry in the 20th century and its relations to numerous mathematical disciplines are summarized in the Handbook of convex geometry edited by P. M. Gruber and J. M. Wills.\n\nSee also\nList of convexity topics\n\nNotes\nReferences\nExpository articles on convex geometry\nBall, K. (1997). \"An elementary introduction to modern convex geometry\". Flavors of Geometry (PDF). Math. Sci. Res. Inst. Publ. Vol. 31. Cambridge: Cambridge Univ. Press. pp. 1–58.\nBerger, M. (1990). \"Convexity\". Amer. Math. Monthly. 97: 650–678. doi:10.2307/2324573.\nGruber, P. M. (1984). \"Aspects of convexity and its applications\". Exposition. Math. 2: 47–83.\nKlee, V. (1971). \"What is a convex set?\". Amer. Math. Monthly. 78: 616–631. doi:10.2307/2316569.\n\nBooks on convex geometry\nBonnesen, T.; Fenchel, W. (1987) [1934]. Theorie der konvexen Körper [Theory of convex bodies]. Moscow, ID: BCS Associates.\nGardner, R. J. (2006) [1995]. Geometric tomography (2nd ed.). New York: Cambridge University Press.\nGruber, P. M. (2007). Convex and discrete geometry. New York: Springer-Verlag.\nGruber, P. M.; Wills, J. M., eds. (1993). Handbook of convex geometry. Vol. A. B. Amsterdam: North-Holland.\nPisier, G. (1989). The volume of convex bodies and Banach space geometry. Cambridge: Cambridge University Press.\nSchneider, R. (2014) [1993]. Convex bodies: the Brunn-Minkowski theory (2nd ed.). Cambridge: Cambridge University Press.\nThompson, A. C. (1996). Minkowski geometry. Cambridge: Cambridge University Press.\nBalestro, Vitor; Martini, Horst; Teixeira, Ralph (2024). Convexity from the Geometric Point of View. Cornerstones. Cham: Springer International Publishing. doi:10.1007/978-3-031-50507-2. ISBN 978-3-031-50506-5.\n\nArticles on history of convex geometry\nFenchel, W. (1983) [1973]. \"Convexity through the ages\". In Gruber, P. M.; Wills, J. M. (eds.). Convexity and its Applications. Basel: Birkhauser Verlag. pp. 120–130. doi:10.1007/978-3-0348-5858-8_6.\nGruber, Peter Manfred (1990), Fischer, Gerd; Hirzebruch, Friedrich; Scharlau, Winfried; Törnig, Willi (eds.), \"Zur Geschichte der Konvexgeometrie und der Geometrie der Zahlen\", Ein Jahrhundert Mathematik 1890–1990: Festschrift zum Jubiläum der DMV (in German), Wiesbaden: Vieweg+Teubner Verlag, pp. 421–455, doi:10.1007/978-3-322-80265-1_9, ISBN 978-3-322-80265-1\nGruber, P. M. (1993). \"History of convexity\". In Gruber, P. M.; Wills, J. M. (eds.). Handbook of convex geometry. Vol. A. Amsterdam: North-Holland. pp. 1–15.\n\nExternal links\n Media related to Convex geometry at Wikimedia Commons",
    "links": [
      "Antimatroid",
      "Archimedes",
      "Computational geometry",
      "Convex analysis",
      "Convex set",
      "Discrete geometry",
      "Doi (identifier)",
      "Euclid",
      "Euclidean space",
      "Functional analysis",
      "Game theory",
      "Geometry",
      "Geometry of numbers",
      "Hermann Brunn",
      "Hermann Minkowski",
      "ISBN (identifier)",
      "Integral geometry",
      "Linear programming",
      "List of convexity topics",
      "Mathematics",
      "Mathematics Subject Classification",
      "Mixed volume",
      "Peter M. Gruber",
      "Probability theory",
      "Tommy Bonnesen",
      "Valuation (geometry)",
      "Werner Fenchel",
      "Help:Authority control"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1 German-language sources (de)",
      "Category:Commons category link from Wikidata",
      "Category:Convex geometry",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Affine connection": {
    "title": "Affine connection",
    "url": "https://en.wikipedia.org/wiki/Affine_connection",
    "summary": "In differential geometry, an affine connection is a geometric object on a smooth manifold which connects nearby tangent spaces, so it permits tangent vector fields to be differentiated as if they were functions on the manifold with values in a fixed vector space. Connections are among the simplest methods of defining differentiation of the sections of vector bundles.\nThe notion of an affine connection has its roots in 19th-century geometry and tensor calculus, but was not fully developed until the early 1920s, by Élie Cartan (as part of his general theory of connections) and Hermann Weyl (who used the notion as a part of his foundations for general relativity). The terminology is due to Cartan and has its origins in the identification of tangent spaces in Euclidean space Rn by translation: the idea is that a choice of affine connection makes a manifold look infinitesimally like Euclidean space not just smoothly, but as an affine space.\nOn any manifold of positive dimension there are in",
    "content": "In differential geometry, an affine connection is a geometric object on a smooth manifold which connects nearby tangent spaces, so it permits tangent vector fields to be differentiated as if they were functions on the manifold with values in a fixed vector space. Connections are among the simplest methods of defining differentiation of the sections of vector bundles.\nThe notion of an affine connection has its roots in 19th-century geometry and tensor calculus, but was not fully developed until the early 1920s, by Élie Cartan (as part of his general theory of connections) and Hermann Weyl (who used the notion as a part of his foundations for general relativity). The terminology is due to Cartan and has its origins in the identification of tangent spaces in Euclidean space Rn by translation: the idea is that a choice of affine connection makes a manifold look infinitesimally like Euclidean space not just smoothly, but as an affine space.\nOn any manifold of positive dimension there are infinitely many affine connections. If the manifold is further endowed with a metric tensor then there is a natural choice of affine connection, called the Levi-Civita connection. The choice of an affine connection is equivalent to prescribing a way of differentiating vector fields which satisfies several reasonable properties (linearity and the Leibniz rule). This yields a possible definition of an affine connection as a covariant derivative or (linear) connection on the tangent bundle. A choice of affine connection is also equivalent to a notion of parallel transport, which is a method for transporting tangent vectors along curves. This also defines a parallel transport on the frame bundle. Infinitesimal parallel transport in the frame bundle yields another description of an affine connection, either as a Cartan connection for the affine group or as a principal connection on the frame bundle.\nThe main invariants of an affine connection are its torsion and its curvature. The torsion measures how closely the Lie bracket of vector fields can be recovered from the affine connection. Affine connections may also be used to define (affine) geodesics on a manifold, generalizing the straight lines of Euclidean space, although the geometry of those straight lines can be very different from usual Euclidean geometry; the main differences are encapsulated in the curvature of the connection.\n\nMotivation and history\nA smooth manifold is a mathematical object which looks locally like a smooth deformation of Euclidean space Rn: for example a smooth curve or surface looks locally like a smooth deformation of a line or a plane. Smooth functions and vector fields can be defined on manifolds, just as they can on Euclidean space, and scalar functions on manifolds can be differentiated in a natural way. However, differentiation of vector fields is less straightforward: this is a simple matter in Euclidean space, because the tangent space of based vectors at a point p can be identified naturally (by translation) with the tangent space at a nearby point q. On a general manifold, there is no such natural identification between nearby tangent spaces, and so tangent vectors at nearby points cannot be compared in a well-defined way. The notion of an affine connection was introduced to remedy this problem by connecting nearby tangent spaces. The origins of this idea can be traced back to two main sources: surface theory and tensor calculus.\n\nMotivation from surface theory\nConsider a smooth surface S in a 3-dimensional Euclidean space. Near any point, S can be approximated by its tangent plane at that point, which is an affine subspace of Euclidean space. Differential geometers in the 19th century were interested in the notion of development in which one surface was rolled along another, without slipping or twisting. In particular, the tangent plane to a point of S can be rolled on S: this should be easy to imagine when S is a surface like the 2-sphere, which is the smooth boundary of a convex region. As the tangent plane is rolled on S, the point of contact traces out a curve on S. Conversely, given a curve on S, the tangent plane can be rolled along that curve. This provides a way to identify the tangent planes at different points along the curve: in particular, a tangent vector in the tangent space at one point on the curve is identified with a unique tangent vector at any other point on the curve. These identifications are always given by affine transformations from one tangent plane to another.\nThis notion of parallel transport of tangent vectors, by affine transformations, along a curve has a characteristic feature: the point of contact of the tangent plane with the surface always moves with the curve under parallel translation (i.e., as the tangent plane is rolled along the surface, the point of contact moves). This generic condition is characteristic of Cartan connections. In more modern approaches, the point of contact is viewed as the origin in th",
    "links": [
      "Absolute parallelism",
      "Abstract index notation",
      "Adjoint bundle",
      "Affine bundle",
      "Affine group",
      "Affine manifold",
      "Affine space",
      "Affine subspace",
      "Affine transformation",
      "Albert Einstein",
      "Almost-contact manifold",
      "Almost complex manifold",
      "Almost flat manifold",
      "Almost symplectic manifold",
      "American Mathematical Society",
      "Angular momentum",
      "Antisymmetric tensor",
      "Associated bundle",
      "Atiyah–Singer index theorem",
      "Atlas (topology)",
      "Augustin-Louis Cauchy",
      "Banach manifold",
      "Basis (linear algebra)",
      "Bernhard Riemann",
      "Bilinear map",
      "Bundle homomorphism",
      "Bundle isomorphism",
      "Bundle map",
      "Carl Friedrich Gauss",
      "Cartan connection",
      "Cartan formalism (physics)",
      "Cartesian product",
      "Cauchy stress tensor",
      "Christoffel symbol",
      "Christoffel symbols",
      "Classification of manifolds",
      "Closed and exact differential forms",
      "Closed manifold",
      "Cofibration",
      "Collapsing manifold",
      "Complete manifold",
      "Complex manifold",
      "Complex manifolds",
      "Computer vision",
      "Concentric",
      "Connection (affine bundle)",
      "Connection (fibred manifold)",
      "Connection (mathematics)",
      "Connection (principal bundle)",
      "Connection (vector bundle)"
    ],
    "categories": [
      "Category:All articles lacking in-text citations",
      "Category:All articles with unsourced statements",
      "Category:Articles lacking in-text citations from February 2017",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from June 2016",
      "Category:CS1 errors: ISBN date",
      "Category:Connection (mathematics)",
      "Category:Differential geometry",
      "Category:Maps of manifolds",
      "Category:Short description matches Wikidata"
    ]
  },
  "American Mathematical Monthly": {
    "title": "The American Mathematical Monthly",
    "url": "https://en.wikipedia.org/wiki/The_American_Mathematical_Monthly",
    "summary": "The American Mathematical Monthly is a peer-reviewed scientific journal of mathematics. It was established by Benjamin Finkel in 1894 and is published by Taylor & Francis on behalf of the Mathematical Association of America. It is an expository journal intended for a wide audience of mathematicians, from undergraduate students to research professionals. Articles are chosen on the basis of their broad interest and reviewed and edited for quality of exposition as well as content. The editor-in-chief is Vadim Ponomarenko (San Diego State University).\nThe journal gives the Lester R. Ford Award annually to \"authors of articles of expository excellence\" published in the journal.",
    "content": "The American Mathematical Monthly is a peer-reviewed scientific journal of mathematics. It was established by Benjamin Finkel in 1894 and is published by Taylor & Francis on behalf of the Mathematical Association of America. It is an expository journal intended for a wide audience of mathematicians, from undergraduate students to research professionals. Articles are chosen on the basis of their broad interest and reviewed and edited for quality of exposition as well as content. The editor-in-chief is Vadim Ponomarenko (San Diego State University).\nThe journal gives the Lester R. Ford Award annually to \"authors of articles of expository excellence\" published in the journal.\n\nEditors-in-chief\nThe following persons are or have been editor-in-chief:\n\nProblem section\nEver since its founding in 1894 the American Mathematical Monthly has invited readers to propose and solve challenging mathematical problems for publication in its Problems and Solutions section. As of 2025 more than 12,000 problem proposals have appeared.\n\nSection timeline\nProblem editors\n*University of Maine Problems Group\n**University of Waterloo Problems Group\n †San Francisco Bay Area Problems Group\n\nTimeline\nSolutions 1894-1940\nThe table below lists solutions based on the following premise: something was published that justifies excluding the problem proposal from a list of unsolved problems.\nFor example, Calculus 360 (\"solution\" 1918 no. 4) is a question whose answer has no truth value and is thus \"unsolvable\" in a certain sense, so a mere reply to the question qualifies as a solution in the table.\nIn 1918 no. 5 a \"note\" on Calculus 435 also counts as a solution because the author refers to a paper then concludes: \"To solve [problem 435] we need only put alpha = 0 in the first of the integrals mentioned.\"  (However, since 435 has a solution in the previous issue, this note was omitted from the table.)\nThe \"note\" on 3064 in 1925 No. 1 counts as a solution because it points out that no solution exists to the problem as stated.  Same for 3110 in 1925 No. 8 and 2706 in 1926 No. 2. (the presence of \"Also solved by\" is sometimes a tipoff to this scenario).\nThe only year in which the Monthly was true to its name was 1894, when 12 issues were published.  Single issues for July-August and September-October appeared in 1895, and in 1896 June-July and August-September were each single issues, launching the modern format (the modern issue-numbering scheme from 1 to 10 did not begin until 1913 however).\n\nSee also\nMathematics Magazine\nNotices of the American Mathematical Society\n\nReferences\nExternal links\nOfficial website",
    "links": [
      "Academic publishing",
      "Albert Arnold Bennett Jr.",
      "Alex F. T. W. Rosenberg",
      "Benjamin Finkel",
      "Bruce Palka",
      "C.H. Ashton",
      "Carl Barnett Allendoerfer",
      "Carroll Vincent Newsom",
      "Daniel J. Velleman",
      "David Raymond Curtiss",
      "Dean G. Hoffman",
      "Della Dumbaugh",
      "Earle Raymond Hedrick",
      "Editor-in-chief",
      "Elton James Moulton",
      "Florian Cajori",
      "Frederick Arthur Ficken",
      "George Abram Miller",
      "Harley Flanders",
      "Herbert Ellsworth Slaught",
      "Herbert S. Wilf",
      "Hybrid open-access journal",
      "I.M. DeLong",
      "ISO 4",
      "ISSN (identifier)",
      "Impact factor",
      "JSTOR (identifier)",
      "John H. Ewing (mathematician)",
      "John Marvin Colaw",
      "LCCN (identifier)",
      "Leonard Eugene Dickson",
      "Lester Randolph Ford",
      "Louis Charles Karpinski",
      "MathSciNet",
      "Mathematical Association of America",
      "Mathematics",
      "Mathematics Magazine",
      "Notices of the American Mathematical Society",
      "OCLC (identifier)",
      "Oliver Edmunds Glenn",
      "Open access",
      "Outline of academic disciplines",
      "Paul Richard Halmos",
      "Peer-reviewed",
      "Periodical literature",
      "Ralph Duncan James",
      "Ralph Philip Boas, Jr.",
      "Raymond Clare Archibald",
      "Richard Philip Baker",
      "Robert Abraham Rosenbaum"
    ],
    "categories": [
      "Category:10 times per year journals",
      "Category:10 times per year journals (infobox)",
      "Category:Academic journals established in 1894",
      "Category:Academic journals published by learned and professional societies of the United States",
      "Category:Articles with short description",
      "Category:English-language journals",
      "Category:Hybrid open access journals (infobox)",
      "Category:Mathematical Association of America",
      "Category:Mathematics journals",
      "Category:Official website different in Wikidata and Wikipedia"
    ]
  },
  "August Möbius": {
    "title": "August Ferdinand Möbius",
    "url": "https://en.wikipedia.org/wiki/August_Ferdinand_M%C3%B6bius",
    "summary": "August Ferdinand Möbius (UK: , US: ; German: [ˈmøːbi̯ʊs]; 17 November 1790 – 26 September 1868) was a German mathematician and theoretical astronomer.",
    "content": "August Ferdinand Möbius (UK: , US: ; German: [ˈmøːbi̯ʊs]; 17 November 1790 – 26 September 1868) was a German mathematician and theoretical astronomer.\n\nLife and education\nMöbius was born in Schulpforta, Electorate of Saxony, and was descended on his mother's side from religious reformer Martin Luther. He was home-schooled until he was 13, when he attended the college in Schulpforta in 1803, and studied there, graduating in 1809. He then enrolled at the University of Leipzig, where he studied astronomy under the mathematician and astronomer Karl Mollweide. In 1813, he began to study astronomy under mathematician Carl Friedrich Gauss at the University of Göttingen, while Gauss was the director of the Göttingen Observatory.  From there, he went to study with Carl Gauss's instructor, Johann Pfaff, at the University of Halle, where he completed his doctoral thesis The occultation of fixed stars in 1815. In 1816, he was appointed  as Extraordinary Professor to the \"chair of astronomy and higher mechanics\" at the University of Leipzig. Möbius died in Leipzig in 1868 at the age of 77. \nHis son Theodor was a noted philologist.\n\nContributions\nHe is best known for his discovery of the Möbius strip, a non-orientable two-dimensional surface with only one side when embedded in three-dimensional Euclidean space. It was independently discovered by Johann Benedict Listing a few months earlier. The Möbius configuration, formed by two mutually inscribed tetrahedra, is also named after him. Möbius was the first to introduce homogeneous coordinates into projective geometry. He is recognized for the introduction of the barycentric coordinate system. Before 1853 and Schläfli's discovery of the 4-polytopes, Möbius (with Cayley and Grassmann) was one of only three other people who had also conceived of the possibility of geometry in more than three dimensions.\nMany mathematical concepts are named after him, including the Möbius plane, the Möbius transformations, important in projective geometry, and the Möbius transform of number theory.  His interest in number theory led to the important Möbius function μ(n) and the Möbius inversion formula. In Euclidean geometry, he systematically developed the use of signed angles and line segments as a way of simplifying and unifying results.\n\nCollected works\nGesammelte Werke  erster Band (v. 1)  (Leipzig : S. Hirzel, 1885)\nGesammelte Werke  zweiter Band (v. 2)  (Leipzig : S. Hirzel, 1885)\nGesammelte Werke  dritter Band (v. 3)  (Leipzig : S. Hirzel, 1885)\nGesammelte Werke  vierter Band (v. 4)  (Leipzig : S. Hirzel, 1885)\nDie elemente der mechanik des himmels, auf neuem wege ohne hülfe höherer rechnungsarten dargestellt von August Ferdinand Möbius (Leipzig, Weidmann'sche buchhandlung, 1843)\n\nSee also\nBarycentric coordinate system\nCollineation\nHomogeneous coordinates\nMöbius counter\nMöbius plane\n\nReferences\nExternal links\n\nO'Connor, John J.; Robertson, Edmund F., \"August Ferdinand Möbius\", MacTutor History of Mathematics Archive, University of St Andrews\nAugust Ferdinand Möbius at the Mathematics Genealogy Project\nAugust Ferdinand Möbius - Œuvres complètes Gallica-Math\nA beautiful visualization of Möbius Transformations, created by mathematicians at the University of Minnesota is viewable at https://www.youtube.com/watch?v=JX3VmDgiFnY",
    "links": [
      "4-polytopes",
      "Adolf Neumann",
      "American English",
      "Arthur Cayley",
      "Astronomer",
      "Barycentric coordinate system",
      "British English",
      "Carl Friedrich Gauss",
      "Collineation",
      "Doctoral advisor",
      "Edmund F. Robertson",
      "Electorate of Saxony",
      "Embedding",
      "Encyclopedia Americana",
      "Encyclopædia Britannica Eleventh Edition",
      "Euclidean space",
      "George Szpiro",
      "Göttingen Observatory",
      "Harold Scott MacDonald Coxeter",
      "Hermann Grassmann",
      "Hermann Hankel",
      "Holy Roman Empire",
      "Homogeneous coordinates",
      "Howard Eves",
      "ISBN (identifier)",
      "Johann Benedict Listing",
      "Johann Pfaff",
      "John C. Wells",
      "Karl Mollweide",
      "Kingdom of Saxony",
      "Leipzig",
      "MacTutor History of Mathematics Archive",
      "Martin Luther",
      "Mathematician",
      "Mathematics",
      "Mathematics Genealogy Project",
      "Möbius configuration",
      "Möbius counter",
      "Möbius function",
      "Möbius inversion formula",
      "Möbius plane",
      "Möbius strip",
      "Möbius transform",
      "Möbius transformation",
      "Möbius–Kantor configuration",
      "Möbius–Kantor graph",
      "Non-orientable",
      "North German Confederation",
      "Number theory",
      "Otto Wilhelm Fiedler"
    ],
    "categories": [
      "Category:1790 births",
      "Category:1868 deaths",
      "Category:19th-century German astronomers",
      "Category:19th-century German mathematicians",
      "Category:Academic staff of Leipzig University",
      "Category:Articles with hCards",
      "Category:Articles with short description",
      "Category:Commons category link is on Wikidata",
      "Category:German geometers",
      "Category:German number theorists"
    ]
  },
  "Abelian integral": {
    "title": "Abelian integral",
    "url": "https://en.wikipedia.org/wiki/Abelian_integral",
    "summary": "In mathematics, an abelian integral, named after the Norwegian mathematician Niels Henrik Abel, is an integral in the complex plane of the form\n\n  \n    \n      \n        \n          ∫\n          \n            \n              z\n              \n                0\n              \n            \n          \n          \n            z\n          \n        \n        R\n        (\n        x\n        ,\n        w\n        )\n        \n        d\n        x\n        ,\n      \n    \n    {\\displaystyle \\int _{z_{0}}^{z}R(x,w)\\,dx,}\n  \n\nwhere \n  \n    \n      \n        R\n        (\n        x\n        ,\n        w\n        )\n      \n    \n    {\\displaystyle R(x,w)}\n  \n is an arbitrary rational function of the two variables \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n and \n  \n    \n      \n        w\n      \n    \n    {\\displaystyle w}\n  \n, which are related by the equation\n\n  \n    \n      \n        F\n        (\n        x\n        ,\n        w\n        )\n        =\n        0\n        ,\n      \n    \n    {\\displaystyle F(x,w)=0,}\n  \n",
    "content": "In mathematics, an abelian integral, named after the Norwegian mathematician Niels Henrik Abel, is an integral in the complex plane of the form\n\n  \n    \n      \n        \n          ∫\n          \n            \n              z\n              \n                0\n              \n            \n          \n          \n            z\n          \n        \n        R\n        (\n        x\n        ,\n        w\n        )\n        \n        d\n        x\n        ,\n      \n    \n    {\\displaystyle \\int _{z_{0}}^{z}R(x,w)\\,dx,}\n  \n\nwhere \n  \n    \n      \n        R\n        (\n        x\n        ,\n        w\n        )\n      \n    \n    {\\displaystyle R(x,w)}\n  \n is an arbitrary rational function of the two variables \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n and \n  \n    \n      \n        w\n      \n    \n    {\\displaystyle w}\n  \n, which are related by the equation\n\n  \n    \n      \n        F\n        (\n        x\n        ,\n        w\n        )\n        =\n        0\n        ,\n      \n    \n    {\\displaystyle F(x,w)=0,}\n  \n\nwhere \n  \n    \n      \n        F\n        (\n        x\n        ,\n        w\n        )\n      \n    \n    {\\displaystyle F(x,w)}\n  \n is an irreducible polynomial in \n  \n    \n      \n        w\n      \n    \n    {\\displaystyle w}\n  \n,\n\n  \n    \n      \n        F\n        (\n        x\n        ,\n        w\n        )\n        ≡\n        \n          φ\n          \n            n\n          \n        \n        (\n        x\n        )\n        \n          w\n          \n            n\n          \n        \n        +\n        ⋯\n        +\n        \n          φ\n          \n            1\n          \n        \n        (\n        x\n        )\n        w\n        +\n        \n          φ\n          \n            0\n          \n        \n        \n          (\n          x\n          )\n        \n        ,\n      \n    \n    {\\displaystyle F(x,w)\\equiv \\varphi _{n}(x)w^{n}+\\cdots +\\varphi _{1}(x)w+\\varphi _{0}\\left(x\\right),}\n  \n\nwhose coefficients \n  \n    \n      \n        \n          φ\n          \n            j\n          \n        \n        (\n        x\n        )\n      \n    \n    {\\displaystyle \\varphi _{j}(x)}\n  \n, \n  \n    \n      \n        j\n        =\n        0\n        ,\n        1\n        ,\n        …\n        ,\n        n\n      \n    \n    {\\displaystyle j=0,1,\\ldots ,n}\n  \n are rational functions of \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n. The value of an abelian integral depends not only on the integration limits, but also on the path along which the integral is taken; it is thus a multivalued function of \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n  \n.\nAbelian integrals are natural generalizations of elliptic integrals, which arise when\n\n  \n    \n      \n        F\n        (\n        x\n        ,\n        w\n        )\n        =\n        \n          w\n          \n            2\n          \n        \n        −\n        P\n        (\n        x\n        )\n        ,\n        \n      \n    \n    {\\displaystyle F(x,w)=w^{2}-P(x),\\,}\n  \n\nwhere \n  \n    \n      \n        P\n        \n          (\n          x\n          )\n        \n      \n    \n    {\\displaystyle P\\left(x\\right)}\n  \n is a polynomial of degree 3 or 4. Another special case of an abelian integral is a hyperelliptic integral, where \n  \n    \n      \n        P\n        (\n        x\n        )\n      \n    \n    {\\displaystyle P(x)}\n  \n, in the formula above, is a polynomial of degree greater than 4.\n\nHistory\nThe theory of abelian integrals originated with a paper by Abel published in 1841. This  paper was written during his stay in Paris in 1826 and presented to Augustin-Louis Cauchy in October of the same year. This theory, later fully developed by others, was one of the crowning achievements of nineteenth century mathematics and has had a major impact on the development of modern mathematics. In more abstract and geometric language, it is contained in the concept of abelian variety, or more precisely in the way an algebraic curve can be mapped into abelian varieties. Abelian integrals were later connected to the prominent mathematician David Hilbert's 16th Problem, and they continue to be considered one of the foremost challenges in contemporary mathematics.\n\nModern view\nIn the theory of Riemann surfaces, an abelian integral is a function related to the indefinite integral of a differential of the first kind. Suppose we are given a Riemann surface \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n and on it a differential 1-form \n  \n    \n      \n        ω\n      \n    \n    {\\displaystyle \\omega }\n  \n that is everywhere holomorphic on \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n, and fix a point \n  \n    \n      \n        \n          P\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle P_{0}}\n  \n on \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n, from which to integrate. We can regard\n\n  \n    \n      \n        \n          ∫\n          \n            \n              P\n              \n                0\n              \n            \n          \n          \n            P\n          \n        \n        ω\n",
    "links": [
      "Abelian variety",
      "Algebraic curve",
      "Algebraic function",
      "American Mathematical Society",
      "Andrew Forsyth",
      "Augustin-Louis Cauchy",
      "B. G. Teubner",
      "Cambridge University Press",
      "Carl Neumann",
      "Compact Riemann surface",
      "Complex manifold",
      "Complex plane",
      "David Hilbert",
      "Differential form",
      "Differential of the first kind",
      "Elliptic curve",
      "Elliptic integral",
      "Genus (mathematics)",
      "Gilbert Ames Bliss",
      "Hilbert's sixteenth problem",
      "Holomorphic function",
      "Homology class",
      "Hyperelliptic curve",
      "Hyperelliptic integral",
      "Indefinite integral",
      "Integral",
      "Irreducible polynomial",
      "Jacobian variety",
      "Joe Harris (mathematician)",
      "John Wiley & Sons",
      "Mathematics",
      "Multi-valued function",
      "Multiply connected",
      "Multivalued function",
      "Niels Henrik Abel",
      "Paul Appell",
      "Phillip Griffiths",
      "Polynomial",
      "Pullback (differential geometry)",
      "Rational function",
      "Riemann surfaces",
      "Édouard Goursat"
    ],
    "categories": [
      "Category:Abelian varieties",
      "Category:Algebraic curves",
      "Category:Articles with short description",
      "Category:CS1 French-language sources (fr)",
      "Category:Riemann surfaces",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Algebraic Geometry (book)": {
    "title": "Algebraic Geometry (book)",
    "url": "https://en.wikipedia.org/wiki/Algebraic_Geometry_(book)",
    "summary": "Algebraic Geometry is an algebraic geometry textbook written by Robin Hartshorne and published by Springer-Verlag in 1977.",
    "content": "Algebraic Geometry is an algebraic geometry textbook written by Robin Hartshorne and published by Springer-Verlag in 1977.\n\nImportance\nIt was the first extended treatment of scheme theory written as a text intended to be accessible to graduate students, and is considered to be the standard reference. This book was cited when Hartshorne was awarded the Leroy P. Steele Prize for mathematical exposition in 1979.\n\nContents\nThe first chapter, titled \"Varieties\", deals with the classical algebraic geometry of varieties over algebraically closed fields. This chapter uses many classical results in commutative algebra, including Hilbert's Nullstellensatz, with the books by Atiyah–Macdonald, Matsumura, and Zariski–Samuel as usual references. The second and the third chapters, \"Schemes\" and \"Cohomology\", form the technical heart of the book. The last two chapters, \"Curves\" and \"Surfaces\", respectively explore the geometry of 1- and 2-dimensional objects, using the tools developed in the chapters 2 and 3.\n\nNotes\nReferences\nHartshorne, Robin (1977). Algebraic Geometry. Berlin, New York: Springer-Verlag. doi:10.1007/978-1-4757-3849-0. ISBN 978-0-387-90244-9. MR 0463157. Zbl 0367.14001.\nShatz, Stephen S. (1979), \"Review: Robin Hartshorne, Algebraic geometry\", Bull. Amer. Math. Soc. (N.S.), 1 (3): 553–560, doi:10.1090/S0273-0979-1979-14618-4",
    "links": [
      "Algebraic geometry",
      "Algebraic variety",
      "Algebraically closed field",
      "Bull. Amer. Math. Soc.",
      "Commutative algebra",
      "Doi (identifier)",
      "Hilbert's Nullstellensatz",
      "ISBN (identifier)",
      "Leroy P. Steele Prize",
      "MR (identifier)",
      "MathSciNet",
      "Robin Hartshorne",
      "Scheme theory",
      "Springer-Verlag",
      "Textbook",
      "Zbl (identifier)"
    ],
    "categories": [
      "Category:1977 non-fiction books",
      "Category:Algebraic geometry",
      "Category:Articles with short description",
      "Category:Graduate Texts in Mathematics",
      "Category:Mathematics textbooks",
      "Category:Monographs",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Algebraic Geometry (journal)": {
    "title": "Compositio Mathematica",
    "url": "https://en.wikipedia.org/wiki/Compositio_Mathematica",
    "summary": "Compositio Mathematica is a monthly peer-reviewed mathematics journal established by L.E.J. Brouwer in 1935. It is owned by the Foundation Compositio Mathematica, and since 2004 it has been published on behalf of the Foundation by the London Mathematical Society in partnership with Cambridge University Press. According to the Journal Citation Reports, the journal has a 2020 2-year impact factor of 1.456 and a 2020 5-year impact factor of 1.696.\nThe editors-in-chief are Fabrizio Andreatta, David Holmes, Bruno Klingler, and Éric Vasserot.",
    "content": "Compositio Mathematica is a monthly peer-reviewed mathematics journal established by L.E.J. Brouwer in 1935. It is owned by the Foundation Compositio Mathematica, and since 2004 it has been published on behalf of the Foundation by the London Mathematical Society in partnership with Cambridge University Press. According to the Journal Citation Reports, the journal has a 2020 2-year impact factor of 1.456 and a 2020 5-year impact factor of 1.696.\nThe editors-in-chief are Fabrizio Andreatta, David Holmes, Bruno Klingler, and Éric Vasserot.\n\nEarly history\nThe journal was established by L. E. J. Brouwer in response to his dismissal from Mathematische Annalen in 1928. An announcement of the new journal was made in a 1934 issue of the American Mathematical Monthly. In 1940, the publication of the journal was suspended due to the German occupation of the Netherlands.\n\nReferences\nExternal links\nOfficial website\nOnline archive (1935-1996)",
    "links": [
      "Academic publishing",
      "Adams Prize",
      "Advisory Committee on Mathematics Education",
      "American Mathematical Monthly",
      "Association of Teachers of Mathematics",
      "British Mathematical Olympiad",
      "British Mathematical Olympiad Subtrust",
      "British Society for Research into Learning Mathematics",
      "CODEN (identifier)",
      "Cambridge University Press",
      "Chartered Mathematician",
      "Council for the Mathematical Sciences",
      "Count On",
      "Doi (identifier)",
      "Edinburgh Mathematical Society",
      "Editor-in-chief",
      "Editors-in-chief",
      "El Nombre",
      "Eureka (University of Cambridge magazine)",
      "Exeter Mathematics School",
      "Forum of Mathematics",
      "Glasgow Mathematical Journal",
      "History of the Netherlands (1939–1945)",
      "HoDoMS",
      "ISO 4",
      "ISSN (identifier)",
      "Impact factor",
      "Institute of Mathematics and its Applications",
      "International Centre for Mathematical Sciences",
      "Isaac Newton Institute",
      "JSTOR (identifier)",
      "Joint Mathematical Council",
      "Journal Citation Reports",
      "Kent Mathematics Project",
      "King's College London Mathematics School",
      "LCCN (identifier)",
      "Lancaster University School of Mathematics",
      "London Mathematical Society",
      "Luitzen Egbertus Jan Brouwer",
      "Making Mathematics Count",
      "Mathematical Association",
      "Mathematics and Computing College",
      "Mathematics in Education and Industry",
      "Mathematics journal",
      "Mathematische Annalen",
      "Maths school",
      "Megamaths",
      "Millennium Mathematics Project",
      "More Maths Grads",
      "National Centre for Excellence in the Teaching of Mathematics"
    ],
    "categories": [
      "Category:Academic journals associated with learned and professional societies of the United Kingdom",
      "Category:Academic journals established in 1935",
      "Category:Articles with outdated impact factors from 2020",
      "Category:Articles with short description",
      "Category:Bimonthly journals",
      "Category:Cambridge University Press academic journals",
      "Category:English-language journals",
      "Category:London Mathematical Society",
      "Category:Mathematics education in the United Kingdom",
      "Category:Mathematics journals"
    ]
  },
  "Algebraic geometric code": {
    "title": "Algebraic geometry code",
    "url": "https://en.wikipedia.org/wiki/Algebraic_geometry_code",
    "summary": "Algebraic geometry codes, often abbreviated AG codes, are a type of linear code that generalize Reed–Solomon codes. The Russian mathematician V. D. Goppa constructed these codes for the first time in 1982.",
    "content": "Algebraic geometry codes, often abbreviated AG codes, are a type of linear code that generalize Reed–Solomon codes. The Russian mathematician V. D. Goppa constructed these codes for the first time in 1982.\n\nHistory\nThe name of these codes has evolved since the publication of Goppa's paper describing them. Historically these codes have also been referred to as geometric Goppa codes; however, this is no longer the standard term used in coding theory literature. This is due to the fact that Goppa codes are a distinct class of codes which were also constructed by Goppa in the early 1970s.\nThese codes attracted interest in the coding theory community because they have the ability to surpass the Gilbert–Varshamov bound; at the time this was discovered, the Gilbert–Varshamov bound had not been broken in the 30 years since its discovery. This was demonstrated by Tfasman, Vladut, and Zink in the same year as the code construction was published, in their paper \"Modular curves, Shimura curves, and Goppa codes, better than Varshamov-Gilbert bound\". The name of this paper may be one source of confusion affecting references to algebraic geometry codes throughout 1980s and 1990s coding theory literature.\n\nConstruction\nIn this section the construction of algebraic geometry codes is described. The section starts with the ideas behind Reed–Solomon codes, which are used to motivate the construction of algebraic geometry codes.\n\nReed–Solomon codes\nAlgebraic geometry codes are a generalization of Reed–Solomon codes. Constructed by Irving Reed and Gustave Solomon in 1960, Reed–Solomon codes use univariate polynomials to form codewords, by evaluating polynomials of sufficiently small degree at the points in a finite field \n  \n    \n      \n        \n          \n            F\n          \n          \n            q\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {F} _{q}}\n  \n.\nFormally, Reed–Solomon codes are defined in the following way. Let \n  \n    \n      \n        \n          \n            F\n          \n          \n            q\n          \n        \n        =\n        {\n        \n          α\n          \n            1\n          \n        \n        ,\n        …\n        ,\n        \n          α\n          \n            q\n          \n        \n        }\n      \n    \n    {\\displaystyle \\mathbb {F} _{q}=\\{\\alpha _{1},\\dots ,\\alpha _{q}\\}}\n  \n. Set positive integers \n  \n    \n      \n        k\n        ≤\n        n\n        ≤\n        q\n      \n    \n    {\\displaystyle k\\leq n\\leq q}\n  \n. Let \n  \n    \n      \n        \n          \n            F\n          \n          \n            q\n          \n        \n        [\n        x\n        \n          ]\n          \n            <\n            k\n          \n        \n        :=\n        \n          {\n          \n            f\n            ∈\n            \n              \n                F\n              \n              \n                q\n              \n            \n            [\n            x\n            ]\n            :\n            deg\n            ⁡\n            f\n            <\n            k\n          \n          }\n        \n      \n    \n    {\\displaystyle \\mathbb {F} _{q}[x]_{<k}:=\\left\\{f\\in \\mathbb {F} _{q}[x]:\\deg f<k\\right\\}}\n  \nThe Reed–Solomon code \n  \n    \n      \n        R\n        S\n        (\n        q\n        ,\n        n\n        ,\n        k\n        )\n      \n    \n    {\\displaystyle RS(q,n,k)}\n  \n is the evaluation code\n  \n    \n      \n        R\n        S\n        (\n        q\n        ,\n        n\n        ,\n        k\n        )\n        =\n        \n          {\n          \n            \n              (\n              \n                f\n                (\n                \n                  α\n                  \n                    1\n                  \n                \n                )\n                ,\n                f\n                (\n                \n                  α\n                  \n                    2\n                  \n                \n                )\n                ,\n                …\n                ,\n                f\n                (\n                \n                  α\n                  \n                    n\n                  \n                \n                )\n              \n              )\n            \n            :\n            f\n            ∈\n            \n              \n                F\n              \n              \n                q\n              \n            \n            [\n            x\n            \n              ]\n              \n                <\n                k\n              \n            \n          \n          }\n        \n        ⊆\n        \n          \n            F\n          \n          \n            q\n          \n          \n            n\n          \n        \n        .\n      \n    \n    {\\displaystyle RS(q,n,k)=\\left\\{\\left(f(\\alpha _{1}),f(\\alpha _{2}),\\dots ,f(\\alpha _{n})\\right):f\\in \\mathbb {F} _{q}[x]_{<k}\\right\\}\\subseteq \\mathbb {F} _{q}^{n}.}\n\nCodes from algebraic curves\nGoppa observed that \n  \n    \n      \n        \n          \n            F\n          \n          \n            q\n          \n        \n      \n    \n    {\\dis",
    "links": [
      "Algebraic function field",
      "Arnaldo Garcia",
      "Binary Goppa code",
      "Coding theory",
      "Divisor (algebraic geometry)",
      "Elwyn Berlekamp",
      "Finite field",
      "Gilbert–Varshamov bound",
      "Gustave Solomon",
      "Hasse's theorem on elliptic curves",
      "ISBN (identifier)",
      "Irving S. Reed",
      "J. H. van Lint",
      "Linear code",
      "Point at infinity",
      "Projective line",
      "Rational point",
      "Reed–Solomon error correction",
      "Riemann–Roch theorem",
      "Support (mathematics)",
      "Thomas Zink",
      "Valery Goppa",
      "Zeros and poles"
    ],
    "categories": [
      "Category:Algebraic curves",
      "Category:Articles containing proofs",
      "Category:Articles with short description",
      "Category:Coding theory",
      "Category:Finite fields",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Algebraic geometry of projective spaces": {
    "title": "Algebraic geometry of projective spaces",
    "url": "https://en.wikipedia.org/wiki/Algebraic_geometry_of_projective_spaces",
    "summary": "The concept of a Projective space plays a central role in algebraic geometry. This article aims to define the notion in terms of abstract algebraic geometry and to describe some basic uses of projective spaces.",
    "content": "The concept of a Projective space plays a central role in algebraic geometry. This article aims to define the notion in terms of abstract algebraic geometry and to describe some basic uses of projective spaces.\n\nHomogeneous polynomial ideals\nLet k be an algebraically closed field, and V be a finite-dimensional vector space over k. The symmetric algebra of the dual vector space V* is called the polynomial ring on V and denoted by k[V]. It is a naturally graded algebra by the degree of polynomials.\nThe projective Nullstellensatz states that, for any homogeneous ideal I that does not contain all polynomials of a certain degree (referred to as an irrelevant ideal), the common zero locus of all polynomials in I (or Nullstelle) is non-trivial (i.e. the common zero locus contains more than the single element {0}), and, more precisely, the ideal of polynomials that vanish on that locus coincides with the radical of the ideal I.\nThis last assertion is best summarized by the formula: for any relevant ideal I, \n\n  \n    \n      \n        \n          \n            I\n          \n        \n        (\n        \n          \n            V\n          \n        \n        (\n        I\n        )\n        )\n        =\n        \n          \n            I\n          \n        \n        .\n      \n    \n    {\\displaystyle {\\mathcal {I}}({\\mathcal {V}}(I))={\\sqrt {I}}.}\n  \n\nIn particular, maximal homogeneous relevant ideals of k[V] are one-to-one with lines through the origin of V.\n\nConstruction of projectivized schemes\nLet V be a finite-dimensional vector space over a field k. The scheme over k defined by Proj(k[V]) is called projectivization of V. The projective n-space on k is the projectivization of the vector space \n  \n    \n      \n        \n          \n            A\n          \n          \n            k\n          \n          \n            n\n            +\n            1\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {A} _{k}^{n+1}}\n  \n.\nThe definition of the sheaf is done on the base of open sets of principal open sets D(P), where P varies over the set of homogeneous polynomials, by setting the sections \n\n  \n    \n      \n        Γ\n        (\n        D\n        (\n        P\n        )\n        ,\n        \n          \n            \n              O\n            \n          \n          \n            \n              P\n            \n            (\n            V\n            )\n          \n        \n        )\n      \n    \n    {\\displaystyle \\Gamma (D(P),{\\mathcal {O}}_{\\mathbb {P} (V)})}\n  \n\nto be the ring \n  \n    \n      \n        (\n        k\n        [\n        V\n        \n          ]\n          \n            P\n          \n        \n        \n          )\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle (k[V]_{P})_{0}}\n  \n, the zero degree component of the ring obtained by localization at P. Its elements are therefore the rational functions with homogeneous numerator and some power of P as the denominator, with same degree as the numerator.\nThe situation is most clear at a non-vanishing linear form φ. The restriction of the structure sheaf to the open set D(φ) is then canonically identified  with the affine scheme spec(k[ker φ]). Since the D(φ) form an open cover of X the projective schemes can be thought of as being obtained by the gluing via projectivization of isomorphic affine schemes.\nIt can be noted that the ring of global sections of this scheme is a field, which implies that the scheme is not affine. Any two open sets intersect non-trivially: ie the scheme is irreducible. When the field k is algebraically closed, \n  \n    \n      \n        \n          P\n        \n        (\n        V\n        )\n      \n    \n    {\\displaystyle \\mathbb {P} (V)}\n  \n is in fact an abstract variety, that furthermore is complete. cf.  Glossary of scheme theory\n\nDivisors and twisting sheaves\nThe Proj construction in fact gives more than a mere scheme: a sheaf in graded modules over the structure sheaf is defined in the process. The homogeneous components of this graded sheaf are denoted \n  \n    \n      \n        \n          \n            O\n          \n        \n        (\n        i\n        )\n      \n    \n    {\\displaystyle {\\mathcal {O}}(i)}\n  \n, the Serre twisting sheaves. All of these sheaves are in fact line bundles. By the correspondence between Cartier divisors and line bundles, the first twisting sheaf \n  \n    \n      \n        \n          \n            O\n          \n        \n        (\n        1\n        )\n      \n    \n    {\\displaystyle {\\mathcal {O}}(1)}\n  \n is equivalent to hyperplane divisors.\nSince the ring of polynomials is a unique factorization domain, any prime ideal of height 1 is principal, which shows that any Weil divisor is linearly equivalent to some power of a hyperplane divisor. This consideration proves that the Picard group of a projective space is free of rank 1. That is \n  \n    \n      \n        Pic\n        ⁡\n        \n          \n            P\n          \n          \n            \n              k\n            \n          \n          \n            n\n          \n        \n        =\n",
    "links": [
      "Abstract variety",
      "Affine scheme",
      "Affine varieties",
      "Algebraic geometry",
      "Algebraically closed",
      "Ample line bundle",
      "Base (topology)",
      "Birkhoff-Grothendieck theorem",
      "Blowing up",
      "Bézout theorem",
      "Canonical bundle",
      "Cartier divisor",
      "Complete variety",
      "Dual vector space",
      "Euler sequence",
      "Exceptional divisor",
      "Fano variety",
      "Field (mathematics)",
      "Finite-dimensional",
      "First Chern class",
      "Glossary of scheme theory",
      "Graded algebra",
      "Hartshorne's Algebraic Geometry",
      "Height (ring theory)",
      "Homogeneous ideal",
      "Homogeneous polynomial",
      "Hypersurface",
      "ISBN (identifier)",
      "Intersection theory",
      "Inverse image functor",
      "Invertible sheaves",
      "Irreducible component",
      "Irrelevant ideal",
      "Line bundle",
      "Linear form",
      "Linear system of divisors",
      "Localization of a ring",
      "MathOverflow",
      "Morphism of schemes",
      "Nullstellensatz",
      "Open cover",
      "Picard group",
      "Polynomial ring",
      "Prime ideal",
      "Principal ideal",
      "Proj",
      "Proj construction",
      "Projective geometry",
      "Projective linear group",
      "Projective space"
    ],
    "categories": [
      "Category:Algebraic geometry",
      "Category:Algebraic varieties",
      "Category:Articles with short description",
      "Category:Geometry of divisors",
      "Category:Projective geometry",
      "Category:Short description with empty Wikidata description",
      "Category:Space (mathematics)"
    ]
  },
  "Algebraic space": {
    "title": "Algebraic space",
    "url": "https://en.wikipedia.org/wiki/Algebraic_space",
    "summary": "In mathematics, algebraic spaces form a generalization of the schemes of algebraic geometry, introduced by Michael Artin for use in deformation theory. Intuitively, \nschemes are given by gluing together affine schemes using the Zariski topology, while algebraic spaces are given by gluing together affine schemes using the finer étale topology. Alternatively one can think of schemes as being locally isomorphic to affine schemes in the Zariski topology, while algebraic spaces are locally isomorphic to affine schemes in the étale topology.\nThe resulting category of algebraic spaces extends the category of schemes and allows one to carry out several natural constructions that are used in the construction of moduli spaces but are not always possible in the smaller category of schemes, such as taking the quotient of a free action by a finite group (cf. the Keel–Mori theorem).",
    "content": "In mathematics, algebraic spaces form a generalization of the schemes of algebraic geometry, introduced by Michael Artin for use in deformation theory. Intuitively, \nschemes are given by gluing together affine schemes using the Zariski topology, while algebraic spaces are given by gluing together affine schemes using the finer étale topology. Alternatively one can think of schemes as being locally isomorphic to affine schemes in the Zariski topology, while algebraic spaces are locally isomorphic to affine schemes in the étale topology.\nThe resulting category of algebraic spaces extends the category of schemes and allows one to carry out several natural constructions that are used in the construction of moduli spaces but are not always possible in the smaller category of schemes, such as taking the quotient of a free action by a finite group (cf. the Keel–Mori theorem).\n\nDefinition\nThere are two common ways to define algebraic spaces: they can be defined as either quotients of schemes by étale equivalence relations, or as sheaves on a big étale site that are locally isomorphic to schemes. These two definitions are essentially equivalent.\n\nAlgebraic spaces as quotients of schemes\nAn algebraic space X comprises a scheme U and a closed subscheme R ⊆ U × U satisfying the following two conditions:\n\n1. R is an equivalence relation as a subset of U × U\n2. The projections pi: R → U onto each factor are étale maps.\nSome authors, such as Knutson, add an extra condition that an algebraic space has to be quasi-separated, meaning that the diagonal map is quasi-compact.\nOne can always assume that R and U are affine schemes. Doing so means that the theory of algebraic spaces is not dependent on the full theory of schemes, and can indeed be used as a (more general) replacement of that theory.\nIf R is the trivial equivalence relation over each connected component of U (i.e. for all x, y belonging to the same connected component of U, we have xRy if and only if x=y), then the algebraic space will be a scheme in the usual sense. Since a general algebraic space X does not satisfy this requirement, it allows a single connected component of U to cover X with many \"sheets\". The point set underlying the algebraic space X is then given by |U| / |R| as a set of equivalence classes.\nLet Y be an algebraic space defined by an equivalence relation S ⊂ V × V.  The set Hom(Y, X) of morphisms of algebraic spaces is then defined by the condition that it makes the descent sequence\n\n  \n    \n      \n        \n          H\n          o\n          m\n        \n        (\n        Y\n        ,\n        X\n        )\n        →\n        \n          H\n          o\n          m\n        \n        (\n        V\n        ,\n        X\n        )\n        \n          \n            \n              \n                \n\n                \n                ⟶\n              \n            \n            \n              \n                ⟶\n                \n\n                \n              \n            \n          \n        \n        \n          H\n          o\n          m\n        \n        (\n        S\n        ,\n        X\n        )\n      \n    \n    {\\displaystyle \\mathrm {Hom} (Y,X)\\rightarrow \\mathrm {Hom} (V,X){{{} \\atop \\longrightarrow } \\atop {\\longrightarrow  \\atop {}}}\\mathrm {Hom} (S,X)}\n  \n\nexact (this definition is motivated by a descent theorem of Grothendieck for surjective étale maps of affine schemes). With these definitions, the algebraic spaces form a category.\nLet U be an affine scheme over a field k defined by a system of polynomials g(x), x = (x1, ..., xn), let\n\n  \n    \n      \n        k\n        {\n        \n          x\n          \n            1\n          \n        \n        ,\n        …\n        ,\n        \n          x\n          \n            n\n          \n        \n        }\n         \n      \n    \n    {\\displaystyle k\\{x_{1},\\ldots ,x_{n}\\}\\ }\n  \n\ndenote the ring of algebraic functions in x over k, and let X = {R ⊂ U × U} be an algebraic space.\nThe appropriate stalks ÕX, x on X are then defined to be the local rings of algebraic functions defined by ÕU, u, where u ∈ U is a point lying over x and ÕU, u is the local ring corresponding to u of the ring\n\nk{x1, ..., xn} / (g)\nof algebraic functions on U.\nA point on an algebraic space is said to be smooth if ÕX, x ≅ k{z1, ..., zd} for some indeterminates z1, ..., zd. The dimension of X at x is then just defined to be d.\nA morphism f: Y → X of algebraic spaces is said to be étale at y ∈ Y (where x = f(y)) if the induced map on stalks\n\nÕX, x → ÕY, y\nis an isomorphism.\nThe structure sheaf OX on the algebraic space X is defined by associating the ring of functions O(V) on V (defined by étale maps from V to the affine line A1 in the sense just defined) to any algebraic space V which is étale over X.\n\nAlgebraic spaces as sheaves\nAn algebraic space \n  \n    \n      \n        \n          \n            X\n          \n        \n      \n    \n    {\\displaystyle {\\mathfrak {X}}}\n  \n can be defined as a sheaf of sets\n\n  \n    \n      \n        \n          \n            X\n          \n    ",
    "links": [
      "Affine scheme",
      "Algebraic function",
      "Algebraic geometry",
      "Analytic space",
      "Category (mathematics)",
      "Codimension",
      "Complex number",
      "Covering space",
      "Deformation theory",
      "Descent (category theory)",
      "Doi (identifier)",
      "Encyclopedia of Mathematics",
      "Equivalence class",
      "Equivalence relation",
      "European Mathematical Society",
      "Finite group",
      "Free action",
      "Grothendieck",
      "Hironaka's example",
      "Hopf manifold",
      "ISBN (identifier)",
      "Indeterminate (variable)",
      "Keel–Mori theorem",
      "Local ring",
      "MR (identifier)",
      "Mathematics",
      "Michael Artin",
      "Moduli space",
      "Moishezon manifold",
      "Oxford University Press",
      "Quasi-separated",
      "Quotient stack",
      "Ring (mathematics)",
      "Scheme (mathematics)",
      "Springer-Verlag",
      "Stack (mathematics)",
      "Zariski topology",
      "Étale morphism",
      "Étale topology"
    ],
    "categories": [
      "Category:Algebraic geometry",
      "Category:Use shortened footnotes from September 2024"
    ]
  },
  "Algebraic stack": {
    "title": "Algebraic stack",
    "url": "https://en.wikipedia.org/wiki/Algebraic_stack",
    "summary": "In mathematics, an algebraic stack is a vast generalization of algebraic spaces, or schemes, which are foundational for studying moduli theory. Many moduli spaces are constructed using techniques specific to algebraic stacks, such as Artin's representability theorem, which is used to construct the moduli space of pointed algebraic curves \n  \n    \n      \n        \n          \n            \n              M\n            \n          \n          \n            g\n            ,\n            n\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {M}}_{g,n}}\n  \n and the moduli stack of elliptic curves. Originally, they were introduced by Alexander Grothendieck to keep track of automorphisms on moduli spaces, a technique which allows for treating these moduli spaces as if their underlying schemes or algebraic spaces are smooth. After Grothendieck developed the general theory of descent, and Giraud the general theory of stacks, the notion of algebraic stacks was defined by Michael Artin.",
    "content": "In mathematics, an algebraic stack is a vast generalization of algebraic spaces, or schemes, which are foundational for studying moduli theory. Many moduli spaces are constructed using techniques specific to algebraic stacks, such as Artin's representability theorem, which is used to construct the moduli space of pointed algebraic curves \n  \n    \n      \n        \n          \n            \n              M\n            \n          \n          \n            g\n            ,\n            n\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {M}}_{g,n}}\n  \n and the moduli stack of elliptic curves. Originally, they were introduced by Alexander Grothendieck to keep track of automorphisms on moduli spaces, a technique which allows for treating these moduli spaces as if their underlying schemes or algebraic spaces are smooth. After Grothendieck developed the general theory of descent, and Giraud the general theory of stacks, the notion of algebraic stacks was defined by Michael Artin.\n\nDefinition\nMotivation\nOne of the motivating examples of an algebraic stack is to consider a groupoid scheme \n  \n    \n      \n        (\n        R\n        ,\n        U\n        ,\n        s\n        ,\n        t\n        ,\n        m\n        )\n      \n    \n    {\\displaystyle (R,U,s,t,m)}\n  \n over a fixed scheme \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n. For example, if \n  \n    \n      \n        R\n        =\n        \n          μ\n          \n            n\n          \n        \n        \n          ×\n          \n            S\n          \n        \n        \n          \n            A\n          \n          \n            S\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle R=\\mu _{n}\\times _{S}\\mathbb {A} _{S}^{n}}\n  \n (where \n  \n    \n      \n        \n          μ\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mu _{n}}\n  \n is the group scheme of roots of unity), \n  \n    \n      \n        U\n        =\n        \n          \n            A\n          \n          \n            S\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle U=\\mathbb {A} _{S}^{n}}\n  \n, \n  \n    \n      \n        s\n        =\n        \n          \n            pr\n          \n          \n            U\n          \n        \n      \n    \n    {\\displaystyle s={\\text{pr}}_{U}}\n  \n is the projection map, \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  \n is the group action\n  \n    \n      \n        \n          ζ\n          \n            n\n          \n        \n        ⋅\n        (\n        \n          x\n          \n            1\n          \n        \n        ,\n        …\n        ,\n        \n          x\n          \n            n\n          \n        \n        )\n        =\n        (\n        \n          ζ\n          \n            n\n          \n        \n        \n          x\n          \n            1\n          \n        \n        ,\n        …\n        ,\n        \n          ζ\n          \n            n\n          \n        \n        \n          x\n          \n            n\n          \n        \n        )\n      \n    \n    {\\displaystyle \\zeta _{n}\\cdot (x_{1},\\ldots ,x_{n})=(\\zeta _{n}x_{1},\\ldots ,\\zeta _{n}x_{n})}\n  \nand \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n  \n is the multiplication map\n  \n    \n      \n        m\n        :\n        (\n        \n          μ\n          \n            n\n          \n        \n        \n          ×\n          \n            S\n          \n        \n        \n          \n            A\n          \n          \n            S\n          \n          \n            n\n          \n        \n        )\n        \n          ×\n          \n            \n              μ\n              \n                n\n              \n            \n            \n              ×\n              \n                S\n              \n            \n            \n              \n                A\n              \n              \n                S\n              \n              \n                n\n              \n            \n          \n        \n        (\n        \n          μ\n          \n            n\n          \n        \n        \n          ×\n          \n            S\n          \n        \n        \n          \n            A\n          \n          \n            S\n          \n          \n            n\n          \n        \n        )\n        →\n        \n          μ\n          \n            n\n          \n        \n        \n          ×\n          \n            S\n          \n        \n        \n          \n            A\n          \n          \n            S\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle m:(\\mu _{n}\\times _{S}\\mathbb {A} _{S}^{n})\\times _{\\mu _{n}\\times _{S}\\mathbb {A} _{S}^{n}}(\\mu _{n}\\times _{S}\\mathbb {A} _{S}^{n})\\to \\mu _{n}\\times _{S}\\mathbb {A} _{S}^{n}}\n  \non \n  \n    \n      \n        \n          μ\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mu _{n}}\n  \n. Then, given an \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n-scheme \n  \n    \n      \n        π\n        :\n        X\n        →\n        S\n      \n",
    "links": [
      "2-Yoneda lemma",
      "2-fibered product",
      "2-functor",
      "2 category",
      "Abelian Lie algebra",
      "Advances in Mathematics",
      "Alexander Grothendieck",
      "Algebraic group",
      "Algebraic space",
      "ArXiv (identifier)",
      "Artin's criterion",
      "Bibcode (identifier)",
      "Category fibered in groupoids",
      "Chow group of a stack",
      "Chromatic homotopy theory",
      "Cohomology of a stack",
      "Deformation theory of line bundles",
      "Deligne–Mumford stack",
      "Derived algebraic geometry",
      "Descent (mathematics)",
      "Descent theory",
      "Doi (identifier)",
      "Fibred category",
      "Fppf topology",
      "Gerbe",
      "Glossary of algebraic geometry",
      "Grothendieck construction",
      "Grothendieck topology",
      "Group scheme",
      "Groupoid scheme",
      "Higher stacks",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "Infinitesimal",
      "Jean Giraud (mathematician)",
      "Kummer sequence",
      "Lie algebra",
      "Michael Artin",
      "Moduli of algebraic curves",
      "Moduli space of algebraic curves",
      "Moduli space of stable bundles",
      "Moduli stack of algebraic curves",
      "Moduli stack of elliptic curves",
      "Moduli stack of formal group laws",
      "Moduli theory",
      "Orbifold",
      "Overcategory",
      "Pursuing Stacks",
      "Quotient stack",
      "Root of unity"
    ],
    "categories": [
      "Category:Algebraic curves",
      "Category:Algebraic geometry",
      "Category:Articles with short description",
      "Category:Moduli theory",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Algebraic statistics": {
    "title": "Algebraic statistics",
    "url": "https://en.wikipedia.org/wiki/Algebraic_statistics",
    "summary": "Algebraic statistics is a branch of mathematical statistics that focuses on the use of algebraic, geometric, and combinatorial methods in statistics. While the use of these methods has a long history in statistics, algebraic statistics is continuously forging new interdisciplinary connections.\nThis growing field has established itself squarely at the intersection of several areas of mathematics, including, for instance, multilinear algebra, commutative algebra, algebraic geometry, convex geometry, combinatorics, theoretical problems in statistics, and their practical applications. For example, algebraic statistics has been useful for experimental design, parameter estimation, and hypothesis testing.",
    "content": "Algebraic statistics is a branch of mathematical statistics that focuses on the use of algebraic, geometric, and combinatorial methods in statistics. While the use of these methods has a long history in statistics, algebraic statistics is continuously forging new interdisciplinary connections.\nThis growing field has established itself squarely at the intersection of several areas of mathematics, including, for instance, multilinear algebra, commutative algebra, algebraic geometry, convex geometry, combinatorics, theoretical problems in statistics, and their practical applications. For example, algebraic statistics has been useful for experimental design, parameter estimation, and hypothesis testing.\n\nHistory\nAlgebraic statistics can be traced back to Karl Pearson, who used polynomial algebra to study Gaussian mixture models.\nSubsequently, Ronald A. Fisher, Henry B. Mann, and Rosemary A. Bailey applied Abelian groups to the design of experiments. Experimental designs were also studied with affine geometry over finite fields and then with the introduction of association schemes by R. C. Bose. Orthogonal arrays were introduced by C. R. Rao also for experimental designs. \nThe field experienced a major revitalization in the 1990s. In 1998, Diaconis and Sturmfels introduced Gröbner bases for constructing Markov chain Monte Carlo algorithms for conditional sampling from discrete exponential families. Pistone and Wynn, in 1996, applied computational commutative algebra to the design and analysis of experiments, providing new tools for understanding confounding and identifiability in complex experimental settings. These works, along with the monograph by Giovanni Pistone, Eva Riccomagno, and Henry P. Wynn, in which the term “algebraic statistics” was first used, played a pivotal role in establishing this field as a unified area of research.\nModern researchers in algebraic statistics explore a wide range of topics, including computational biology, graphical models, and statistical learning.\n\nActive Research Areas\nPhylogenetics\nMaximum likelihood estimation\nMethod of moments\nGraphical models\nTropical statistics\nStatistical learning theory\nAlgebraic geometry has also recently found applications to statistical learning theory, including a generalization of the Akaike information criterion to singular statistical models.\n\nOther topics\nAlgebraic analysis and abstract statistical inference\nInvariant measures on locally compact groups  have long been used in statistical theory, particularly in multivariate analysis. Beurling's factorization theorem and much of the work on (abstract) harmonic analysis sought better understanding of the Wold decomposition of stationary stochastic processes, which is important in time series statistics.\nEncompassing previous results on probability theory on algebraic structures, Ulf Grenander developed a theory of \"abstract inference\".  Grenander's abstract inference and his theory of patterns are useful for spatial statistics and image analysis; these theories rely on lattice theory.\n\nPartially ordered sets and lattices\nPartially ordered vector spaces and vector lattices are used throughout statistical theory. Garrett Birkhoff metrized the positive cone using Hilbert's projective metric and proved Jentsch's theorem using the contraction mapping theorem. Birkhoff's results have been used for maximum entropy estimation (which can be viewed as linear programming in infinite dimensions) by Jonathan Borwein and colleagues.\nVector lattices and conical measures were introduced into statistical decision theory by Lucien Le Cam.\n\nIntroductory Example\nConsider a random variable X which can take on the values 0, 1, 2. Such a variable is completely characterized by the three probabilities \n\n  \n    \n      \n        \n          p\n          \n            i\n          \n        \n        =\n        \n          P\n          r\n        \n        (\n        X\n        =\n        i\n        )\n        ,\n        \n        i\n        =\n        0\n        ,\n        1\n        ,\n        2\n      \n    \n    {\\displaystyle p_{i}=\\mathrm {Pr} (X=i),\\quad i=0,1,2}\n  \n\nand these numbers satisfy\n\n  \n    \n      \n        \n          ∑\n          \n            i\n            =\n            0\n          \n          \n            2\n          \n        \n        \n          p\n          \n            i\n          \n        \n        =\n        1\n        \n        \n          \n            and\n          \n        \n        \n        0\n        ≤\n        \n          p\n          \n            i\n          \n        \n        ≤\n        1.\n      \n    \n    {\\displaystyle \\sum _{i=0}^{2}p_{i}=1\\quad {\\mbox{and}}\\quad 0\\leq p_{i}\\leq 1.}\n  \n\nConversely, any three such numbers unambiguously specify a random variable, so we can identify the random variable X with the tuple \n  \n    \n      \n        (\n        \n          p\n          \n            0\n          \n        \n        ,\n        \n          p\n          \n            1\n          \n        \n        ,\n        \n          p\n          \n        ",
    "links": [
      "Abelian group",
      "Affine geometry",
      "Akaike information criterion",
      "Alexander Ostrowski",
      "Algebraic curve",
      "Algebraic geometry",
      "American Mathematical Society",
      "Anne Penfold Street",
      "Arne Beurling",
      "Association scheme",
      "Bernd Sturmfels",
      "Bernoulli distribution",
      "Binomial random variable",
      "C. R. Rao",
      "Combinatorics",
      "Combinatorics of Experimental Design",
      "Commutative algebra",
      "Contraction mapping",
      "Contraction mapping theorem",
      "Damaraju Raghavarao",
      "Deborah Street",
      "Design of experiments",
      "Estimation",
      "Finite fields",
      "Garrett Birkhoff",
      "Haar measure",
      "Harmonic analysis",
      "Henry Mann",
      "Henry Wynn",
      "Hilbert metric",
      "Hypothesis testing",
      "ISBN (identifier)",
      "Image analysis",
      "Infinite dimensional optimization",
      "Invariant subspace",
      "Jonathan Borwein",
      "Karl Pearson",
      "Lattice theory",
      "Linear programming",
      "Lior Pachter",
      "Locally compact group",
      "Lucien Le Cam",
      "Mathematical statistics",
      "Multilinear algebra",
      "Multivariate analysis",
      "Ordered vector space",
      "Orthogonal array",
      "Oscar Kempthorne",
      "Parameter estimation",
      "Pattern theory"
    ],
    "categories": [
      "Category:All articles that may have off-topic sections",
      "Category:Statistical theory",
      "Category:Wikipedia articles that may have off-topic sections from May 2023"
    ]
  },
  "An Invitation to Algebraic Geometry": {
    "title": "An Invitation to Algebraic Geometry",
    "url": "https://en.wikipedia.org/wiki/An_Invitation_to_Algebraic_Geometry",
    "summary": "An Invitation to Algebraic Geometry is a graduate level introductory textbook on Algebraic Geometry.  It provides a broad survey of fundamental ideas rather than a detailed or technical course of study. It is based on lectures by Karen Smith given in Finland in 1996, and published by Springer Verlag in 2000.",
    "content": "An Invitation to Algebraic Geometry is a graduate level introductory textbook on Algebraic Geometry.  It provides a broad survey of fundamental ideas rather than a detailed or technical course of study. It is based on lectures by Karen Smith given in Finland in 1996, and published by Springer Verlag in 2000.\n\nTopics\nThe book has eight chapters and an appendix. The chapter headings give a good summary of the topics covered: Affine Algebraic Varieties, Algebraic Foundations, Projective Varieties, Quasi-Projective Varieties, Classical Constructions, Smoothness, Birational Geometry, and Maps to Projective Spaces.\n\nAudience and reception\nThe book is based on lectures given to Ph.D students and mature mathematicians with backgrounds primarily in classical and topological analysis. So few algebraic prerequisites are presumed.\nQuoting from reviews gives a good sense of the style of the book. Mark Green says \"It is a genuinely entry-level book that begins with the definition of a prime ideal and the Nullstellensatz.\" Thomas Garrity says \"This is a wonderfully intuitive book, stressing the general ideas.  It would be a good place to start for any student with a firm first course in algebra that included ring theory.\" Peter Rabinovitch says the book \"is a tasty introduction — if after looking through it you are not interested in algebraic geometry, I don’t think you ever will be.\"\nGreen goes on to say that \"There is a consistent policy throughout the book of tying in elementary algebraic geometry to recent developments by current leaders such as Kollar, Kontsevich, Mori, Lazarsfeld, and de Jong, so that readers come away with a clear conception of where this is all going and what the next steps might be if a particular topic sparks their interest.\"\n\n\n== References ==",
    "links": [
      "Algebraic Geometry",
      "American Mathematical Monthly",
      "CRC Press",
      "Doi (identifier)",
      "JSTOR (identifier)",
      "Karen E. Smith",
      "Springer Verlag"
    ],
    "categories": [
      "Category:Algebraic geometry",
      "Category:Articles with short description",
      "Category:Mathematics textbooks",
      "Category:Short description matches Wikidata"
    ]
  },
  "Arakelov's geometry": {
    "title": "Arakelov theory",
    "url": "https://en.wikipedia.org/wiki/Arakelov_theory",
    "summary": "In mathematics, Arakelov theory (or Arakelov geometry) is an approach to Diophantine geometry, named for Suren Arakelov. It is used to study Diophantine equations in higher dimensions.",
    "content": "In mathematics, Arakelov theory (or Arakelov geometry) is an approach to Diophantine geometry, named for Suren Arakelov. It is used to study Diophantine equations in higher dimensions.\n\nBackground\nThe main motivation behind Arakelov geometry is that there is a correspondence between prime ideals \n  \n    \n      \n        \n          \n            p\n          \n        \n        ∈\n        \n          Spec\n        \n        (\n        \n          Z\n        \n        )\n      \n    \n    {\\displaystyle {\\mathfrak {p}}\\in {\\text{Spec}}(\\mathbb {Z} )}\n  \n and finite places \n  \n    \n      \n        \n          v\n          \n            p\n          \n        \n        :\n        \n          \n            Q\n          \n          \n            ∗\n          \n        \n        →\n        \n          R\n        \n      \n    \n    {\\displaystyle v_{p}:\\mathbb {Q} ^{*}\\to \\mathbb {R} }\n  \n, but there also exists a place at infinity \n  \n    \n      \n        \n          v\n          \n            ∞\n          \n        \n      \n    \n    {\\displaystyle v_{\\infty }}\n  \n, given by the Archimedean valuation, which doesn't have a corresponding prime ideal. Arakelov geometry gives a technique for compactifying \n  \n    \n      \n        \n          Spec\n        \n        (\n        \n          Z\n        \n        )\n      \n    \n    {\\displaystyle {\\text{Spec}}(\\mathbb {Z} )}\n  \n into a complete space \n  \n    \n      \n        \n          \n            \n              \n                Spec\n              \n              (\n              \n                Z\n              \n              )\n            \n            ¯\n          \n        \n      \n    \n    {\\displaystyle {\\overline {{\\text{Spec}}(\\mathbb {Z} )}}}\n  \n which has a prime lying at infinity. Arakelov's original construction studies one such theory, where a definition of divisors is constructed for a scheme \n  \n    \n      \n        \n          \n            X\n          \n        \n      \n    \n    {\\displaystyle {\\mathfrak {X}}}\n  \n of relative dimension 1 over \n  \n    \n      \n        \n          Spec\n        \n        (\n        \n          \n            \n              O\n            \n          \n          \n            K\n          \n        \n        )\n      \n    \n    {\\displaystyle {\\text{Spec}}({\\mathcal {O}}_{K})}\n  \n such that it extends to a Riemann surface \n  \n    \n      \n        \n          X\n          \n            ∞\n          \n        \n        =\n        \n          \n            X\n          \n        \n        (\n        \n          C\n        \n        )\n      \n    \n    {\\displaystyle X_{\\infty }={\\mathfrak {X}}(\\mathbb {C} )}\n  \n for every valuation at infinity. In addition, he equips these Riemann surfaces with Hermitian metrics on holomorphic vector bundles over X(C), the complex points of \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n. This extra Hermitian structure is applied as a substitute for the failure of the scheme Spec(Z) to be a complete variety.\nNote that other techniques exist for constructing a complete space extending \n  \n    \n      \n        \n          Spec\n        \n        (\n        \n          Z\n        \n        )\n      \n    \n    {\\displaystyle {\\text{Spec}}(\\mathbb {Z} )}\n  \n, which is the basis of F1 geometry.\n\nOriginal definition of divisors\nLet \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n be a field, \n  \n    \n      \n        \n          \n            \n              O\n            \n          \n          \n            K\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {O}}_{K}}\n  \n its ring of integers, and \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n a genus \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n  \n curve over \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n with a non-singular model \n  \n    \n      \n        \n          \n            X\n          \n        \n        →\n        \n          Spec\n        \n        (\n        \n          \n            \n              O\n            \n          \n          \n            K\n          \n        \n        )\n      \n    \n    {\\displaystyle {\\mathfrak {X}}\\to {\\text{Spec}}({\\mathcal {O}}_{K})}\n  \n, called an arithmetic surface. Also, let \n  \n    \n      \n        ∞\n        :\n        K\n        →\n        \n          C\n        \n      \n    \n    {\\displaystyle \\infty :K\\to \\mathbb {C} }\n  \n be an inclusion of fields (which is supposed to represent a place at infinity). Also, let \n  \n    \n      \n        \n          X\n          \n            ∞\n          \n        \n      \n    \n    {\\displaystyle X_{\\infty }}\n  \n be the associated Riemann surface from the base change to \n  \n    \n      \n        \n          C\n        \n      \n    \n    {\\displaystyle \\mathbb {C} }\n  \n. Using this data, one can define a c-divisor as a formal linear combination \n  \n    \n      \n        D\n        =\n        \n          ∑\n          \n            i\n          \n        \n        \n          k\n          \n            i\n          \n        \n        \n          C\n          \n            i\n          \n        \n        +\n        \n          ∑\n          \n            ∞\n ",
    "links": [
      "Absolute value (algebra)",
      "Adelic group",
      "Ample line bundle",
      "Annales Scientifiques de l'École Normale Supérieure",
      "Annals of Mathematics",
      "ArXiv (identifier)",
      "Arithmetic surface",
      "Bibcode (identifier)",
      "Bogomolov conjecture",
      "Chern character",
      "Chern class",
      "Chow ring",
      "Christophe Soulé",
      "Complete variety",
      "Compositio Mathematica",
      "Diophantine equation",
      "Diophantine geometry",
      "Doi (identifier)",
      "Emmanuel Ullmo",
      "Encyclopedia of Mathematics",
      "European Mathematical Society",
      "Field with one element",
      "Gerd Faltings",
      "Green's function",
      "Grothendieck–Riemann–Roch theorem",
      "Henri Gillet",
      "Hermitian metric",
      "Hodge theory",
      "Hodge–Arakelov theory",
      "Holomorphic vector bundle",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "Intersection theory",
      "Inventiones Mathematicae",
      "JSTOR (identifier)",
      "Journal of the American Mathematical Society",
      "Lucien Szpiro",
      "MR (identifier)",
      "Mathematics",
      "Mordell conjecture",
      "Noether formula",
      "P-adic Hodge theory",
      "P-adic valuation",
      "Paul Vojta",
      "Pierre Deligne",
      "Power series",
      "Riemann surface",
      "S2CID (identifier)",
      "Scheme (mathematics)",
      "Serge Lang"
    ],
    "categories": [
      "Category:Algebraic geometry",
      "Category:Articles with short description",
      "Category:Diophantine geometry",
      "Category:Short description matches Wikidata"
    ]
  },
  "Absolute value (algebra)": {
    "title": "Absolute value (algebra)",
    "url": "https://en.wikipedia.org/wiki/Absolute_value_(algebra)",
    "summary": "In algebra, an absolute value is a function that generalizes the usual absolute value. More precisely, if D is a field or (more generally) an integral domain, an absolute value on D is a function, commonly denoted \n  \n    \n      \n        \n          |\n        \n        x\n        \n          |\n        \n        ,\n      \n    \n    {\\displaystyle |x|,}\n  \n from D to the real numbers  satisfying:\n\nIt follows from the axioms that \n  \n    \n      \n        \n          |\n        \n        1\n        \n          |\n        \n        =\n        1\n        ,\n      \n    \n    {\\displaystyle |1|=1,}\n  \n  \n  \n    \n      \n        \n          |\n        \n        −\n        1\n        \n          |\n        \n        =\n        1\n        ,\n      \n    \n    {\\displaystyle |-1|=1,}\n  \n and \n  \n    \n      \n        \n          |\n        \n        −\n        x\n        \n          |\n        \n        =\n        \n          |\n        \n        x\n        \n          |\n        \n      \n    \n    {\\displaystyle |-x|=|x|}\n  \n for every ⁠\n  \n    \n ",
    "content": "In algebra, an absolute value is a function that generalizes the usual absolute value. More precisely, if D is a field or (more generally) an integral domain, an absolute value on D is a function, commonly denoted \n  \n    \n      \n        \n          |\n        \n        x\n        \n          |\n        \n        ,\n      \n    \n    {\\displaystyle |x|,}\n  \n from D to the real numbers  satisfying:\n\nIt follows from the axioms that \n  \n    \n      \n        \n          |\n        \n        1\n        \n          |\n        \n        =\n        1\n        ,\n      \n    \n    {\\displaystyle |1|=1,}\n  \n  \n  \n    \n      \n        \n          |\n        \n        −\n        1\n        \n          |\n        \n        =\n        1\n        ,\n      \n    \n    {\\displaystyle |-1|=1,}\n  \n and \n  \n    \n      \n        \n          |\n        \n        −\n        x\n        \n          |\n        \n        =\n        \n          |\n        \n        x\n        \n          |\n        \n      \n    \n    {\\displaystyle |-x|=|x|}\n  \n for every ⁠\n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n⁠. Furthermore, for every positive integer n,\n\n  \n    \n      \n        \n          |\n        \n        n\n        \n          |\n        \n        ≤\n        n\n        ,\n      \n    \n    {\\displaystyle |n|\\leq n,}\n  \n where the leftmost n denotes the sum of n summands equal to the identity element of D.\nThe classical absolute value and its square root are examples of absolute values, but the square of the classical absolute value is not, as it does not fulfill the triangular inequality.\nAn absolute value induces a metric (and thus a topology) on D by settting \n  \n    \n      \n        d\n        (\n        x\n        ,\n        y\n        )\n        =\n        \n          |\n        \n        x\n        −\n        y\n        \n          |\n        \n        .\n      \n    \n    {\\displaystyle d(x,y)=|x-y|.}\n\nExamples\nThe standard absolute value on the integers, the rationals and the real numbers: \n  \n    \n      \n        \n          |\n        \n        x\n        \n          |\n        \n        =\n        x\n      \n    \n    {\\displaystyle |x|=x}\n  \n for \n  \n    \n      \n        x\n        ≥\n        0\n      \n    \n    {\\displaystyle x\\geq 0}\n  \n and \n  \n    \n      \n        \n          |\n        \n        x\n        \n          |\n        \n        =\n        −\n        x\n      \n    \n    {\\displaystyle |x|=-x}\n  \n for \n  \n    \n      \n        x\n        <\n        0\n      \n    \n    {\\displaystyle x<0}\n  \n.\nThe standard absolute value or modulus on the complex numbers: \n  \n    \n      \n        \n          |\n        \n        a\n        +\n        b\n        i\n        \n          |\n        \n        =\n        \n          \n            (\n            \n              a\n              \n                2\n              \n            \n            +\n            \n              b\n              \n                2\n              \n            \n            )\n          \n        \n      \n    \n    {\\displaystyle |a+bi|={\\sqrt {(a^{2}+b^{2})}}}\n  \n for \n  \n    \n      \n        a\n        ,\n        b\n        ∈\n        \n          \n            R\n          \n        \n      \n    \n    {\\displaystyle a,b\\in {\\mathbb {R}}}\n  \n.\nThe p-adic absolute value on the rational numbers, where p is a fixed prime: \n  \n    \n      \n        \n          |\n        \n        0\n        \n          \n            |\n          \n          \n            p\n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle |0|_{p}=0}\n  \n and for \n  \n    \n      \n        x\n        ≠\n        0\n      \n    \n    {\\displaystyle x\\neq 0}\n  \n we set \n  \n    \n      \n        \n          |\n        \n        x\n        \n          \n            |\n          \n          \n            p\n          \n        \n        =\n        \n          p\n          \n            −\n            n\n          \n        \n      \n    \n    {\\displaystyle |x|_{p}=p^{-n}}\n  \n, where n is the unique integer such that \n  \n    \n      \n        x\n        =\n        \n          p\n          \n            n\n          \n        \n        \n          \n            a\n            b\n          \n        \n      \n    \n    {\\displaystyle x=p^{n}{\\frac {a}{b}}}\n  \n and a and b are two integers coprime with p.\nIf \n  \n    \n      \n        F\n        (\n        x\n        )\n      \n    \n    {\\displaystyle F(x)}\n  \n is the field of rational fractions over a field F in the variable x, and \n  \n    \n      \n        P\n      \n    \n    {\\displaystyle P}\n  \n is a fixed irreducible polynomial over F, the P-adic absolute value on \n  \n    \n      \n        F\n        (\n        x\n        )\n      \n    \n    {\\displaystyle F(x)}\n  \n is defined as follows: \n  \n    \n      \n        \n          |\n        \n        0\n        \n          \n            |\n          \n          \n            P\n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle |0|_{P}=0}\n  \n and for \n  \n    \n      \n        f\n        ≠\n        0\n      \n    \n    {\\displaystyle f\\neq 0}\n  \n we set \n  \n    \n      \n        \n          |\n        \n        f\n        \n          \n            |\n          \n          \n            P\n          \n    ",
    "links": [
      "Absolute value",
      "Absolute value (disambiguation)",
      "Alexander Ostrowski",
      "Algebra",
      "Algebraic number theory",
      "Archimedes",
      "Cambridge University Press",
      "Cauchy sequence",
      "Complete metric space",
      "Complex numbers",
      "Coprime integers",
      "Coprime polynomials",
      "Embedding",
      "Equivalence class",
      "Field (mathematics)",
      "Field extension",
      "Field norm",
      "Field of fractions",
      "Finite field",
      "Function (mathematics)",
      "ISBN (identifier)",
      "Identity element",
      "If and only if",
      "Integer",
      "Integral domain",
      "Irreducible polynomial",
      "Isomorphic",
      "J. W. S. Cassels",
      "Local ring",
      "Magnitude (mathematics)",
      "Maximal ideal",
      "Metric (mathematics)",
      "Nathan Jacobson",
      "Neal Koblitz",
      "Nicolas Bourbaki",
      "Norm (mathematics)",
      "Ostrowski's theorem",
      "P-adic number",
      "P-adic valuation",
      "Positive-definite function",
      "Prime ideal",
      "Prime number",
      "Quotient ring",
      "Rational fraction",
      "Rational numbers",
      "Real number",
      "Ring (mathematics)",
      "Square root",
      "Subring",
      "Topological space"
    ],
    "categories": [
      "Category:Abstract algebra",
      "Category:Articles with short description",
      "Category:Pages that use a deprecated format of the math tags",
      "Category:Short description matches Wikidata"
    ]
  },
  "Adele ring": {
    "title": "Adele ring",
    "url": "https://en.wikipedia.org/wiki/Adele_ring",
    "summary": "In mathematics, the adele ring of a global field (also adelic ring, ring of adeles or ring of adèles) is a central object of class field theory, a branch of algebraic number theory. It is the restricted product of all the completions of the global field and is an example of a self-dual topological ring.\nAn adele derives from a particular kind of idele. \"Idele\" derives from the French \"idèle\" and was coined by the French mathematician Claude Chevalley. The word stands for 'ideal element' (abbreviated: id.el.). Adele (French: \"adèle\") stands for 'additive idele' (that is, additive ideal element).\nThe ring of adeles allows one to describe the Artin reciprocity law, which is a generalisation of quadratic reciprocity, and other reciprocity laws over finite fields. In addition, it is a classical theorem from Weil that \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n-bundles on an algebraic curve over a finite field can be described in terms of adeles for a reductive group \n  \n",
    "content": "In mathematics, the adele ring of a global field (also adelic ring, ring of adeles or ring of adèles) is a central object of class field theory, a branch of algebraic number theory. It is the restricted product of all the completions of the global field and is an example of a self-dual topological ring.\nAn adele derives from a particular kind of idele. \"Idele\" derives from the French \"idèle\" and was coined by the French mathematician Claude Chevalley. The word stands for 'ideal element' (abbreviated: id.el.). Adele (French: \"adèle\") stands for 'additive idele' (that is, additive ideal element).\nThe ring of adeles allows one to describe the Artin reciprocity law, which is a generalisation of quadratic reciprocity, and other reciprocity laws over finite fields. In addition, it is a classical theorem from Weil that \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n-bundles on an algebraic curve over a finite field can be described in terms of adeles for a reductive group \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n. Adeles are also connected with the adelic algebraic groups and adelic curves.\nThe study of geometry of numbers over the ring of adeles of a number field is called adelic geometry.\n\nDefinition\nLet \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n be a global field (a finite extension of \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbf {Q} }\n  \n or the function field of a curve \n  \n    \n      \n        X\n        \n          /\n        \n        \n          \n            F\n            \n              \n                q\n              \n            \n          \n        \n      \n    \n    {\\displaystyle X/\\mathbf {F_{\\mathit {q}}} }\n  \n over a finite field). The adele ring of \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n is the subring\n\n  \n    \n      \n        \n          \n            A\n          \n          \n            K\n          \n        \n         \n        =\n         \n        ∏\n        (\n        \n          K\n          \n            ν\n          \n        \n        ,\n        \n          \n            \n              O\n            \n          \n          \n            ν\n          \n        \n        )\n         \n        ⊆\n         \n        ∏\n        \n          K\n          \n            ν\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {A} _{K}\\ =\\ \\prod (K_{\\nu },{\\mathcal {O}}_{\\nu })\\ \\subseteq \\ \\prod K_{\\nu }}\n  \n\nconsisting of the tuples \n  \n    \n      \n        (\n        \n          a\n          \n            ν\n          \n        \n        )\n      \n    \n    {\\displaystyle (a_{\\nu })}\n  \n where \n  \n    \n      \n        \n          a\n          \n            ν\n          \n        \n      \n    \n    {\\displaystyle a_{\\nu }}\n  \n lies in the subring \n  \n    \n      \n        \n          \n            \n              O\n            \n          \n          \n            ν\n          \n        \n        ⊂\n        \n          K\n          \n            ν\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {O}}_{\\nu }\\subset K_{\\nu }}\n  \n for all but finitely many places \n  \n    \n      \n        ν\n      \n    \n    {\\displaystyle \\nu }\n  \n. Here the index \n  \n    \n      \n        ν\n      \n    \n    {\\displaystyle \\nu }\n  \n ranges over all valuations of the global field \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n, \n  \n    \n      \n        \n          K\n          \n            ν\n          \n        \n      \n    \n    {\\displaystyle K_{\\nu }}\n  \n is the completion at that valuation and \n  \n    \n      \n        \n          \n            \n              O\n            \n          \n          \n            ν\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {O}}_{\\nu }}\n  \n the corresponding valuation ring.\n\nMotivation\nThe ring of adeles solves the technical problem of \"doing analysis on the rational numbers \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbf {Q} }\n  \n.\" The classical solution was to pass to the standard metric completion \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbf {R} }\n  \n and use analytic techniques there. But, as was learned later on, there are many more absolute values other than the Euclidean distance, one for each prime number \n  \n    \n      \n        p\n        ∈\n        \n          Z\n        \n      \n    \n    {\\displaystyle p\\in \\mathbf {Z} }\n  \n, as classified by Ostrowski's theorem. The Euclidean absolute value, denoted \n  \n    \n      \n        \n          |\n        \n        ⋅\n        \n          \n            |\n          \n          \n            ∞\n          \n        \n      \n    \n    {\\displaystyle |\\cdot |_{\\infty }}\n  \n, is only one among many others, \n  \n    \n      \n        \n          |\n        \n        ⋅\n        \n          \n            |\n          \n          \n            p\n          \n        \n      \n    \n    {\\displaystyle |\\cdot |_{p}}\n  \n, but the ring of adeles makes it possible to comprehend and use all of the valuations at once. This ha",
    "links": [
      "Abelian extension",
      "Absolute value (algebra)",
      "Adele",
      "Adelic algebraic group",
      "Albrecht Fröhlich",
      "Algebraic curve",
      "Algebraic number field",
      "Algebraic number theory",
      "André Weil",
      "ArXiv (identifier)",
      "Artin reciprocity law",
      "Cartesian product",
      "Chinese remainder theorem",
      "Class field theory",
      "Claude Chevalley",
      "Complete metric space",
      "Completion of a ring",
      "Complex plane",
      "Dedekind zeta function",
      "Dirichlet L-function",
      "Divisible group",
      "Doi (identifier)",
      "Duality (mathematics)",
      "Equivalence class",
      "Euclidean distance",
      "Everywhere-dense set",
      "French language",
      "Function field of an algebraic variety",
      "Fundamental theorem on homomorphisms",
      "Geometry of numbers",
      "Global field",
      "Haar measure",
      "Harmonic analysis",
      "Hasse principle",
      "Hasse–Minkowski theorem",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "Ideal class group",
      "Idele",
      "Integer factorization",
      "J. W. S. Cassels",
      "John T. Tate",
      "John Tate (mathematician)",
      "Jürgen Neukirch",
      "L-function",
      "Langlands program",
      "Lebesgue measure",
      "Line bundle",
      "List of mathematical jargon",
      "Local class field theory"
    ],
    "categories": [
      "Category:Algebraic number theory",
      "Category:All articles needing additional references",
      "Category:Articles containing French-language text",
      "Category:Articles needing additional references from May 2023",
      "Category:Articles with short description",
      "Category:CS1 German-language sources (de)",
      "Category:Pages that use a deprecated format of the math tags",
      "Category:Short description is different from Wikidata",
      "Category:Topological algebra",
      "Category:Wikipedia articles needing clarification from May 2023"
    ]
  },
  "Arithmetic function": {
    "title": "Arithmetic function",
    "url": "https://en.wikipedia.org/wiki/Arithmetic_function",
    "summary": "In number theory, an arithmetic, arithmetical, or number-theoretic function is generally any function whose domain is the set of positive integers and whose range is a subset of the complex numbers. Hardy & Wright include in their definition the requirement that an arithmetical function \"expresses some arithmetical property of n\". There is a larger class of number-theoretic functions that do not fit this definition, for example, the prime-counting functions. This article provides links to functions of both classes.\nAn example of an arithmetic function is the divisor function whose value at a positive integer n is equal to the number of divisors of n.\nArithmetic functions are often extremely irregular (see table), but some of them have series expansions in terms of Ramanujan's sum.",
    "content": "In number theory, an arithmetic, arithmetical, or number-theoretic function is generally any function whose domain is the set of positive integers and whose range is a subset of the complex numbers. Hardy & Wright include in their definition the requirement that an arithmetical function \"expresses some arithmetical property of n\". There is a larger class of number-theoretic functions that do not fit this definition, for example, the prime-counting functions. This article provides links to functions of both classes.\nAn example of an arithmetic function is the divisor function whose value at a positive integer n is equal to the number of divisors of n.\nArithmetic functions are often extremely irregular (see table), but some of them have series expansions in terms of Ramanujan's sum.\n\nMultiplicative and additive functions\nAn arithmetic function a is\n\ncompletely additive if a(mn) = a(m) + a(n) for all natural numbers m and n;\ncompletely multiplicative if a(1) = 1 and a(mn) = a(m)a(n) for all natural numbers m and n;\nTwo whole numbers m and n are called coprime if their greatest common divisor is 1, that is, if there is no prime number that divides both of them.\nThen an arithmetic function a is\n\nadditive if a(mn) = a(m) + a(n) for all coprime natural numbers m and n;\nmultiplicative if a(1) = 1 and a(mn) = a(m)a(n) for all coprime natural numbers m and n.\n\nNotation\nIn this article, \n  \n    \n      \n        \n          ∑\n          \n            p\n          \n        \n        f\n        (\n        p\n        )\n      \n    \n    {\\textstyle \\sum _{p}f(p)}\n  \n and \n  \n    \n      \n        \n          ∏\n          \n            p\n          \n        \n        f\n        (\n        p\n        )\n      \n    \n    {\\textstyle \\prod _{p}f(p)}\n  \n mean that the sum or product is over all prime numbers:\n\n  \n    \n      \n        \n          ∑\n          \n            p\n          \n        \n        f\n        (\n        p\n        )\n        =\n        f\n        (\n        2\n        )\n        +\n        f\n        (\n        3\n        )\n        +\n        f\n        (\n        5\n        )\n        +\n        ⋯\n      \n    \n    {\\displaystyle \\sum _{p}f(p)=f(2)+f(3)+f(5)+\\cdots }\n  \n\nand\n\n  \n    \n      \n        \n          ∏\n          \n            p\n          \n        \n        f\n        (\n        p\n        )\n        =\n        f\n        (\n        2\n        )\n        f\n        (\n        3\n        )\n        f\n        (\n        5\n        )\n        ⋯\n        .\n      \n    \n    {\\displaystyle \\prod _{p}f(p)=f(2)f(3)f(5)\\cdots .}\n  \n\nSimilarly, \n  \n    \n      \n        \n          ∑\n          \n            \n              p\n              \n                k\n              \n            \n          \n        \n        f\n        (\n        \n          p\n          \n            k\n          \n        \n        )\n      \n    \n    {\\textstyle \\sum _{p^{k}}f(p^{k})}\n  \n and \n  \n    \n      \n        \n          ∏\n          \n            \n              p\n              \n                k\n              \n            \n          \n        \n        f\n        (\n        \n          p\n          \n            k\n          \n        \n        )\n      \n    \n    {\\textstyle \\prod _{p^{k}}f(p^{k})}\n  \n mean that the sum or product is over all prime powers with strictly positive exponent (so k = 0 is not included):\n\n  \n    \n      \n        \n          ∑\n          \n            \n              p\n              \n                k\n              \n            \n          \n        \n        f\n        (\n        \n          p\n          \n            k\n          \n        \n        )\n        =\n        \n          ∑\n          \n            p\n          \n        \n        \n          ∑\n          \n            k\n            >\n            0\n          \n        \n        f\n        (\n        \n          p\n          \n            k\n          \n        \n        )\n        =\n        f\n        (\n        2\n        )\n        +\n        f\n        (\n        3\n        )\n        +\n        f\n        (\n        4\n        )\n        +\n        f\n        (\n        5\n        )\n        +\n        f\n        (\n        7\n        )\n        +\n        f\n        (\n        8\n        )\n        +\n        f\n        (\n        9\n        )\n        +\n        ⋯\n        .\n      \n    \n    {\\displaystyle \\sum _{p^{k}}f(p^{k})=\\sum _{p}\\sum _{k>0}f(p^{k})=f(2)+f(3)+f(4)+f(5)+f(7)+f(8)+f(9)+\\cdots .}\n  \n\nThe notations \n  \n    \n      \n        \n          ∑\n          \n            d\n            ∣\n            n\n          \n        \n        f\n        (\n        d\n        )\n      \n    \n    {\\textstyle \\sum _{d\\mid n}f(d)}\n  \n and \n  \n    \n      \n        \n          ∏\n          \n            d\n            ∣\n            n\n          \n        \n        f\n        (\n        d\n        )\n      \n    \n    {\\textstyle \\prod _{d\\mid n}f(d)}\n  \n mean that the sum or product is over all positive divisors of n, including 1 and n. For example, if n = 12, then\n\n  \n    \n      \n        \n          ∏\n          \n            d\n            ∣\n            12\n          \n        \n        f\n        (\n        d\n        )\n        =\n        f\n ",
    "links": [
      "Abundant number",
      "Achilles number",
      "Additive function",
      "Additive persistence",
      "Aliquot sequence",
      "Almost perfect number",
      "Almost prime",
      "Amenable number",
      "Amicable numbers",
      "An Introduction to the Theory of Numbers",
      "Arithmetic derivative",
      "Arithmetic dynamics",
      "Arithmetic number",
      "Aronson's sequence",
      "Asymptotic analysis",
      "Automorphic number",
      "Average order of an arithmetic function",
      "Ban number",
      "Bell number",
      "Betrothed numbers",
      "Binary number",
      "Blum integer",
      "Cake number",
      "Cambridge University Press",
      "Carmichael function",
      "Carmichael number",
      "Catalan number",
      "Catalan pseudoprime",
      "Cauchy product",
      "Centered cube number",
      "Centered decagonal number",
      "Centered dodecahedral number",
      "Centered heptagonal number",
      "Centered hexagonal number",
      "Centered icosahedral number",
      "Centered nonagonal number",
      "Centered octagonal number",
      "Centered octahedral number",
      "Centered pentagonal number",
      "Centered polygonal number",
      "Centered polyhedral number",
      "Centered square number",
      "Centered tetrahedral number",
      "Centered triangular number",
      "Chebyshev function",
      "Classification of discontinuities",
      "Colossally abundant number",
      "Completely additive function",
      "Completely multiplicative function",
      "Complex number"
    ],
    "categories": [
      "Category:All pages needing cleanup",
      "Category:Arithmetic functions",
      "Category:Articles needing cleanup from July 2020",
      "Category:Articles with sections that need to be turned into prose from July 2020",
      "Category:Articles with short description",
      "Category:CS1 errors: ISBN date",
      "Category:Functions and mappings",
      "Category:Short description is different from Wikidata",
      "Category:Webarchive template wayback links"
    ]
  },
  "Arithmetic topology": {
    "title": "Arithmetic topology",
    "url": "https://en.wikipedia.org/wiki/Arithmetic_topology",
    "summary": "Arithmetic topology is an area of mathematics that is a combination of algebraic number theory and topology. It establishes an analogy between number fields and closed, orientable 3-manifolds.",
    "content": "Arithmetic topology is an area of mathematics that is a combination of algebraic number theory and topology. It establishes an analogy between number fields and closed, orientable 3-manifolds.\n\nAnalogies\nThe following are some of the analogies used by mathematicians between number fields and 3-manifolds:\n\nA number field corresponds to a closed, orientable 3-manifold\nIdeals in the ring of integers correspond to links, and prime ideals correspond to knots.\nThe field Q of rational numbers corresponds to the 3-sphere.\nExpanding on the last two examples,  there is an analogy between knots and prime numbers in which one considers \"links\" between primes. The triple of primes (13, 61, 937) are \"linked\" modulo 2 (the Rédei symbol is −1) but are \"pairwise unlinked\" modulo 2 (the Legendre symbols are all 1). Therefore these primes have been called a \"proper Borromean triple modulo 2\" or \"mod 2 Borromean primes\".\n\nHistory\nIn the 1960s topological interpretations of class field theory were given by John Tate based on Galois cohomology, and also by Michael Artin and Jean-Louis Verdier based on Étale cohomology. Then David Mumford (and independently Yuri Manin) came up with an analogy between prime ideals and knots which was further explored by Barry Mazur. In the 1990s Reznikov and Kapranov began studying these analogies, coining the term arithmetic topology for this area of study.\n\nSee also\nArithmetic geometry\nArithmetic dynamics\nTopological quantum field theory\nLanglands program\n\nNotes\nFurther reading\nMasanori Morishita (2011), Knots and Primes, Springer, ISBN 978-1-4471-2157-2\nMasanori Morishita (2009), Analogies Between Knots And Primes, 3-Manifolds And Number Rings\nChristopher Deninger (2002), A note on arithmetic topology and dynamical systems\nAdam S. Sikora (2001), Analogies between group actions on 3-manifolds and number fields\nCurtis T. McMullen (2003), From dynamics on surfaces to rational points on curves\nChao Li and Charmaine Sia (2012), Knots and Primes\n\nExternal links\nMazur’s knotty dictionary",
    "links": [
      "0",
      "1",
      "3-manifold",
      "3-sphere",
      "Abstract algebra",
      "Additive number theory",
      "Algebra",
      "Algebraic geometry",
      "Algebraic number",
      "Algebraic number theory",
      "Algebraic topology",
      "Anabelian geometry",
      "Analytic geometry",
      "Analytic number theory",
      "Applied mathematics",
      "ArXiv (identifier)",
      "Arakelov theory",
      "Arithmetic",
      "Arithmetic combinatorics",
      "Arithmetic dynamics",
      "Arithmetic function",
      "Arithmetic geometry",
      "Barry Mazur",
      "Bibcode (identifier)",
      "Calculus",
      "Category theory",
      "Chinese remainder theorem",
      "Class field theory",
      "Combinatorics",
      "Commutative algebra",
      "Complex analysis",
      "Composite number",
      "Computational complexity theory",
      "Computational mathematics",
      "Computational number theory",
      "Computer algebra",
      "Computer science",
      "Control theory",
      "Curtis T. McMullen",
      "David Mumford",
      "Differential equation",
      "Differential geometry",
      "Differential topology",
      "Diophantine approximation",
      "Diophantine equation",
      "Diophantine geometry",
      "Discrete geometry",
      "Discrete mathematics",
      "Doi (identifier)",
      "Elementary algebra"
    ],
    "categories": [
      "Category:3-manifolds",
      "Category:Algebraic number theory",
      "Category:Articles with short description",
      "Category:Knot theory",
      "Category:Short description is different from Wikidata",
      "Category:Use mdy dates from March 2023",
      "Category:Webarchive template wayback links"
    ]
  },
  "Artin L-function": {
    "title": "Artin L-function",
    "url": "https://en.wikipedia.org/wiki/Artin_L-function",
    "summary": "In mathematics, an Artin L-function is a type of Dirichlet series associated to a linear representation ρ of a Galois group G. These functions were introduced in 1923 by Emil Artin, in connection with his research into class field theory. Their fundamental properties, in particular the Artin conjecture described below,  have turned out to be resistant to easy proof. One of the aims of proposed non-abelian class field theory is to incorporate the complex-analytic nature of Artin L-functions into a larger framework, such as is provided by automorphic forms and the Langlands program. So far, only a small part of such a theory has been put on a firm basis.",
    "content": "In mathematics, an Artin L-function is a type of Dirichlet series associated to a linear representation ρ of a Galois group G. These functions were introduced in 1923 by Emil Artin, in connection with his research into class field theory. Their fundamental properties, in particular the Artin conjecture described below,  have turned out to be resistant to easy proof. One of the aims of proposed non-abelian class field theory is to incorporate the complex-analytic nature of Artin L-functions into a larger framework, such as is provided by automorphic forms and the Langlands program. So far, only a small part of such a theory has been put on a firm basis.\n\nDefinition\nGiven \n  \n    \n      \n        ρ\n      \n    \n    {\\displaystyle \\rho }\n  \n, a representation of \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n on a finite-dimensional complex vector space \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n, where \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n is the Galois group of the finite extension \n  \n    \n      \n        L\n        \n          /\n        \n        K\n      \n    \n    {\\displaystyle L/K}\n  \n of number fields, the Artin \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  \n-function \n  \n    \n      \n        L\n        (\n        ρ\n        ,\n        s\n        )\n      \n    \n    {\\displaystyle L(\\rho ,s)}\n  \n is defined by an Euler product. For each prime ideal \n  \n    \n      \n        \n          \n            p\n          \n        \n      \n    \n    {\\displaystyle {\\mathfrak {p}}}\n  \n in \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n's ring of integers, there is an Euler factor, which is easiest to define in the case where \n  \n    \n      \n        \n          \n            p\n          \n        \n      \n    \n    {\\displaystyle {\\mathfrak {p}}}\n  \n is unramified in \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  \n (true for almost all \n  \n    \n      \n        \n          \n            p\n          \n        \n      \n    \n    {\\displaystyle {\\mathfrak {p}}}\n  \n). In that case, the Frobenius element \n  \n    \n      \n        \n          F\n          r\n          o\n          b\n        \n        (\n        \n          \n            p\n          \n        \n        )\n      \n    \n    {\\displaystyle \\mathbf {Frob} ({\\mathfrak {p}})}\n  \n is defined as a conjugacy class in \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n. Therefore, the characteristic polynomial of  \n  \n    \n      \n        ρ\n        (\n        \n          F\n          r\n          o\n          b\n        \n        (\n        \n          \n            p\n          \n        \n        )\n        )\n      \n    \n    {\\displaystyle \\rho (\\mathbf {Frob} ({\\mathfrak {p}}))}\n  \n is well-defined. The Euler factor for \n  \n    \n      \n        \n          \n            p\n          \n        \n      \n    \n    {\\displaystyle {\\mathfrak {p}}}\n  \n is a slight modification of the characteristic polynomial, equally well-defined,\n\n  \n    \n      \n        charpoly\n        ⁡\n        (\n        ρ\n        (\n        \n          F\n          r\n          o\n          b\n        \n        (\n        \n          \n            p\n          \n        \n        )\n        )\n        \n          )\n          \n            −\n            1\n          \n        \n        =\n        det\n        ⁡\n        \n          \n            [\n            \n              I\n              −\n              t\n              ρ\n              (\n              \n                F\n                r\n                o\n                b\n              \n              (\n              \n                \n                  p\n                \n              \n              )\n              )\n            \n            ]\n          \n          \n            −\n            1\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\operatorname {charpoly} (\\rho (\\mathbf {Frob} ({\\mathfrak {p}})))^{-1}=\\operatorname {det} \\left[I-t\\rho (\\mathbf {Frob} ({\\mathfrak {p}}))\\right]^{-1},}\n  \n\nas rational function in t, evaluated at \n  \n    \n      \n        t\n        =\n        N\n        (\n        \n          \n            p\n          \n        \n        \n          )\n          \n            −\n            s\n          \n        \n      \n    \n    {\\displaystyle t=N({\\mathfrak {p}})^{-s}}\n  \n, with \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n  \n a complex variable in the usual Riemann zeta function notation. (Here N is the field norm of an ideal.)\nWhen \n  \n    \n      \n        \n          \n            p\n          \n        \n      \n    \n    {\\displaystyle {\\mathfrak {p}}}\n  \n is ramified, and I is the inertia group which is a subgroup of G, a similar construction is applied, but to the subspace of V fixed (pointwise) by I.\nThe Artin L-function \n  \n    \n      \n        L\n        (\n        ρ\n        ,\n        s\n        )\n      \n    \n    {\\displaystyle L(\\rho ,s)}\n  \n is then the infinite product over all prime ideals \n  \n    \n      \n        \n          \n            p\n          \n        \n      \n    \n    {\\displ",
    "links": [
      "Abelian group",
      "Adelic group",
      "Albrecht Fröhlich",
      "Almost all",
      "Andrew Wiles",
      "André Weil",
      "Artin conjecture (L-functions)",
      "Artin reciprocity",
      "Automorphic L-function",
      "Automorphic form",
      "Automorphic representation",
      "Base change lifting",
      "Beilinson conjectures",
      "Birch and Swinnerton-Dyer conjecture",
      "Bloch–Kato conjecture (L-functions)",
      "Brauer's theorem on induced characters",
      "Character theory",
      "Characteristic polynomial",
      "Chebotarev's density theorem",
      "Class field theory",
      "Class number formula",
      "Coinvariant",
      "Complex conjugate representation",
      "Complex number",
      "Conjugacy class",
      "Cuspidal representation",
      "Dedekind zeta function",
      "Dirichlet's theorem on arithmetic progressions",
      "Dirichlet L-function",
      "Dirichlet series",
      "Doi (identifier)",
      "Emil Artin",
      "Encyclopedia of Mathematics",
      "Equivalent representation",
      "Equivariant L-function",
      "Erich Hecke",
      "Euler product",
      "Euler system",
      "European Mathematical Society",
      "Field norm",
      "Finite extension",
      "Frobenius element",
      "Function field of an algebraic variety",
      "Functional equation (L-function)",
      "GL(n)",
      "Galois extension",
      "Galois group",
      "Galois module",
      "Gamma function",
      "Generalized Riemann hypothesis"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1 German-language sources (de)",
      "Category:Class field theory",
      "Category:Short description matches Wikidata",
      "Category:Zeta and L-functions"
    ]
  },
  "Category of rings": {
    "title": "Category of rings",
    "url": "https://en.wikipedia.org/wiki/Category_of_rings",
    "summary": "In mathematics, the category of rings, denoted by Ring, is the category whose objects are rings (with identity) and whose morphisms are ring homomorphisms (that preserve the identity). Like many categories in mathematics, the category of rings is large, meaning that the class of all rings is proper.",
    "content": "In mathematics, the category of rings, denoted by Ring, is the category whose objects are rings (with identity) and whose morphisms are ring homomorphisms (that preserve the identity). Like many categories in mathematics, the category of rings is large, meaning that the class of all rings is proper.\n\nAs a concrete category\nThe category Ring is a concrete category meaning that the objects are sets with additional structure (addition and multiplication) and the morphisms are functions that preserve this structure. There is a natural forgetful functor\n\nU : Ring → Set\nfor the category of rings to the category of sets which sends each ring to its underlying set (thus \"forgetting\" the operations of addition and multiplication). This functor has a left adjoint\n\nF : Set → Ring\nwhich assigns to each set X the free ring generated by X.\nOne can also view the category of rings as a concrete category over Ab (the category of abelian groups) or over Mon (the category of monoids). Specifically, there are forgetful functors\n\nA : Ring → Ab\nM : Ring → Mon\nwhich \"forget\" multiplication and addition, respectively. Both of these functors have left adjoints. The left adjoint of A is the functor which assigns to every abelian group X (thought of as a Z-module) the tensor ring T(X). The left adjoint of M is the functor which assigns to every monoid X the integral monoid ring Z[X].\n\nProperties\nLimits and colimits\nThe category Ring is both complete and cocomplete, meaning that all small limits and colimits exist in Ring. Like many other algebraic categories, the forgetful functor U : Ring → Set creates (and preserves) limits and filtered colimits, but does not preserve either coproducts or coequalizers. The forgetful functors to Ab and Mon also create and preserve limits.\nExamples of limits and colimits in Ring include:\n\nThe ring of integers Z is an initial object in Ring.\nThe zero ring is a terminal object in Ring.\nThe product in Ring is given by the direct product of rings. This is just the cartesian product of the underlying sets with addition and multiplication defined component-wise.\nThe coproduct of a family of rings exists and is given by a construction analogous to the free product of groups.  The coproduct of nonzero rings can be the zero ring; in particular, this happens whenever the factors have relatively prime characteristic (since the characteristic of the coproduct of (Ri)i∈I must divide the characteristics of each of the rings Ri).\nThe equalizer in Ring is just the set-theoretic equalizer (the equalizer of two ring homomorphisms is always a subring).\nThe coequalizer of two ring homomorphisms f and g from R to S is the quotient of S by the ideal generated by all elements of the form f(r) − g(r) for r ∈ R.\nGiven a ring homomorphism f : R → S the kernel pair of f (this is just the pullback of f with itself) is a congruence relation on R. The ideal determined by this congruence relation is precisely the (ring-theoretic) kernel of f. Note that category-theoretic kernels do not make sense in Ring since there are no zero morphisms (see below).\n\nMorphisms\nUnlike many categories studied in mathematics, there do not always exist morphisms between pairs of objects in Ring. This is a consequence of the fact that ring homomorphisms must preserve the identity. For example, there are no morphisms from the zero ring 0 to any nonzero ring. A necessary condition for there to be morphisms from R to S is that the characteristic of S divide that of R.\nNote that even though some of the hom-sets are empty, the category Ring is still connected since it has an initial object.\nSome special classes of morphisms in Ring include:\n\nIsomorphisms in Ring are the bijective ring homomorphisms.\nMonomorphisms in Ring are the injective homomorphisms. Not every monomorphism is regular however.\nEvery surjective homomorphism is an epimorphism in Ring, but the converse is not true. The inclusion Z → Q is a nonsurjective epimorphism.  The natural ring homomorphism from any commutative ring R to any one of its localizations is an epimorphism which is not necessarily surjective.\nThe surjective homomorphisms can be characterized as the regular or extremal epimorphisms in Ring (these two classes coinciding).\nBimorphisms in Ring are the injective epimorphisms. The inclusion Z → Q is an example of a bimorphism which is not an isomorphism.\n\nOther properties\nThe only injective object in Ring up to isomorphism is the zero ring (i.e. the terminal object).\nLacking zero morphisms, the category of rings cannot be a preadditive category. (However, every ring—considered as a category with a single object—is a preadditive category).\nThe category of rings is a symmetric monoidal category with the tensor product of rings ⊗Z as the monoidal product and the ring of integers Z as the unit object. It follows from the Eckmann–Hilton theorem, that a monoid in Ring is a commutative ring. The action of a monoid (= commutative ring) R on an object (= ring) A of Ring is an R-algebra.\n\n",
    "links": [
      "Abelian group",
      "Algebra (ring theory)",
      "Algebra homomorphism",
      "Algebraic number field",
      "Algebraic number theory",
      "Algebraic structure",
      "Associative algebra",
      "Bijective",
      "Bimorphism",
      "Cartesian product",
      "Categories for the Working Mathematician",
      "Category-theoretic kernel",
      "Category (mathematics)",
      "Category of abelian groups",
      "Category of affine schemes",
      "Category of groups",
      "Category of monoids",
      "Category of sets",
      "Characteristic (algebra)",
      "Class (set theory)",
      "Clifford algebra",
      "Coequalizer",
      "Commutative algebra",
      "Commutative ring",
      "Commutative rings",
      "Commutator (ring theory)",
      "Complete category",
      "Concrete category",
      "Congruence relation",
      "Connected category",
      "Contravariant functor",
      "Coproduct",
      "Creation of limits",
      "Direct product of rings",
      "Division ring",
      "Eckmann–Hilton theorem",
      "Epimorphism",
      "Equalizer (mathematics)",
      "Equivalence of categories",
      "Euclidean domain",
      "Extremal epimorphism",
      "Field (mathematics)",
      "Field extension",
      "Filtered colimit",
      "Finite field",
      "Finitely complete category",
      "Forgetful functor",
      "Formal power series ring",
      "Fractional ideal",
      "Free algebra"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Categories in category theory",
      "Category:Ring theory",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Chinese remainder theorem": {
    "title": "Chinese remainder theorem",
    "url": "https://en.wikipedia.org/wiki/Chinese_remainder_theorem",
    "summary": "In mathematics, the Chinese remainder theorem states that if one knows the remainders of the Euclidean division of an integer n by several integers, then one can determine uniquely the remainder of the division of n by the product of these integers, under the condition that the divisors are pairwise coprime (no two divisors share a common factor other than 1). \n\nThe theorem is sometimes called Sunzi's theorem. Both names of the theorem refer to its earliest known statement that appeared in Sunzi Suanjing, a Chinese manuscript written during the 3rd to 5th century CE. This first statement was restricted to the following example:\nIf one knows that the remainder of n divided by 3 is 2, the remainder of n divided by 5 is 3, and the remainder of n divided by 7 is 2, then with no other information, one can determine the remainder of n divided by 105 (the product of 3, 5, and 7) without knowing the value of n. In this example, the remainder is 23. Moreover, this remainder is the only possible",
    "content": "In mathematics, the Chinese remainder theorem states that if one knows the remainders of the Euclidean division of an integer n by several integers, then one can determine uniquely the remainder of the division of n by the product of these integers, under the condition that the divisors are pairwise coprime (no two divisors share a common factor other than 1). \n\nThe theorem is sometimes called Sunzi's theorem. Both names of the theorem refer to its earliest known statement that appeared in Sunzi Suanjing, a Chinese manuscript written during the 3rd to 5th century CE. This first statement was restricted to the following example:\nIf one knows that the remainder of n divided by 3 is 2, the remainder of n divided by 5 is 3, and the remainder of n divided by 7 is 2, then with no other information, one can determine the remainder of n divided by 105 (the product of 3, 5, and 7) without knowing the value of n. In this example, the remainder is 23. Moreover, this remainder is the only possible positive value of n that is less than 105.\nThe Chinese remainder theorem is widely used for computing with large integers, as it allows replacing a computation for which one knows a bound on the size of the result by several similar computations on small integers.\nThe Chinese remainder theorem (expressed in terms of congruences) is true over every principal ideal domain. It has been generalized to any ring, with a formulation involving two-sided ideals.\n\nHistory\nThe earliest known statement of the problem appears in the 5th-century book Sunzi Suanjing by the Chinese mathematician Sunzi:\n\nThere are certain things whose number is unknown. If we count them by threes, we have two left over; by fives, we have three left over; and by sevens, two are left over. How many things are there?\nSunzi's work would not be considered a theorem by modern standards; it only gives one particular problem, without showing how to solve it, much less any proof about the general case or a general algorithm for solving it. An algorithm for solving this problem was described by Aryabhata (6th century). Special cases of the Chinese remainder theorem were also known to Brahmagupta (7th century) and appear in Fibonacci's Liber Abaci (1202). The result was later generalized with a complete solution called Da-yan-shu (大衍術) in Qin Jiushao's 1247 Mathematical Treatise in Nine Sections  which was translated into English in early 19th century by British missionary Alexander Wylie.\n\nThe notion of congruences was first introduced and used by Carl Friedrich Gauss in his Disquisitiones Arithmeticae of 1801. Gauss illustrates the Chinese remainder theorem on a problem involving calendars, namely, \"to find the years that have a certain period number with respect to the solar and lunar cycle and the Roman indiction.\" Gauss introduces a procedure for solving the problem that had already been used by Leonhard Euler but was in fact an ancient method that had appeared several times.\n\nStatement\nLet n1, ..., nk be integers greater than 1, which are often called moduli or divisors. Let us denote by N the product of the ni.\nThe Chinese remainder theorem asserts that if the ni are pairwise coprime, and if a1, ..., ak are integers such that 0 ≤ ai < ni for every i, then there is one and only one integer x, such that 0 ≤ x < N and the remainder of the Euclidean division of x by ni is ai for every i.\nThis may be restated as follows in terms of congruences:\nIf the \n  \n    \n      \n        \n          n\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle n_{i}}\n  \n are pairwise coprime, and if a1, ..., ak are any integers, then the system\n\n  \n    \n      \n        \n          \n            \n              \n                x\n              \n              \n                \n                ≡\n                \n                  a\n                  \n                    1\n                  \n                \n                \n                  \n                  (\n                  mod\n                  \n                  \n                    n\n                    \n                      1\n                    \n                  \n                  )\n                \n              \n            \n            \n              \n              \n                \n                \n                \n                \n                ⋮\n              \n            \n            \n              \n                x\n              \n              \n                \n                ≡\n                \n                  a\n                  \n                    k\n                  \n                \n                \n                  \n                  (\n                  mod\n                  \n                  \n                    n\n                    \n                      k\n                    \n                  \n                  )\n                \n                ,\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}x&\\equiv a_{1}{\\pmod {n_{1}}}\\\\&\\,\\,\\,\\vdot",
    "links": [
      "0",
      "1",
      "Abelian group",
      "Absolute value",
      "Abstract algebra",
      "Additive number theory",
      "Alexander Wylie (missionary)",
      "Algebra homomorphism",
      "Algebraic number",
      "Algebraic number theory",
      "Algorithm",
      "Anabelian geometry",
      "Analytic number theory",
      "Arakelov theory",
      "Arithmetic",
      "Arithmetic combinatorics",
      "Arithmetic dynamics",
      "Arithmetic function",
      "Arithmetic geometry",
      "Arithmetic progression",
      "Arithmetic topology",
      "Aryabhata",
      "Brahmagupta",
      "Bézout's identity",
      "Bézout coefficients",
      "Cardinality",
      "Carl Friedrich Gauss",
      "Central idempotent",
      "Charles E. Leiserson",
      "Chinese Text Project",
      "Class field theory",
      "Clifford Stein",
      "Codomain",
      "Combinatorics",
      "Commutative ring",
      "Composite number",
      "Computational number theory",
      "Congruence class",
      "Converse (logic)",
      "Coprime",
      "Coprime integers",
      "Coprime polynomials",
      "Covering system",
      "Degree of a polynomial",
      "Derivative",
      "Diophantine approximation",
      "Diophantine equation",
      "Diophantine geometry",
      "Disquisitiones Arithmeticae",
      "Divisor"
    ],
    "categories": [
      "Category:Articles containing Chinese-language text",
      "Category:Articles containing proofs",
      "Category:Articles with short description",
      "Category:CS1: long volume value",
      "Category:Chinese mathematical discoveries",
      "Category:Commutative algebra",
      "Category:Modular arithmetic",
      "Category:Short description is different from Wikidata",
      "Category:Theorems in number theory"
    ]
  },
  "Class field theory": {
    "title": "Class field theory",
    "url": "https://en.wikipedia.org/wiki/Class_field_theory",
    "summary": "In mathematics, class field theory (CFT) is the fundamental branch of algebraic number theory whose goal is to describe all the abelian Galois extensions of local and global fields using objects associated to the ground field. \nHilbert is credited as one of pioneers of the notion of a class field. However, this notion was already familiar to Kronecker and it was actually Weber who coined the term before Hilbert's fundamental papers came out. The relevant ideas were developed in the period of several decades, giving rise to a set of conjectures by Hilbert that were subsequently proved by Takagi and Artin (with the help of Chebotarev's theorem). \nOne of the major results is: given a number field F, and writing K for the maximal abelian unramified extension of F, the Galois group of K over F is canonically isomorphic to the ideal class group of F. This statement was generalized to the so called  Artin reciprocity law; in the idelic language, writing CF for the idele class group of F, and ",
    "content": "In mathematics, class field theory (CFT) is the fundamental branch of algebraic number theory whose goal is to describe all the abelian Galois extensions of local and global fields using objects associated to the ground field. \nHilbert is credited as one of pioneers of the notion of a class field. However, this notion was already familiar to Kronecker and it was actually Weber who coined the term before Hilbert's fundamental papers came out. The relevant ideas were developed in the period of several decades, giving rise to a set of conjectures by Hilbert that were subsequently proved by Takagi and Artin (with the help of Chebotarev's theorem). \nOne of the major results is: given a number field F, and writing K for the maximal abelian unramified extension of F, the Galois group of K over F is canonically isomorphic to the ideal class group of F. This statement was generalized to the so called  Artin reciprocity law; in the idelic language, writing CF for the idele class group of F, and taking L to be any finite abelian extension of F, this law gives a canonical isomorphism\n\n  \n    \n      \n        \n          θ\n          \n            L\n            \n              /\n            \n            F\n          \n        \n        :\n        \n          C\n          \n            F\n          \n        \n        \n          /\n        \n        \n          \n            N\n            \n              L\n              \n                /\n              \n              F\n            \n          \n          (\n          \n            C\n            \n              L\n            \n          \n          )\n        \n        →\n        Gal\n        ⁡\n        (\n        L\n        \n          /\n        \n        F\n        )\n        ,\n      \n    \n    {\\displaystyle \\theta _{L/F}:C_{F}/{N_{L/F}(C_{L})}\\to \\operatorname {Gal} (L/F),}\n  \n\nwhere \n  \n    \n      \n        \n          N\n          \n            L\n            \n              /\n            \n            F\n          \n        \n      \n    \n    {\\displaystyle N_{L/F}}\n  \n denotes the idelic norm map from L to F. This isomorphism is named the reciprocity map. \nThe existence theorem states that the reciprocity map can be used to give a bijection between the set of abelian extensions of F and the set of closed subgroups of finite index of \n  \n    \n      \n        \n          C\n          \n            F\n          \n        \n        .\n      \n    \n    {\\displaystyle C_{F}.}\n  \n\nA standard method for developing global class field theory since the 1930s was to construct local class field theory, which describes abelian extensions of local fields, and then use it to construct global class field theory. This was first done by Emil Artin and Tate using the theory of group cohomology, and in particular by developing the notion of class formations. Later, Neukirch found a proof of the main statements of global class field theory without using cohomological ideas. His method was explicit and algorithmic. \nInside class field theory one can distinguish special class field theory and general class field theory. \nExplicit class field theory provides an explicit construction of maximal abelian extensions of a number field in various situations. This portion of the theory consists of Kronecker–Weber theorem, which can be used to construct the abelian extensions of \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n, and the theory of complex multiplication to construct abelian extensions of CM-fields. \nThere are three main generalizations of class field theory: higher class field theory, the Langlands program (or 'Langlands correspondences'), and anabelian geometry.\n\nFormulation in contemporary language\nIn modern mathematical language, class field theory (CFT) can be formulated as follows. Consider the maximal abelian extension A of a local or global field K. It is of infinite degree over K; the Galois group G of A over K is an infinite profinite group, so a compact topological group, and it is abelian. The central aims of class field theory are: to describe G in terms of certain appropriate topological objects associated to K, to describe finite abelian extensions of K in terms of open subgroups of finite index in the topological object associated to K. In particular, one wishes to establish a one-to-one correspondence between finite abelian extensions of K and their norm groups in this topological object for K. This topological object is the multiplicative group in the case of local fields with finite residue field and the idele class group in the case of global fields. The finite abelian extension corresponding to an open subgroup of finite index is called the class field for that subgroup, which gave the name to the theory.\nThe fundamental result of general class field theory states that the group G is naturally isomorphic to the profinite completion of CK, the multiplicative group of a local field or the idele class group of the global field, with respect to the natural topology on CK related",
    "links": [
      "Abelian extension",
      "Abelianization",
      "Absolute Galois group",
      "Academic Press",
      "Albrecht Fröhlich",
      "Algebraic K-theory",
      "Algebraic fundamental group",
      "Algebraic number theory",
      "American Mathematical Society",
      "Anabelian geometry",
      "Artin-Verdier duality",
      "Artin reciprocity law",
      "BSD conjecture",
      "Bernard Dwork",
      "Brauer group",
      "CM-field",
      "Chebotarev's density theorem",
      "Class formation",
      "Claude Chevalley",
      "Compact topological group",
      "Complex multiplication",
      "David Hilbert",
      "Doi (identifier)",
      "Eduard Ritter von Weber",
      "Emil Artin",
      "Ernst Kummer",
      "Field norm",
      "Frobenioid",
      "Galois extension",
      "Galois group",
      "Genus of a quadratic form",
      "Global field",
      "Goro Shimura",
      "Group cohomology",
      "Helmut Hasse",
      "Higher local field",
      "Hilbert class field",
      "History of class field theory",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "Ichiro Satake",
      "Ideal class group",
      "Idele",
      "Idele class group",
      "Ivan Fesenko",
      "Iwasawa theory",
      "J. W. S. Cassels",
      "James S. Milne",
      "John Tate (mathematician)",
      "Jürgen Neukirch"
    ],
    "categories": [
      "Category:Articles containing German-language text",
      "Category:Articles with short description",
      "Category:Class field theory",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Class number formula": {
    "title": "Class number formula",
    "url": "https://en.wikipedia.org/wiki/Class_number_formula",
    "summary": "In number theory, the class number formula relates many important invariants of an algebraic number field to a special value of its Dedekind zeta function.",
    "content": "In number theory, the class number formula relates many important invariants of an algebraic number field to a special value of its Dedekind zeta function.\n\nGeneral statement of the class number formula\nWe start with the following data:\n\nK is a number field.\n[K : Q] = n = r1 + 2r2, where r1 denotes the number of real embeddings of K, and 2r2 is the number of complex embeddings of K.\nζK(s) is the Dedekind zeta function of K.\nhK is the class number, the number of elements in the ideal class group of K.\nRegK is the regulator of K.\nwK is the number of roots of unity contained in K.\nDK is the discriminant of the extension K/Q.\nThen:\n\nTheorem (Class Number Formula). ζK(s) converges absolutely for Re(s) > 1 and extends to a meromorphic function defined for all complex s with only one simple pole at s = 1, with residue\n\n  \n    \n      \n        \n          lim\n          \n            s\n            →\n            1\n          \n        \n        (\n        s\n        −\n        1\n        )\n        \n          ζ\n          \n            K\n          \n        \n        (\n        s\n        )\n        =\n        \n          \n            \n              \n                2\n                \n                  \n                    r\n                    \n                      1\n                    \n                  \n                \n              \n              ⋅\n              (\n              2\n              π\n              \n                )\n                \n                  \n                    r\n                    \n                      2\n                    \n                  \n                \n              \n              ⋅\n              \n                Reg\n                \n                  K\n                \n              \n              ⋅\n              \n                h\n                \n                  K\n                \n              \n            \n            \n              \n                w\n                \n                  K\n                \n              \n              ⋅\n              \n                \n                  \n                    |\n                  \n                  \n                    D\n                    \n                      K\n                    \n                  \n                  \n                    |\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\lim _{s\\to 1}(s-1)\\zeta _{K}(s)={\\frac {2^{r_{1}}\\cdot (2\\pi )^{r_{2}}\\cdot \\operatorname {Reg} _{K}\\cdot h_{K}}{w_{K}\\cdot {\\sqrt {|D_{K}|}}}}}\n  \n\nThis is the most general \"class number formula\". In particular cases, for example when K is a cyclotomic extension of Q, there are particular and more refined class number formulas.\n\nProof\nThe idea of the proof of the class number formula is most easily seen when K = Q(i). In this case, the ring of integers in K is the Gaussian integers.\nAn elementary manipulation shows that the residue of the Dedekind zeta function at s = 1 is the average of the coefficients of the Dirichlet series representation of the Dedekind zeta function. The n-th coefficient of the Dirichlet series is essentially the number of representations of n as a sum of two squares of nonnegative integers. So one can compute the residue of the Dedekind zeta function at s = 1 by computing the average number of representations. As in the article on the Gauss circle problem, one can compute this by approximating the number of lattice points inside of a quarter circle centered at the origin, concluding that the residue is one quarter of pi.\nThe proof when K is an arbitrary imaginary quadratic number field is very similar.\nIn the general case, by Dirichlet's unit theorem, the group of units in the ring of integers of K is infinite. One can nevertheless reduce the computation of the residue to a lattice point counting problem using the classical theory of real and complex embeddings and approximate the number of lattice points in a region by the volume of the region, to complete the proof.\n\nDirichlet class number formula\nPeter Gustav Lejeune Dirichlet published a proof of the class number formula for quadratic fields in 1839, but it was stated in the language of quadratic forms rather than classes of ideals. It appears that Gauss already knew this formula in 1801.\nThis exposition follows Davenport.\nLet d be a fundamental discriminant, and write h(d) for the number of equivalence classes of quadratic forms with discriminant d. Let \n  \n    \n      \n        χ\n        =\n        \n          (\n          \n            \n            \n              \n                d\n                m\n              \n            \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\chi =\\left(\\!{\\frac {d}{m}}\\!\\right)}\n  \n be the Kronecker symbol. Then \n  \n    \n      \n        χ\n      \n    \n    {\\displaystyle \\chi }\n  \n is a Dirichlet character. Write \n  \n    \n      \n        L\n        (\n        s\n        ,\n        χ\n        )\n      \n    \n    {\\displaystyle L(s,\\chi )}\n  \n for the Dirichlet L-serie",
    "links": [
      "Abelian group",
      "Algebraic extension",
      "Artin L-function",
      "Artin conjecture (L-functions)",
      "Automorphic L-function",
      "Beilinson conjectures",
      "Birch and Swinnerton-Dyer conjecture",
      "Bloch–Kato conjecture (L-functions)",
      "Brumer–Stark conjecture",
      "Class field theory",
      "Conditionally convergent",
      "Conductor of an abelian extension",
      "Cyclotomic extension",
      "Cyclotomic unit",
      "Dedekind zeta function",
      "Dirichlet's unit theorem",
      "Dirichlet L-function",
      "Dirichlet L-series",
      "Dirichlet character",
      "Dirichlet series",
      "Discriminant of an algebraic number field",
      "Ernst Kummer",
      "Euler system",
      "Function (mathematics)",
      "Fundamental discriminant",
      "Fundamental unit (number theory)",
      "Galois extension",
      "Gauss circle problem",
      "Gaussian integer",
      "Generalized Riemann hypothesis",
      "Harold Davenport",
      "Hasse–Weil zeta function",
      "Hugh Montgomery (mathematician)",
      "ISBN (identifier)",
      "Ideal (ring theory)",
      "Ideal class",
      "Ideal class group",
      "Iwasawa theory",
      "Kronecker symbol",
      "Kronecker–Weber theorem",
      "L-function",
      "L-function with Grössencharakter",
      "Langlands program",
      "Lindelöf hypothesis",
      "Linear representation",
      "Main conjecture of Iwasawa theory",
      "MathOverflow",
      "Meromorphic",
      "Motivic L-function",
      "Number field"
    ],
    "categories": [
      "Category:Algebraic number theory",
      "Category:Articles with short description",
      "Category:Quadratic forms",
      "Category:Short description matches Wikidata",
      "Category:Wikipedia articles incorporating text from PlanetMath"
    ]
  },
  "Clifford algebra": {
    "title": "Clifford algebra",
    "url": "https://en.wikipedia.org/wiki/Clifford_algebra",
    "summary": "In mathematics, a Clifford algebra is an algebra generated by a vector space with a quadratic form, and is a unital associative algebra with the additional structure of a distinguished subspace. As K-algebras, they generalize the real numbers, complex numbers, quaternions and several other hypercomplex number systems. The theory of Clifford algebras is intimately connected with the theory of quadratic forms and orthogonal transformations. Clifford algebras have important applications in a variety of fields including geometry, theoretical physics and digital image processing. They are named after the English mathematician William Kingdon Clifford (1845–1879). \nThe most familiar Clifford algebras, the orthogonal Clifford algebras, are also referred to as (pseudo-)Riemannian Clifford algebras, as distinct from symplectic Clifford algebras.",
    "content": "In mathematics, a Clifford algebra is an algebra generated by a vector space with a quadratic form, and is a unital associative algebra with the additional structure of a distinguished subspace. As K-algebras, they generalize the real numbers, complex numbers, quaternions and several other hypercomplex number systems. The theory of Clifford algebras is intimately connected with the theory of quadratic forms and orthogonal transformations. Clifford algebras have important applications in a variety of fields including geometry, theoretical physics and digital image processing. They are named after the English mathematician William Kingdon Clifford (1845–1879). \nThe most familiar Clifford algebras, the orthogonal Clifford algebras, are also referred to as (pseudo-)Riemannian Clifford algebras, as distinct from symplectic Clifford algebras.\n\nIntroduction and basic properties\nA Clifford algebra is a unital associative algebra that contains and is generated by a vector space V over a field K, where V is equipped with a quadratic form Q : V → K. The Clifford algebra Cl(V, Q) is the \"freest\" unital associative algebra generated by V subject to the condition\n\n  \n    \n      \n        \n          v\n          \n            2\n          \n        \n        =\n        Q\n        (\n        v\n        )\n        1\n         \n        \n           for all \n        \n        v\n        ∈\n        V\n        ,\n      \n    \n    {\\displaystyle v^{2}=Q(v)1\\ {\\text{ for all }}v\\in V,}\n  \n\nwhere the product on the left is that of the algebra, and the 1 on the right is the algebra's multiplicative identity (not to be confused with the multiplicative identity of K).  The idea of being the \"freest\" or \"most general\" algebra subject to this identity can be formally expressed through the notion of a universal property, as done below.\nWhen V is a finite-dimensional real vector space and Q is nondegenerate, Cl(V, Q) may be identified by the label Clp,q(R), indicating that V has an orthogonal basis with p elements with ei2 = +1, q with ei2 = −1, and where R indicates that this is a Clifford algebra over the reals; i.e. coefficients of elements of the algebra are real numbers. This basis may be found by orthogonal diagonalization.\nThe free algebra generated by V may be written as the tensor algebra ⨁n≥0 V ⊗ ⋯ ⊗ V, that is, the direct sum of the tensor product of n copies of V over all n. Therefore one obtains a Clifford algebra as the quotient of this tensor algebra by the two-sided ideal generated by elements of the form v ⊗ v − Q(v)1 for all elements v ∈ V. The product induced by the tensor product in the quotient algebra is written using juxtaposition (e.g. uv).  Its associativity follows from the associativity of the tensor product.\nThe Clifford algebra has a distinguished subspace V, being the image of the embedding map. Such a subspace cannot in general be uniquely determined given only a K-algebra that is isomorphic to the Clifford algebra.\nIf 2 is invertible in the ground field K, then one can rewrite the fundamental identity above in the form\n\n  \n    \n      \n        u\n        v\n        +\n        v\n        u\n        =\n        2\n        ⟨\n        u\n        ,\n        v\n        ⟩\n        1\n         \n        \n           for all \n        \n        u\n        ,\n        v\n        ∈\n        V\n        ,\n      \n    \n    {\\displaystyle uv+vu=2\\langle u,v\\rangle 1\\ {\\text{ for all }}u,v\\in V,}\n  \n\nwhere\n\n  \n    \n      \n        ⟨\n        u\n        ,\n        v\n        ⟩\n        =\n        \n          \n            1\n            2\n          \n        \n        \n          (\n          \n            Q\n            (\n            u\n            +\n            v\n            )\n            −\n            Q\n            (\n            u\n            )\n            −\n            Q\n            (\n            v\n            )\n          \n          )\n        \n      \n    \n    {\\displaystyle \\langle u,v\\rangle ={\\frac {1}{2}}\\left(Q(u+v)-Q(u)-Q(v)\\right)}\n  \n\nis the symmetric bilinear form associated with Q, via the polarization identity.\nQuadratic forms and Clifford algebras in characteristic 2 form an exceptional case in this respect. In particular, if char(K) = 2 it is not true that a quadratic form necessarily or uniquely determines a symmetric bilinear form that satisfies Q(v) = ⟨v, v⟩, Many of the statements in this article include the condition that the characteristic is not 2, and are false if this condition is removed.\n\nAs a quantization of the exterior algebra\nClifford algebras are closely related to exterior algebras. Indeed, if Q = 0 then the Clifford algebra Cl(V, Q) is just the exterior algebra ⋀V. Whenever 2 is invertible in the ground field K, there exists a canonical linear isomorphism between ⋀V and Cl(V, Q). That is, they are naturally isomorphic as vector spaces, but with different multiplications (in the case of characteristic two, they are still isomorphic as vector spaces, just not naturally). Clifford multiplication together with the distinguished subspace is strictly riche",
    "links": [
      "*-algebra",
      "Adjoint of an operator",
      "Algebra homomorphism",
      "Algebra of physical space",
      "Algebra over a field",
      "Algebraic group",
      "Algebraic number",
      "Algebraic number field",
      "Algebraic number theory",
      "Algebraic structure",
      "Algorithm",
      "Algorithm design",
      "Alternating form",
      "American Mathematical Society",
      "Analysis of algorithms",
      "Analytical mechanics",
      "Antiautomorphism",
      "Applied mathematics",
      "Approximation theory",
      "ArXiv (identifier)",
      "Associated graded algebra",
      "Associative algebra",
      "Automata theory",
      "Automated theorem proving",
      "Automorphism",
      "Basil Hiley",
      "Basis (linear algebra)",
      "Bibcode (identifier)",
      "Bicomplex number",
      "Bilinear form",
      "Binomial coefficient",
      "Bioctonion",
      "Biquaternion",
      "Bosonic string theory",
      "Bott periodicity",
      "CCR and CAR algebras",
      "Calculus of variations",
      "Cambridge University Press",
      "Cardinal number",
      "Cartan–Dieudonné theorem",
      "Category (mathematics)",
      "Category of rings",
      "Cayley–Dickson construction",
      "Central simple algebra",
      "Chaos theory",
      "Characteristic (algebra)",
      "Classical field theory",
      "Classification of Clifford algebras",
      "Clifford analysis",
      "Clifford bundle"
    ],
    "categories": [
      "Category:All Wikipedia articles written in American English",
      "Category:All articles to be expanded",
      "Category:All articles with empty sections",
      "Category:All articles with specifically marked weasel-worded phrases",
      "Category:Articles to be expanded from April 2025",
      "Category:Articles with empty sections from April 2025",
      "Category:Articles with short description",
      "Category:Articles with specifically marked weasel-worded phrases from July 2019",
      "Category:Clifford algebras",
      "Category:Quadratic forms"
    ]
  },
  "Commutative ring": {
    "title": "Commutative ring",
    "url": "https://en.wikipedia.org/wiki/Commutative_ring",
    "summary": "In mathematics, a commutative ring is a ring in which the multiplication operation is commutative. The study of commutative rings is called commutative algebra. Complementarily, noncommutative algebra is the study of ring properties that are not specific to commutative rings. This distinction results from the high number of fundamental properties of commutative rings that do not extend to noncommutative rings.\nCommutative rings appear in the following chain of class inclusions:\n\nrngs ⊃ rings ⊃ commutative rings ⊃  integral domains ⊃ integrally closed domains ⊃ GCD domains ⊃ unique factorization domains ⊃ principal ideal domains ⊃ euclidean domains ⊃ fields ⊃ algebraically closed fields",
    "content": "In mathematics, a commutative ring is a ring in which the multiplication operation is commutative. The study of commutative rings is called commutative algebra. Complementarily, noncommutative algebra is the study of ring properties that are not specific to commutative rings. This distinction results from the high number of fundamental properties of commutative rings that do not extend to noncommutative rings.\nCommutative rings appear in the following chain of class inclusions:\n\nrngs ⊃ rings ⊃ commutative rings ⊃  integral domains ⊃ integrally closed domains ⊃ GCD domains ⊃ unique factorization domains ⊃ principal ideal domains ⊃ euclidean domains ⊃ fields ⊃ algebraically closed fields\n\nDefinition and first examples\nDefinition\nA ring is a set \n  \n    \n      \n        R\n      \n    \n    {\\displaystyle R}\n  \n equipped with two binary operations, i.e. operations combining any two elements of the ring to a third. They are called addition and multiplication and commonly denoted by \"\n  \n    \n      \n        +\n      \n    \n    {\\displaystyle +}\n  \n\" and \"\n  \n    \n      \n        ⋅\n      \n    \n    {\\displaystyle \\cdot }\n  \n\"; e.g. \n  \n    \n      \n        a\n        +\n        b\n      \n    \n    {\\displaystyle a+b}\n  \n and \n  \n    \n      \n        a\n        ⋅\n        b\n      \n    \n    {\\displaystyle a\\cdot b}\n  \n. To form a ring these two operations have to satisfy a number of properties: the ring has to be an abelian group under addition as well as a monoid under multiplication, where multiplication distributes over addition; i.e., \n  \n    \n      \n        a\n        ⋅\n        \n          (\n          \n            b\n            +\n            c\n          \n          )\n        \n        =\n        \n          (\n          \n            a\n            ⋅\n            b\n          \n          )\n        \n        +\n        \n          (\n          \n            a\n            ⋅\n            c\n          \n          )\n        \n      \n    \n    {\\displaystyle a\\cdot \\left(b+c\\right)=\\left(a\\cdot b\\right)+\\left(a\\cdot c\\right)}\n  \n. The identity elements for addition and multiplication are denoted \n  \n    \n      \n        0\n      \n    \n    {\\displaystyle 0}\n  \n and \n  \n    \n      \n        1\n      \n    \n    {\\displaystyle 1}\n  \n, respectively.\nIf the multiplication is commutative, i.e.\n\n  \n    \n      \n        a\n        ⋅\n        b\n        =\n        b\n        ⋅\n        a\n        ,\n      \n    \n    {\\displaystyle a\\cdot b=b\\cdot a,}\n  \n\nthen the ring \n  \n    \n      \n        R\n      \n    \n    {\\displaystyle R}\n  \n is called commutative. In the remainder of this article, all rings will be commutative, unless explicitly stated otherwise.\n\nFirst examples\nAn important example, and in some sense crucial, is the ring of integers \n  \n    \n      \n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} }\n  \n with the two operations of addition and multiplication. As the multiplication of integers is a commutative operation, this is a commutative ring. It is usually denoted \n  \n    \n      \n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} }\n  \n as an abbreviation of the German word Zahlen (numbers).\nA field is a commutative ring where \n  \n    \n      \n        0\n        ≠\n        1\n      \n    \n    {\\displaystyle 0\\neq 1}\n  \n and every non-zero element \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n is invertible; i.e., has a multiplicative inverse \n  \n    \n      \n        b\n      \n    \n    {\\displaystyle b}\n  \n such that \n  \n    \n      \n        a\n        ⋅\n        b\n        =\n        1\n      \n    \n    {\\displaystyle a\\cdot b=1}\n  \n. Therefore, by definition, any field is a commutative ring. The rational, real and complex numbers form fields.\nIf \n  \n    \n      \n        R\n      \n    \n    {\\displaystyle R}\n  \n is a given commutative ring, then the set of all polynomials in the variable \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n whose coefficients are in \n  \n    \n      \n        R\n      \n    \n    {\\displaystyle R}\n  \n forms the polynomial ring, denoted \n  \n    \n      \n        R\n        \n          [\n          X\n          ]\n        \n      \n    \n    {\\displaystyle R\\left[X\\right]}\n  \n. The same holds true for several variables.\nIf \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n is some topological space, for example a subset of some \n  \n    \n      \n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{n}}\n  \n, real- or complex-valued continuous functions on \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n form a commutative ring. The same is true for differentiable or holomorphic functions, when the two concepts are defined, such as for \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n a complex manifold.\n\nDivisibility\nIn contrast to fields, where every nonzero element is multiplicatively invertible, the concept of divisibility for rings is richer. An element \n  \n    \n      \n       ",
    "links": [
      "0 (number)",
      "Abelian group",
      "Affine scheme",
      "Affine space",
      "Algebra over a field",
      "Algebraic K-theory",
      "Algebraic geometry",
      "Algebraic integers",
      "Algebraic number field",
      "Algebraic number theory",
      "Algebraic structure",
      "Algebraically closed field",
      "Almost commutative ring",
      "Almost ring",
      "Annals of Mathematics",
      "ArXiv (identifier)",
      "Artin approximation theorem",
      "Artinian ring",
      "Ascending chain condition",
      "Associative algebra",
      "Banach–Stone theorem",
      "Basis (linear algebra)",
      "Betti number",
      "Bialgebra",
      "Binary operation",
      "Binomial formula",
      "Boolean algebra (structure)",
      "Boolean ring",
      "Cambridge University Press",
      "Cartesian product",
      "Category (mathematics)",
      "Category of rings",
      "Cayley–Hamilton theorem",
      "Chinese remainder theorem",
      "Clifford algebra",
      "Closed immersion",
      "Cluster algebra",
      "Cobordism",
      "Cobordism ring",
      "Cohen–Macaulay ring",
      "Cohomology ring",
      "Commutative",
      "Commutative algebra",
      "Commutator (ring theory)",
      "Compact space",
      "Complement (set theory)",
      "Complemented lattice",
      "Complete intersection ring",
      "Complete ring",
      "Complex manifold"
    ],
    "categories": [
      "Category:Algebraic structures",
      "Category:Articles with short description",
      "Category:CS1: abbreviated year range",
      "Category:Commutative algebra",
      "Category:Ring theory",
      "Category:Short description matches Wikidata",
      "Category:Wikipedia articles needing clarification from March 2012"
    ]
  },
  "Commutator (ring theory)": {
    "title": "Commutator",
    "url": "https://en.wikipedia.org/wiki/Commutator",
    "summary": "In mathematics, the commutator gives an indication of the extent to which a certain binary operation fails to be commutative. There are different definitions used in group theory and ring theory.",
    "content": "In mathematics, the commutator gives an indication of the extent to which a certain binary operation fails to be commutative. There are different definitions used in group theory and ring theory.\n\nGroup theory\nThe commutator of two elements, g and h, of a group G, is the element\n\n[g, h] = g−1h−1gh.\nThis element is equal to the group's identity if and only if g and h commute (that is, if and only if gh = hg).\nThe set of all commutators of a group is not in general closed under the group operation, but the subgroup of G generated by all commutators is closed and is called the derived group or the commutator subgroup of G. Commutators are used to define nilpotent and solvable groups and the largest abelian quotient group.\nThe definition of the commutator above is used throughout this article, but many group theorists define the commutator as\n\n[g, h] = ghg−1h−1.\nUsing the first definition, this can be expressed as [g−1, h−1].\n\nIdentities (group theory)\nCommutator identities are an important tool in group theory. The expression ax denotes the conjugate of a by x, defined as x−1ax.\n\n  \n    \n      \n        \n          x\n          \n            y\n          \n        \n        =\n        x\n        [\n        x\n        ,\n        y\n        ]\n        .\n      \n    \n    {\\displaystyle x^{y}=x[x,y].}\n  \n\n  \n    \n      \n        [\n        y\n        ,\n        x\n        ]\n        =\n        [\n        x\n        ,\n        y\n        \n          ]\n          \n            −\n            1\n          \n        \n        .\n      \n    \n    {\\displaystyle [y,x]=[x,y]^{-1}.}\n  \n\n  \n    \n      \n        [\n        x\n        ,\n        z\n        y\n        ]\n        =\n        [\n        x\n        ,\n        y\n        ]\n        ⋅\n        [\n        x\n        ,\n        z\n        \n          ]\n          \n            y\n          \n        \n      \n    \n    {\\displaystyle [x,zy]=[x,y]\\cdot [x,z]^{y}}\n  \n and \n  \n    \n      \n        [\n        x\n        z\n        ,\n        y\n        ]\n        =\n        [\n        x\n        ,\n        y\n        \n          ]\n          \n            z\n          \n        \n        ⋅\n        [\n        z\n        ,\n        y\n        ]\n        .\n      \n    \n    {\\displaystyle [xz,y]=[x,y]^{z}\\cdot [z,y].}\n  \n\n  \n    \n      \n        \n          [\n          \n            x\n            ,\n            \n              y\n              \n                −\n                1\n              \n            \n          \n          ]\n        \n        =\n        [\n        y\n        ,\n        x\n        \n          ]\n          \n            \n              y\n              \n                −\n                1\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\left[x,y^{-1}\\right]=[y,x]^{y^{-1}}}\n  \n and \n  \n    \n      \n        \n          [\n          \n            \n              x\n              \n                −\n                1\n              \n            \n            ,\n            y\n          \n          ]\n        \n        =\n        [\n        y\n        ,\n        x\n        \n          ]\n          \n            \n              x\n              \n                −\n                1\n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\left[x^{-1},y\\right]=[y,x]^{x^{-1}}.}\n  \n\n  \n    \n      \n        \n          \n            [\n            \n              \n                [\n                \n                  x\n                  ,\n                  \n                    y\n                    \n                      −\n                      1\n                    \n                  \n                \n                ]\n              \n              ,\n              z\n            \n            ]\n          \n          \n            y\n          \n        \n        ⋅\n        \n          \n            [\n            \n              \n                [\n                \n                  y\n                  ,\n                  \n                    z\n                    \n                      −\n                      1\n                    \n                  \n                \n                ]\n              \n              ,\n              x\n            \n            ]\n          \n          \n            z\n          \n        \n        ⋅\n        \n          \n            [\n            \n              \n                [\n                \n                  z\n                  ,\n                  \n                    x\n                    \n                      −\n                      1\n                    \n                  \n                \n                ]\n              \n              ,\n              y\n            \n            ]\n          \n          \n            x\n          \n        \n        =\n        1\n      \n    \n    {\\displaystyle \\left[\\left[x,y^{-1}\\right],z\\right]^{y}\\cdot \\left[\\left[y,z^{-1}\\right],x\\right]^{z}\\cdot \\left[\\left[z,x^{-1}\\right],y\\right]^{x}=1}\n  \n and \n  \n    \n      \n        \n          [\n          \n            \n              [\n              \n                x\n                ,\n                y\n              \n              ]\n            \n  ",
    "links": [
      "Abelian group",
      "Addison-Wesley",
      "Adjoint representation of a Lie algebra",
      "Anticommutativity",
      "ArXiv (identifier)",
      "Associative algebra",
      "Associator",
      "Baker–Campbell–Hausdorff formula",
      "Banach algebra",
      "Bibcode (identifier)",
      "Bilinear map",
      "Binary operation",
      "Canonical commutation relation",
      "Centralizer",
      "Clifford algebra",
      "Commutation (disambiguation)",
      "Commutative",
      "Commutator (electric)",
      "Commutator subgroup",
      "Conjugate (group theory)",
      "Conjugate variables",
      "David J. Griffiths",
      "Derivation (abstract algebra)",
      "Derivation (differential algebra)",
      "Derived subgroup",
      "Dirac equation",
      "Doi (identifier)",
      "Encyclopedia of Mathematics",
      "Endomorphism",
      "Ernst Witt",
      "European Mathematical Society",
      "Exponential function",
      "Formal power series",
      "General Leibniz rule",
      "Generating set of a group",
      "Graded algebra",
      "Group (mathematics)",
      "Group theory",
      "Hadamard's lemma",
      "Hilbert space",
      "ISBN (identifier)",
      "Israel Nathan Herstein",
      "Jacobi identity",
      "Jordan algebra",
      "Lie algebra",
      "Lie group",
      "Linear algebra",
      "MR (identifier)",
      "Mathematics",
      "McGraw Hill"
    ],
    "categories": [
      "Category:Abstract algebra",
      "Category:Articles with short description",
      "Category:Binary operations",
      "Category:Group theory",
      "Category:Mathematical identities",
      "Category:Short description is different from Wikidata",
      "Category:Use shortened footnotes from November 2022"
    ]
  },
  "Complete field": {
    "title": "Complete field",
    "url": "https://en.wikipedia.org/wiki/Complete_field",
    "summary": "In mathematics, a complete field is a field equipped with a metric and complete with respect to that metric. A field supports the elementary operations of addition, subtraction, multiplication, and division, while a metric represents the distance between two points in the set. Basic examples include the real numbers, the complex numbers, and complete valued fields (such as the p-adic numbers).",
    "content": "In mathematics, a complete field is a field equipped with a metric and complete with respect to that metric. A field supports the elementary operations of addition, subtraction, multiplication, and division, while a metric represents the distance between two points in the set. Basic examples include the real numbers, the complex numbers, and complete valued fields (such as the p-adic numbers).\n\nDefinitions\nField\nA field is a set \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n with binary operations \n  \n    \n      \n        +\n      \n    \n    {\\displaystyle +}\n  \n and \n  \n    \n      \n        ⋅\n      \n    \n    {\\displaystyle \\cdot }\n  \n (called addition and multiplication, respectively), along with elements \n  \n    \n      \n        0\n      \n    \n    {\\displaystyle 0}\n  \n and \n  \n    \n      \n        1\n      \n    \n    {\\displaystyle 1}\n  \n such that for all \n  \n    \n      \n        a\n        ,\n        b\n        ,\n        c\n        ∈\n        F\n      \n    \n    {\\displaystyle a,b,c\\in F}\n  \n, the following relations hold:\n\n  \n    \n      \n        a\n        +\n        (\n        b\n        +\n        c\n        )\n        =\n        (\n        a\n        +\n        b\n        )\n        +\n        c\n      \n    \n    {\\displaystyle a+(b+c)=(a+b)+c}\n  \n\n  \n    \n      \n        a\n        +\n        b\n        =\n        b\n        +\n        a\n      \n    \n    {\\displaystyle a+b=b+a}\n  \n\n  \n    \n      \n        a\n        +\n        0\n        =\n        a\n        =\n        0\n        +\n        a\n      \n    \n    {\\displaystyle a+0=a=0+a}\n  \n\n  \n    \n      \n        a\n        +\n        x\n        =\n        0\n      \n    \n    {\\displaystyle a+x=0}\n  \n has a solution\n\n  \n    \n      \n        a\n        (\n        b\n        c\n        )\n        =\n        (\n        a\n        b\n        )\n        c\n      \n    \n    {\\displaystyle a(bc)=(ab)c}\n  \n\n  \n    \n      \n        a\n        b\n        =\n        b\n        a\n      \n    \n    {\\displaystyle ab=ba}\n  \n\n  \n    \n      \n        a\n        (\n        b\n        +\n        c\n        )\n        =\n        a\n        b\n        +\n        a\n        c\n      \n    \n    {\\displaystyle a(b+c)=ab+ac}\n  \n and \n  \n    \n      \n        (\n        a\n        +\n        b\n        )\n        c\n        =\n        a\n        c\n        +\n        b\n        c\n      \n    \n    {\\displaystyle (a+b)c=ac+bc}\n  \n\n  \n    \n      \n        a\n        1\n        =\n        a\n        =\n        1\n        a\n      \n    \n    {\\displaystyle a1=a=1a}\n  \n\n  \n    \n      \n        a\n        x\n        =\n        1\n      \n    \n    {\\displaystyle ax=1}\n  \n has a solution for \n  \n    \n      \n        a\n        ≠\n        0\n      \n    \n    {\\displaystyle a\\neq 0}\n\nComplete metric\nA metric on a set \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n is a function \n  \n    \n      \n        d\n        :\n        \n          F\n          \n            2\n          \n        \n        →\n        [\n        0\n        ,\n        ∞\n        )\n      \n    \n    {\\displaystyle d:F^{2}\\to [0,\\infty )}\n  \n, that is, it takes two points in \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n and sends them to a non-negative real number, such that the following relations hold for all \n  \n    \n      \n        x\n        ,\n        y\n        ,\n        z\n        ∈\n        F\n      \n    \n    {\\displaystyle x,y,z\\in F}\n  \n:\n\n  \n    \n      \n        d\n        (\n        x\n        ,\n        y\n        )\n        =\n        0\n      \n    \n    {\\displaystyle d(x,y)=0}\n  \n if and only if \n  \n    \n      \n        x\n        =\n        y\n      \n    \n    {\\displaystyle x=y}\n  \n\n  \n    \n      \n        d\n        (\n        x\n        ,\n        y\n        )\n        =\n        d\n        (\n        y\n        ,\n        x\n        )\n      \n    \n    {\\displaystyle d(x,y)=d(y,x)}\n  \n\n  \n    \n      \n        d\n        (\n        x\n        ,\n        y\n        )\n        ≤\n        d\n        (\n        x\n        ,\n        z\n        )\n        +\n        d\n        (\n        z\n        ,\n        y\n        )\n      \n    \n    {\\displaystyle d(x,y)\\leq d(x,z)+d(z,y)}\n  \n\nA sequence \n  \n    \n      \n        \n          x\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle x_{n}}\n  \n in the space is Cauchy with respect to this metric if for all \n  \n    \n      \n        ϵ\n        >\n        0\n      \n    \n    {\\displaystyle \\epsilon >0}\n  \n there exists an \n  \n    \n      \n        N\n        ∈\n        \n          N\n        \n      \n    \n    {\\displaystyle N\\in \\mathbb {N} }\n  \n such that for all \n  \n    \n      \n        n\n        ,\n        m\n        ≥\n        N\n      \n    \n    {\\displaystyle n,m\\geq N}\n  \n we have \n  \n    \n      \n        d\n        (\n        \n          x\n          \n            n\n          \n        \n        ,\n        \n          x\n          \n            m\n          \n        \n        )\n        <\n        ϵ\n      \n    \n    {\\displaystyle d(x_{n},x_{m})<\\epsilon }\n  \n, and a metric is then complete if every Cauchy sequence in the metric space converges, that is, there is some \n  \n    \n      \n        x\n        ∈\n  ",
    "links": [
      "Addition",
      "Binary operations",
      "Cauchy sequence",
      "Compact group",
      "Complete metric space",
      "Complete topological vector space",
      "Complete valued field",
      "Completion (algebra)",
      "Complex number",
      "Convergent sequence",
      "Distance",
      "Division (mathematics)",
      "Element (mathematics)",
      "Field (mathematics)",
      "Function (mathematics)",
      "Hensel's lemma",
      "Henselian ring",
      "ISBN (identifier)",
      "If and only if",
      "Imaginary number",
      "Locally compact field",
      "Locally compact group",
      "Locally compact quantum group",
      "Mathematics",
      "Metric (mathematics)",
      "Metric space",
      "Multiplication",
      "Non-negative",
      "OCLC (identifier)",
      "Ordered topological vector space",
      "Ostrowski's theorem",
      "P-adic numbers",
      "Real number",
      "Sequence",
      "Set (mathematics)",
      "Subtraction",
      "Topological abelian group",
      "Topological field",
      "Topological group",
      "Topological module",
      "Topological ring",
      "Topological semigroup",
      "Topological vector space"
    ],
    "categories": [
      "Category:Field (mathematics)",
      "Category:Pages displaying short descriptions of redirect targets via Module:Annotated link"
    ]
  },
  "Arithmetica": {
    "title": "Diophantus",
    "url": "https://en.wikipedia.org/wiki/Diophantus",
    "summary": "Diophantus of Alexandria (Ancient Greek: Διόφαντος, romanized: Diophantos) (; fl. 250 CE) was a Greek mathematician who was the author of the Arithmetica in thirteen books, ten of which are still extant, made up of arithmetical problems that are solved through algebraic equations. \nAlthough Joseph-Louis Lagrange called Diophantus \"the inventor of algebra\" he did not invent it; however, his exposition became the standard within the Neoplatonic schools of Late antiquity, and its translation into Arabic in the 9th century AD and had influence in the development of later algebra: Diophantus' method of solution matches medieval Arabic algebra in its concepts and overall procedure. The 1621 edition of Arithmetica by Bachet gained fame after Pierre de Fermat wrote his famous \"Last Theorem\" in the margins of his copy.\nIn modern use, Diophantine equations are algebraic equations with integer coefficients for which integer solutions are sought. Diophantine geometry and Diophantine approximations",
    "content": "Diophantus of Alexandria (Ancient Greek: Διόφαντος, romanized: Diophantos) (; fl. 250 CE) was a Greek mathematician who was the author of the Arithmetica in thirteen books, ten of which are still extant, made up of arithmetical problems that are solved through algebraic equations. \nAlthough Joseph-Louis Lagrange called Diophantus \"the inventor of algebra\" he did not invent it; however, his exposition became the standard within the Neoplatonic schools of Late antiquity, and its translation into Arabic in the 9th century AD and had influence in the development of later algebra: Diophantus' method of solution matches medieval Arabic algebra in its concepts and overall procedure. The 1621 edition of Arithmetica by Bachet gained fame after Pierre de Fermat wrote his famous \"Last Theorem\" in the margins of his copy.\nIn modern use, Diophantine equations are algebraic equations with integer coefficients for which integer solutions are sought. Diophantine geometry and Diophantine approximations are two other subareas of number theory that are named after him. Some problems from the Arithmetica have inspired modern work in both abstract algebra and number theory.\n\nBiography\nThe exact details of Diophantus' life are obscure. Although he probably flourished in the third century CE, he may have lived anywhere between 170 BCE, roughly contemporaneous with Hypsicles, the latest author he quotes from, and 350 CE, when Theon of Alexandria quotes from him. Paul Tannery suggested that a reference to an \"Anatolius\" as a student of Diophantus in the works of Michael Psellos may refer to the early Christian bishop Anatolius of Alexandria, who may possibly the same Anatolius mentioned by Eunapius as a teacher of the pagan Neopythagorean philosopher Iamblichus, either of which would place him in the 3rd century CE.\n\nThe only definitive piece of information about his life is derived from a set of mathematical puzzles attributed to the 5th or 6th century CE grammarian Metrodorus preserved in book 14 of the Greek Anthology. One of the problems (sometimes called Diophantus' epitaph) states:Here lies Diophantus, the wonder behold. Through art algebraic, the stone tells how old: 'God gave him his boyhood one-sixth of his life, One twelfth more as youth while whiskers grew rife; And then yet one-seventh ere marriage begun; In five years there came a bouncing new son. Alas, the dear child of master and sage After attaining half the measure of his father's life chill fate took him. After consoling his fate by the science of numbers for four years, he ended his life.'This puzzle implies that Diophantus' age x can be expressed as\nx = ⁠x/6⁠ + ⁠x/12⁠ + ⁠x/7⁠ + 5 + ⁠x/2⁠ + 4\nwhich gives x a value of 84 years. However, the accuracy of the information cannot be confirmed.\n\nArithmetica\nArithmetica is the major work of Diophantus and the most prominent work on premodern algebra in Greek mathematics. It is a collection of 290 algebraic problems giving numerical solutions of determinate equations (those with a unique solution) and indeterminate equations. Arithmetica was originally written in thirteen books, but only six of them survive in Greek, while another four books survive in Arabic, which were discovered in 1968. The books in Arabic correspond to books 4 to 7 of the original treatise, while the Greek books correspond to books 1 to 3 and 8 to 10.\nArithmetica is the earliest extant work present that solve arithmetic problems by algebra. Diophantus however did not invent the method of algebra, which existed before him. Algebra was practiced and diffused orally by practitioners, with Diophantus picking up technique to solve problems in arithmetic.\nEquations in the book are presently called Diophantine equations. The method for solving these equations is known as Diophantine analysis.  Most of the Arithmetica problems lead to quadratic equations.\n\nNotation\nDiophantus introduced an algebraic symbolism that used an abridged notation for frequently occurring operations, and an abbreviation for the unknown and for the powers of the unknown. \nSimilar to medieval Arabic algebra, Diophantus uses three stages to solution of a problem by algebra:\n\nAn unknown is named and an equation is set up\nAn equation is simplified to a standard form (al-jabr and al-muqābala in Arabic)\nSimplified equation is solved\nDiophantus does not give classification of equations in six types like Al-Khwarizmi in extant parts of Arithmetica. He does says that he would give solution to three terms equations later, so this part of work is possibly just lost.\nThe main difference between Diophantine notation and modern algebraic notation is that the former lacked special symbols for operations, relations, and exponentials. So for example, what would be written in modern notation as\n\n  \n    \n      \n        \n          x\n          \n            3\n          \n        \n        −\n        2\n        \n          x\n          \n            2\n          \n        \n        +\n        10\n        x\n        −\n",
    "links": [
      "A History of Greek Mathematics",
      "Abstract algebra",
      "Adequality",
      "Al-Khwarizmi",
      "Alexandria",
      "Algebra",
      "Algebraic equation",
      "Almagest",
      "Alpha",
      "Anatolius of Alexandria",
      "Anaxagoras",
      "Ancient Egyptian mathematics",
      "Ancient Greek astronomy",
      "Ancient Greek language",
      "Ancient Greek mathematics",
      "Andrew Wiles",
      "Angle bisector theorem",
      "Angle trisection",
      "Anthemius of Tralles",
      "Apollonian circles",
      "Apollonian gasket",
      "Apollonius's theorem",
      "Apollonius of Perga",
      "ArXiv (identifier)",
      "Archaic Greek alphabets",
      "Archimedes",
      "Archimedes Palimpsest",
      "Archytas",
      "Aristaeus the Elder",
      "Aristarchus's inequality",
      "Aristarchus of Samos",
      "Arithmetic",
      "Arithmetica",
      "Astronomy",
      "Attic numerals",
      "Autolycus of Pitane",
      "Babylonian mathematics",
      "Bachet",
      "Beta",
      "Bibcode (identifier)",
      "Bion of Abdera",
      "Bryson of Heraclea",
      "Callippus",
      "Carpus of Antioch",
      "Catoptrics",
      "Central Library of Astan Quds Razavi",
      "Chinese mathematics",
      "Chora Monastery",
      "Chord (geometry)",
      "Chrysippus"
    ],
    "categories": [
      "Category:3rd-century Egyptian people",
      "Category:3rd-century Greek writers",
      "Category:3rd-century births",
      "Category:3rd-century deaths",
      "Category:3rd-century mathematicians",
      "Category:3rd-century writers",
      "Category:Ancient Greek mathematicians",
      "Category:Articles containing Ancient Greek (to 1453)-language text",
      "Category:Articles with hCards",
      "Category:Articles with short description"
    ]
  },
  "An algebra": {
    "title": "Algebra over a field",
    "url": "https://en.wikipedia.org/wiki/Algebra_over_a_field",
    "summary": "In mathematics, an algebra over a field (often simply called an algebra) is a vector space equipped with a bilinear product. Thus, an algebra is an algebraic structure consisting of a set together with operations of multiplication and addition and scalar multiplication by elements of a field and satisfying the axioms implied by \"vector space\" and \"bilinear\".\nThe multiplication operation in an algebra may or may not be associative, leading to the notions of associative algebras where associativity of multiplication is assumed, and non-associative algebras, where associativity is not assumed (but not excluded, either). Given an integer n, the ring of real square matrices of order n is an example of an associative algebra over the field of real numbers under matrix addition and matrix multiplication since matrix multiplication is associative. Three-dimensional Euclidean space with multiplication given by the vector cross product is an example of a nonassociative algebra over the field of ",
    "content": "In mathematics, an algebra over a field (often simply called an algebra) is a vector space equipped with a bilinear product. Thus, an algebra is an algebraic structure consisting of a set together with operations of multiplication and addition and scalar multiplication by elements of a field and satisfying the axioms implied by \"vector space\" and \"bilinear\".\nThe multiplication operation in an algebra may or may not be associative, leading to the notions of associative algebras where associativity of multiplication is assumed, and non-associative algebras, where associativity is not assumed (but not excluded, either). Given an integer n, the ring of real square matrices of order n is an example of an associative algebra over the field of real numbers under matrix addition and matrix multiplication since matrix multiplication is associative. Three-dimensional Euclidean space with multiplication given by the vector cross product is an example of a nonassociative algebra over the field of real numbers since the vector cross product is nonassociative, satisfying the Jacobi identity instead.\nAn algebra is unital or unitary if it has an identity element with respect to the multiplication. The ring of real square matrices of order n forms a unital algebra since the identity matrix of order n is the identity element with respect to matrix multiplication. It is an example of a unital associative algebra, a (unital) ring that is also a vector space.\nMany authors use the term algebra to mean associative algebra, or unital associative algebra, or in  some subjects such as algebraic geometry, unital associative commutative algebra.\nReplacing the field of scalars by a commutative ring leads to the more general notion of an algebra over a ring. Algebras are not to be confused with vector spaces equipped with a bilinear form, like inner product spaces, as, for such a space, the result of a product is not in the space, but rather in the field of coefficients.\n\nDefinition and motivation\nMotivating examples\nDefinition\nLet K be a field, and let A be a vector space over K equipped with an additional binary operation from A × A to A, denoted here by · (that is, if x and y are any two elements of A, then x · y is an element of A that is called the product of x and y).  Then A is an algebra over K if the following identities hold for all elements x, y, z in A , and all elements (often called scalars) a and b in K:\n\nRight distributivity: (x + y) · z = x · z + y · z\nLeft distributivity: z · (x + y) = z · x + z · y\nCompatibility with scalars: (ax) · (by) = (ab) (x · y).\nThese three axioms are another way of saying that the binary operation is bilinear. An algebra over K is sometimes also called a K-algebra, and K is called the base field of A. The binary operation is often referred to as multiplication in A. The convention adopted in this article is that multiplication of elements of an algebra is not necessarily associative, although some authors use the term algebra to refer to an associative algebra.\nWhen a binary operation on a vector space is commutative, left distributivity and right distributivity are equivalent, and, in this case, only one distributivity requires a proof. In general, for non-commutative operations left distributivity and right distributivity are not equivalent, and require separate proofs.\n\nBasic concepts\nAlgebra homomorphisms\nGiven K-algebras A and B, a homomorphism of K-algebras or K-algebra homomorphism is a K-linear map f: A → B such that f(xy) = f(x) f(y) for all x, y in A. If A and B are unital, then a homomorphism satisfying f(1A) = 1B is said to be a unital homomorphism. The space of all K-algebra homomorphisms between A and B is frequently written as\n\n  \n    \n      \n        \n          \n            H\n            o\n            m\n          \n          \n            K\n            \n              -alg\n            \n          \n        \n        (\n        A\n        ,\n        B\n        )\n        .\n      \n    \n    {\\displaystyle \\mathbf {Hom} _{K{\\text{-alg}}}(A,B).}\n  \n\nA K-algebra isomorphism is a bijective K-algebra homomorphism.\n\nSubalgebras and ideals\nA subalgebra of an algebra over a field K is a linear subspace that has the property that the product of any two of its elements is again in the subspace. In other words, a subalgebra of an algebra is a non-empty subset of elements that is closed under addition, multiplication, and scalar multiplication. In symbols, we say that a subset L of a K-algebra A is a subalgebra if for every x, y in L and c in K, we have that x · y, x + y, and cx are all in L.\nIn the above example of the complex numbers viewed as a two-dimensional algebra over the real numbers, the one-dimensional real line is a subalgebra.\nA left ideal of a K-algebra is a linear subspace that has the property that any element of the subspace multiplied on the left by any element of the algebra produces an element of the subspace. In symbols, we say that a subset L of a K-algebra A is a left ideal if for",
    "links": [
      "Abelian group",
      "Algebra over an operad",
      "Algebraic geometry",
      "Algebraic structure",
      "Alternative algebra",
      "Anticommutative property",
      "Associative",
      "Associative algebra",
      "Associativity",
      "B*-algebra",
      "Banach algebra",
      "Banach space",
      "Basis (linear algebra)",
      "Bialgebra",
      "Bijective",
      "Bilinear form",
      "Bilinear map",
      "Bilinear operation",
      "Bilinear operator",
      "Binary operation",
      "Boolean algebra (structure)",
      "Bruno Buchberger",
      "C*-algebra",
      "Center (ring theory)",
      "Clifford algebra",
      "Commutative",
      "Commutative algebra",
      "Commutative ring",
      "Commutativity",
      "Complemented lattice",
      "Complex number",
      "Complex plane",
      "Composition algebra",
      "Continuous function",
      "Covariance and contravariance of vectors",
      "Cross product",
      "Differential algebra",
      "Dimension (linear algebra)",
      "Direct sum",
      "Distributivity",
      "Division ring",
      "Doi (identifier)",
      "Domain (ring theory)",
      "Dual number",
      "Eduard Study",
      "Einstein notation",
      "Euclidean space",
      "Extension of scalars",
      "Field (mathematics)",
      "Field extension"
    ],
    "categories": [
      "Category:Algebras",
      "Category:Articles with short description",
      "Category:Short description matches Wikidata",
      "Category:Wikipedia articles needing page number citations from November 2024"
    ]
  },
  "Algebraic category": {
    "title": "Variety (universal algebra)",
    "url": "https://en.wikipedia.org/wiki/Variety_(universal_algebra)",
    "summary": "In universal algebra, a variety of algebras or equational class is the class of all algebraic structures of a given signature satisfying a given set of identities. For example, the groups form a variety of algebras, as do the abelian groups, the rings, the monoids etc. According to Birkhoff's theorem, a class of algebraic structures of the same signature is a variety if and only if it is closed under the taking of homomorphic images, subalgebras, and (direct) products. In the context of category theory, a variety of algebras, together with its homomorphisms, forms a category; these are usually called finitary algebraic categories.\nA covariety is the class of all coalgebraic structures of a given signature.",
    "content": "In universal algebra, a variety of algebras or equational class is the class of all algebraic structures of a given signature satisfying a given set of identities. For example, the groups form a variety of algebras, as do the abelian groups, the rings, the monoids etc. According to Birkhoff's theorem, a class of algebraic structures of the same signature is a variety if and only if it is closed under the taking of homomorphic images, subalgebras, and (direct) products. In the context of category theory, a variety of algebras, together with its homomorphisms, forms a category; these are usually called finitary algebraic categories.\nA covariety is the class of all coalgebraic structures of a given signature.\n\nTerminology\nA variety of algebras should not be confused with an algebraic variety, which means a set of solutions to a system of polynomial equations. They are formally quite distinct and their theories have little in common.\nThe term \"variety of algebras\" refers to algebras in the general sense of universal algebra; there is also a more specific sense of algebra, namely as algebra over a field, i.e. a vector space equipped with a bilinear multiplication.\n\nDefinition\nA signature (in this context) is a set, whose elements are called operations, each of which is assigned a natural number (0, 1, 2, ...) called its arity.  Given a signature σ and a set V, whose elements are called variables, a word is a finite rooted tree in which each node is labelled by either a variable or an operation, such that every node labelled by a variable has no branches away from the root and every node labelled by an operation o has as many branches away from the root as the arity of o.  An equational law is a pair of such words; the axiom consisting of the words v and w is written as v = w.\nA theory consists of a signature, a set of variables, and a set of equational laws. Any theory gives a variety of algebras as follows.  Given a theory T, an algebra of T consists of a set A together with, for each operation o of T with arity n, a function oA : An → A such that for each axiom v = w and each assignment of elements of A to the variables in that axiom, the equation holds that is given by applying the operations to the elements of A as indicated by the trees defining v and w. The class of algebras of a given theory T is called a variety of algebras.\nGiven two algebras of a theory T, say A and B, a homomorphism is a function f : A → B such that\n\n  \n    \n      \n        f\n        (\n        \n          o\n          \n            A\n          \n        \n        (\n        \n          a\n          \n            1\n          \n        \n        ,\n        …\n        ,\n        \n          a\n          \n            n\n          \n        \n        )\n        )\n        =\n        \n          o\n          \n            B\n          \n        \n        (\n        f\n        (\n        \n          a\n          \n            1\n          \n        \n        )\n        ,\n        …\n        ,\n        f\n        (\n        \n          a\n          \n            n\n          \n        \n        )\n        )\n      \n    \n    {\\displaystyle f(o_{A}(a_{1},\\dots ,a_{n}))=o_{B}(f(a_{1}),\\dots ,f(a_{n}))}\n  \n\nfor every operation o of arity n. Any theory gives a category where the objects are algebras of that theory and the morphisms are homomorphisms.\n\nExamples\nThe class of all semigroups forms a variety of algebras of signature (2), meaning that a semigroup has a single binary operation. A sufficient defining equation is the associative law:\n\n  \n    \n      \n        x\n        (\n        y\n        z\n        )\n        =\n        (\n        x\n        y\n        )\n        z\n        .\n      \n    \n    {\\displaystyle x(yz)=(xy)z.}\n  \n\nThe class of groups forms a variety of algebras of signature (2,0,1), the three operations being respectively multiplication (binary), identity (nullary, a constant) and inversion (unary). The familiar axioms of associativity,  identity and inverse form one suitable set of identities:\n\n  \n    \n      \n        x\n        (\n        y\n        z\n        )\n        =\n        (\n        x\n        y\n        )\n        z\n      \n    \n    {\\displaystyle x(yz)=(xy)z}\n  \n\n  \n    \n      \n        1\n        x\n        =\n        x\n        1\n        =\n        x\n      \n    \n    {\\displaystyle 1x=x1=x}\n  \n\n  \n    \n      \n        x\n        \n          x\n          \n            −\n            1\n          \n        \n        =\n        \n          x\n          \n            −\n            1\n          \n        \n        x\n        =\n        1.\n      \n    \n    {\\displaystyle xx^{-1}=x^{-1}x=1.}\n  \n\nThe class of rings also forms a variety of algebras. The signature here is (2,2,0,0,1) (two binary operations, two constants, and one unary operation).\nIf we fix a specific ring R, we can consider the class of left R-modules. To express the scalar multiplication with elements from R, we need one unary operation for each element of R. If the ring is infinite, we will thus have infinitely many operations, which is allowed by the",
    "links": [
      "Abelian group",
      "Algebra Universalis",
      "Algebra over a field",
      "Algebraic structure",
      "Algebraic variety",
      "Bibcode (identifier)",
      "Bilinear map",
      "Cancellative semigroup",
      "Category (mathematics)",
      "Category theory",
      "Class (set theory)",
      "Colimits",
      "Converse (logic)",
      "Direct product",
      "Doi (identifier)",
      "Eilenberg's theorem",
      "Eilenberg–Moore category",
      "F-coalgebra",
      "Field (mathematics)",
      "Finitely generated abelian group",
      "Forgetful functor",
      "Formal language",
      "Free abelian group",
      "Free algebra",
      "Free group",
      "Free module",
      "Full subcategory",
      "Garrett Birkhoff",
      "Group (mathematics)",
      "Homomorphism",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "Lawvere theories",
      "Left adjoint",
      "Locally presentable category",
      "Mathematical Proceedings of the Cambridge Philosophical Society",
      "Mathematical identity",
      "Module (mathematics)",
      "Monad (category theory)",
      "Monoid",
      "Natural number",
      "Profinite word",
      "Quasiidentity",
      "Quasivariety",
      "Regular language",
      "Ring (mathematics)",
      "Rooted tree",
      "S2CID (identifier)",
      "Semigroup",
      "Sigma algebra"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Short description is different from Wikidata",
      "Category:Universal algebra"
    ]
  },
  "Archimedean group": {
    "title": "Archimedean group",
    "url": "https://en.wikipedia.org/wiki/Archimedean_group",
    "summary": "In abstract algebra, a branch of mathematics, an Archimedean group is a linearly ordered group for which the Archimedean property holds: every two positive group elements are bounded by integer multiples of each other. The set R of real numbers together with the operation of addition and the usual ordering relation between pairs of numbers is an Archimedean group. By a result of Otto Hölder, every Archimedean group is isomorphic to a subgroup of this group. The name \"Archimedean\" comes from Otto Stolz, who named the Archimedean property after its appearance in the works of Archimedes.",
    "content": "In abstract algebra, a branch of mathematics, an Archimedean group is a linearly ordered group for which the Archimedean property holds: every two positive group elements are bounded by integer multiples of each other. The set R of real numbers together with the operation of addition and the usual ordering relation between pairs of numbers is an Archimedean group. By a result of Otto Hölder, every Archimedean group is isomorphic to a subgroup of this group. The name \"Archimedean\" comes from Otto Stolz, who named the Archimedean property after its appearance in the works of Archimedes.\n\nDefinition\nAn additive group consists of a set of elements, an associative addition operation that combines pairs of elements and returns a single element,\nan identity element (or zero element) whose sum with any other element is the other element, and an additive inverse operation such that the sum of any element and its inverse is zero.\nA group is a linearly ordered group when, in addition, its elements can be linearly ordered in a way that is compatible with the group operation: for all elements x, y, and z, if x ≤ y then x + z ≤ y + z and z + x ≤ z + y.\nThe notation na (where n is a natural number) stands for the group sum of n copies of a.\nAn Archimedean group (G, +, ≤) is a linearly ordered group subject to the following additional condition, the Archimedean property: For every a and b in G which are greater than 0, it is possible to find a natural number n for which the inequality b ≤ na holds.\nAn equivalent definition is that an Archimedean group is a linearly ordered group without any bounded cyclic subgroups: there does not exist a cyclic subgroup S and an element x  with x greater than all elements in S. It is straightforward to see that this is equivalent to the other definition: the Archimedean property for a pair of elements a and b is just the statement that the cyclic subgroup generated by a is not bounded by b.\n\nExamples of Archimedean groups\nThe sets of the integers, the rational numbers, and the real numbers, together with the operation of addition and the usual ordering (≤), are Archimedean groups. Every subgroup of an Archimedean group is itself Archimedean, so it follows that every subgroup of these groups, such as the additive group of the even numbers or of the dyadic rationals, also forms an Archimedean group.\nConversely, as Otto Hölder showed, every Archimedean group is isomorphic (as an ordered group) to a subgroup of the real numbers. It follows from this that every Archimedean group is necessarily an abelian group: its addition operation must be commutative.\n\nExamples of non-Archimedean groups\nGroups that cannot be linearly ordered, such as the finite groups, are not Archimedean. For another example, see the p-adic numbers, a system of numbers generalizing the rational numbers in a different way to the real numbers.\nNon-Archimedean ordered groups also exist; the ordered group (G, +, ≤) defined as follows is not Archimedean. Let the elements of G be the points of the Euclidean plane, given by their Cartesian coordinates: pairs  (x, y) of real numbers. Let the group addition operation be pointwise (vector) addition, and order these points in lexicographic order: if a = (u, v) and b = (x, y), then a + b = (u + x, v + y), and\na ≤ b exactly when either v < y or v = y and u ≤ x. Then this gives an ordered group, but one that is not Archimedean. To see this, consider the elements (1, 0) and (0, 1), both of which are greater than the zero element of the group (the origin). For every natural number n, it follows from these definitions that n (1, 0) = (n, 0) < (0, 1), so there is no n that satisfies the Archimedean property. This group can be thought of as the additive group of pairs of a real number and an infinitesimal, \n  \n    \n      \n        (\n        x\n        ,\n        y\n        )\n        =\n        x\n        ϵ\n        +\n        y\n        ,\n      \n    \n    {\\displaystyle (x,y)=x\\epsilon +y,}\n  \n where \n  \n    \n      \n        ϵ\n      \n    \n    {\\displaystyle \\epsilon }\n  \n is a unit infinitesimal: \n  \n    \n      \n        ϵ\n        >\n        0\n      \n    \n    {\\displaystyle \\epsilon >0}\n  \n but \n  \n    \n      \n        ϵ\n        <\n        y\n      \n    \n    {\\displaystyle \\epsilon <y}\n  \n for any positive real number \n  \n    \n      \n        y\n        >\n        0\n      \n    \n    {\\displaystyle y>0}\n  \n. Non-Archimedean ordered fields can be defined similarly, and their additive groups are non-Archimedean ordered groups. These are used in non-standard analysis, and include the hyperreal numbers and surreal numbers.\nWhile non-Archimedean ordered groups cannot be embedded in the real numbers, they can be embedded in a power of the real numbers, with lexicographic order, by the Hahn embedding theorem; the example above is the 2-dimensional case.\n\nAdditional properties\nEvery Archimedean group has the property that, for every Dedekind cut of the group, and every group element ε > 0, there exists another group ele",
    "links": [
      "Abelian group",
      "Abstract algebra",
      "American Mathematical Society",
      "Archimedean equivalence",
      "Archimedean property",
      "Archimedes",
      "Associativity",
      "Binary operation",
      "Cartesian coordinate",
      "Commutative monoid",
      "Commutative property",
      "Converse (logic)",
      "Cyclic group",
      "Dedekind cut",
      "Doi (identifier)",
      "Dyadic rational",
      "Embedding",
      "Euclidean plane",
      "Even number",
      "Finite group",
      "Group (mathematics)",
      "Group isomorphism",
      "Hahn embedding theorem",
      "Hyperreal number",
      "ISBN (identifier)",
      "Identity element",
      "Infinitesimal",
      "Integer",
      "Inverse element",
      "Isomorphic",
      "Lexicographic order",
      "Linear order",
      "Linearly ordered group",
      "MR (identifier)",
      "Mathematical proof",
      "Mathematics",
      "Monoid",
      "Natural number",
      "Non-Archimedean ordered field",
      "Non-standard analysis",
      "Operation (mathematics)",
      "Origin (mathematics)",
      "Otto Hölder",
      "Otto Stolz",
      "P-adic number",
      "Paulo Ribenboim",
      "Pointwise",
      "Rational number",
      "Real number",
      "Subgroup"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1 Russian-language sources (ru)",
      "Category:Ordered groups",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Bialgebra": {
    "title": "Bialgebra",
    "url": "https://en.wikipedia.org/wiki/Bialgebra",
    "summary": "In mathematics, a bialgebra over a field K is a vector space over K which is both a unital associative algebra and a counital coassociative coalgebra.  The algebraic and coalgebraic structures are made compatible with a few more axioms. Specifically, the comultiplication and the counit are both unital algebra homomorphisms, or equivalently, the multiplication and the unit of the algebra both are coalgebra morphisms.  (These statements are equivalent since they are expressed by the same commutative diagrams.)\nSimilar bialgebras are related by bialgebra homomorphisms. A bialgebra homomorphism is a linear map that is both an algebra and a coalgebra homomorphism.\nAs reflected in the symmetry of the commutative diagrams, the definition of bialgebra is self-dual, so if one can define a dual of B (which is always possible if B is finite-dimensional), then it is automatically a bialgebra.",
    "content": "In mathematics, a bialgebra over a field K is a vector space over K which is both a unital associative algebra and a counital coassociative coalgebra.  The algebraic and coalgebraic structures are made compatible with a few more axioms. Specifically, the comultiplication and the counit are both unital algebra homomorphisms, or equivalently, the multiplication and the unit of the algebra both are coalgebra morphisms.  (These statements are equivalent since they are expressed by the same commutative diagrams.)\nSimilar bialgebras are related by bialgebra homomorphisms. A bialgebra homomorphism is a linear map that is both an algebra and a coalgebra homomorphism.\nAs reflected in the symmetry of the commutative diagrams, the definition of bialgebra is self-dual, so if one can define a dual of B (which is always possible if B is finite-dimensional), then it is automatically a bialgebra.\n\nFormal definition\n(B, ∇, η, Δ, ε) is a bialgebra over K if it has the following properties: \n\nB is a vector space over K;\nthere are K-linear maps (multiplication) ∇: B ⊗ B → B (equivalent to K-multilinear map ∇: B × B → B) and (unit) η: K → B, such that (B, ∇, η) is a unital associative algebra;\nthere are K-linear maps (comultiplication) Δ: B → B ⊗ B and (counit) ε: B → K, such that (B, Δ, ε) is a (counital coassociative) coalgebra;\ncompatibility conditions expressed by the following commutative diagrams:\nMultiplication ∇ and comultiplication Δ\n\nwhere τ: B ⊗ B → B ⊗ B is the linear map defined by τ(x ⊗ y) = y ⊗ x for all x and y in B,\nMultiplication ∇ and counit ε\n\nComultiplication Δ and unit η\n\nUnit η and counit ε\n\nCoassociativity and counit\nThe K-linear map Δ: B → B ⊗ B is coassociative if \n  \n    \n      \n        (\n        \n          \n            i\n            d\n          \n          \n            B\n          \n        \n        ⊗\n        Δ\n        )\n        ∘\n        Δ\n        =\n        (\n        Δ\n        ⊗\n        \n          \n            i\n            d\n          \n          \n            B\n          \n        \n        )\n        ∘\n        Δ\n      \n    \n    {\\displaystyle (\\mathrm {id} _{B}\\otimes \\Delta )\\circ \\Delta =(\\Delta \\otimes \\mathrm {id} _{B})\\circ \\Delta }\n  \n.\nThe K-linear map ε: B → K is a counit if \n  \n    \n      \n        (\n        \n          \n            i\n            d\n          \n          \n            B\n          \n        \n        ⊗\n        ϵ\n        )\n        ∘\n        Δ\n        =\n        \n          \n            i\n            d\n          \n          \n            B\n          \n        \n        =\n        (\n        ϵ\n        ⊗\n        \n          \n            i\n            d\n          \n          \n            B\n          \n        \n        )\n        ∘\n        Δ\n      \n    \n    {\\displaystyle (\\mathrm {id} _{B}\\otimes \\epsilon )\\circ \\Delta =\\mathrm {id} _{B}=(\\epsilon \\otimes \\mathrm {id} _{B})\\circ \\Delta }\n  \n.\nCoassociativity and counit are expressed by the commutativity of the following two diagrams (they are the duals of the diagrams expressing associativity and unit of an algebra):\n\nCompatibility conditions\nThe four commutative diagrams can be read either as \"comultiplication and counit are homomorphisms of algebras\" or,  equivalently, \"multiplication and unit are homomorphisms of coalgebras\".\nThese statements are meaningful once we explain the natural structures of algebra and coalgebra in all the vector spaces involved besides B: (K, ∇0, η0) is a unital associative algebra in an obvious way and (B ⊗ B, ∇2, η2) is a unital associative algebra with unit and  multiplication\n\n  \n    \n      \n        \n          η\n          \n            2\n          \n        \n        :=\n        (\n        η\n        ⊗\n        η\n        )\n        :\n        K\n        ⊗\n        K\n        ≡\n        K\n        →\n        (\n        B\n        ⊗\n        B\n        )\n      \n    \n    {\\displaystyle \\eta _{2}:=(\\eta \\otimes \\eta ):K\\otimes K\\equiv K\\to (B\\otimes B)}\n  \n\n  \n    \n      \n        \n          ∇\n          \n            2\n          \n        \n        :=\n        (\n        ∇\n        ⊗\n        ∇\n        )\n        ∘\n        (\n        i\n        d\n        ⊗\n        τ\n        ⊗\n        i\n        d\n        )\n        :\n        (\n        B\n        ⊗\n        B\n        )\n        ⊗\n        (\n        B\n        ⊗\n        B\n        )\n        →\n        (\n        B\n        ⊗\n        B\n        )\n      \n    \n    {\\displaystyle \\nabla _{2}:=(\\nabla \\otimes \\nabla )\\circ (id\\otimes \\tau \\otimes id):(B\\otimes B)\\otimes (B\\otimes B)\\to (B\\otimes B)}\n  \n,\nso that \n  \n    \n      \n        \n          ∇\n          \n            2\n          \n        \n        (\n        (\n        \n          x\n          \n            1\n          \n        \n        ⊗\n        \n          x\n          \n            2\n          \n        \n        )\n        ⊗\n        (\n        \n          y\n          \n            1\n          \n        \n        ⊗\n        \n          y\n          \n            2\n          \n        \n        )\n        )\n        =\n        ∇\n        (\n        \n          x\n          \n            1\n       ",
    "links": [
      "Abelian group",
      "Algebra over a field",
      "Algebraic structure",
      "Associative algebra",
      "Basis (linear algebra)",
      "Boolean algebra (structure)",
      "Coalgebra",
      "Commutative diagram",
      "Commutative ring",
      "Complemented lattice",
      "Composition algebra",
      "Comultiplication",
      "Convolution",
      "Counit",
      "Division ring",
      "Domain (ring theory)",
      "Dual (category theory)",
      "Dual space",
      "Field (mathematics)",
      "Frobenius algebra",
      "Graded ring",
      "Group (mathematics)",
      "Group theory",
      "Group with operators",
      "Heyting algebra",
      "Homomorphism",
      "Homomorphisms",
      "Hopf algebra",
      "ISBN (identifier)",
      "Integral domain",
      "Lattice (order)",
      "Lie algebra",
      "Lie bialgebra",
      "Lie group",
      "Linear algebra",
      "Linear map",
      "Magma (algebra)",
      "Map of lattices",
      "Marginal distribution",
      "Mathematics",
      "Module (mathematics)",
      "Monoid",
      "Multilinear map",
      "Multiplication as juxtaposition",
      "Near-ring",
      "Non-associative algebra",
      "Probability distribution",
      "Quasi-bialgebra",
      "Quasigroup",
      "Racks and quandles"
    ],
    "categories": [
      "Category:All articles needing additional references",
      "Category:Articles needing additional references from December 2009",
      "Category:Bialgebras",
      "Category:Coalgebras",
      "Category:Monoidal categories"
    ]
  },
  "Category of groups": {
    "title": "Category of groups",
    "url": "https://en.wikipedia.org/wiki/Category_of_groups",
    "summary": "In mathematics, the category Grp (or Gp) has the class of all groups for objects and group homomorphisms for morphisms. As such, it is a concrete category. The study of this category is known as group theory.",
    "content": "In mathematics, the category Grp (or Gp) has the class of all groups for objects and group homomorphisms for morphisms. As such, it is a concrete category. The study of this category is known as group theory.\n\nRelation to other categories\nThere are two forgetful functors from Grp,  M: Grp → Mon from groups to monoids and U: Grp → Set from groups to sets. M has two adjoints: one right, I: Mon→Grp, and one left, K: Mon→Grp. I: Mon→Grp is the functor sending every monoid to the submonoid of invertible elements and K: Mon→Grp the functor sending every monoid to the Grothendieck group of that monoid. The forgetful functor U: Grp → Set has a left adjoint given by the composite KF: Set→Mon→Grp, where F is the free functor; this functor assigns to every set S the free group on S.\n\nCategorical properties\nThe monomorphisms in Grp are precisely the injective homomorphisms, the epimorphisms are precisely the surjective homomorphisms, and the isomorphisms are precisely the bijective homomorphisms.\nThe category Grp is both complete and co-complete. The category-theoretical product in Grp is just the direct product of groups while the category-theoretical coproduct in Grp is the free product of groups. The zero objects in Grp are the trivial groups (consisting of just an identity element).\nEvery morphism f : G → H in Grp has a category-theoretic kernel (given by the ordinary kernel of algebra ker f = {x in G | f(x) = e}), and also a category-theoretic cokernel (given by the factor group of H by the normal closure of f(G) in H). Unlike in abelian categories, it is not true that every monomorphism in Grp is the kernel of its cokernel.\n\nNot additive and therefore not abelian\nThe category of abelian groups, Ab, is a full subcategory of Grp. Ab is an abelian category, but Grp is not. Indeed, Grp isn't even an additive category, because there is no natural way to define the \"sum\" of two group homomorphisms. A proof of this is as follows: The set of morphisms from the symmetric group S3 of order three to itself, \n  \n    \n      \n        E\n        =\n        Hom\n        ⁡\n        (\n        \n          S\n          \n            3\n          \n        \n        ,\n        \n          S\n          \n            3\n          \n        \n        )\n      \n    \n    {\\displaystyle E=\\operatorname {Hom} (S_{3},S_{3})}\n  \n, has ten elements: an element z whose product on either side with every element of E is z (the homomorphism sending every element to the identity), three elements such that their product on one fixed side is always itself (the projections onto the three subgroups of order two), and six automorphisms.  If Grp were an additive category, then this set E of ten elements would be a ring.  In any ring, the zero element is singled out by the property that 0x=x0=0 for all x in the ring, and so z would have to be the zero of E.  However, there are no two nonzero elements of E whose product is z, so this finite ring would have no zero divisors.  A finite ring with no zero divisors is a field by Wedderburn's little theorem, but there is no field with ten elements because every finite field has for its order, the power of a prime.\n\nExact sequences\nThe notion of exact sequence is meaningful in Grp, and some results from the theory of abelian categories, such as the nine lemma, the five lemma, and their consequences hold true in Grp. The snake lemma however is not true in Grp.\nGrp is a regular category.\n\nReferences\n\nGoldblatt, Robert (2006) [1984]. Topoi, the Categorial Analysis of Logic (Revised ed.). Dover Publications. ISBN 978-0-486-45026-1. Retrieved 2009-11-25.",
    "links": [
      "Abelian category",
      "Abelian group",
      "Abelian variety",
      "Additive category",
      "Additive group",
      "Adjoint functors",
      "Algebraic group",
      "Algebraic structure",
      "Alternating group",
      "Arithmetic group",
      "Bijective",
      "Category of abelian groups",
      "Category of sets",
      "Category theory",
      "Cauchy's theorem (group theory)",
      "Circle group",
      "Class (set theory)",
      "Classification of finite simple groups",
      "Cokernel (category theory)",
      "Complete category",
      "Concrete category",
      "Conformal group",
      "Continuous group",
      "Coproduct",
      "Cyclic group",
      "Diffeomorphism",
      "Dihedral group",
      "Direct product of groups",
      "Direct sum of groups",
      "Discrete group",
      "Dover Publications",
      "E6 (mathematics)",
      "E7 (mathematics)",
      "E8 (mathematics)",
      "Elementary abelian group",
      "Elliptic curve",
      "Epimorphism",
      "Euclidean group",
      "Exact sequence",
      "F4 (mathematics)",
      "Factor group",
      "Field (mathematics)",
      "Finite field",
      "Finite group",
      "Finite ring",
      "Five lemma",
      "Forgetful functor",
      "Free group",
      "Free object",
      "Free product"
    ],
    "categories": [
      "Category:All accuracy disputes",
      "Category:All articles needing additional references",
      "Category:All articles with unsourced statements",
      "Category:Articles needing additional references from November 2009",
      "Category:Articles with disputed statements from September 2021",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from September 2021",
      "Category:Categories in category theory",
      "Category:Group theory",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Category of sets": {
    "title": "Category of sets",
    "url": "https://en.wikipedia.org/wiki/Category_of_sets",
    "summary": "In the mathematical field of category theory, the category of sets, denoted by Set, is the category whose objects are sets.  The arrows or morphisms between sets A and B are the functions from A to B, and the composition of morphisms is the composition of functions.\nMany other categories (such as the category of groups, with group homomorphisms as arrows) add structure to the objects of the category of sets or restrict the arrows to functions of a particular kind (or both).",
    "content": "In the mathematical field of category theory, the category of sets, denoted by Set, is the category whose objects are sets.  The arrows or morphisms between sets A and B are the functions from A to B, and the composition of morphisms is the composition of functions.\nMany other categories (such as the category of groups, with group homomorphisms as arrows) add structure to the objects of the category of sets or restrict the arrows to functions of a particular kind (or both).\n\nProperties of the category of sets\nThe axioms of a category are satisfied by Set because composition of functions is associative, and because every set X has an identity function idX : X → X which serves as identity element for function composition.\nThe epimorphisms in Set are the surjective maps, the monomorphisms are the injective maps, and the isomorphisms are the bijective maps.\nThe empty set serves as the initial object in Set with empty functions as morphisms.  Every singleton is a terminal object, with the functions mapping all elements of the source sets to the single target element as morphisms. There are thus no zero objects in Set. \nThe category Set is complete and co-complete. The product in this category is given by the cartesian product of sets. The coproduct is given by the disjoint union: given sets Ai where i ranges over some index set I, we construct the coproduct as the union of Ai×{i} (the cartesian product with i serves to ensure that all the components stay disjoint).\nSet is the prototype of a concrete category; other categories are concrete if they are \"built on\" Set in some well-defined way.\nEvery two-element set serves as a subobject classifier in Set. The power object of a set A is given by its power set, and the exponential object of the sets A and B is given by the set of all functions from A to B. Set is thus a topos (and in particular cartesian closed and exact in the sense of Barr).\nSet is not abelian, additive nor preadditive.\nEvery non-empty set is an injective object in Set. Every set is a projective object in Set (assuming the axiom of choice).\nThe finitely presentable objects in Set are the finite sets. Since every set is a direct limit of its finite subsets, the category Set is a locally finitely presentable category.\nIf C is an arbitrary category, the contravariant functors from C to Set are often an important object of study. If A is an object of C, then the functor from C to Set that sends X to HomC(X,A) (the set of morphisms in C from X to A) is an example of such a functor. If C is a small category (i.e. the collection of its objects forms a set), then the contravariant functors from C to Set, together with natural transformations as morphisms, form a new category, a functor category known as the category of presheaves on C.\n\nFoundations for the category of sets\nIn Zermelo–Fraenkel set theory the collection of all sets is not a set; this follows from the axiom of foundation. One refers to collections that are not sets as proper classes. One cannot handle proper classes as one handles sets; in particular, one cannot write that those proper classes belong to a collection (either a set or a proper class). This is a problem because it means that the category of sets cannot be formalized straightforwardly in this setting. Categories like Set whose collection of objects forms a proper class are known as large categories, to distinguish them from the small categories whose objects form a set. \nOne way to resolve the problem is to work in a system that gives formal status to proper classes, such as NBG set theory. In this setting, categories formed from sets are said to be small and those (like Set) that are formed from proper classes are said to be large.\nAnother solution is to assume the existence of Grothendieck universes. Roughly speaking, a Grothendieck universe is a set which is itself a model of ZF(C) (for instance if a set belongs to a universe, its elements and its powerset will belong to the universe).  The existence of Grothendieck universes (other than the empty set and the set \n  \n    \n      \n        \n          V\n          \n            ω\n          \n        \n      \n    \n    {\\displaystyle V_{\\omega }}\n  \n of all hereditarily finite sets) is not implied by the usual ZF axioms; it is an additional, independent axiom, roughly equivalent to the existence of strongly inaccessible cardinals. Assuming this extra axiom, one can limit the objects of Set to the elements of a particular universe. (There is no \"set of all sets\" within the model, but one can still reason about the class U of all inner sets, i.e., elements of U.)\nIn one variation of this scheme, the class of sets is the union of the entire tower of Grothendieck universes. (This is necessarily a proper class, but each Grothendieck universe is a set because it is an element of some larger Grothendieck universe.) However, one does not work directly with the \"category of all sets\". Instead, theorems are expressed in terms of the category SetU",
    "links": [
      "Abelian category",
      "Academic Press",
      "Accessible category",
      "Additive category",
      "Associative property",
      "Axiom of choice",
      "Axiom of foundation",
      "Axiom of reducibility",
      "Axiomatic system",
      "Bijective",
      "Cartesian closed category",
      "Cartesian product",
      "Category (mathematics)",
      "Category of groups",
      "Category of measurable spaces",
      "Category of topological spaces",
      "Category theory",
      "Complete category",
      "Concrete category",
      "Constructive set theory",
      "Contravariant functor",
      "Coproduct (category theory)",
      "Dependent type",
      "Descriptive set theory",
      "Determinacy",
      "Direct limit",
      "Disjoint union",
      "Doi (identifier)",
      "Elementary Theory of the Category of Sets",
      "Empty function",
      "Empty set",
      "Epimorphism",
      "Exponential object",
      "Formal system",
      "Foundations of mathematics",
      "Function (mathematics)",
      "Function composition",
      "Functor category",
      "Girard's paradox",
      "Glossary of category theory",
      "Graduate Texts in Mathematics",
      "Grothendieck universe",
      "Group homomorphisms",
      "Hereditarily finite set",
      "Higher category theory",
      "Hilbert system",
      "History of type theory",
      "Homotopy type theory",
      "ISBN (identifier)",
      "Identity function"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Basic concepts in set theory",
      "Category:Categories in category theory",
      "Category:Foundations of mathematics",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Category of topological spaces": {
    "title": "Category of topological spaces",
    "url": "https://en.wikipedia.org/wiki/Category_of_topological_spaces",
    "summary": "In mathematics, the category of topological spaces, often denoted Top, is the category whose objects are topological spaces and whose morphisms are continuous maps.  This is a category because the composition of two continuous maps is again continuous, and the identity function is continuous. The study of Top and of properties of topological spaces using the techniques of category theory is known as categorical topology.\nN.B. Some authors use the name Top for the categories with topological manifolds, with \ncompactly generated spaces as objects and continuous maps as morphisms or with the category of compactly generated weak Hausdorff spaces.",
    "content": "In mathematics, the category of topological spaces, often denoted Top, is the category whose objects are topological spaces and whose morphisms are continuous maps.  This is a category because the composition of two continuous maps is again continuous, and the identity function is continuous. The study of Top and of properties of topological spaces using the techniques of category theory is known as categorical topology.\nN.B. Some authors use the name Top for the categories with topological manifolds, with \ncompactly generated spaces as objects and continuous maps as morphisms or with the category of compactly generated weak Hausdorff spaces.\n\nAs a concrete category\nLike many categories, the category Top is a concrete category, meaning its objects are sets with additional structure (i.e. topologies) and its morphisms are functions preserving this structure. There is a natural forgetful functor\n\nto the category of sets which assigns to each topological space the underlying set and to each continuous map the underlying function.\nThe forgetful functor U has both a left adjoint\n\nwhich equips a given set with the discrete topology, and a right adjoint\n\nwhich equips a given set with the indiscrete topology. Both of these functors are, in fact, right inverses to U (meaning that UD and UI are equal to the identity functor on Set). Moreover, since any function between discrete or between indiscrete spaces is continuous, both of these functors give full embeddings of Set into Top.\nTop is also fiber-complete meaning that the category of all topologies on a given set X (called the fiber of U above X) forms a complete lattice when ordered by inclusion. The greatest element in this fiber is the discrete topology on X, while the least element is the indiscrete topology.\nTop is the model of what is called a topological category. These categories are characterized by the fact that every structured source \n  \n    \n      \n        (\n        X\n        →\n        U\n        \n          A\n          \n            i\n          \n        \n        \n          )\n          \n            I\n          \n        \n      \n    \n    {\\displaystyle (X\\to UA_{i})_{I}}\n  \n has a unique initial lift \n  \n    \n      \n        (\n        A\n        →\n        \n          A\n          \n            i\n          \n        \n        \n          )\n          \n            I\n          \n        \n      \n    \n    {\\displaystyle (A\\to A_{i})_{I}}\n  \n. In Top the initial lift is obtained by placing the initial topology on the source. Topological categories have many properties in common with Top (such as fiber-completeness, discrete and indiscrete functors, and unique lifting of limits).\n\nLimits and colimits\nThe category Top is both complete and cocomplete, which means that all small limits and colimits exist in Top. In fact, the forgetful functor U : Top → Set uniquely lifts both limits and colimits and preserves them as well. Therefore, (co)limits in Top are given by placing topologies on the corresponding (co)limits in Set.\nSpecifically, if F is a diagram in Top and  (L, φ : L → F) is a limit of UF in Set, the corresponding limit of F in Top is obtained by placing the initial topology on (L, φ : L → F). Dually, colimits in Top are obtained by placing the final topology on the corresponding colimits in Set.\nUnlike many algebraic categories, the forgetful functor U : Top → Set does not create or reflect limits since there will typically be non-universal cones in Top covering universal cones in Set.\nExamples of limits and colimits in Top include:\n\nThe empty set (considered as a topological space) is the initial object of Top; any singleton topological space is a terminal object. There are thus no zero objects in Top.\nThe product in Top is given by the product topology on the Cartesian product. The coproduct is given by the disjoint union of topological spaces.\nThe equalizer of a pair of morphisms is given by placing the subspace topology on the set-theoretic equalizer. Dually, the coequalizer is given by placing the quotient topology on the set-theoretic coequalizer.\nDirect limits and inverse limits are the set-theoretic limits with the final topology and initial topology respectively.\nAdjunction spaces are an example of pushouts in Top.\n\nOther properties\nThe monomorphisms in Top are the injective continuous maps, the epimorphisms are the surjective continuous maps, and the isomorphisms are the homeomorphisms.\nThe extremal  monomorphisms are (up to isomorphism) the subspace embeddings. In fact, in Top all extremal monomorphisms happen to satisfy the stronger property of being regular.\nThe extremal epimorphisms are (essentially) the quotient maps. Every extremal epimorphism is regular.\nThe split monomorphisms are (essentially) the inclusions of retracts into their ambient space.\nThe split epimorphisms are (up to isomorphism) the continuous surjective maps of a space onto one of its retracts.\nThere are no zero morphisms in Top, and in particular the category is not preadditive.\nTop i",
    "links": [
      "Adjunction space",
      "Cartesian closed category",
      "Cartesian product",
      "Category (category theory)",
      "Category of compactly generated weak Hausdorff spaces",
      "Category of groups",
      "Category of measurable spaces",
      "Category of metric spaces",
      "Category of sets",
      "Category of topological spaces with base point",
      "Category of topological vector spaces",
      "Category theory",
      "Codomain",
      "Coequalizer",
      "Compactly generated Hausdorff space",
      "Compactly generated space",
      "Complete category",
      "Complete lattice",
      "Concrete category",
      "Cone (category theory)",
      "Continuous map",
      "Convergence space",
      "Coproduct (category theory)",
      "Coslice category",
      "Dense set",
      "Diagram (category theory)",
      "Direct limit",
      "Discrete topology",
      "Disjoint union (topology)",
      "Doi (identifier)",
      "Empty set",
      "Epimorphism",
      "Equaliser (mathematics)",
      "Exponential object",
      "Extremal monomorphism",
      "Fiber (mathematics)",
      "Final topology",
      "Forgetful functor",
      "Full embedding",
      "Full subcategory",
      "Function (mathematics)",
      "Function composition",
      "Greatest element",
      "Hausdorff space",
      "Homeomorphism",
      "Homotopy category of topological spaces",
      "Homotopy equivalent",
      "Homotopy hypothesis",
      "Horst Herrlich",
      "ISBN (identifier)"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Categories in category theory",
      "Category:General topology",
      "Category:Pages displaying short descriptions of redirect targets via Module:Annotated link",
      "Category:Short description matches Wikidata",
      "Category:Webarchive template wayback links"
    ]
  },
  "Composition algebra": {
    "title": "Composition algebra",
    "url": "https://en.wikipedia.org/wiki/Composition_algebra",
    "summary": "In mathematics, a composition algebra A over a field K is a not necessarily associative algebra over K together with a nondegenerate quadratic form  N that satisfies\n\n  \n    \n      \n        N\n        (\n        x\n        y\n        )\n        =\n        N\n        (\n        x\n        )\n        N\n        (\n        y\n        )\n      \n    \n    {\\displaystyle N(xy)=N(x)N(y)}\n  \n\nfor all x and y in A.\nA composition algebra includes an involution called a conjugation: \n  \n    \n      \n        x\n        ↦\n        \n          x\n          \n            ∗\n          \n        \n        .\n      \n    \n    {\\displaystyle x\\mapsto x^{*}.}\n  \n The quadratic form \n  \n    \n      \n        N\n        (\n        x\n        )\n        =\n        x\n        \n          x\n          \n            ∗\n          \n        \n      \n    \n    {\\displaystyle N(x)=xx^{*}}\n  \n is called the norm of the algebra.\nA composition algebra (A, ∗, N) is either a division algebra or a split algebra, depending on the existence of a non-zero v in A s",
    "content": "In mathematics, a composition algebra A over a field K is a not necessarily associative algebra over K together with a nondegenerate quadratic form  N that satisfies\n\n  \n    \n      \n        N\n        (\n        x\n        y\n        )\n        =\n        N\n        (\n        x\n        )\n        N\n        (\n        y\n        )\n      \n    \n    {\\displaystyle N(xy)=N(x)N(y)}\n  \n\nfor all x and y in A.\nA composition algebra includes an involution called a conjugation: \n  \n    \n      \n        x\n        ↦\n        \n          x\n          \n            ∗\n          \n        \n        .\n      \n    \n    {\\displaystyle x\\mapsto x^{*}.}\n  \n The quadratic form \n  \n    \n      \n        N\n        (\n        x\n        )\n        =\n        x\n        \n          x\n          \n            ∗\n          \n        \n      \n    \n    {\\displaystyle N(x)=xx^{*}}\n  \n is called the norm of the algebra.\nA composition algebra (A, ∗, N) is either a division algebra or a split algebra, depending on the existence of a non-zero v in A such that N(v) = 0, called a null vector. When x is not a null vector, the multiplicative inverse of x is \n  \n    \n      \n        \n          \n            \n              x\n              \n                ∗\n              \n            \n            \n              N\n              (\n              x\n              )\n            \n          \n        \n      \n    \n    {\\textstyle {\\frac {x^{*}}{N(x)}}}\n  \n. When there is a non-zero null vector, N is an isotropic quadratic form, and \"the algebra splits\".\n\nStructure theorem\nEvery unital composition algebra over a field K can be obtained by repeated application of the Cayley–Dickson construction starting from K (if the characteristic of K is different from 2) or a 2-dimensional composition subalgebra (if char(K) = 2).  The possible dimensions of a composition algebra are 1, 2, 4, and 8.\n\n1-dimensional composition algebras only exist when char(K) ≠ 2.\nComposition algebras of dimension 1 and 2 are commutative and associative.\nComposition algebras of dimension 2 are either quadratic field extensions of K or isomorphic to K ⊕ K.\nComposition algebras of dimension 4 are called quaternion algebras.  They are associative but not commutative.\nComposition algebras of dimension 8 are called octonion algebras.  They are neither associative nor commutative.\nFor consistent terminology, algebras of dimension 1 have been called unarion, and those of dimension 2 binarion.\nEvery composition algebra is an alternative algebra.\nUsing the doubled form ( _ : _ ): A × A → K defined by \n  \n    \n      \n        (\n        a\n        :\n        b\n        )\n        =\n        N\n        (\n        a\n        +\n        b\n        )\n        −\n        N\n        (\n        a\n        )\n        −\n        N\n        (\n        b\n        )\n        =\n        a\n        \n          b\n          \n            ∗\n          \n        \n        +\n        b\n        \n          a\n          \n            ∗\n          \n        \n        ,\n      \n    \n    {\\displaystyle (a:b)=N(a+b)-N(a)-N(b)=ab^{*}+ba^{*},}\n  \n then the trace of a is given by ⁠\n  \n    \n      \n        (\n        a\n        :\n        1\n        )\n        =\n        a\n        +\n        \n          a\n          \n            ∗\n          \n        \n      \n    \n    {\\displaystyle (a:1)=a+a^{*}}\n  \n⁠ and the conjugate by ⁠\n  \n    \n      \n        \n          a\n          \n            ∗\n          \n        \n        =\n        (\n        a\n        :\n        1\n        )\n        e\n        −\n        a\n      \n    \n    {\\displaystyle a^{*}=(a:1)e-a}\n  \n⁠ where ⁠\n  \n    \n      \n        e\n      \n    \n    {\\displaystyle e}\n  \n⁠ is multiplicative identity of ⁠\n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n⁠. A series of exercises proves that a composition algebra is always an alternative algebra.\n\nInstances and usage\nWhen the field K is taken to be complex numbers C and the quadratic form z2, then four composition algebras over C are C itself, the bicomplex numbers, the biquaternions (isomorphic to the 2×2 complex matrix ring M(2, C)), and the bioctonions C ⊗ O, which are also called complex octonions.\nThe matrix ring M(2, C) has long been an object of interest, first as biquaternions by\nHamilton (1853), later in the isomorphic matrix form, and especially as Pauli algebra.\nThe squaring function N(x) = x2 on the real number field forms the primordial composition algebra.\nWhen the field K is taken to be real numbers R, then there are just six other real composition algebras. \nIn two, four, and eight dimensions there are both a division algebra and a split algebra:\n\nbinarions: complex numbers with quadratic form x2 + y2 and split-complex numbers with quadratic form x2 − y2,\nquaternions and split-quaternions,\noctonions and split-octonions.\nEvery composition algebra has an associated bilinear form B(x,y) constructed with the norm N and a polarization identity:\n\n  \n    \n      \n        B\n        (\n        x\n        ,\n        y\n        )\n         \n        =\n         \n        [\n        N\n        (\n        x\n        +\n ",
    "links": [
      "Abelian group",
      "Abhandlungen aus dem Mathematischen Seminar der Universität Hamburg",
      "Academic Press",
      "Adrian Albert",
      "Alexander Merkurjev",
      "Algebra over a field",
      "Algebraic structure",
      "Alternative algebra",
      "American Mathematical Society",
      "Annals of Mathematics",
      "Associative algebra",
      "Automorphism",
      "Bialgebra",
      "Bicomplex number",
      "Bilinear form",
      "Bioctonion",
      "Biquaternion",
      "Boolean algebra (structure)",
      "Brahmagupta–Fibonacci identity",
      "Cayley number",
      "Cayley–Dickson construction",
      "Characteristic (algebra)",
      "Commutative ring",
      "Complemented lattice",
      "Complex number",
      "Degen's eight-square identity",
      "Degenerate form",
      "Diophantus",
      "Division algebra",
      "Division ring",
      "Doi (identifier)",
      "Domain (ring theory)",
      "Dover Publications",
      "Euler's four-square identity",
      "Field (mathematics)",
      "Freudenthal magic square",
      "Graded ring",
      "Graduate Studies in Mathematics",
      "Group (mathematics)",
      "Group theory",
      "Group with operators",
      "Heyting algebra",
      "Hopf algebra",
      "Hurwitz's theorem (composition algebras)",
      "Hurwitz problem",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "Imaginary unit",
      "Integral domain",
      "Involution (mathematics)"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Composition algebras",
      "Category:Historical treatment of octonions",
      "Category:Historical treatment of quaternions",
      "Category:Quadratic forms",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Coordinate vector": {
    "title": "Coordinate vector",
    "url": "https://en.wikipedia.org/wiki/Coordinate_vector",
    "summary": "In linear algebra, a coordinate vector is a representation of a vector as an ordered list of numbers (a tuple) that describes the vector in terms of a particular ordered basis. An easy example may be a position such as (5, 2, 1) in a 3-dimensional Cartesian coordinate system with the basis as the axes of this system. Coordinates are always specified relative to an ordered basis. Bases and their associated coordinate representations let one realize vector spaces and linear transformations concretely as column vectors, row vectors, and matrices; hence, they are useful in calculations.\nThe idea of a coordinate vector can also be used for infinite-dimensional vector spaces, as addressed below.",
    "content": "In linear algebra, a coordinate vector is a representation of a vector as an ordered list of numbers (a tuple) that describes the vector in terms of a particular ordered basis. An easy example may be a position such as (5, 2, 1) in a 3-dimensional Cartesian coordinate system with the basis as the axes of this system. Coordinates are always specified relative to an ordered basis. Bases and their associated coordinate representations let one realize vector spaces and linear transformations concretely as column vectors, row vectors, and matrices; hence, they are useful in calculations.\nThe idea of a coordinate vector can also be used for infinite-dimensional vector spaces, as addressed below.\n\nDefinition\nLet V be a vector space of dimension n over a field F and let \n\n  \n    \n      \n        B\n        =\n        {\n        \n          b\n          \n            1\n          \n        \n        ,\n        \n          b\n          \n            2\n          \n        \n        ,\n        …\n        ,\n        \n          b\n          \n            n\n          \n        \n        }\n      \n    \n    {\\displaystyle B=\\{b_{1},b_{2},\\ldots ,b_{n}\\}}\n  \n\nbe an ordered basis for V. Then for every \n  \n    \n      \n        v\n        ∈\n        V\n      \n    \n    {\\displaystyle v\\in V}\n  \n there is a unique linear combination of the basis vectors that equals \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n  \n:\n\n  \n    \n      \n        v\n        =\n        \n          α\n          \n            1\n          \n        \n        \n          b\n          \n            1\n          \n        \n        +\n        \n          α\n          \n            2\n          \n        \n        \n          b\n          \n            2\n          \n        \n        +\n        ⋯\n        +\n        \n          α\n          \n            n\n          \n        \n        \n          b\n          \n            n\n          \n        \n        .\n      \n    \n    {\\displaystyle v=\\alpha _{1}b_{1}+\\alpha _{2}b_{2}+\\cdots +\\alpha _{n}b_{n}.}\n  \n\nThe coordinate vector of \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n  \n relative to B is the sequence of coordinates\n\n  \n    \n      \n        [\n        v\n        \n          ]\n          \n            B\n          \n        \n        =\n        (\n        \n          α\n          \n            1\n          \n        \n        ,\n        \n          α\n          \n            2\n          \n        \n        ,\n        …\n        ,\n        \n          α\n          \n            n\n          \n        \n        )\n        .\n      \n    \n    {\\displaystyle [v]_{B}=(\\alpha _{1},\\alpha _{2},\\ldots ,\\alpha _{n}).}\n  \n\nThis is also called the representation of \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n  \n with respect to B, or the B representation of \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n  \n. The \n  \n    \n      \n        \n          α\n          \n            1\n          \n        \n        ,\n        \n          α\n          \n            2\n          \n        \n        ,\n        …\n        ,\n        \n          α\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\alpha _{1},\\alpha _{2},\\ldots ,\\alpha _{n}}\n  \n are called the coordinates of \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n  \n. The order of the basis becomes important here, since it determines the order in which the coefficients are listed in the coordinate vector.\nCoordinate vectors of finite-dimensional vector spaces can be represented by matrices as column or row vectors. In the above notation, one can write\n\n  \n    \n      \n        [\n        v\n        \n          ]\n          \n            B\n          \n        \n        =\n        \n          \n            [\n            \n              \n                \n                  \n                    α\n                    \n                      1\n                    \n                  \n                \n              \n              \n                \n                  ⋮\n                \n              \n              \n                \n                  \n                    α\n                    \n                      n\n                    \n                  \n                \n              \n            \n            ]\n          \n        \n      \n    \n    {\\displaystyle [v]_{B}={\\begin{bmatrix}\\alpha _{1}\\\\\\vdots \\\\\\alpha _{n}\\end{bmatrix}}}\n  \n\nand\n\n  \n    \n      \n        [\n        v\n        \n          ]\n          \n            B\n          \n          \n            T\n          \n        \n        =\n        \n          \n            [\n            \n              \n                \n                  \n                    α\n                    \n                      1\n                    \n                  \n                \n                \n                  \n                    α\n                    \n                      2\n                    \n                  \n                \n                \n                  ⋯\n                \n                \n                  \n                    α\n                    \n                      n\n     ",
    "links": [
      "Automorphism",
      "Cartesian coordinate system",
      "Change of basis",
      "Column vector",
      "Coordinate space",
      "Coordinates",
      "Differentiation operator",
      "Dimension (vector space)",
      "Eigenstate",
      "Eigenvalues",
      "Field (mathematics)",
      "Full linear ring",
      "Hermitian",
      "ISBN (identifier)",
      "Infinite matrix",
      "Inverse function",
      "Invertible matrix",
      "Isomorphism",
      "Linear algebra",
      "Linear combination",
      "Linear transformation",
      "Matrix (mathematics)",
      "Ordered basis",
      "Pauli matrices",
      "Polynomials",
      "Row vector",
      "Sequence",
      "Spin (physics)",
      "Transpose",
      "Tuple",
      "Vector (mathematics and physics)",
      "Vector space",
      "Wikipedia:Verifiability",
      "Help:Maintenance template removal",
      "Help:Referencing for beginners"
    ],
    "categories": [
      "Category:All articles needing additional references",
      "Category:Articles needing additional references from February 2009",
      "Category:Articles with short description",
      "Category:Linear algebra",
      "Category:Short description is different from Wikidata",
      "Category:Vectors (mathematics and physics)"
    ]
  },
  "Addition": {
    "title": "Addition",
    "url": "https://en.wikipedia.org/wiki/Addition",
    "summary": "Addition (usually signified by the plus symbol, +) is one of the four basic operations of arithmetic, the other three being subtraction, multiplication, and division. The addition of two whole numbers results in the total or sum of those values combined. For example, the adjacent image shows two columns of apples, one with three apples and the other with two apples, totaling to five apples. This observation is expressed as \"3 + 2 = 5\", which is read as  \"three plus two equals five\".\nBesides counting items, addition can also be defined and executed without referring to concrete objects, using abstractions called numbers instead, such as integers, real numbers, and complex numbers. Addition belongs to arithmetic, a branch of mathematics. In algebra, another area of mathematics, addition can also be performed on abstract objects such as vectors, matrices, and elements of additive groups.\nAddition has several important properties. It is commutative, meaning that the order of the numbers be",
    "content": "Addition (usually signified by the plus symbol, +) is one of the four basic operations of arithmetic, the other three being subtraction, multiplication, and division. The addition of two whole numbers results in the total or sum of those values combined. For example, the adjacent image shows two columns of apples, one with three apples and the other with two apples, totaling to five apples. This observation is expressed as \"3 + 2 = 5\", which is read as  \"three plus two equals five\".\nBesides counting items, addition can also be defined and executed without referring to concrete objects, using abstractions called numbers instead, such as integers, real numbers, and complex numbers. Addition belongs to arithmetic, a branch of mathematics. In algebra, another area of mathematics, addition can also be performed on abstract objects such as vectors, matrices, and elements of additive groups.\nAddition has several important properties. It is commutative, meaning that the order of the numbers being added does not matter, so 3 + 2 = 2 + 3, and it is associative, meaning that when one adds more than two numbers, the order in which addition is performed does not matter. Repeated addition of 1 is the same as counting (see Successor function). Addition of 0 does not change a number. Addition also obeys rules concerning related operations such as subtraction and multiplication.\nPerforming addition is one of the simplest numerical tasks to perform. Addition of very small numbers is accessible to toddlers; the most basic task, 1 + 1, can be performed by infants as young as five months, and even some members of other animal species. In primary education, students are taught to add numbers in the decimal system, beginning with single digits and progressively tackling more difficult problems. Mechanical aids range from the ancient abacus to the modern computer, where research on the most efficient implementations of addition continues to this day.\n\nNotation and terminology\nAddition is written using the plus sign \"+\" between the terms, and the result is expressed with an equals sign. For example, \n  \n    \n      \n        1\n        +\n        2\n        =\n        3\n      \n    \n    {\\displaystyle 1+2=3}\n  \n reads \"one plus two equals three\". Nonetheless, some situations where addition is \"understood\", even though no symbol appears: a whole number followed immediately by a fraction indicates the sum of the two, called a mixed number, with an example,\n  \n    \n      \n        3\n        \n          \n            1\n            2\n          \n        \n        =\n        3\n        +\n        \n          \n            1\n            2\n          \n        \n        =\n        3.5.\n      \n    \n    {\\displaystyle 3{\\frac {1}{2}}=3+{\\frac {1}{2}}=3.5.}\n  \n This notation can cause confusion, since in most other contexts, juxtaposition denotes multiplication instead.\n\nThe numbers or the objects to be added in general addition are collectively referred to as the terms, the addends or the summands. This terminology carries over to the summation of multiple terms.\nThis is to be distinguished from factors, which are multiplied.\nSome authors call the first addend the augend. In fact, during the Renaissance, many authors did not consider the first addend an \"addend\" at all. Today, due to the commutative property of addition, \"augend\" is rarely used, and both terms are generally called addends.\nAll of the above terminology derives from Latin. \"Addition\" and \"add\" are English words derived from the Latin verb addere, which is in turn a compound of ad \"to\" and dare \"to give\", from the Proto-Indo-European root *deh₃- \"to give\"; thus to add is to give to. Using the gerundive suffix -nd results in \"addend\", \"thing to be added\". Likewise from augere \"to increase\", one gets \"augend\", \"thing to be increased\".\n\n\"Sum\" and \"summand\" derive from the Latin noun summa \"the highest\" or \"the top\", used in Medieval Latin phrase summa linea (\"top line\") meaning the sum of a column of numerical quantities, following the ancient Greek and Roman practice of putting the sum at the top of a column.\nAddere and summare date back at least to Boethius, if not to earlier Roman writers such as Vitruvius and Frontinus; Boethius also used several other terms for the addition operation. The later Middle English terms \"adden\" and \"adding\" were popularized by Chaucer.\n\nDefinition and interpretations\nAddition is one of the four basic operations of arithmetic, with the other three being subtraction, multiplication, and division. This operation works by adding two or more terms. An arbitrary of many operation of additions is called the summation. An infinite summation is a delicate procedure known as a series, and it can be expressed through capital sigma notation \n  \n    \n      \n        ∑\n      \n    \n    {\\textstyle \\sum }\n  \n, which compactly denotes iteration of the operation of addition based on the given indexes. For example,\n\n  \n    \n      \n        \n          ∑\n          \n            k\n           ",
    "links": [
      "0 (number)",
      "1 (number)",
      "ADD (disambiguation)",
      "Abacus",
      "Abelian group",
      "Absolute value",
      "Abstract algebra",
      "Acceleration",
      "Ackermann function",
      "Adder (electronics)",
      "Adding machine",
      "Addition (disambiguation)",
      "Additive group",
      "Additive identity",
      "Additive inverse",
      "Affix",
      "Africa",
      "Al-Khwarizmi",
      "Algebra",
      "Algebra over a field",
      "Algebraic structure",
      "Analog computer",
      "Ancient Greece",
      "Ancient Rome",
      "Angle",
      "Anicius Manlius Severinus Boethius",
      "Apple",
      "ArXiv (identifier)",
      "Arabic numerals",
      "Arithmetic",
      "Arithmetic mean",
      "Arithmetic operations",
      "Arithmetic overflow",
      "Asia",
      "Asian elephant",
      "Associative",
      "Associativity",
      "Axiom of Choice",
      "Axle",
      "B.G. Teubner Verlagsgesellschaft",
      "Beyond Infinity (mathematics book)",
      "Bhāskara II",
      "Bibcode (identifier)",
      "Binary addition",
      "Binary arithmetic",
      "Binary operation",
      "Bitwise operation",
      "Blaise Pascal",
      "Boolean logic",
      "Brahmagupta"
    ],
    "categories": [
      "Category:Addition",
      "Category:Articles containing Latin-language text",
      "Category:Articles containing Proto-Indo-European-language text",
      "Category:Articles with example C code",
      "Category:Articles with short description",
      "Category:CS1 French-language sources (fr)",
      "Category:CS1 German-language sources (de)",
      "Category:CS1 Italian-language sources (it)",
      "Category:Elementary arithmetic",
      "Category:Good articles"
    ]
  },
  "Associativity": {
    "title": "Associative property",
    "url": "https://en.wikipedia.org/wiki/Associative_property",
    "summary": "In mathematics, the associative property is a property of some binary operations that rearranging the parentheses in an expression will not change the result. In propositional logic, associativity is a valid rule of replacement for expressions in logical proofs.\nWithin an expression containing two or more occurrences in a row of the same associative operator, the order in which the operations are performed does not matter as long as the sequence of the operands is not changed. That is (after rewriting the expression with parentheses and in infix notation if necessary), rearranging the parentheses in such an expression will not change its value. Consider the following equations:\n\n  \n    \n      \n        \n          \n            \n              \n                (\n                2\n                +\n                3\n                )\n                +\n                4\n              \n              \n                \n                =\n                2\n                +\n                (\n    ",
    "content": "In mathematics, the associative property is a property of some binary operations that rearranging the parentheses in an expression will not change the result. In propositional logic, associativity is a valid rule of replacement for expressions in logical proofs.\nWithin an expression containing two or more occurrences in a row of the same associative operator, the order in which the operations are performed does not matter as long as the sequence of the operands is not changed. That is (after rewriting the expression with parentheses and in infix notation if necessary), rearranging the parentheses in such an expression will not change its value. Consider the following equations:\n\n  \n    \n      \n        \n          \n            \n              \n                (\n                2\n                +\n                3\n                )\n                +\n                4\n              \n              \n                \n                =\n                2\n                +\n                (\n                3\n                +\n                4\n                )\n                =\n                9\n                \n              \n            \n            \n              \n                2\n                ×\n                (\n                3\n                ×\n                4\n                )\n              \n              \n                \n                =\n                (\n                2\n                ×\n                3\n                )\n                ×\n                4\n                =\n                24.\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}(2+3)+4&=2+(3+4)=9\\,\\\\2\\times (3\\times 4)&=(2\\times 3)\\times 4=24.\\end{aligned}}}\n  \n\nEven though the parentheses were rearranged on each line, the values of the expressions were not altered. Since this holds true when performing addition and multiplication on any real numbers, it can be said that \"addition and multiplication of real numbers are associative operations\".\nAssociativity is not the same as commutativity, which addresses whether the order of two operands affects the result. For example, the order does not matter in the multiplication of real numbers, that is, a × b = b × a, so we say that the multiplication of real numbers is a commutative operation. However, operations such as function composition and matrix multiplication are associative, but not (generally) commutative.\nAssociative operations are abundant in mathematics; in fact, many algebraic structures (such as semigroups and categories) explicitly require their binary operations to be associative.  However, many important and interesting operations are non-associative; some examples include subtraction, exponentiation, and the vector cross product. In contrast to the theoretical properties of real numbers, the addition of floating point numbers in computer science is not associative, and the choice of how to associate an expression can have a significant effect on rounding error.\n\nDefinition\nFormally, a binary operation \n  \n    \n      \n        ∗\n      \n    \n    {\\displaystyle \\ast }\n  \n on a set S is called associative if it satisfies the associative law:\n\n  \n    \n      \n        (\n        x\n        ∗\n        y\n        )\n        ∗\n        z\n        =\n        x\n        ∗\n        (\n        y\n        ∗\n        z\n        )\n      \n    \n    {\\displaystyle (x\\ast y)\\ast z=x\\ast (y\\ast z)}\n  \n, for all \n  \n    \n      \n        x\n        ,\n        y\n        ,\n        z\n      \n    \n    {\\displaystyle x,y,z}\n  \n in S.\nHere, ∗ is used to replace the symbol of the operation, which may be any symbol, and even the absence of symbol (juxtaposition) as for multiplication.\n\n  \n    \n      \n        (\n        x\n        y\n        )\n        z\n        =\n        x\n        (\n        y\n        z\n        )\n      \n    \n    {\\displaystyle (xy)z=x(yz)}\n  \n, for all \n  \n    \n      \n        x\n        ,\n        y\n        ,\n        z\n      \n    \n    {\\displaystyle x,y,z}\n  \n in S.\nThe associative law can also be expressed in functional notation thus: \n  \n    \n      \n        (\n        f\n        ∘\n        (\n        g\n        ∘\n        h\n        )\n        )\n        (\n        x\n        )\n        =\n        (\n        (\n        f\n        ∘\n        g\n        )\n        ∘\n        h\n        )\n        (\n        x\n        )\n      \n    \n    {\\displaystyle (f\\circ (g\\circ h))(x)=((f\\circ g)\\circ h)(x)}\n\nGeneralized associative law\nIf a binary operation is associative, repeated application of the operation produces the same result regardless of how valid pairs of parentheses are inserted in the expression. This is called the generalized associative law.\nThe number of possible bracketings is just the Catalan number, \n  \n    \n      \n        \n          C\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle C_{n}}\n  \n\n, for n operations on n+1 values. For instance, a product of 3 operations on 4 elements may be written (ignoring permutations of the arguments), in \n  \n    \n    ",
    "links": [
      "ACM Computing Surveys",
      "Absorption (logic)",
      "Addition",
      "Algebraic structure",
      "Alternativity",
      "ArXiv (identifier)",
      "Arithmetic",
      "Associativity (disambiguation)",
      "Average",
      "Biconditional elimination",
      "Biconditional introduction",
      "Binary operation",
      "Boolean algebra",
      "Catalan number",
      "Category (mathematics)",
      "Category theory",
      "Commutative diagram",
      "Commutative non-associative magmas",
      "Commutative property",
      "Commutativity",
      "Complement (set theory)",
      "Complex number",
      "Conditional proof",
      "Conjunction elimination",
      "Conjunction introduction",
      "Constructive dilemma",
      "Cross product",
      "Currying",
      "Curry–Howard correspondence",
      "De Morgan's laws",
      "Destructive dilemma",
      "Disjunction elimination",
      "Disjunction introduction",
      "Disjunctive syllogism",
      "Distributive property",
      "Distributivity",
      "Division (mathematics)",
      "Doi (identifier)",
      "Double negation",
      "Elementary algebra",
      "Existential generalization",
      "Existential instantiation",
      "Exponentiation",
      "Exportation (logic)",
      "First-order logic",
      "Flexible algebra",
      "Floating-point arithmetic",
      "Floating point",
      "Formal proof",
      "Function (mathematics)"
    ],
    "categories": [
      "Category:All articles needing additional references",
      "Category:All articles with unsourced statements",
      "Category:Articles needing additional references from June 2009",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from June 2022",
      "Category:Elementary algebra",
      "Category:Functional analysis",
      "Category:Properties of binary operations",
      "Category:Rules of inference",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Algebraic invariant": {
    "title": "Invariant theory",
    "url": "https://en.wikipedia.org/wiki/Invariant_theory",
    "summary": "Invariant theory is a branch of abstract algebra dealing with actions of groups on algebraic varieties, such as vector spaces, from the point of view of their effect on functions. Classically, the theory dealt with the question of explicit description of polynomial functions that do not change, or are invariant, under the transformations from a given linear group. For example, if we consider the action of the special linear group SLn on the space of n by n matrices by left multiplication, then the determinant is an invariant of this action because the determinant of A X equals the determinant of X, when  A is in SLn.",
    "content": "Invariant theory is a branch of abstract algebra dealing with actions of groups on algebraic varieties, such as vector spaces, from the point of view of their effect on functions. Classically, the theory dealt with the question of explicit description of polynomial functions that do not change, or are invariant, under the transformations from a given linear group. For example, if we consider the action of the special linear group SLn on the space of n by n matrices by left multiplication, then the determinant is an invariant of this action because the determinant of A X equals the determinant of X, when  A is in SLn.\n\nIntroduction\nLet \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n be a group, and \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n a finite-dimensional vector space over a field \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n (which in classical invariant theory was usually assumed to be the complex numbers). A representation of \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n in \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n is a group homomorphism \n  \n    \n      \n        π\n        :\n        G\n        →\n        G\n        L\n        (\n        V\n        )\n      \n    \n    {\\displaystyle \\pi :G\\to GL(V)}\n  \n, which induces a group action of \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n on \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n. If \n  \n    \n      \n        k\n        [\n        V\n        ]\n      \n    \n    {\\displaystyle k[V]}\n  \n is the space of polynomial functions on \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n, then the group action of \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n on \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n produces an action on \n  \n    \n      \n        k\n        [\n        V\n        ]\n      \n    \n    {\\displaystyle k[V]}\n  \n by the following formula: \n\n  \n    \n      \n        (\n        g\n        ⋅\n        f\n        )\n        (\n        x\n        )\n        :=\n        f\n        (\n        \n          g\n          \n            −\n            1\n          \n        \n        (\n        x\n        )\n        )\n        \n        ∀\n        x\n        ∈\n        V\n        ,\n        g\n        ∈\n        G\n        ,\n        f\n        ∈\n        k\n        [\n        V\n        ]\n        .\n      \n    \n    {\\displaystyle (g\\cdot f)(x):=f(g^{-1}(x))\\qquad \\forall x\\in V,g\\in G,f\\in k[V].}\n  \n\nWith this action it is natural to consider the subspace of all polynomial functions which are invariant under this group action, in other words the set of polynomials such that \n  \n    \n      \n        g\n        ⋅\n        f\n        =\n        f\n      \n    \n    {\\displaystyle g\\cdot f=f}\n  \n for all \n  \n    \n      \n        g\n        ∈\n        G\n      \n    \n    {\\displaystyle g\\in G}\n  \n. This space of invariant polynomials is denoted \n  \n    \n      \n        k\n        [\n        V\n        \n          ]\n          \n            G\n          \n        \n      \n    \n    {\\displaystyle k[V]^{G}}\n  \n.\nFirst problem of invariant theory: Is \n  \n    \n      \n        k\n        [\n        V\n        \n          ]\n          \n            G\n          \n        \n      \n    \n    {\\displaystyle k[V]^{G}}\n  \n a finitely generated algebra over \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n?\nFor example, if \n  \n    \n      \n        G\n        =\n        S\n        \n          L\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle G=SL_{n}}\n  \n and \n  \n    \n      \n        V\n        =\n        \n          M\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle V=M_{n}}\n  \n the space of square matrices, and the action of \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n on \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n is given by left multiplication, then \n  \n    \n      \n        k\n        [\n        V\n        \n          ]\n          \n            G\n          \n        \n      \n    \n    {\\displaystyle k[V]^{G}}\n  \n is isomorphic to a polynomial algebra in one variable, generated by the determinant. In other words, in this case, every invariant polynomial is a linear combination of powers of the determinant polynomial. So in this case, \n  \n    \n      \n        k\n        [\n        V\n        \n          ]\n          \n            G\n          \n        \n      \n    \n    {\\displaystyle k[V]^{G}}\n  \n is finitely generated over \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n.\nIf the answer is yes, then the next question is to find a minimal basis, and ask whether the module of polynomial relations between the basis elements (known as the syzygies) is finitely generated over \n  \n    \n      \n        k\n        [\n        V\n        ]\n      \n    \n    {\\displaystyle k[V]}\n  \n.\nInvariant theory of finite groups has intimate connections with Galois theory. One of the first major results was the main theorem on th",
    "links": [
      "ADE classification",
      "Abstract algebra",
      "Academic Press",
      "Advances in Mathematics",
      "Affine variety",
      "Alfred Young (mathematician)",
      "Algebraic form",
      "Algebraic geometry",
      "Algebraic topology",
      "Algebraic variety",
      "Armand Borel",
      "Arthur Cayley",
      "Bernd Sturmfels",
      "Binary polyhedral group",
      "Cambridge University Press",
      "Cayley's omega process",
      "Characteristic (algebra)",
      "Chevalley–Shephard–Todd theorem",
      "Commutative algebra",
      "Complex number",
      "David Hilbert",
      "David Mumford",
      "Determinant",
      "Differential geometry",
      "Doi (identifier)",
      "Du Val singularities",
      "Duke Mathematical Journal",
      "Encyclopedia of Mathematics",
      "European Mathematical Society",
      "Felix Klein",
      "Field (mathematics)",
      "Finite group",
      "Finitely generated algebra",
      "First and second fundamental theorems of invariant theory",
      "Frank Grosshans",
      "Galois theory",
      "Geometric invariant theory",
      "George Boole",
      "Gian-Carlo Rota",
      "Gram's theorem",
      "Group (mathematics)",
      "Group action (mathematics)",
      "Group homomorphism",
      "Group representation",
      "Hermann Weyl",
      "Hilbert's basis theorem",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "Infinite group",
      "Instanton"
    ],
    "categories": [
      "Category:All Wikipedia articles written in American English",
      "Category:Articles with short description",
      "Category:CS1: long volume value",
      "Category:CS1 errors: ISBN date",
      "Category:Invariant theory",
      "Category:Short description matches Wikidata",
      "Category:Use American English from January 2019"
    ]
  },
  "Algebraic K-theory": {
    "title": "Algebraic K-theory",
    "url": "https://en.wikipedia.org/wiki/Algebraic_K-theory",
    "summary": "Algebraic K-theory is a subject area in mathematics with connections to geometry, topology, ring theory, and number theory.  Geometric, algebraic, and arithmetic objects are assigned objects called K-groups.  These are groups in the sense of abstract algebra.  They contain detailed information about the original object but are notoriously difficult to compute; for example, an important outstanding problem is to compute the K-groups of the integers.\nK-theory was discovered in the late 1950s by Alexander Grothendieck in his study of intersection theory on algebraic varieties. In the modern language, Grothendieck defined only K0, the zeroth K-group, but even this single group has plenty of applications, such as the Grothendieck–Riemann–Roch theorem. Intersection theory is still a motivating force in the development of (higher) algebraic K-theory through its links with motivic cohomology and specifically Chow groups.  The subject also includes classical number-theoretic topics like quadrat",
    "content": "Algebraic K-theory is a subject area in mathematics with connections to geometry, topology, ring theory, and number theory.  Geometric, algebraic, and arithmetic objects are assigned objects called K-groups.  These are groups in the sense of abstract algebra.  They contain detailed information about the original object but are notoriously difficult to compute; for example, an important outstanding problem is to compute the K-groups of the integers.\nK-theory was discovered in the late 1950s by Alexander Grothendieck in his study of intersection theory on algebraic varieties. In the modern language, Grothendieck defined only K0, the zeroth K-group, but even this single group has plenty of applications, such as the Grothendieck–Riemann–Roch theorem. Intersection theory is still a motivating force in the development of (higher) algebraic K-theory through its links with motivic cohomology and specifically Chow groups.  The subject also includes classical number-theoretic topics like quadratic reciprocity and embeddings of number fields into the real numbers and complex numbers, as well as more modern concerns like the construction of higher regulators and special values of L-functions.\nThe lower K-groups were discovered first, in the sense that adequate descriptions of these groups in terms of other algebraic structures were found.  For example, if F is a field, then K0(F) is isomorphic to the integers Z and is closely related to the notion of vector space dimension.  For a commutative ring R, the group K0(R) is related to the Picard group of R, and when R is the ring of integers in a number field, this generalizes the classical construction of the class group.  The group K1(R) is closely related to the group of units R×, and if R is a field, it is exactly the group of units.  For a number field F, the group K2(F) is related to class field theory, the Hilbert symbol, and the solvability of quadratic equations over completions.  In contrast, finding the correct definition of the higher K-groups of rings was a difficult achievement of Daniel Quillen, and many of the basic facts about the higher K-groups of algebraic varieties were not known until the work of Robert Thomason.\n\nHistory\nThe history of K-theory was detailed by Charles Weibel.\n\nThe Grothendieck group K0\nIn the 19th century, Bernhard Riemann and his student Gustav Roch proved what is now known as the Riemann–Roch theorem.  If X is a Riemann surface, then the sets of meromorphic functions and meromorphic differential forms on X form vector spaces.  A line bundle on X determines subspaces of these vector spaces, and if X is projective, then these subspaces are finite dimensional.  The Riemann–Roch theorem states that the difference in dimensions between these subspaces is equal to the degree of the line bundle (a measure of twistedness) plus one minus the genus of X.  In the mid-20th century, the Riemann–Roch theorem was generalized by Friedrich Hirzebruch to all algebraic varieties.  In Hirzebruch's formulation, the Hirzebruch–Riemann–Roch theorem, the theorem became a statement about Euler characteristics: The Euler characteristic of a vector bundle on an algebraic variety (which is the alternating sum of the dimensions of its cohomology groups) equals the Euler characteristic of the trivial bundle plus a correction factor coming from characteristic classes of the vector bundle.  This is a generalization because on a projective Riemann surface, the Euler characteristic of a line bundle equals the difference in dimensions mentioned previously, the Euler characteristic of the trivial bundle is one minus the genus, and the only nontrivial characteristic class is the degree.\nThe subject of K-theory takes its name from a 1957 construction of Alexander Grothendieck which appeared in the Grothendieck–Riemann–Roch theorem, his generalization of Hirzebruch's theorem.  Let X be a smooth algebraic variety.  To each vector bundle on X, Grothendieck associates an invariant, its class.  The set of all classes on X was called K(X) from the German Klasse.  By definition, K(X) is a quotient of the free abelian group on isomorphism classes of vector bundles on X, and so it is an abelian group.  If the basis element corresponding to a vector bundle V is denoted [V], then for each short exact sequence of vector bundles:\n\n  \n    \n      \n        0\n        →\n        \n          V\n          ′\n        \n        →\n        V\n        →\n        \n          V\n          ″\n        \n        →\n        0\n        ,\n      \n    \n    {\\displaystyle 0\\to V'\\to V\\to V''\\to 0,}\n  \n\nGrothendieck imposed the relation [V] = [V′] + [V″].  These generators and relations define K(X), and they imply that it is the universal way to assign invariants to vector bundles in a way compatible with exact sequences.\nGrothendieck took the perspective that the Riemann–Roch theorem is a statement about morphisms of varieties, not the varieties themselves.  He proved that there is a homomorphism from K(X) to the Chow",
    "links": [
      "Abelian category",
      "Abelianization",
      "Abstract algebra",
      "Adams conjecture",
      "Adams operation",
      "Additive K-theory",
      "Alexander Grothendieck",
      "Algebraic number field",
      "Algebraic variety",
      "Allen Hatcher",
      "American Mathematical Society",
      "Annales Scientifiques de l'École Normale Supérieure",
      "Annals of Mathematics",
      "Armand Borel",
      "Astérisque",
      "Atiyah–Hirzebruch spectral sequence",
      "Barry Mazur",
      "Basic theorems in algebraic K-theory",
      "Bass' conjecture",
      "Bernhard Riemann",
      "Bibcode (identifier)",
      "Birkhäuser",
      "Bloch's formula",
      "Bloch-Kato conjecture",
      "Block matrix",
      "Brown–Gersten spectral sequence",
      "Bulletin de la Société Mathématique de France",
      "Bulletin of the American Mathematical Society",
      "C. T. C. Wall",
      "Cambridge University",
      "Cambridge University Press",
      "Cartesian product",
      "Cell complex",
      "Central simple algebra",
      "Centre of a group",
      "Chapman and Hall",
      "Characteristic class",
      "Charles Weibel",
      "Chern character",
      "Chern class",
      "Chevalley group",
      "Chow group",
      "Class field theory",
      "Class group",
      "Classifying space",
      "Clutching construction",
      "Coherent sheaf",
      "Commutative ring",
      "Commutator subgroup",
      "Compact topological space"
    ],
    "categories": [
      "Category:Algebraic K-theory",
      "Category:Algebraic geometry",
      "Category:Articles with short description",
      "Category:CS1 French-language sources (fr)",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Algebraic topology (object)": {
    "title": "Algebraic topology (object)",
    "url": "https://en.wikipedia.org/wiki/Algebraic_topology_(object)",
    "summary": "In mathematics, the algebraic topology on the set of group representations from G to a topological group H is the topology of pointwise convergence, i.e. pi converges to p if the limit of pi(g) = p(g) for every g in G.\nThis terminology is often used in the case of the algebraic topology on the set of discrete, faithful representations of a Kleinian group into PSL(2,C).  Another topology, the geometric topology (also called the Chabauty topology), can be put on the set of images of the representations, and its closure can include extra Kleinian groups that are not images of points in the closure in the algebraic topology.  This fundamental distinction is behind the phenomenon of hyperbolic Dehn surgery and plays an important role in the general theory of hyperbolic 3-manifolds.",
    "content": "In mathematics, the algebraic topology on the set of group representations from G to a topological group H is the topology of pointwise convergence, i.e. pi converges to p if the limit of pi(g) = p(g) for every g in G.\nThis terminology is often used in the case of the algebraic topology on the set of discrete, faithful representations of a Kleinian group into PSL(2,C).  Another topology, the geometric topology (also called the Chabauty topology), can be put on the set of images of the representations, and its closure can include extra Kleinian groups that are not images of points in the closure in the algebraic topology.  This fundamental distinction is behind the phenomenon of hyperbolic Dehn surgery and plays an important role in the general theory of hyperbolic 3-manifolds.\n\nReferences\nWilliam Thurston, The geometry and topology of 3-manifolds, Princeton lecture notes (1978–1981).",
    "links": [
      "Algebra",
      "Chabauty topology",
      "Discrete group",
      "Faithful representation",
      "Geometric topology (object)",
      "Hyperbolic 3-manifold",
      "Hyperbolic Dehn surgery",
      "Kleinian group",
      "Mathematics",
      "PSL(2,C)",
      "Topological group",
      "William Thurston",
      "Talk:Algebraic topology (object)",
      "Wikipedia:Articles with a single source",
      "Wikipedia:Stub",
      "Template:Algebra-stub",
      "Template talk:Algebra-stub",
      "Help:Referencing for beginners"
    ],
    "categories": [
      "Category:3-manifolds",
      "Category:Algebra stubs",
      "Category:Algebraic topology",
      "Category:All articles needing additional references",
      "Category:All stub articles",
      "Category:Articles needing additional references from May 2024"
    ]
  },
  "Blakers–Massey theorem": {
    "title": "Blakers–Massey theorem",
    "url": "https://en.wikipedia.org/wiki/Blakers%E2%80%93Massey_theorem",
    "summary": "In mathematics, the first Blakers–Massey theorem, named after Albert Blakers and William S. Massey, gave vanishing conditions for certain triad homotopy groups of spaces.",
    "content": "In mathematics, the first Blakers–Massey theorem, named after Albert Blakers and William S. Massey, gave vanishing conditions for certain triad homotopy groups of spaces.\n\nDescription of the result\nThis connectivity result may be expressed more precisely, as follows. Suppose X is a topological space which is the pushout of the diagram\n\n  \n    \n      \n        A\n        \n          \n            ←\n            \n               \n              f\n               \n            \n          \n        \n        C\n        \n          \n            →\n            \n               \n              g\n               \n            \n          \n        \n        B\n      \n    \n    {\\displaystyle A{\\xleftarrow {\\ f\\ }}C{\\xrightarrow {\\ g\\ }}B}\n  \n,\nwhere f is an m-connected map and g is n-connected. Then the map of pairs\n\n  \n    \n      \n        (\n        A\n        ,\n        C\n        )\n        →\n        (\n        X\n        ,\n        B\n        )\n      \n    \n    {\\displaystyle (A,C)\\rightarrow (X,B)}\n  \n\ninduces an isomorphism in relative homotopy groups in degrees \n  \n    \n      \n        k\n        ≤\n        (\n        m\n        +\n        n\n        −\n        1\n        )\n      \n    \n    {\\displaystyle k\\leq (m+n-1)}\n  \n and a surjection in the next degree.\nHowever the third paper of Blakers and Massey in this area determines the critical, i.e., first non-zero, triad homotopy group as a tensor product, under a number of assumptions, including some simple connectivity. This condition and some dimension conditions were relaxed in work of Ronald Brown and Jean-Louis Loday. The algebraic result implies the connectivity result, since a tensor product is zero if one of the factors is zero. In the non simply connected case, one has to use the nonabelian tensor product of Brown and Loday.\nThe triad connectivity result can be expressed in a number of other ways, for example, it says that the pushout square above behaves like a homotopy pullback up to dimension \n  \n    \n      \n        m\n        +\n        n\n      \n    \n    {\\displaystyle m+n}\n  \n.\n\nGeneralization to higher toposes\nThe generalization of the connectivity part of the theorem from traditional homotopy theory to any other infinity-topos with an infinity-site of definition was given by Charles Rezk in 2010.\n\nFully formal proof\nIn 2013 a fairly short, fully formal proof using homotopy type theory as a mathematical foundation and an Agda variant as a proof assistant was announced by Peter LeFanu Lumsdaine; this became Theorem 8.10.2 of Homotopy Type Theory – Univalent Foundations of Mathematics. This induces an internal proof for any infinity-topos (i.e. without reference to a site of definition); in particular, it gives a new proof of the original result.\n\nReferences\nExternal links\nBlakers–Massey theorem at the nLab\ntom Dieck, Tammo (2008). Algebraic Topology. EMS Textbooks in Mathematics. European Mathematical Society. Theorem 6.4.1",
    "links": [
      "Agda (programming language)",
      "Albert Blakers",
      "Allen Hatcher",
      "Annals of Mathematics",
      "Bibcode (identifier)",
      "Charles Rezk",
      "Doi (identifier)",
      "European Mathematical Society",
      "Excisive triad",
      "Foundations of mathematics",
      "Homotopy group",
      "Homotopy pullback",
      "Homotopy type theory",
      "Infinity-site",
      "Infinity-topos",
      "Institute for Advanced Study",
      "Isomorphism",
      "JSTOR (identifier)",
      "Jean-Louis Loday",
      "MR (identifier)",
      "N-connected space",
      "NLab",
      "PMC (identifier)",
      "PMID (identifier)",
      "Peter LeFanu Lumsdaine",
      "Proceedings of the London Mathematical Society",
      "Proceedings of the National Academy of Sciences of the United States of America",
      "Proof assistant",
      "Pushout (category theory)",
      "Ronald Brown (mathematician)",
      "Simply connected space",
      "Tammo tom Dieck",
      "Tensor product of modules",
      "Topological space",
      "William S. Massey"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Short description matches Wikidata",
      "Category:Theorems in algebraic topology"
    ]
  },
  "Borsuk–Ulam theorem": {
    "title": "Borsuk–Ulam theorem",
    "url": "https://en.wikipedia.org/wiki/Borsuk%E2%80%93Ulam_theorem",
    "summary": "Informally, the Borsuk–Ulam theorem states that if one makes a \"balloon animal\" (or any arbitrarily distorted shape) out of a spherical balloon, and then squash it into a plane (letting the air out somehow), at least one pair of points that were on opposite sides of the original sphere will be mapped to the same place.\nFormally, the theorem states that every continuous function from an n-sphere into n-dimensional Euclidean space must map some pair of antipodal points to the same point. Two points on a sphere are called antipodal if they lie in exactly opposite directions from the center—like the North and South Poles.\nMore compactly: if \n  \n    \n      \n        f\n        :\n        \n          S\n          \n            n\n          \n        \n        →\n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle f:S^{n}\\to \\mathbb {R} ^{n}}\n  \n is continuous then there exists an \n  \n    \n      \n        x\n        ∈\n        \n         ",
    "content": "Informally, the Borsuk–Ulam theorem states that if one makes a \"balloon animal\" (or any arbitrarily distorted shape) out of a spherical balloon, and then squash it into a plane (letting the air out somehow), at least one pair of points that were on opposite sides of the original sphere will be mapped to the same place.\nFormally, the theorem states that every continuous function from an n-sphere into n-dimensional Euclidean space must map some pair of antipodal points to the same point. Two points on a sphere are called antipodal if they lie in exactly opposite directions from the center—like the North and South Poles.\nMore compactly: if \n  \n    \n      \n        f\n        :\n        \n          S\n          \n            n\n          \n        \n        →\n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle f:S^{n}\\to \\mathbb {R} ^{n}}\n  \n is continuous then there exists an \n  \n    \n      \n        x\n        ∈\n        \n          S\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle x\\in S^{n}}\n  \n such that:  \n  \n    \n      \n        f\n        (\n        −\n        x\n        )\n        =\n        f\n        (\n        x\n        )\n      \n    \n    {\\displaystyle f(-x)=f(x)}\n  \n.\nThe case \n  \n    \n      \n        n\n        =\n        1\n      \n    \n    {\\displaystyle n=1}\n  \n can be illustrated by saying that there always exist a pair of opposite points on the Earth's equator with the same temperature. The same is true for any circle. This assumes the temperature varies continuously in space, which is, however, not always the case.\nThe case \n  \n    \n      \n        n\n        =\n        2\n      \n    \n    {\\displaystyle n=2}\n  \n is often illustrated by saying that at any moment, there is always a pair of antipodal points on the Earth's surface with equal temperatures and equal barometric pressures, assuming that both parameters vary continuously in space.  \nThe Borsuk–Ulam theorem has several equivalent statements in terms of odd functions. Recall that \n  \n    \n      \n        \n          S\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle S^{n}}\n  \n is the n-sphere and \n  \n    \n      \n        \n          B\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle B^{n}}\n  \n is the n-ball:\n\nIf \n  \n    \n      \n        g\n        :\n        \n          S\n          \n            n\n          \n        \n        →\n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle g:S^{n}\\to \\mathbb {R} ^{n}}\n  \n is a continuous odd function, then there exists an \n  \n    \n      \n        x\n        ∈\n        \n          S\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle x\\in S^{n}}\n  \n such that:  \n  \n    \n      \n        g\n        (\n        x\n        )\n        =\n        0\n      \n    \n    {\\displaystyle g(x)=0}\n  \n.\nIf \n  \n    \n      \n        g\n        :\n        \n          B\n          \n            n\n          \n        \n        →\n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle g:B^{n}\\to \\mathbb {R} ^{n}}\n  \n is a continuous function which is odd on \n  \n    \n      \n        \n          S\n          \n            n\n            −\n            1\n          \n        \n      \n    \n    {\\displaystyle S^{n-1}}\n  \n (the boundary of \n  \n    \n      \n        \n          B\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle B^{n}}\n  \n), then there exists an \n  \n    \n      \n        x\n        ∈\n        \n          B\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle x\\in B^{n}}\n  \n such that:  \n  \n    \n      \n        g\n        (\n        x\n        )\n        =\n        0\n      \n    \n    {\\displaystyle g(x)=0}\n  \n.\n\nHistory\nAccording to Matoušek (2003, p. 25), the first historical mention of the statement of the Borsuk–Ulam theorem appears in Lyusternik & Shnirel'man (1930).  The first proof was given by Karol Borsuk (1933), where the formulation of the problem was attributed to Stanisław Ulam.  Since then, many alternative proofs have been found by various authors, as collected by Steinlein (1985).\n\nEquivalent statements\nThe following statements are equivalent to the Borsuk–Ulam theorem.\n\nWith odd functions\nA function \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n  \n is called odd (aka antipodal or antipode-preserving) if for every \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n, \n  \n    \n      \n        g\n        (\n        −\n        x\n        )\n        =\n        −\n        g\n        (\n        x\n        )\n      \n    \n    {\\displaystyle g(-x)=-g(x)}\n  \n.\nThe Borsuk–Ulam theorem is equivalent to each of the following statements:\n(1) Each continuous odd function \n  \n    \n      \n        \n          S\n          \n            n\n          \n        \n        →\n        \n          \n            R\n          \n          \n            n\n",
    "links": [
      "Algebraic topology",
      "Annals of Mathematics",
      "Antipodal point",
      "Balloon animal",
      "Bibcode (identifier)",
      "Brouwer fixed-point theorem",
      "CiteSeerX (identifier)",
      "Cohomology",
      "Compact space",
      "Continuous function",
      "Covering space",
      "Degree of a continuous mapping",
      "Doi (identifier)",
      "Earth",
      "Encyclopedia of Mathematics",
      "Euclidean space",
      "European Mathematical Society",
      "Francis Su",
      "Fundamenta Mathematicae",
      "Fundamental group",
      "GF(2)",
      "Ham sandwich theorem",
      "Hdl (identifier)",
      "Homeomorphic",
      "Hurewicz theorem",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "Imre Bárány",
      "Intermediate value theorem",
      "JSTOR (identifier)",
      "Jiří Matoušek (mathematician)",
      "Journal of Combinatorial Theory",
      "Kakutani's theorem (geometry)",
      "Karol Borsuk",
      "Knaster–Kuratowski–Mazurkiewicz lemma",
      "Lazar Lyusternik",
      "Lev Schnirelmann",
      "Lusternik–Schnirelmann theorem",
      "MR (identifier)",
      "N-ball",
      "N-sphere",
      "Necklace splitting problem",
      "Odd function",
      "Real projective space",
      "Riemannian manifold",
      "Ring homomorphism",
      "Sperner's lemma",
      "Sphere",
      "Stanisław Ulam",
      "The American Mathematical Monthly"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1 German-language sources (de)",
      "Category:Combinatorics",
      "Category:Fixed-point theorems",
      "Category:Short description is different from Wikidata",
      "Category:Theorems in algebraic topology",
      "Category:Theorems in topology",
      "Category:Theory of continuous functions"
    ]
  },
  "Brouwer fixed point theorem": {
    "title": "Brouwer fixed-point theorem",
    "url": "https://en.wikipedia.org/wiki/Brouwer_fixed-point_theorem",
    "summary": "Brouwer's fixed-point theorem is a fixed-point theorem in topology, named after L. E. J. (Bertus) Brouwer. It states that for any continuous function \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n mapping a nonempty compact convex set to itself, there is a point \n  \n    \n      \n        \n          x\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle x_{0}}\n  \n such that \n  \n    \n      \n        f\n        (\n        \n          x\n          \n            0\n          \n        \n        )\n        =\n        \n          x\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle f(x_{0})=x_{0}}\n  \n. The simplest forms of Brouwer's theorem are for continuous functions \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n from a closed interval \n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n  \n in the real numbers to itself or from a closed disk \n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n  \n to itself.",
    "content": "Brouwer's fixed-point theorem is a fixed-point theorem in topology, named after L. E. J. (Bertus) Brouwer. It states that for any continuous function \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n mapping a nonempty compact convex set to itself, there is a point \n  \n    \n      \n        \n          x\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle x_{0}}\n  \n such that \n  \n    \n      \n        f\n        (\n        \n          x\n          \n            0\n          \n        \n        )\n        =\n        \n          x\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle f(x_{0})=x_{0}}\n  \n. The simplest forms of Brouwer's theorem are for continuous functions \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n from a closed interval \n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n  \n in the real numbers to itself or from a closed disk \n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n  \n to itself. A more general form than the latter is for continuous functions from a nonempty convex compact subset \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n of Euclidean space to itself.\nAmong hundreds of fixed-point theorems, Brouwer's is particularly well known, due in part to its use across numerous fields of mathematics. In its original field, this result is one of the key theorems characterizing the topology of Euclidean spaces, along with the Jordan curve theorem, the hairy ball theorem, the invariance of dimension and the Borsuk–Ulam theorem. This gives it a place among the fundamental theorems of topology. The theorem is also used for proving deep results about differential equations and is covered in most introductory courses on differential geometry. It appears in unlikely fields such as game theory. In economics, Brouwer's fixed-point theorem and its extension, the Kakutani fixed-point theorem, play a central role in the proof of existence of general equilibrium in market economies as developed in the 1950s by economics Nobel prize winners Kenneth Arrow and Gérard Debreu.\nThe theorem was first studied in view of work on differential equations by the French mathematicians around Henri Poincaré and Charles Émile Picard. Proving results such as the Poincaré–Bendixson theorem requires the use of topological methods. This work at the end of the 19th century opened into several successive versions of the theorem. The case of differentiable mappings of the n-dimensional closed ball was first proved in 1910 by Jacques Hadamard and the general case for continuous mappings by Brouwer in 1911.\n\nStatement\nThe theorem has several formulations, depending on the context in which it is used and its degree of generalization. The simplest is sometimes given as follows:\n\nIn the plane\nEvery continuous function from a closed disk to itself has at least one fixed point.\nThis can be generalized to an arbitrary finite dimension:\n\nIn Euclidean space\nEvery continuous function from a closed ball of a Euclidean space into itself has a fixed point.\nA slightly more general version is as follows:\n\nConvex compact set\nEvery continuous function from a nonempty convex compact subset K of a Euclidean space to K itself has a fixed point.\nAn even more general form is better known under a different name:\n\nSchauder fixed point theorem\nEvery continuous function from a nonempty convex compact subset K of a Banach space to K itself has a fixed point.\n\nImportance of the pre-conditions\nThe theorem holds only for functions that are endomorphisms (functions that have the same set as the domain and codomain) and for nonempty sets that are compact (thus, in particular, bounded and closed) and convex (or homeomorphic to convex). The following examples show why the pre-conditions are important.\n\nThe function f as an endomorphism\nConsider the function\n\n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        x\n        +\n        1\n      \n    \n    {\\displaystyle f(x)=x+1}\n  \n\nwith domain [-1,1]. The range of the function is [0,2]. Thus, f is not an endomorphism.\n\nBoundedness\nConsider the function\n\n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        x\n        +\n        1\n        ,\n      \n    \n    {\\displaystyle f(x)=x+1,}\n  \n\nwhich is a continuous function from \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n to itself. As it shifts every point to the right, it cannot have a fixed point. The space \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n is convex and closed, but not bounded.\n\nClosedness\nConsider the function\n\n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        \n          \n            \n              x\n              +\n              1\n            \n            2\n          \n        \n        ,\n      \n    \n    {\\displaystyle f(x)={\\frac {x+1}{2}},}\n  \n\nwhich is a continuous function from the open interval \n  \n ",
    "links": [
      "Algebraic topology",
      "Amer. Math. Monthly",
      "American Mathematical Society",
      "Approximation theory",
      "Arrow–Debreu model",
      "Arte",
      "Banach fixed-point theorem",
      "Banach space",
      "Bibcode (identifier)",
      "Bijective",
      "Birkhäuser",
      "Borsuk-Ulam theorem",
      "Borsuk–Ulam theorem",
      "Boundary (topology)",
      "Bounded set",
      "Bump function",
      "Cambridge University Press",
      "Cauchy–Lipschitz theorem",
      "Central Limit Theorem",
      "Charles Émile Picard",
      "Closed ball",
      "Closed set",
      "Codomain",
      "Compact space",
      "Compactness",
      "Computability",
      "Connected space",
      "Constructive proof",
      "Constructive set theory",
      "Constructivism (mathematics)",
      "Continuous function",
      "Continuous function (topology)",
      "Contraction mapping",
      "Convex set",
      "Convolution",
      "Cut-the-knot",
      "Cyclic group",
      "David Gale",
      "De Rham cohomology",
      "Degree of a continuous mapping",
      "Determinacy",
      "Differential equation",
      "Differential geometry",
      "Differential topology",
      "Disk (mathematics)",
      "Doi (identifier)",
      "Encyclopedia of Mathematics",
      "Encyclopædia Universalis",
      "Euclidean space",
      "European Mathematical Society"
    ],
    "categories": [
      "Category:All articles with unsourced statements",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from September 2018",
      "Category:CS1 French-language sources (fr)",
      "Category:CS1 German-language sources (de)",
      "Category:CS1 Russian-language sources (ru)",
      "Category:CS1 errors: ISBN date",
      "Category:Fixed-point theorems",
      "Category:Short description is different from Wikidata",
      "Category:Theorems in convex geometry"
    ]
  },
  "Cellular approximation theorem": {
    "title": "Cellular approximation theorem",
    "url": "https://en.wikipedia.org/wiki/Cellular_approximation_theorem",
    "summary": "In algebraic topology, the cellular approximation theorem states that a map between CW-complexes can always be taken to be of a specific type. Concretely, if X and Y are CW-complexes, and f : X → Y is a continuous map, then f is said to be cellular, if f takes the n-skeleton of X to the n-skeleton of Y for all n, i.e. if \n  \n    \n      \n        f\n        (\n        \n          X\n          \n            n\n          \n        \n        )\n        ⊆\n        \n          Y\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle f(X^{n})\\subseteq Y^{n}}\n  \n for all n. The content of the cellular approximation theorem is then that any continuous map f : X → Y between CW-complexes X and Y is homotopic to a cellular map, and if f is already cellular on a subcomplex A of X, then we can furthermore choose the homotopy to be stationary on A. From an algebraic topological viewpoint, any map between CW-complexes can thus be taken to be cellular.",
    "content": "In algebraic topology, the cellular approximation theorem states that a map between CW-complexes can always be taken to be of a specific type. Concretely, if X and Y are CW-complexes, and f : X → Y is a continuous map, then f is said to be cellular, if f takes the n-skeleton of X to the n-skeleton of Y for all n, i.e. if \n  \n    \n      \n        f\n        (\n        \n          X\n          \n            n\n          \n        \n        )\n        ⊆\n        \n          Y\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle f(X^{n})\\subseteq Y^{n}}\n  \n for all n. The content of the cellular approximation theorem is then that any continuous map f : X → Y between CW-complexes X and Y is homotopic to a cellular map, and if f is already cellular on a subcomplex A of X, then we can furthermore choose the homotopy to be stationary on A. From an algebraic topological viewpoint, any map between CW-complexes can thus be taken to be cellular.\n\nIdea of proof\nThe proof can be given by induction after n, with the statement that f is cellular on the skeleton Xn. For the base case n=0, notice that every path-component of Y must contain a 0-cell. The image under f of a 0-cell of X can thus be connected to a 0-cell of Y by a path, but this gives a homotopy from f to a map which is cellular on the 0-skeleton of X.\nAssume inductively that f is cellular on the (n − 1)-skeleton of X, and let en  be an n-cell of X. The closure of en is compact in X, being the image of the characteristic map of the cell, and hence the image of the closure of en under f is also compact in Y. Then it is a general result of CW-complexes that any compact subspace of a CW-complex meets (that is, intersects non-trivially) only finitely many cells of the complex. Thus f(en) meets at most finitely many cells of Y, so we can take \n  \n    \n      \n        \n          e\n          \n            k\n          \n        \n        ⊆\n        Y\n      \n    \n    {\\displaystyle e^{k}\\subseteq Y}\n  \n to be a cell of highest dimension meeting f(en). If \n  \n    \n      \n        k\n        ≤\n        n\n      \n    \n    {\\displaystyle k\\leq n}\n  \n, the map f is already cellular on en, since in this case only cells of the n-skeleton of Y meets f(en), so we may assume that k > n. It is then a technical, non-trivial result (see Hatcher) that the restriction of f to \n  \n    \n      \n        \n          X\n          \n            n\n            −\n            1\n          \n        \n        ∪\n        \n          e\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle X^{n-1}\\cup e^{n}}\n  \n can be homotoped relative to Xn-1 to a map missing a point p ∈ ek. Since Yk − {p} deformation retracts onto the subspace Yk-ek, we can further homotope the restriction of f to \n  \n    \n      \n        \n          X\n          \n            n\n            −\n            1\n          \n        \n        ∪\n        \n          e\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle X^{n-1}\\cup e^{n}}\n  \n to a map, say, g, with the property that g(en) misses the cell ek of Y, still relative to Xn-1. Since f(en) met only finitely many cells of Y to begin with, we can repeat this process finitely many times to make \n  \n    \n      \n        f\n        (\n        \n          e\n          \n            n\n          \n        \n        )\n      \n    \n    {\\displaystyle f(e^{n})}\n  \n miss all cells of Y of dimension larger than n.\nWe repeat this process for every n-cell of X, fixing cells of the subcomplex A on which f is already cellular, and we thus obtain a homotopy (relative to the (n − 1)-skeleton of X and the n-cells of A) of the restriction of f to Xn to a map cellular on all cells of X of dimension at most n. Using then the homotopy extension property to extend this to a homotopy on all of X, and patching these homotopies together, will finish the proof. For details, consult Hatcher.\n\nApplications\nSome homotopy groups\nThe cellular approximation theorem can be used to immediately calculate some homotopy groups. In particular, if \n  \n    \n      \n        n\n        <\n        k\n        ,\n      \n    \n    {\\displaystyle n<k,}\n  \n then \n  \n    \n      \n        \n          π\n          \n            n\n          \n        \n        (\n        \n          S\n          \n            k\n          \n        \n        )\n        =\n        0.\n      \n    \n    {\\displaystyle \\pi _{n}(S^{k})=0.}\n  \n Give \n  \n    \n      \n        \n          S\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle S^{n}}\n  \n and \n  \n    \n      \n        \n          S\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle S^{k}}\n  \n their canonical CW-structure, with one 0-cell each, and with one n-cell for \n  \n    \n      \n        \n          S\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle S^{n}}\n  \n and one k-cell for \n  \n    \n      \n        \n          S\n          \n            k\n          \n        \n        .\n      \n    \n    {\\displaystyle S^{k}.}\n  \n Any base-poi",
    "links": [
      "Algebraic topology",
      "Base-point",
      "CW-complex",
      "CW-pair",
      "CW complex",
      "Cambridge University Press",
      "Canonical form",
      "Closure (topology)",
      "Compact set",
      "Deformation retraction",
      "Function (mathematics)",
      "Homotopy",
      "Homotopy extension property",
      "Homotopy group",
      "ISBN (identifier)",
      "Image (mathematics)",
      "Intersection (set theory)",
      "Map (mathematics)",
      "Mathematical induction",
      "N-connected",
      "N-skeleton",
      "Non-trivial",
      "Path-connected",
      "Weak equivalence (homotopy theory)"
    ],
    "categories": [
      "Category:Theorems in algebraic topology"
    ]
  },
  "Chain (algebraic topology)": {
    "title": "Chain (algebraic topology)",
    "url": "https://en.wikipedia.org/wiki/Chain_(algebraic_topology)",
    "summary": "In algebraic topology, a k-chain\nis a formal linear combination of the k-cells in a cell complex. In simplicial complexes (respectively, cubical complexes), k-chains are combinations of k-simplices (respectively, k-cubes), but not necessarily connected. Chains are used in homology; the elements of a homology group are equivalence classes of chains.",
    "content": "In algebraic topology, a k-chain\nis a formal linear combination of the k-cells in a cell complex. In simplicial complexes (respectively, cubical complexes), k-chains are combinations of k-simplices (respectively, k-cubes), but not necessarily connected. Chains are used in homology; the elements of a homology group are equivalence classes of chains.\n\nDefinition\nFor a simplicial complex \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n, the group \n  \n    \n      \n        \n          C\n          \n            n\n          \n        \n        (\n        X\n        )\n      \n    \n    {\\displaystyle C_{n}(X)}\n  \n of \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n-chains of \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is given by:\n\n  \n    \n      \n        \n          C\n          \n            n\n          \n        \n        (\n        X\n        )\n        =\n        \n          {\n          \n            \n              ∑\n              \n                i\n              \n            \n            \n              m\n              \n                i\n              \n            \n            \n              σ\n              \n                i\n              \n            \n            \n              |\n            \n            \n              m\n              \n                i\n              \n            \n            ∈\n            \n              Z\n            \n          \n          }\n        \n      \n    \n    {\\displaystyle C_{n}(X)=\\left\\{\\sum \\limits _{i}m_{i}\\sigma _{i}|m_{i}\\in \\mathbb {Z} \\right\\}}\n  \n\nwhere \n  \n    \n      \n        \n          σ\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle \\sigma _{i}}\n  \n are singular \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n-simplices of \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n. Note that an element in \n  \n    \n      \n        \n          C\n          \n            n\n          \n        \n        (\n        X\n        )\n      \n    \n    {\\displaystyle C_{n}(X)}\n  \n is not necessarily a connected simplicial complex.\n\nIntegration on chains\nIntegration is defined on chains by taking the linear combination of integrals over the simplices in the chain with coefficients (which are typically integers).\nThe set of all k-chains forms a group and the sequence of these groups is called a chain complex.\n\nBoundary operator on chains\n\nThe boundary of a chain is the linear combination of boundaries of the simplices in the chain.  The boundary of a k-chain is a (k−1)-chain. Note that the boundary of a simplex is not a simplex, but a chain with coefficients 1 or −1 – thus chains are the closure of simplices under the boundary operator.\nExample 1: The boundary of a path is the formal difference of its endpoints: it is a telescoping sum. To illustrate, if the 1-chain \n  \n    \n      \n        c\n        =\n        \n          t\n          \n            1\n          \n        \n        +\n        \n          t\n          \n            2\n          \n        \n        +\n        \n          t\n          \n            3\n          \n        \n        \n      \n    \n    {\\displaystyle c=t_{1}+t_{2}+t_{3}\\,}\n  \n is a path from point \n  \n    \n      \n        \n          v\n          \n            1\n          \n        \n        \n      \n    \n    {\\displaystyle v_{1}\\,}\n  \n to point \n  \n    \n      \n        \n          v\n          \n            4\n          \n        \n        \n      \n    \n    {\\displaystyle v_{4}\\,}\n  \n, where \n\n  \n    \n      \n        \n          t\n          \n            1\n          \n        \n        =\n        [\n        \n          v\n          \n            1\n          \n        \n        ,\n        \n          v\n          \n            2\n          \n        \n        ]\n        \n      \n    \n    {\\displaystyle t_{1}=[v_{1},v_{2}]\\,}\n  \n,\n\n  \n    \n      \n        \n          t\n          \n            2\n          \n        \n        =\n        [\n        \n          v\n          \n            2\n          \n        \n        ,\n        \n          v\n          \n            3\n          \n        \n        ]\n        \n      \n    \n    {\\displaystyle t_{2}=[v_{2},v_{3}]\\,}\n  \n and\n\n  \n    \n      \n        \n          t\n          \n            3\n          \n        \n        =\n        [\n        \n          v\n          \n            3\n          \n        \n        ,\n        \n          v\n          \n            4\n          \n        \n        ]\n        \n      \n    \n    {\\displaystyle t_{3}=[v_{3},v_{4}]\\,}\n  \n are its constituent 1-simplices, then\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  ∂\n                  \n                    1\n                  \n                \n                c\n              \n              \n                \n                =\n                \n                  ∂\n                  \n                    1\n                  \n                \n                (\n                \n                  t\n                  \n                    1\n                  \n                \n                +\n                \n                  ",
    "links": [
      "Algebraic topology",
      "Allen Hatcher",
      "CW complex",
      "Cambridge University Press",
      "Chain (order theory)",
      "Chain complex",
      "Cubical complex",
      "Differential geometry",
      "Doi (identifier)",
      "Exterior derivative",
      "Formal linear combination",
      "Homology (mathematics)",
      "ISBN (identifier)",
      "K-cell (mathematics)",
      "MR (identifier)",
      "OCLC (identifier)",
      "Order theory",
      "Path (topology)",
      "Polygonal curve",
      "Simplicial complex",
      "Singular homology",
      "Stokes' theorem",
      "Telescoping sum"
    ],
    "categories": [
      "Category:Algebraic topology",
      "Category:Articles with short description",
      "Category:Integration on manifolds",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Cohomology": {
    "title": "Cohomology",
    "url": "https://en.wikipedia.org/wiki/Cohomology",
    "summary": "In mathematics, specifically in homology theory and algebraic topology, cohomology is a general term for a sequence of abelian groups, usually one associated with a topological space, often defined from a cochain complex. Cohomology can be viewed as a method of assigning richer algebraic invariants to a space than homology. Some versions of cohomology arise by dualizing the construction of homology. In other words, cochains are functions on the group of chains in homology theory.\nFrom its start in topology, this idea became a dominant method in the mathematics of the second half of the twentieth century. From the initial idea of homology as a method of constructing algebraic invariants of topological spaces, the range of applications of homology and cohomology theories has spread throughout geometry and algebra. The terminology tends to hide the fact that cohomology, a contravariant theory, is more natural than homology in many applications. At a basic level, this has to do with functi",
    "content": "In mathematics, specifically in homology theory and algebraic topology, cohomology is a general term for a sequence of abelian groups, usually one associated with a topological space, often defined from a cochain complex. Cohomology can be viewed as a method of assigning richer algebraic invariants to a space than homology. Some versions of cohomology arise by dualizing the construction of homology. In other words, cochains are functions on the group of chains in homology theory.\nFrom its start in topology, this idea became a dominant method in the mathematics of the second half of the twentieth century. From the initial idea of homology as a method of constructing algebraic invariants of topological spaces, the range of applications of homology and cohomology theories has spread throughout geometry and algebra. The terminology tends to hide the fact that cohomology, a contravariant theory, is more natural than homology in many applications. At a basic level, this has to do with functions and pullbacks in geometric situations: given spaces \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n and \n  \n    \n      \n        Y\n      \n    \n    {\\displaystyle Y}\n  \n, and some function \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n on \n  \n    \n      \n        Y\n      \n    \n    {\\displaystyle Y}\n  \n, for any mapping \n  \n    \n      \n        f\n        :\n        X\n        →\n        Y\n      \n    \n    {\\displaystyle f:X\\to Y}\n  \n, composition with \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n gives rise to a function \n  \n    \n      \n        F\n        ∘\n        f\n      \n    \n    {\\displaystyle F\\circ f}\n  \n on \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n. The most important cohomology theories have a product, the cup product, which gives them a ring structure.  Because of this feature, cohomology is usually a stronger invariant than homology.\n\nSingular cohomology\nSingular cohomology is a powerful invariant in topology, associating a graded-commutative ring with any topological space. Every continuous map \n  \n    \n      \n        f\n        :\n        X\n        →\n        Y\n      \n    \n    {\\displaystyle f:X\\to Y}\n  \n determines a homomorphism from the cohomology ring of \n  \n    \n      \n        Y\n      \n    \n    {\\displaystyle Y}\n  \n to that of \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n; this puts strong restrictions on the possible maps from \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n to \n  \n    \n      \n        Y\n      \n    \n    {\\displaystyle Y}\n  \n. Unlike more subtle invariants such as homotopy groups, the cohomology ring tends to be computable in practice for spaces of interest.\nFor a topological space \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n, the definition of singular cohomology starts with the singular chain complex:\n\n  \n    \n      \n        ⋯\n        →\n        \n          C\n          \n            i\n            +\n            1\n          \n        \n        \n          \n            \n              \n                →\n              \n              \n                \n                  ∂\n                  \n                    i\n                    +\n                    1\n                  \n                \n              \n            \n          \n        \n        \n          C\n          \n            i\n          \n        \n        \n          \n            \n              \n                →\n              \n              \n                \n                  ∂\n                  \n                    i\n                  \n                \n              \n            \n          \n        \n         \n        \n          C\n          \n            i\n            −\n            1\n          \n        \n        →\n        ⋯\n      \n    \n    {\\displaystyle \\cdots \\to C_{i+1}{\\stackrel {\\partial _{i+1}}{\\to }}C_{i}{\\stackrel {\\partial _{i}}{\\to }}\\ C_{i-1}\\to \\cdots }\n  \n\nBy definition, the singular homology of \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is the homology of this chain complex (the kernel of one homomorphism modulo the image of the previous one). In more detail, \n  \n    \n      \n        \n          C\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle C_{i}}\n  \n is the free abelian group on the set of continuous maps from the standard \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n-simplex to \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n (called \"singular \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n-simplices in \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n\"), and \n  \n    \n      \n        \n          ∂\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle \\partial _{i}}\n  \n is the \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n-th boundary homomorphism. The groups \n  \n    \n      \n        \n          C\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle C_{i}",
    "links": [
      "Abelian category",
      "Abelian group",
      "Abstract algebra",
      "Albrecht Dold",
      "Alexander Grothendieck",
      "Alexander duality",
      "Alexander–Spanier cohomology",
      "Algebraic K-theory",
      "Algebraic geometry",
      "Algebraic topology",
      "Algebraic varieties",
      "Allen Hatcher",
      "Andrey Kolmogorov",
      "André–Quillen cohomology",
      "Associative algebra",
      "BRST cohomology",
      "Banach fixed-point theorem",
      "Betti number",
      "Bilinear map",
      "Birkhäuser",
      "Bounded cohomology",
      "Brown–Peterson cohomology",
      "Bundle (mathematics)",
      "CW complex",
      "Cambridge University Press",
      "Cap product",
      "Cartesian square (category theory)",
      "Category (mathematics)",
      "Cellular homology",
      "Chain (algebraic topology)",
      "Chain homotopy",
      "Character (mathematics)",
      "Characteristic (algebra)",
      "Characteristic class",
      "Chern class",
      "Closed manifold",
      "Closed set",
      "Closed subset",
      "Cobordism",
      "Cochain complex",
      "Codimension",
      "Coherent sheaf cohomology",
      "Cohomology ring",
      "Cohomotopy group",
      "Combinatorial topology",
      "Commentarii Mathematici Helvetici",
      "Commutative ring",
      "Compact space",
      "Complex-oriented cohomology theory",
      "Complex analysis"
    ],
    "categories": [
      "Category:All Wikipedia articles written in American English",
      "Category:Articles with short description",
      "Category:CS1 errors: ISBN date",
      "Category:Cohomology theories",
      "Category:Short description is different from Wikidata",
      "Category:Use American English from January 2019"
    ]
  },
  "Continuity (topology)": {
    "title": "Continuous function",
    "url": "https://en.wikipedia.org/wiki/Continuous_function",
    "summary": "In mathematics, a continuous function is a function such that a small variation of the argument induces a small variation of the value of the function. This implies there are no abrupt changes in value, known as discontinuities. More precisely, a function is continuous if arbitrarily small changes in its value can be assured by restricting to sufficiently small changes of its argument. A discontinuous function is a function that is not continuous. Until the 19th century, mathematicians largely relied on intuitive notions of continuity and considered only continuous functions. The epsilon–delta definition of a limit was introduced to formalize the definition of continuity.\nContinuity is one of the core concepts of calculus and mathematical analysis, where arguments and values of functions are real and complex numbers. The concept has been generalized to functions between metric spaces and between topological spaces. The latter are the most general continuous functions, and their definit",
    "content": "In mathematics, a continuous function is a function such that a small variation of the argument induces a small variation of the value of the function. This implies there are no abrupt changes in value, known as discontinuities. More precisely, a function is continuous if arbitrarily small changes in its value can be assured by restricting to sufficiently small changes of its argument. A discontinuous function is a function that is not continuous. Until the 19th century, mathematicians largely relied on intuitive notions of continuity and considered only continuous functions. The epsilon–delta definition of a limit was introduced to formalize the definition of continuity.\nContinuity is one of the core concepts of calculus and mathematical analysis, where arguments and values of functions are real and complex numbers. The concept has been generalized to functions between metric spaces and between topological spaces. The latter are the most general continuous functions, and their definition is the basis of topology.\nA stronger form of continuity is uniform continuity. In order theory, especially in domain theory, a related concept of continuity is Scott continuity.\nAs an example, the function H(t) denoting the height of a growing flower at time t would be considered continuous. In contrast, the function M(t) denoting the amount of money in a bank account at time t would be considered discontinuous since it \"jumps\" at each point in time when money is deposited or withdrawn.\n\nHistory\nA form of the epsilon–delta definition of continuity was first given by Bernard Bolzano in 1817. Augustin-Louis Cauchy defined continuity of \n  \n    \n      \n        y\n        =\n        f\n        (\n        x\n        )\n      \n    \n    {\\displaystyle y=f(x)}\n  \n as follows: an infinitely small increment \n  \n    \n      \n        α\n      \n    \n    {\\displaystyle \\alpha }\n  \n of the independent variable x always produces an infinitely small change \n  \n    \n      \n        f\n        (\n        x\n        +\n        α\n        )\n        −\n        f\n        (\n        x\n        )\n      \n    \n    {\\displaystyle f(x+\\alpha )-f(x)}\n  \n of the dependent variable y (see e.g. Cours d'Analyse, p. 34). Cauchy defined infinitely small quantities in terms of variable quantities, and his definition of continuity closely parallels the infinitesimal definition used today (see microcontinuity). The formal definition and the distinction between pointwise continuity and uniform continuity were first given by Bolzano in the 1830s, but the work wasn't published until the 1930s. Like Bolzano, Karl Weierstrass denied continuity of a function at a point c unless it was defined at and on both sides of c, but Édouard Goursat allowed the function to be defined only at and on one side of c, and Camille Jordan allowed it even if the function was defined only at c. All three of those nonequivalent definitions of pointwise continuity are still in use. Eduard Heine provided the first published definition of uniform continuity in 1872, but based these ideas on lectures given by Peter Gustav Lejeune Dirichlet in 1854.\n\nReal functions\nDefinition\nA real function that is a function from real numbers to real numbers can be represented by a graph in the Cartesian plane; such a function is continuous if, roughly speaking, the graph is a single unbroken curve whose domain is the entire real line. A more mathematically rigorous definition is given below.\nContinuity of real functions is usually defined in terms of limits. A function f with variable x is continuous at the real number c, if the limit of \n  \n    \n      \n        f\n        (\n        x\n        )\n        ,\n      \n    \n    {\\displaystyle f(x),}\n  \n as x tends to c, is equal to \n  \n    \n      \n        f\n        (\n        c\n        )\n        .\n      \n    \n    {\\displaystyle f(c).}\n  \n\nThere are several different definitions of the (global) continuity of a function, which depend on the nature of its domain. \nA function is continuous on an open interval if the interval is contained in the function's domain and the function is continuous at every interval point. A function that is continuous on the interval \n  \n    \n      \n        (\n        −\n        ∞\n        ,\n        +\n        ∞\n        )\n      \n    \n    {\\displaystyle (-\\infty ,+\\infty )}\n  \n (the whole real line) is often called simply a continuous function; one also says that such a function is continuous everywhere. For example, all polynomial functions are continuous everywhere.\nA function is continuous on a semi-open or a closed interval; if the interval is contained in the domain of the function, the function is continuous at every interior point of the interval, and the value of the function at each endpoint that belongs to the interval is the limit of the values of the function when the variable tends to the endpoint from the interior of the interval. For example, the function \n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        \n          \n         ",
    "links": [
      "(ε, δ)-definition of limit",
      "0 (number)",
      "Abel's test",
      "Absolute continuity",
      "Absolute value",
      "Adequality",
      "Algebraic function",
      "Almost everywhere",
      "Alternating series",
      "Alternating series test",
      "Analytic function",
      "Antiderivative",
      "Approximate continuity",
      "Approximate limit",
      "Approximately continuous",
      "Arc length",
      "Argument of a function",
      "Arithmetico-geometric sequence",
      "Arithmetico–geometric sequence",
      "Asymptote",
      "Augustin-Louis Cauchy",
      "Axiom of countable choice",
      "Basis (topology)",
      "Bernard Bolzano",
      "Bernoulli number",
      "Bijection",
      "Bijective",
      "Binary relation",
      "Binomial series",
      "Binomial theorem",
      "Blumberg theorem",
      "Boolean-valued function",
      "Boolean function",
      "Bounded linear operator",
      "Brook Taylor",
      "Calculus",
      "Calculus of variations",
      "Calculus on Euclidean space",
      "Cambridge University Press",
      "Camille Jordan",
      "Cartesian coordinate system",
      "Category (mathematics)",
      "Category theory",
      "Cauchy",
      "Cauchy condensation test",
      "Cauchy sequence",
      "Chain rule",
      "Characterizations of the category of topological spaces",
      "CiteSeerX (identifier)",
      "Class (mathematics)"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Calculus",
      "Category:Commons category link is on Wikidata",
      "Category:Pages using sidebar with the child parameter",
      "Category:Short description is different from Wikidata",
      "Category:Theory of continuous functions",
      "Category:Types of functions"
    ]
  },
  "Continuum (topology)": {
    "title": "Continuum (topology)",
    "url": "https://en.wikipedia.org/wiki/Continuum_(topology)",
    "summary": "In the mathematical field of point-set topology, a continuum (plural: \"continua\") is a nonempty compact connected metric space, or, less frequently, a compact connected Hausdorff space. Continuum theory is the branch of topology devoted to the study of continua.",
    "content": "In the mathematical field of point-set topology, a continuum (plural: \"continua\") is a nonempty compact connected metric space, or, less frequently, a compact connected Hausdorff space. Continuum theory is the branch of topology devoted to the study of continua.\n\nDefinitions\nA continuum that contains more than one point is called nondegenerate.\nA subset A of a continuum X such that A itself is a continuum is called a subcontinuum of X. A space homeomorphic to a subcontinuum of the Euclidean plane R2 is called a planar continuum.\nA continuum X is homogeneous if for every two points x and y in X, there exists a homeomorphism h: X → X such that h(x) = y.\nA Peano continuum is a continuum that is locally connected at each point.\nAn indecomposable continuum is a continuum that cannot be represented as the union of two proper subcontinua. A continuum X is hereditarily indecomposable if every subcontinuum of X is indecomposable.\nThe dimension of a continuum usually means its topological dimension. A one-dimensional continuum is often called a curve.\n\nExamples\nAn arc is a space homeomorphic to the closed interval [0,1]. If h: [0,1] → X is a homeomorphism and h(0) = p and h(1) = q then p and q are called the endpoints of X; one also says that X is an arc from p to q. An arc is the simplest and most familiar type of a continuum. It is one-dimensional, arcwise connected, and locally connected.\nThe topologist's sine curve is a subset of the plane that is the union of the graph of the function f(x) = sin(1/x), 0 < x ≤ 1 with the segment −1 ≤ y ≤ 1 of the y-axis. It is a one-dimensional continuum that is not arcwise connected, and it is locally disconnected at the points along the y-axis.\nThe Warsaw circle is obtained by \"closing up\" the topologist's sine curve by an arc connecting (0,−1) and (1,sin(1)). It is a one-dimensional continuum whose homotopy groups are all trivial, but it is not a contractible space.\n\nAn  n-cell is a space homeomorphic to the closed ball in the Euclidean space Rn. It is contractible and is the simplest example of an n-dimensional continuum.\nAn  n-sphere is a space homeomorphic to the standard n-sphere in the (n + 1)-dimensional Euclidean space. It is an n-dimensional homogeneous continuum that is not contractible, and therefore different from an n-cell.\nThe Hilbert cube is an infinite-dimensional continuum.\nSolenoids are among the simplest examples of indecomposable homogeneous continua. They are neither arcwise connected nor locally connected.\nThe Sierpinski carpet, also known as the Sierpinski universal curve, is a one-dimensional planar Peano continuum that contains a homeomorphic image of any one-dimensional planar continuum.\nThe pseudo-arc is a homogeneous hereditarily indecomposable planar continuum.\n\nProperties\nThere are two fundamental techniques for constructing continua, by means of nested intersections and inverse limits.\n\nIf {Xn} is a nested family of continua, i.e. Xn ⊇ Xn+1, then their intersection is a continuum.\nIf {(Xn, fn)} is an inverse sequence of continua Xn, called the coordinate spaces, together with continuous maps fn: Xn+1 → Xn, called the bonding maps, then its inverse limit is a continuum.\nA finite or countable product of continua is a continuum.\n\nSee also\nLinear continuum\nMenger sponge\nShape theory (mathematics)\n\nReferences\nSources\nSam B. Nadler, Jr, Continuum theory. An introduction. Pure and Applied Mathematics, Marcel Dekker. ISBN 0-8247-8659-9.\n\nExternal links\nOpen problems in continuum theory\nExamples in continuum theory\nContinuum Theory and Topological Dynamics, M. Barge and J. Kennedy, in Open Problems in Topology, J. van Mill and G.M. Reed (Editors) Elsevier Science Publishers B.V. (North-Holland), 1990.\nHyperspacewiki",
    "links": [
      "Algebraic topology",
      "Arcwise connected",
      "Banach fixed-point theorem",
      "Betti number",
      "Bundle (mathematics)",
      "CW complex",
      "Chern class",
      "Closed interval",
      "Closed set",
      "Cobordism",
      "Cohomology",
      "Combinatorial topology",
      "Compact space",
      "Connected space",
      "Continuity (topology)",
      "Continuous map",
      "Contractible space",
      "De Rham cohomology",
      "Differential topology",
      "Digital topology",
      "Euclidean plane",
      "Euclidean space",
      "Euler characteristic",
      "Fundamental group",
      "General topology",
      "Geometric topology",
      "Hausdorff space",
      "Hilbert cube",
      "Homeomorphic",
      "Homology (mathematics)",
      "Homotopy",
      "Homotopy group",
      "ISBN (identifier)",
      "Indecomposable continuum",
      "Interior (topology)",
      "Invariance of domain",
      "Inverse limit",
      "Klein bottle",
      "Linear continuum",
      "List of algebraic topology topics",
      "List of general topology topics",
      "List of geometric topology topics",
      "List of important publications in mathematics",
      "List of topology topics",
      "Locally connected",
      "Low-dimensional topology",
      "Manifold",
      "Mathematical",
      "Menger sponge",
      "Metric space"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Continuum theory",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Covering space": {
    "title": "Covering space",
    "url": "https://en.wikipedia.org/wiki/Covering_space",
    "summary": "In topology, a covering or covering projection is a map between topological spaces that, intuitively, locally acts like a projection of multiple copies of a space onto itself. In particular, coverings are special types of local homeomorphisms. If \n  \n    \n      \n        p\n        :\n        \n          \n            \n              X\n              ~\n            \n          \n        \n        →\n        X\n      \n    \n    {\\displaystyle p:{\\tilde {X}}\\to X}\n  \n is a covering, \n  \n    \n      \n        (\n        \n          \n            \n              X\n              ~\n            \n          \n        \n        ,\n        p\n        )\n      \n    \n    {\\displaystyle ({\\tilde {X}},p)}\n  \n is said to be a covering space or cover of \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n, and \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is said to be the base of the covering, or simply the base. By abuse of terminology, \n  \n    \n      \n        \n          \n            \n           ",
    "content": "In topology, a covering or covering projection is a map between topological spaces that, intuitively, locally acts like a projection of multiple copies of a space onto itself. In particular, coverings are special types of local homeomorphisms. If \n  \n    \n      \n        p\n        :\n        \n          \n            \n              X\n              ~\n            \n          \n        \n        →\n        X\n      \n    \n    {\\displaystyle p:{\\tilde {X}}\\to X}\n  \n is a covering, \n  \n    \n      \n        (\n        \n          \n            \n              X\n              ~\n            \n          \n        \n        ,\n        p\n        )\n      \n    \n    {\\displaystyle ({\\tilde {X}},p)}\n  \n is said to be a covering space or cover of \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n, and \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is said to be the base of the covering, or simply the base. By abuse of terminology, \n  \n    \n      \n        \n          \n            \n              X\n              ~\n            \n          \n        \n      \n    \n    {\\displaystyle {\\tilde {X}}}\n  \n and \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n may sometimes be called covering spaces as well. Since coverings are local homeomorphisms, a covering space is a special kind of étalé space.\nCovering spaces first arose in the context of complex analysis (specifically, the technique of analytic continuation), where they were introduced by Riemann as domains on which naturally multivalued complex functions become single-valued. These spaces are now called Riemann surfaces.\nCovering spaces are an important tool in several areas of mathematics. In modern geometry, covering spaces (or branched coverings, which have slightly weaker conditions) are used in the construction of manifolds, orbifolds, and the morphisms between them. In algebraic topology, covering spaces are closely related to the fundamental group: for one, since all coverings have the homotopy lifting property, covering spaces are an important tool in the calculation of homotopy groups. A standard example in this vein is the calculation of the fundamental group of the circle by means of the covering of \n  \n    \n      \n        \n          S\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle S^{1}}\n  \n by \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n (see below). Under certain conditions, covering spaces also exhibit a Galois correspondence with the subgroups of the fundamental group.\n\nDefinition\nLet \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n be a topological space. A covering of \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is a continuous map\n\n  \n    \n      \n        π\n        :\n        \n          \n            \n              X\n              ~\n            \n          \n        \n        →\n        X\n      \n    \n    {\\displaystyle \\pi :{\\tilde {X}}\\rightarrow X}\n  \n\nsuch that for every \n  \n    \n      \n        x\n        ∈\n        X\n      \n    \n    {\\displaystyle x\\in X}\n  \n there exists an open neighborhood \n  \n    \n      \n        \n          U\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle U_{x}}\n  \n of \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n and a discrete space \n  \n    \n      \n        \n          D\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle D_{x}}\n  \n such that \n  \n    \n      \n        \n          π\n          \n            −\n            1\n          \n        \n        (\n        \n          U\n          \n            x\n          \n        \n        )\n      \n    \n    {\\displaystyle \\pi ^{-1}(U_{x})}\n  \n is the disjoint union \n  \n    \n      \n        \n          \n            ⨆\n            \n              d\n              ∈\n              \n                D\n                \n                  x\n                \n              \n            \n          \n          \n            V\n            \n              d\n            \n          \n        \n      \n    \n    {\\displaystyle \\displaystyle \\bigsqcup _{d\\in D_{x}}V_{d}}\n  \n and \n  \n    \n      \n        π\n        \n          \n            |\n          \n          \n            \n              V\n              \n                d\n              \n            \n          \n        \n        :\n        \n          V\n          \n            d\n          \n        \n        →\n        \n          U\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle \\pi |_{V_{d}}:V_{d}\\rightarrow U_{x}}\n  \n is a homeomorphism for every \n  \n    \n      \n        d\n        ∈\n        \n          D\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle d\\in D_{x}}\n  \n.\nThe open sets \n  \n    \n      \n        \n          V\n          \n            d\n          \n        \n      \n    \n    {\\displaystyle V_{d}}\n  \n are called sheets, which are uniquely determined up to homeomorphism if \n  \n    \n      \n        \n          U\n          \n            x\n          \n   ",
    "links": [
      "Abuse of terminology",
      "Aerospace engineering",
      "Algebraic topology",
      "Analytic continuation",
      "ArXiv (identifier)",
      "Bernhard Riemann",
      "Bethe lattice",
      "Bibcode (identifier)",
      "Bijection",
      "Bipartite double cover",
      "Boundary of a manifold",
      "Branched covering",
      "Cardinality",
      "Category theory",
      "Cayley graph",
      "Chart (mathematics)",
      "Charts on SO(3)",
      "Circle",
      "Closed set",
      "Compact riemann surface",
      "Complex analysis",
      "Complex manifold",
      "Conjugacy class",
      "Connected space",
      "Continuous function",
      "Coprime integers",
      "Cover (topology)",
      "Covering graph",
      "Covering group",
      "Cyclic group",
      "Dense set",
      "Discrete group",
      "Discrete space",
      "Disjoint union (topology)",
      "Doi (identifier)",
      "Equivalence of categories",
      "Euler angles",
      "Fiber bundle",
      "Final topology",
      "Free group action",
      "Functor",
      "Fundamental group",
      "G-set",
      "Galois connection",
      "Geometry",
      "Gimbal",
      "Gimbal lock",
      "Graph theory",
      "Group (mathematics)",
      "Group action"
    ],
    "categories": [
      "Category:Algebraic topology",
      "Category:Articles with short description",
      "Category:CS1 German-language sources (de)",
      "Category:CS1 maint: location missing publisher",
      "Category:Fiber bundles",
      "Category:Homotopy theory",
      "Category:Short description matches Wikidata",
      "Category:Topological graph theory",
      "Category:Wikipedia articles needing clarification from December 2024"
    ]
  },
  "CW complex": {
    "title": "CW complex",
    "url": "https://en.wikipedia.org/wiki/CW_complex",
    "summary": "In mathematics, and specifically in topology, a CW complex (also cellular complex or cell complex) is a topological space that is built by gluing together topological balls (so-called cells) of different dimensions in specific ways. The notion generalizes both manifolds and simplicial complexes and has particular significance for algebraic topology. It was initially introduced by J. H. C. Whitehead to meet the needs of homotopy theory.\nCW complexes have better categorical properties than simplicial complexes, but still retain a combinatorial nature that allows for computation (often with a much smaller complex). \nThe C in CW stands for \"closure-finite\", and the W for \"weak\" topology.",
    "content": "In mathematics, and specifically in topology, a CW complex (also cellular complex or cell complex) is a topological space that is built by gluing together topological balls (so-called cells) of different dimensions in specific ways. The notion generalizes both manifolds and simplicial complexes and has particular significance for algebraic topology. It was initially introduced by J. H. C. Whitehead to meet the needs of homotopy theory.\nCW complexes have better categorical properties than simplicial complexes, but still retain a combinatorial nature that allows for computation (often with a much smaller complex). \nThe C in CW stands for \"closure-finite\", and the W for \"weak\" topology.\n\nDefinition\nCW complex\nA CW complex is constructed by taking the union of a sequence of topological spaces \n  \n    \n      \n        ∅\n        =\n        \n          X\n          \n            −\n            1\n          \n        \n        ⊂\n        \n          X\n          \n            0\n          \n        \n        ⊂\n        \n          X\n          \n            1\n          \n        \n        ⊂\n        ⋯\n      \n    \n    {\\displaystyle \\emptyset =X_{-1}\\subset X_{0}\\subset X_{1}\\subset \\cdots }\n  \n such that each \n  \n    \n      \n        \n          X\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle X_{k}}\n  \n is obtained from \n  \n    \n      \n        \n          X\n          \n            k\n            −\n            1\n          \n        \n      \n    \n    {\\displaystyle X_{k-1}}\n  \n by gluing copies of k-cells \n  \n    \n      \n        (\n        \n          e\n          \n            α\n          \n          \n            k\n          \n        \n        \n          )\n          \n            α\n          \n        \n      \n    \n    {\\displaystyle (e_{\\alpha }^{k})_{\\alpha }}\n  \n, each homeomorphic to the open unit ball \n  \n    \n      \n        \n          B\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle B^{k}}\n  \n in \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n-dimensional Euclidean space, to \n  \n    \n      \n        \n          X\n          \n            k\n            −\n            1\n          \n        \n      \n    \n    {\\displaystyle X_{k-1}}\n  \n by continuous gluing maps \n  \n    \n      \n        \n          g\n          \n            α\n          \n          \n            k\n          \n        \n        :\n        ∂\n        \n          e\n          \n            α\n          \n          \n            k\n          \n        \n        →\n        \n          X\n          \n            k\n            −\n            1\n          \n        \n      \n    \n    {\\displaystyle g_{\\alpha }^{k}:\\partial e_{\\alpha }^{k}\\to X_{k-1}}\n  \n. The maps are also called attaching maps. Thus as a set, \n  \n    \n      \n        \n          X\n          \n            k\n          \n        \n        =\n        \n          X\n          \n            k\n            −\n            1\n          \n        \n        \n          ⊔\n          \n            α\n          \n        \n        \n          e\n          \n            α\n          \n          \n            k\n          \n        \n      \n    \n    {\\displaystyle X_{k}=X_{k-1}\\sqcup _{\\alpha }e_{\\alpha }^{k}}\n  \n.\nEach \n  \n    \n      \n        \n          X\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle X_{k}}\n  \n is called the k-skeleton of the complex.\nThe topology of \n  \n    \n      \n        X\n        =\n        \n          ∪\n          \n            k\n          \n        \n        \n          X\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle X=\\cup _{k}X_{k}}\n  \n is a weak topology: a subset \n  \n    \n      \n        U\n        ⊂\n        X\n      \n    \n    {\\displaystyle U\\subset X}\n  \n is open iff \n  \n    \n      \n        U\n        ∩\n        \n          X\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle U\\cap X_{k}}\n  \n is open for each k-skeleton \n  \n    \n      \n        \n          X\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle X_{k}}\n  \n.\nIn the language of category theory, the topology on \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is the direct limit of the diagram \n  \n    \n      \n        \n          X\n          \n            −\n            1\n          \n        \n        ↪\n        \n          X\n          \n            0\n          \n        \n        ↪\n        \n          X\n          \n            1\n          \n        \n        ↪\n        ⋯\n      \n    \n    {\\displaystyle X_{-1}\\hookrightarrow X_{0}\\hookrightarrow X_{1}\\hookrightarrow \\cdots }\n  \nThe name \"CW\" stands for \"closure-finite weak topology\", which is explained by the following theorem:\n\nThis partition of X is also called a cellulation.\n\nThe construction, in words\nThe CW complex construction is a straightforward generalization of the following process:\n\nA 0-dimensional CW complex is just a set of zero or more discrete points (with the discrete topology).\nA 1-dimensional CW complex is constructed by taking the disjoint union of a 0-dimensional CW complex with ",
    "links": [
      "3-sphere",
      "Abstract cell complex",
      "Alexandroff extension",
      "Algebraic topology",
      "Algebraic variety",
      "Allen Hatcher",
      "Atiyah–Hirzebruch spectral sequence",
      "Attaching map",
      "Baire space",
      "Ball (mathematics)",
      "Banach fixed-point theorem",
      "Betti number",
      "Brown representability theorem",
      "Bulletin of the American Mathematical Society",
      "Bundle (mathematics)",
      "Cambridge University Press",
      "Cartesian product",
      "Category theory",
      "Cellular approximation theorem",
      "Cellular homology",
      "Chain complex",
      "Chern class",
      "Closed set",
      "Cobordism",
      "Cohomology",
      "Combinatorial topology",
      "Compact-open topology",
      "Compact space",
      "Compactly generated Hausdorff space",
      "Compactly generated space",
      "Comparison of topologies",
      "Connected space",
      "Continuity (topology)",
      "Continuous function",
      "Continuum (topology)",
      "Contractible space",
      "Covering space",
      "De Rham cohomology",
      "Differentiable manifold",
      "Differential topology",
      "Digital topology",
      "Direct limit",
      "Discrete space",
      "Discrete two-point space",
      "Disjoint union (topology)",
      "Doi (identifier)",
      "Elementary matrix",
      "Encyclopedia of Mathematics",
      "Equator",
      "Euler characteristic"
    ],
    "categories": [
      "Category:Algebraic topology",
      "Category:Articles with short description",
      "Category:Homotopy theory",
      "Category:Short description matches Wikidata",
      "Category:Topological spaces"
    ]
  },
  "A. M. Turing": {
    "title": "Alan Turing",
    "url": "https://en.wikipedia.org/wiki/Alan_Turing",
    "summary": "Alan Mathison Turing (; 23 June 1912 – 7 June 1954) was an English mathematician, computer scientist, logician, cryptanalyst, philosopher and theoretical biologist. He was highly influential in the development of theoretical computer science, providing a formalisation of the concepts of algorithm and computation with the Turing machine, which can be considered a model of a general-purpose computer. Turing is widely considered to be the father of theoretical computer science.\nBorn in London, Turing was raised in southern England. He graduated from King's College, Cambridge, and in 1938, earned a doctorate degree from Princeton University. During World War II, Turing worked for the Government Code and Cypher School at Bletchley Park, Britain's codebreaking centre that produced Ultra intelligence. He led Hut 8, the section responsible for German naval cryptanalysis. Turing devised techniques for speeding the breaking of German ciphers, including improvements to the pre-war Polish bomba me",
    "content": "Alan Mathison Turing (; 23 June 1912 – 7 June 1954) was an English mathematician, computer scientist, logician, cryptanalyst, philosopher and theoretical biologist. He was highly influential in the development of theoretical computer science, providing a formalisation of the concepts of algorithm and computation with the Turing machine, which can be considered a model of a general-purpose computer. Turing is widely considered to be the father of theoretical computer science.\nBorn in London, Turing was raised in southern England. He graduated from King's College, Cambridge, and in 1938, earned a doctorate degree from Princeton University. During World War II, Turing worked for the Government Code and Cypher School at Bletchley Park, Britain's codebreaking centre that produced Ultra intelligence. He led Hut 8, the section responsible for German naval cryptanalysis. Turing devised techniques for speeding the breaking of German ciphers, including improvements to the pre-war Polish bomba method, an electromechanical machine that could find settings for the Enigma machine. He played a crucial role in cracking intercepted messages that enabled the Allies to defeat the Axis powers in the Battle of the Atlantic and other engagements.\nAfter the war, Turing worked at the National Physical Laboratory, where he designed the Automatic Computing Engine, one of the first designs for a stored-program computer. In 1948, Turing joined Max Newman's Computing Machine Laboratory at the University of Manchester, where he contributed to the development of early Manchester computers and became interested in mathematical biology. Turing wrote on the chemical basis of morphogenesis and predicted oscillating chemical reactions such as the Belousov–Zhabotinsky reaction, first observed in the 1960s. Despite these accomplishments, he was never fully recognised during his lifetime because much of his work was covered by the Official Secrets Act.\nIn 1952, Turing was prosecuted for homosexual acts. He accepted hormone treatment, a procedure commonly referred to as chemical castration, as an alternative to prison. Turing died on 7 June 1954, aged 41, from cyanide poisoning. An inquest determined his death as suicide, but the evidence is also consistent with accidental poisoning. \nFollowing a campaign in 2009, British prime minister Gordon Brown made an official public apology for \"the appalling way [Turing] was treated\". Queen Elizabeth II granted a pardon in 2013. The term \"Alan Turing law\" is used informally to refer to a 2017 law in the UK that retroactively pardoned men cautioned or convicted under historical legislation that outlawed homosexual acts.\nTuring left an extensive legacy in mathematics and computing which has become widely recognised with statues and many things named after him, including an annual award for computing innovation. His portrait appears on the Bank of England £50 note, first released on 23 June 2021 to coincide with his birthday. The audience vote in a 2019 BBC series named Turing the greatest scientist of the 20th century.\n\nEarly life and education\nFamily\nTuring was born in Maida Vale, London, while his father, Julius Mathison Turing, was on leave from his position with the Indian Civil Service (ICS) of the British Raj government at Chatrapur, then in the Madras Presidency and presently in Odisha state, in India. Turing's father was the son of a clergyman, the Rev. John Robert Turing, from a Scottish family of merchants that had been based in the Netherlands and included a baronet. Turing's mother, Julius's wife, was Ethel Sara Turing (née Stoney), daughter of Edward Waller Stoney, chief engineer of the Madras Railways. The Stoneys were a Protestant Anglo-Irish gentry family from both County Tipperary and County Longford, while Ethel herself had spent much of her childhood in County Clare. Julius and Ethel married on 1 October 1907 at the Church of Ireland St. Bartholomew's Church on Clyde Road in Ballsbridge, Dublin.\nJulius's work with the ICS brought the family to British India, where his grandfather had been a general in the Bengal Army. However, both Julius and Ethel wanted their children to be brought up in Britain, so they moved to Maida Vale, London, where Alan Turing was born on 23 June 1912, as recorded by a blue plaque on the outside of the house of his birth, later the Colonnade Hotel. Turing had an elder brother, John Ferrier Turing, father of Dermot Turing, 12th Baronet of the Turing baronets. In 1922, he discovered Natural Wonders Every Child Should Know by Edwin Tenney Brewster. He credited it with opening his eyes to science.\nTuring's father's civil service commission was still active during Turing's childhood years, and his parents travelled between Hastings in the United Kingdom and India, leaving their two sons to stay with a retired Army couple. At Hastings, Turing stayed at Baston Lodge, Upper Maze Hill, St Leonards-on-Sea, now marked with a blue plaque. The plaque was unveiled on 23 June 2",
    "links": [
      "1926 United Kingdom general strike",
      "ACE (computer)",
      "Abraham Wald",
      "Abram Besicovitch",
      "Action This Day (memo)",
      "Ada Lovelace",
      "Adele Goldstine",
      "Alan Kay",
      "Alan Turing: The Enigma",
      "Alan Turing law",
      "Albert Einstein",
      "Albert Neuberger",
      "Alfred D. Chandler Jr.",
      "Alfred Ubbelohde",
      "Algorithm",
      "Alick Glennie",
      "Allies of World War 2",
      "Alonzo Church",
      "American Journal of Mathematics",
      "American Physical Society",
      "Amnesty law",
      "Andrew Hodges",
      "Andrew Koenig (programmer)",
      "Anglo-Irish people",
      "Anthony Cave Brown",
      "Artificial intelligence",
      "Asa Briggs",
      "Astronomer Royal",
      "Atheism",
      "Autocatalytic",
      "Automatic Computing Engine",
      "Axis powers",
      "BBC News",
      "Ballsbridge",
      "Ban (unit)",
      "Banburismus",
      "Bank of England £50 note",
      "Baronet",
      "Baston Lodge",
      "Battle of the Atlantic",
      "Beatrice Worsley",
      "Bell Labs",
      "Belousov–Zhabotinsky reaction",
      "Ben Wallace (politician)",
      "Bendix G-15",
      "Bengal Army",
      "Bertie the Brain",
      "Betty Holberton",
      "Bibcode (identifier)",
      "Binary multiplier"
    ],
    "categories": [
      "Category:1912 births",
      "Category:1954 deaths",
      "Category:1954 suicides",
      "Category:20th-century English LGBTQ people",
      "Category:20th-century English mathematicians",
      "Category:20th-century English philosophers",
      "Category:20th-century atheists",
      "Category:Academics of the University of Manchester",
      "Category:Academics of the University of Manchester Institute of Science and Technology",
      "Category:Alan Turing"
    ]
  },
  "Alan Turing": {
    "title": "Alan Turing",
    "url": "https://en.wikipedia.org/wiki/Alan_Turing",
    "summary": "Alan Mathison Turing (; 23 June 1912 – 7 June 1954) was an English mathematician, computer scientist, logician, cryptanalyst, philosopher and theoretical biologist. He was highly influential in the development of theoretical computer science, providing a formalisation of the concepts of algorithm and computation with the Turing machine, which can be considered a model of a general-purpose computer. Turing is widely considered to be the father of theoretical computer science.\nBorn in London, Turing was raised in southern England. He graduated from King's College, Cambridge, and in 1938, earned a doctorate degree from Princeton University. During World War II, Turing worked for the Government Code and Cypher School at Bletchley Park, Britain's codebreaking centre that produced Ultra intelligence. He led Hut 8, the section responsible for German naval cryptanalysis. Turing devised techniques for speeding the breaking of German ciphers, including improvements to the pre-war Polish bomba me",
    "content": "Alan Mathison Turing (; 23 June 1912 – 7 June 1954) was an English mathematician, computer scientist, logician, cryptanalyst, philosopher and theoretical biologist. He was highly influential in the development of theoretical computer science, providing a formalisation of the concepts of algorithm and computation with the Turing machine, which can be considered a model of a general-purpose computer. Turing is widely considered to be the father of theoretical computer science.\nBorn in London, Turing was raised in southern England. He graduated from King's College, Cambridge, and in 1938, earned a doctorate degree from Princeton University. During World War II, Turing worked for the Government Code and Cypher School at Bletchley Park, Britain's codebreaking centre that produced Ultra intelligence. He led Hut 8, the section responsible for German naval cryptanalysis. Turing devised techniques for speeding the breaking of German ciphers, including improvements to the pre-war Polish bomba method, an electromechanical machine that could find settings for the Enigma machine. He played a crucial role in cracking intercepted messages that enabled the Allies to defeat the Axis powers in the Battle of the Atlantic and other engagements.\nAfter the war, Turing worked at the National Physical Laboratory, where he designed the Automatic Computing Engine, one of the first designs for a stored-program computer. In 1948, Turing joined Max Newman's Computing Machine Laboratory at the University of Manchester, where he contributed to the development of early Manchester computers and became interested in mathematical biology. Turing wrote on the chemical basis of morphogenesis and predicted oscillating chemical reactions such as the Belousov–Zhabotinsky reaction, first observed in the 1960s. Despite these accomplishments, he was never fully recognised during his lifetime because much of his work was covered by the Official Secrets Act.\nIn 1952, Turing was prosecuted for homosexual acts. He accepted hormone treatment, a procedure commonly referred to as chemical castration, as an alternative to prison. Turing died on 7 June 1954, aged 41, from cyanide poisoning. An inquest determined his death as suicide, but the evidence is also consistent with accidental poisoning. \nFollowing a campaign in 2009, British prime minister Gordon Brown made an official public apology for \"the appalling way [Turing] was treated\". Queen Elizabeth II granted a pardon in 2013. The term \"Alan Turing law\" is used informally to refer to a 2017 law in the UK that retroactively pardoned men cautioned or convicted under historical legislation that outlawed homosexual acts.\nTuring left an extensive legacy in mathematics and computing which has become widely recognised with statues and many things named after him, including an annual award for computing innovation. His portrait appears on the Bank of England £50 note, first released on 23 June 2021 to coincide with his birthday. The audience vote in a 2019 BBC series named Turing the greatest scientist of the 20th century.\n\nEarly life and education\nFamily\nTuring was born in Maida Vale, London, while his father, Julius Mathison Turing, was on leave from his position with the Indian Civil Service (ICS) of the British Raj government at Chatrapur, then in the Madras Presidency and presently in Odisha state, in India. Turing's father was the son of a clergyman, the Rev. John Robert Turing, from a Scottish family of merchants that had been based in the Netherlands and included a baronet. Turing's mother, Julius's wife, was Ethel Sara Turing (née Stoney), daughter of Edward Waller Stoney, chief engineer of the Madras Railways. The Stoneys were a Protestant Anglo-Irish gentry family from both County Tipperary and County Longford, while Ethel herself had spent much of her childhood in County Clare. Julius and Ethel married on 1 October 1907 at the Church of Ireland St. Bartholomew's Church on Clyde Road in Ballsbridge, Dublin.\nJulius's work with the ICS brought the family to British India, where his grandfather had been a general in the Bengal Army. However, both Julius and Ethel wanted their children to be brought up in Britain, so they moved to Maida Vale, London, where Alan Turing was born on 23 June 1912, as recorded by a blue plaque on the outside of the house of his birth, later the Colonnade Hotel. Turing had an elder brother, John Ferrier Turing, father of Dermot Turing, 12th Baronet of the Turing baronets. In 1922, he discovered Natural Wonders Every Child Should Know by Edwin Tenney Brewster. He credited it with opening his eyes to science.\nTuring's father's civil service commission was still active during Turing's childhood years, and his parents travelled between Hastings in the United Kingdom and India, leaving their two sons to stay with a retired Army couple. At Hastings, Turing stayed at Baston Lodge, Upper Maze Hill, St Leonards-on-Sea, now marked with a blue plaque. The plaque was unveiled on 23 June 2",
    "links": [
      "1926 United Kingdom general strike",
      "ACE (computer)",
      "Abraham Wald",
      "Abram Besicovitch",
      "Action This Day (memo)",
      "Ada Lovelace",
      "Adele Goldstine",
      "Alan Kay",
      "Alan Turing: The Enigma",
      "Alan Turing law",
      "Albert Einstein",
      "Albert Neuberger",
      "Alfred D. Chandler Jr.",
      "Alfred Ubbelohde",
      "Algorithm",
      "Alick Glennie",
      "Allies of World War 2",
      "Alonzo Church",
      "American Journal of Mathematics",
      "American Physical Society",
      "Amnesty law",
      "Andrew Hodges",
      "Andrew Koenig (programmer)",
      "Anglo-Irish people",
      "Anthony Cave Brown",
      "Artificial intelligence",
      "Asa Briggs",
      "Astronomer Royal",
      "Atheism",
      "Autocatalytic",
      "Automatic Computing Engine",
      "Axis powers",
      "BBC News",
      "Ballsbridge",
      "Ban (unit)",
      "Banburismus",
      "Bank of England £50 note",
      "Baronet",
      "Baston Lodge",
      "Battle of the Atlantic",
      "Beatrice Worsley",
      "Bell Labs",
      "Belousov–Zhabotinsky reaction",
      "Ben Wallace (politician)",
      "Bendix G-15",
      "Bengal Army",
      "Bertie the Brain",
      "Betty Holberton",
      "Bibcode (identifier)",
      "Binary multiplier"
    ],
    "categories": [
      "Category:1912 births",
      "Category:1954 deaths",
      "Category:1954 suicides",
      "Category:20th-century English LGBTQ people",
      "Category:20th-century English mathematicians",
      "Category:20th-century English philosophers",
      "Category:20th-century atheists",
      "Category:Academics of the University of Manchester",
      "Category:Academics of the University of Manchester Institute of Science and Technology",
      "Category:Alan Turing"
    ]
  },
  "Algorithm aversion": {
    "title": "Algorithm aversion",
    "url": "https://en.wikipedia.org/wiki/Algorithm_aversion",
    "summary": "Algorithm aversion is defined as a \"biased assessment of an algorithm which manifests in negative behaviors and attitudes towards the algorithm compared to a human agent.\" This phenomenon describes the tendency of humans to reject advice or recommendations from an algorithm in situations where they would accept the same advice if it came from a human.\nAlgorithms, particularly those utilizing machine learning methods or artificial intelligence (AI), play a growing role in decision-making across various fields. Examples include recommender systems in e-commerce for identifying products a customer might like and AI systems in healthcare that assist in diagnoses and treatment decisions. Despite their proven ability to outperform humans in many contexts, algorithmic recommendations are often met with resistance or rejection, which can lead to inefficiencies and suboptimal outcomes.\nThe study of algorithm aversion is critical as algorithms become increasingly embedded in our daily lives. Fac",
    "content": "Algorithm aversion is defined as a \"biased assessment of an algorithm which manifests in negative behaviors and attitudes towards the algorithm compared to a human agent.\" This phenomenon describes the tendency of humans to reject advice or recommendations from an algorithm in situations where they would accept the same advice if it came from a human.\nAlgorithms, particularly those utilizing machine learning methods or artificial intelligence (AI), play a growing role in decision-making across various fields. Examples include recommender systems in e-commerce for identifying products a customer might like and AI systems in healthcare that assist in diagnoses and treatment decisions. Despite their proven ability to outperform humans in many contexts, algorithmic recommendations are often met with resistance or rejection, which can lead to inefficiencies and suboptimal outcomes.\nThe study of algorithm aversion is critical as algorithms become increasingly embedded in our daily lives. Factors such as perceived accountability, lack of transparency, and skepticism towards machine judgment contribute to this aversion. Conversely, there are scenarios where individuals are more likely to trust and follow algorithmic advice over human recommendations, a phenomenon referred to as algorithm appreciation. Understanding these dynamics is essential for improving human-algorithm interactions and fostering greater acceptance of AI-driven decision-making.\n\nExamples of algorithm aversion\nAlgorithm aversion manifests in various domains where algorithms are employed to assist or replace human decision-making. Below are examples from diverse contexts, highlighting situations where people tend to resist algorithmic advice or decisions:\n\nHealthcare\nPatients often resist AI-based medical diagnostics and treatment recommendations, despite the proven accuracy of such systems. For instance, patients tend to trust human doctors more, as they perceive AI systems as lacking empathy and the ability to handle nuanced emotional interactions. Negative emotions are more likely to arise as AI plays a larger role in healthcare decision-making.\n\nRecruitment and employment\nAlgorithmic agents used in recruitment are often perceived as less capable of fulfilling relational roles, such as providing emotional support or career development. While algorithms are trusted for transactional tasks like salary negotiations, human recruiters are favored for relational tasks due to their perceived ability to connect on an emotional level.\n\nConsumer behavior\nConsumers generally react less favorably to decisions made by algorithms compared to those made by humans. For example, when a decision results in a positive outcome, consumers find it harder to internalize the result if it comes from an algorithm. Conversely, negative outcomes tend to elicit similar responses regardless of whether the decision was made by an algorithm or a human.\n\nMarketing and content creation\nIn the marketing domain, AI influencers can be as effective as human influencers in promoting products. However, trust levels remain lower for AI-driven recommendations, as consumers often perceive human influencers as more authentic. Similarly, participants tend to favor content explicitly identified as human-generated over AI-generated, even when the quality of AI content matches or surpasses human-created content.\n\nCultural differences\nCultural norms play a significant role in algorithm aversion. In individualistic cultures, such as in the United States, there is a higher tendency to reject algorithmic recommendations due to an emphasis on autonomy and personalized decision-making. In contrast, collectivist cultures, such as in India, exhibit lower aversion, particularly when familiarity with algorithms is higher or when decisions align with societal norms.\n\nMoral and emotional decisions\nAlgorithms are less trusted for tasks involving moral or emotional judgment, such as ethical dilemmas or empathetic decision-making. For example, individuals may reject algorithmic decisions in scenarios where they perceive moral stakes to be high, such as autonomous vehicle decisions or medical life-or-death situations.\n\nMechanisms underlying algorithm aversion\nAlgorithm aversion arises from a combination of psychological, task-related, cultural, and design-related factors. These mechanisms interact to shape individuals' negative perceptions and behaviors toward algorithms, even in cases where algorithmic performance is objectively superior to human decision-making.\n\nPsychological mechanisms\nPerceived responsibility\nIndividuals often feel a heightened sense of accountability when using algorithmic advice compared to human advice. This stems from the belief that, if a decision goes wrong, they will be solely responsible because an algorithm lacks the capacity to share blame. By contrast, decisions made with human input are perceived as more collaborative, allowing for shared accountability. For example, users a",
    "links": [
      "Algorithm",
      "Artificial intelligence",
      "Bias",
      "Bibcode (identifier)",
      "Doi (identifier)",
      "E-commerce",
      "Explainable artificial intelligence",
      "Hdl (identifier)",
      "Human-in-the-loop",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "Machine learning",
      "PMC (identifier)",
      "PMID (identifier)",
      "Wikipedia:What Wikipedia is not",
      "Wikipedia:Writing better articles",
      "Template:Citation",
      "Help:Maintenance template removal",
      "Category:CS1 maint: numeric names: authors list"
    ],
    "categories": [
      "Category:Algorithmic information theory",
      "Category:All articles with style issues",
      "Category:Articles with short description",
      "Category:CS1 maint: numeric names: authors list",
      "Category:Psychological anthropology",
      "Category:Short description matches Wikidata",
      "Category:Wikipedia articles with style issues from October 2023"
    ]
  },
  "Algorithm characterizations": {
    "title": "Algorithm characterizations",
    "url": "https://en.wikipedia.org/wiki/Algorithm_characterizations",
    "summary": "Algorithm characterizations are attempts to formalize the word algorithm. Algorithm does not have a generally accepted formal definition. Researchers are actively working on this problem. This article will present some of the \"characterizations\" of the notion of \"algorithm\" in more detail.",
    "content": "Algorithm characterizations are attempts to formalize the word algorithm. Algorithm does not have a generally accepted formal definition. Researchers are actively working on this problem. This article will present some of the \"characterizations\" of the notion of \"algorithm\" in more detail.\n\nThe problem of definition\nOver the last 200 years, the definition of the algorithm has become more complicated and detailed as researchers have tried to pin down the term. Indeed, there may be more than one type of \"algorithm\". But most agree that algorithm has something to do with defining generalized processes for the creation of \"output\" integers from other \"input\" integers – \"input parameters\" arbitrary and infinite in extent, or limited in extent but still variable—by the manipulation of distinguishable symbols (counting numbers) with finite collections of rules that a person can perform with paper and pencil.\nThe most common number-manipulation schemes—both in formal mathematics and in routine life—are: (1) the recursive functions calculated by a person with paper and pencil, and (2) the Turing machine or its Turing equivalents—the primitive register-machine or \"counter-machine\" model, the random-access machine model (RAM), the random-access stored-program machine model (RASP) and its functional equivalent \"the computer\".\nWhen we are doing \"arithmetic\" we are really calculating by the use of \"recursive functions\" in the shorthand algorithms we learned in grade school, for example, adding and subtracting.\nThe proofs that every \"recursive function\" we can calculate by hand we can compute by machine and vice versa—note the usage of the words calculate versus compute—is remarkable. But this equivalence together with the thesis (unproven assertion) that this includes every calculation/computation indicates why so much emphasis has been placed upon the use of Turing-equivalent machines in the definition of specific algorithms, and why the definition of \"algorithm\" itself often refers back to \"the Turing machine\". This is discussed in more detail under Stephen Kleene's characterization.\nThe following are summaries of the more famous characterizations (Kleene, Markov, Knuth) together with those that introduce novel elements—elements that further expand the definition or contribute to a more precise definition.\n[\nA mathematical problem and its result can be considered as two points in a space, and the solution consists of a sequence of steps or a path linking them. Quality of the solution is a function of the path. There might be more than one attribute defined for the path, e.g. length, complexity of shape, an ease of generalizing, difficulty, and so on.\n]\n\nChomsky hierarchy\nThere is more consensus on the \"characterization\" of the notion of \"simple algorithm\".\nAll algorithms need to be specified in a formal language, and the \"simplicity notion\" arises from the simplicity of the language. The Chomsky (1956) hierarchy is a containment hierarchy of classes of formal grammars that generate formal languages. It is used for classifying of programming languages and abstract machines.\nFrom the Chomsky hierarchy perspective, if the algorithm can be specified on a simpler language (than  unrestricted), it can be  characterized by this kind of language, else it is a typical \"unrestricted algorithm\".\nExamples: a \"general purpose\" macro language, like M4 is unrestricted (Turing complete), but the C preprocessor macro language is not, so any algorithm expressed in C preprocessor is a \"simple algorithm\".\nSee also Relationships between complexity classes.\n\nFeatures of a good algorithm\nThe following are desirable features of a well-defined algorithm, as discussed in Scheider and Gersting (1995):\n\nUnambiguous Operations: an algorithm must have specific, outlined steps. The steps should be exact enough to precisely specify what to do at each step.\nWell-Ordered: The exact order of operations performed in an algorithm should be concretely defined.\nFeasibility: All steps of an algorithm should be possible (also known as effectively computable).\nInput: an algorithm should be able to accept a well-defined set of inputs.\nOutput: an algorithm should produce some result as an output, so that its correctness can be reasoned about.\nFiniteness: an algorithm should terminate after a finite number of instructions.\nProperties of specific algorithms that may be desirable include space and time efficiency, generality (i.e. being able to handle many inputs), or determinism.\n\n1881 John Venn's negative reaction to W. Stanley Jevons's Logical Machine of 1870\nIn early 1870 W. Stanley Jevons presented a \"Logical Machine\" (Jevons 1880:200) for analyzing a syllogism or other logical form e.g. an argument reduced to a Boolean equation. By means of what Couturat (1914) called a \"sort of logical piano [,] ... the equalities which represent the premises ... are \"played\" on a keyboard like that of a typewriter. ... When all the premises have been \"played\", the panel sho",
    "links": [
      "A. A. Markov",
      "Abstract machine",
      "Ackermann function",
      "Alan Turing",
      "Alexander S. Kechris",
      "Algorithm",
      "Algorithm examples",
      "Alonzo Church",
      "Andreas Blass",
      "Andrey Markov Jr.",
      "ArXiv (identifier)",
      "Boolean equation",
      "C preprocessor",
      "Cantor's diagonal argument",
      "Chinese room",
      "Chomsky hierarchy",
      "Christos H. Papadimitriou",
      "Church's thesis",
      "Church Thesis",
      "Church–Turing Thesis",
      "Complexity class",
      "Computable function",
      "Computational theory of mind",
      "Computer",
      "Constructive mathematics",
      "Containment hierarchy",
      "Counter-machine model",
      "Counter machine",
      "Daniel Dennett",
      "Darwin's Dangerous Idea",
      "Data flow diagram",
      "David Berlinski",
      "Decision tree",
      "Deterministic algorithm",
      "Doi (identifier)",
      "Donald Knuth",
      "Dynamic semantics",
      "Effectively computable",
      "Emil Post",
      "Euclidean algorithm",
      "Finite-state machine",
      "Formal grammar",
      "Formal language",
      "Formal proof",
      "Formal system",
      "George Boolos",
      "Greatest common divisor",
      "Gödel",
      "H. J. Keisler",
      "Harry R. Lewis"
    ],
    "categories": [
      "Category:Algorithms",
      "Category:All articles to be expanded",
      "Category:All articles with specifically marked weasel-worded phrases",
      "Category:Articles to be expanded from June 2008",
      "Category:Articles with short description",
      "Category:Articles with specifically marked weasel-worded phrases from February 2013",
      "Category:Computability theory",
      "Category:Formal methods",
      "Category:Models of computation",
      "Category:Short description matches Wikidata"
    ]
  },
  "Algorithm engineering": {
    "title": "Algorithm engineering",
    "url": "https://en.wikipedia.org/wiki/Algorithm_engineering",
    "summary": "Algorithm engineering focuses on the design, analysis, implementation, optimization, profiling and experimental evaluation of computer algorithms, bridging the gap between algorithmics theory and practical applications of algorithms in software engineering.\nIt is a general methodology for algorithmic research.",
    "content": "Algorithm engineering focuses on the design, analysis, implementation, optimization, profiling and experimental evaluation of computer algorithms, bridging the gap between algorithmics theory and practical applications of algorithms in software engineering.\nIt is a general methodology for algorithmic research.\n\nOrigins\nIn 1995, a report from an NSF-sponsored workshop \"with the purpose of assessing the current goals and directions of the Theory of Computing (TOC) community\" identified the slow speed of adoption of theoretical insights by practitioners as an important issue and suggested measures to\n\nreduce the uncertainty by practitioners whether a certain theoretical breakthrough will translate into practical gains in their field of work, and\ntackle the lack of ready-to-use algorithm libraries, which provide stable, bug-free and well-tested implementations for algorithmic problems and expose an easy-to-use interface for library consumers.\nBut also, promising algorithmic approaches have been neglected due to difficulties in mathematical analysis.\nThe term \"algorithm engineering\" was first used with specificity in 1997, with the first Workshop on Algorithm Engineering (WAE97), organized by Giuseppe F. Italiano.\n\nDifference from algorithm theory\nAlgorithm engineering does not intend to replace or compete with algorithm theory, but tries to enrich, refine and reinforce its formal approaches with experimental algorithmics (also called empirical algorithmics).\nThis way it can provide new insights into the efficiency and performance of algorithms in cases where\n\nthe algorithm at hand is less amenable to algorithm theoretic analysis,\nformal analysis pessimistically suggests bounds which are unlikely to appear on inputs of practical interest,\nthe algorithm relies on the intricacies of modern hardware architectures like data locality, branch prediction, instruction stalls, instruction latencies which the machine model used in Algorithm Theory is unable to capture in the required detail,\nthe crossover between competing algorithms with different constant costs and asymptotic behaviors needs to be determined.\n\nMethodology\nSome researchers describe algorithm engineering's methodology as a cycle consisting of algorithm design, analysis, implementation and experimental evaluation, joined by further aspects like machine models or realistic inputs.\nThey argue that equating algorithm engineering with experimental algorithmics is too limited, because viewing design and analysis, implementation and experimentation as separate activities ignores the crucial feedback loop between those elements of algorithm engineering.\n\nRealistic models and real inputs\nWhile specific applications are outside the methodology of algorithm engineering, they play an important role in shaping realistic models of the problem and the underlying machine, and supply real inputs and other design parameters for experiments.\n\nDesign\nCompared to algorithm theory, which usually focuses on the asymptotic behavior of algorithms, algorithm engineers need to keep further requirements in mind: Simplicity of the algorithm, implementability in programming languages on real hardware, and allowing code reuse.\nAdditionally, constant factors of algorithms have such a considerable impact on real-world inputs that sometimes an algorithm with worse asymptotic behavior performs better in practice due to lower constant factors.\n\nAnalysis\nSome problems can be solved with heuristics and randomized algorithms in a simpler and more efficient fashion than with deterministic algorithms. Unfortunately, this makes even simple randomized algorithms difficult to analyze because there are subtle dependencies to be taken into account.\n\nImplementation\nHuge semantic gaps between theoretical insights, formulated algorithms, programming languages and hardware pose a challenge to efficient implementations of even simple algorithms, because small implementation details can have rippling effects on execution behavior.\nThe only reliable way to compare several implementations of an algorithm is to spend an considerable amount of time on tuning and profiling, running those algorithms on multiple architectures, and looking at the generated machine code.\n\nExperiments\nSee: Experimental algorithmics\n\nApplication engineering\nImplementations of algorithms used for experiments differ in significant ways from code usable in applications.\nWhile the former prioritizes fast prototyping, performance and instrumentation for measurements during experiments, the latter requires thorough testing, maintainability, simplicity, and tuning for particular classes of inputs.\n\nAlgorithm libraries\nStable, well-tested algorithm libraries like LEDA play an important role in technology transfer by speeding up the adoption of new algorithms in applications. \nSuch libraries reduce the required investment and risk for practitioners, because it removes the burden of understanding and implementing the results of academic resear",
    "links": [
      "Algorithms",
      "Center for Discrete Mathematics and Theoretical Computer Science",
      "DIMACS",
      "Experimental algorithmics",
      "Giuseppe Francesco Italiano",
      "Library of Efficient Data types and Algorithms",
      "National Science Foundation",
      "Peter Sanders (computer scientist)",
      "Rutgers University",
      "SIGACT",
      "Society for Industrial and Applied Mathematics",
      "Software engineering",
      "Symposium on Experimental Algorithms"
    ],
    "categories": [
      "Category:Algorithms",
      "Category:Theoretical computer science"
    ]
  },
  "Algorithmic bias": {
    "title": "Algorithmic bias",
    "url": "https://en.wikipedia.org/wiki/Algorithmic_bias",
    "summary": "Algorithmic bias describes systematic and repeatable harmful tendency in a computerized sociotechnical system to create \"unfair\" outcomes, such as \"privileging\" one category over another in ways different from the intended function of the algorithm.\nBias can emerge from many factors, including but not limited to the design of the algorithm or the unintended or unanticipated use or decisions relating to the way data is coded, collected, selected or used to train the algorithm.  For example, algorithmic bias has been observed in search engine results and social media platforms. This bias can have impacts ranging from inadvertent privacy violations to reinforcing social biases of race, gender, sexuality, and ethnicity. The study of algorithmic bias is most concerned with algorithms that reflect \"systematic and unfair\" discrimination. This bias has only recently been addressed in legal frameworks, such as the European Union's General Data Protection Regulation (proposed 2018) and the Artif",
    "content": "Algorithmic bias describes systematic and repeatable harmful tendency in a computerized sociotechnical system to create \"unfair\" outcomes, such as \"privileging\" one category over another in ways different from the intended function of the algorithm.\nBias can emerge from many factors, including but not limited to the design of the algorithm or the unintended or unanticipated use or decisions relating to the way data is coded, collected, selected or used to train the algorithm.  For example, algorithmic bias has been observed in search engine results and social media platforms. This bias can have impacts ranging from inadvertent privacy violations to reinforcing social biases of race, gender, sexuality, and ethnicity. The study of algorithmic bias is most concerned with algorithms that reflect \"systematic and unfair\" discrimination. This bias has only recently been addressed in legal frameworks, such as the European Union's General Data Protection Regulation (proposed 2018) and the Artificial Intelligence Act (proposed 2021, approved 2024).\nAs algorithms expand their ability to organize society, politics, institutions, and behavior, sociologists have become concerned with the ways in which unanticipated output and manipulation of data can impact the physical world. Because algorithms are often considered to be neutral and unbiased, they can inaccurately project greater authority than human expertise (in part due to the psychological phenomenon of automation bias), and in some cases, reliance on algorithms can displace human responsibility for their outcomes. Bias can enter into algorithmic systems as a result of pre-existing cultural, social, or institutional expectations; by how features and labels are chosen; because of technical limitations of their design; or by being used in unanticipated contexts or by audiences who are not considered in the software's initial design.\nAlgorithmic bias has been cited in cases ranging from election outcomes to the spread of online hate speech. It has also arisen in criminal justice, healthcare, and hiring, compounding existing racial, socioeconomic, and gender biases. The relative inability of facial recognition technology to accurately identify darker-skinned faces has been linked to multiple wrongful arrests of black men, an issue stemming from imbalanced datasets. Problems in understanding, researching, and discovering algorithmic bias persist due to the proprietary nature of algorithms, which are typically treated as trade secrets. Even when full transparency is provided, the complexity of certain algorithms poses a barrier to understanding their functioning. Furthermore, algorithms may change, or respond to input or output in ways that cannot be anticipated or easily reproduced for analysis. In many cases, even within a single website or application, there is no single \"algorithm\" to examine, but a network of many interrelated programs and data inputs, even between users of the same service.\nA 2021 survey identified multiple forms of algorithmic bias, including historical, representation, and measurement biases, each of which can contribute to unfair outcomes.\n\nDefinitions\nAlgorithms are difficult to define, but may be generally understood as lists of instructions that determine how programs read, collect, process, and analyze data to generate output. For a rigorous technical introduction, see Algorithms. Advances in computer hardware have led to an increased ability to process, store and transmit data. This has in turn boosted the design and adoption of technologies such as machine learning and artificial intelligence. By analyzing and processing data, algorithms are the backbone of search engines, social media websites, recommendation engines, online retail, online advertising, and more.\nContemporary social scientists are concerned with algorithmic processes embedded into hardware and software applications because of their political and social impact, and question the underlying assumptions of an algorithm's neutrality. The term algorithmic bias describes systematic and repeatable errors that create unfair outcomes, such as privileging one arbitrary group of users over others. For example, a credit score algorithm may deny a loan without being unfair, if it is consistently weighing relevant financial criteria. If the algorithm recommends loans to one group of users, but denies loans to another set of nearly identical users based on unrelated criteria, and if this behavior can be repeated across multiple occurrences, an algorithm can be described as biased. This bias may be intentional or unintentional (for example, it can come from biased data obtained from a worker that previously did the job the algorithm is going to do from now on).\n\nMethods\nBias can be introduced to an algorithm in several ways. During the assemblage of a dataset, data may be collected, digitized, adapted, and entered into a database according to human-designed cataloging criteria. Next, progra",
    "links": [
      "A/B tests",
      "AI-assisted software development",
      "AI Magazine",
      "AI boom",
      "AI control problem",
      "AI safety",
      "AI takeover",
      "AI winter",
      "Ableism",
      "Academic bias",
      "Adultism",
      "Affirmative action",
      "African American English",
      "Age disparity in sexual relationships",
      "Age of candidacy",
      "Age segregation",
      "Ageism",
      "Algorithm",
      "Algorithm characterizations",
      "Algorithmic accountability",
      "Algorithmic transparency",
      "Algorithmic wage discrimination",
      "Algorithms of Oppression",
      "Allophilia",
      "Amatonormativity",
      "Amazon.com",
      "Amazon (company)",
      "American Airlines",
      "Anthropocentrism",
      "Anti-Afghan sentiment",
      "Anti-African sentiment",
      "Anti-Albanian sentiment",
      "Anti-Arab racism",
      "Anti-Armenian sentiment",
      "Anti-Asian racism in France",
      "Anti-Asian racism in post-Apartheid South Africa",
      "Anti-Asian racism in the United States",
      "Anti-Assyrian sentiment",
      "Anti-Austrian sentiment",
      "Anti-Azerbaijani sentiment",
      "Anti-Bengali sentiment",
      "Anti-Black racism",
      "Anti-Catalan sentiment",
      "Anti-Catholicism",
      "Anti-Chechen sentiment",
      "Anti-Chinese sentiment",
      "Anti-Christian sentiment",
      "Anti-Colombian sentiment",
      "Anti-Croat sentiment",
      "Anti-Defamation League"
    ],
    "categories": [
      "Category:All articles with vague or ambiguous time",
      "Category:All pages needing factual verification",
      "Category:Articles with excerpts",
      "Category:Articles with short description",
      "Category:Bias",
      "Category:CS1: long volume value",
      "Category:CS1 maint: location missing publisher",
      "Category:CS1 maint: numeric names: authors list",
      "Category:Computing and society",
      "Category:Discrimination"
    ]
  },
  "Algorithmic composition": {
    "title": "Algorithmic composition",
    "url": "https://en.wikipedia.org/wiki/Algorithmic_composition",
    "summary": "Algorithmic composition is the technique of using algorithms to create music.\nAlgorithms (or, at the very least, formal sets of rules) have been used to compose music for centuries; the procedures used to plot voice-leading in Western counterpoint, for example, can often be reduced to algorithmic determinacy. The term can be used to describe music-generating techniques that run without ongoing human intervention, for example through the introduction of chance procedures. However through live coding and other interactive interfaces, a fully human-centric approach to algorithmic composition is possible.\nSome algorithms or data that have no immediate musical relevance are used by composers as creative inspiration for their music. Algorithms such as fractals, L-systems, statistical models, and even arbitrary data (e.g. census figures, GIS coordinates, or magnetic field measurements) have been used as source materials.",
    "content": "Algorithmic composition is the technique of using algorithms to create music.\nAlgorithms (or, at the very least, formal sets of rules) have been used to compose music for centuries; the procedures used to plot voice-leading in Western counterpoint, for example, can often be reduced to algorithmic determinacy. The term can be used to describe music-generating techniques that run without ongoing human intervention, for example through the introduction of chance procedures. However through live coding and other interactive interfaces, a fully human-centric approach to algorithmic composition is possible.\nSome algorithms or data that have no immediate musical relevance are used by composers as creative inspiration for their music. Algorithms such as fractals, L-systems, statistical models, and even arbitrary data (e.g. census figures, GIS coordinates, or magnetic field measurements) have been used as source materials.\n\nModels\nCompositional algorithms are usually classified by the specific programming techniques they use. The results of the process can then be divided into 1) music composed by computer and 2) music composed with the aid of computer. Music may be considered composed by computer when the algorithm is able to make choices of its own during the creation process.\nAnother way to sort compositional algorithms is to examine the results of their compositional processes. Algorithms can either 1) provide notational information (sheet music or MIDI) for other instruments or 2) provide an independent way of sound synthesis (playing the composition by itself). There are also algorithms creating both notational data and sound synthesis.\nOne way to categorize compositional algorithms is by their structure and the way of processing data, as seen in this model of six partly overlapping types:\n\nmathematical models\nknowledge-based systems\ngrammars\nevolutionary methods\nsystems which learn\nhybrid systems\n\nTranslational models\nThis is an approach to music synthesis that involves \"translating\" information from an existing non-musical medium into a new sound. The translation can be either rule-based or stochastic. For example, when translating a picture into sound, a JPEG image of a horizontal line may be interpreted in sound as a constant pitch, while an upwards-slanted line may be an ascending scale. Oftentimes, the software seeks to extract concepts or metaphors from the medium, (such as height or sentiment) and apply the extracted information to generate songs using the ways music theory typically represents those concepts. Another example is the translation of text into music, which can approach composition by extracting sentiment (positive or negative) from the text using machine learning methods like sentiment analysis and represents that sentiment in terms of chord quality such as minor (sad) or major (happy) chords in the musical output generated.\n\nMathematical models\nMathematical models are based on mathematical equations and random events. The most common way to create compositions through mathematics is stochastic processes. In stochastic models a piece of music is composed as a result of non-deterministic methods. The compositional process is only partially controlled by the composer by weighting the possibilities of random events. Prominent examples of stochastic algorithms are Markov chains and various uses of Gaussian distributions. Stochastic algorithms are often used together with other algorithms in various decision-making processes.\nMusic has also been composed through natural phenomena. These chaotic models create compositions from the harmonic and inharmonic phenomena of nature. For example, since the 1970s fractals have been studied also as models for algorithmic composition.\nAs an example of deterministic compositions through mathematical models, the On-Line Encyclopedia of Integer Sequences provides an option to play an integer sequence as 12-tone equal temperament music. (It is initially set to convert each integer to a note on an 88-key musical keyboard by computing the integer modulo 88, at a steady rhythm. Thus 123456, the natural numbers, equals half of a chromatic scale.) As another example, the all-interval series has been used for computer-aided composition.\n\nKnowledge-based systems\nOne way to create compositions is to isolate the aesthetic code of a certain musical genre and use this code to create new similar compositions. Knowledge-based systems are based on a pre-made set of arguments that can be used to compose new works of the same style or genre. Usually this is accomplished by a set of tests or rules requiring fulfillment for the composition to be complete.\n\nGrammars\nMusic can also be examined as a language with a distinctive grammar set. Compositions are created by first constructing a musical grammar, which is then used to create comprehensible musical pieces. Grammars often include rules for macro-level composing, for instance harmonies and rhythm, rather than single notes.\n\nO",
    "links": [
      "12-tone equal temperament",
      "ACM Computing Surveys",
      "AIVA",
      "Aleatoric music",
      "Algorithm",
      "American Association for Artificial Intelligence",
      "Andranik Tangian",
      "ArXiv (identifier)",
      "Barry Vercoe",
      "Bell Labs",
      "Bibcode (identifier)",
      "CCMIX",
      "CSIRAC",
      "Cambridge Companions to Music",
      "Canon (music)",
      "Census",
      "Center for New Music and Audio Technologies",
      "Change ringing",
      "Charles Dodge (composer)",
      "ChucK",
      "Cognitive science",
      "Communications of the ACM",
      "Composer",
      "Composers Desktop Project",
      "Computational creativity",
      "Computer Music Center",
      "Computer Music Journal",
      "Computer music",
      "Counterpoint",
      "Csound",
      "Curtis Roads",
      "Data",
      "David Cope",
      "Deterministic",
      "Digital synthesizer",
      "Doi (identifier)",
      "Dorien Herremans",
      "Eduardo Reck Miranda",
      "Elaine Chew",
      "Equation",
      "Euclid's algorithm",
      "Euclidean rhythm",
      "Evolution",
      "Evolutionary algorithm",
      "Evolutionary music",
      "Experimental Music Studios",
      "FAUST (programming language)",
      "Fractal",
      "Gaussian distribution",
      "Generative music"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Commons category link from Wikidata",
      "Category:Computer music",
      "Category:Markov models",
      "Category:Music theory",
      "Category:Procedural generation",
      "Category:Short description matches Wikidata",
      "Category:Webarchive template wayback links"
    ]
  },
  "Algorithmic entities": {
    "title": "Algorithmic entities",
    "url": "https://en.wikipedia.org/wiki/Algorithmic_entities",
    "summary": "Algorithmic entities refer to autonomous algorithms that operate without human control or interference. Recently, attention is being given to the idea of algorithmic entities being granted (partial or full) legal personhood. Professor Shawn Bayern and Professor Lynn M. LoPucki popularized through their papers the idea of having algorithmic entities that obtain legal personhood and the accompanying rights and obligations.",
    "content": "Algorithmic entities refer to autonomous algorithms that operate without human control or interference. Recently, attention is being given to the idea of algorithmic entities being granted (partial or full) legal personhood. Professor Shawn Bayern and Professor Lynn M. LoPucki popularized through their papers the idea of having algorithmic entities that obtain legal personhood and the accompanying rights and obligations.\n\nLegal algorithmic entities\nAcademics and politicians have been discussing over the last few years whether it is possible to have a legal algorithmic entity, meaning that an algorithm or AI is granted legal personhood. In most countries, the law only recognizes natural or real persons and legal persons. The main argument is that behind every legal person (or layers of legal persons), there is eventually a natural person.\nIn some countries there have been made some exceptions to this in the form of the granting of an environmental personhood to rivers, waterfalls, forests and mountains. In the past, some form of personhood also existed for certain religious constructions such as churches and temples.\nCertain countries – albeit for publicity purposes – have shown willingness to grant (some form of) legal personhood to robots. On the 27th of October 2017, Saudi Arabia became to first country in the world to grant citizenship to a robot when it gave “Sophia” a passport. In the same year, official residency status was granted to a chatbot named “Shibuya Mirai” in Tokyo, Japan.\nThe general consensus is that AI in any case cannot be regarded as a natural or real person and that granting AI (legal) personhood at this stage is unwanted from a societal point of view. However, the academic and public discussions continue as AI software becomes more sophisticated and companies are increasingly implementing artificial intelligence to assist in all aspects of business and society. This leads to some scholars to wonder whether AI should be granted legal personhood as it is not unthinkable to one day have a sophisticated algorithm capable of managing a firm completely independent of human interventions.\nBrown argues that the question of whether legal personhood for AI may be granted is tied directly to the issue of whether AI can or should even be allowed to legally own property.  Brown “concludes that that legal personhood is the best approach for AI to own personal property.”  This is an especially important inquiry since many scholars already recognize AI as having possession and control of some digital assets or even data. AI can also create written text, photo, art, and even algorithms, though ownership of these works is not currently granted to AI in any country because it is not recognized as a legal person.\n\nUnited States\nBayern (2016) argues that this is already possible currently under US law. He states, that, in the United States, creating an AI controlled firm without human interference or ownership is already possible under current legislation by creating a “zero member LLC”:\n\n(1) an individual member creates a member-managed LLC, filing the appropriate paperwork with the state; (2) the individual (along, possibly, with the LLC, which is controlled by the sole member) enters into an operating agreement governing the conduct of the LLC; (3) the operating agreement specifies that the LLC will take actions as determined by an autonomous system, specifying terms or conditions as appropriate to achieve the autonomous system’s legal goals; (4) the sole member withdraws from the LLC, leaving the LLC without any members. The result is potentially a perpetual LLC—a new legal person—that requires no ongoing intervention from any preexisting legal person in order to maintain its status.\nSherer (2018) argues – after conducting an analysis on New York's (and other states’) LLC law(s), the Revised Uniform Limited Liability Company Act (RULLCA) and US case law on fundamentals of legal personhood – that this option is not viable, but agrees with Bayern on the existence of a ‘loophole’ whereby an AI system could “effectively control a LLC and thereby have the functional equivalent of legal personhood”. Bayern's loophole of “entity cross-ownership” would work as follows:\n\n(1) Existing person P establishes member-managed LLCs A and B, with identical operating agreements both providing that the entity is controlled by an autonomous system that is not a preexisting legal person; (2) P causes A to be admitted as a member of B and B to be admitted as a member of A; (3) P withdraws from both entities.\nUnlike the zero member LLC, the entity cross-ownership would not trigger a response by the law for having a memberless entity as what remains are two entities each having one member. In corporations, this sort of situations is often prevented by formal provisions in the statutes (predominantly for voting rights for shares), however, such limitations do not seem to be in place for LLCs as they are more flexible in arrang",
    "links": [
      "AI",
      "Algorithms",
      "Chatbot",
      "Doi (identifier)",
      "EU",
      "Environmental personhood",
      "European Commission",
      "European Economic and Social Committee",
      "European Parliament",
      "ISBN (identifier)",
      "Legal person",
      "Legal personhood",
      "Lynn M. LoPucki",
      "Natural person",
      "Robot",
      "Shawn Bayern",
      "Sophia (robot)"
    ],
    "categories": [
      "Category:Existential risk from artificial intelligence",
      "Category:Regulation of artificial intelligence",
      "Category:Regulation of robots"
    ]
  },
  "Algorithmic paradigm": {
    "title": "Algorithmic paradigm",
    "url": "https://en.wikipedia.org/wiki/Algorithmic_paradigm",
    "summary": "An algorithmic paradigm or algorithm design paradigm is a generic model or framework which underlies the design of a class of algorithms. An algorithmic paradigm is an abstraction higher than the notion of an algorithm, just as an algorithm is an abstraction higher than a computer program.",
    "content": "An algorithmic paradigm or algorithm design paradigm is a generic model or framework which underlies the design of a class of algorithms. An algorithmic paradigm is an abstraction higher than the notion of an algorithm, just as an algorithm is an abstraction higher than a computer program.\n\nList of well-known paradigms\nGeneral\nBacktracking\nBranch and bound\nBrute-force search\nDivide and conquer\nDynamic programming\nGreedy algorithm\nRecursion\nPrune and search\n\nParameterized complexity\nKernelization\nIterative compression\n\nComputational geometry\nSweep line algorithms\nRotating calipers\nRandomized incremental construction\n\n\n== References ==",
    "links": [
      "Abstraction",
      "Algorithm",
      "Array (data structure)",
      "Associative array",
      "Backtracking",
      "Binary search",
      "Binary search tree",
      "Branch and bound",
      "Breadth-first search",
      "Brute-force search",
      "Computer program",
      "Data structure",
      "Depth-first search",
      "Divide-and-conquer algorithm",
      "Dynamic programming",
      "Fenwick tree",
      "Fold (higher-order function)",
      "Graph (abstract data type)",
      "Graph traversal",
      "Greedy algorithm",
      "Hash function",
      "Hash table",
      "Heap (data structure)",
      "Iterative compression",
      "Kernelization",
      "Linked list",
      "List of algorithms",
      "List of data structures",
      "Minimax",
      "Online algorithm",
      "Paradigm",
      "Prune and search",
      "Queue (abstract data type)",
      "Randomized algorithm",
      "Recursion (computer science)",
      "Root-finding algorithm",
      "Rotating calipers",
      "Segment tree",
      "Sorting algorithm",
      "Stack (abstract data type)",
      "Streaming algorithm",
      "String-searching algorithm",
      "String (computer science)",
      "Sweep line algorithm",
      "Topological sorting",
      "Tree (abstract data type)",
      "Trie",
      "Template:Data structures and algorithms",
      "Template talk:Data structures and algorithms"
    ],
    "categories": [
      "Category:Algorithms",
      "Category:Articles with short description",
      "Category:Short description matches Wikidata"
    ]
  },
  "Algorithmic synthesis": {
    "title": "High-level synthesis",
    "url": "https://en.wikipedia.org/wiki/High-level_synthesis",
    "summary": "High-level synthesis (HLS), sometimes referred to as C synthesis, electronic system-level (ESL) synthesis, algorithmic synthesis, or behavioral synthesis, is an automated design process that takes an abstract behavioral specification of a digital system and finds a register-transfer level structure that realizes the given behavior.\nSynthesis begins with a high-level specification of the problem, where behavior is generally decoupled from low-level circuit mechanics such as clock-level timing. Early HLS explored a variety of input specification languages, although recent research and commercial applications generally accept synthesizable subsets of ANSI C/C++/SystemC/MATLAB. The code is analyzed, architecturally constrained, and scheduled to transcompile from a transaction-level model (TLM) into a register-transfer level (RTL) design in a hardware description language (HDL), which is in turn commonly synthesized to the gate level by the use of a logic synthesis tool.\nThe goal of HLS is ",
    "content": "High-level synthesis (HLS), sometimes referred to as C synthesis, electronic system-level (ESL) synthesis, algorithmic synthesis, or behavioral synthesis, is an automated design process that takes an abstract behavioral specification of a digital system and finds a register-transfer level structure that realizes the given behavior.\nSynthesis begins with a high-level specification of the problem, where behavior is generally decoupled from low-level circuit mechanics such as clock-level timing. Early HLS explored a variety of input specification languages, although recent research and commercial applications generally accept synthesizable subsets of ANSI C/C++/SystemC/MATLAB. The code is analyzed, architecturally constrained, and scheduled to transcompile from a transaction-level model (TLM) into a register-transfer level (RTL) design in a hardware description language (HDL), which is in turn commonly synthesized to the gate level by the use of a logic synthesis tool.\nThe goal of HLS is to let hardware designers efficiently build and verify hardware, by giving them better control over optimization of their design architecture, and through the nature of allowing the designer to describe the design at a higher level of abstraction while the tool does the RTL implementation. Verification of the RTL is an important part of the process.\nHardware can be designed at varying levels of abstraction. The commonly used levels of abstraction are gate level, register-transfer level (RTL), and algorithmic level.\nWhile logic synthesis uses an RTL description of the design, high-level synthesis works at a higher level of abstraction, starting with an algorithmic description in a high-level language such as SystemC and ANSI C/C++. The designer typically develops the module functionality and the interconnect protocol. The high-level synthesis tools handle the micro-architecture and transform untimed or partially timed functional code into fully timed RTL implementations, automatically creating cycle-by-cycle detail for hardware implementation. The (RTL) implementations are then used directly in a conventional logic synthesis flow to create a gate-level implementation.\n\nHistory\nEarly academic work extracted scheduling, allocation, and binding as the basic steps for high-level-synthesis. Scheduling partitions the algorithm in control steps that are used to define the states in the finite-state machine. Each control step contains one small section of the algorithm that can be performed in a single clock cycle in the hardware. Allocation and binding maps the instructions and variables to the hardware components, multiplexers, registers and wires of the data path.\nFirst generation behavioral synthesis was introduced by Synopsys in 1994 as Behavioral Compiler and used Verilog or VHDL as input languages. The abstraction level used was partially timed (clocked) processes. Tools based on behavioral Verilog or VHDL were not widely adopted in part because neither languages nor the partially timed abstraction were well suited to modeling behavior at a high level. 10 years later, in early 2004, Synopsys end-of-lifed Behavioral Compiler.\nIn 1998, Forte Design Systems introduced its Cynthesizer tool which used SystemC as an entry language instead of Verilog or VHDL.  Cynthesizer was adopted by many Japanese companies in 2000 as Japan had a very mature SystemC user community.  The first high-level synthesis tapeout was achieved in 2001 by Sony using Cynthesizer. Adoption in the United States started in earnest in 2008.\nIn 2006, an efficient and scalable \"SDC modulo scheduling\" technique was developed on control and data flow graphs  and was later extended to pipeline scheduling. This technique uses the integer linear programming formulation. But it shows that the underlying constraint matrix is totally unimodular (after approximating the resource constraints). Thus, the problem can be solved in polynomial time optimally using a linear programming solver in polynomial time. This work was inducted to the FPGA and Reconfigurable Computing Hall of Fame 2022.\nThe SDC scheduling algorithm was implemented in the xPilot HLS system developed at UCLA, and later licensed to the AutoESL Design Technologies, a spin-off from UCLA. AutoESL was acquired by Xilinx (now part of AMD) in 2011, and the HLS tool developed by AutoESL became the base of Xilinx HLS solutions, Vivado HLS and Vitis HLS, widely used for FPGA designs.\n\nSource input\nThe most common source inputs for high-level synthesis are based on standard languages such as ANSI C/C++, SystemC and MATLAB.\nHigh-level synthesis typically also includes a bit-accurate executable specification as input, since to derive an efficient hardware implementation, additional information is needed on what is an acceptable Mean-Square Error or Bit-Error Rate etc. For example, if the designer starts with an FIR filter written using the \"double\" floating type, before he can derive an efficient hardware implementation, th",
    "links": [
      ".NET",
      "ANSI C",
      "Academic Free License",
      "Algorithm",
      "Alice C. Parker",
      "Application-specific integrated circuit",
      "Asynchronous circuit",
      "BSD licenses",
      "Bluespec",
      "Boolean algebra",
      "Boolean circuit",
      "Brigham Young University",
      "C++",
      "C (programming language)",
      "C Sharp (programming language)",
      "C to HDL",
      "Cadence Design Systems",
      "Capacitor",
      "Carnegie Mellon University",
      "Catapult C",
      "Circuit minimization for Boolean functions",
      "Clock signal",
      "Combinational logic",
      "Commercial software",
      "Compiler",
      "Complex programmable logic device",
      "Computer architecture",
      "Computer hardware",
      "Cryptographic accelerator",
      "Custom hardware attack",
      "Data-flow analysis",
      "Data processing unit",
      "Dataflow architecture",
      "Digital audio",
      "Digital cinematography",
      "Digital electronics",
      "Digital photography",
      "Digital radio",
      "Digital signal",
      "Digital signal (signal processing)",
      "Digital signal processing",
      "Digital signal processor",
      "Digital television",
      "Digital video",
      "DirectX Video Acceleration",
      "Distributed computing",
      "Doi (identifier)",
      "EE Times",
      "ETH Zurich",
      "Electronic circuit"
    ],
    "categories": [
      "Category:All Wikipedia articles written in American English",
      "Category:All articles needing additional references",
      "Category:All articles with self-published sources",
      "Category:All articles with unsourced statements",
      "Category:Articles needing additional references from October 2016",
      "Category:Articles needing more viewpoints from April 2011",
      "Category:Articles with multiple maintenance issues",
      "Category:Articles with self-published sources from January 2018",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from March 2023"
    ]
  },
  "Algorithmic technique": {
    "title": "Algorithmic technique",
    "url": "https://en.wikipedia.org/wiki/Algorithmic_technique",
    "summary": "In mathematics and computer science, an algorithmic technique is a general approach for implementing a process or computation.",
    "content": "In mathematics and computer science, an algorithmic technique is a general approach for implementing a process or computation.\n\nGeneral techniques\nThere are several broadly recognized algorithmic techniques that offer a proven method or process for designing and constructing algorithms. Different techniques may be used depending on the objective, which may include searching, sorting, mathematical optimization, constraint satisfaction, categorization, analysis, and prediction.\n\nBrute force\nBrute force is a simple, exhaustive technique that evaluates every possible outcome to find a solution.\n\nDivide and conquer\nThe divide and conquer technique decomposes complex problems recursively into smaller sub-problems. Each sub-problem is then solved and these partial solutions are recombined to determine the overall solution. This technique is often used for searching and sorting.\n\nDynamic\nDynamic programming is a systematic technique in which a complex problem is decomposed recursively into smaller, overlapping subproblems for solution. Dynamic programming stores the results of the overlapping sub-problems locally using an optimization technique called memoization.\n\nEvolutionary\nAn evolutionary approach develops candidate solutions and then, in a manner similar to biological evolution, performs a series of random alterations or combinations of these solutions and evaluates the new results against a fitness function. The most fit or promising results are selected for additional iterations, to achieve an overall optimal solution.\n\nGraph traversal\nGraph traversal is a technique for finding solutions to problems that can be represented as graphs. This approach is broad, and includes depth-first search, breadth-first search, tree traversal, and many specific variations that may include local optimizations and excluding search spaces that can be determined to be non-optimum or not possible. These techniques may be used to solve a variety of problems including shortest path and constraint satisfaction problems.\n\nGreedy\nA greedy approach begins by evaluating one possible outcome from the set of possible outcomes, and then searches locally for an improvement on that outcome. When a local improvement is found, it will repeat the process and again search locally for additional improvements near this local optimum. A greedy technique is generally simple to implement, and these series of decisions can be used to find local optimums depending on where the search began. However, greedy techniques may not identify the global optimum across the entire set of possible outcomes.,\n\nHeuristic\nA heuristic approach employs a practical method to reach an immediate solution not guaranteed to be optimal.\n\nLearning\nLearning techniques employ statistical methods to perform categorization and analysis without explicit programming. Supervised learning, unsupervised learning, reinforcement learning, and deep learning techniques are included in this category.\n\nMathematical optimization\nMathematical optimization is a technique that can be used to calculate a mathematical optimum by minimizing or maximizing a function.\n\nModeling\nModeling is a general technique for abstracting a real-world problem into a framework or paradigm that assists with solution.\n\nRecursion\nRecursion is a general technique for designing an algorithm that calls itself with a progressively simpler part of the task down to one or more base cases with defined results.\n\nSliding Window\nThe sliding window reduces the use of nested loops and replaces them with a single loop, thereby reducing the time complexity.\n\nTwo Pointers\nTwo pointers is an algorithmic technique that uses two indices (or pointers) to traverse a data structure, usually an array or string, often from different ends or at different speeds. It’s widely used to solve problems involving searching, sorting, or scanning with linear time complexity.\n\nBacktracking\nBacktracking is a general algorithmic technique used for solving problems recursively by trying to build a solution incrementally, one piece at a time, and removing those solutions that fail to satisfy the problem constraints as soon as possible.\n\nSee also\nAlgorithm engineering\nAlgorithm characterizations\nTheory of computation\n\nNotes\nExternal links\nAlgorithmic Design and Techniques - edX\nAlgorithmic Techniques and Analysis – Carnegie Mellon\nAlgorithmic Techniques for Massive Data – MIT",
    "links": [
      "Algorithm characterizations",
      "Algorithm engineering",
      "Algorithmic paradigm",
      "Backtracking",
      "Bibcode (identifier)",
      "Breadth-first search",
      "Brute-force search",
      "Carnegie Mellon",
      "Categorization",
      "Computation",
      "Computer science",
      "Constraint satisfaction problem",
      "Data analysis",
      "Deep learning",
      "Depth-first search",
      "Divide-and-conquer algorithm",
      "Doi (identifier)",
      "Dynamic programming",
      "EdX",
      "Evolutionary algorithm",
      "Graph theory",
      "Graph traversal",
      "Greedy algorithm",
      "Heuristic",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "Machine learning",
      "Massachusetts Institute of Technology",
      "Mathematical model",
      "Mathematical optimization",
      "Mathematics",
      "Memoization",
      "Overlapping subproblems",
      "PMID (identifier)",
      "Prediction",
      "Recursion",
      "Reinforcement learning",
      "S2CID (identifier)",
      "Search algorithm",
      "Shortest path problem",
      "Sorting algorithm",
      "Supervised learning",
      "Theory of computation",
      "Tree traversal",
      "Unsupervised learning"
    ],
    "categories": [
      "Category:Mathematical logic",
      "Category:Theoretical computer science"
    ]
  },
  "Algorithmic topology": {
    "title": "Computational topology",
    "url": "https://en.wikipedia.org/wiki/Computational_topology",
    "summary": "Algorithmic topology, or computational topology, is a subfield of topology with an overlap with areas of computer science, in particular, computational geometry and computational complexity theory.\nA primary concern of algorithmic topology, as its name suggests, is to develop efficient algorithms for solving problems that arise naturally in fields such as computational geometry, graphics, robotics, social science, structural biology, and chemistry, using methods from computable topology.",
    "content": "Algorithmic topology, or computational topology, is a subfield of topology with an overlap with areas of computer science, in particular, computational geometry and computational complexity theory.\nA primary concern of algorithmic topology, as its name suggests, is to develop efficient algorithms for solving problems that arise naturally in fields such as computational geometry, graphics, robotics, social science, structural biology, and chemistry, using methods from computable topology.\n\nMajor algorithms by subject area\nAlgorithmic 3-manifold theory\nA large family of algorithms concerning 3-manifolds revolve around normal surface theory, which is a phrase that encompasses several techniques to turn problems in 3-manifold theory into integer linear programming problems.\n\nRubinstein and Thompson's 3-sphere recognition algorithm.  This is an algorithm that takes as input a triangulated 3-manifold and determines whether or not the manifold is homeomorphic to the 3-sphere.  It has exponential run-time in the number of tetrahedral simplexes in the initial 3-manifold, and also an exponential memory profile.  Saul Schleimer went on to show the problem lies in the complexity class NP.   Furthermore, Raphael Zentner showed that the problem lies in the complexity class coNP, provided that the generalized Riemann hypothesis holds. He uses instanton gauge theory, the geometrization theorem of 3-manifolds, and subsequent work of Greg Kuperberg  on the complexity of knottedness detection.\nThe connect-sum decomposition of 3-manifolds is also implemented in Regina, has exponential run-time and is based on a similar algorithm to the 3-sphere recognition algorithm.\nDetermining that the Seifert-Weber 3-manifold contains no incompressible surface has been algorithmically implemented by Burton, Rubinstein and Tillmann and based on normal surface theory.\nThe Manning algorithm is an algorithm to find hyperbolic structures on 3-manifolds whose fundamental group have a solution to the word problem.\nAt present the JSJ decomposition has not been implemented algorithmically in computer software.  Neither has the compression-body decomposition.  There are some very popular and successful heuristics, such as SnapPea which has much success computing approximate hyperbolic structures on triangulated 3-manifolds.  It is known that the full classification of 3-manifolds can be done algorithmically, in fact, it is known that deciding whether two closed, oriented 3-manifolds given by triangulations (simplicial complexes) are equivalent (homeomorphic) is elementary recursive. This generalizes the result on 3-sphere recognition.\n\nConversion algorithms\nSnapPea implements an algorithm to convert a planar knot or link diagram into a cusped triangulation.  This algorithm has a roughly linear run-time in the number of crossings in the diagram, and low memory profile.  The algorithm is similar to the Wirthinger algorithm for constructing presentations of the fundamental group of link complements given by planar diagrams. Similarly, SnapPea can convert surgery presentations of 3-manifolds into triangulations of the presented 3-manifold.\nD. Thurston and F. Costantino have a procedure to construct a triangulated 4-manifold from a triangulated 3-manifold.  Similarly, it can be used to construct surgery presentations of triangulated 3-manifolds, although the procedure is not explicitly written as an algorithm in principle it should have polynomial run-time in the number of tetrahedra of the given 3-manifold triangulation.\nS. Schleimer has an algorithm which produces a triangulated 3-manifold, given input a word (in Dehn twist generators) for the mapping class group of a surface.  The 3-manifold is the one that uses the word as the attaching map for a Heegaard splitting of the 3-manifold. The algorithm is based on the concept of a layered triangulation.\n\nAlgorithmic knot theory\nDetermining whether or not a knot is trivial is known to be in the complexity classes NP as well as co-NP. The problem of determining the genus of a knot in a 3-manifold is NP-complete; however, while  NP remains an upper bound on the complexity of determining the genus of a knot in R3 or S3, as of 2006 it was unknown whether the algorithmic problem of determining the genus of a knot in those particular 3-manifolds was still NP-hard.\n\nComputational homotopy\nComputational methods for homotopy groups of spheres.\nComputational methods for solving systems of polynomial equations.\nBrown has an algorithm to compute the homotopy groups of spaces that are finite Postnikov complexes, although it is not widely considered implementable.\n\nComputational homology\nComputation of homology groups of cell complexes reduces to bringing the boundary matrices into Smith normal form. Although this is a completely solved problem algorithmically, there are various technical obstacles to efficient computation for large complexes. There are two central obstacles. Firstly, the basic Smith form algorithm has c",
    "links": [
      "3-manifold",
      "3-sphere",
      "Advances in Mathematics",
      "Algorithm",
      "ArXiv (identifier)",
      "Bibcode (identifier)",
      "CW complex",
      "Chemistry",
      "Co-NP",
      "Computable topology",
      "Computational complexity theory",
      "Computational geometry",
      "Computer science",
      "Connected sum",
      "Dehn twist",
      "Digital topology",
      "Doi (identifier)",
      "Duke Mathematical Journal",
      "Edgar H. Brown",
      "Elementary recursive",
      "Experimental mathematics",
      "Filtration (mathematics)",
      "Fundamental group",
      "Geometric modeling",
      "Graphics",
      "Heegaard splitting",
      "Homeomorphism",
      "Homology group",
      "Homotopy groups of spheres",
      "ISBN (identifier)",
      "JSJ decomposition",
      "JSTOR (identifier)",
      "Jeffrey Lagarias",
      "Joel Hass",
      "Journal of Topology",
      "Journal of the ACM",
      "Knot (mathematics)",
      "Knot genus",
      "MR (identifier)",
      "Mapping class group",
      "Marc Lackenby",
      "NP-complete",
      "NP-hard",
      "NP (complexity)",
      "Nick Pippenger",
      "Normal surface",
      "PMC (identifier)",
      "PMID (identifier)",
      "Persistent homology",
      "Postnikov system"
    ],
    "categories": [
      "Category:Applied mathematics",
      "Category:Articles with short description",
      "Category:Computational complexity theory",
      "Category:Computational fields of study",
      "Category:Computational science",
      "Category:Computational topology",
      "Category:Short description is different from Wikidata",
      "Category:Webarchive template wayback links"
    ]
  },
  "Algorithm (disambiguation)": {
    "title": "Algorithm (disambiguation)",
    "url": "https://en.wikipedia.org/wiki/Algorithm_(disambiguation)",
    "summary": "An algorithm is an unambiguous method of solving a specific problem.\nAlgorithm or algorhythm may also refer to:",
    "content": "An algorithm is an unambiguous method of solving a specific problem.\nAlgorithm or algorhythm may also refer to:\n\nPeople\nAl-Khwarizmi, 8th century Persian originator of algebra, whose name (romanized variously as Algorithm, Alghoarism, Algorism, etc.) is the etymological origin of algorithm\n\nMusic\nThe Algorithm, a French musical project\nAlgorithm (My Heart to Fear album), 2013, or the title track\nAlgorithm (Lucky Daye album), 2024\nAlgorithm, a 2024 song by South Korean singer Chung Ha\nThe Algorithm (Filter album), 2023\nAlgorythm (album), a 2018 album by Beyond Creation\nAlgorhythm (Todrick Hall album), a 2022 album by Todrick Hall\nSnoop Dogg Presents Algorithm, a 2021 compilation album by Snoop Dogg\nAlgorythm, a 1994 album by Boxcar\n\"Algorithm\" (song), a 2018 song by Muse\n\"Algorhythm\", a 2018 song by Childish Gambino\nAlgorythm Records, an imprint of the drum and bass group Counterstrike\n\"Algorythm\", a 2024 song by South Korean girl group Itzy\n\nOther\nAlgorithm (C++), a C++ Standard Library header that provides implementations of common algorithms\nAlgorithms (journal), a technical periodical\nA temporal inversion device in the 2020 science-fiction film Tenet\nRecommendation algorithms (often called informally simply as \"the algorithm\" or \"algorithms\"), used by social media websites for personalization\n\nSee also\nAlgorithmic (disambiguation)\nAlgorism\nRuleset (disambiguation)",
    "links": [
      "Al-Khwarizmi",
      "Algorhythm (Todrick Hall album)",
      "Algorism",
      "Algorithm",
      "Algorithm (C++)",
      "Algorithm (Lucky Daye album)",
      "Algorithm (My Heart to Fear album)",
      "Algorithm (song)",
      "Algorithmic (disambiguation)",
      "Algorithms (journal)",
      "Algorythm (album)",
      "Boxcar (band)",
      "Chung Ha",
      "Counterstrike (drum and bass group)",
      "Donald Glover",
      "Itzy",
      "Recommendation algorithm",
      "Ruleset (disambiguation)",
      "Snoop Dogg Presents Algorithm",
      "Tenet (film)",
      "The Algorithm",
      "The Algorithm (Filter album)",
      "Help:Disambiguation"
    ],
    "categories": [
      "Category:All article disambiguation pages",
      "Category:All disambiguation pages",
      "Category:Disambiguation pages",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Arabic mathematics": {
    "title": "Mathematics in the medieval Islamic world",
    "url": "https://en.wikipedia.org/wiki/Mathematics_in_the_medieval_Islamic_world",
    "summary": "Mathematics during the Golden Age of Islam, especially during the 9th and 10th centuries, was built upon syntheses of Greek mathematics (Euclid, Archimedes, Apollonius) and Indian mathematics (Aryabhata, Brahmagupta). Important developments of the period include extension of the place-value system to include decimal fractions, the systematised study of algebra and advances in geometry and trigonometry.\nThe medieval Islamic world underwent significant developments in mathematics. Muhammad ibn Musa al-Khwārizmī played a key role in this transformation, introducing algebra as a distinct field in the 9th century. Al-Khwārizmī's approach, departing from earlier arithmetical traditions, laid the groundwork for the arithmetization of algebra, influencing mathematical thought for an extended period. Successors like Al-Karaji expanded on his work, contributing to advancements in various mathematical domains. The practicality and broad applicability of these mathematical methods facilitated the ",
    "content": "Mathematics during the Golden Age of Islam, especially during the 9th and 10th centuries, was built upon syntheses of Greek mathematics (Euclid, Archimedes, Apollonius) and Indian mathematics (Aryabhata, Brahmagupta). Important developments of the period include extension of the place-value system to include decimal fractions, the systematised study of algebra and advances in geometry and trigonometry.\nThe medieval Islamic world underwent significant developments in mathematics. Muhammad ibn Musa al-Khwārizmī played a key role in this transformation, introducing algebra as a distinct field in the 9th century. Al-Khwārizmī's approach, departing from earlier arithmetical traditions, laid the groundwork for the arithmetization of algebra, influencing mathematical thought for an extended period. Successors like Al-Karaji expanded on his work, contributing to advancements in various mathematical domains. The practicality and broad applicability of these mathematical methods facilitated the dissemination of Arabic mathematics to the West, contributing substantially to the evolution of Western mathematics.\nArabic mathematical knowledge spread through various channels during the medieval era, driven by the practical applications of Al-Khwārizmī's methods. This dissemination was influenced not only by economic and political factors but also by cultural exchanges, exemplified by events such as the Crusades and the translation movement. The Islamic Golden Age, spanning from the 8th to the 14th century, marked a period of considerable advancements in various scientific disciplines, attracting scholars from medieval Europe seeking access to this knowledge. Trade routes and cultural interactions played a crucial role in introducing Arabic mathematical ideas to the West. The translation of Arabic mathematical texts, along with Greek and Roman works, during the 14th to 17th century, played a pivotal role in shaping the intellectual landscape of the Renaissance.\n\nOrigin and spread of Arab-Islamic mathematics\nArabic mathematics, particularly algebra, developed significantly during the medieval period. Muhammad ibn Musa al-Khwārizmī's (Arabic: محمد بن موسى الخوارزمي; c. 780 – c. 850) work between AD 813 and 833 in Baghdad was a turning point. He introduced the term \"algebra\" in the title of his book, \"Kitab al-jabr wa al-muqabala,\" marking it as a distinct discipline. He regarded his work as \"a short work on Calculation by (the rules of) Completion and Reduction, confining it to what is easiest and most useful in arithmetic\". Later, people commented his work was not just a theoretical treatise but also practical, aimed at solving problems in areas like commerce and land measurement.\nAl-Khwārizmī's approach was groundbreaking in that it did not arise from any previous \"arithmetical\" tradition, including that of Diophantus. He developed a new vocabulary for algebra, distinguishing between purely algebraic terms and those shared with arithmetic. Al-Khwārizmī noticed that the representation of numbers is crucial in daily life. Thus, he wanted to find or summarize a way to simplify the mathematical operation, so-called later, the algebra. His algebra was initially focused on linear and quadratic equations and the elementary arithmetic of binomials and trinomials. This approach, which involved solving equations using radicals and related algebraic calculations, influenced mathematical thinking long after his death.\nAl-Khwārizmī's proof of the rule for solving quadratic equations of the form (ax2 + bx = c), commonly referred to as \"squares plus roots equal numbers,\" was a monumental achievement in the history of algebra. This breakthrough laid the groundwork for the systematic approach to solving quadratic equations, which became a fundamental aspect of algebra as it developed in the Western world. Al-Khwārizmī's method, which involved completing the square, not only provided a practical solution for equations of this type but also introduced an abstract and generalized approach to mathematical problems. His work, encapsulated in his seminal text \"Al-Kitab al-Mukhtasar fi Hisab al-Jabr wal-Muqabala\" (The Compendious Book on Calculation by Completion and Balancing), was translated into Latin in the 12th century. This translation played a pivotal role in the transmission of algebraic knowledge to Europe, significantly influencing mathematicians during the Renaissance and shaping the evolution of modern mathematics. Al-Khwārizmī's contributions, especially his proof for quadratic equations, are a testament to the rich mathematical heritage of the Islamic world and its enduring impact on Western mathematics.\nThe spread of Arabic mathematics to the West was facilitated by several factors. The practicality and broad applicability of al-Khwārizmī's methods were especially notable. These methods converted numerical and geometrical problems into equations in standard form, leading to canonical solution formulae. His work, along with that of ",
    "links": [
      "'Abd al-'Aziz al-Wafa'i",
      "'Abd al-Hamīd ibn Turk",
      "Abu'l-Hasan al-Uqlidisi",
      "Abu'l-Hasan ibn Ali al-Qalasadi",
      "Abu-Mahmud Khojandi",
      "Abu Ali al-Hasan al-Marrakushi",
      "Abu Bakr al-Hassar",
      "Abu Hanifa Dinawari",
      "Abu Ja'far al-Khazin",
      "Abu Kamil",
      "Abu Kamil Shuja'",
      "Abu Mansur al-Baghdadi",
      "Abu Nasr Mansur",
      "Abu Sahl al-Quhi",
      "Abu Said Gorgani",
      "Abu al-Jud",
      "Abu al-Saqr al-Qabisi 'Abd al-'Aziz ibn Uthman",
      "Abu al-Wafa' Buzjani",
      "Abū Isḥāq Ibrāhīm al-Zarqālī",
      "Abū Kāmil Shujāʿ ibn Aslam",
      "Abū Sahl al-Qūhī",
      "Abū al-Rayḥān al-Bīrūnī",
      "Abū al-Wafā' al-Būzjānī",
      "Abū al-Ḥasan ibn ʿAlī al-Qalaṣādī",
      "Adab (Islam)",
      "Adolph Pavlovich Yushkevich",
      "Ahmad al-Buni",
      "Ahmad ibn Munim al-Abdari",
      "Ahmad ibn Yusuf",
      "Al-Abbās ibn Said al-Jawharī",
      "Al-Azhar University",
      "Al-Battani",
      "Al-Battānī",
      "Al-Birjandi",
      "Al-Biruni",
      "Al-Hassar",
      "Al-Isfahani",
      "Al-Isfizari",
      "Al-Jabr",
      "Al-Karaji",
      "Al-Kharaqī",
      "Al-Khazini",
      "Al-Khwarizmi",
      "Al-Kindi",
      "Al-Mahani",
      "Al-Mustansiriya University",
      "Al-Nayrizi",
      "Al-Qabisi",
      "Al-Saghani",
      "Al-Samaw'al"
    ],
    "categories": [
      "Category:All articles with unsourced statements",
      "Category:Articles containing Arabic-language text",
      "Category:Articles containing French-language text",
      "Category:Articles containing suspected AI-generated texts from August 2025",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from April 2023",
      "Category:CS1 German-language sources (de)",
      "Category:CS1 Italian-language sources (it)",
      "Category:CS1 errors: ISBN date",
      "Category:CS1 maint: location missing publisher"
    ]
  },
  "A History of Vector Analysis": {
    "title": "A History of Vector Analysis",
    "url": "https://en.wikipedia.org/wiki/A_History_of_Vector_Analysis",
    "summary": "A History of Vector Analysis (1967) is a book on the history of vector analysis by Michael J. Crowe, originally published by the University of Notre Dame Press.\nAs a scholarly treatment of a reformation in technical communication, the text is a contribution to the history of science. In 2002, Crowe gave a talk summarizing the book, including an entertaining introduction in which he covered its publication history and related the award of a Jean Scott prize of $4000.  Crowe had entered the book in a competition for \"a study on the history of complex and hypercomplex numbers\" twenty-five years after his book was first published.",
    "content": "A History of Vector Analysis (1967) is a book on the history of vector analysis by Michael J. Crowe, originally published by the University of Notre Dame Press.\nAs a scholarly treatment of a reformation in technical communication, the text is a contribution to the history of science. In 2002, Crowe gave a talk summarizing the book, including an entertaining introduction in which he covered its publication history and related the award of a Jean Scott prize of $4000.  Crowe had entered the book in a competition for \"a study on the history of complex and hypercomplex numbers\" twenty-five years after his book was first published.\n\nSummary of book\nThe book has eight chapters: the first on the origins of vector analysis including Ancient Greek and 16th and 17th century influences; the second on the 19th century William Rowan Hamilton and quaternions; the third on other 19th and 18th century vectorial systems including equipollence of Giusto Bellavitis and the exterior algebra of Hermann Grassmann.\nChapter four is on the general interest in the 19th century on vectorial systems including analysis of journal publications as well as sections on major figures and their views (e.g., Peter Guthrie Tait as an advocate of Quaternions and James Clerk Maxwell as a critic of Quaternions); the fifth chapter describes the development of the modern system of vector analysis by Josiah Willard Gibbs and Oliver Heaviside.\nIn chapter six, \"Struggle for existence\",\nMichael J. Crowe delves into the zeitgeist that pruned down quaternion theory into vector analysis on three-dimensional space. He makes clear the ambition of this effort by considering five major texts as well as a couple dozen articles authored by participants in \"The Great Vector Debate\". These are the books:\n\nElementary Treatise on Quaternions (1890) Peter Guthrie Tait\nElements of Vector Analysis (1881,1884) Josiah Willard Gibbs\nElectromagnetic Theory (1893,1899,1912) Oliver Heaviside\nUtility of Quaternions in Physics (1893) Alexander McAulay\nVector Analysis and Quaternions (1906) Alexander Macfarlane\nTwenty of the ancillary articles appeared in Nature; others were in Philosophical Magazine, London or Edinburgh Proceedings of the Royal Society, Physical Review, and Proceedings of the American Association for the Advancement of Science. The authors included Cargill Gilston Knott and a half-dozen other hands.\nThe \"struggle for existence\" is a phrase from Charles Darwin’s Origin of Species and Crowe quotes Darwin:  \"...young and rising naturalists,...will be able to view both sides of the question with impartiality.\" After 1901 with the Gibbs/Wilson/Yale publication Vector Analysis, the question was decided in favour of the vectorialists with separate dot and cross products. The pragmatic temper of the times set aside the four-dimensional source of vector algebra.\nCrowe's chapter seven is a survey of \"Twelve major publications in Vector Analysis from 1894 to 1910\". Of these twelve, seven are in German, two in Italian, one in Russian, and two in English. Whereas the previous chapter examined a debate in English, the final chapter notes the influence of Heinrich Hertz' results with radio and the rush of German research using vectors. Joseph George Coffin of MIT and Clark University published his Vector Analysis in 1909; it too leaned heavily into applications. Thus Crowe provides a context for Gibbs and Wilson’s famous textbook of 1901.\nThe eighth chapter is the author's summary and conclusions. The book relies on references in chapter endnotes instead of a bibliography section.  Crowe also states that the Bibliography of the Quaternion Association, and its supplements to 1912, already listed all the primary literature for the study.\n\nSummary of reviews\nThere were significant reviews given near the time of original publication. Stanley Goldberg wrote \"The polemics on both sides make very rich reading, especially when they are spiced with the sarcastic wit of a Heaviside, and the fervent, almost religious railing of a Tait.\" Morris Kline begins his 1969 review with \"Since historical publications on modern developments are rare, this book is welcome.\" and ends with \"the subtitle [,The Evolution of the Idea of a Vectorial System,] is a better description of the contents than the title proper.\"  Then William C. Waterhouse—picking up where Kline's review left off—writes in 1972 \"Crowe's book on vector analysis seems a little anemic in comparison, perhaps because its title is misleading. ... [Crowe] does succeed in his goal of tracing the genealogy of the 3-space system, concluding that it was developed out of quaternions by physicists.\"\nKarin Reich wrote that Arnold Sommerfeld's name was missing from the book. As assistant to Felix Klein, Sommerfeld was assigned the project of unifying vector concepts and notations for Klein's encyclopedia.\nIn 2003 Sandro Caparrini challenged Crowe’s conclusions by noting that \"geometrical representations of forces and velocities by means of d",
    "links": [
      "Alexander Macfarlane",
      "Alexander McAulay",
      "American Association for the Advancement of Science",
      "American Mathematical Monthly",
      "Angular velocity",
      "Arnold Sommerfeld",
      "Bulletin of the American Mathematical Society",
      "Cargill Gilston Knott",
      "Charles Darwin",
      "Clark University",
      "Cross product",
      "Dot product",
      "Equipollence (geometry)",
      "Exterior algebra",
      "Felix Klein",
      "Gaetano Giorgini",
      "Giusto Bellavitis",
      "Goodreads",
      "Heinrich Hertz",
      "Hermann Grassmann",
      "History of quaternions",
      "History of science",
      "Hypercomplex number",
      "ISBN (identifier)",
      "James Clerk Maxwell",
      "Josiah Willard Gibbs",
      "Karin Reich",
      "Klein's encyclopedia",
      "Mathematical Reviews",
      "Michael J. Crowe",
      "Michel Chasles",
      "Morris Kline",
      "Nature (journal)",
      "Non-fiction books",
      "Oliver Heaviside",
      "Origin of Species",
      "Peter Guthrie Tait",
      "Philosophical Magazine",
      "Physical Review",
      "Quaternion Association",
      "Quaternions",
      "Royal Society",
      "Technical communication",
      "Three-dimensional space",
      "Torque",
      "University of Notre Dame Press",
      "Vector Analysis",
      "Vector analysis",
      "Vector space",
      "Wayback Machine"
    ],
    "categories": [
      "Category:1967 non-fiction books",
      "Category:Articles with short description",
      "Category:Books about the history of mathematics",
      "Category:Historical treatment of quaternions",
      "Category:Mathematics books",
      "Category:Short description is different from Wikidata",
      "Category:Webarchive template wayback links"
    ]
  },
  "Arithmetic series": {
    "title": "Arithmetic progression",
    "url": "https://en.wikipedia.org/wiki/Arithmetic_progression",
    "summary": "An arithmetic progression or arithmetic sequence is a sequence of numbers such that the difference from any succeeding term to its preceding term remains constant throughout the sequence. The constant difference is called common difference of that arithmetic progression. For instance, the sequence 5, 7, 9, 11, 13, 15, . . . is an arithmetic progression with a common difference of 2.\nIf the initial term of an arithmetic progression is \n  \n    \n      \n        \n          a\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle a_{1}}\n  \n and the common difference of successive members is \n  \n    \n      \n        d\n      \n    \n    {\\displaystyle d}\n  \n, then the \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n-th term of the sequence (\n  \n    \n      \n        \n          a\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle a_{n}}\n  \n) is given by\n\n  \n    \n      \n        \n          a\n          \n            n\n          \n        \n     ",
    "content": "An arithmetic progression or arithmetic sequence is a sequence of numbers such that the difference from any succeeding term to its preceding term remains constant throughout the sequence. The constant difference is called common difference of that arithmetic progression. For instance, the sequence 5, 7, 9, 11, 13, 15, . . . is an arithmetic progression with a common difference of 2.\nIf the initial term of an arithmetic progression is \n  \n    \n      \n        \n          a\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle a_{1}}\n  \n and the common difference of successive members is \n  \n    \n      \n        d\n      \n    \n    {\\displaystyle d}\n  \n, then the \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n-th term of the sequence (\n  \n    \n      \n        \n          a\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle a_{n}}\n  \n) is given by\n\n  \n    \n      \n        \n          a\n          \n            n\n          \n        \n        =\n        \n          a\n          \n            1\n          \n        \n        +\n        (\n        n\n        −\n        1\n        )\n        d\n        .\n      \n    \n    {\\displaystyle a_{n}=a_{1}+(n-1)d.}\n  \n\nA finite portion of an arithmetic progression is called a finite arithmetic progression and sometimes just called an arithmetic progression. The sum of a finite arithmetic progression is called an arithmetic series.\n\nHistory\nAccording to an anecdote of uncertain reliability, in primary school Carl Friedrich Gauss reinvented the formula \n  \n    \n      \n        \n          \n            \n              \n                n\n                (\n                n\n                +\n                1\n                )\n              \n              2\n            \n          \n        \n      \n    \n    {\\displaystyle {\\tfrac {n(n+1)}{2}}}\n  \n for summing the integers from 1 through \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n, for the case \n  \n    \n      \n        n\n        =\n        100\n      \n    \n    {\\displaystyle n=100}\n  \n, by grouping the numbers from both ends of the sequence into pairs summing to 101 and multiplying by the number of pairs. Regardless of the truth of this story, Gauss was not the first to discover this formula. Similar rules were known in antiquity to Archimedes, Hypsicles and Diophantus; in China to Zhang Qiujian; in India to Aryabhata, Brahmagupta and Bhaskara II; and in medieval Europe to Alcuin, Dicuil, Fibonacci, Sacrobosco, and anonymous commentators of Talmud known as Tosafists. Some find it likely that its origin goes back to the Pythagoreans in the 5th century BC.\n\nSum\nThe sum of the members of a finite arithmetic progression is called an arithmetic series. For example, consider the sum:\n\n  \n    \n      \n        2\n        +\n        5\n        +\n        8\n        +\n        11\n        +\n        14\n        =\n        40\n      \n    \n    {\\displaystyle 2+5+8+11+14=40}\n  \n\nThis sum can be found quickly by taking the number n of terms being added (here 5), multiplying by the sum of the first and last number in the progression (here 2 + 14 = 16), and dividing by 2:\n\n  \n    \n      \n        \n          \n            \n              n\n              (\n              \n                a\n                \n                  1\n                \n              \n              +\n              \n                a\n                \n                  n\n                \n              \n              )\n            \n            2\n          \n        \n      \n    \n    {\\displaystyle {\\frac {n(a_{1}+a_{n})}{2}}}\n  \n\nIn the case above, this gives the equation:\n\n  \n    \n      \n        2\n        +\n        5\n        +\n        8\n        +\n        11\n        +\n        14\n        =\n        \n          \n            \n              5\n              (\n              2\n              +\n              14\n              )\n            \n            2\n          \n        \n        =\n        \n          \n            \n              5\n              ×\n              16\n            \n            2\n          \n        \n        =\n        40.\n      \n    \n    {\\displaystyle 2+5+8+11+14={\\frac {5(2+14)}{2}}={\\frac {5\\times 16}{2}}=40.}\n  \n\nThis formula works for any arithmetic progression of real numbers beginning with \n  \n    \n      \n        \n          a\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle a_{1}}\n  \n and ending with \n  \n    \n      \n        \n          a\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle a_{n}}\n  \n. For example,\n\n  \n    \n      \n        \n          (\n          \n            −\n            \n              \n                3\n                2\n              \n            \n          \n          )\n        \n        +\n        \n          (\n          \n            −\n            \n              \n                1\n                2\n              \n            \n          \n          )\n        \n        +\n        \n          \n            1\n            2\n          \n        \n        =\n        \n          \n            \n   ",
    "links": [
      "1/2 + 1/4 + 1/8 + 1/16 + ⋯",
      "1/2 − 1/4 + 1/8 − 1/16 + ⋯",
      "1/4 + 1/16 + 1/64 + 1/256 + ⋯",
      "1 + 1 + 1 + 1 + ⋯",
      "1 + 2 + 3 + 4 + ⋯",
      "1 + 2 + 4 + 8 + ⋯",
      "1 − 1 + 2 − 6 + 24 − 120 + ⋯",
      "1 − 2 + 3 − 4 + ⋯",
      "1 − 2 + 4 − 8 + ⋯",
      "Absolute convergence",
      "Alcuin",
      "Alternating series",
      "American Scientist",
      "Archimedes",
      "Arithmetico-geometric sequence",
      "Aryabhata",
      "Bhaskara II",
      "Brahmagupta",
      "Carl Friedrich Gauss",
      "Cauchy sequence",
      "Chinese remainder theorem",
      "Complete sequence",
      "Complex number",
      "Conditional convergence",
      "Convergent series",
      "Cube (algebra)",
      "Dicuil",
      "Diophantus",
      "Dirichlet series",
      "Discrete uniform distribution",
      "Divergence of the sum of the reciprocals of the primes",
      "Divergent series",
      "Doi (identifier)",
      "Encyclopedia of Mathematics",
      "Eric W. Weisstein",
      "European Mathematical Society",
      "Factorial",
      "Fibonacci",
      "Fibonacci sequence",
      "Figurate number",
      "Formal power series",
      "Fourier series",
      "Gamma function",
      "Generalized arithmetic progression",
      "Generalized hypergeometric series",
      "Generating series",
      "Geometric progression",
      "Grandi's series",
      "Harmonic progression (mathematics)",
      "Harmonic series (mathematics)"
    ],
    "categories": [
      "Category:Arithmetic series",
      "Category:Articles containing proofs",
      "Category:Articles with short description",
      "Category:CS1 errors: ISBN date",
      "Category:Sequences and series",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Baire category theorem": {
    "title": "Baire category theorem",
    "url": "https://en.wikipedia.org/wiki/Baire_category_theorem",
    "summary": "The Baire category theorem (BCT) is an important result in general topology and functional analysis. The theorem has two forms, each of which gives sufficient conditions for a topological space to be a Baire space (a topological space such that the intersection of countably many dense open sets is still dense).  It is used in the proof of results in many areas of analysis and geometry, including some of the fundamental theorems of functional analysis.\nVersions of the Baire category theorem were first proved independently in 1897 by Osgood for the real line \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n and in 1899 by Baire for Euclidean space \n  \n    \n      \n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{n}}\n  \n.  The more general statement for completely metrizable spaces was first shown by Hausdorff in 1914.",
    "content": "The Baire category theorem (BCT) is an important result in general topology and functional analysis. The theorem has two forms, each of which gives sufficient conditions for a topological space to be a Baire space (a topological space such that the intersection of countably many dense open sets is still dense).  It is used in the proof of results in many areas of analysis and geometry, including some of the fundamental theorems of functional analysis.\nVersions of the Baire category theorem were first proved independently in 1897 by Osgood for the real line \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n and in 1899 by Baire for Euclidean space \n  \n    \n      \n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{n}}\n  \n.  The more general statement for completely metrizable spaces was first shown by Hausdorff in 1914.\n\nStatement\nA Baire space is a topological space \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n in which every countable intersection of open dense sets is dense in \n  \n    \n      \n        X\n        .\n      \n    \n    {\\displaystyle X.}\n  \n  See the corresponding article for a list of equivalent characterizations, as some are more useful than others depending on the application.\n\n(BCT1) Every complete pseudometric space is a Baire space.  In particular, every completely metrizable topological space is a Baire space.\n(BCT2) Every locally compact regular space is a Baire space.  In particular, every locally compact Hausdorff space is a Baire space.\nNeither of these statements directly implies the other, since there are complete metric spaces that are not locally compact (the irrational numbers with the metric defined below; also, any Banach space of infinite dimension), and there are locally compact Hausdorff spaces that are not metrizable (for instance, any uncountable product of non-trivial compact Hausdorff spaces; also, several function spaces used in functional analysis; the uncountable Fort space).\nSee Steen and Seebach in the references below.\n\nRelation to the axiom of choice\nThe proof of BCT1 for arbitrary complete metric spaces requires some form of the axiom of choice; and in fact BCT1 is equivalent over ZF to the axiom of dependent choice, a weak form of the axiom of choice.\nA restricted form of the Baire category theorem, in which the complete metric space is also assumed to be separable, is provable in ZF with no additional choice principles.\nThis restricted form applies in particular to the real line, the Baire space \n  \n    \n      \n        \n          ω\n          \n            ω\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\omega ^{\\omega },}\n  \n the Cantor space \n  \n    \n      \n        \n          2\n          \n            ω\n          \n        \n        ,\n      \n    \n    {\\displaystyle 2^{\\omega },}\n  \n and a separable Hilbert space such as the \n  \n    \n      \n        \n          L\n          \n            p\n          \n        \n      \n    \n    {\\displaystyle L^{p}}\n  \n-space \n  \n    \n      \n        \n          L\n          \n            2\n          \n        \n        (\n        \n          \n            R\n          \n          \n            n\n          \n        \n        )\n      \n    \n    {\\displaystyle L^{2}(\\mathbb {R} ^{n})}\n  \n.\n\nUses\nIn functional analysis, BCT1 can be used to prove the open mapping theorem, the closed graph theorem and the uniform boundedness principle.\nBCT1 also shows that every nonempty complete metric space with no isolated point is uncountable. (If \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is a nonempty countable metric space with no isolated point, then each singleton \n  \n    \n      \n        {\n        x\n        }\n      \n    \n    {\\displaystyle \\{x\\}}\n  \n in \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is nowhere dense, and \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is meagre in itself.) In particular, this proves that the set of all real numbers is uncountable.\nBCT1 shows that each of the following is a Baire space:\n\nThe space \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n of real numbers\nThe irrational numbers, with the metric defined by \n  \n    \n      \n        d\n        (\n        x\n        ,\n        y\n        )\n        =\n        \n          \n            \n              1\n              \n                n\n                +\n                1\n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle d(x,y)={\\tfrac {1}{n+1}},}\n  \n where \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n is the first index for which the continued fraction expansions of \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n and \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n differ (this is a complete metric space)\nThe Cantor set\nBy BCT2, every finite-dimensiona",
    "links": [
      "Axiom of choice",
      "Axiom of dependent choice",
      "Azriel Levy",
      "Baire space",
      "Baire space (set theory)",
      "Banach space",
      "Cantor set",
      "Cantor space",
      "Cauchy sequence",
      "Choquet's game",
      "Closed (topology)",
      "Closed graph theorem",
      "Compact (topology)",
      "Complete metric space",
      "Completely metrizable",
      "Completely metrizable space",
      "Continued fraction",
      "Countable",
      "Countably",
      "Counterexamples in Topology",
      "Dense set",
      "Dimension of a vector space",
      "Dover Publications",
      "Eric Schechter",
      "Euclidean space",
      "Felix Hausdorff",
      "Finite intersection property",
      "Fort space",
      "Functional analysis",
      "General topology",
      "Geometry",
      "Graduate Texts in Mathematics",
      "Hartogs's theorem",
      "Hausdorff space",
      "Hilbert space",
      "ISBN (identifier)",
      "Intersection",
      "Irrational number",
      "Isolated point",
      "J. Arthur Seebach Jr.",
      "John L. Kelley",
      "Local base",
      "Locally compact",
      "Locally compact Hausdorff",
      "Locally compact regular",
      "Long line (topology)",
      "Lp space",
      "Lynn Steen",
      "Manifold",
      "Mathematical analysis"
    ],
    "categories": [
      "Category:Articles containing proofs",
      "Category:Articles with short description",
      "Category:Functional analysis",
      "Category:General topology",
      "Category:Short description is different from Wikidata",
      "Category:Theorems in topology"
    ]
  },
  "Amazon Standard Identification Number": {
    "title": "Amazon Standard Identification Number",
    "url": "https://en.wikipedia.org/wiki/Amazon_Standard_Identification_Number",
    "summary": "An Amazon Standard Identification Number (ASIN) is a 10-character alphanumeric unique identifier assigned by Amazon.com and its partners for product identification within the Amazon organization. They were designed in 1996 by Rebecca Allen, an Amazon software engineer, when it became clear that Amazon was going to sell products other than just books. The 10-character format of the ASIN was adopted so that Amazon databases and software, which were designed to expect a 10-character International Standard Book Number (ISBN) field, would not have to be changed to accommodate the new identification format.",
    "content": "An Amazon Standard Identification Number (ASIN) is a 10-character alphanumeric unique identifier assigned by Amazon.com and its partners for product identification within the Amazon organization. They were designed in 1996 by Rebecca Allen, an Amazon software engineer, when it became clear that Amazon was going to sell products other than just books. The 10-character format of the ASIN was adopted so that Amazon databases and software, which were designed to expect a 10-character International Standard Book Number (ISBN) field, would not have to be changed to accommodate the new identification format.\n\nUsage and structure\nEach product on Amazon.com is given a unique ASIN. For books with a 10-digit International Standard Book Number (ISBN), the ASIN and the ISBN are the same. The Kindle edition of a book will not use its ISBN as the ASIN, although the electronic version of a book may have its own ISBN. The ASIN forms part of the URL of a product detail page on Amazon's website.\n\n\n== References ==",
    "links": [
      "1-Click",
      "1Life Healthcare",
      "2024 Teamsters Amazon Strike",
      "43 Things",
      "A9.com",
      "ASIN (disambiguation)",
      "AWS Elastic Beanstalk",
      "AWS Glue",
      "AWS Lambda",
      "AbeBooks",
      "Alexa Internet",
      "Alphanumeric",
      "Amapedia",
      "Amazon's Best Books of the Year",
      "Amazon.com",
      "Amazon.com, Inc. v. Barnesandnoble.com, Inc.",
      "Amazon.com Inc v Canada (Commissioner of Patents)",
      "AmazonFresh",
      "Amazon (company)",
      "Amazon Air",
      "Amazon Alexa",
      "Amazon Appstore",
      "Amazon Astro",
      "Amazon Aurora",
      "Amazon Books",
      "Amazon Breakthrough Novel Award",
      "Amazon China",
      "Amazon Clinic",
      "Amazon CloudFront",
      "Amazon Dash",
      "Amazon Digital Game Store",
      "Amazon Drive",
      "Amazon DynamoDB",
      "Amazon Echo",
      "Amazon Echo Buds",
      "Amazon Echo Show",
      "Amazon ElastiCache",
      "Amazon Elastic Block Store",
      "Amazon Elastic Compute Cloud",
      "Amazon Elastic File System",
      "Amazon Elastic MapReduce",
      "Amazon Fire",
      "Amazon Fire TV",
      "Amazon Fishbowl",
      "Amazon Freevee",
      "Amazon Fresh",
      "Amazon Games",
      "Amazon Glacier",
      "Amazon Go",
      "Amazon HQ2"
    ],
    "categories": [
      "Category:Amazon (company)",
      "Category:Articles with short description",
      "Category:Book terminology",
      "Category:Identifiers",
      "Category:Internet properties established in 1996",
      "Category:Short description is different from Wikidata",
      "Category:Use dmy dates from August 2020"
    ]
  },
  "Bernard Bolzano": {
    "title": "Bernard Bolzano",
    "url": "https://en.wikipedia.org/wiki/Bernard_Bolzano",
    "summary": "Bernard Bolzano (UK: , US: ; German: [bɔlˈtsaːno]; Italian: [bolˈtsaːno]; born Bernardus Placidus Johann Nepomuk Bolzano; 5 October 1781 – 18 December 1848) was a Bohemian mathematician, logician, philosopher, theologian and Catholic priest of Italian extraction, also known for his liberal views.\nBolzano wrote in German, his native language. For the most part, his work came to prominence posthumously.",
    "content": "Bernard Bolzano (UK: , US: ; German: [bɔlˈtsaːno]; Italian: [bolˈtsaːno]; born Bernardus Placidus Johann Nepomuk Bolzano; 5 October 1781 – 18 December 1848) was a Bohemian mathematician, logician, philosopher, theologian and Catholic priest of Italian extraction, also known for his liberal views.\nBolzano wrote in German, his native language. For the most part, his work came to prominence posthumously.\n\nFamily\nBolzano was the son of two pious Catholics. His father, Bernard Pompeius Bolzano, was an Italian who had moved to Prague, where he married Maria Cecilia Maurer who came from Prague's German-speaking family Maurer. Only two of their twelve children lived to adulthood.\n\nCareer\nWhen he was ten years old, Bolzano entered the Gymnasium of the Piarists in Prague, which he attended from 1791 to 1796.\nBolzano entered the University of Prague in 1796 and studied mathematics, philosophy and physics. Starting in 1800, he also began studying theology, becoming a Catholic priest in 1804. He was appointed to the new chair of philosophy of religion at Prague University in 1805. He proved to be a popular lecturer not only in religion but also in philosophy, and he was elected Dean of the Philosophical Faculty in 1818.\nBolzano alienated many faculty and church leaders with his teachings of the social waste of militarism and the needlessness of war. He urged a total reform of the educational, social and economic systems that would direct the nation's interests toward peace rather than toward armed conflict between nations. His political convictions, which he was inclined to share with others with some frequency, eventually proved to be too liberal for the Austrian authorities. On December 24, 1819, he was removed from his professorship (upon his refusal to recant his beliefs) and was exiled to the countryside and then devoted his energies to his writings on social, religious, philosophical, and mathematical matters.\nAlthough forbidden to publish in mainstream journals as a condition of his exile, Bolzano continued to develop his ideas and publish them either on his own or in obscure Eastern European journals. In 1842 he moved back to Prague, where he died in 1848.\n\nMathematical work\nBolzano made several original contributions to mathematics. His overall philosophical stance was that, contrary to much of the prevailing mathematics of the era, it was better not to introduce intuitive ideas such as time and motion into mathematics. To this end, he was one of the earliest mathematicians to begin instilling rigor into mathematical analysis with his three chief mathematical works Beyträge zu einer begründeteren Darstellung der Mathematik (1810), Der binomische Lehrsatz (1816) and Rein analytischer Beweis (1817). These works presented \"...a sample of a new way of developing analysis\", whose ultimate goal would not be realized until some fifty years later when they came to the attention of Karl Weierstrass.\nTo the foundations of mathematical analysis he contributed the introduction of a fully rigorous ε–δ definition of a mathematical limit.  Bolzano was the first to recognize the greatest lower bound property of the real numbers. Like several others of his day, he was skeptical of the possibility of Gottfried Leibniz's infinitesimals, that had been the earliest putative foundation for differential calculus.  Bolzano's notion of a limit was similar to the modern one: that a limit, rather than being a relation among infinitesimals, must instead be cast in terms of how the dependent variable approaches a definite quantity as the independent variable approaches some other definite quantity.\nBolzano also gave the first purely analytic proof of the fundamental theorem of algebra, which had originally been proven by Gauss from geometrical considerations. He also gave the first purely analytic proof of the intermediate value theorem (also known as Bolzano's theorem). Today he is mostly remembered for the Bolzano–Weierstrass theorem, which Karl Weierstrass developed independently and published years after Bolzano's first proof and which was initially called the Weierstrass theorem until Bolzano's earlier work was rediscovered.\n\nPhilosophical work\nBolzano's posthumously published work Paradoxien des Unendlichen (The Paradoxes of the Infinite) (1851) was greatly admired by many of the eminent logicians who came after him, including Charles Sanders Peirce, Georg Cantor, and Richard Dedekind. Bolzano's main claim to fame, however, is his 1837 Wissenschaftslehre (Theory of Science), a work in four volumes that covered not only philosophy of science in the modern sense but also logic, epistemology and scientific pedagogy. The logical theory that Bolzano developed in this work has come to be acknowledged as ground-breaking. Other works are a four-volume Lehrbuch der Religionswissenschaft (Textbook of the Science of Religion) and the metaphysical work Athanasia, a defense of the immortality of the soul. Bolzano also did valuable work in mathema",
    "links": [
      "(ε, δ)-definition of limit",
      "19th-century philosophy",
      "A Treatise Concerning the Principles of Human Knowledge",
      "Abstract and concrete",
      "Abstract object",
      "Abstract object theory",
      "Action theory (philosophy)",
      "Al-Ghazali",
      "Al-Kindi",
      "Al-Nijat",
      "Alexius Meinong",
      "Alfred North Whitehead",
      "Alois Höfler",
      "Alvin Plantinga",
      "American English",
      "American Mathematical Monthly",
      "Analytic-synthetic distinction",
      "Analytic philosophy",
      "Analytic proof",
      "Anima mundi",
      "Anti-realism",
      "ArXiv (identifier)",
      "Aristotle",
      "Arthur Schopenhauer",
      "Asymmetric relation",
      "Austrian Empire",
      "Averroes",
      "Avicenna",
      "Axiology",
      "Baruch Spinoza",
      "Being and Nothingness",
      "Being and Time",
      "Bertrand Russell",
      "Boethius",
      "Bolzano's theorem",
      "Bolzano–Weierstrass theorem",
      "British English",
      "Carl Benjamin Boyer",
      "Carl Friedrich Gauss",
      "Category of being",
      "Catholic",
      "Catholic Church",
      "Catholic priest",
      "Causal closure",
      "Causality",
      "Charles Sanders Peirce",
      "Charles University in Prague",
      "Christian Wolff (philosopher)",
      "Christianity",
      "Classical liberalism"
    ],
    "categories": [
      "Category:1781 births",
      "Category:1848 deaths",
      "Category:19th-century Czech non-fiction writers",
      "Category:19th-century Czech philosophers",
      "Category:19th-century essayists",
      "Category:19th-century mathematicians",
      "Category:19th-century philosophers",
      "Category:All accuracy disputes",
      "Category:Articles with Internet Archive links",
      "Category:Articles with disputed statements from April 2010"
    ]
  },
  "Bhāskara II": {
    "title": "Bhāskara II",
    "url": "https://en.wikipedia.org/wiki/Bh%C4%81skara_II",
    "summary": "Bhāskara II ([bʰɑːskərə]; c.1114–1185), also known as Bhāskarāchārya (lit. 'Bhāskara the teacher'), was an Indian polymath, mathematician, and astronomer. From verses in his main work, Siddhānta Śiromaṇi, it can be inferred that he was born in 1114 in Vijjadavida (Vijjalavida) and living in the Satpura mountain ranges of Western Ghats, believed to be the town of Patana in Chalisgaon, located in present-day Khandesh region of Maharashtra by scholars. In a temple in Maharashtra, an inscription supposedly created by his grandson Changadeva, lists Bhaskaracharya's ancestral lineage for several generations before him as well as two generations after him. Henry Colebrooke who was the first European to translate (1817) Bhaskaracharya's mathematical classics refers to the family as Maharashtrian Brahmins residing on the banks of the Godavari.\nBorn in a Hindu Deshastha Brahmin family of scholars, mathematicians and astronomers, Bhaskara II was the leader of a cosmic observatory at Ujjain, the m",
    "content": "Bhāskara II ([bʰɑːskərə]; c.1114–1185), also known as Bhāskarāchārya (lit. 'Bhāskara the teacher'), was an Indian polymath, mathematician, and astronomer. From verses in his main work, Siddhānta Śiromaṇi, it can be inferred that he was born in 1114 in Vijjadavida (Vijjalavida) and living in the Satpura mountain ranges of Western Ghats, believed to be the town of Patana in Chalisgaon, located in present-day Khandesh region of Maharashtra by scholars. In a temple in Maharashtra, an inscription supposedly created by his grandson Changadeva, lists Bhaskaracharya's ancestral lineage for several generations before him as well as two generations after him. Henry Colebrooke who was the first European to translate (1817) Bhaskaracharya's mathematical classics refers to the family as Maharashtrian Brahmins residing on the banks of the Godavari.\nBorn in a Hindu Deshastha Brahmin family of scholars, mathematicians and astronomers, Bhaskara II was the leader of a cosmic observatory at Ujjain, the main mathematical centre of ancient India. Bhāskara and his works represent a significant contribution to mathematical and astronomical knowledge in the 12th century. He has been called the greatest mathematician of medieval India. His main work, Siddhānta-Śiromaṇi (Sanskrit for \"Crown of Treatises\"), is divided into four parts called Līlāvatī, Bījagaṇita, Grahagaṇita and Golādhyāya, which are also sometimes considered four independent works. These four sections deal with arithmetic, algebra, mathematics of the planets, and spheres respectively. He also wrote another treatise named Karaṇā Kautūhala.\n\nDate, place and family\nBhāskara gives his date of birth, and date of composition of his major work, in a verse in the Āryā metre:\n\nThis reveals that he was born in 1036 of the Shaka era (1114 CE), and that he composed the Siddhānta Shiromani when he was 36 years old. Siddhānta Shiromani was completed during 1150 CE. He also wrote another work called the Karaṇa-kutūhala when he was 69 (in 1183). His works show the influence of Brahmagupta, Śrīdhara, Mahāvīra, Padmanābha and other predecessors. Bhaskara lived in Patnadevi located near Patan (Chalisgaon) in the vicinity of Sahyadri.\nHe was born in a Deśastha Rigvedi Brahmin family near Vijjadavida (Vijjalavida). \nMunishvara (17th century), a commentator on Siddhānta Shiromani of Bhaskara has given the information about the location of Vijjadavida in his work Marīci Tīkā as follows:\n\nसह्यकुलपर्वतान्तर्गत भूप्रदेशे \nमहाराष्ट्रदेशान्तर्गतविदर्भपरपर्यायविराटदेशादपि निकटे \nगोदावर्यां नातिदूरे \n\nपंचक्रोशान्तरे विज्जलविडम्।\nThis description locates Vijjalavida in Maharashtra, near the Vidarbha region and close to the banks of Godavari river. However scholars differ about the exact location. Many scholars have placed the place near Patan in Chalisgaon Taluka of Jalgaon district whereas a section of scholars identified it with the modern day Beed city. Some sources identified Vijjalavida as Bijapur or Bidar in Karnataka. Identification of Vijjalavida with Basar in Telangana has also been suggested.\nBhāskara is said to have been the head of an astronomical observatory at Ujjain, the leading mathematical centre of medieval India. History records his great-great-great-grandfather holding a hereditary post as a court scholar, as did his son and other descendants. His father Maheśvara (Maheśvaropādhyāya) was a mathematician, astronomer and astrologer, who taught him mathematics, which he later passed on to his son Lokasamudra. Lokasamudra's son helped to set up a school in 1207 for the study of Bhāskara's writings. He died in 1185 CE.\n\nThe Siddhānta-Śiromaṇi\nLīlāvatī\nThe first section Līlāvatī (also known as pāṭīgaṇita or aṅkagaṇita), named after his daughter, consists of 277 verses. It covers calculations, progressions, measurement, permutations, and other topics.\n\nBijaganita\nThe second section Bījagaṇita(Algebra) has 213 verses. It discusses zero, infinity, positive and negative numbers, and indeterminate equations including (the now called) Pell's equation, solving it using a kuṭṭaka method. In particular, he also solved the \n  \n    \n      \n        61\n        \n          x\n          \n            2\n          \n        \n        +\n        1\n        =\n        \n          y\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle 61x^{2}+1=y^{2}}\n  \n case that was to elude Fermat and his European contemporaries centuries later\n\nGrahaganita\nIn the third section Grahagaṇita, while treating the motion of planets, he considered their instantaneous speeds. He arrived at the approximation: It consists of 451 verses\n\n  \n    \n      \n        sin\n        ⁡\n        \n          y\n          ′\n        \n        −\n        sin\n        ⁡\n        y\n        ≈\n        (\n        \n          y\n          ′\n        \n        −\n        y\n        )\n        cos\n        ⁡\n        y\n      \n    \n    {\\displaystyle \\sin y'-\\sin y\\approx (y'-y)\\cos y}\n  \n for.\n\n  \n    \n      \n        \n          y\n          ′\n        \n  ",
    "links": [
      "0",
      "0 (number)",
      "A. A. Krishnaswamy Ayyangar",
      "Achyuta Pisharati",
      "Akshay Venkatesh",
      "Algebra",
      "Apastamba Dharmasutra",
      "Area",
      "Arithmetic",
      "Armillary sphere",
      "Aryabhata",
      "Aryabhata II",
      "Aryabhatiya",
      "Astronomer",
      "Astronomy",
      "Avadhesh Narayan Singh",
      "B. B. Datta",
      "Babylonian mathematics",
      "Bakhshali manuscript",
      "Bapudeva Sastri",
      "Basara, Telangana",
      "Baudhayana sutras",
      "Beed",
      "Bhaskara (satellite)",
      "Bhaskaracharya College of Applied Sciences",
      "Bhaskaracharya Institute For Space Applications and Geo-Informatics",
      "Bhaskaracharya Pratishthana",
      "Bhau Daji",
      "Bhāskara's wheel",
      "Bhāskara I",
      "Bibcode (identifier)",
      "Bidar",
      "Bijaganita",
      "Bijapur",
      "Brahmadeva",
      "Brahmagupta",
      "Brahmi numerals",
      "Bride's Chair",
      "Brāhmasphuṭasiddhānta",
      "Bījapallava",
      "C.R. Rao",
      "C. S. Seshadri",
      "C. T. Rajagopal",
      "Chakravala method",
      "Chennai Mathematical Institute",
      "Chinese mathematics",
      "Combination",
      "Common Era",
      "Conjunction (astronomy)",
      "Cosmography"
    ],
    "categories": [
      "Category:1110s births",
      "Category:1185 deaths",
      "Category:12th-century Indian astronomers",
      "Category:12th-century Indian mathematicians",
      "Category:Acharyas",
      "Category:Algebraists",
      "Category:All Wikipedia articles written in Indian English",
      "Category:All articles lacking reliable references",
      "Category:All articles with unsourced statements",
      "Category:Articles lacking reliable references from March 2022"
    ]
  },
  "Applied geometry": {
    "title": "Applied mathematics",
    "url": "https://en.wikipedia.org/wiki/Applied_mathematics",
    "summary": "Applied mathematics is the application of mathematical methods by different fields such as physics, engineering, medicine, biology, finance, business, computer science, and industry. Thus, applied mathematics is a combination of mathematical science and specialized knowledge. The term \"applied mathematics\" also describes the professional specialty in which mathematicians work on practical problems by formulating and studying mathematical models.\nIn the past, practical applications have motivated the development of mathematical theories, which then became the subject of study in pure mathematics where abstract concepts are studied for their own sake. The activity of applied mathematics is thus intimately connected with research in pure mathematics.",
    "content": "Applied mathematics is the application of mathematical methods by different fields such as physics, engineering, medicine, biology, finance, business, computer science, and industry. Thus, applied mathematics is a combination of mathematical science and specialized knowledge. The term \"applied mathematics\" also describes the professional specialty in which mathematicians work on practical problems by formulating and studying mathematical models.\nIn the past, practical applications have motivated the development of mathematical theories, which then became the subject of study in pure mathematics where abstract concepts are studied for their own sake. The activity of applied mathematics is thus intimately connected with research in pure mathematics.\n\nHistory\nHistorically, applied mathematics consisted principally of applied analysis, most notably differential equations; approximation theory (broadly construed, to include representations, asymptotic methods, variational methods, and numerical analysis); and applied probability. These areas of mathematics related directly to the development of Newtonian physics, and in fact, the distinction between mathematicians and physicists was not sharply drawn before the mid-19th century. This history left a pedagogical legacy in the United States: until the early 20th century, subjects such as classical mechanics were often taught in applied mathematics departments at American universities rather than in physics departments, and fluid mechanics may still be taught in applied mathematics departments. Engineering and computer science departments have traditionally made use of applied mathematics.\n\nDivisions\nToday, the term \"applied mathematics\" is used in a broader sense. It includes the classical areas noted above as well as other areas that have become increasingly important in applications. Even fields such as number theory that are part of pure mathematics are now important in applications (such as cryptography), though they are not generally considered to be part of the field of applied mathematics per se.\nThere is no consensus as to what the various branches of applied mathematics are. Such categorizations are made difficult by the way mathematics and science change over time, and also by the way universities organize departments, courses, and degrees.\nMany mathematicians distinguish between \"applied mathematics\", which is concerned with mathematical methods, and the \"applications of mathematics\" within science and engineering. A biologist using a population model and applying known mathematics would not be doing applied mathematics, but rather using it; however, mathematical biologists have posed problems that have stimulated the growth of pure mathematics. Mathematicians such as Poincaré and Arnold deny the existence of \"applied mathematics\" and claim that there are only \"applications of mathematics.\" Similarly, non-mathematicians blend applied mathematics and applications of mathematics. The use and development of mathematics to solve industrial problems is also called \"industrial mathematics\".\nThe success of modern numerical mathematical methods and software has led to the emergence of computational mathematics, computational science, and computational engineering, which use high-performance computing for the simulation of phenomena and the solution of problems in the sciences and engineering. These are often considered interdisciplinary.\n\nApplicable mathematics\nSometimes, the term applicable mathematics is used to distinguish between the traditional applied mathematics that developed alongside physics and the many areas of mathematics that are applicable to real-world problems today, although there is no consensus as to a precise definition.\nMathematicians often distinguish between \"applied mathematics\" on the one hand, and the \"applications of mathematics\" or \"applicable mathematics\" both within and outside of science and engineering, on the other. Some mathematicians emphasize the term applicable mathematics to separate or delineate the traditional applied areas from new applications arising from fields that were previously seen as pure mathematics. For example, from this viewpoint, an ecologist or geographer using population models and applying known mathematics would not be doing applied, but rather applicable, mathematics. Even fields such as number theory that are part of pure mathematics are now important in applications (such as cryptography), though they are not generally considered to be part of the field of applied mathematics per se. Such descriptions can lead to applicable mathematics being seen as a collection of mathematical methods such as real analysis, linear algebra, mathematical modelling, optimisation, combinatorics, probability and statistics, which are useful in areas outside traditional mathematics and not specific to mathematical physics.\nOther authors prefer describing applicable mathematics as a union of \"new\" mathematical applications",
    "links": [
      "Abstract algebra",
      "Actuarial science",
      "Aerospace engineering",
      "Aleksandr Lyapunov",
      "Algebra",
      "Algebra of physical space",
      "Algebraic geometry",
      "Algebraic number theory",
      "Algebraic statistics",
      "Algebraic structure",
      "Algebraic topology",
      "Algorithm",
      "Algorithm design",
      "American Mathematical Society",
      "Analysis of algorithms",
      "Analytic geometry",
      "Analytic number theory",
      "Analytical mechanics",
      "Analytics",
      "Andrey Kolmogorov",
      "Applied Maths",
      "Applied science",
      "Approximation theory",
      "Arithmetic",
      "Arithmetic geometry",
      "Asymptotic analysis",
      "Automata theory",
      "Automated theorem proving",
      "Bibcode (identifier)",
      "Biologist",
      "Biology",
      "Bosonic string theory",
      "Brown University",
      "Business",
      "Calculus",
      "Calculus of variations",
      "Category theory",
      "Chaos theory",
      "Charles Babbage",
      "Chemistry",
      "Civil engineering",
      "Classical field theory",
      "Classical mechanics",
      "Clifford Truesdell",
      "Clifford algebra",
      "Clifford analysis",
      "Coding theory",
      "Combinatorial design",
      "Combinatorial optimization",
      "Combinatorics"
    ],
    "categories": [
      "Category:Applied mathematics",
      "Category:Articles with short description",
      "Category:Commons category link from Wikidata",
      "Category:Short description is different from Wikidata",
      "Category:Webarchive template wayback links"
    ]
  },
  "Cartesian coordinate system": {
    "title": "Cartesian coordinate system",
    "url": "https://en.wikipedia.org/wiki/Cartesian_coordinate_system",
    "summary": "In geometry, a Cartesian coordinate system (UK: , US: ) in a plane is a coordinate system that specifies each point uniquely by a pair of real numbers called coordinates, which are the signed distances to the point from two fixed perpendicular oriented lines, called coordinate lines, coordinate axes or just axes (plural of axis) of the system. The point where the axes meet is called the origin and has (0, 0) as coordinates. The axes directions represent an orthogonal basis. The combination of origin and basis forms a coordinate frame called the Cartesian frame.\nSimilarly, the position of any point in three-dimensional space can be specified by three Cartesian coordinates, which are the signed distances from the point to three mutually perpendicular planes. More generally, n Cartesian coordinates specify the point in an n-dimensional Euclidean space for any dimension n. These coordinates are the signed distances from the point to n mutually perpendicular fixed hyperplanes.\n\nCartesian co",
    "content": "In geometry, a Cartesian coordinate system (UK: , US: ) in a plane is a coordinate system that specifies each point uniquely by a pair of real numbers called coordinates, which are the signed distances to the point from two fixed perpendicular oriented lines, called coordinate lines, coordinate axes or just axes (plural of axis) of the system. The point where the axes meet is called the origin and has (0, 0) as coordinates. The axes directions represent an orthogonal basis. The combination of origin and basis forms a coordinate frame called the Cartesian frame.\nSimilarly, the position of any point in three-dimensional space can be specified by three Cartesian coordinates, which are the signed distances from the point to three mutually perpendicular planes. More generally, n Cartesian coordinates specify the point in an n-dimensional Euclidean space for any dimension n. These coordinates are the signed distances from the point to n mutually perpendicular fixed hyperplanes.\n\nCartesian coordinates are named for René Descartes, whose invention of them in the 17th century revolutionized mathematics by allowing the expression of problems of geometry in terms of algebra and calculus. Using the Cartesian coordinate system, geometric shapes (such as curves) can be described by equations involving the coordinates of points of the shape. For example, a circle of radius 2, centered at the origin of the plane, may be described as the set of all points whose coordinates x and y satisfy the equation x2 + y2 = 4; the area, the perimeter and the tangent line at any point can be computed from this equation by using integrals and derivatives, in a way that can be applied to any curve.\nCartesian coordinates are the foundation of analytic geometry, and provide enlightening geometric interpretations for many other branches of mathematics, such as linear algebra, complex analysis, differential geometry, multivariate calculus, group theory and more. A familiar example is the concept of the graph of a function. Cartesian coordinates are also essential tools for most applied disciplines that deal with geometry, including astronomy, physics, engineering and many more. They are the most common coordinate system used in computer graphics, computer-aided geometric design and other geometry-related data processing.\n\nHistory\nThe adjective Cartesian refers to the French mathematician and philosopher René Descartes, who published this idea in 1637 while he was resident in the Netherlands. It was independently discovered by Pierre de Fermat, who also worked in three dimensions, although Fermat did not publish the discovery. The French cleric Nicole Oresme used constructions similar to Cartesian coordinates well before the time of Descartes and Fermat.\nBoth Descartes and Fermat used a single axis in their treatments and have a variable length measured in reference to this axis. The concept of using a pair of axes was introduced later, after Descartes' La Géométrie was translated into Latin in 1649 by Frans van Schooten and his students. These commentators introduced several concepts while trying to clarify the ideas contained in Descartes's work.\nThe development of the Cartesian coordinate system would play a fundamental role in the development of the calculus by Isaac Newton and Gottfried Wilhelm Leibniz. The two-coordinate description of the plane was later generalized into the concept of vector spaces.\nMany other coordinate systems have been developed since Descartes, such as the polar coordinates for the plane, and the spherical and cylindrical coordinates for three-dimensional space.\n\nDescription\nOne dimension\nAn affine line with a chosen Cartesian coordinate system is called a number line. Every point on the line has a real-number coordinate, and every real number represents some point on the line.\nThere are two degrees of freedom in the choice of Cartesian coordinate system for a line, which can be specified by choosing two distinct points along the line and assigning them to two distinct real numbers (most commonly zero and one). Other points can then be uniquely assigned to numbers by linear interpolation. Equivalently, one point can be assigned to a specific real number, for instance an origin point corresponding to zero, and an oriented length along the line can be chosen as a unit, with the orientation indicating the correspondence between directions along the line and positive or negative numbers. Each point corresponds to its signed distance from the origin (a number with an absolute value equal to the distance and a + or − sign chosen based on direction).\nA geometric transformation of the line can be represented by a function of a real variable, for example translation of the line corresponds to addition, and scaling the line corresponds to multiplication. Any two Cartesian coordinate systems on the line can be related to each-other by a linear function (function of the form \n  \n    \n      \n        x\n        ↦\n        a\n       ",
    "links": [
      "3D projection",
      "6-sphere coordinates",
      "Abscissa",
      "Absolute value (algebra)",
      "Affine line",
      "Affine plane",
      "Affine transformation",
      "Algebra",
      "American English",
      "Analytic geometry",
      "Area",
      "Array data type",
      "Astronomy",
      "Augmented matrix",
      "Axes conventions",
      "Balloonist theory",
      "Bijective",
      "Bipolar coordinate system",
      "Bipolar cylindrical coordinates",
      "Bispherical coordinates",
      "British English",
      "Calculus",
      "Cartesian circle",
      "Cartesian coordinate robot",
      "Cartesian diver",
      "Cartesian doubt",
      "Cartesian product",
      "Cartesianism",
      "Causal adequacy principle",
      "Christina, Queen of Sweden",
      "Circle",
      "Clockwise",
      "Cogito, ergo sum",
      "Column matrix",
      "Complex analysis",
      "Complex number",
      "Computational geometry",
      "Computer-aided geometric design",
      "Computer graphics",
      "Computer programming",
      "Conical coordinates",
      "Coordinate frame",
      "Coordinate line",
      "Coordinate rotations and reflections",
      "Coordinate system",
      "Curve",
      "Curve orientation",
      "Cylindrical coordinate system",
      "Degree of freedom",
      "Derivative"
    ],
    "categories": [
      "Category:Analytic geometry",
      "Category:Articles with short description",
      "Category:Elementary mathematics",
      "Category:Orthogonal coordinate systems",
      "Category:René Descartes",
      "Category:Short description is different from Wikidata",
      "Category:Three-dimensional coordinate systems",
      "Category:Use dmy dates from December 2022"
    ]
  },
  "Ancient Greece": {
    "title": "Ancient Greece",
    "url": "https://en.wikipedia.org/wiki/Ancient_Greece",
    "summary": "Ancient Greece (Ancient Greek: Ἑλλάς, romanized: Hellás) was a northeastern Mediterranean civilization, existing from the Greek Dark Ages of the 12th–9th centuries BC to the end of classical antiquity (c. 600 AD), that comprised a loose collection of culturally and linguistically related city-states and communities. Prior to the Roman period, most of these regions were officially unified only once under the Kingdom of Macedon from 338 to 323 BC. In Western history, the era of classical antiquity was immediately followed by the Early Middle Ages and the Byzantine period.\nThree centuries after the decline of Mycenaean Greece during the Bronze Age collapse, Greek urban poleis began to form in the 8th century BC, ushering in the Archaic period and the colonization of the Mediterranean Basin. This was followed by the age of Classical Greece, from the Greco-Persian Wars to the death of Alexander the Great in 323 BC, and which included the Golden Age of Athens and the Peloponnesian War. The u",
    "content": "Ancient Greece (Ancient Greek: Ἑλλάς, romanized: Hellás) was a northeastern Mediterranean civilization, existing from the Greek Dark Ages of the 12th–9th centuries BC to the end of classical antiquity (c. 600 AD), that comprised a loose collection of culturally and linguistically related city-states and communities. Prior to the Roman period, most of these regions were officially unified only once under the Kingdom of Macedon from 338 to 323 BC. In Western history, the era of classical antiquity was immediately followed by the Early Middle Ages and the Byzantine period.\nThree centuries after the decline of Mycenaean Greece during the Bronze Age collapse, Greek urban poleis began to form in the 8th century BC, ushering in the Archaic period and the colonization of the Mediterranean Basin. This was followed by the age of Classical Greece, from the Greco-Persian Wars to the death of Alexander the Great in 323 BC, and which included the Golden Age of Athens and the Peloponnesian War. The unification of Greece by Macedon under Philip II and subsequent conquest of the Achaemenid Empire by Alexander the Great spread Hellenistic civilization across the Middle East. The Hellenistic period is considered to have ended in 30 BC, when the last Hellenistic kingdom, Ptolemaic Egypt, was annexed by the Roman Republic.\nClassical Greek culture, especially philosophy, had a powerful influence on ancient Rome, which carried a version of it throughout the Mediterranean and much of Europe. For this reason, Classical Greece is generally considered the cradle of Western civilization, the seminal culture from which the modern West derives many of its founding archetypes and ideas in politics, philosophy, science, and art.\n\nChronology\nClassical antiquity in the Mediterranean region is commonly considered to have begun in the 8th century BC (around the time of the earliest recorded poetry of Homer) and ended in the 6th century AD.\nClassical antiquity in Greece was preceded by the Greek Dark Ages (c. 1200 – c. 800 BC), archaeologically characterised by the protogeometric and geometric styles of designs on pottery. Following the Dark Ages was the Archaic period, beginning around the 8th century BC, which saw early developments in Greek culture and society leading to the Classical period from the Persian invasion of Greece in 480 BC until the death of Alexander the Great in 323 BC. The Classical period is characterized by a \"classical\" style, i.e. one which was considered exemplary by later observers, most famously in the Parthenon of Athens. Politically, the Classical period was dominated by Athens and the Delian League during the 5th century, but displaced by Spartan hegemony during the early 4th century BC, before power shifted to Thebes and the Boeotian League and finally to the League of Corinth led by Macedon. This period was shaped by the Greco-Persian Wars, the Peloponnesian War, and the Rise of Macedon.\nFollowing the Classical period was the Hellenistic period (323–146 BC), during which Greek culture and power expanded into the Near East from the death of Alexander until the Roman conquest. Roman Greece is usually counted from the Roman victory over the Corinthians at the Battle of Corinth in 146 BC to the establishment of Byzantium by Constantine as the capital of the Roman Empire in 330 AD. Finally, Late Antiquity refers to the period of Christianization during the later 4th to early 6th centuries AD, consummated by the closure of the Academy of Athens by Justinian I in 529.\n\nHistoriography\nThe historical period of ancient Greece is unique in world history as the first period attested directly in comprehensive, narrative historiography, while earlier ancient history or protohistory is known from much more fragmentary documents such as annals, king lists, and pragmatic epigraphy.\nHerodotus is widely known as the \"father of history\": his Histories are eponymous of the entire field. Written between the 450s and 420s BC, Herodotus' work reaches about a century into the past, discussing 6th-century BC historical figures such as Darius I of Persia, Cambyses II and Psamtik III, and alluding to some 8th-century BC persons such as Candaules. The accuracy of Herodotus' works is debated.\nHerodotus was succeeded by authors such as Thucydides, Xenophon, Demosthenes, Plato and Aristotle. Most were either Athenian or pro-Athenian, which is why far more is known about the history and politics of Athens than of many other cities.\nTheir scope is further limited by a focus on political, military and diplomatic history, ignoring economic and social history.\n\nHistory\nArchaic period\nThe archaic period, lasting approximately from 800 to 500 BC, saw the culmination of political and social developments which had begun in the Greek Dark Age, with the polis (city-state) becoming the most important unit of political organisation in Greece. The absence of powerful states in Greece after the collapse of Mycenaean power, and the geography of Greece, where ",
    "links": [
      "20th-century Western painting",
      "4th of August Regime",
      "ABCANZ Armies",
      "ANZUK",
      "ANZUS",
      "AUKUS",
      "AUSCANNZUKUS",
      "Abolitionism",
      "Abonoteichos",
      "Abrahamic religions",
      "Acarnania",
      "Acarnanian League",
      "Achaea (province)",
      "Achaean League",
      "Achaean War",
      "Achaemenid Empire",
      "Acharnians",
      "Acropolis",
      "Aegean Islands",
      "Aegean Sea",
      "Aegean civilization",
      "Aegina",
      "Aeginetan War",
      "Aeolian Islands",
      "Aeolic Greek",
      "Aeolis",
      "Aeschylus",
      "Aesop",
      "Aetolia",
      "Aetolian League",
      "Aetolian War",
      "Afghanistan",
      "Age of Discovery",
      "Age of Enlightenment",
      "Age of Revolution",
      "Agnosticism",
      "Agora",
      "Agriculture in ancient Greece",
      "Agrigento",
      "Akra (Crimmerian Bosporus)",
      "Akrai",
      "Akrillai",
      "Al-Mina",
      "Al Mina",
      "Alcaeus of Mytilene",
      "Alexander I of Macedon",
      "Alexander Mosaic",
      "Alexander the Great",
      "Alexandria",
      "Alicudi"
    ],
    "categories": [
      "Category:All articles with unsourced statements",
      "Category:Ancient Greece",
      "Category:Articles containing Ancient Greek (to 1453)-language text",
      "Category:Articles containing Latin-language text",
      "Category:Articles which contain graphical timelines",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from April 2025",
      "Category:Articles with unsourced statements from August 2024",
      "Category:CS1: long volume value",
      "Category:CS1 errors: ISBN date"
    ]
  },
  "Apollonius of Perga": {
    "title": "Apollonius of Perga",
    "url": "https://en.wikipedia.org/wiki/Apollonius_of_Perga",
    "summary": "Apollonius of Perga (Ancient Greek: Ἀπολλώνιος ὁ Περγαῖος Apollṓnios ho Pergaîos; c. 240 BC – c. 190 BC) was an ancient Greek geometer and astronomer known for his work on conic sections. Beginning from the earlier contributions of Euclid and Archimedes on the topic, he brought them to the state prior to the invention of analytic geometry. His definitions of the terms ellipse, parabola, and hyperbola are the ones in use today. With his predecessors Euclid and Archimedes, Apollonius is generally considered among the greatest mathematicians of antiquity. \nAside from geometry, Apollonius worked on numerous other topics, including astronomy. Most of this work has not survived, where exceptions are typically fragments referenced by other authors like Pappus of Alexandria. His hypothesis of eccentric orbits to explain the apparently aberrant motion of the planets, commonly believed until the Middle Ages, was superseded during the Renaissance. The Apollonius crater on the Moon is named in his",
    "content": "Apollonius of Perga (Ancient Greek: Ἀπολλώνιος ὁ Περγαῖος Apollṓnios ho Pergaîos; c. 240 BC – c. 190 BC) was an ancient Greek geometer and astronomer known for his work on conic sections. Beginning from the earlier contributions of Euclid and Archimedes on the topic, he brought them to the state prior to the invention of analytic geometry. His definitions of the terms ellipse, parabola, and hyperbola are the ones in use today. With his predecessors Euclid and Archimedes, Apollonius is generally considered among the greatest mathematicians of antiquity. \nAside from geometry, Apollonius worked on numerous other topics, including astronomy. Most of this work has not survived, where exceptions are typically fragments referenced by other authors like Pappus of Alexandria. His hypothesis of eccentric orbits to explain the apparently aberrant motion of the planets, commonly believed until the Middle Ages, was superseded during the Renaissance. The Apollonius crater on the Moon is named in his honor.\n\nLife\nDespite his momentous contributions to the field of mathematics, scant biographical information on  Apollonius remains. The 6th century Greek commentator Eutocius of Ascalon, writing on Apollonius' Conics, states: \n\nApollonius, the geometrician, ...  came from Perga in Pamphylia in the times of Ptolemy III Euergetes, so records Herakleios the biographer of Archimedes ....\nFrom this passage Apollonius can be approximately dated, but specific birth and death years stated by modern scholars are only speculative. Ptolemy III Euergetes (\"benefactor\") was third Greek dynast of Egypt in the Diadochi succession, who reigned 246–222/221 BC. \"Times\" are always recorded by ruler or officiating magistrate, so Apollonius was likely born after 246. The identity of Herakleios is uncertain.\nPerga was a Hellenized city in Pamphylia, Anatolia, whose ruins yet stand. It was a center of Hellenistic culture. Eutocius appears to associate Perga with the Ptolemaic dynasty of Egypt. Never under Egypt, Perga in 246 BC belonged to the Seleucid Empire, an independent diadochi state ruled by the Seleucid dynasty. During the last half of the 3rd century BC, Perga changed hands a number of times, being alternatively under the Seleucids and under the Attalids of Pergamon to the north. Someone designated \"of Perga\" might be expected to have lived and worked there; to the contrary, if Apollonius was later identified with Perga, it was not on the basis of his residence. The remaining autobiographical material implies that he lived, studied, and wrote in Alexandria.\nA letter by the Greek mathematician and astronomer Hypsicles was originally part of the supplement taken from a pseudepigraphic work transmitted as Book XIV of Euclid's Elements.\n\nBasilides of Tyre, O Protarchus, when he came to Alexandria and met my father, spent the greater part of his sojourn with him on account of the bond between them due to their common interest in mathematics. And on one occasion, when looking into the tract written by Apollonius about the comparison of the dodecahedron and icosahedron inscribed in one and the same sphere, that is to say, on the question what ratio they bear to one another, they came to the conclusion that Apollonius' treatment of it in this book was not correct; accordingly, as I understood from my father, they proceeded to amend and rewrite it. But I myself afterwards came across another book published by Apollonius, containing a demonstration of the matter in question, and I was greatly attracted by his investigation of the problem. Now the book published by Apollonius is accessible to all; for it has a large circulation in a form which seems to have been the result of later careful elaboration.\n\nAutobiographical prefaces\nSome autobiographical material can be found in the surviving prefaces to the books of Conics. These are letters Apollonius addressed to influential friends asking them to review the book enclosed with the letter. The first two prefaces are addressed to Eudemus of Pergamon.\nEudemus likely was or became the head of the research center of the Museum of Pergamon, a city known for its books and parchment industry from which the name parchment is derived. Research in Greek mathematical institutions, which followed the model of the Athenian Lycaeum, was part of the educational effort to which the library and museum were adjunct. There was only one such school in the state, under royal patronage. Books were rare and expensive and collecting them was a royal obligation.\nApollonius's preface to Book I tells Eudemus that the first four books were concerned with the development of elements while the last four were concerned with special topics. Apollonius reminds Eudemus that Conics was initially requested by Naucrates, a geometer and house guest at Alexandria otherwise unknown to history. Apollonius provided Naucrates the first draft of all eight books, but he refers to them as being \"without a thorough purgation\", and intended to veri",
    "links": [
      "A History of Greek Mathematics",
      "Aberdeen",
      "Abscissa",
      "Acta Eruditorum",
      "Adrianus Romanus",
      "Aglaonice",
      "Agrippa (astronomer)",
      "Al-Ma'mun",
      "Alexander Anderson (mathematician)",
      "Almagest",
      "Analytic geometry",
      "Analytical geometry",
      "Anatolia",
      "Anaxagoras",
      "Anaximander",
      "Ancient Egyptian mathematics",
      "Ancient Greek astronomy",
      "Ancient Greek language",
      "Ancient Greek mathematics",
      "Ancient Greek units of measurement",
      "Andronicus of Cyrrhus",
      "Angle",
      "Angle bisector theorem",
      "Angle trisection",
      "Anthemius of Tralles",
      "Antikythera mechanism",
      "Apex (geometry)",
      "Apollonian circles",
      "Apollonian gasket",
      "Apollonius's theorem",
      "Apollonius (crater)",
      "Aratus",
      "Archimedes",
      "Archimedes Palimpsest",
      "Archytas",
      "Aristaeus the Elder",
      "Aristarchus's inequality",
      "Aristarchus of Samos",
      "Aristyllus",
      "Arithmetica",
      "Armillary sphere",
      "Astrolabe",
      "Astronomer",
      "Astronomy in the medieval Islamic world",
      "Asymptotes",
      "Attalid kingdom",
      "Attalus II Philadelphus",
      "Attalus of Rhodes",
      "Attic numerals",
      "Autolycus of Pitane"
    ],
    "categories": [
      "Category:190s BC deaths",
      "Category:260s BC births",
      "Category:2nd-century BC Greek mathematicians",
      "Category:3rd-century BC Greek mathematicians",
      "Category:All articles needing rewrite",
      "Category:All articles with unsourced statements",
      "Category:Ancient Greek astronomers",
      "Category:Ancient Greek geometers",
      "Category:Ancient Greek inventors",
      "Category:Articles containing Ancient Greek (to 1453)-language text"
    ]
  },
  "Balloonist theory": {
    "title": "Balloonist theory",
    "url": "https://en.wikipedia.org/wiki/Balloonist_theory",
    "summary": "Balloonist theory was a theory in early neuroscience that attempted to explain muscle movement by asserting that muscles contract by inflating with air or fluid. The Roman and Greek physician Galen believed that muscles contracted due to a fluid flowing into them, and for 1500 years afterward, it was believed that nerves were hollow and that they carried fluid.  René Descartes, who was interested in hydraulics and used fluid pressure to explain various aspects of physiology such as the reflex arc, proposed that \"animal spirits\" flowed into muscle and were responsible for their contraction. In the model, which Descartes used to explain reflexes, the spirits would flow from the ventricles of the brain, through the nerves, and to the muscles to animate the latter.\nIn 1667, Thomas Willis proposed that muscles may expand by the reaction of animal spirits with vital spirits.  He hypothesized that this reaction would produce air in a manner similar to the reaction that causes an explosion, ca",
    "content": "Balloonist theory was a theory in early neuroscience that attempted to explain muscle movement by asserting that muscles contract by inflating with air or fluid. The Roman and Greek physician Galen believed that muscles contracted due to a fluid flowing into them, and for 1500 years afterward, it was believed that nerves were hollow and that they carried fluid.  René Descartes, who was interested in hydraulics and used fluid pressure to explain various aspects of physiology such as the reflex arc, proposed that \"animal spirits\" flowed into muscle and were responsible for their contraction. In the model, which Descartes used to explain reflexes, the spirits would flow from the ventricles of the brain, through the nerves, and to the muscles to animate the latter.\nIn 1667, Thomas Willis proposed that muscles may expand by the reaction of animal spirits with vital spirits.  He hypothesized that this reaction would produce air in a manner similar to the reaction that causes an explosion, causing muscles to swell and produce movement.\nThis theory has now been superseded by the mainstream scientific community due to the establishment of neuroscience, which is supported by empirical evidence.\n\nPhysiological refutations of the theory\nIn 1667, Jan Swammerdam, a Dutch anatomist famous for working with insects, struck the first important blow against the balloonist theory.  Swammerdam, who was the first to experiment on nerve-muscle preparations, showed that muscles do not increase in size when they contract (and he supposed if a substance such as animal spirits flowed into muscles, their volume should increase when they contract).  Swammerdam placed severed frog thigh muscle in an airtight syringe with a small amount of water in the tip.  He could thus determine whether there was a change the volume of the muscle when it contracted by observing a change in the level of the water (image at right). When Swammerdam caused the muscle to contract by irritating the nerve, the water level did not rise but rather was lowered by a minute amount; this showed that no air or fluid could be flowing into the muscle.  Swammerdam did not believe the results of his own experiment, suggesting that they were the result of artifact.  However, he concluded in his book The Book of Nature II that \"motion or irritation of the nerve alone is necessary to produce muscular motion\". This idea was an important step toward the current understanding of how nerves actually cause muscle contraction.\nBalloonist theory took a second hit from Francis Glisson who performed an experiment in which a man flexed a muscle under water. The water level did not go up (in fact it went down slightly), further supporting the conclusion that no air or fluid could be entering the muscle.\nGiovanni Alfonso Borelli performed an experiment to test the idea that muscle is inflated by air. He slit the muscle of an animal under water and watched to see whether bubbles of air would rise to the surface. Since no bubbles were seen to rise, this experiment helped to refute the balloonist theory.\nThe invention of the microscope allowed preparations of nerves to be viewed at high magnification, showing that they are not hollow.\nIn 1791, Luigi Galvani learned that frogs' muscles could be made to move by the application of electricity.  This finding provided a basis for the current understanding that electrical energy (carried by ions), and not air or fluid, is the impetus behind muscle movement.\n\nSee also\nPassions of the Soul\n\n\n== References ==",
    "links": [
      "Analytic geometry",
      "Anatomist",
      "Brain ventricle",
      "Cartesian circle",
      "Cartesian coordinate system",
      "Cartesian diver",
      "Cartesian doubt",
      "Cartesianism",
      "Causal adequacy principle",
      "Christina, Queen of Sweden",
      "Cogito, ergo sum",
      "Descartes' rule of signs",
      "Discourse on the Method",
      "Doi (identifier)",
      "Dream argument",
      "Electricity",
      "Evil demon",
      "Existence of God",
      "Folium of Descartes",
      "Foundationalism",
      "Francine Descartes",
      "Francis Glisson",
      "Galen",
      "Giovanni Alfonso Borelli",
      "Hydraulics",
      "Ion",
      "Jan Swammerdam",
      "La Géométrie",
      "Luigi Galvani",
      "Mechanism (philosophy)",
      "Meditations on First Philosophy",
      "Mental substance",
      "Microscope",
      "Mind–body problem",
      "Muscle",
      "Nerve-muscle preparation",
      "Neuroscience",
      "PMID (identifier)",
      "Passions of the Soul",
      "Physiology",
      "Principles of Philosophy",
      "Rationalism",
      "Reflex",
      "Reflex arc",
      "René Descartes",
      "Res extensa",
      "Rules for the Direction of the Mind",
      "S2CID (identifier)",
      "Superseded theories in science",
      "The Search for Truth by Natural Light"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:History of neuroscience",
      "Category:Muscular system",
      "Category:Short description matches Wikidata"
    ]
  },
  "Cantor–Dedekind axiom": {
    "title": "Cantor–Dedekind axiom",
    "url": "https://en.wikipedia.org/wiki/Cantor%E2%80%93Dedekind_axiom",
    "summary": "In mathematical logic, the Cantor–Dedekind axiom is the thesis that the real numbers are order-isomorphic to the linear continuum of geometry. In other words, the axiom states that there is a one-to-one correspondence between real numbers and points on a line.\nThis axiom became a theorem proved by Emil Artin in his book Geometric Algebra. More precisely, Euclidean spaces defined over the field of real numbers satisfy the axioms of Euclidean geometry, and, from the axioms of Euclidean geometry, one can construct a field that is isomorphic to the real numbers.\nAnalytic geometry was developed from the Cartesian coordinate system introduced by René Descartes. It implicitly assumed this axiom by blending the distinct concepts of real numbers and points on a line, sometimes referred to as the real number line. Artin's proof, not only makes this blend explicitly, but also that analytic geometry is strictly equivalent with the traditional synthetic geometry, in the sense that exactly the same ",
    "content": "In mathematical logic, the Cantor–Dedekind axiom is the thesis that the real numbers are order-isomorphic to the linear continuum of geometry. In other words, the axiom states that there is a one-to-one correspondence between real numbers and points on a line.\nThis axiom became a theorem proved by Emil Artin in his book Geometric Algebra. More precisely, Euclidean spaces defined over the field of real numbers satisfy the axioms of Euclidean geometry, and, from the axioms of Euclidean geometry, one can construct a field that is isomorphic to the real numbers.\nAnalytic geometry was developed from the Cartesian coordinate system introduced by René Descartes. It implicitly assumed this axiom by blending the distinct concepts of real numbers and points on a line, sometimes referred to as the real number line. Artin's proof, not only makes this blend explicitly, but also that analytic geometry is strictly equivalent with the traditional synthetic geometry, in the sense that exactly the same theorems can be proved in the two frameworks.\nAnother consequence is that Alfred Tarski's proof of the decidability of first-order theories of the real numbers could be seen as an algorithm to solve any first-order problem in Euclidean geometry.\n\nSee also\nCantor's theorem\n\nReferences\n\nArtin, Emil (1988) [1957], Geometric Algebra, Wiley Classics Library, New York: John Wiley & Sons Inc., pp. x+214, doi:10.1002/9781118164518, ISBN 0-471-60839-4, MR 1009557\nEhrlich, P. (1994). \"General introduction\". Real Numbers, Generalizations of the Reals, and Theories of Continua, vi–xxxii. Edited by P. Ehrlich, Kluwer Academic Publishers, Dordrecht\nBruce E. Meserve (1953) Fundamental Concepts of Algebra, p. 32, at Google Books\nB.E. Meserve (1955) Fundamental Concepts of Geometry, p. 86, at Google Books",
    "links": [
      "0.999...",
      "Absolute difference",
      "Alfred Tarski",
      "Algorithm",
      "Alice T. Schafer",
      "Analytic geometry",
      "Axiom",
      "Cantor's theorem",
      "Cantor set",
      "Cartesian coordinate system",
      "Completeness of the real numbers",
      "Construction of the real numbers",
      "Decidability of first-order theories of the real numbers",
      "Doi (identifier)",
      "Emil Artin",
      "Euclidean geometry",
      "Euclidean space",
      "Extended real number line",
      "Field (mathematics)",
      "Geometric Algebra (book)",
      "Geometry",
      "Google Books",
      "Gregory number",
      "ISBN (identifier)",
      "Irrational number",
      "Isomorphic",
      "Linear continuum",
      "MR (identifier)",
      "Mathematical logic",
      "Normal number",
      "Rational number",
      "Rational zeta series",
      "Real coordinate space",
      "Real line",
      "Real number",
      "Real number line",
      "René Descartes",
      "Synthetic geometry",
      "Tarski's axiomatization of the reals",
      "Theorem",
      "Vitali set",
      "Wikipedia:Stub",
      "Template:Mathlogic-stub",
      "Template:Real numbers",
      "Template talk:Mathlogic-stub",
      "Template talk:Real numbers"
    ],
    "categories": [
      "Category:All stub articles",
      "Category:Articles with short description",
      "Category:Mathematical axioms",
      "Category:Mathematical logic stubs",
      "Category:Real numbers",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Dimension (vector space)": {
    "title": "Dimension (vector space)",
    "url": "https://en.wikipedia.org/wiki/Dimension_(vector_space)",
    "summary": "In mathematics, the dimension of a vector space V is the cardinality (i.e., the number of vectors) of a basis of V over its base field. It is sometimes called Hamel dimension (after Georg Hamel) or algebraic dimension to distinguish it from other types of dimension.\nFor every vector space there exists a basis, and all bases of a vector space have equal cardinality; as a result, the dimension of a vector space is uniquely defined. We say \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n is finite-dimensional if the dimension of \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n is finite, and infinite-dimensional if its dimension is infinite.\nThe dimension of the vector space \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n over the field \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n can be written as \n  \n    \n      \n        \n          dim\n          \n            F\n          \n        \n        ⁡\n        (\n        V\n        )\n    ",
    "content": "In mathematics, the dimension of a vector space V is the cardinality (i.e., the number of vectors) of a basis of V over its base field. It is sometimes called Hamel dimension (after Georg Hamel) or algebraic dimension to distinguish it from other types of dimension.\nFor every vector space there exists a basis, and all bases of a vector space have equal cardinality; as a result, the dimension of a vector space is uniquely defined. We say \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n is finite-dimensional if the dimension of \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n is finite, and infinite-dimensional if its dimension is infinite.\nThe dimension of the vector space \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n over the field \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n can be written as \n  \n    \n      \n        \n          dim\n          \n            F\n          \n        \n        ⁡\n        (\n        V\n        )\n      \n    \n    {\\displaystyle \\dim _{F}(V)}\n  \n or as \n  \n    \n      \n        [\n        V\n        :\n        F\n        ]\n        ,\n      \n    \n    {\\displaystyle [V:F],}\n  \n read \"dimension of \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n over \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n\". When \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n can be inferred from context, \n  \n    \n      \n        dim\n        ⁡\n        (\n        V\n        )\n      \n    \n    {\\displaystyle \\dim(V)}\n  \n is typically written.\n\nExamples\nThe vector space \n  \n    \n      \n        \n          \n            R\n          \n          \n            3\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{3}}\n  \n has\n\n  \n    \n      \n        \n          {\n          \n            \n              \n                (\n                \n                  \n                    \n                      1\n                    \n                  \n                  \n                    \n                      0\n                    \n                  \n                  \n                    \n                      0\n                    \n                  \n                \n                )\n              \n            \n            ,\n            \n              \n                (\n                \n                  \n                    \n                      0\n                    \n                  \n                  \n                    \n                      1\n                    \n                  \n                  \n                    \n                      0\n                    \n                  \n                \n                )\n              \n            \n            ,\n            \n              \n                (\n                \n                  \n                    \n                      0\n                    \n                  \n                  \n                    \n                      0\n                    \n                  \n                  \n                    \n                      1\n                    \n                  \n                \n                )\n              \n            \n          \n          }\n        \n      \n    \n    {\\displaystyle \\left\\{{\\begin{pmatrix}1\\\\0\\\\0\\end{pmatrix}},{\\begin{pmatrix}0\\\\1\\\\0\\end{pmatrix}},{\\begin{pmatrix}0\\\\0\\\\1\\end{pmatrix}}\\right\\}}\n  \n\nas a standard basis, and therefore \n  \n    \n      \n        \n          dim\n          \n            \n              R\n            \n          \n        \n        ⁡\n        (\n        \n          \n            R\n          \n          \n            3\n          \n        \n        )\n        =\n        3.\n      \n    \n    {\\displaystyle \\dim _{\\mathbb {R} }(\\mathbb {R} ^{3})=3.}\n  \n More generally, \n  \n    \n      \n        \n          dim\n          \n            \n              R\n            \n          \n        \n        ⁡\n        (\n        \n          \n            R\n          \n          \n            n\n          \n        \n        )\n        =\n        n\n        ,\n      \n    \n    {\\displaystyle \\dim _{\\mathbb {R} }(\\mathbb {R} ^{n})=n,}\n  \n and even more generally, \n  \n    \n      \n        \n          dim\n          \n            F\n          \n        \n        ⁡\n        (\n        \n          F\n          \n            n\n          \n        \n        )\n        =\n        n\n      \n    \n    {\\displaystyle \\dim _{F}(F^{n})=n}\n  \n for any field \n  \n    \n      \n        F\n        .\n      \n    \n    {\\displaystyle F.}\n  \n \nThe complex numbers \n  \n    \n      \n        \n          C\n        \n      \n    \n    {\\displaystyle \\mathbb {C} }\n  \n are both a real and complex vector space; we have \n  \n    \n      \n        \n          dim\n          \n            \n              R\n            \n          \n        \n        ⁡\n        (\n        \n          C\n        \n        )\n        =\n        2\n      \n    \n    {\\displaystyle \\dim _{\\mathbb {R} }(\\mathbb {C} )=2}\n  \n and \n  \n    \n      \n        \n          dim\n          \n            \n              C\n            \n          \n        \n        ⁡\n        (\n        ",
    "links": [
      "Affine space",
      "Algebra over a field",
      "Axiom of choice",
      "Banach space",
      "Basic Linear Algebra Subprograms",
      "Basis (linear algebra)",
      "Bialgebra",
      "Bijective",
      "Bilinear map",
      "Bivector",
      "Block matrix",
      "Cardinality",
      "Cayley–Dickson construction",
      "Change of basis",
      "Character (mathematics)",
      "Circular definition",
      "Codimension",
      "Comparison of linear algebra libraries",
      "Complex number",
      "Counit",
      "Cramer's rule",
      "Cross-polytope",
      "Cross product",
      "Degrees of freedom",
      "Demihypercube",
      "Determinant",
      "Dimension",
      "Dimension of an algebraic variety",
      "Dimension theorem for vector spaces",
      "Direct sum of modules",
      "Dot product",
      "Dual space",
      "Eigenvalues and eigenvectors",
      "Eight-dimensional space",
      "Euclidean space",
      "Euclidean vector",
      "Exterior algebra",
      "Field (mathematics)",
      "Field extension",
      "Five-dimensional space",
      "Floating-point arithmetic",
      "Four-dimensional space",
      "Fractal dimension",
      "Free module",
      "Function space",
      "Gaussian elimination",
      "Geometric algebra",
      "Georg Hamel",
      "Glossary of linear algebra",
      "Graded dimension"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Dimension",
      "Category:Linear algebra",
      "Category:Pages displaying short descriptions of redirect targets via Module:Annotated link",
      "Category:Short description matches Wikidata",
      "Category:Vector spaces",
      "Category:Vectors (mathematics and physics)"
    ]
  },
  "Hadjicostas's formula": {
    "title": "Hadjicostas's formula",
    "url": "https://en.wikipedia.org/wiki/Hadjicostas%27s_formula",
    "summary": "In mathematics, Hadjicostas's formula is a formula relating a certain double integral to values of the gamma function and the Riemann zeta function. It is named after Petros Hadjicostas.",
    "content": "In mathematics, Hadjicostas's formula is a formula relating a certain double integral to values of the gamma function and the Riemann zeta function. It is named after Petros Hadjicostas.\n\nStatement\nLet s be a complex number with s ≠ -1 and Re(s) > −2.  Then\n\n  \n    \n      \n        \n          ∫\n          \n            0\n          \n          \n            1\n          \n        \n        \n          ∫\n          \n            0\n          \n          \n            1\n          \n        \n        \n          \n            \n              1\n              −\n              x\n            \n            \n              1\n              −\n              x\n              y\n            \n          \n        \n        (\n        −\n        log\n        ⁡\n        (\n        x\n        y\n        )\n        \n          )\n          \n            s\n          \n        \n        \n        d\n        x\n        \n        d\n        y\n        =\n        Γ\n        (\n        s\n        +\n        2\n        )\n        \n          (\n          \n            ζ\n            (\n            s\n            +\n            2\n            )\n            −\n            \n              \n                1\n                \n                  s\n                  +\n                  1\n                \n              \n            \n          \n          )\n        \n        .\n      \n    \n    {\\displaystyle \\int _{0}^{1}\\int _{0}^{1}{\\frac {1-x}{1-xy}}(-\\log(xy))^{s}\\,dx\\,dy=\\Gamma (s+2)\\left(\\zeta (s+2)-{\\frac {1}{s+1}}\\right).}\n  \n\nHere Γ is the Gamma function and ζ is the Riemann zeta function.\n\nBackground\nThe first instance of the formula was proved and used by Frits Beukers in his 1978 paper giving an alternative proof of Apéry's theorem.  He proved the formula when s = 0, and proved an equivalent formulation for the case s = 1.  This led Petros Hadjicostas to conjecture the above formula in 2004, and within a week it had been proven by Robin Chapman.  He proved the formula holds when Re(s) > −1, and then extended the result by analytic continuation to get the full result.\n\nSpecial cases\nAs well as the two cases used by Beukers to get alternate expressions for ζ(2) and ζ(3), the formula can be used to express the Euler–Mascheroni constant as a double integral by letting s tend to −1:\n\n  \n    \n      \n        γ\n        =\n        \n          ∫\n          \n            0\n          \n          \n            1\n          \n        \n        \n          ∫\n          \n            0\n          \n          \n            1\n          \n        \n        \n          \n            \n              1\n              −\n              x\n            \n            \n              (\n              1\n              −\n              x\n              y\n              )\n              (\n              −\n              log\n              ⁡\n              (\n              x\n              y\n              )\n              )\n            \n          \n        \n        \n        d\n        x\n        \n        d\n        y\n        .\n      \n    \n    {\\displaystyle \\gamma =\\int _{0}^{1}\\int _{0}^{1}{\\frac {1-x}{(1-xy)(-\\log(xy))}}\\,dx\\,dy.}\n  \n\nThe latter formula was first discovered by Jonathan Sondow and is the one referred to in the title of Hadjicostas's paper.\n\nNotes\nSee also\nHessami Pilehrood, Kh.; Hessami Pilehrood, T. (2008). \"Vacca-type series for values of the generalized-Euler-constant function and its derivative\". arXiv:0808.0410 [math.NT].\nSondow, J (2005). \"Double integrals for Euler's constant and ln 4/π and an analog of Hadjicostas's formula\". American Mathematical Monthly. 112: 61–65. arXiv:math.CA/0211148. doi:10.2307/30037385. JSTOR 30037385.\nSondow, Jonathan; Hadjicostas, Petros (2008). \"The generalized-Euler-constant function γ(z) and a generalization of Somos's quadratic recurrence constant\". Journal of Mathematical Analysis and Applications. 332: 292–314. arXiv:math/0610499. doi:10.1016/j.jmaa.2006.09.081.",
    "links": [
      "American Mathematical Monthly",
      "Analytic continuation",
      "Apéry's theorem",
      "ArXiv (identifier)",
      "Complex number",
      "Doi (identifier)",
      "Euler–Mascheroni constant",
      "Frits Beukers",
      "Gamma function",
      "JSTOR (identifier)",
      "Mathematics",
      "Multiple integral",
      "Riemann zeta function"
    ],
    "categories": [
      "Category:Zeta and L-functions"
    ]
  },
  "Hypergeometric series": {
    "title": "Hypergeometric function",
    "url": "https://en.wikipedia.org/wiki/Hypergeometric_function",
    "summary": "In mathematics, the Gaussian or ordinary hypergeometric function 2F1(a,b;c;z) is a special function represented by the hypergeometric series, that includes many other special functions as specific or limiting cases. It is a solution of a second-order linear ordinary differential equation (ODE). Every second-order linear ODE with three regular singular points can be transformed into this equation.\nFor systematic lists of some of the many thousands of published identities involving the hypergeometric function, see the reference works by Erdélyi et al. (1953) and Olde Daalhuis (2010). There is no known system for organizing all of the identities; indeed, there is no known algorithm that can generate all identities; a number of different algorithms are known that generate different series of identities. The theory of the algorithmic discovery of identities remains an active research topic.",
    "content": "In mathematics, the Gaussian or ordinary hypergeometric function 2F1(a,b;c;z) is a special function represented by the hypergeometric series, that includes many other special functions as specific or limiting cases. It is a solution of a second-order linear ordinary differential equation (ODE). Every second-order linear ODE with three regular singular points can be transformed into this equation.\nFor systematic lists of some of the many thousands of published identities involving the hypergeometric function, see the reference works by Erdélyi et al. (1953) and Olde Daalhuis (2010). There is no known system for organizing all of the identities; indeed, there is no known algorithm that can generate all identities; a number of different algorithms are known that generate different series of identities. The theory of the algorithmic discovery of identities remains an active research topic.\n\nHistory\nThe term \"hypergeometric series\" was first used by John Wallis in his 1655 book Arithmetica Infinitorum.\nHypergeometric series were studied by Leonhard Euler, but the first full systematic treatment was given by Carl Friedrich Gauss (1813).\nStudies in the nineteenth century included those of Ernst Kummer (1836), and the fundamental characterisation by Bernhard Riemann (1857) of the hypergeometric function by means of the differential equation it satisfies.\nRiemann showed that the second-order differential equation for 2F1(z), examined in the complex plane, could be characterised (on the Riemann sphere) by its three regular singularities.\nThe cases where the solutions are algebraic functions were found by Hermann Schwarz (Schwarz's list).\n\nThe hypergeometric series\nThe hypergeometric function is defined for |z| < 1 by the power series\n\n  \n    \n      \n        \n          \n\n          \n          \n            2\n          \n        \n        \n          F\n          \n            1\n          \n        \n        (\n        a\n        ,\n        b\n        ;\n        c\n        ;\n        z\n        )\n        =\n        \n          ∑\n          \n            n\n            =\n            0\n          \n          \n            ∞\n          \n        \n        \n          \n            \n              (\n              a\n              \n                )\n                \n                  n\n                \n              \n              (\n              b\n              \n                )\n                \n                  n\n                \n              \n            \n            \n              (\n              c\n              \n                )\n                \n                  n\n                \n              \n            \n          \n        \n        \n          \n            \n              z\n              \n                n\n              \n            \n            \n              n\n              !\n            \n          \n        \n        =\n        1\n        +\n        \n          \n            \n              a\n              b\n            \n            c\n          \n        \n        \n          \n            z\n            \n              1\n              !\n            \n          \n        \n        +\n        \n          \n            \n              a\n              (\n              a\n              +\n              1\n              )\n              b\n              (\n              b\n              +\n              1\n              )\n            \n            \n              c\n              (\n              c\n              +\n              1\n              )\n            \n          \n        \n        \n          \n            \n              z\n              \n                2\n              \n            \n            \n              2\n              !\n            \n          \n        \n        +\n        ⋯\n        .\n      \n    \n    {\\displaystyle {}_{2}F_{1}(a,b;c;z)=\\sum _{n=0}^{\\infty }{\\frac {(a)_{n}(b)_{n}}{(c)_{n}}}{\\frac {z^{n}}{n!}}=1+{\\frac {ab}{c}}{\\frac {z}{1!}}+{\\frac {a(a+1)b(b+1)}{c(c+1)}}{\\frac {z^{2}}{2!}}+\\cdots .}\n  \n\nIt is undefined (or infinite) if c equals a non-positive integer. Here (q)n is the (rising) Pochhammer symbol, which is defined by:\n\n  \n    \n      \n        (\n        q\n        \n          )\n          \n            n\n          \n        \n        =\n        \n          \n            {\n            \n              \n                \n                  1\n                \n                \n                  n\n                  =\n                  0\n                \n              \n              \n                \n                  q\n                  (\n                  q\n                  +\n                  1\n                  )\n                  ⋯\n                  (\n                  q\n                  +\n                  n\n                  −\n                  1\n                  )\n                \n                \n                  n\n                  >\n                  0\n                \n              \n            \n            \n          \n        \n      \n    \n    {\\displaystyle (q)_{n}={\\begin{cases}1&n=0\\\\q(q+1)\\cdots (q+n-1)&n>0\\end{cases}}}\n  \n\nThe series terminates if either a o",
    "links": [
      "1/2 + 1/4 + 1/8 + 1/16 + ⋯",
      "1/2 − 1/4 + 1/8 − 1/16 + ⋯",
      "1/4 + 1/16 + 1/64 + 1/256 + ⋯",
      "1 + 1 + 1 + 1 + ⋯",
      "1 + 2 + 3 + 4 + ⋯",
      "1 + 2 + 4 + 8 + ⋯",
      "1 − 1 + 2 − 6 + 24 − 120 + ⋯",
      "1 − 2 + 3 − 4 + ⋯",
      "1 − 2 + 4 − 8 + ⋯",
      "A Course of Modern Analysis",
      "Absolute convergence",
      "Algebraic function",
      "Alternating series",
      "American Mathematical Society",
      "Analytic continuation",
      "Appell series",
      "ArXiv (identifier)",
      "Arithmetic progression",
      "Arthur Erdélyi",
      "Automorphic function",
      "Barnes integral",
      "Basic hypergeometric series",
      "Bernhard Riemann",
      "Bessel functions",
      "Beta function",
      "Bibcode (identifier)",
      "Bilateral hypergeometric series",
      "Binomial theorem",
      "Binomial transform",
      "Carl Friedrich Gauss",
      "Cauchy sequence",
      "Chebyshev polynomial",
      "Chebyshev polynomials",
      "Complete elliptic integral",
      "Complete sequence",
      "Conditional convergence",
      "Confluent hypergeometric function",
      "Conformal map",
      "Convergent series",
      "Coxeter group",
      "Cube (algebra)",
      "Digamma function",
      "Digital Library of Mathematical Functions",
      "Dirichlet series",
      "Divergence of the sum of the reciprocals of the primes",
      "Divergent series",
      "Doi (identifier)",
      "E. L. Ince",
      "E. T. Whittaker",
      "Einar Hille"
    ],
    "categories": [
      "Category:All Wikipedia articles written in American English",
      "Category:Articles with short description",
      "Category:CS1 French-language sources (fr)",
      "Category:CS1 German-language sources (de)",
      "Category:CS1 Latin-language sources (la)",
      "Category:CS1 errors: ISBN date",
      "Category:Factorial and binomial topics",
      "Category:Hypergeometric functions",
      "Category:Ordinary differential equations",
      "Category:Series (mathematics)"
    ]
  },
  "Integral": {
    "title": "Integral",
    "url": "https://en.wikipedia.org/wiki/Integral",
    "summary": "In mathematics, an integral is the continuous analog of a sum, which is used to calculate areas, volumes, and their generalizations. Integration, the process of computing an integral, is one of the two fundamental operations of calculus, the other being differentiation. Integration was initially used to solve problems in mathematics and physics, such as finding the area under a curve, or determining displacement from velocity. Usage of integration expanded to a wide variety of scientific fields thereafter.\nA definite integral computes the signed area of the region in the plane that is bounded by the graph of a given function between two points in the real line. Conventionally, areas above the horizontal axis of the plane are positive while areas below are negative. Integrals also refer to the concept of an antiderivative, a function whose derivative is the given function; in this case, they are also called indefinite integrals. The fundamental theorem of calculus relates definite integ",
    "content": "In mathematics, an integral is the continuous analog of a sum, which is used to calculate areas, volumes, and their generalizations. Integration, the process of computing an integral, is one of the two fundamental operations of calculus, the other being differentiation. Integration was initially used to solve problems in mathematics and physics, such as finding the area under a curve, or determining displacement from velocity. Usage of integration expanded to a wide variety of scientific fields thereafter.\nA definite integral computes the signed area of the region in the plane that is bounded by the graph of a given function between two points in the real line. Conventionally, areas above the horizontal axis of the plane are positive while areas below are negative. Integrals also refer to the concept of an antiderivative, a function whose derivative is the given function; in this case, they are also called indefinite integrals. The fundamental theorem of calculus relates definite integration to differentiation and provides a method to compute the definite integral of a function when its antiderivative is known; differentiation and integration are inverse operations.\nAlthough methods of calculating areas and volumes dated from ancient Greek mathematics, the principles of integration were formulated independently by Isaac Newton and Gottfried Wilhelm Leibniz in the late 17th century, who thought of the area under a curve as an infinite sum of rectangles of infinitesimal width. Bernhard Riemann later gave a rigorous definition of integrals, which is based on a limiting procedure that approximates the area of a curvilinear region by breaking the region into infinitesimally thin vertical slabs. In the early 20th century, Henri Lebesgue generalized Riemann's formulation by introducing what is now referred to as the Lebesgue integral; it is more general than Riemann's in the sense that a wider class of functions are Lebesgue-integrable.\nIntegrals may be generalized depending on the type of the function as well as the domain over which the integration is performed. For example, a line integral is defined for functions of two or more variables, and the interval of integration is replaced by a curve connecting two points in space. In a surface integral, the curve is replaced by a piece of a surface in three-dimensional space.\n\nHistory\nPre-calculus integration\nThe first documented systematic technique capable of determining integrals is the method of exhaustion of the ancient Greek astronomer Eudoxus and philosopher Democritus (ca. 370 BC), which sought to find areas and volumes by breaking them up into an infinite number of divisions for which the area or volume was known. This method was further developed and employed by Archimedes in the 3rd century BC and used to calculate the area of a circle, the surface area and volume of a sphere, area of an ellipse, the area under a parabola, the volume of a segment of a paraboloid of revolution, the volume of a segment of a hyperboloid of revolution, and the area of a spiral.\nA similar method was independently developed in China around the 3rd century AD by Liu Hui, who used it to find the area of the circle. This method was later used in the 5th century by Chinese father-and-son mathematicians Zu Chongzhi and Zu Geng to find the volume of a sphere.\nIn the Middle East, Hasan Ibn al-Haytham, Latinized as Alhazen (c. 965 – c. 1040 AD) derived a formula for the sum of fourth powers. Alhazen determined the equations to calculate the area enclosed by the curve represented by \n  \n    \n      \n        y\n        =\n        \n          x\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle y=x^{k}}\n  \n (which translates to the integral \n  \n    \n      \n        ∫\n        \n          x\n          \n            k\n          \n        \n        \n        d\n        x\n      \n    \n    {\\displaystyle \\int x^{k}\\,dx}\n  \n in contemporary notation), for any given non-negative integer value of \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n. He used the results to carry out what would now be called an integration of this function, where the formulae for the sums of integral squares and fourth powers allowed him to calculate the volume of a paraboloid.\nThe next significant advances in integral calculus did not begin to appear until the 17th century. At this time, the work of Cavalieri with his method of indivisibles, and work by Fermat, began to lay the foundations of modern calculus, with Cavalieri computing the integrals of xn up to degree n = 9 in Cavalieri's quadrature formula. The case n = −1 required the invention of a function, the hyperbolic logarithm, achieved by quadrature of the hyperbola in 1647.\nFurther steps were made in the early 17th century by Barrow and Torricelli, who provided the first hints of a connection between integration and differentiation. Barrow provided the first proof of the fundamental theorem of calculus. Wallis generalized Cavalieri's ",
    "links": [
      "*-algebra",
      "0 (number)",
      "Abel's test",
      "Absolute value",
      "Accuracy and precision",
      "Addison-Wesley",
      "Aleksandr Khinchin",
      "Alfréd Haar",
      "Alhazen",
      "Almost everywhere",
      "Alternating series",
      "Alternating series test",
      "American Mathematical Society",
      "Ancient Greece",
      "Ancient Greek mathematics",
      "Antiderivative",
      "ArXiv (identifier)",
      "Arc length",
      "Archimedes",
      "Area",
      "Area of a circle",
      "Area under the curve (pharmacokinetics)",
      "Arithmetico–geometric sequence",
      "Arnaud Denjoy",
      "Average precision",
      "BLEU",
      "Babenko–Beckner inequality",
      "Banach space",
      "Basel problem",
      "Bernhard Riemann",
      "Bessel's inequality",
      "Bibcode (identifier)",
      "Binomial series",
      "Bochner integral",
      "Bochner space",
      "Bonaventura Cavalieri",
      "Bose–Einstein integral",
      "Bounded function",
      "Bounded set",
      "Bounded variation",
      "Brunn–Minkowski theorem",
      "Bulletin of the American Mathematical Society",
      "Burkill integral",
      "C*-algebra",
      "Calculus",
      "Calculus of variations",
      "Calculus on Euclidean space",
      "Calinski–Harabasz index",
      "Cartesian product",
      "Cauchy condensation test"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1 errors: ISBN date",
      "Category:Functions and mappings",
      "Category:Integrals",
      "Category:Linear operators in calculus",
      "Category:Pages using sidebar with the child parameter",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Minimal polynomial (field theory)": {
    "title": "Minimal polynomial (field theory)",
    "url": "https://en.wikipedia.org/wiki/Minimal_polynomial_(field_theory)",
    "summary": "In field theory, a branch of mathematics, the minimal polynomial of an element α of an extension field of a field is, roughly speaking, the polynomial of lowest degree having coefficients in the smaller field, such that α is a root of the polynomial. If the minimal polynomial of α exists, it is unique. The coefficient of the highest-degree term in the polynomial is required to be 1.\nMore formally, a minimal polynomial is defined relative to a field extension E/F and an element of the extension field E/F. The minimal polynomial of an element, if it exists, is a member of F[x], the  ring of polynomials in the variable x with coefficients in F. Given an element α of E, let Jα be the set of all polynomials f(x) in F[x] such that f(α) = 0. The element α is called a root or zero of each polynomial in Jα\nMore specifically, Jα is the kernel of the ring homomorphism from F[x] to E which sends polynomials g to their value g(α) at the element α. Because it is the kernel of a ring homomorphism, Jα",
    "content": "In field theory, a branch of mathematics, the minimal polynomial of an element α of an extension field of a field is, roughly speaking, the polynomial of lowest degree having coefficients in the smaller field, such that α is a root of the polynomial. If the minimal polynomial of α exists, it is unique. The coefficient of the highest-degree term in the polynomial is required to be 1.\nMore formally, a minimal polynomial is defined relative to a field extension E/F and an element of the extension field E/F. The minimal polynomial of an element, if it exists, is a member of F[x], the  ring of polynomials in the variable x with coefficients in F. Given an element α of E, let Jα be the set of all polynomials f(x) in F[x] such that f(α) = 0. The element α is called a root or zero of each polynomial in Jα\nMore specifically, Jα is the kernel of the ring homomorphism from F[x] to E which sends polynomials g to their value g(α) at the element α. Because it is the kernel of a ring homomorphism, Jα is an ideal of the polynomial ring F[x]: it is closed under polynomial addition and subtraction (hence containing the zero polynomial), as well as under multiplication by elements of F (which is scalar multiplication if F[x] is regarded as a vector space over F).\nThe zero polynomial, all of whose coefficients are 0, is in every Jα since 0αi = 0 for all α and i. This makes the zero polynomial useless for classifying different values of α into types, so it is excepted. If there are any non-zero polynomials in Jα, i.e. if the latter is not the zero ideal, then α is called an algebraic element over F, and there exists a monic polynomial of least degree in Jα. This is the minimal polynomial of α with respect to E/F. It is unique and irreducible over F. If the zero polynomial is the only member of Jα, then α is called a transcendental element over F and has no minimal polynomial with respect to E/F.\nMinimal polynomials are useful for constructing and analyzing field extensions. When α is algebraic with minimal polynomial f(x), the smallest field that contains both F and α is isomorphic to the quotient ring F[x]/⟨f(x)⟩, where ⟨f(x)⟩ is the ideal of F[x] generated by f(x). Minimal polynomials are also used to define conjugate elements.\n\nDefinition\nLet E/F be a field extension, α an element of E, and F[x] the ring of polynomials in x over F. The element α has a minimal polynomial when α is algebraic over F, that is, when f(α) = 0 for some non-zero polynomial f(x) in F[x]. Then the minimal polynomial of α is defined as the monic polynomial of least degree among all polynomials in F[x] having α as a root.\n\nProperties\nThroughout this section, let E/F be a field extension over F as above, let α ∈ E be an algebraic element over F and let Jα be the ideal of polynomials vanishing on α.\n\nUniqueness\nThe minimal polynomial f of α is unique.\nTo prove this, suppose that f and g are monic polynomials in Jα of minimal degree n > 0. We have that r := f−g ∈ Jα (because the latter is closed under addition/subtraction) and that m :=  deg(r) < n (because the polynomials are monic of the same degree). If r is not zero, then r / cm (writing cm ∈ F for the non-zero coefficient of highest degree in r) is a monic polynomial of degree m < n such that r / cm ∈ Jα (because the latter is closed under multiplication/division by non-zero elements of F), which contradicts our original assumption of minimality for n. We conclude that 0 = r = f − g, i.e. that f = g.\n\nIrreducibility\nThe minimal polynomial f of α is irreducible, i.e. it cannot be factorized as f = gh for two polynomials g and h of strictly lower degree.\nTo prove this, first observe that any factorization f = gh implies that either g(α) = 0 or h(α) = 0, because f(α) = 0 and F is a field (hence also an integral domain). Choosing both g and h to be of degree strictly lower than f would then contradict the minimality requirement on f, so f must be irreducible.\n\nMinimal polynomial generates Jα\nThe minimal polynomial f of α generates the ideal Jα, i.e. every  g in Jα can be factorized as g=fh for some h'  in F[x].\nTo prove this, it suffices to observe that F[x] is a principal ideal domain, because F is a field: this means that every ideal I in F[x], Jα amongst them, is generated by a single element f. With the exception of the zero ideal I = {0}, the generator f must be non-zero and it must be the unique polynomial of minimal degree, up to a factor in F (because the degree of fg is strictly larger than that of f whenever g is of degree greater than zero). In particular, there is a unique monic generator f, and all generators must be irreducible. When I is chosen to be Jα, for α algebraic over F, then the monic generator f is the minimal polynomial of α.\n\nExamples\nMinimal polynomial of a Galois field extension\nGiven a Galois field extension \n  \n    \n      \n        L\n        \n          /\n        \n        K\n      \n    \n    {\\displaystyle L/K}\n  \n the minimal polynomial of any \n  \n    \n      \n        α\n        ∈",
    "links": [
      "Algebraic element",
      "Algebraic number field",
      "Conjugate elements",
      "Cyclotomic polynomial",
      "Degree of a polynomial",
      "Eric W. Weisstein",
      "Field (mathematics)",
      "Field extension",
      "Field theory (mathematics)",
      "ISBN (identifier)",
      "Ideal (ring theory)",
      "Integral domain",
      "Irreducible polynomial",
      "MathWorld",
      "Mathematics",
      "Minimal polynomial (linear algebra)",
      "Minimal polynomial of 2cos(2pi/n)",
      "Monic polynomial",
      "PlanetMath",
      "Polynomial",
      "Polynomial ring",
      "Principal ideal domain",
      "Quadratic integer",
      "Quotient ring",
      "Ring homomorphism",
      "Ring isomorphism",
      "Ring of integers",
      "Root of unity",
      "Scalar multiplication",
      "Swinnerton-Dyer polynomial",
      "Transcendental element",
      "Vector space",
      "Zero of a function"
    ],
    "categories": [
      "Category:All Wikipedia articles written in American English",
      "Category:Articles with short description",
      "Category:Field (mathematics)",
      "Category:Polynomials",
      "Category:Short description is different from Wikidata",
      "Category:Use American English from March 2019"
    ]
  },
  "On-Line Encyclopedia of Integer Sequences": {
    "title": "On-Line Encyclopedia of Integer Sequences",
    "url": "https://en.wikipedia.org/wiki/On-Line_Encyclopedia_of_Integer_Sequences",
    "summary": "The On-Line Encyclopedia of Integer Sequences (OEIS) is an online database of integer sequences. It was created and maintained by Neil Sloane while researching at AT&T Labs. He transferred the intellectual property and hosting of the OEIS to the OEIS Foundation in 2009, and is its chairman. \nOEIS records information on integer sequences of interest to both professional and amateur mathematicians, and is widely cited. As of February 2024, it contains over 370,000 sequences, and is growing by approximately 30 entries per day.\nEach entry contains the leading terms of the sequence, keywords, mathematical motivations, literature links, and more, including the option to generate a graph or play a musical representation of the sequence. The database is searchable by keyword, by subsequence, or by any of 16 fields. There is also an advanced search function called SuperSeeker which runs a large number of different algorithms to identify sequences related to the input.",
    "content": "The On-Line Encyclopedia of Integer Sequences (OEIS) is an online database of integer sequences. It was created and maintained by Neil Sloane while researching at AT&T Labs. He transferred the intellectual property and hosting of the OEIS to the OEIS Foundation in 2009, and is its chairman. \nOEIS records information on integer sequences of interest to both professional and amateur mathematicians, and is widely cited. As of February 2024, it contains over 370,000 sequences, and is growing by approximately 30 entries per day.\nEach entry contains the leading terms of the sequence, keywords, mathematical motivations, literature links, and more, including the option to generate a graph or play a musical representation of the sequence. The database is searchable by keyword, by subsequence, or by any of 16 fields. There is also an advanced search function called SuperSeeker which runs a large number of different algorithms to identify sequences related to the input.\n\nHistory\nNeil Sloane started collecting integer sequences as a graduate student in 1964 to support his work in combinatorics. The database was at first stored on punched cards. He published selections from the database in book form twice:\n\nA Handbook of Integer Sequences (1973, ISBN 0-12-648550-X), containing 2,372 sequences in lexicographic order and assigned numbers from 1 to 2372.\nThe Encyclopedia of Integer Sequences with Simon Plouffe (1995, ISBN 0-12-558630-2), containing 5,488 sequences and assigned M-numbers from M0000 to M5487.  The Encyclopedia includes the references to the corresponding sequences (which may differ in their few initial terms) in A Handbook of Integer Sequences as N-numbers from N0001 to N2372 (instead of 1 to 2372.) The Encyclopedia includes the A-numbers that are used in the OEIS, whereas the Handbook did not.\n\nThese books were well-received and, especially after the second publication, mathematicians supplied Sloane with a steady flow of new sequences. The collection became unmanageable in book form, and when the database reached 16,000 entries Sloane decided to go online – first as an email service (August 1994), and soon thereafter as a website (1996). As a spin-off from the database work, Sloane founded the Journal of Integer Sequences in 1998.\nThe database continues to grow at a rate of some 10,000 entries a year.\nSloane has personally managed 'his' sequences for almost 40 years, but starting in 2002, a board of associate editors and volunteers has helped maintain the omnibus database.\nIn 2004, Sloane celebrated the addition of the 100,000th sequence to the database, A100000, which counts the marks on the Ishango bone. In 2006, the user interface was overhauled and more advanced search capabilities were added. In 2010 an OEIS wiki was created to simplify the collaboration of the OEIS editors and contributors. The 200,000th sequence, A200000, was added to the database in November 2011; it was initially entered as A200715, and moved to A200000 after a week of discussion on the SeqFan mailing list, following a proposal by OEIS Editor-in-Chief Charles Greathouse to choose a special sequence for A200000. A300000 was defined in February 2018, and by end of January 2023 the database contained more than 360,000 sequences.\n\nNon-integers\nBesides integer sequences, the OEIS also catalogs sequences of fractions, the digits of transcendental numbers, complex numbers and so on by transforming them into integer sequences.\nSequences of fractions are represented by two sequences (named with the keyword 'frac'): the sequence of numerators and the sequence of denominators. For example, the fifth-order Farey sequence, \n  \n    \n      \n        \n          \n            \n              1\n              5\n            \n          \n          ,\n          \n            \n              1\n              4\n            \n          \n          ,\n          \n            \n              1\n              3\n            \n          \n          ,\n          \n            \n              2\n              5\n            \n          \n          ,\n          \n            \n              1\n              2\n            \n          \n          ,\n          \n            \n              3\n              5\n            \n          \n          ,\n          \n            \n              2\n              3\n            \n          \n          ,\n          \n            \n              3\n              4\n            \n          \n          ,\n          \n            \n              4\n              5\n            \n          \n        \n      \n    \n    {\\displaystyle \\textstyle {1 \\over 5},{1 \\over 4},{1 \\over 3},{2 \\over 5},{1 \\over 2},{3 \\over 5},{2 \\over 3},{3 \\over 4},{4 \\over 5}}\n  \n, is catalogued as the numerator sequence 1, 1, 1, 2, 1, 3, 2, 3, 4 (A006842) and the denominator sequence 5, 4, 3, 5, 2, 5, 3, 4, 5 (A006843).\nImportant irrational numbers such as π = 3.1415926535897... are catalogued under representative integer sequences such as decimal expansions (here 3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8, 9, 7, 9, 3, 2, ",
    "links": [
      "ASCII",
      "AT&T Labs",
      "Abramowitz and Stegun",
      "Absolute value",
      "American Scientist",
      "Anti-commutative",
      "ArXiv (identifier)",
      "Associative",
      "Australian Broadcasting Corporation",
      "Bessel polynomials",
      "Bibcode (identifier)",
      "Binary number",
      "Binary operation",
      "Binomial coefficient",
      "Brian Hayes (scientist)",
      "Bridget Tenner",
      "CC BY-SA",
      "Cellular automaton",
      "Centered hexagonal number",
      "Cevian",
      "Cf.",
      "Charles Greathouse",
      "Cloacal exstrophy",
      "Combinatorics",
      "Commutative",
      "Complex number",
      "Composite number",
      "Computer music",
      "Continued fraction",
      "Coprime",
      "Creative Commons",
      "Cube (algebra)",
      "Decimal",
      "Divisible",
      "Divisor",
      "Doi (identifier)",
      "Egyptian fraction",
      "Eigenvalue",
      "Email",
      "Encyclopedia of Integer Sequences",
      "Exponential function",
      "Farey sequence",
      "Fibonacci number",
      "Fraction",
      "Function (mathematics)",
      "Generating function",
      "Graph of a function",
      "Graph theory",
      "Greek alphabet",
      "Harald Niederreiter"
    ],
    "categories": [
      "Category:1964 establishments in the United States",
      "Category:20th-century encyclopedias",
      "Category:21st-century encyclopedias",
      "Category:All articles containing potentially dated statements",
      "Category:American online encyclopedias",
      "Category:Articles containing potentially dated statements from 2016",
      "Category:Articles containing potentially dated statements from February 2024",
      "Category:Articles with short description",
      "Category:CS1:Vancouver names with accept markup",
      "Category:CS1 French-language sources (fr)"
    ]
  },
  "Particular values of the Riemann zeta function": {
    "title": "Particular values of the Riemann zeta function",
    "url": "https://en.wikipedia.org/wiki/Particular_values_of_the_Riemann_zeta_function",
    "summary": "In mathematics, the Riemann zeta function is a function in complex analysis, which is also important in number theory. It is often denoted \n  \n    \n      \n        ζ\n        (\n        s\n        )\n      \n    \n    {\\displaystyle \\zeta (s)}\n  \n and is named after the mathematician Bernhard Riemann. When the argument \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n  \n is a real number greater than one, the zeta function satisfies the equation\n\n  \n    \n      \n        ζ\n        (\n        s\n        )\n        =\n        \n          ∑\n          \n            n\n            =\n            1\n          \n          \n            ∞\n          \n        \n        \n          \n            1\n            \n              n\n              \n                s\n              \n            \n          \n        \n        \n        .\n      \n    \n    {\\displaystyle \\zeta (s)=\\sum _{n=1}^{\\infty }{\\frac {1}{n^{s}}}\\,.}\n  \n\nIt can therefore provide the sum of various convergent infinite series, such as \n  \n    \n      \n  ",
    "content": "In mathematics, the Riemann zeta function is a function in complex analysis, which is also important in number theory. It is often denoted \n  \n    \n      \n        ζ\n        (\n        s\n        )\n      \n    \n    {\\displaystyle \\zeta (s)}\n  \n and is named after the mathematician Bernhard Riemann. When the argument \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n  \n is a real number greater than one, the zeta function satisfies the equation\n\n  \n    \n      \n        ζ\n        (\n        s\n        )\n        =\n        \n          ∑\n          \n            n\n            =\n            1\n          \n          \n            ∞\n          \n        \n        \n          \n            1\n            \n              n\n              \n                s\n              \n            \n          \n        \n        \n        .\n      \n    \n    {\\displaystyle \\zeta (s)=\\sum _{n=1}^{\\infty }{\\frac {1}{n^{s}}}\\,.}\n  \n\nIt can therefore provide the sum of various convergent infinite series, such as \n  \n    \n      \n        ζ\n        (\n        2\n        )\n        =\n        \n          \n            1\n            \n              1\n              \n                2\n              \n            \n          \n        \n        +\n      \n    \n    {\\textstyle \\zeta (2)={\\frac {1}{1^{2}}}+}\n  \n\n  \n    \n      \n        \n          \n            1\n            \n              2\n              \n                2\n              \n            \n          \n        \n        +\n      \n    \n    {\\textstyle {\\frac {1}{2^{2}}}+}\n  \n\n  \n    \n      \n        \n          \n            1\n            \n              3\n              \n                2\n              \n            \n          \n        \n        +\n        …\n        \n        .\n      \n    \n    {\\textstyle {\\frac {1}{3^{2}}}+\\ldots \\,.}\n  \n Explicit or numerically efficient formulae exist for \n  \n    \n      \n        ζ\n        (\n        s\n        )\n      \n    \n    {\\displaystyle \\zeta (s)}\n  \n at integer arguments, all of which have real values, including this example. This article lists these formulae, together with tables of values. It also includes derivatives and some series composed of the zeta function at integer arguments.\nThe same equation in \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n  \n above also holds when \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n  \n is a complex number whose real part is greater than one, ensuring that the infinite sum still converges. The zeta function can then be extended to the whole of the complex plane by analytic continuation, except for a simple pole at \n  \n    \n      \n        s\n        =\n        1\n      \n    \n    {\\displaystyle s=1}\n  \n. The complex derivative exists in this more general region, making the zeta function a meromorphic function. The above equation no longer applies for these extended values of \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n  \n, for which the corresponding summation would diverge. For example, the full zeta function exists at \n  \n    \n      \n        s\n        =\n        −\n        1\n      \n    \n    {\\displaystyle s=-1}\n  \n (and is therefore finite there), but the corresponding series would be \n  \n    \n      \n        1\n        +\n        2\n        +\n        3\n        +\n        …\n        \n        ,\n      \n    \n    {\\textstyle 1+2+3+\\ldots \\,,}\n  \n whose partial sums would grow indefinitely large.\nThe zeta function values listed below include function values at the negative even numbers (\n  \n    \n      \n        s\n        =\n        −\n        2\n        ,\n        −\n        4\n        ,\n      \n    \n    {\\displaystyle s=-2,-4,}\n  \n etc.), for which \n  \n    \n      \n        ζ\n        (\n        s\n        )\n        =\n        0\n      \n    \n    {\\displaystyle \\zeta (s)=0}\n  \n and which make up the so-called trivial zeros. The Riemann zeta function article includes a colour plot illustrating how the function varies over a continuous rectangular region of the complex plane. The successful characterisation of its non-trivial zeros in the wider plane is important in number theory, because of the Riemann hypothesis.\n\nThe Riemann zeta function at 0 and 1\nAt zero, one has\n\n  \n    \n      \n        ζ\n        (\n        0\n        )\n        =\n        \n          \n            B\n            \n              1\n            \n            \n              −\n            \n          \n        \n        =\n        −\n        \n          \n            B\n            \n              1\n            \n            \n              +\n            \n          \n        \n        =\n        −\n        \n          \n            \n              1\n              2\n            \n          \n        \n        \n      \n    \n    {\\displaystyle \\zeta (0)={B_{1}^{-}}=-{B_{1}^{+}}=-{\\tfrac {1}{2}}\\!}\n  \n\nAt 1 there is a pole, so \n  \n    \n      \n        ζ\n        (\n        1\n        )\n      \n    \n    {\\displaystyle \\zeta (1)}\n  \n is not finite but the left and right limits are:\n\n  \n    \n      \n        \n          lim\n          \n            ε\n            →\n            \n              0\n              \n       ",
    "links": [
      "1 + 2 + 3 + 4 + · · ·",
      "Analytic continuation",
      "Andrew Odlyzko",
      "Apéry's constant",
      "Apéry's theorem",
      "ArXiv (identifier)",
      "Arithmetic–geometric mean",
      "Basel problem",
      "Bernhard Riemann",
      "Bernoulli number",
      "Bernoulli numbers",
      "Bibcode (identifier)",
      "Complex analysis",
      "Complex derivative",
      "Complex number",
      "Complex plane",
      "Correlation function (statistical mechanics)",
      "Digamma function",
      "Doi (identifier)",
      "Euler–Mascheroni constant",
      "Generating function",
      "Glaisher–Kinkelin constant",
      "Harmonic series (mathematics)",
      "Heisenberg model (quantum)",
      "JSTOR (identifier)",
      "Lambert series",
      "MR (identifier)",
      "Mathematics",
      "Meromorphic function",
      "Number theory",
      "OEIS",
      "On-Line Encyclopedia of Integer Sequences",
      "Partial sum",
      "Particular values of the gamma function",
      "Planck's law",
      "Pole (complex analysis)",
      "Ramanujan summation",
      "Real number",
      "Real part",
      "Residue (complex analysis)",
      "Riemann hypothesis",
      "Riemann zeta function",
      "Russian Mathematical Surveys",
      "S2CID (identifier)",
      "Series (mathematics)",
      "Simon Plouffe",
      "Simple pole",
      "Stefan–Boltzmann law",
      "Tanguy Rivoal",
      "Wadim Zudilin"
    ],
    "categories": [
      "Category:All Wikipedia articles written in American English",
      "Category:Articles with short description",
      "Category:Irrational numbers",
      "Category:Mathematical constants",
      "Category:Short description is different from Wikidata",
      "Category:Use American English from March 2019",
      "Category:Webarchive template wayback links",
      "Category:Zeta and L-functions"
    ]
  },
  "Proof by contradiction": {
    "title": "Proof by contradiction",
    "url": "https://en.wikipedia.org/wiki/Proof_by_contradiction",
    "summary": "In logic, proof by contradiction is a form of proof that establishes the truth or the validity of a proposition by showing that assuming the proposition to be false leads to a contradiction.\nAlthough it is quite freely used in mathematical proofs, not every school of mathematical thought accepts this kind of nonconstructive proof as universally valid.\nMore broadly, proof by contradiction is any form of argument that establishes a statement by arriving at a contradiction, even when the initial assumption is not the negation of the statement to be proved. In this general sense, proof by contradiction is also known as indirect proof, proof by assuming the opposite, and reductio ad impossibile.\nA mathematical proof employing proof by contradiction usually proceeds as follows:\n\nThe proposition to be proved is P.\nWe assume P to be false, i.e., we assume ¬P.\nIt is then shown that ¬P implies falsehood. This is typically accomplished by deriving two mutually contradictory assertions, Q and ¬Q, ",
    "content": "In logic, proof by contradiction is a form of proof that establishes the truth or the validity of a proposition by showing that assuming the proposition to be false leads to a contradiction.\nAlthough it is quite freely used in mathematical proofs, not every school of mathematical thought accepts this kind of nonconstructive proof as universally valid.\nMore broadly, proof by contradiction is any form of argument that establishes a statement by arriving at a contradiction, even when the initial assumption is not the negation of the statement to be proved. In this general sense, proof by contradiction is also known as indirect proof, proof by assuming the opposite, and reductio ad impossibile.\nA mathematical proof employing proof by contradiction usually proceeds as follows:\n\nThe proposition to be proved is P.\nWe assume P to be false, i.e., we assume ¬P.\nIt is then shown that ¬P implies falsehood. This is typically accomplished by deriving two mutually contradictory assertions, Q and ¬Q, and appealing to the law of noncontradiction.\nSince assuming P to be false leads to a contradiction, it is concluded that P is in fact true.\nAn important special case is the existence proof by contradiction: in order to demonstrate that an object with a given property exists, we derive a contradiction from the assumption that all objects satisfy the negation of the property.\n\nFormalization\nThe principle may be formally expressed as the propositional formula ¬¬P ⇒ P, equivalently (¬P ⇒ ⊥) ⇒ P, which reads: \"If assuming P to be false implies falsehood, then P is true.\"\nIn natural deduction the principle takes the form of the rule of inference\n\n  \n    \n      \n        \n          \n            \n              \n                \n              \n              \n                \n                  ⊢\n                  ¬\n                  ¬\n                  P\n                \n              \n            \n            \n              \n                \n              \n              \n                \n                  ⊢\n                  P\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\cfrac {\\vdash \\lnot \\lnot P}{\\vdash P}}}\n  \n\nwhich reads: \"If \n  \n    \n      \n        ¬\n        ¬\n        P\n      \n    \n    {\\displaystyle \\lnot \\lnot P}\n  \n is proved, then \n  \n    \n      \n        P\n      \n    \n    {\\displaystyle P}\n  \n may be concluded.\"\nIn sequent calculus the principle is expressed by the sequent\n\n  \n    \n      \n        Γ\n        ,\n        ¬\n        ¬\n        P\n        ⊢\n        P\n        ,\n        Δ\n      \n    \n    {\\displaystyle \\Gamma ,\\lnot \\lnot P\\vdash P,\\Delta }\n  \n\nwhich reads: \"Hypotheses \n  \n    \n      \n        Γ\n      \n    \n    {\\displaystyle \\Gamma }\n  \n and \n  \n    \n      \n        ¬\n        ¬\n        P\n      \n    \n    {\\displaystyle \\lnot \\lnot P}\n  \n entail the conclusion \n  \n    \n      \n        P\n      \n    \n    {\\displaystyle P}\n  \n or \n  \n    \n      \n        Δ\n      \n    \n    {\\displaystyle \\Delta }\n  \n.\"\n\nJustification\nIn classical logic the principle may be justified by the examination of the truth table of the proposition ¬¬P ⇒ P, which demonstrates it to be a tautology:\n\nAnother way to justify the principle is to derive it from the law of the excluded middle, as follows. We assume ¬¬P and seek to prove P. By the law of excluded middle P either holds or it does not:\n\nif P holds, then of course P holds.\nif ¬P holds, then we derive falsehood by applying the law of noncontradiction to ¬P and ¬¬P, after which the principle of explosion allows us to conclude P.\nIn either case, we established P. It turns out that, conversely, proof by contradiction can be used to derive the law of excluded middle.\nIn classical sequent calculus LK proof by contradiction is derivable from the inference rules for negation:\n\n  \n    \n      \n        \n          \n            \n              \n                \n              \n              \n                \n                  \n                    \n                      \n                        \n                          \n                        \n                        \n                          \n                            \n                              \n                                \n                                  \n                                    \n                                  \n                                  \n                                    \n                                       \n                                    \n                                  \n                                \n                                \n                                  \n                                    \n                                  \n                                  \n                                    \n                                      Γ\n                                      ,\n                                      P\n                                      ⊢\n                                      P\n                                      ,\n             ",
    "links": [
      "A Mathematician's Apology",
      "Abstract logic",
      "Ackermann set theory",
      "Aleph number",
      "Algebraic logic",
      "Algorithm",
      "Alphabet (formal languages)",
      "Argument",
      "Aristotle",
      "Arity",
      "Atomic formula",
      "Atomic sentence",
      "Automata theory",
      "Automated theorem proving",
      "Axiom",
      "Axiom of choice",
      "Axiom schema",
      "Axiomatic system",
      "Axiomatization of Boolean algebras",
      "Banach–Tarski paradox",
      "Bijection",
      "Binary operation",
      "Boolean algebra",
      "Boolean algebras canonically defined",
      "Boolean function",
      "Brouwer–Heyting–Kolmogorov interpretation",
      "Cantor's diagonal argument",
      "Cantor's paradox",
      "Cantor's theorem",
      "Cardinality",
      "Cartesian product",
      "Categorical theory",
      "Category (mathematics)",
      "Category of sets",
      "Category theory",
      "Church encoding",
      "Church–Turing thesis",
      "Class (set theory)",
      "Classical logic",
      "Codomain",
      "Compactness theorem",
      "Complement (set theory)",
      "Complete theory",
      "Complex number",
      "Computability theory",
      "Computable function",
      "Computable set",
      "Computably enumerable set",
      "Concrete category",
      "Conservative extension"
    ],
    "categories": [
      "Category:All Wikipedia articles needing clarification",
      "Category:All articles with unsourced statements",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from October 2021",
      "Category:CS1 maint: location",
      "Category:Mathematical proofs",
      "Category:Methods of proof",
      "Category:Short description is different from Wikidata",
      "Category:Theorems in propositional logic",
      "Category:Use dmy dates from September 2023"
    ]
  },
  "Riemann zeta function": {
    "title": "Riemann zeta function",
    "url": "https://en.wikipedia.org/wiki/Riemann_zeta_function",
    "summary": "The Riemann zeta function or Euler–Riemann zeta function, denoted by the Greek letter ζ (zeta), is a mathematical function of a complex variable defined as \n  \n    \n      \n        ζ\n        (\n        s\n        )\n        =\n        \n          ∑\n          \n            n\n            =\n            1\n          \n          \n            ∞\n          \n        \n        \n          \n            1\n            \n              n\n              \n                s\n              \n            \n          \n        \n        =\n        \n          \n            1\n            \n              1\n              \n                s\n              \n            \n          \n        \n        +\n        \n          \n            1\n            \n              2\n              \n                s\n              \n            \n          \n        \n        +\n        \n          \n            1\n            \n              3\n              \n                s\n              \n            \n          \n        \n        +\n        ⋯\n      \n    \n    {\\disp",
    "content": "The Riemann zeta function or Euler–Riemann zeta function, denoted by the Greek letter ζ (zeta), is a mathematical function of a complex variable defined as \n  \n    \n      \n        ζ\n        (\n        s\n        )\n        =\n        \n          ∑\n          \n            n\n            =\n            1\n          \n          \n            ∞\n          \n        \n        \n          \n            1\n            \n              n\n              \n                s\n              \n            \n          \n        \n        =\n        \n          \n            1\n            \n              1\n              \n                s\n              \n            \n          \n        \n        +\n        \n          \n            1\n            \n              2\n              \n                s\n              \n            \n          \n        \n        +\n        \n          \n            1\n            \n              3\n              \n                s\n              \n            \n          \n        \n        +\n        ⋯\n      \n    \n    {\\displaystyle \\zeta (s)=\\sum _{n=1}^{\\infty }{\\frac {1}{n^{s}}}={\\frac {1}{1^{s}}}+{\\frac {1}{2^{s}}}+{\\frac {1}{3^{s}}}+\\cdots }\n  \n for \n  \n    \n      \n        Re\n        ⁡\n        (\n        s\n        )\n        >\n        1\n      \n    \n    {\\displaystyle \\operatorname {Re} (s)>1}\n  \n, and its analytic continuation elsewhere.\nThe Riemann zeta function plays a pivotal role in analytic number theory and has applications in physics, probability theory, and applied statistics.\nLeonhard Euler first introduced and studied the function over the reals in the first half of the eighteenth century. Bernhard Riemann's 1859 article \"On the Number of Primes Less Than a Given Magnitude\" extended the Euler definition to a complex variable, proved its meromorphic continuation and functional equation, and established a relation between its zeros and the distribution of prime numbers.  This paper also contained the Riemann hypothesis, a conjecture about the distribution of complex zeros of the Riemann zeta function that many mathematicians consider the most important unsolved problem in pure mathematics.\nThe values of the Riemann zeta function at even positive integers were computed by Euler. The first of them, ζ(2), provides a solution to the Basel problem. In 1979 Roger Apéry proved the irrationality of ζ(3). The values at negative integer points, also found by Euler, are rational numbers and play an important role in the theory of modular forms. Many generalizations of the Riemann zeta function, such as Dirichlet series, Dirichlet L-functions and L-functions, are known.\n\nDefinition\nThe Riemann zeta function ζ(s) is a function of a complex variable s = σ + it, where σ and t are real numbers. (The notation s, σ, and t is used traditionally in the study of the zeta function, following Riemann.) When Re(s) = σ > 1, the function can be written as a converging summation or as an integral:\n\n  \n    \n      \n        ζ\n        (\n        s\n        )\n        =\n        \n          ∑\n          \n            n\n            =\n            1\n          \n          \n            ∞\n          \n        \n        \n          \n            1\n            \n              n\n              \n                s\n              \n            \n          \n        \n        =\n        \n          \n            1\n            \n              Γ\n              (\n              s\n              )\n            \n          \n        \n        \n          ∫\n          \n            0\n          \n          \n            ∞\n          \n        \n        \n          \n            \n              x\n              \n                s\n                −\n                1\n              \n            \n            \n              \n                e\n                \n                  x\n                \n              \n              −\n              1\n            \n          \n        \n        \n        \n          d\n        \n        x\n        \n        ,\n      \n    \n    {\\displaystyle \\zeta (s)=\\sum _{n=1}^{\\infty }{\\frac {1}{n^{s}}}={\\frac {1}{\\Gamma (s)}}\\int _{0}^{\\infty }{\\frac {x^{s-1}}{e^{x}-1}}\\,\\mathrm {d} x\\,,}\n  \n\nwhere\n\n  \n    \n      \n        Γ\n        (\n        s\n        )\n        =\n        \n          ∫\n          \n            0\n          \n          \n            ∞\n          \n        \n        \n          x\n          \n            s\n            −\n            1\n          \n        \n        \n        \n          e\n          \n            −\n            x\n          \n        \n        \n        \n          d\n        \n        x\n      \n    \n    {\\displaystyle \\Gamma (s)=\\int _{0}^{\\infty }x^{s-1}\\,e^{-x}\\,\\mathrm {d} x}\n  \n\nis the gamma function. The Riemann zeta function is defined for other complex values via analytic continuation of the function defined for σ > 1.\nLeonhard Euler considered the above series in 1740 for positive integer values of s, and later Chebyshev extended the definition to \n  \n    \n      \n        Re\n        ⁡\n        (\n        s\n        )\n        >\n        1.\n      \n    \n    {\\displaystyle \\operatorname {Re} (s)>1.}\n  \n\nThe above s",
    "links": [
      "1/2 + 1/4 + 1/8 + 1/16 + ⋯",
      "1/2 − 1/4 + 1/8 − 1/16 + ⋯",
      "1/4 + 1/16 + 1/64 + 1/256 + ⋯",
      "1 + 1 + 1 + 1 + ⋯",
      "1 + 2 + 3 + 4 + ···",
      "1 + 2 + 3 + 4 + ⋯",
      "1 + 2 + 4 + 8 + ⋯",
      "1 − 1 + 2 − 6 + 24 − 120 + ⋯",
      "1 − 2 + 3 − 4 + ⋯",
      "1 − 2 + 4 − 8 + ⋯",
      "3Blue1Brown",
      "A. A. Karatsuba",
      "Abel–Plana formula",
      "Abramowitz and Stegun",
      "Absolute convergence",
      "Aleksandar Ivić",
      "Alternating series",
      "American Mathematical Society",
      "Analytic continuation",
      "Analytic function",
      "Analytic number theory",
      "Anatolii Alexeevitch Karatsuba",
      "Apéry's constant",
      "ArXiv (identifier)",
      "Arithmetic progression",
      "Arithmetic zeta function",
      "Artin L-function",
      "Artin conjecture (L-functions)",
      "Asymptotic density",
      "Atle Selberg",
      "Automorphic L-function",
      "Basel problem",
      "Beilinson conjectures",
      "Bernhard Riemann",
      "Bernoulli number",
      "Bibcode (identifier)",
      "Birch and Swinnerton-Dyer conjecture",
      "Bloch–Kato conjecture (L-functions)",
      "Brady Haran",
      "Brian Conrey",
      "Brownian motion",
      "Brownian motion and Riemann zeta function",
      "C. Stanley Ogilvy",
      "Canadian Mathematical Society",
      "Carlson's theorem",
      "Casimir effect",
      "Cauchy principal value",
      "Cauchy sequence",
      "Cauchy–Riemann equations",
      "Chebyshev"
    ],
    "categories": [
      "Category:All articles with unsourced statements",
      "Category:Analytic number theory",
      "Category:Articles containing video clips",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from August 2025",
      "Category:Bernhard Riemann",
      "Category:CS1: long volume value",
      "Category:CS1 French-language sources (fr)",
      "Category:CS1 German-language sources (de)",
      "Category:Commons category link from Wikidata"
    ]
  },
  "Sequence": {
    "title": "Sequence",
    "url": "https://en.wikipedia.org/wiki/Sequence",
    "summary": "In mathematics, a sequence is an enumerated collection of objects in which repetitions are allowed and order matters. Like a set, it contains members (also called elements, or terms). The number of elements (possibly infinite) is called the length of the sequence. Unlike a set, the same elements can appear multiple times at different positions in a sequence, and unlike a set, the order does matter. Formally, a sequence can be defined as a function from natural numbers (the positions of elements in the sequence) to the elements at each position. The notion of a sequence can be generalized to an indexed family, defined as a function from an arbitrary index set.\nFor example, (M, A, R, Y) is a sequence of letters with the letter \"M\" first and \"Y\" last. This sequence differs from (A, R, M, Y). Also, the sequence (1, 1, 2, 3, 5, 8), which contains the number 1 at two different positions, is a valid sequence. Sequences can be finite, as in these examples, or infinite, such as the sequence of ",
    "content": "In mathematics, a sequence is an enumerated collection of objects in which repetitions are allowed and order matters. Like a set, it contains members (also called elements, or terms). The number of elements (possibly infinite) is called the length of the sequence. Unlike a set, the same elements can appear multiple times at different positions in a sequence, and unlike a set, the order does matter. Formally, a sequence can be defined as a function from natural numbers (the positions of elements in the sequence) to the elements at each position. The notion of a sequence can be generalized to an indexed family, defined as a function from an arbitrary index set.\nFor example, (M, A, R, Y) is a sequence of letters with the letter \"M\" first and \"Y\" last. This sequence differs from (A, R, M, Y). Also, the sequence (1, 1, 2, 3, 5, 8), which contains the number 1 at two different positions, is a valid sequence. Sequences can be finite, as in these examples, or infinite, such as the sequence of all even positive integers (2, 4, 6, ...).\nThe position of an element in a sequence is its rank or index; it is the natural number for which the element is the image. The first element has index 0 or 1, depending on the context or a specific convention. In mathematical analysis, a sequence is often denoted by letters in the form of \n  \n    \n      \n        \n          a\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle a_{n}}\n  \n, \n  \n    \n      \n        \n          b\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle b_{n}}\n  \n and \n  \n    \n      \n        \n          c\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle c_{n}}\n  \n, where the subscript n refers to the nth element of the sequence; for example, the nth element of the Fibonacci sequence \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n is generally denoted as \n  \n    \n      \n        \n          F\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle F_{n}}\n  \n.\nIn computing and computer science, finite sequences are usually called strings, words or lists, with the specific technical term chosen depending on the type of object the sequence enumerates and the different ways to represent the sequence in computer memory. Infinite sequences are called streams.\nThe empty sequence ( ) is included in most notions of sequence. It may be excluded depending on the context.\n\nExamples and notation\nA sequence can be thought of as a list of elements with a particular order. Sequences are useful in a number of mathematical disciplines for studying functions, spaces, and other mathematical structures using the convergence properties of sequences. In particular, sequences are the basis for series, which are important in differential equations and analysis. Sequences are also of interest in their own right, and can be studied as patterns or puzzles, such as in the study of prime numbers.\nThere are a number of ways to denote a sequence, some of which are more useful for specific types of sequences. One way to specify a sequence is to list all its elements. For example, the first four odd numbers form the sequence (1, 3, 5, 7). This notation is used for infinite sequences as well. For instance, the infinite sequence of positive odd integers is written as (1, 3, 5, 7, ...). Because notating sequences with ellipsis leads to ambiguity, listing is most useful for customary infinite sequences which can be easily recognized from their first few elements. Other ways of denoting a sequence are discussed after the examples.\n\nExamples\nThe prime numbers are the natural numbers greater than 1 that have no divisors but 1 and themselves. Taking these in their natural order gives the sequence (2, 3, 5, 7, 11, 13, 17, ...). The prime numbers are widely used in mathematics, particularly in number theory where many results related to them exist.\nThe Fibonacci numbers comprise the integer sequence in which each element is the sum of the previous two elements. The first two elements are either 0 and 1 or 1 and 1 so that the sequence is (0, 1, 1, 2, 3, 5, 8, 13, 21, 34, ...).\nOther examples of sequences include those made up of rational numbers, real numbers and complex numbers. The sequence (.9, .99, .999, .9999, ...), for instance, approaches the number 1. In fact, every real number can be written as the limit of a sequence of rational numbers (e.g. via its decimal expansion, also see completeness of the real numbers). As another example, π is the limit of the sequence (3, 3.1, 3.14, 3.141, 3.1415, ...), which is increasing. A related sequence is the sequence of decimal digits of π, that is, (3, 1, 4, 1, 5, 9, ...). Unlike the preceding sequence, this sequence does not have any pattern that is easily discernible by inspection.\nOther examples are sequences of functions, whose elements are functions instead of numbers.\nThe On-Line Encyclopedia of Integer Sequences comprises a large list of examples o",
    "links": [
      "1/2 + 1/4 + 1/8 + 1/16 + ⋯",
      "1/2 − 1/4 + 1/8 − 1/16 + ⋯",
      "1/4 + 1/16 + 1/64 + 1/256 + ⋯",
      "1 + 1 + 1 + 1 + ⋯",
      "1 + 2 + 3 + 4 + ⋯",
      "1 + 2 + 4 + 8 + ⋯",
      "1 − 1 + 2 − 6 + 24 − 120 + ⋯",
      "1 − 2 + 3 − 4 + ⋯",
      "1 − 2 + 4 − 8 + ⋯",
      "Absolute convergence",
      "Algebraic function",
      "Algebraic structure",
      "Algebraic topology",
      "Alphabet (computer science)",
      "Alternating series",
      "Analysis (mathematics)",
      "Analytic function",
      "Arithmetic progression",
      "Automatic sequence",
      "Base 2",
      "Bibcode (identifier)",
      "Bijection",
      "Binary relation",
      "Binary sequence",
      "Binet's formula",
      "Bit",
      "Boolean-valued function",
      "Boolean function",
      "Cantor's diagonal argument",
      "Cantor space",
      "Cartesian product",
      "Cauchy product",
      "Cauchy sequence",
      "Character (computing)",
      "Coarsest topology",
      "Codomain",
      "Compact space",
      "Complete metric space",
      "Complete sequence",
      "Completeness of the real numbers",
      "Complex-valued function",
      "Complex number",
      "Complex numbers",
      "Computer memory",
      "Computer science",
      "Computing",
      "Conditional convergence",
      "Connected space",
      "Constant-recursive sequence",
      "Constant (mathematics)"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Elementary mathematics",
      "Category:Sequences and series",
      "Category:Short description is different from Wikidata",
      "Category:Webarchive template wayback links"
    ]
  },
  "Vector space": {
    "title": "Vector space",
    "url": "https://en.wikipedia.org/wiki/Vector_space",
    "summary": "In mathematics and physics, a vector space (also called a linear space) is a set whose elements, often called vectors, can be added together and multiplied (\"scaled\") by numbers called scalars. The operations of vector addition and scalar multiplication must satisfy certain requirements, called vector axioms. Real vector spaces and complex vector spaces are kinds of vector spaces based on different kinds of scalars: real numbers and complex numbers. Scalars can also be, more generally, elements of any field.\nVector spaces generalize Euclidean vectors, which allow modeling of physical quantities (such as forces and velocity) that have not only a magnitude, but also a direction. The concept of vector spaces is fundamental for linear algebra, together with the concept of matrices, which allows computing in vector spaces. This provides a concise and synthetic way for manipulating and studying systems of linear equations.\nVector spaces are characterized by their dimension, which, roughly sp",
    "content": "In mathematics and physics, a vector space (also called a linear space) is a set whose elements, often called vectors, can be added together and multiplied (\"scaled\") by numbers called scalars. The operations of vector addition and scalar multiplication must satisfy certain requirements, called vector axioms. Real vector spaces and complex vector spaces are kinds of vector spaces based on different kinds of scalars: real numbers and complex numbers. Scalars can also be, more generally, elements of any field.\nVector spaces generalize Euclidean vectors, which allow modeling of physical quantities (such as forces and velocity) that have not only a magnitude, but also a direction. The concept of vector spaces is fundamental for linear algebra, together with the concept of matrices, which allows computing in vector spaces. This provides a concise and synthetic way for manipulating and studying systems of linear equations.\nVector spaces are characterized by their dimension, which, roughly speaking, specifies the number of independent directions in the space. This means that, for two vector spaces over a given field and with the same dimension, the properties that depend only on the vector-space structure are exactly the same (technically the vector spaces are isomorphic). A vector space is finite-dimensional if its dimension is a natural number. Otherwise, it is infinite-dimensional, and its dimension is an infinite cardinal. Finite-dimensional vector spaces occur naturally in geometry and related areas. Infinite-dimensional vector spaces occur in many areas of mathematics. For example, polynomial rings are countably infinite-dimensional vector spaces, and many function spaces have the cardinality of the continuum as a dimension.\nMany vector spaces that are considered in mathematics are also endowed with other structures. This is the case of algebras, which include field extensions, polynomial rings, associative algebras and Lie algebras. This is also the case of topological vector spaces, which include function spaces, inner product spaces, normed spaces, Hilbert spaces and Banach spaces.\n\nDefinition and basic properties\nIn this article, vectors are represented in boldface to distinguish them from scalars.\nA vector space over a field F is a non-empty set V together with a binary operation and a binary function that satisfy the eight axioms listed below. In this context, the elements of V are commonly called vectors, and the elements of F are called scalars.\n\nThe binary operation, called vector addition or simply addition assigns to any two vectors v and w in V a third vector in V which is commonly written as v + w, and called the sum of these two vectors.\nThe binary function, called scalar multiplication, assigns to any scalar a in F and any vector v in V another vector in V, which is denoted av.\nTo have a vector space, the eight following axioms must be satisfied for every u, v and w in V, and a and b in F.\n\nWhen the scalar field is the real numbers, the vector space is called a real vector space, and when the scalar field is the complex numbers, the vector space is called a complex vector space. These two cases are the most common ones, but vector spaces with scalars in an arbitrary field F are also commonly considered. Such a vector space is called an F-vector space or a vector space over F.\nAn equivalent definition of a vector space can be given, which is much more concise but less elementary: the first four axioms (related to vector addition) say that a vector space is an abelian group under addition, and the four remaining axioms (related to the scalar multiplication) say that this operation defines a ring homomorphism from the field F into the endomorphism ring of this group.\nSubtraction of two vectors can be defined as\n\n  \n    \n      \n        \n          v\n        \n        −\n        \n          w\n        \n        =\n        \n          v\n        \n        +\n        (\n        −\n        \n          w\n        \n        )\n        .\n      \n    \n    {\\displaystyle \\mathbf {v} -\\mathbf {w} =\\mathbf {v} +(-\\mathbf {w} ).}\n  \n\nDirect consequences of the axioms include that, for every \n  \n    \n      \n        s\n        ∈\n        F\n      \n    \n    {\\displaystyle s\\in F}\n  \n and \n  \n    \n      \n        \n          v\n        \n        ∈\n        V\n        ,\n      \n    \n    {\\displaystyle \\mathbf {v} \\in V,}\n  \n one has\n\n  \n    \n      \n        0\n        \n          v\n        \n        =\n        \n          0\n        \n        ,\n      \n    \n    {\\displaystyle 0\\mathbf {v} =\\mathbf {0} ,}\n  \n\n  \n    \n      \n        s\n        \n          0\n        \n        =\n        \n          0\n        \n        ,\n      \n    \n    {\\displaystyle s\\mathbf {0} =\\mathbf {0} ,}\n  \n\n  \n    \n      \n        (\n        −\n        1\n        )\n        \n          v\n        \n        =\n        −\n        \n          v\n        \n        ,\n      \n    \n    {\\displaystyle (-1)\\mathbf {v} =-\\mathbf {v} ,}\n  \n\n  \n    \n      \n        s\n        \n          v\n        \n        =\n   ",
    "links": [
      "2-sphere",
      "Abelian category",
      "Abelian group",
      "Academic Press",
      "Addison-Wesley",
      "Additive inverse",
      "Affine geometry",
      "Affine space",
      "Algebra",
      "Algebra (Lang)",
      "Algebra over a field",
      "Algebraic geometry",
      "Algebraic number theory",
      "Algebraic structure",
      "Algebraically closed field",
      "Algebras over a field",
      "Almost everywhere",
      "American Mathematical Monthly",
      "American Mathematical Society",
      "Analytic geometry",
      "Anticommutativity",
      "Arnold Schönhage",
      "Arrow (symbol)",
      "Arthur Cayley",
      "Associative algebra",
      "Associative property",
      "Associativity",
      "August Ferdinand Möbius",
      "Axiom",
      "Axiom of choice",
      "Banach space",
      "Bartel Leendert van der Waerden",
      "Barycentric coordinates (mathematics)",
      "Basic Linear Algebra Subprograms",
      "Basis (linear algebra)",
      "Bernard Bolzano",
      "Bernhard Bolzano",
      "Bialgebra",
      "Bijection",
      "Bilinear map",
      "Bilinear operator",
      "Binary function",
      "Binary operation",
      "Bivector",
      "Block matrix",
      "Boolean algebra (structure)",
      "Cardinality",
      "Cardinality of the continuum",
      "Cartesian coordinates",
      "Cartesian product"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1 French-language sources (fr)",
      "Category:CS1 German-language sources (de)",
      "Category:CS1 Italian-language sources (it)",
      "Category:CS1 maint: location missing publisher",
      "Category:Concepts in physics",
      "Category:Good articles",
      "Category:Group theory",
      "Category:Mathematical structures",
      "Category:Pages using multiple image with auto scaled images"
    ]
  },
  "Bernoulli number": {
    "title": "Bernoulli number",
    "url": "https://en.wikipedia.org/wiki/Bernoulli_number",
    "summary": "In mathematics, the Bernoulli numbers Bn are a sequence of rational numbers which occur frequently in analysis. The Bernoulli numbers appear in (and can be defined by) the Taylor series expansions of the tangent and hyperbolic tangent functions, in Faulhaber's formula for the sum of m-th powers of the first n positive integers, in the Euler–Maclaurin formula, and in expressions for certain values of the Riemann zeta function.\nThe values of the first 20 Bernoulli numbers are given in the adjacent table. Two conventions are used in the literature, denoted here by \n  \n    \n      \n        \n          B\n          \n            n\n          \n          \n            −\n            \n\n            \n          \n        \n      \n    \n    {\\displaystyle B_{n}^{-{}}}\n  \n and \n  \n    \n      \n        \n          B\n          \n            n\n          \n          \n            +\n            \n\n            \n          \n        \n      \n    \n    {\\displaystyle B_{n}^{+{}}}\n  \n; they differ only for n = 1, where \n  \n   ",
    "content": "In mathematics, the Bernoulli numbers Bn are a sequence of rational numbers which occur frequently in analysis. The Bernoulli numbers appear in (and can be defined by) the Taylor series expansions of the tangent and hyperbolic tangent functions, in Faulhaber's formula for the sum of m-th powers of the first n positive integers, in the Euler–Maclaurin formula, and in expressions for certain values of the Riemann zeta function.\nThe values of the first 20 Bernoulli numbers are given in the adjacent table. Two conventions are used in the literature, denoted here by \n  \n    \n      \n        \n          B\n          \n            n\n          \n          \n            −\n            \n\n            \n          \n        \n      \n    \n    {\\displaystyle B_{n}^{-{}}}\n  \n and \n  \n    \n      \n        \n          B\n          \n            n\n          \n          \n            +\n            \n\n            \n          \n        \n      \n    \n    {\\displaystyle B_{n}^{+{}}}\n  \n; they differ only for n = 1, where \n  \n    \n      \n        \n          B\n          \n            1\n          \n          \n            −\n            \n\n            \n          \n        \n        =\n        −\n        1\n        \n          /\n        \n        2\n      \n    \n    {\\displaystyle B_{1}^{-{}}=-1/2}\n  \n and \n  \n    \n      \n        \n          B\n          \n            1\n          \n          \n            +\n            \n\n            \n          \n        \n        =\n        +\n        1\n        \n          /\n        \n        2\n      \n    \n    {\\displaystyle B_{1}^{+{}}=+1/2}\n  \n. For every odd n > 1, Bn = 0. For every even n > 0, Bn is negative if n is divisible by 4 and positive otherwise. The Bernoulli numbers are special values of the Bernoulli polynomials \n  \n    \n      \n        \n          B\n          \n            n\n          \n        \n        (\n        x\n        )\n      \n    \n    {\\displaystyle B_{n}(x)}\n  \n, with \n  \n    \n      \n        \n          B\n          \n            n\n          \n          \n            −\n            \n\n            \n          \n        \n        =\n        \n          B\n          \n            n\n          \n        \n        (\n        0\n        )\n      \n    \n    {\\displaystyle B_{n}^{-{}}=B_{n}(0)}\n  \n and \n  \n    \n      \n        \n          B\n          \n            n\n          \n          \n            +\n          \n        \n        =\n        \n          B\n          \n            n\n          \n        \n        (\n        1\n        )\n      \n    \n    {\\displaystyle B_{n}^{+}=B_{n}(1)}\n  \n.\nThe Bernoulli numbers were discovered around the same time by the Swiss mathematician Jacob Bernoulli, after whom they are named, and independently by Japanese mathematician Seki Takakazu.  Seki's discovery was posthumously published in 1712 in his work Katsuyō Sanpō; Bernoulli's, also posthumously, in his Ars Conjectandi of 1713.  Ada Lovelace's note G on the Analytical Engine from 1842 describes an algorithm for generating Bernoulli numbers with Babbage's machine; it is disputed whether Lovelace or Babbage developed the algorithm. As a result, the Bernoulli numbers have the distinction of being the subject of the first published complex computer program.\n\nNotation\nThe superscript ± used in this article distinguishes the two sign conventions for Bernoulli numbers. Only the n = 1 term is affected: \n\nB−n  with B−1 =  −⁠1/2⁠  (OEIS: A027641 / OEIS: A027642) is the sign convention prescribed by NIST and most modern textbooks.\nB+n with B+1 = +⁠1/2⁠  (OEIS: A164555 / OEIS: A027642) was used in the older literature, and (since 2022) by Donald Knuth following Peter Luschny's \"Bernoulli Manifesto\".\nIn the formulas below, one can switch from one sign convention to the other with the relation \n  \n    \n      \n        \n          B\n          \n            n\n          \n          \n            +\n          \n        \n        =\n        (\n        −\n        1\n        \n          )\n          \n            n\n          \n        \n        \n          B\n          \n            n\n          \n          \n            −\n          \n        \n      \n    \n    {\\displaystyle B_{n}^{+}=(-1)^{n}B_{n}^{-}}\n  \n, or for integer n = 2 or greater, simply ignore it.\nSince Bn = 0 for all odd n > 1, and many formulas only involve even-index Bernoulli numbers, a few authors write \"Bn\" instead of B2n . This article does not follow that notation.\n\nHistory\nEarly history\nThe Bernoulli numbers are rooted in the early history of the computation of sums of integer powers, which have been of interest to mathematicians since antiquity.\n\nMethods to calculate the sum of the first n positive integers, the sum of the squares and of the cubes of the first n positive integers were known, but there were no real 'formulas', only descriptions given entirely in words. Among the great mathematicians of antiquity to consider this problem were Pythagoras (c. 572–497 BCE, Greece), Archimedes (287–212 BCE, Italy), Aryabhata (b. 476, India), Al-Karaji (d. 1019, Persia) and Ibn al-Haytham (965–1039, Iraq).\nDuring the late sixteenth and early seventeenth centurie",
    "links": [
      "(ε, δ)-definition of limit",
      "Abel's test",
      "Abraham de Moivre",
      "Ada Lovelace",
      "Adequality",
      "Agoh–Giuga conjecture",
      "Al-Karaji",
      "Algebraic number",
      "Algorithm",
      "Alternating permutation",
      "Alternating permutations",
      "Alternating series",
      "Alternating series test",
      "Analytical Engine",
      "Ankeny–Artin–Chowla congruence",
      "Antiderivative",
      "ArXiv (identifier)",
      "Arc length",
      "Archimedes",
      "Arithmetico-geometric sequence",
      "Ars Conjectandi",
      "Aryabhata",
      "Asymptotic analysis",
      "Asymptotic expansion",
      "Asymptotic series",
      "Bell number",
      "Bernoulli polynomial",
      "Bernoulli polynomials",
      "Bernoulli polynomials of the second kind",
      "Bernoulli umbra",
      "Bibcode (identifier)",
      "Big-O notation",
      "Binomial coefficient",
      "Binomial series",
      "Binomial theorem",
      "Blaise Pascal",
      "Boustrophedon transform",
      "Brook Taylor",
      "Calculus",
      "Carl Gustav Jacob Jacobi",
      "Cauchy condensation test",
      "Chain rule",
      "Charles Babbage",
      "Chinese remainder theorem",
      "Closed-form expression",
      "Closed manifold",
      "Coefficient",
      "Colin Maclaurin",
      "Computational complexity theory",
      "Computer program"
    ],
    "categories": [
      "Category:All Wikipedia articles written in American English",
      "Category:Articles containing German-language text",
      "Category:Articles with short description",
      "Category:CS1: long volume value",
      "Category:CS1 Italian-language sources (it)",
      "Category:CS1 Latin-language sources (la)",
      "Category:Eponymous numbers in mathematics",
      "Category:Integer sequences",
      "Category:Number theory",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Bernoulli numbers": {
    "title": "Bernoulli number",
    "url": "https://en.wikipedia.org/wiki/Bernoulli_number",
    "summary": "In mathematics, the Bernoulli numbers Bn are a sequence of rational numbers which occur frequently in analysis. The Bernoulli numbers appear in (and can be defined by) the Taylor series expansions of the tangent and hyperbolic tangent functions, in Faulhaber's formula for the sum of m-th powers of the first n positive integers, in the Euler–Maclaurin formula, and in expressions for certain values of the Riemann zeta function.\nThe values of the first 20 Bernoulli numbers are given in the adjacent table. Two conventions are used in the literature, denoted here by \n  \n    \n      \n        \n          B\n          \n            n\n          \n          \n            −\n            \n\n            \n          \n        \n      \n    \n    {\\displaystyle B_{n}^{-{}}}\n  \n and \n  \n    \n      \n        \n          B\n          \n            n\n          \n          \n            +\n            \n\n            \n          \n        \n      \n    \n    {\\displaystyle B_{n}^{+{}}}\n  \n; they differ only for n = 1, where \n  \n   ",
    "content": "In mathematics, the Bernoulli numbers Bn are a sequence of rational numbers which occur frequently in analysis. The Bernoulli numbers appear in (and can be defined by) the Taylor series expansions of the tangent and hyperbolic tangent functions, in Faulhaber's formula for the sum of m-th powers of the first n positive integers, in the Euler–Maclaurin formula, and in expressions for certain values of the Riemann zeta function.\nThe values of the first 20 Bernoulli numbers are given in the adjacent table. Two conventions are used in the literature, denoted here by \n  \n    \n      \n        \n          B\n          \n            n\n          \n          \n            −\n            \n\n            \n          \n        \n      \n    \n    {\\displaystyle B_{n}^{-{}}}\n  \n and \n  \n    \n      \n        \n          B\n          \n            n\n          \n          \n            +\n            \n\n            \n          \n        \n      \n    \n    {\\displaystyle B_{n}^{+{}}}\n  \n; they differ only for n = 1, where \n  \n    \n      \n        \n          B\n          \n            1\n          \n          \n            −\n            \n\n            \n          \n        \n        =\n        −\n        1\n        \n          /\n        \n        2\n      \n    \n    {\\displaystyle B_{1}^{-{}}=-1/2}\n  \n and \n  \n    \n      \n        \n          B\n          \n            1\n          \n          \n            +\n            \n\n            \n          \n        \n        =\n        +\n        1\n        \n          /\n        \n        2\n      \n    \n    {\\displaystyle B_{1}^{+{}}=+1/2}\n  \n. For every odd n > 1, Bn = 0. For every even n > 0, Bn is negative if n is divisible by 4 and positive otherwise. The Bernoulli numbers are special values of the Bernoulli polynomials \n  \n    \n      \n        \n          B\n          \n            n\n          \n        \n        (\n        x\n        )\n      \n    \n    {\\displaystyle B_{n}(x)}\n  \n, with \n  \n    \n      \n        \n          B\n          \n            n\n          \n          \n            −\n            \n\n            \n          \n        \n        =\n        \n          B\n          \n            n\n          \n        \n        (\n        0\n        )\n      \n    \n    {\\displaystyle B_{n}^{-{}}=B_{n}(0)}\n  \n and \n  \n    \n      \n        \n          B\n          \n            n\n          \n          \n            +\n          \n        \n        =\n        \n          B\n          \n            n\n          \n        \n        (\n        1\n        )\n      \n    \n    {\\displaystyle B_{n}^{+}=B_{n}(1)}\n  \n.\nThe Bernoulli numbers were discovered around the same time by the Swiss mathematician Jacob Bernoulli, after whom they are named, and independently by Japanese mathematician Seki Takakazu.  Seki's discovery was posthumously published in 1712 in his work Katsuyō Sanpō; Bernoulli's, also posthumously, in his Ars Conjectandi of 1713.  Ada Lovelace's note G on the Analytical Engine from 1842 describes an algorithm for generating Bernoulli numbers with Babbage's machine; it is disputed whether Lovelace or Babbage developed the algorithm. As a result, the Bernoulli numbers have the distinction of being the subject of the first published complex computer program.\n\nNotation\nThe superscript ± used in this article distinguishes the two sign conventions for Bernoulli numbers. Only the n = 1 term is affected: \n\nB−n  with B−1 =  −⁠1/2⁠  (OEIS: A027641 / OEIS: A027642) is the sign convention prescribed by NIST and most modern textbooks.\nB+n with B+1 = +⁠1/2⁠  (OEIS: A164555 / OEIS: A027642) was used in the older literature, and (since 2022) by Donald Knuth following Peter Luschny's \"Bernoulli Manifesto\".\nIn the formulas below, one can switch from one sign convention to the other with the relation \n  \n    \n      \n        \n          B\n          \n            n\n          \n          \n            +\n          \n        \n        =\n        (\n        −\n        1\n        \n          )\n          \n            n\n          \n        \n        \n          B\n          \n            n\n          \n          \n            −\n          \n        \n      \n    \n    {\\displaystyle B_{n}^{+}=(-1)^{n}B_{n}^{-}}\n  \n, or for integer n = 2 or greater, simply ignore it.\nSince Bn = 0 for all odd n > 1, and many formulas only involve even-index Bernoulli numbers, a few authors write \"Bn\" instead of B2n . This article does not follow that notation.\n\nHistory\nEarly history\nThe Bernoulli numbers are rooted in the early history of the computation of sums of integer powers, which have been of interest to mathematicians since antiquity.\n\nMethods to calculate the sum of the first n positive integers, the sum of the squares and of the cubes of the first n positive integers were known, but there were no real 'formulas', only descriptions given entirely in words. Among the great mathematicians of antiquity to consider this problem were Pythagoras (c. 572–497 BCE, Greece), Archimedes (287–212 BCE, Italy), Aryabhata (b. 476, India), Al-Karaji (d. 1019, Persia) and Ibn al-Haytham (965–1039, Iraq).\nDuring the late sixteenth and early seventeenth centurie",
    "links": [
      "(ε, δ)-definition of limit",
      "Abel's test",
      "Abraham de Moivre",
      "Ada Lovelace",
      "Adequality",
      "Agoh–Giuga conjecture",
      "Al-Karaji",
      "Algebraic number",
      "Algorithm",
      "Alternating permutation",
      "Alternating permutations",
      "Alternating series",
      "Alternating series test",
      "Analytical Engine",
      "Ankeny–Artin–Chowla congruence",
      "Antiderivative",
      "ArXiv (identifier)",
      "Arc length",
      "Archimedes",
      "Arithmetico-geometric sequence",
      "Ars Conjectandi",
      "Aryabhata",
      "Asymptotic analysis",
      "Asymptotic expansion",
      "Asymptotic series",
      "Bell number",
      "Bernoulli polynomial",
      "Bernoulli polynomials",
      "Bernoulli polynomials of the second kind",
      "Bernoulli umbra",
      "Bibcode (identifier)",
      "Big-O notation",
      "Binomial coefficient",
      "Binomial series",
      "Binomial theorem",
      "Blaise Pascal",
      "Boustrophedon transform",
      "Brook Taylor",
      "Calculus",
      "Carl Gustav Jacob Jacobi",
      "Cauchy condensation test",
      "Chain rule",
      "Charles Babbage",
      "Chinese remainder theorem",
      "Closed-form expression",
      "Closed manifold",
      "Coefficient",
      "Colin Maclaurin",
      "Computational complexity theory",
      "Computer program"
    ],
    "categories": [
      "Category:All Wikipedia articles written in American English",
      "Category:Articles containing German-language text",
      "Category:Articles with short description",
      "Category:CS1: long volume value",
      "Category:CS1 Italian-language sources (it)",
      "Category:CS1 Latin-language sources (la)",
      "Category:Eponymous numbers in mathematics",
      "Category:Integer sequences",
      "Category:Number theory",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Apéry's constant": {
    "title": "Apéry's constant",
    "url": "https://en.wikipedia.org/wiki/Ap%C3%A9ry%27s_constant",
    "summary": "In mathematics, Apéry's constant is the infinite sum of the reciprocals of the positive integers, cubed. That is, it is defined as the number\n\n  \n    \n      \n        \n          \n            \n              \n                ζ\n                (\n                3\n                )\n              \n              \n                \n                =\n                \n                  ∑\n                  \n                    n\n                    =\n                    1\n                  \n                  \n                    ∞\n                  \n                \n                \n                  \n                    1\n                    \n                      n\n                      \n                        3\n                      \n                    \n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                \n                  lim\n                  \n                    n\n                    →",
    "content": "In mathematics, Apéry's constant is the infinite sum of the reciprocals of the positive integers, cubed. That is, it is defined as the number\n\n  \n    \n      \n        \n          \n            \n              \n                ζ\n                (\n                3\n                )\n              \n              \n                \n                =\n                \n                  ∑\n                  \n                    n\n                    =\n                    1\n                  \n                  \n                    ∞\n                  \n                \n                \n                  \n                    1\n                    \n                      n\n                      \n                        3\n                      \n                    \n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                \n                  lim\n                  \n                    n\n                    →\n                    ∞\n                  \n                \n                \n                  (\n                  \n                    \n                      \n                        1\n                        \n                          1\n                          \n                            3\n                          \n                        \n                      \n                    \n                    +\n                    \n                      \n                        1\n                        \n                          2\n                          \n                            3\n                          \n                        \n                      \n                    \n                    +\n                    ⋯\n                    +\n                    \n                      \n                        1\n                        \n                          n\n                          \n                            3\n                          \n                        \n                      \n                    \n                  \n                  )\n                \n                ,\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}\\zeta (3)&=\\sum _{n=1}^{\\infty }{\\frac {1}{n^{3}}}\\\\&=\\lim _{n\\to \\infty }\\left({\\frac {1}{1^{3}}}+{\\frac {1}{2^{3}}}+\\cdots +{\\frac {1}{n^{3}}}\\right),\\end{aligned}}}\n  \n\nwhere ζ is the Riemann zeta function. It has an approximate value of\n\nζ(3) ≈ 1.202056903159594285399738161511449990764986292… (sequence A002117 in the OEIS).\nIt is named after Roger Apéry, who proved that it is an irrational number.\n\nUses\nApéry's constant arises naturally in a number of physical problems, including in the second- and third-order terms of the electron's gyromagnetic ratio using quantum electrodynamics. It also arises in the analysis of random minimum spanning trees and in conjunction with the gamma function when solving certain integrals involving exponential functions in a quotient, which appear occasionally in physics, for instance, when evaluating the two-dimensional case of the Debye model and the Stefan–Boltzmann law.\nThe reciprocal of ζ(3) (0.8319073725807... (sequence A088453 in the OEIS)) is the probability that any three positive integers, chosen at random, will be relatively prime, in the sense that as N approaches infinity, the probability that three positive integers less than N chosen uniformly at random will not share a common prime factor approaches this value. (The probability for n positive integers is 1/ζ(n).) In the same sense, it is the probability that a positive integer chosen at random will not be evenly divisible by the cube of an integer greater than one. (The probability for not having divisibility by an n-th power is 1/ζ(n).)\n\nProperties\nζ(3) was named Apéry's constant after the French mathematician Roger Apéry, who proved in 1978 that it is an irrational number. This result is known as Apéry's theorem. The original proof is complex and hard to grasp, and simpler proofs were found later.\nBeukers's simplified irrationality proof involves approximating the integrand of the known triple integral for ζ(3),\n\n  \n    \n      \n        ζ\n        (\n        3\n        )\n        =\n        \n          ∫\n          \n            0\n          \n          \n            1\n          \n        \n        \n          ∫\n          \n            0\n          \n          \n            1\n          \n        \n        \n          ∫\n          \n            0\n          \n          \n            1\n          \n        \n        \n          \n            1\n            \n              1\n              −\n              x\n              y\n              z\n            \n          \n        \n        \n        d\n        x\n        \n        d\n        y\n        \n        d\n        z\n        ,\n      \n    \n    {\\displaystyle \\zeta (3)=\\int _{0}^{1}\\int _{0}^{1}\\int _{0}^{1}{\\frac {1}{1-xyz}}\\,dx\\,dy\\,dz,}\n  \n\nby the Legendre polynomials.\nIn particular, van der Poorten's article chronicles this approach by noting th",
    "links": [
      "Adrien-Marie Legendre",
      "Alan M. Frieze",
      "Alfred van der Poorten",
      "Almost integer",
      "Andrey Markov",
      "Apéry's theorem",
      "ArXiv (identifier)",
      "Basel problem",
      "Bibcode (identifier)",
      "Binary digit",
      "Cahen's constant",
      "Catalan's constant",
      "Chaitin's constant",
      "Continued fraction",
      "Cube (algebra)",
      "Debye model",
      "Discrete Applied Mathematics",
      "Doi (identifier)",
      "Dottie number",
      "Doubling the cube",
      "E (mathematical constant)",
      "Erdős–Borwein constant",
      "Eric W. Weisstein",
      "Frits Beukers",
      "Gamma function",
      "Golden ratio",
      "Gyromagnetic ratio",
      "ISBN (identifier)",
      "Infinite sum",
      "Irrational number",
      "Johan Jensen (mathematician)",
      "Legendre polynomials",
      "Lemniscate constant",
      "Leonhard Euler",
      "Linear time",
      "Liouville number",
      "List of sums of reciprocals",
      "List of unsolved problems in mathematics",
      "Logarithmic space",
      "MR (identifier)",
      "MathWorld",
      "Mathematics",
      "Multiplicative inverse",
      "Natural logarithm of 2",
      "OCLC (identifier)",
      "Omega constant",
      "On-Line Encyclopedia of Integer Sequences",
      "Particular values of the Riemann zeta function",
      "Period (algebraic geometry)",
      "Pi"
    ],
    "categories": [
      "Category:Analytic number theory",
      "Category:Articles with short description",
      "Category:CS1 Latin-language sources (la)",
      "Category:CS1 Russian-language sources (ru)",
      "Category:CS1 maint: overridden setting",
      "Category:Irrational numbers",
      "Category:Mathematical constants",
      "Category:Short description is different from Wikidata",
      "Category:Wikipedia articles incorporating text from PlanetMath",
      "Category:Zeta and L-functions"
    ]
  },
  "Henri Cohen (number theorist)": {
    "title": "Henri Cohen (number theorist)",
    "url": "https://en.wikipedia.org/wiki/Henri_Cohen_(number_theorist)",
    "summary": "Henri Cohen (born 8 June 1947) is a number theorist, and an emeritus professor at the University of Bordeaux.  He is best known for leading the team that created the PARI/GP computer algebra system.  He also introduced the Rankin–Cohen bracket, co-proposed the Cohen-Lenstra heuristics and has written several textbooks in computational and algebraic number theory.",
    "content": "Henri Cohen (born 8 June 1947) is a number theorist, and an emeritus professor at the University of Bordeaux.  He is best known for leading the team that created the PARI/GP computer algebra system.  He also introduced the Rankin–Cohen bracket, co-proposed the Cohen-Lenstra heuristics and has written several textbooks in computational and algebraic number theory.\n\nSelected publications\nCohen, Henri (1996). A Course In Computational Algebraic Number Theory. Graduate Texts in Mathematics. Vol. 138. Springer-Verlag. ISBN 0-387-55640-0. 3rd, corrected printing{{cite book}}:  CS1 maint: postscript (link); 2nd correct. print 1995; 1st printing 1993\nCohen, Henri (2000). Advanced Topics in Computational Number Theory. Graduate Texts in Mathematics. Vol. 193. Springer-Verlag. ISBN 0-387-98727-4.\nCohen, Henri (2006). Handbook of Elliptic and Hyperelliptic Curve Cryptography. Discrete Mathematics and Its Applications. Chapman & Hall/CRC. ISBN 978-1-58488-518-4.\nCohen, Henri (2007). Number Theory – Volume I: Tools and Diophantine Equations. Graduate Texts in Mathematics. Vol. 239. Springer-Verlag. ISBN 978-0-387-49922-2.\nCohen, Henri (2007). Number Theory – Volume II: Analytic and Modern Tools. Graduate Texts in Mathematics. Vol. 240. Springer-Verlag. ISBN 978-0-387-49893-5.\n\nReferences\nExternal links\nPersonal web page\nHenri Cohen at the Mathematics Genealogy Project",
    "links": [
      "Algebraic number theory",
      "CRC Press",
      "Cohen-Lenstra heuristics",
      "Computational number theory",
      "Computer algebra",
      "Discrete Mathematics and Its Applications",
      "Doi (identifier)",
      "Graduate Texts in Mathematics",
      "Hale Trotter",
      "ISBN (identifier)",
      "Mathematics Genealogy Project",
      "Number theory",
      "PARI/GP",
      "Rankin–Cohen bracket",
      "Springer-Verlag",
      "Textbooks",
      "University of Bordeaux",
      "Wikipedia:Stub",
      "Template:Cite book",
      "Template:France-mathematician-stub",
      "Template talk:France-mathematician-stub",
      "Help:Authority control",
      "Category:CS1 maint: postscript"
    ],
    "categories": [
      "Category:1947 births",
      "Category:20th-century French mathematicians",
      "Category:21st-century French mathematicians",
      "Category:Academic staff of the University of Bordeaux",
      "Category:All stub articles",
      "Category:Articles with short description",
      "Category:CS1 maint: postscript",
      "Category:French mathematician stubs",
      "Category:French number theorists",
      "Category:Living people"
    ]
  },
  "Irrational number": {
    "title": "Irrational number",
    "url": "https://en.wikipedia.org/wiki/Irrational_number",
    "summary": "In mathematics, the irrational numbers are all the real numbers that are not rational numbers. That is, irrational numbers cannot be expressed as the ratio of two integers. When the ratio of lengths of two line segments is an irrational number, the line segments are also described as being incommensurable, meaning that they share no \"measure\" in common, that is, there is no length (\"the measure\"), no matter how short, that could be used to express the lengths of both of the two given segments as integer multiples of itself.\nAmong irrational numbers are the ratio π of a circle's circumference to its diameter, Euler's number e, the golden ratio φ, and the square root of two.  In fact, all square roots of natural numbers, other than of perfect squares, are irrational.\nLike all real numbers, irrational numbers can be expressed in positional notation, notably as a decimal number. In the case of irrational numbers, the decimal expansion does not terminate, nor end with a repeating sequence. ",
    "content": "In mathematics, the irrational numbers are all the real numbers that are not rational numbers. That is, irrational numbers cannot be expressed as the ratio of two integers. When the ratio of lengths of two line segments is an irrational number, the line segments are also described as being incommensurable, meaning that they share no \"measure\" in common, that is, there is no length (\"the measure\"), no matter how short, that could be used to express the lengths of both of the two given segments as integer multiples of itself.\nAmong irrational numbers are the ratio π of a circle's circumference to its diameter, Euler's number e, the golden ratio φ, and the square root of two.  In fact, all square roots of natural numbers, other than of perfect squares, are irrational.\nLike all real numbers, irrational numbers can be expressed in positional notation, notably as a decimal number. In the case of irrational numbers, the decimal expansion does not terminate, nor end with a repeating sequence. For example, the decimal representation of π starts with 3.14159, but no finite number of digits can represent π exactly, nor does it repeat. Conversely, a decimal expansion that terminates or repeats must be a rational number. These are provable properties of rational numbers and positional number systems and are not used as definitions in mathematics.\nIrrational numbers can also be expressed as non-terminating continued fractions (which in some cases are periodic), and in many other ways.\nAs a consequence of Cantor's proof that the real numbers are uncountable and the rationals countable, it follows that almost all real numbers are irrational.\n\nHistory\nAncient Greece\nThe first proof of the existence of irrational numbers is usually attributed to a Pythagorean (possibly Hippasus of Metapontum), who probably discovered them while identifying sides of the pentagram.\nThe Pythagorean method would have claimed that there must be some sufficiently small, indivisible unit that could fit evenly into one of these lengths as well as the other. Hippasus in the 5th century BC, however, was able to deduce that there was no common unit of measure, and that the assertion of such an existence was a contradiction. He did this by demonstrating that if the hypotenuse of an isosceles right triangle was indeed commensurable with a leg, then one of those lengths measured in that unit of measure must be both odd and even, which is impossible. His reasoning is as follows:\n\nStart with an isosceles right triangle with side lengths of integers a, b, and c (a = b since it is isosceles). The ratio of the hypotenuse to a leg is represented by c:b.\nAssume a, b, and c are in the smallest possible terms  (i.e. they have no common factors).\nBy the Pythagorean theorem: c2 = a2+b2 = b2+b2 = 2b2. (Since the triangle is isosceles, a = b).\nSince c2 = 2b2, c2 is divisible by 2, and therefore even.\nSince c2 is even, c must be even.\nSince c is even, dividing c by 2 yields an integer. Let y be this integer (c = 2y).\nSquaring both sides of c = 2y yields c2 = (2y)2, or c2 = 4y2.\nSubstituting 4y2 for c2 in the first equation (c2 = 2b2) gives us 4y2= 2b2.\nDividing by 2 yields 2y2 = b2.\nSince y is an integer, and 2y2 = b2, b2 is divisible by 2, and therefore even.\nSince b2 is even, b must be even.\nWe have just shown that both b and c must be even.   Hence they have a common factor of 2.  However, this contradicts the assumption that they have no common factors.  This contradiction proves that c and b cannot both be integers and thus the existence of a number that cannot be expressed as a ratio of two integers.\nGreek mathematicians termed this ratio of incommensurable magnitudes alogos, or inexpressible. Hippasus, however, was not lauded for his efforts: according to one legend, he made his discovery while out at sea, and was subsequently thrown overboard by his fellow Pythagoreans 'for having produced an element in the universe which denied the... doctrine that all phenomena in the universe can be reduced to whole numbers and their ratios.' Another legend states that Hippasus was merely exiled for this revelation. Whatever the consequence to Hippasus himself, his discovery posed a very serious problem to Pythagorean mathematics, since it shattered the assumption that numbers and geometry were inseparable; a foundation of their theory.\nThe discovery of incommensurable ratios was indicative of another problem facing the Greeks: the relation of the discrete to the continuous. This was brought to light by Zeno of Elea, who questioned the conception that quantities are discrete and composed of a finite number of units of a given size. Past Greek conceptions dictated that they necessarily must be, for \"whole numbers represent discrete objects, and a commensurable ratio represents a relation between two collections of discrete objects\", but Zeno found that in fact \"[quantities] in general are not discrete collections of units; this is why ratios of incommensurable [quantities] ap",
    "links": [
      "Abraham de Moivre",
      "Abū Kāmil Shujā ibn Aslam",
      "Adolf Hurwitz",
      "Adrien-Marie Legendre",
      "Al-Hassār",
      "Al-Mahani",
      "Algebra",
      "Algebra of physical space",
      "Algebraic independence",
      "Algebraic number",
      "Almost all",
      "Annals of Mathematics",
      "Apartness relation",
      "Apéry's constant",
      "Arithmetic",
      "Bessel–Clifford function",
      "Bhāskara I",
      "Bhāskara II",
      "Bibcode (identifier)",
      "Bicomplex number",
      "Binary numeral system",
      "Bioctonion",
      "Biquaternion",
      "Brahmagupta",
      "Brahmana",
      "Brjuno number",
      "Cahen's constant",
      "Cantor's diagonal argument",
      "Cardinal number",
      "Carl Benjamin Boyer",
      "Catalan's constant",
      "Chaitin's constant",
      "Charles Hermite",
      "Charles Méray",
      "Clifford A. Pickover",
      "Clifford algebra",
      "Closed-form expression",
      "Coefficient",
      "Commensurability (mathematics)",
      "Complete (topology)",
      "Completely metrizable",
      "Complex number",
      "Composite number",
      "Composition algebra",
      "Computable number",
      "Constructible number",
      "Constructive mathematics",
      "Constructive proof",
      "Continued fraction",
      "Countable set"
    ],
    "categories": [
      "Category:All articles needing additional references",
      "Category:All articles with unsourced statements",
      "Category:Articles containing proofs",
      "Category:Articles needing additional references from May 2023",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from January 2018",
      "Category:CS1 French-language sources (fr)",
      "Category:CS1 errors: ISBN date",
      "Category:Commons category link is on Wikidata",
      "Category:Irrational numbers"
    ]
  },
  "Proceedings - Mathematical Sciences": {
    "title": "Proceedings - Mathematical Sciences",
    "url": "https://en.wikipedia.org/wiki/Proceedings_-_Mathematical_Sciences",
    "summary": "Proceedings - Mathematical Sciences is a peer-reviewed  scientific journal that covers current research in mathematics. Papers in pure and applied areas are also published on the basis of the mathematical content. It is published by Springer Science+Business Media on behalf of the Indian Academy of Sciences. The editor-in-chief is Parameswaran Sankaran (Chennai Mathematical Institute).",
    "content": "Proceedings - Mathematical Sciences is a peer-reviewed  scientific journal that covers current research in mathematics. Papers in pure and applied areas are also published on the basis of the mathematical content. It is published by Springer Science+Business Media on behalf of the Indian Academy of Sciences. The editor-in-chief is Parameswaran Sankaran (Chennai Mathematical Institute).\n\nHistory\nThe journal was originally part of the Proceedings of the Indian Academy of Sciences. This journal was established in 1934, but in 1978 it was split into three different journals: Proceedings of the Indian Academy of Sciences – Mathematical Sciences, Journal of Earth System Science, and Journal of Chemical Sciences, all of them continuing as \"volume 87\". The journal was later renamed as Proceedings - Mathematical Sciences.\n\nAbstracting and indexing\nThe journal is abstracted and indexed in:\n\nAccording to the Journal Citation Reports, the journal has a 2019 impact factor of 0.272.\n\nReferences\nExternal links\nOfficial website",
    "links": [
      "Academic OneFile",
      "Academic Search",
      "Academic publishing",
      "CODEN (identifier)",
      "Chennai Mathematical Institute",
      "Current Index to Statistics",
      "EBSCO Publishing",
      "EI-Compendex",
      "Editor-in-chief",
      "INIS Atomindex",
      "ISO 4",
      "ISSN (identifier)",
      "Impact factor",
      "Indian Academy of Sciences",
      "Indian Science Abstracts",
      "Journal Citation Reports",
      "Journal of Chemical Sciences",
      "Journal of Earth System Science",
      "LCCN (identifier)",
      "MathSciNet",
      "Mathematical Reviews",
      "Mathematics",
      "OCLC (identifier)",
      "Outline of academic disciplines",
      "Peer review",
      "Periodical literature",
      "Research",
      "Science Citation Index Expanded",
      "Scientific journal",
      "Scopus",
      "Springer Science+Business Media",
      "Thomson Reuters",
      "Web of Science",
      "Zentralblatt Math",
      "Wikipedia:WikiProject Academic Journals/Bluebook journals"
    ],
    "categories": [
      "Category:Academic journals established in 1978",
      "Category:Articles with outdated impact factors from 2019",
      "Category:Articles with short description",
      "Category:Continuous journals (infobox)",
      "Category:English-language journals",
      "Category:Mathematics journals",
      "Category:Official website different in Wikidata and Wikipedia",
      "Category:Quarterly journals",
      "Category:Short description is different from Wikidata",
      "Category:Springer Science+Business Media academic journals"
    ]
  },
  "Rational number": {
    "title": "Rational number",
    "url": "https://en.wikipedia.org/wiki/Rational_number",
    "summary": "In mathematics, a rational number is a number that can be expressed as the quotient or fraction ⁠\n  \n    \n      \n        \n          \n            \n              p\n              q\n            \n          \n        \n      \n    \n    {\\displaystyle {\\tfrac {p}{q}}}\n  \n⁠ of two integers, a numerator p and a non-zero denominator q. For example, ⁠\n  \n    \n      \n        \n          \n            \n              3\n              7\n            \n          \n        \n      \n    \n    {\\displaystyle {\\tfrac {3}{7}}}\n  \n⁠ is a rational number, as is every integer (for example, \n  \n    \n      \n        −\n        5\n        =\n        \n          \n            \n              \n                −\n                5\n              \n              1\n            \n          \n        \n      \n    \n    {\\displaystyle -5={\\tfrac {-5}{1}}}\n  \n). \nThe set of all rational numbers is often referred to as \"the rationals\",  and is closed under addition, subtraction, multiplication, and division by a nonzero rational number. It is a f",
    "content": "In mathematics, a rational number is a number that can be expressed as the quotient or fraction ⁠\n  \n    \n      \n        \n          \n            \n              p\n              q\n            \n          \n        \n      \n    \n    {\\displaystyle {\\tfrac {p}{q}}}\n  \n⁠ of two integers, a numerator p and a non-zero denominator q. For example, ⁠\n  \n    \n      \n        \n          \n            \n              3\n              7\n            \n          \n        \n      \n    \n    {\\displaystyle {\\tfrac {3}{7}}}\n  \n⁠ is a rational number, as is every integer (for example, \n  \n    \n      \n        −\n        5\n        =\n        \n          \n            \n              \n                −\n                5\n              \n              1\n            \n          \n        \n      \n    \n    {\\displaystyle -5={\\tfrac {-5}{1}}}\n  \n). \nThe set of all rational numbers is often referred to as \"the rationals\",  and is closed under addition, subtraction, multiplication, and division by a nonzero rational number. It is a field under these operations and therefore also called\nthe field of rationals or the field of rational numbers. It is usually denoted by boldface Q, or blackboard bold ⁠\n  \n    \n      \n        \n          Q\n        \n        .\n      \n    \n    {\\displaystyle \\mathbb {Q} .}\n  \n⁠\nA rational number is a real number. The real numbers that are rational are those whose decimal expansion either terminates after a finite number of digits (example: 3/4 = 0.75), or eventually begins to repeat the same finite sequence of digits over and over (example: 9/44 = 0.20454545...). This statement is true not only in base 10, but also in every other integer base, such as the binary and hexadecimal ones (see Repeating decimal § Extension to other bases).\nA real number that is not rational is called irrational. Irrational numbers include the square root of 2 (⁠\n  \n    \n      \n        \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle {\\sqrt {2}}}\n  \n⁠), π, e, and the golden ratio (φ). Since the set of rational numbers is countable, and the set of real numbers is uncountable, almost all real numbers are irrational.\nThe field of rational numbers is the unique field that contains the integers, and is contained in any field containing the integers. In other words, the field of rational numbers is a prime field. A field has characteristic zero if and only if it contains the rational numbers as a subfield. Finite extensions of ⁠\n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n⁠ are called algebraic number fields, and the algebraic closure of ⁠\n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n⁠ is the field of algebraic numbers.\nIn mathematical analysis, the rational numbers form a dense subset of the real numbers. The real numbers can be constructed from the rational numbers by completion, using Cauchy sequences, Dedekind cuts, or infinite decimals (see Construction of the real numbers).\n\nTerminology\nIn mathematics, \"rational\" is often used as a noun abbreviating \"rational number\". The adjective rational sometimes means that the coefficients are rational numbers. For example, a rational point is a point with rational coordinates (i.e., a point whose coordinates are rational numbers); a rational matrix is a matrix of rational numbers; a rational polynomial may be a polynomial with rational coefficients, although the term \"polynomial over the rationals\" is generally preferred, to avoid confusion between \"rational expression\" and \"rational function\" (a polynomial is a rational expression and defines a rational function, even if its coefficients are not rational numbers). However, a rational curve is not a curve defined over the rationals, but a curve which can be parameterized by rational functions.\n\nEtymology\nAlthough nowadays rational numbers are defined in terms of ratios, the term rational is not a derivation of ratio. On the contrary, it is ratio that is derived from rational: the first use of ratio with its modern meaning was attested in English about 1660, while the use of rational for qualifying numbers appeared almost a century earlier, in 1570. This meaning of rational came from the mathematical meaning of irrational, which was first used in 1551, and it was used in \"translations of Euclid (following his peculiar use of ἄλογος)\".\nThis unusual history originated in the fact that ancient Greeks \"avoided heresy by forbidding themselves from thinking of those [irrational] lengths as numbers\". So such lengths were irrational, in the sense of illogical, that is \"not to be spoken about\" (ἄλογος in Greek).\n\nArithmetic\nIrreducible fraction\nEvery rational number may be expressed in a unique way as an irreducible fraction ⁠\n  \n    \n      \n        \n          \n            \n              a\n              b\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle {\\tfrac {a}{b}},}\n  \n⁠ where a and b are coprime integers and b > 0. This i",
    "links": [
      "Absolute difference",
      "Absolute value (algebra)",
      "Addition",
      "Additive inverse",
      "Algebra of physical space",
      "Algebraic closure",
      "Algebraic integer",
      "Algebraic number",
      "Algebraic number field",
      "Almost all",
      "Bicomplex number",
      "Binary numeral system",
      "Bioctonion",
      "Biquaternion",
      "Blackboard bold",
      "Canonical form",
      "Cardinal number",
      "Cauchy sequence",
      "Characteristic (algebra)",
      "Characteristic zero",
      "Chebyshev nodes",
      "Clifford algebra",
      "Closed-form expression",
      "Closed set",
      "Closure (mathematics)",
      "Coefficient",
      "Common fraction",
      "Completeness (topology)",
      "Completion (metric space)",
      "Complex number",
      "Complex numbers",
      "Composite number",
      "Composition algebra",
      "Computable number",
      "Congruence relation",
      "Constructible number",
      "Construction of the real numbers",
      "Continued fraction",
      "Coordinates",
      "Coprime",
      "Coprime integers",
      "Countable",
      "Countable set",
      "Cyclotomic field",
      "Decimal",
      "Decimal expansion",
      "Dedekind cut",
      "Definable number",
      "Definable real number",
      "Denominator"
    ],
    "categories": [
      "Category:Articles containing Ancient Greek (to 1453)-language text",
      "Category:Articles with short description",
      "Category:Commons category link is on Wikidata",
      "Category:Elementary mathematics",
      "Category:Field (mathematics)",
      "Category:Fractions (mathematics)",
      "Category:Rational numbers",
      "Category:Sets of real numbers",
      "Category:Short description matches Wikidata"
    ]
  },
  "Roger Apéry": {
    "title": "Roger Apéry",
    "url": "https://en.wikipedia.org/wiki/Roger_Ap%C3%A9ry",
    "summary": "Roger Apéry (French: [apeʁi]; 14 November 1916, Rouen – 18 December 1994, Caen) was a Greek-French mathematician most remembered for Apéry's theorem, which states that ζ(3) is an irrational number. Here, ζ(s) denotes the Riemann zeta function.",
    "content": "Roger Apéry (French: [apeʁi]; 14 November 1916, Rouen – 18 December 1994, Caen) was a Greek-French mathematician most remembered for Apéry's theorem, which states that ζ(3) is an irrational number. Here, ζ(s) denotes the Riemann zeta function.\n\nBiography\nApéry was born in Rouen in 1916 to a French mother and Greek father. His childhood was spent in Lille until 1926, when the family moved to Paris, where he studied at the Lycée Ledru-Rollin and the Lycée Louis-le-Grand.  He was admitted  at the École normale supérieure in 1935.  His studies were interrupted at the start of World War II; he was mobilized in September 1939, taken prisoner of war in June 1940, repatriated with pleurisy in June 1941, and hospitalized until August 1941. He wrote his doctoral thesis in algebraic geometry under the direction of Paul Dubreil and René Garnier in 1947.\nIn 1947 Apéry was appointed Maître de conférences (lecturer) at the University of Rennes. In 1949 he was appointed Professor at the University of Caen, where he remained until his retirement.\nIn 1979 he published an unexpected proof of the irrationality of ζ(3), which is the sum of the inverses of the cubes of the positive integers. An indication of the difficulty is that the corresponding problem for other odd powers remains unsolved. Nevertheless, many mathematicians have since worked on the so-called Apéry sequences to seek alternative proofs that might apply to other odd powers (Frits Beukers, Alfred van der Poorten, Marc Prévost, Keith Ball, Tanguy Rivoal, Wadim Zudilin, and others).\nApéry was active in politics and for a few years in the 1960s was president of the Calvados Radical Party of the Left. He abandoned politics after the reforms instituted by Edgar Faure after the 1968 revolt, when he realised that university life was running against the tradition he had always upheld.\n\nPersonal life\nApéry married in 1947 and had three sons, including mathematician François Apéry. His first marriage ended in divorce in 1971. He then remarried in 1972 and divorced in 1977.\nIn 1994, Apéry died from Parkinson's disease after a long illness in Caen. He was buried next to his parents at the Père Lachaise Cemetery in Paris. His tombstone has a mathematical inscription stating his theorem.\n\n  \n    \n      \n        1\n        +\n        \n          \n            1\n            8\n          \n        \n        +\n        \n          \n            1\n            27\n          \n        \n        +\n        \n          \n            1\n            64\n          \n        \n        +\n        ⋯\n        ≠\n        \n          \n            p\n            q\n          \n        \n      \n    \n    {\\displaystyle 1+{\\frac {1}{8}}+{\\frac {1}{27}}+{\\frac {1}{64}}+\\cdots \\neq {\\frac {p}{q}}}\n\nSee also\nApéry's constant\nBasel problem\n\nExternal links\nApéry, François (1996). \"Roger Apéry, 1916-1994: A Radical Mathematician\". The Mathematical Intelligencer. 18 (2): 54–61. doi:10.1007/BF03027295. S2CID 120113351.\nvan der Poorten, Alfred (1979). \"A proof that Euler missed ... Apéry's proof of the irrationality of ζ(3)\". The Mathematical Intelligencer. 1 (4): 195–203. doi:10.1007/BF03028234. S2CID 121589323.",
    "links": [
      "Academic ranks in France",
      "Alfred van der Poorten",
      "Algebraic geometry",
      "Apéry's constant",
      "Apéry's theorem",
      "Basel problem",
      "Caen",
      "Calvados (department)",
      "Doi (identifier)",
      "Edgar Faure",
      "France",
      "French Third Republic",
      "Frits Beukers",
      "Greece",
      "Irrational number",
      "Keith Martin Ball",
      "Lille",
      "Lycée Louis-le-Grand",
      "Mathematician",
      "May 1968 in France",
      "Paris",
      "Parkinson's disease",
      "Paul Dubreil",
      "Positive integer",
      "Prisoner of war",
      "Père Lachaise Cemetery",
      "Radical Party of the Left",
      "Riemann zeta function",
      "Rouen",
      "S2CID (identifier)",
      "Tanguy Rivoal",
      "The Mathematical Intelligencer",
      "University of Caen",
      "University of Rennes",
      "Wadim Zudilin",
      "World War II",
      "École normale supérieure (Paris)",
      "Help:Authority control",
      "Help:IPA/French"
    ],
    "categories": [
      "Category:1916 births",
      "Category:1994 deaths",
      "Category:20th-century French mathematicians",
      "Category:Academic staff of the University of Caen Normandy",
      "Category:Academic staff of the University of Rennes",
      "Category:Articles with hCards",
      "Category:Articles with short description",
      "Category:Burials at Père Lachaise Cemetery",
      "Category:Deaths from Parkinson's disease in France",
      "Category:French military personnel of World War II"
    ]
  },
  "The Mathematical Intelligencer": {
    "title": "The Mathematical Intelligencer",
    "url": "https://en.wikipedia.org/wiki/The_Mathematical_Intelligencer",
    "summary": "The Mathematical Intelligencer is a mathematical journal published by Springer Science+Business Media that aims at a conversational and scholarly tone, rather than the technical and specialist tone more common among academic journals. Volumes are released quarterly with a subset of open access articles. Some articles have been cross-published in the Scientific American. Karen Parshall and Sergei Tabachnikov are  currently the co-editors-in-chief.",
    "content": "The Mathematical Intelligencer is a mathematical journal published by Springer Science+Business Media that aims at a conversational and scholarly tone, rather than the technical and specialist tone more common among academic journals. Volumes are released quarterly with a subset of open access articles. Some articles have been cross-published in the Scientific American. Karen Parshall and Sergei Tabachnikov are  currently the co-editors-in-chief.\n\nHistory\nThe journal was started informally in 1971 by Walter Kaufmann-Buehler and Alice and Klaus Peters. \"Intelligencer\" was chosen by Kaufmann-Buehler as a word that would appear slightly old-fashioned. An exploration of mathematically themed stamps, written by Robin Wilson, became one of its earliest columns. \nPrior to 1977, articles of the Intelligencer were not contained in regular volumes and were sent out sporadically to those on a mailing list. To gauge interest, the inaugural mailing included twelve thousand people of whom four thousand requested further copies via postcard. One of the latter was André Weil, who mocked the mailing's admittedly idiosyncratic typography.\nIn 1978, the founders appointed Bruce Chandler and Harold \"Ed\" Edwards Jr. to serve jointly in the role of editor-in-chief. The volumes started again with 0 (introductory volume in August 1977) and the first issue of volume 1 appeared in March 1978.\nSubsequent editors-in-chief were John Ewing from 1979 to 1986, Sheldon Axler from 1987 to 1991, and Chandler Davis from 1991 to 2004. Beginning in 2004, Davis shared editing responsibilities with long-time contributor Marjorie Senechal. She became the sole editor on Davis's retirement in 2013 and continued to edit the journal through the end of 2020. Parshall and Tabachnikov took over from her in 2021.\nAlmost from the beginning, the journal's editors have shown a “willingness to deal with controversial topics.” For example, Chandler and Edwards excerpted Morris Kline's controversial 1977 book, Why the Professor Can’t Teach, prompting numerous reactions.  Their successor, Ewing, acknowledged that “the purpose of the Intelligencer remains the same: to inform, to entertain, and to provoke.\"  Axler was even more categorical: “Controversies can make for interesting reading, especially in mathematics where we rarely argue about the scientific validity of a result. … [They] keep the publication edgy.”   Indeed, Axler identified at least three controversies that erupted during his editorship.  One was a book review by Steven Krantz in 1989 which expanded to criticize research interest in fractals; \"Fractal geometry has not solved any problems. It is not even clear that it has created any new ones.\" This prompted Benoit Mandelbrot to publish a rebuttal in the same journal. The rebuttal format was initially planned for a paper accepted by Senechal that was authored by Theodore Hill and Sergei Tabachnikov on the variability hypothesis. In the end, however, it was not published. Further controversy arose when a revised version of the paper, by Hill alone, was published by The New York Journal of Mathematics but then retracted without a notice.\n\nContents\nThe Mathematical Intelligencer publishes a variety of contributions on and about mathematics. In addition to articles of a strictly mathematical nature, shorter “notes,” poetry, short fiction, and the occasional interview, the journal currently features regular columns on the history of mathematics (“Years Ago” overseen by Jemma Lorenat), humor (“Mathematically Bent” written by Colin Adams), “Mathematical Gems and Curiosities” (edited by Valentin Ovsienko and Sophie Morier-Genoud), “Mathematical Communities” (edited by Marjorie Senechal), “The Mathematical Tourist” (edited by Ma. Louise Antonette De Las Peñas), and mathematics on stamps (“Stamp Corner” edited by Robin Wilson).  Long-time contributor, Jim Henle also authored a column on “Cucina Matematica” until 2015 as well as, until 2022, one “For Our Mathematical Pleasure.” Under John McCleary, the book review section covers books, both non-fiction and fiction, of interest to the mathematically inclined.\n\nReception\nThe Mathematical Intelligencer has been described as a journal that publishes articles about front-line research rather than research per se. In 2001, Branislav Kisacanin opined that it belongs in \"every good mathematics library\". Apart from the Intelligencer's main articles, a humor column written by mathematician Colin Adams has also been well received.\n\n\n== References ==",
    "links": [
      "A K Peters",
      "Academic publishing",
      "André Weil",
      "Benoit Mandelbrot",
      "Bruce Chandler (mathematician)",
      "Chandler Davis",
      "Colin Adams (mathematician)",
      "Doi (identifier)",
      "Editors-in-chief",
      "Fractal",
      "Harold Edwards (mathematician)",
      "ISBN (identifier)",
      "ISO 4",
      "ISSN (identifier)",
      "Karen Parshall",
      "Marjorie Senechal",
      "MathSciNet",
      "Mathematical Association of America",
      "Mathematical journal",
      "Mathematics",
      "Mathematics on stamps",
      "Morris Kline",
      "Neue Zürcher Zeitung",
      "Open access",
      "Outline of academic disciplines",
      "Robin Wilson (mathematician)",
      "Scientific American",
      "Sergei Tabachnikov",
      "Sheldon Axler",
      "Springer Science+Business Media",
      "Steven Krantz",
      "Ted Hill (mathematician)",
      "The New York Journal of Mathematics",
      "Variability hypothesis",
      "Wikipedia:WikiProject Academic Journals/Bluebook journals"
    ],
    "categories": [
      "Category:Academic journals established in 1971",
      "Category:Articles with short description",
      "Category:English-language journals",
      "Category:Mathematics journals",
      "Category:Quarterly journals",
      "Category:Short description is different from Wikidata",
      "Category:Springer Science+Business Media academic journals"
    ]
  },
  "Transcendental number": {
    "title": "Transcendental number",
    "url": "https://en.wikipedia.org/wiki/Transcendental_number",
    "summary": "In mathematics, a transcendental number is a real or complex number that is not algebraic: that is, not the root of a non-zero polynomial with integer (or, equivalently, rational) coefficients. The best-known transcendental numbers are π and e. The quality of a number being transcendental is called transcendence.\nThough only a few classes of transcendental numbers are known, partly because it can be extremely difficult to show that a given number is transcendental, transcendental numbers are not rare: indeed, almost all real and complex numbers are transcendental, since the algebraic numbers form a countable set, while the set of real numbers ⁠\n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n⁠ and the set of complex numbers ⁠\n  \n    \n      \n        \n          C\n        \n      \n    \n    {\\displaystyle \\mathbb {C} }\n  \n⁠ are both uncountable sets, and therefore larger than any countable set.\nAll transcendental real numbers (also known as real ",
    "content": "In mathematics, a transcendental number is a real or complex number that is not algebraic: that is, not the root of a non-zero polynomial with integer (or, equivalently, rational) coefficients. The best-known transcendental numbers are π and e. The quality of a number being transcendental is called transcendence.\nThough only a few classes of transcendental numbers are known, partly because it can be extremely difficult to show that a given number is transcendental, transcendental numbers are not rare: indeed, almost all real and complex numbers are transcendental, since the algebraic numbers form a countable set, while the set of real numbers ⁠\n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n⁠ and the set of complex numbers ⁠\n  \n    \n      \n        \n          C\n        \n      \n    \n    {\\displaystyle \\mathbb {C} }\n  \n⁠ are both uncountable sets, and therefore larger than any countable set.\nAll transcendental real numbers (also known as real transcendental numbers or transcendental irrational numbers) are irrational numbers, since all rational numbers are algebraic. The converse is not true: Not all irrational numbers are transcendental. Hence, the set of real numbers consists of non-overlapping sets of rational, algebraic irrational, and transcendental real numbers. For example, the square root of 2 is an irrational number, but it is not a transcendental number as it is a root of the polynomial equation x2 − 2 = 0. The golden ratio (denoted \n  \n    \n      \n        φ\n      \n    \n    {\\displaystyle \\varphi }\n  \n or \n  \n    \n      \n        ϕ\n      \n    \n    {\\displaystyle \\phi }\n  \n) is another irrational number that is not transcendental, as it is a root of the polynomial equation x2 − x − 1 = 0.\n\nHistory\nThe name \"transcendental\" comes from Latin  trānscendere 'to climb over or beyond, surmount', and was first used for the mathematical concept in Leibniz's 1682 paper in which he proved that sin x is not an algebraic function of x. Euler, in the eighteenth century, was probably the first person to define transcendental numbers in the modern sense.\nJohann Heinrich Lambert conjectured that e and π were both transcendental numbers in his 1768 paper proving the number π is irrational, and proposed a tentative sketch proof that π is transcendental.\nJoseph Liouville first proved the existence of transcendental numbers in 1844, and in 1851 gave the first decimal examples such as the Liouville constant \n\n  \n    \n      \n        \n          \n            \n              \n                \n                  L\n                  \n                    b\n                  \n                \n              \n              \n                \n                =\n                \n                  ∑\n                  \n                    n\n                    =\n                    1\n                  \n                  \n                    ∞\n                  \n                \n                \n                  10\n                  \n                    −\n                    n\n                    !\n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                \n                  10\n                  \n                    −\n                    1\n                  \n                \n                +\n                \n                  10\n                  \n                    −\n                    2\n                  \n                \n                +\n                \n                  10\n                  \n                    −\n                    6\n                  \n                \n                +\n                \n                  10\n                  \n                    −\n                    24\n                  \n                \n                +\n                \n                  10\n                  \n                    −\n                    120\n                  \n                \n                +\n                \n                  10\n                  \n                    −\n                    720\n                  \n                \n                +\n                \n                  10\n                  \n                    −\n                    5040\n                  \n                \n                +\n                \n                  10\n                  \n                    −\n                    40320\n                  \n                \n                +\n                …\n              \n            \n            \n              \n              \n                \n                =\n                0.\n                \n                  \n                    1\n                  \n                \n                \n                  \n                    1\n                  \n                \n                000\n                \n                  \n                    1\n                  \n                \n                00000000000000000\n                \n                  \n                    1\n   ",
    "links": [
      "0",
      "1",
      "Acta Mathematica",
      "Additive number theory",
      "Alan Baker (mathematician)",
      "Alexander Gelfond",
      "Algebra of physical space",
      "Algebraic function",
      "Algebraic independence",
      "Algebraic number",
      "Algebraic number theory",
      "Algebraically closed field",
      "Algebraically independent",
      "Almost all",
      "Amer. Math. Monthly",
      "American Mathematical Society",
      "Anabelian geometry",
      "Analytic number theory",
      "Andrew Odlyzko",
      "Apéry's constant",
      "ArXiv (identifier)",
      "Arakelov theory",
      "Arithmetic",
      "Arithmetic combinatorics",
      "Arithmetic dynamics",
      "Arithmetic function",
      "Arithmetic geometry",
      "Arithmetic topology",
      "Baker's theorem",
      "Bessel function",
      "Beta function",
      "Bibcode (identifier)",
      "Bicomplex number",
      "Bioctonion",
      "Biquaternion",
      "Cahen's constant",
      "Cambridge University Press",
      "Cantor's diagonal argument",
      "Cantor's first set theory article",
      "Cardinal number",
      "Catalan's constant",
      "Chaitin's constant",
      "Champernowne constant",
      "Charles Hermite",
      "Chinese remainder theorem",
      "Chudnovsky brothers",
      "CiteSeerX (identifier)",
      "Class field theory",
      "Clifford algebra",
      "Closed-form expression"
    ],
    "categories": [
      "Category:Articles containing proofs",
      "Category:Articles with short description",
      "Category:CS1: long volume value",
      "Category:CS1 German-language sources (de)",
      "Category:CS1 Russian-language sources (ru)",
      "Category:CS1 interwiki-linked names",
      "Category:Short description is different from Wikidata",
      "Category:Transcendental numbers",
      "Category:Wikisource templates with missing id"
    ]
  },
  "Conference Board of the Mathematical Sciences": {
    "title": "Conference Board of the Mathematical Sciences",
    "url": "https://en.wikipedia.org/wiki/Conference_Board_of_the_Mathematical_Sciences",
    "summary": "The Conference Board of the Mathematical Sciences (CBMS) is an umbrella organization of seventeen professional societies in the mathematical sciences in the United States. \nIt and its member societies are recognized by the International Mathematical Union as the national mathematical societies for their country.\nThe CBMS was founded in 1960 as the successor organization to the six-organization Policy Committee for Mathematics (founded by the American Mathematical Society and the Mathematical Association of America as the War Policy Committee in 1942) and the 1958 Conference Organization of the Mathematical Sciences. As well as representing US mathematics at the IMU, it acts as a communication channel between its member societies and the US Government, and coordinates joint projects of its member societies.",
    "content": "The Conference Board of the Mathematical Sciences (CBMS) is an umbrella organization of seventeen professional societies in the mathematical sciences in the United States. \nIt and its member societies are recognized by the International Mathematical Union as the national mathematical societies for their country.\nThe CBMS was founded in 1960 as the successor organization to the six-organization Policy Committee for Mathematics (founded by the American Mathematical Society and the Mathematical Association of America as the War Policy Committee in 1942) and the 1958 Conference Organization of the Mathematical Sciences. As well as representing US mathematics at the IMU, it acts as a communication channel between its member societies and the US Government, and coordinates joint projects of its member societies.\n\nMember societies\nAMATYC   American Mathematical Association of Two-Year Colleges\nAMS      American Mathematical Society\nAMTE     Association of Mathematics Teacher Educators\nASA      American Statistical Association\nASL      Association for Symbolic Logic\nAWM      Association for Women in Mathematics\nASSM     Association of State Supervisors of Mathematics\nBBA      Benjamin Banneker Association\nINFORMS  Institute for Operations Research and the Management Sciences\nIMS      Institute of Mathematical Statistics\nMAA      Mathematical Association of America\nNAM      National Association of Mathematicians\nNCSM     National Council of Supervisors of Mathematics\nNCTM     National Council of Teachers of Mathematics\nSIAM     Society for Industrial and Applied Mathematics\nSOA      Society of Actuaries\nTODOS    TODOS: Mathematics for All\nWME      Women and Mathematics Education\n\nReferences\nExternal links\nConference Board of the Mathematical Sciences",
    "links": [
      "American Mathematical Association of Two-Year Colleges",
      "American Mathematical Society",
      "American Statistical Association",
      "Association for Symbolic Logic",
      "Association for Women in Mathematics",
      "Association of Mathematics Teacher Educators",
      "Association of State Supervisors of Mathematics",
      "Benjamin Banneker Association",
      "Doi (identifier)",
      "Institute for Operations Research and the Management Sciences",
      "Institute of Mathematical Statistics",
      "International Mathematical Union",
      "MR (identifier)",
      "Mathematical Association of America",
      "Mathematics",
      "National Association of Mathematicians",
      "National Council of Supervisors of Mathematics",
      "National Council of Teachers of Mathematics",
      "Society for Industrial and Applied Mathematics",
      "Society of Actuaries",
      "TODOS: Mathematics for All",
      "Umbrella organization",
      "United States",
      "Wayback Machine",
      "Women and Mathematics Education",
      "Wikipedia:Stub",
      "Template:Math-org-stub",
      "Template talk:Math-org-stub",
      "Help:Authority control"
    ],
    "categories": [
      "Category:All stub articles",
      "Category:Mathematical societies",
      "Category:Mathematics organization stubs",
      "Category:Webarchive template wayback links"
    ]
  },
  "American Journal of Mathematics": {
    "title": "American Journal of Mathematics",
    "url": "https://en.wikipedia.org/wiki/American_Journal_of_Mathematics",
    "summary": "The American Journal of Mathematics is a bimonthly mathematics journal published by the Johns Hopkins University Press.",
    "content": "The American Journal of Mathematics is a bimonthly mathematics journal published by the Johns Hopkins University Press.\n\nHistory\nThe American Journal of Mathematics is the oldest continuously published mathematical journal in the United States, established in 1878 at the Johns Hopkins University by James Joseph Sylvester, an English-born mathematician who also served as the journal's editor-in-chief from its inception through early 1884. Initially W. E. Story was associate editor in charge; he was replaced by Thomas Craig in 1880. For volume 7 Simon Newcomb became chief editor with Craig managing until 1894. Then with volume 16 it was \"Edited by Thomas Craig with the Co-operation of Simon Newcomb\" until 1898.\nOther notable mathematicians who have served as editors or editorial associates of the journal include Frank Morley, Oscar Zariski, Lars Ahlfors, Hermann Weyl, Wei-Liang Chow, S. S. Chern, André Weil, Harish-Chandra, Jean Dieudonné, Henri Cartan, Stephen Smale, Jun-Ichi Igusa, and Joseph A. Shalika.\nFields medalist Cédric Villani has speculated that \"the most famous article in its long history\" may be a 1958 paper by John Nash, \"Continuity of solutions of parabolic and elliptic equations\".\n\nScope and impact factor\nThe American Journal of Mathematics is a general-interest (i.e., non-specialized) mathematics journal covering all the major areas of contemporary mathematics.  According to the Journal Citation Reports, its 2009 impact factor is 1.337, ranking it 22nd out of 255 journals in the category \"Mathematics\".\n\nEditors\nAs of June, 2012, the editors are  Christopher D. Sogge, editor-in-chief (Johns Hopkins University), William Minicozzi II (Massachusetts Institute of Technology), Freydoon Shahidi (Purdue University), and Vyacheslav Shokurov (The Johns Hopkins University).\n\nReferences\nExternal links\nOfficial website",
    "links": [
      "Academic publishing",
      "Albert Shaw Lectures on Diplomatic History",
      "André Weil",
      "Applied Physics Laboratory",
      "Bimonthly",
      "CODEN (identifier)",
      "Center for Talented Youth",
      "Christopher D. Sogge",
      "Cédric Villani",
      "Deborah Kent",
      "Doi (identifier)",
      "Editor-in-chief",
      "Evergreen House",
      "Foreign Affairs Symposium",
      "Frank Morley",
      "Freydoon Shahidi",
      "Harish-Chandra",
      "Henri Cartan",
      "Hermann Weyl",
      "Homewood Campus of Johns Hopkins University",
      "Homewood Field",
      "Homewood Museum",
      "ISBN (identifier)",
      "ISO 4",
      "ISSN (identifier)",
      "Impact factor",
      "JSTOR (identifier)",
      "James Joseph Sylvester",
      "Jean Dieudonné",
      "John Forbes Nash, Jr.",
      "Johns Hopkins",
      "Johns Hopkins Bloomberg School of Public Health",
      "Johns Hopkins Blue Jays",
      "Johns Hopkins Blue Jays football",
      "Johns Hopkins Blue Jays men's lacrosse",
      "Johns Hopkins Blue Jays women's lacrosse",
      "Johns Hopkins Carey Business School",
      "Johns Hopkins Children's Center",
      "Johns Hopkins Club",
      "Johns Hopkins Film Festival",
      "Johns Hopkins Hospital",
      "Johns Hopkins School of Education",
      "Johns Hopkins School of Medicine",
      "Johns Hopkins School of Nursing",
      "Johns Hopkins University",
      "Johns Hopkins University Press",
      "Johns Hopkins Writing Seminars",
      "Johns Hopkins–Loyola lacrosse rivalry",
      "Johns Hopkins–Maryland lacrosse rivalry",
      "Johns Hopkins–McDaniel football rivalry"
    ],
    "categories": [
      "Category:Academic journals established in 1878",
      "Category:Articles with outdated impact factors from 2009",
      "Category:Articles with short description",
      "Category:Bimonthly journals",
      "Category:Bimonthly journals (infobox)",
      "Category:English-language journals",
      "Category:Johns Hopkins University Press academic journals",
      "Category:Mathematics journals",
      "Category:Official website different in Wikidata and Wikipedia",
      "Category:Short description is different from Wikidata"
    ]
  },
  "American Mathematical Association of Two-Year Colleges": {
    "title": "American Mathematical Association of Two-Year Colleges",
    "url": "https://en.wikipedia.org/wiki/American_Mathematical_Association_of_Two-Year_Colleges",
    "summary": "The American Mathematical Association of Two-Year Colleges (AMATYC) is an organization dedicated to the improvement of education in the first two years of college mathematics in the United States and Canada. AMATYC hosts an annual conference, summer institutes, workshops and mentoring for teachers in and outside math, and a semiannual math competition. AMATYC publishes one refereed journal, MathAMATYC Educator, and issues position statements on matters of mathematics education.\nThe math competition is held in spring and fall semester each year and is limited to problems in precalculus. Only students enrolled in two-year colleges are eligible to participate. Only students who haven't received any degree/diploma, including within or outside of the U.S, can enter the competition.\nAMATYC was founded in 1974. Its office is at Southwest Tennessee Community College in Memphis, Tennessee.\nAMATYC is divided into eight regions: Central, Mid-Atlantic, Midwest, Northeast, Northwest, Southeast, Sou",
    "content": "The American Mathematical Association of Two-Year Colleges (AMATYC) is an organization dedicated to the improvement of education in the first two years of college mathematics in the United States and Canada. AMATYC hosts an annual conference, summer institutes, workshops and mentoring for teachers in and outside math, and a semiannual math competition. AMATYC publishes one refereed journal, MathAMATYC Educator, and issues position statements on matters of mathematics education.\nThe math competition is held in spring and fall semester each year and is limited to problems in precalculus. Only students enrolled in two-year colleges are eligible to participate. Only students who haven't received any degree/diploma, including within or outside of the U.S, can enter the competition.\nAMATYC was founded in 1974. Its office is at Southwest Tennessee Community College in Memphis, Tennessee.\nAMATYC is divided into eight regions: Central, Mid-Atlantic, Midwest, Northeast, Northwest, Southeast, Southwest, and West. A vice president is assigned to each region.\n\nSee also\nMathematical Association of America\nNational Council of Teachers of Mathematics\n\nExternal links\nOfficial website",
    "links": [
      "American Institute of Mathematics",
      "American Invitational Mathematics Examination",
      "American Mathematical Society",
      "American Mathematics Competitions",
      "Association for Women in Mathematics",
      "Canada",
      "Community college",
      "Geometry Center",
      "Institute for Advanced Study",
      "Institute for Computational and Experimental Research in Mathematics",
      "Institute for Mathematics and its Applications",
      "Institute for Pure and Applied Mathematics",
      "Integration Bee",
      "Math competition",
      "Mathcounts",
      "Mathematical Association of America",
      "Mathematical Biosciences Institute",
      "Mathematical Olympiad Summer Program",
      "Mathematics",
      "Memphis, Tennessee",
      "National Council of Teachers of Mathematics",
      "Precalculus",
      "Semester",
      "Simons Laufer Mathematical Sciences Institute",
      "Society for Industrial and Applied Mathematics",
      "Southwest Tennessee Community College",
      "Statistical and Applied Mathematical Sciences Institute",
      "United States",
      "United States of America Mathematical Olympiad",
      "William Lowell Putnam Mathematical Competition",
      "Wikipedia:No original research",
      "Wikipedia:Stub",
      "Wikipedia:Verifiability",
      "Template:American mathematics",
      "Template:Math-org-stub",
      "Template talk:American mathematics",
      "Template talk:Math-org-stub",
      "Help:Authority control",
      "Help:Maintenance template removal"
    ],
    "categories": [
      "Category:1974 establishments in Tennessee",
      "Category:All articles lacking reliable references",
      "Category:All stub articles",
      "Category:Articles lacking reliable references from May 2012",
      "Category:Educational organizations established in 1974",
      "Category:Mathematics education organizations in the United States",
      "Category:Mathematics organization stubs",
      "Category:Organizations based in Memphis, Tennessee"
    ]
  },
  "Bulletin of the American Mathematical Society": {
    "title": "Bulletin of the American Mathematical Society",
    "url": "https://en.wikipedia.org/wiki/Bulletin_of_the_American_Mathematical_Society",
    "summary": "The Bulletin of the American Mathematical Society is a quarterly mathematical journal published by the American Mathematical Society.",
    "content": "The Bulletin of the American Mathematical Society is a quarterly mathematical journal published by the American Mathematical Society.\n\nScope\nIt publishes surveys on contemporary research topics, written at a level accessible to non-experts. It also publishes, by invitation only, book reviews and short Mathematical Perspectives articles.\n\nHistory\nIt began as the Bulletin of the New York Mathematical Society and underwent a name change when the society became national.  The Bulletin's function has changed over the years; its original function was to serve as a research journal for its members.\n\nIndexing\nThe Bulletin is indexed in Mathematical Reviews, Science Citation Index, ISI Alerting Services, CompuMath Citation Index, and Current Contents/Physical, Chemical & Earth Sciences.\n\nSee also\nJournal of the American Mathematical Society\nMemoirs of the American Mathematical Society\nNotices of the American Mathematical Society\nProceedings of the American Mathematical Society\nTransactions of the American Mathematical Society\n\nReferences\nExternal links\nJournal web site",
    "links": [
      "Academic publishing",
      "American Mathematical Society",
      "CODEN (identifier)",
      "Current Contents",
      "Editor-in-chief",
      "ISO 4",
      "ISSN (identifier)",
      "Impact factor",
      "Institute for Scientific Information",
      "Journal of the American Mathematical Society",
      "MathSciNet",
      "Mathematical Reviews",
      "Mathematical journal",
      "Mathematics",
      "Memoirs of the American Mathematical Society",
      "Notices of the American Mathematical Society",
      "Outline of academic disciplines",
      "Periodical literature",
      "Proceedings of the American Mathematical Society",
      "Science Citation Index",
      "Susan Friedlander",
      "Transactions of the American Mathematical Society",
      "United States",
      "Wikipedia:Citing sources",
      "Wikipedia:Independent sources",
      "Wikipedia:Neutral point of view",
      "Wikipedia:Verifiability",
      "Wikipedia:WikiProject Academic Journals/Bluebook journals",
      "Help:Authority control",
      "Help:Maintenance template removal"
    ],
    "categories": [
      "Category:All articles lacking reliable references",
      "Category:American Mathematical Society academic journals",
      "Category:Articles lacking reliable references from June 2022",
      "Category:Articles with outdated impact factors from 2018",
      "Category:Articles with short description",
      "Category:English-language journals",
      "Category:Mathematics journals",
      "Category:Quarterly journals",
      "Category:Quarterly journals (infobox)",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Canadian Mathematical Society": {
    "title": "Canadian Mathematical Society",
    "url": "https://en.wikipedia.org/wiki/Canadian_Mathematical_Society",
    "summary": "The Canadian Mathematical Society (CMS; French: Société mathématique du Canada) is an association of professional mathematicians dedicated to advancing mathematical research, outreach, scholarship and education in Canada. The Society serves the national and international communities through the publication of high-quality academic journals and community bulletins, as well as by organizing a variety of mathematical competitions and enrichment programs. These include the Canadian Open Mathematics Challenge (COMC), the Canadian Mathematical Olympiad (CMO), and the selection and training of Canada's team for the International Mathematical Olympiad (IMO) and the European Girls’ Mathematical Olympiad (EGMO).\nThe CMS was originally conceived in June 1945 as the Canadian Mathematical Congress. A name change was debated for many years; ultimately, a new name was adopted in 1979, upon the Society’s incorporation as a non-profit charitable organization.\nThe Society is affiliated with various nati",
    "content": "The Canadian Mathematical Society (CMS; French: Société mathématique du Canada) is an association of professional mathematicians dedicated to advancing mathematical research, outreach, scholarship and education in Canada. The Society serves the national and international communities through the publication of high-quality academic journals and community bulletins, as well as by organizing a variety of mathematical competitions and enrichment programs. These include the Canadian Open Mathematics Challenge (COMC), the Canadian Mathematical Olympiad (CMO), and the selection and training of Canada's team for the International Mathematical Olympiad (IMO) and the European Girls’ Mathematical Olympiad (EGMO).\nThe CMS was originally conceived in June 1945 as the Canadian Mathematical Congress. A name change was debated for many years; ultimately, a new name was adopted in 1979, upon the Society’s incorporation as a non-profit charitable organization.\nThe Society is affiliated with various national and international mathematical societies, including the Canadian Applied and Industrial Mathematics Society and the Society for Industrial and Applied Mathematics. The CMS is also a member of the International Mathematical Union and the International Council for Industrial and Applied Mathematics.\n\nHistory\nThe Canadian Mathematical Society was originally conceived in June 1945 as the Canadian Mathematical Congress. The founding members hoped that \"this congress [would] be the beginning of important mathematical development in Canada\". Seeking to end confusion with the quadrennial mathematical congresses, a name change was considered for many years. Finally, upon its incorporation as a non-profit, charitable organization in 1978, a new name was adopted – the Canadian Mathematical Society. Since then, the Society has expanded its activities to serve K-12 and post secondary students, as well as professors and established researchers. \nGraham P. Wright served as Executive Director of the CMS from 1979 to 2009. He was a key contributor to virtually all aspects of the Society’s operations, including his service as Managing Editor of many of the CMS’s scientific publications, his work as an organizer of Math Camps and Mathematics Competitions (notably his work for the 1995 International Mathematical Olympiad held in Toronto), and his tireless efforts in support of the Society’s committees and scientific meetings. In addition, he helped build the Society’s Executive Office in Ottawa and develop its web-based electronic services.\nThe Canadian Mathematical Society was to celebrate its 75th anniversary during its 2020 Summer Meeting in Ottawa, Ontario. However, due to the COVID-19 pandemic, the meeting was postponed to 2021 Summer Meeting. The Society is set to celebrate its 80th anniversary during its 2025 Summer Meeting in Québec, QC.\n\nActivities\nPublications\nSource:\nThe flagship publications of the CMS are the prominent, peer-reviewed research journals Canadian Journal of Mathematics, which is intended for full research papers, and the Canadian Mathematical Bulletin, which publishes shorter papers.  All past issues except the last five volumes are free to download. Access to the most recent research requires a subscription.\nIn cooperation with Springer Publications, the CMS publishes many text books aimed at a university and academic researcher level. The series is called CMS Books in Mathematics.\nThe CMS publishes ten issues per year of Crux Mathematicorum, which contains problem-solving challenges and techniques suitable for training in secondary school problem solving competitions such as the Canadian Mathematical Olympiad or the International Mathematical Olympiad. All issues are free to download and use. In the past, the CMS also published A Taste of Mathematics (ATOM), a series of small booklets on a variety of topics suitable for high school enrichment. This series is still available to download and use on the Society’s website.\nThe CMS Notes is the Society's official newsletter, published six times per year and available to members or the public online. It includes news relevant to the Canadian mathematical community, including notice on conferences, columns on research and education, book reviews, award announcements, and employment advertisements for mathematicians.\nIn April 2024, the CMS launched Math Matters, a weekly newsletters sent to members and subscribers of the Society’s mailing list. This newsletter was created to streamline communication by consolidating most updates into one comprehensive weekly edition. Math Matters, distributed on Fridays, serves as a platform to keep the mathematical community updated on announcements, calls, submissions, events, job advertisements, and more.\nAs of 2025, the CMS is preparing for the launch of its new journal, Canadian Mathematical Communications (CMC), an open-access venue for high-impact papers in all areas of pure and applied mathematics. Deep theories and foundational ",
    "links": [
      "Academic journal",
      "Adrien Pouliot",
      "Adrien Pouliot Award",
      "Albert John Coleman",
      "American Mathematical Society",
      "Applied mathematics",
      "Ars Combinatoria (journal)",
      "Asian Pacific Mathematics Olympiad",
      "Atlantic Association for Research in the Mathematical Sciences",
      "Australian Mathematical Society",
      "Banff International Research Station",
      "Brain teaser",
      "COVID-19 pandemic",
      "CRM-Fields-PIMS prize",
      "Canada",
      "Canadian Journal of Mathematics",
      "Canadian Mathematical Bulletin",
      "Canadian Mathematical Olympiad",
      "Canadian Open Mathematics Challenge",
      "Carl S. Herz",
      "Central Canada",
      "Centre de Recherches Mathématiques",
      "Centre de recherches mathématiques",
      "Centre for Education in Mathematics and Computing",
      "Charitable organization (Canada)",
      "Christiane Rousseau",
      "Connecting Women in Mathematics Across Canada",
      "Coxeter–James Prize",
      "Crux Mathematicorum",
      "Curriculum",
      "David Borwein",
      "Department of Mathematics and Statistics, McGill University",
      "Diversity, equity, and inclusion",
      "Eastern Canada",
      "Eddy Campbell",
      "English language",
      "European Girls' Mathematical Olympiad",
      "Fields Institute",
      "Frederick Valentine Atkinson",
      "French language",
      "Gender equality",
      "George F. D. Duff",
      "Gilbert de Beauregard Robinson",
      "Girl",
      "Grade 12",
      "Harold Scott MacDonald Coxeter",
      "Indigenous peoples in Canada",
      "International Council for Industrial and Applied Mathematics",
      "International Mathematical Olympiad",
      "International Mathematical Union"
    ],
    "categories": [
      "Category:1945 establishments in Canada",
      "Category:Articles with short description",
      "Category:Canadian Mathematical Society",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Charlotte Scott": {
    "title": "Charlotte Scott",
    "url": "https://en.wikipedia.org/wiki/Charlotte_Scott",
    "summary": "Charlotte Angas Scott (8 June 1858 – 10 November 1931) was a British mathematician who made her career in the United States; she was influential in the development of American mathematics, including the mathematical education of women.  Scott played an important role in Cambridge changing the rules for its famous Mathematical Tripos exam.",
    "content": "Charlotte Angas Scott (8 June 1858 – 10 November 1931) was a British mathematician who made her career in the United States; she was influential in the development of American mathematics, including the mathematical education of women.  Scott played an important role in Cambridge changing the rules for its famous Mathematical Tripos exam.\n\nEarly life\nShe was the second of seven children to Caleb Scott, a minister of the Congregational Church, and Eliza Exley Scott. Educated at Girton College, Cambridge from 1876 to 1880 on a scholarship, she was then a Resident Lecturer in Mathematics there until 1884. In 1885 she became one of the first British women to receive a doctorate, and the first British woman to receive a doctorate in mathematics, which she received from the University of London. She did her graduate research under Arthur Cayley at Cambridge University, but since Cambridge did not begin issuing degrees to women until 1948, Scott received her BSc (1882) and D.Sc. (1885) from the University of London through external examinations.\n\nPassing the Tripos\nIn 1880, Scott obtained special permission to take the Cambridge Mathematical Tripos Exam, as women were not normally allowed to sit for the exam. She came eighth on the Tripos of all students taking them, but due to her sex, the title of \"eighth wrangler,\" a high honour, went officially to a male student.\nAt the ceremony, however, after the seventh wrangler had been announced, all the students in the audience shouted her name.\n\nThe man read out the names and when he came to 'eighth,' before he could say the name, all the undergraduates called out 'Scott of Girton,' and cheered tremendously, shouting her name over and over again with tremendous cheers and waving of hats.\nBecause she could not attend the award ceremony, Scott celebrated her accomplishment at Girton College where there were cheers and clapping at dinner, a special evening ceremony where the students sang \"See the Conquering Hero Comes\", received an ode written by a staff member, and was crowned with laurels.\nAfter this incident women were allowed to formally take the exam and their exam scores listed, although separately from the men's and thus not included in the rankings. Women obtaining the necessary score also received a special certificate instead of the BA degree with honours.  In 1922, James Harkness remarked that Scott's achievement marked \"the turning point in England from the theoretical feminism of Mill and others to the practical education and political advances of the present time\".\n\nWork\nMoving to the United States in 1885, she became one of eight founding faculty and Associate Professor of Mathematics at Bryn Mawr College, and Professor from 1888 to 1917. She was the first mathematician at Bryn Mawr College and the first department head. During this period she directed the PhD theses of some pioneering women mathematicians. Of the nine other women to earn doctorates in mathematics in the nineteenth century, three studied with Scott.\nHer mathematical speciality was the study of specific algebraic curves of degree higher than two.  Her book An Introductory Account of Certain Modern Ideas and Methods in Plane Analytical Geometry was published in 1894 and reprinted thirty years later. Scott was one of the first English language textbook writers to be \"perfectly aware\" of the \"distinction between a general principle and a particular example\".  She played an important role in the transition to twentieth century custom of abstract mathematical proofs.\nIn 1891, she became the first woman to join the New York Mathematical Society, later called the American Mathematical Society. She served as the first woman on the first Council of the American Mathematical Society in 1894, and received an acclaimed review from the Society in 1896. She is also credited with being the author of the first mathematical research paper written in the US that was widely recognised in Europe, \"A Proof of Noether's Fundamental Theorem\" (Mathematische Annalen, Vol. 52 (1899)). She was one of only four women to attend the inaugural International Congress of Mathematicians in Zurich in 1897; the other three were Iginia Massarini, Vera von Schiff, and Charlotte Wedell.\nIn 1906 Scott served as vice-president of the American Mathematical Society.\n\nWomen in mathematics\nScott maintained the view that personal conservatism was a requirement to promote women's educational and political equality.  She disapproved of smoking and makeup, however she did bob her hair before moving to Bryn Mawr (short hair being controversial even in the 1920s).  This view was also held by the early Girton College community, because unaccompanied women in Cambridge could be thrown into Spinning House, a special prison for prostitutes and suspected prostitutes.\nShe was a staunch supporter of rigour in women's classes, writing in a letter to Bryn Mawr President M. Carey Thomas:\n\nI am most disturbed and disappointed at present to find you tak",
    "links": [
      "Ada Maddison",
      "Agnes Scott College",
      "Algebraic curve",
      "American Mathematical Society",
      "American Men and Women of Science",
      "Arthur Cayley",
      "Ascension Parish Burial Ground, Cambridge",
      "Bachelor of Arts",
      "Bob cut",
      "Bryn Mawr College",
      "Cambridge",
      "Cambridge Mathematical Tripos",
      "Cambridge University",
      "Cambridgeshire",
      "Charlotte Harland Scott",
      "Charlotte Montagu Douglas Scott, Duchess of Buccleuch",
      "Charlotte Wedell",
      "Chrysanthemum",
      "Congregational church",
      "Dictionary of National Biography",
      "Dissertation",
      "Doctoral advisor",
      "Doi (identifier)",
      "Emilie Martin",
      "Find a Grave",
      "Girton College, Cambridge",
      "Grace Andrews (mathematician)",
      "ISBN (identifier)",
      "International Congress of Mathematicians",
      "James Harkness (mathematician)",
      "John Stuart Mill",
      "Judy Green (mathematician)",
      "Lincoln, England",
      "Lincolnshire",
      "Louise Duffield Cummings",
      "M. Carey Thomas",
      "Mary Gertrude Haseman",
      "Mathematical proof",
      "Mathematician",
      "Mathematics Genealogy Project",
      "Mathematische Annalen",
      "Max Noether",
      "North West Cambridge Development",
      "Patricia Clark Kenschaft",
      "Rheumatoid arthritis",
      "S2CID (identifier)",
      "Spinning House",
      "University of Cambridge",
      "University of London",
      "Virginia Ragsdale"
    ],
    "categories": [
      "Category:1858 births",
      "Category:1931 deaths",
      "Category:Academics of the University of Cambridge",
      "Category:Alumni of Girton College, Cambridge",
      "Category:Alumni of University of London Worldwide",
      "Category:Alumni of the University of London",
      "Category:Articles with hCards",
      "Category:Articles with short description",
      "Category:British women mathematicians",
      "Category:Bryn Mawr College faculty"
    ]
  },
  "European Mathematical Society": {
    "title": "European Mathematical Society",
    "url": "https://en.wikipedia.org/wiki/European_Mathematical_Society",
    "summary": "The European Mathematical Society (EMS) is a European organization dedicated to the development of mathematics in Europe. Its members are different mathematical societies in Europe, academic institutions and individual mathematicians. The current president is Jan Philip Solovej, professor at the Department of Mathematics at the University of Copenhagen.",
    "content": "The European Mathematical Society (EMS) is a European organization dedicated to the development of mathematics in Europe. Its members are different mathematical societies in Europe, academic institutions and individual mathematicians. The current president is Jan Philip Solovej, professor at the Department of Mathematics at the University of Copenhagen.\n\nGoals\nThe Society seeks to serve all kinds of mathematicians in universities, research institutes and other forms of higher education.  Its aims are to\n\nPromote mathematical research, both pure and applied,\nAssist and advise on problems of mathematical education,\nConcern itself with the broader relations of mathematics to society,\nFoster interaction between mathematicians of different countries,\nEstablish a sense of identity amongst European mathematicians,\nRepresent the mathematical community in supra-national institutions.\nThe EMS is itself an Affiliate Member of the International Mathematical Union and an Associate Member of the International Council for Industrial and Applied Mathematics.\n\nHistory\nThe precursor to the EMS, the European Mathematical Council was founded in 1978 at the International Congress of Mathematicians in Helsinki. This informal federation of mathematical societies was chaired by Sir Michael Atiyah. The European Mathematical Society was founded on 28 October 1990 in Mądralin near Warsaw, Poland, with Friedrich Hirzebruch as founding President. Initially, the EMS had 27 member societies. The first European Congress of Mathematics (ECM) was held at the Sorbonne and Panthéon-Sorbonne universities in Paris in 1992, and is now held every 4 years at different locations around Europe, organised by the EMS.  ECM 2020 was postponed for a year due to the covid pandemic took place in 2021 in Portorož in Slovenia. The next ECM (2028) will be held in Bologna.\n\nPresidents of the EMS\nSource:\n\nFriedrich Hirzebruch, 1990–1994\nJean-Pierre Bourguignon, 1995–1998\nRolf Jeltsch, 1999–2002\nJohn Kingman, 2003–2006\nAri Laptev, 2007–2010\nMarta Sanz-Solé, 2011–2014\nPavel Exner, 2015–2018\nVolker Mehrmann, 2019–2022\nJan Philip Solovej, 2023–present\n\nStructure and Governance\nThe governing body of the EMS is its Council, which comprises delegates representing all of the societies which are themselves members of the EMS, along with delegates representing the institutional and individual EMS members. The Council meets every 2 years, and appoints the President and Executive Committee who are responsible for the running of the society.\nBesides the Executive Committee, the EMS has standing committees on: Applications and Interdisciplinary Relations, Developing Countries, Mathematical Education, ERCOM (Directors of European Research Centres in the Mathematical Sciences), Ethics, European Solidarity, Meetings, Publications and Electronic Dissemination, Raising Public Awareness of Mathematics, Women in Mathematics.\nThe EMS's rules are set down in its Statutes and Bylaws. The EMS is headquartered at the University of Helsinki.\n\nPrizes\nThe European Congress of Mathematics (ECM) is held every four years under the Society's auspices, at which ten EMS Prizes are awarded to \"recognize excellent contributions in Mathematics by young researchers not older than 35 years\".\nSince 2000, the Felix Klein Prize (endowed by the Institute for Industrial Mathematics in Kaiserslautern) has been awarded to \"a young scientist or a small group of young scientists (normally under the age of 38) for using sophisticated methods to give an outstanding solution, which meets with the complete satisfaction of industry, to a concrete and difficult industrial problem.\"\nSince 2012, the Otto Neugebauer Prize (endowed by Springer Verlag) has been awarded to a researcher or group of researchers '\"for highly original and influential work in the field of history of mathematics that enhances our understanding of either the development of mathematics or a particular mathematical subject in any period and in any geographical region\".\nSince 2024, the Simon Norton Prize for Mathematics Outreach has been awarded to individuals, teams or partnerships whose work in any area of mathematics engagement has had an outstanding and demonstrable impact or influence on its audience.\nThe following are the awardees so far, (a F symbol denotes mathematicians who later earned a Fields Medal).\n\n1992 prizes\nEMS Prizes: Richard Borcherds (UK)F – Jens Franke (Germany) – Alexander Goncharov (Russia) – Maxim Kontsevich (Russia)F – François Labourie (France) – Tomasz Łuczak (Poland) – Stefan Müller (Germany) – Vladimír Šverák (Czechoslovakia) – Gábor Tardos (Hungary) – Claire Voisin (France)\n\n1996 prizes\nEMS Prizes: Alexis Bonnet (France) – Timothy Gowers (UK)F – Annette Huber-Klawitter (Germany) – Aise Johan de Jong (Netherlands) – Dmitry Kramkov (Russia) – Jiří Matoušek (Czech Republic) – Loïc Merel (France) – Grigori Perelman (Russia)F, declined – Ricardo Pérez-Marco (Spain/France) – Leonid Polterovich (Russia/Israel)\n\n2000 prizes",
    "links": [
      "Academic journal",
      "Adam Kanigowski",
      "Adrian Ioana",
      "Agata Smoktunowicz",
      "Aise Johan de Jong",
      "Aleksandr Logunov (mathematician)",
      "Alessio Figalli",
      "Alexander Efimov",
      "Alexander Goncharov",
      "Alexander Kuznetsov (mathematician)",
      "Alexei Borodin",
      "Alexis Bonnet",
      "Algebraic Geometry (journal)",
      "Ana Caraiani",
      "Andrei Okounkov",
      "Annales de l'Institut Henri Poincaré C",
      "Annales de l'Institut Henri Poincaré D",
      "Annette Huber-Klawitter",
      "Ari Laptev",
      "Armenian Mathematical Union",
      "Arnulf Jentzen",
      "Artur Avila",
      "Assaf Naor",
      "Associazione per la Matematica Applicata alle Scienze Economiche e Sociali",
      "Austrian Mathematical Society",
      "Belgian Mathematical Society",
      "Belgian Statistical Society",
      "Ben J. Green",
      "Bibcode (identifier)",
      "Bologna",
      "Bosnian Mathematical Society",
      "Boáz Klartag",
      "Catalan Mathematical Society",
      "Centre International de Rencontres Mathématiques",
      "Centre de Recerca Matemàtica",
      "Centrum Wiskunde & Informatica",
      "Ciprian Manolescu",
      "Claire Voisin",
      "Commentarii Mathematici Helvetici",
      "Corinna Ulcigrai",
      "Cristiana De Filippis",
      "Croatian Mathematical Society",
      "Cyprus Mathematical Society",
      "Czech Mathematical Society",
      "Cédric Villani",
      "Danish Mathematical Society",
      "Danylo Radchenko",
      "David Clark Dobson",
      "Dennis Gaitsgory",
      "Dmitry Kramkov"
    ],
    "categories": [
      "Category:1990 establishments in Europe",
      "Category:All articles that are excessively detailed",
      "Category:All articles with style issues",
      "Category:Articles with short description",
      "Category:Mathematical societies",
      "Category:Organizations established in 1990",
      "Category:Pan-European learned societies",
      "Category:Short description is different from Wikidata",
      "Category:Wikipedia articles that are excessively detailed from November 2024",
      "Category:Wikipedia articles with style issues from November 2024"
    ]
  },
  "Dirichlet's theorem on arithmetic progressions": {
    "title": "Dirichlet's theorem on arithmetic progressions",
    "url": "https://en.wikipedia.org/wiki/Dirichlet%27s_theorem_on_arithmetic_progressions",
    "summary": "In number theory, Dirichlet's theorem, also called the Dirichlet prime number theorem, states that for any two positive coprime integers a and d, there are infinitely many primes of the form a + nd, where n is also a positive integer. In other words, there are infinitely many primes that are congruent to a modulo d. The numbers of the form a + nd form an arithmetic progression\n\n  \n    \n      \n        a\n        ,\n         \n        a\n        +\n        d\n        ,\n         \n        a\n        +\n        2\n        d\n        ,\n         \n        a\n        +\n        3\n        d\n        ,\n         \n        …\n        ,\n         \n      \n    \n    {\\displaystyle a,\\ a+d,\\ a+2d,\\ a+3d,\\ \\dots ,\\ }\n  \n\nand Dirichlet's theorem states that this sequence contains infinitely many prime numbers. The theorem extends Euclid's theorem that there are infinitely many prime numbers (of the form 1 + 2n).  Stronger forms of Dirichlet's theorem state that for any such arithmetic progression, the sum of the reciproc",
    "content": "In number theory, Dirichlet's theorem, also called the Dirichlet prime number theorem, states that for any two positive coprime integers a and d, there are infinitely many primes of the form a + nd, where n is also a positive integer. In other words, there are infinitely many primes that are congruent to a modulo d. The numbers of the form a + nd form an arithmetic progression\n\n  \n    \n      \n        a\n        ,\n         \n        a\n        +\n        d\n        ,\n         \n        a\n        +\n        2\n        d\n        ,\n         \n        a\n        +\n        3\n        d\n        ,\n         \n        …\n        ,\n         \n      \n    \n    {\\displaystyle a,\\ a+d,\\ a+2d,\\ a+3d,\\ \\dots ,\\ }\n  \n\nand Dirichlet's theorem states that this sequence contains infinitely many prime numbers. The theorem extends Euclid's theorem that there are infinitely many prime numbers (of the form 1 + 2n).  Stronger forms of Dirichlet's theorem state that for any such arithmetic progression, the sum of the reciprocals of the prime numbers in the progression diverges and that different such arithmetic progressions with the same modulus have approximately the same proportions of primes. Equivalently, the primes are evenly distributed (asymptotically) among the congruence classes modulo d containing a's coprime to d. \nThe theorem is named after the German mathematician Peter Gustav Lejeune Dirichlet, who proved it in 1837.\n\nExamples\nThe primes of the form 4n + 3 are (sequence A002145 in the OEIS)\n\n3, 7, 11, 19, 23, 31, 43, 47, 59, 67, 71, 79, 83, 103, 107, 127, 131, 139, 151, 163, 167, 179, 191, 199, 211, 223, 227, 239, 251, 263, 271, 283, ...\nThey correspond to the following values of n: (sequence A095278 in the OEIS)\n\n0, 1, 2, 4, 5, 7, 10, 11, 14, 16, 17, 19, 20, 25, 26, 31, 32, 34, 37, 40, 41, 44, 47, 49, 52, 55, 56, 59, 62, 65, 67, 70, 76, 77, 82, 86, 89, 91, 94, 95, ...\nThe strong form of Dirichlet's theorem implies that\n\n  \n    \n      \n        \n          \n            1\n            3\n          \n        \n        +\n        \n          \n            1\n            7\n          \n        \n        +\n        \n          \n            1\n            11\n          \n        \n        +\n        \n          \n            1\n            19\n          \n        \n        +\n        \n          \n            1\n            23\n          \n        \n        +\n        \n          \n            1\n            31\n          \n        \n        +\n        \n          \n            1\n            43\n          \n        \n        +\n        \n          \n            1\n            47\n          \n        \n        +\n        \n          \n            1\n            59\n          \n        \n        +\n        \n          \n            1\n            67\n          \n        \n        +\n        ⋯\n      \n    \n    {\\displaystyle {\\frac {1}{3}}+{\\frac {1}{7}}+{\\frac {1}{11}}+{\\frac {1}{19}}+{\\frac {1}{23}}+{\\frac {1}{31}}+{\\frac {1}{43}}+{\\frac {1}{47}}+{\\frac {1}{59}}+{\\frac {1}{67}}+\\cdots }\n  \n\nis a divergent series.\nSequences dn + a with odd d are often ignored because half the numbers are even and the other half is the same numbers as a sequence with 2d, if we start with n = 0. For example, 6n + 1 produces the same primes as 3n + 1, while 6n + 5 produces the same as 3n + 2 except for the only even prime 2. The following table lists several arithmetic progressions with infinitely many primes and the first few ones in each of them.\n\nWe can generate some forms of primes by using an iterative method. For example, we can generate primes of the form \n  \n    \n      \n        4\n        n\n        +\n        3\n      \n    \n    {\\displaystyle 4n+3}\n  \n by using the following method:\nLet \n  \n    \n      \n        \n          a\n          \n            0\n          \n        \n        =\n        4\n        (\n        1\n        )\n        +\n        3\n        =\n        7\n      \n    \n    {\\displaystyle a_{0}=4(1)+3=7}\n  \n. Then we let \n  \n    \n      \n        \n          a\n          \n            1\n          \n        \n        =\n        4\n        \n          a\n          \n            0\n          \n        \n        +\n        3\n        =\n        4\n        (\n        7\n        )\n        +\n        3\n        =\n        31\n      \n    \n    {\\displaystyle a_{1}=4a_{0}+3=4(7)+3=31}\n  \n which is prime. We continue by computing \n  \n    \n      \n        4\n        (\n        7\n        )\n        (\n        31\n        )\n        +\n        3\n        =\n        871\n        =\n        13\n        (\n        67\n        )\n      \n    \n    {\\displaystyle 4(7)(31)+3=871=13(67)}\n  \n. Because \n  \n    \n      \n        4\n        (\n        7\n        )\n        (\n        31\n        )\n        +\n        3\n      \n    \n    {\\displaystyle 4(7)(31)+3}\n  \n is of the form \n  \n    \n      \n        4\n        n\n        +\n        3\n      \n    \n    {\\displaystyle 4n+3}\n  \n, either 13 or 67 is of the form \n  \n    \n      \n        4\n        n\n        +\n        3\n      \n    \n    {\\displaystyle 4n+3}\n  \n. We have that \n  \n    \n      \n        67\n        =\n        4\n        (\n        16\n        )\n        +\n ",
    "links": [
      "Adrien-Marie Legendre",
      "Algebraic number theory",
      "Almost all",
      "Analytic number theory",
      "Annals of Mathematics",
      "Arithmetic progression",
      "Atle Selberg",
      "Bombieri–Vinogradov theorem",
      "Brun–Titchmarsh theorem",
      "Bunyakovsky conjecture",
      "Carl Friedrich Gauss",
      "Chebotarev's density theorem",
      "Chebyshev's bias",
      "Congruence relation",
      "Coprime",
      "Cyclotomic polynomial",
      "Dickson's conjecture",
      "Dirichlet's approximation theorem",
      "Dirichlet-multinomial distribution",
      "Dirichlet L-function",
      "Dirichlet L-series",
      "Dirichlet character",
      "Dirichlet convolution",
      "Dirichlet distribution",
      "Dirichlet integral",
      "Dirichlet problem",
      "Dirichlet process",
      "Dirichlet series",
      "Disquisitiones Arithmeticae",
      "Divergent series",
      "Doi (identifier)",
      "Elementary proof",
      "Eric W. Weisstein",
      "Euclid's theorem",
      "Euler's totient function",
      "Graduate Texts in Mathematics",
      "Green–Tao theorem",
      "ISBN (identifier)",
      "Integer",
      "JSTOR (identifier)",
      "Jürgen Neukirch",
      "Landau's problems",
      "Linnik's theorem",
      "MR (identifier)",
      "MathWorld",
      "Modular arithmetic",
      "Multiplicative inverse",
      "Number theory",
      "On-Line Encyclopedia of Integer Sequences",
      "Open problem"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Short description is different from Wikidata",
      "Category:Theorems about prime numbers",
      "Category:Zeta and L-functions"
    ]
  },
  "Dirichlet L-function": {
    "title": "Dirichlet L-function",
    "url": "https://en.wikipedia.org/wiki/Dirichlet_L-function",
    "summary": "In mathematics, a Dirichlet \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  \n-series is a function of the form\n\n  \n    \n      \n        L\n        (\n        s\n        ,\n        χ\n        )\n        =\n        \n          ∑\n          \n            n\n            =\n            1\n          \n          \n            ∞\n          \n        \n        \n          \n            \n              χ\n              (\n              n\n              )\n            \n            \n              n\n              \n                s\n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle L(s,\\chi )=\\sum _{n=1}^{\\infty }{\\frac {\\chi (n)}{n^{s}}}.}\n  \n\nwhere \n  \n    \n      \n        χ\n      \n    \n    {\\displaystyle \\chi }\n  \n is a Dirichlet character and \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n  \n a complex variable with real part greater than \n  \n    \n      \n        1\n      \n    \n    {\\displaystyle 1}\n  \n. It is a special case of a Dirichlet series. By analytic",
    "content": "In mathematics, a Dirichlet \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  \n-series is a function of the form\n\n  \n    \n      \n        L\n        (\n        s\n        ,\n        χ\n        )\n        =\n        \n          ∑\n          \n            n\n            =\n            1\n          \n          \n            ∞\n          \n        \n        \n          \n            \n              χ\n              (\n              n\n              )\n            \n            \n              n\n              \n                s\n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle L(s,\\chi )=\\sum _{n=1}^{\\infty }{\\frac {\\chi (n)}{n^{s}}}.}\n  \n\nwhere \n  \n    \n      \n        χ\n      \n    \n    {\\displaystyle \\chi }\n  \n is a Dirichlet character and \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n  \n a complex variable with real part greater than \n  \n    \n      \n        1\n      \n    \n    {\\displaystyle 1}\n  \n. It is a special case of a Dirichlet series. By analytic continuation, it can be extended to a meromorphic function on the whole complex plane, and is then called a Dirichlet \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  \n-function and also denoted \n  \n    \n      \n        L\n        (\n        s\n        ,\n        χ\n        )\n      \n    \n    {\\displaystyle L(s,\\chi )}\n  \n.\nThese functions are named after Peter Gustav Lejeune Dirichlet who introduced them in (Dirichlet 1837) to prove the theorem on primes in arithmetic progressions that also bears his name. In the course of the proof, Dirichlet shows that \n  \n    \n      \n        L\n        (\n        s\n        ,\n        χ\n        )\n      \n    \n    {\\displaystyle L(s,\\chi )}\n  \n is non-zero at \n  \n    \n      \n        s\n        =\n        1\n      \n    \n    {\\displaystyle s=1}\n  \n. Moreover, if \n  \n    \n      \n        χ\n      \n    \n    {\\displaystyle \\chi }\n  \n is principal, then the corresponding Dirichlet \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  \n-function has a simple pole at \n  \n    \n      \n        s\n        =\n        1\n      \n    \n    {\\displaystyle s=1}\n  \n. Otherwise, the \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  \n-function is entire.\n\nEuler product\nSince a Dirichlet character \n  \n    \n      \n        χ\n      \n    \n    {\\displaystyle \\chi }\n  \n is completely multiplicative, its \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  \n-function can also be written as an Euler product in the half-plane of absolute convergence:\n\n  \n    \n      \n        L\n        (\n        s\n        ,\n        χ\n        )\n        =\n        \n          ∏\n          \n            p\n          \n        \n        \n          \n            (\n            \n              1\n              −\n              χ\n              (\n              p\n              )\n              \n                p\n                \n                  −\n                  s\n                \n              \n            \n            )\n          \n          \n            −\n            1\n          \n        \n        \n           for \n        \n        \n          Re\n        \n        (\n        s\n        )\n        >\n        1\n        ,\n      \n    \n    {\\displaystyle L(s,\\chi )=\\prod _{p}\\left(1-\\chi (p)p^{-s}\\right)^{-1}{\\text{ for }}{\\text{Re}}(s)>1,}\n  \n\nwhere the product is over all prime numbers.\n\nPrimitive characters\nResults about L-functions are often stated more simply if the character is assumed to be primitive, although the results typically can be extended to imprimitive characters with minor complications. This is because of the relationship between a imprimitive character \n  \n    \n      \n        χ\n      \n    \n    {\\displaystyle \\chi }\n  \n and the primitive character \n  \n    \n      \n        \n          χ\n          \n            ⋆\n          \n        \n      \n    \n    {\\displaystyle \\chi ^{\\star }}\n  \n which induces it:\n\n  \n    \n      \n        χ\n        (\n        n\n        )\n        =\n        \n          \n            {\n            \n              \n                \n                  \n                    χ\n                    \n                      ⋆\n                    \n                  \n                  (\n                  n\n                  )\n                  ,\n                \n                \n                  \n                    i\n                    f\n                  \n                  gcd\n                  (\n                  n\n                  ,\n                  q\n                  )\n                  =\n                  1\n                \n              \n              \n                \n                  0\n                  ,\n                \n                \n                  \n                    i\n                    f\n                  \n                  gcd\n                  (\n                  n\n                  ,\n                  q\n                  )\n                  ≠\n                  1\n                \n              \n            \n            \n          \n        \n      \n    \n    {\\displaystyle \\chi (n)={\\begin{cases}\\chi ^{\\sta",
    "links": [
      "Absolute convergence",
      "American Mathematical Society",
      "Analytic continuation",
      "Artin L-function",
      "Artin conjecture (L-functions)",
      "Automorphic L-function",
      "Beilinson conjectures",
      "Birch and Swinnerton-Dyer conjecture",
      "Bloch–Kato conjecture (L-functions)",
      "Class number formula",
      "Completely multiplicative",
      "Complex plane",
      "Complex variable",
      "Dedekind zeta function",
      "Digital Library of Mathematical Functions",
      "Dirichlet's theorem on arithmetic progressions",
      "Dirichlet beta function",
      "Dirichlet character",
      "Dirichlet series",
      "Encyclopedia of Mathematics",
      "Entire function",
      "Euler product",
      "Euler system",
      "European Mathematical Society",
      "Frank W. J. Olver",
      "Functional equation",
      "Functional equation (L-function)",
      "Gamma function",
      "Gauss sum",
      "Generalized Riemann hypothesis",
      "Half-plane",
      "Harold Davenport",
      "Hasse–Weil zeta function",
      "Henryk Iwaniec",
      "Hugh Montgomery (mathematician)",
      "Hurwitz zeta function",
      "ISBN (identifier)",
      "Integer",
      "L-function",
      "L-function with Grössencharakter",
      "Langlands program",
      "Lindelöf hypothesis",
      "MR (identifier)",
      "Main conjecture of Iwasawa theory",
      "Mathematics",
      "Meromorphic function",
      "Michael Rosen (mathematician)",
      "Modularity theorem",
      "Motivic L-function",
      "Number theory"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Short description is different from Wikidata",
      "Category:Zeta and L-functions"
    ]
  },
  "Automorphic L-function": {
    "title": "Automorphic L-function",
    "url": "https://en.wikipedia.org/wiki/Automorphic_L-function",
    "summary": "In mathematics, an automorphic L-function is a function L(s,π,r) of a complex variable s, associated to an automorphic representation π of a reductive group G over a global field and a finite-dimensional complex representation r of the Langlands dual group LG of G, generalizing the Dirichlet L-series of a Dirichlet character and the Mellin transform of a modular form. They were introduced by Langlands (1967, 1970, 1971).\nBorel (1979) and Arthur & Gelbart (1991) gave surveys of automorphic L-functions.",
    "content": "In mathematics, an automorphic L-function is a function L(s,π,r) of a complex variable s, associated to an automorphic representation π of a reductive group G over a global field and a finite-dimensional complex representation r of the Langlands dual group LG of G, generalizing the Dirichlet L-series of a Dirichlet character and the Mellin transform of a modular form. They were introduced by Langlands (1967, 1970, 1971).\nBorel (1979) and Arthur & Gelbart (1991) gave surveys of automorphic L-functions.\n\nProperties\nAutomorphic \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  \n-functions should have the following properties (which have been proved in some cases but are still conjectural in other cases).\nThe L-function \n  \n    \n      \n        L\n        (\n        s\n        ,\n        π\n        ,\n        r\n        )\n      \n    \n    {\\displaystyle L(s,\\pi ,r)}\n  \n should be a product over the places \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n  \n of \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n of local \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  \n functions.\n\n  \n    \n      \n        L\n        (\n        s\n        ,\n        π\n        ,\n        r\n        )\n        =\n        \n          ∏\n          \n            v\n          \n        \n        L\n        (\n        s\n        ,\n        \n          π\n          \n            v\n          \n        \n        ,\n        \n          r\n          \n            v\n          \n        \n        )\n      \n    \n    {\\displaystyle L(s,\\pi ,r)=\\prod _{v}L(s,\\pi _{v},r_{v})}\n  \n\nHere the automorphic representation \n  \n    \n      \n        π\n        =\n        ⊗\n        \n          π\n          \n            v\n          \n        \n      \n    \n    {\\displaystyle \\pi =\\otimes \\pi _{v}}\n  \n is a tensor product of the representations \n  \n    \n      \n        \n          π\n          \n            v\n          \n        \n      \n    \n    {\\displaystyle \\pi _{v}}\n  \n of local groups.\nThe L-function is expected to have an analytic continuation as a meromorphic function of all complex \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n  \n, and satisfy a functional equation\n\n  \n    \n      \n        L\n        (\n        s\n        ,\n        π\n        ,\n        r\n        )\n        =\n        ϵ\n        (\n        s\n        ,\n        π\n        ,\n        r\n        )\n        L\n        (\n        1\n        −\n        s\n        ,\n        π\n        ,\n        \n          r\n          \n            ∨\n          \n        \n        )\n      \n    \n    {\\displaystyle L(s,\\pi ,r)=\\epsilon (s,\\pi ,r)L(1-s,\\pi ,r^{\\lor })}\n  \n\nwhere the factor \n  \n    \n      \n        ϵ\n        (\n        s\n        ,\n        π\n        ,\n        r\n        )\n      \n    \n    {\\displaystyle \\epsilon (s,\\pi ,r)}\n  \n is a product of \"local constants\"\n\n  \n    \n      \n        ϵ\n        (\n        s\n        ,\n        π\n        ,\n        r\n        )\n        =\n        \n          ∏\n          \n            v\n          \n        \n        ϵ\n        (\n        s\n        ,\n        \n          π\n          \n            v\n          \n        \n        ,\n        \n          r\n          \n            v\n          \n        \n        ,\n        \n          ψ\n          \n            v\n          \n        \n        )\n      \n    \n    {\\displaystyle \\epsilon (s,\\pi ,r)=\\prod _{v}\\epsilon (s,\\pi _{v},r_{v},\\psi _{v})}\n  \n\nalmost all of which are 1.\n\nGeneral linear groups\nGodement & Jacquet (1972) constructed the automorphic L-functions for general linear groups with r the standard representation (so-called standard L-functions) and verified analytic continuation and the functional equation, by using a generalization of the method in Tate's thesis. Ubiquitous in the Langlands Program are Rankin-Selberg products of representations of GL(m) and GL(n). The resulting Rankin-Selberg L-functions satisfy a number of analytic properties, their functional equation being first proved via the Langlands–Shahidi method.\nIn general, the Langlands functoriality conjectures imply that automorphic L-functions of a connected reductive group are equal to products of automorphic L-functions of general linear groups. A proof of Langlands functoriality would also lead towards a thorough understanding of the analytic properties of automorphic L-functions.\n\nSee also\nGrand Riemann hypothesis\n\nReferences\nArthur, James; Gelbart, Stephen (1991), \"Lectures on automorphic L-functions\", in Coates, John; Taylor, M. J. (eds.), L-functions and arithmetic (Durham, 1989) (PDF), London Math. Soc. Lecture Note Ser., vol. 153, Cambridge University Press, pp. 1–59, doi:10.1017/CBO9780511526053.003, ISBN 978-0-521-38619-7, MR 1110389\nBorel, Armand (1979), \"Automorphic L-functions\", in Borel, Armand; Casselman, W. (eds.), Automorphic forms, representations and L-functions (Proc. Sympos. Pure Math., Oregon State Univ., Corvallis, Ore., 1977), Part 2, vol. XXXIII, Providence, R.I.: American Mathematical Society, pp. 27–61, doi:10.1090/pspum/033.2/546608, ISBN 978-0-8218-1437-6, MR 0546608",
    "links": [
      "American Mathematical Society",
      "Armand Borel",
      "Artin L-function",
      "Artin conjecture (L-functions)",
      "Automorphic representation",
      "Beilinson conjectures",
      "Birch and Swinnerton-Dyer conjecture",
      "Bloch–Kato conjecture (L-functions)",
      "Cambridge University Press",
      "Class number formula",
      "Dedekind zeta function",
      "Dirichlet L-function",
      "Dirichlet L-series",
      "Dirichlet character",
      "Doi (identifier)",
      "Euler system",
      "Generalized Riemann hypothesis",
      "Global field",
      "Grand Riemann hypothesis",
      "Hasse–Weil zeta function",
      "ISBN (identifier)",
      "JSTOR (identifier)",
      "L-function",
      "L-function with Grössencharakter",
      "Langlands dual group",
      "Langlands functoriality",
      "Langlands program",
      "Langlands–Shahidi method",
      "Lindelöf hypothesis",
      "MR (identifier)",
      "Main conjecture of Iwasawa theory",
      "Mathematics",
      "Mellin transform",
      "Modular form",
      "Motivic L-function",
      "Number theory",
      "P-adic L-function",
      "Ramanujan–Petersson conjecture",
      "Rankin–Selberg method",
      "Reductive group",
      "Riemann hypothesis",
      "Riemann zeta function",
      "Riemann–von Mangoldt formula",
      "Robert Langlands",
      "Roger Godement",
      "Selberg class",
      "Selmer group",
      "Special values of L-functions",
      "Springer-Verlag",
      "Standard L-function"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Automorphic forms",
      "Category:Langlands program",
      "Category:Short description matches Wikidata",
      "Category:Zeta and L-functions"
    ]
  },
  "Auxiliary function": {
    "title": "Auxiliary function",
    "url": "https://en.wikipedia.org/wiki/Auxiliary_function",
    "summary": "In mathematics, auxiliary functions are an important construction in transcendental number theory.  They are functions that appear in most proofs in this area of mathematics and that have specific, desirable properties, such as taking the value zero for many arguments, or having a zero of high order at some point.",
    "content": "In mathematics, auxiliary functions are an important construction in transcendental number theory.  They are functions that appear in most proofs in this area of mathematics and that have specific, desirable properties, such as taking the value zero for many arguments, or having a zero of high order at some point.\n\nDefinition\nAuxiliary functions are not a rigorously defined kind of function, rather they are functions which are either explicitly constructed or at least shown to exist and which provide a contradiction to some assumed hypothesis, or otherwise prove the result in question.  Creating a function during the course of a proof in order to prove the result is not a technique exclusive to transcendence theory, but the term \"auxiliary function\" usually refers to the functions created in this area.\n\nExplicit functions\nLiouville's transcendence criterion\nBecause of the naming convention mentioned above, auxiliary functions can be dated back to their source simply by looking at the earliest results in transcendence theory.  One of these first results was Liouville's proof that transcendental numbers exist when he showed that the so called Liouville numbers were transcendental.  He did this by discovering a transcendence criterion which these numbers satisfied.  To derive this criterion he started with a general algebraic number α and found some property that this number would necessarily satisfy. The auxiliary function he used in the course of proving this criterion was simply the minimal polynomial of α, which is the irreducible polynomial f with integer coefficients such that f(α) = 0.  This function can be used to estimate how well the algebraic number α can be estimated by rational numbers p/q.  Specifically if α has degree d at least two then he showed that\n\n  \n    \n      \n        \n          |\n          \n            f\n            \n              (\n              \n                \n                  p\n                  q\n                \n              \n              )\n            \n          \n          |\n        \n        ≥\n        \n          \n            1\n            \n              q\n              \n                d\n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\left|f\\left({\\frac {p}{q}}\\right)\\right|\\geq {\\frac {1}{q^{d}}},}\n  \n\nand also, using the mean value theorem, that there is some constant depending on α, say c(α), such that\n\n  \n    \n      \n        \n          |\n          \n            f\n            \n              (\n              \n                \n                  p\n                  q\n                \n              \n              )\n            \n          \n          |\n        \n        ≤\n        c\n        (\n        α\n        )\n        \n          |\n          \n            α\n            −\n            \n              \n                p\n                q\n              \n            \n          \n          |\n        \n        .\n      \n    \n    {\\displaystyle \\left|f\\left({\\frac {p}{q}}\\right)\\right|\\leq c(\\alpha )\\left|\\alpha -{\\frac {p}{q}}\\right|.}\n  \n\nCombining these results gives a property that the algebraic number must satisfy; therefore any number not satisfying this criterion must be transcendental.\nThe auxiliary function in Liouville's work is very simple, merely a polynomial that vanishes at a given algebraic number.  This kind of property is usually the one that auxiliary functions satisfy.  They either vanish or become very small at particular points, which is usually combined with the assumption that they do not vanish or can't be too small to derive a result.\n\nFourier's proof of the irrationality of e\nAnother simple, early occurrence is in Fourier's proof of the irrationality of e, though the notation used usually disguises this fact.  Fourier's proof used the power series of the exponential function:\n\n  \n    \n      \n        \n          e\n          \n            x\n          \n        \n        =\n        \n          ∑\n          \n            n\n            =\n            0\n          \n          \n            ∞\n          \n        \n        \n          \n            \n              x\n              \n                n\n              \n            \n            \n              n\n              !\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle e^{x}=\\sum _{n=0}^{\\infty }{\\frac {x^{n}}{n!}}.}\n  \n\nBy truncating this power series after, say, N + 1 terms we get a polynomial with rational coefficients of degree N which is in some sense \"close\" to the function ex.  Specifically if we look at the auxiliary function defined by the remainder:\n\n  \n    \n      \n        R\n        (\n        x\n        )\n        =\n        \n          e\n          \n            x\n          \n        \n        −\n        \n          ∑\n          \n            n\n            =\n            0\n          \n          \n            N\n          \n        \n        \n          \n            \n              x\n              \n                n\n              \n            \n            \n              n\n              !\n",
    "links": [
      "Alan Baker (mathematician)",
      "Alexander Gelfond",
      "Algebraic number",
      "Arakelov theory",
      "Axel Thue",
      "Baker's theorem",
      "Big O notation",
      "Carl Ludwig Siegel",
      "Charles Hermite",
      "Complex number",
      "Denominator",
      "Doi (identifier)",
      "Entire function",
      "Exponential function",
      "Exponential polynomial",
      "Function (mathematics)",
      "Gelfond–Schneider theorem",
      "Hermite",
      "Hermite–Lindemann theorem",
      "Irrationality measure",
      "Irreducibility (mathematics)",
      "Jonathan Pila",
      "Joseph Fourier",
      "Joseph Liouville",
      "Lindemann–Weierstrass theorem",
      "Liouville number",
      "Mathematics",
      "Maximum modulus principle",
      "Mean value theorem",
      "Meromorphic",
      "Minimal polynomial (field theory)",
      "Multiplicity (mathematics)",
      "Number field",
      "Pigeonhole Principle",
      "Power series",
      "Rational function",
      "Rational number",
      "S2CID (identifier)",
      "Schneider–Lang theorem",
      "Serge Lang",
      "Siegel's lemma",
      "Theodor Schneider",
      "Transcendental number theory",
      "Transcendental numbers",
      "Wronskian"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1: long volume value",
      "Category:Diophantine approximation",
      "Category:Number theory",
      "Category:Short description matches Wikidata"
    ]
  },
  "Diophantine equation": {
    "title": "Diophantine equation",
    "url": "https://en.wikipedia.org/wiki/Diophantine_equation",
    "summary": "In mathematics, a Diophantine equation is an equation, typically a polynomial equation in two or more unknowns with integer coefficients, for which only integer solutions are of interest. A linear Diophantine equation equates the sum of two or more unknowns, with coefficients, to a constant.  An exponential Diophantine equation is one in which unknowns can appear in exponents.\nDiophantine problems have fewer equations than unknowns and involve finding integers that solve all equations simultaneously. Because such systems of equations define algebraic curves, algebraic surfaces, or, more generally, algebraic sets, their study is a part of algebraic geometry that is called Diophantine geometry.\nThe word Diophantine refers to the Hellenistic mathematician of the 3rd century, Diophantus of Alexandria, who made a study of such equations and was one of the first mathematicians to introduce symbolism into algebra. The mathematical study of Diophantine problems that Diophantus initiated is now",
    "content": "In mathematics, a Diophantine equation is an equation, typically a polynomial equation in two or more unknowns with integer coefficients, for which only integer solutions are of interest. A linear Diophantine equation equates the sum of two or more unknowns, with coefficients, to a constant.  An exponential Diophantine equation is one in which unknowns can appear in exponents.\nDiophantine problems have fewer equations than unknowns and involve finding integers that solve all equations simultaneously. Because such systems of equations define algebraic curves, algebraic surfaces, or, more generally, algebraic sets, their study is a part of algebraic geometry that is called Diophantine geometry.\nThe word Diophantine refers to the Hellenistic mathematician of the 3rd century, Diophantus of Alexandria, who made a study of such equations and was one of the first mathematicians to introduce symbolism into algebra. The mathematical study of Diophantine problems that Diophantus initiated is now called Diophantine analysis.\nWhile individual equations present a kind of puzzle and have been considered throughout history, the formulation of general theories of Diophantine equations, beyond the case of linear and quadratic equations, was an achievement of the twentieth century.\n\nExamples\nIn the following Diophantine equations, w, x, y, and z are the unknowns and the other letters are given constants:\n\nLinear Diophantine equations\nOne equation\nThe simplest linear Diophantine equation takes the form \n\n  \n    \n      \n        a\n        x\n        +\n        b\n        y\n        =\n        c\n        ,\n      \n    \n    {\\displaystyle ax+by=c,}\n  \n \nwhere a, b and c are given integers. The solutions are described by the following theorem:\n\nThis Diophantine equation has a solution (where x and y are integers) if and only if c is a multiple of the greatest common divisor of a and b. Moreover, if (x, y) is a solution, then the other solutions have the form (x + kv, y − ku), where k is an arbitrary integer, and u and v are the quotients of a and b (respectively) by the greatest common divisor of a and b.\nProof: If d is this greatest common divisor, Bézout's identity asserts the existence of integers e and f such that ae + bf = d. If c is a multiple of d, then c = dh for some integer h, and (eh, fh) is a solution. On the other hand, for every pair of integers x and y, the greatest common divisor d of a and b divides ax + by. Thus, if the equation has a solution, then c must be a multiple of d. If a = ud and b = vd, then for every solution (x, y), we have \n\n  \n    \n      \n        \n          \n            \n              \n                a\n                (\n                x\n                +\n                k\n                v\n                )\n                +\n                b\n                (\n                y\n                −\n                k\n                u\n                )\n              \n              \n                \n                =\n                a\n                x\n                +\n                b\n                y\n                +\n                k\n                (\n                a\n                v\n                −\n                b\n                u\n                )\n              \n            \n            \n              \n              \n                \n                =\n                a\n                x\n                +\n                b\n                y\n                +\n                k\n                (\n                u\n                d\n                v\n                −\n                v\n                d\n                u\n                )\n              \n            \n            \n              \n              \n                \n                =\n                a\n                x\n                +\n                b\n                y\n                ,\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}a(x+kv)+b(y-ku)&=ax+by+k(av-bu)\\\\&=ax+by+k(udv-vdu)\\\\&=ax+by,\\end{aligned}}}\n  \n \nshowing that (x + kv, y − ku) is another solution. Finally, given two solutions such that \n\n  \n    \n      \n        a\n        \n          x\n          \n            1\n          \n        \n        +\n        b\n        \n          y\n          \n            1\n          \n        \n        =\n        a\n        \n          x\n          \n            2\n          \n        \n        +\n        b\n        \n          y\n          \n            2\n          \n        \n        =\n        c\n        ,\n      \n    \n    {\\displaystyle ax_{1}+by_{1}=ax_{2}+by_{2}=c,}\n  \n \none deduces that \n  \n    \n      \n        u\n        (\n        \n          x\n          \n            2\n          \n        \n        −\n        \n          x\n          \n            1\n          \n        \n        )\n        +\n        v\n        (\n        \n          y\n          \n            2\n          \n        \n        −\n        \n          y\n          \n            1\n          \n        \n        )\n        =\n        0.\n      \n    \n    {\\displaystyle u(x_{2}-x_{1})+",
    "links": [
      "A History of Greek Mathematics",
      "Academic Press",
      "Affine algebraic variety",
      "Alexandria",
      "Algebra",
      "Algebraic curve",
      "Algebraic geometry",
      "Algebraic set",
      "Algebraic surface",
      "Algebraically closed",
      "Algorithm",
      "Almagest",
      "Anaxagoras",
      "Ancient Egyptian mathematics",
      "Ancient Greek astronomy",
      "Ancient Greek mathematics",
      "Andrew Wiles",
      "Angle bisector theorem",
      "Angle trisection",
      "Annals of Mathematics",
      "Anthemius of Tralles",
      "Apollonian circles",
      "Apollonian gasket",
      "Apollonius's theorem",
      "Apollonius of Perga",
      "Archimedes",
      "Archimedes's cattle problem",
      "Archimedes Palimpsest",
      "Archytas",
      "Aristaeus the Elder",
      "Aristarchus's inequality",
      "Aristarchus of Samos",
      "Arithmetica",
      "Aryabhata",
      "Attic numerals",
      "Autolycus of Pitane",
      "Babylonian mathematics",
      "Beal's conjecture",
      "Bion of Abdera",
      "Brahmagupta",
      "Bryson of Heraclea",
      "Bézout's identity",
      "Callippus",
      "Cambridge University Press",
      "Cannonball problem",
      "Carpus of Antioch",
      "Catalan's conjecture",
      "Catoptrics",
      "Chakravala method",
      "Chinese mathematics"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Diophantine equations",
      "Category:Short description is different from Wikidata",
      "Category:Use dmy dates from October 2020"
    ]
  },
  "Diophantine geometry": {
    "title": "Diophantine geometry",
    "url": "https://en.wikipedia.org/wiki/Diophantine_geometry",
    "summary": "In mathematics, Diophantine geometry is the study of Diophantine equations by means of powerful methods in algebraic geometry. By the 20th century it became clear for some mathematicians that methods of algebraic geometry are ideal tools to study these equations. Diophantine geometry is part of the broader field of arithmetic geometry.\nFour theorems in Diophantine geometry that are of fundamental importance include:\n\nMordell–Weil theorem\nRoth's theorem\nSiegel's theorem\nFaltings's theorem",
    "content": "In mathematics, Diophantine geometry is the study of Diophantine equations by means of powerful methods in algebraic geometry. By the 20th century it became clear for some mathematicians that methods of algebraic geometry are ideal tools to study these equations. Diophantine geometry is part of the broader field of arithmetic geometry.\nFour theorems in Diophantine geometry that are of fundamental importance include:\n\nMordell–Weil theorem\nRoth's theorem\nSiegel's theorem\nFaltings's theorem\n\nBackground\nSerge Lang published a book Diophantine Geometry in the area in 1962, and by this book he coined the term \"Diophantine geometry\". The traditional arrangement of material on Diophantine equations was by degree and number of variables, as in Mordell's Diophantine Equations (1969). Mordell's book starts with a remark on homogeneous equations f = 0 over the rational field, attributed to C. F. Gauss, that non-zero solutions in integers (even primitive lattice points) exist if non-zero rational solutions do, and notes a caveat of L. E. Dickson, which is about parametric solutions. The Hilbert–Hurwitz result from 1890 reducing the Diophantine geometry of curves of genus 0 to degrees 1 and 2 (conic sections) occurs in Chapter 17, as does Mordell's conjecture. Siegel's theorem on integral points occurs in Chapter 28. Mordell's theorem on the finite generation of the group of rational points on an elliptic curve is in Chapter 16, and integer points on the Mordell curve in Chapter 26.\nIn a hostile review of Lang's book, Mordell wrote:\n\nIn recent times, powerful new geometric ideas and methods have been developed by means of which important new arithmetical theorems and related results have been found and proved and some of these are not easily proved otherwise. Further, there has been a tendency to clothe the old results, their extensions, and proofs in the new geometrical language. Sometimes, however, the full implications of results are best described in a geometrical setting. Lang has these aspects very much in mind in this book, and seems to miss no opportunity for geometric presentation. This accounts for his title \"Diophantine Geometry.\"\nHe notes that the content of the book is largely versions of the Mordell–Weil theorem, Thue–Siegel–Roth theorem, Siegel's theorem, with a treatment of Hilbert's irreducibility theorem and applications (in the style of Siegel). Leaving aside issues of generality, and a completely different style, the major mathematical difference between the two books is that Lang used abelian varieties and offered a proof of Siegel's theorem, while Mordell noted that the proof \"is of a very advanced character\" (p. 263).\nDespite a bad press initially, Lang's conception has been sufficiently widely accepted for a 2006 tribute to call the book \"visionary\". A larger field sometimes called arithmetic of abelian varieties now includes Diophantine geometry along with class field theory, complex multiplication, local zeta-functions and L-functions. Paul Vojta wrote:\n\nWhile others at the time shared this viewpoint (e.g., Weil, Tate, Serre), it is easy to forget that others did not, as Mordell's review of Diophantine Geometry attests.\n\nApproaches\nA single equation defines a hypersurface, and simultaneous Diophantine equations give rise to a general algebraic variety V over K; the typical question is about the nature of the set V(K) of points on V with co-ordinates in K, and by means of height functions, quantitative questions about the \"size\" of these solutions may be posed, as well as the qualitative issues of whether any points exist, and if so whether there are an infinite number. Given the geometric approach, the consideration of homogeneous equations and homogeneous co-ordinates is fundamental, for the same reasons that projective geometry is the dominant approach in algebraic geometry. Rational number solutions therefore are the primary consideration; but integral solutions (i.e. lattice points) can be treated in the same way as an affine variety may be considered inside a projective variety that has extra points at infinity.\nThe general approach of Diophantine geometry is illustrated by Faltings's theorem (a conjecture of L. J. Mordell) stating that an algebraic curve C of genus g > 1 over the rational numbers has only finitely many rational points. The first result of this kind may have been the theorem of Hilbert and Hurwitz dealing with the case g = 0. The theory consists both of theorems and many conjectures and open questions.\n\nSee also\nGlossary of arithmetic and Diophantine geometry\nArakelov geometry\n\nCitations\nReferences\nExternal links\nLang's review of Mordell's Diophantine Equations\nMordell's review of Lang's Diophantine Geometry",
    "links": [
      "0",
      "1",
      "Abelian varieties",
      "Absolute geometry",
      "Abstract algebra",
      "Addition",
      "Additive number theory",
      "Adolf Hurwitz",
      "Affine geometry",
      "Affine space",
      "Affine variety",
      "Ahmes",
      "Alan Baker (mathematician)",
      "Algebra",
      "Algebraic curve",
      "Algebraic expression",
      "Algebraic geometry",
      "Algebraic number",
      "Algebraic number theory",
      "Algebraic topology",
      "Algebraic variety",
      "Alhazen",
      "Altitude (triangle)",
      "Anabelian geometry",
      "Analytic geometry",
      "Analytic number theory",
      "André Weil",
      "Angle",
      "Apollonius of Perga",
      "Applied mathematics",
      "Arakelov geometry",
      "Arakelov theory",
      "Archimedes",
      "Area",
      "Area of a circle",
      "Arithmetic",
      "Arithmetic combinatorics",
      "Arithmetic dynamics",
      "Arithmetic function",
      "Arithmetic geometry",
      "Arithmetic of abelian varieties",
      "Arithmetic topology",
      "Aryabhata",
      "Automorphism",
      "Axiomatic system",
      "Basis (linear algebra)",
      "Baudhayana",
      "Before Common Era",
      "Bernhard Riemann",
      "Blaise Pascal"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Diophantine geometry",
      "Category:Pages using sidebar with the child parameter",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Dirichlet series": {
    "title": "Dirichlet series",
    "url": "https://en.wikipedia.org/wiki/Dirichlet_series",
    "summary": "In mathematics, a Dirichlet series is any series of the form\n\n  \n    \n      \n        \n          ∑\n          \n            n\n            =\n            1\n          \n          \n            ∞\n          \n        \n        \n          \n            \n              a\n              \n                n\n              \n            \n            \n              n\n              \n                s\n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\sum _{n=1}^{\\infty }{\\frac {a_{n}}{n^{s}}},}\n  \n\nwhere s is complex, and \n  \n    \n      \n        \n          a\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle a_{n}}\n  \n is a complex sequence. It is a special case of general Dirichlet series.\nDirichlet series play a variety of important roles in analytic number theory. The most usually seen definition of the Riemann zeta function is a Dirichlet series, as are the Dirichlet L-functions. Specifically, the Riemann zeta function ζ(s) is the Dirichlet se",
    "content": "In mathematics, a Dirichlet series is any series of the form\n\n  \n    \n      \n        \n          ∑\n          \n            n\n            =\n            1\n          \n          \n            ∞\n          \n        \n        \n          \n            \n              a\n              \n                n\n              \n            \n            \n              n\n              \n                s\n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\sum _{n=1}^{\\infty }{\\frac {a_{n}}{n^{s}}},}\n  \n\nwhere s is complex, and \n  \n    \n      \n        \n          a\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle a_{n}}\n  \n is a complex sequence. It is a special case of general Dirichlet series.\nDirichlet series play a variety of important roles in analytic number theory. The most usually seen definition of the Riemann zeta function is a Dirichlet series, as are the Dirichlet L-functions. Specifically, the Riemann zeta function ζ(s) is the Dirichlet series of the constant unit function u(n), namely:\n\n  \n    \n      \n        ζ\n        (\n        s\n        )\n        =\n        \n          ∑\n          \n            n\n            =\n            1\n          \n          \n            ∞\n          \n        \n        \n          \n            1\n            \n              n\n              \n                s\n              \n            \n          \n        \n        =\n        \n          ∑\n          \n            n\n            =\n            1\n          \n          \n            ∞\n          \n        \n        \n          \n            \n              u\n              (\n              n\n              )\n            \n            \n              n\n              \n                s\n              \n            \n          \n        \n        =\n        D\n        (\n        u\n        ,\n        s\n        )\n        ,\n      \n    \n    {\\displaystyle \\zeta (s)=\\sum _{n=1}^{\\infty }{\\frac {1}{n^{s}}}=\\sum _{n=1}^{\\infty }{\\frac {u(n)}{n^{s}}}=D(u,s),}\n  \n\nwhere D(u, s) denotes the Dirichlet series of u(n).\nIt is conjectured that the Selberg class of series obeys the generalized Riemann hypothesis. The series is named in honor of Peter Gustav Lejeune Dirichlet.\n\nCombinatorial importance\nDirichlet series can be used as generating series for counting weighted sets of objects with respect to a weight which is combined multiplicatively when taking Cartesian products.\nSuppose that A is a set with a function w: A → N assigning a weight to each of the elements of A, and suppose additionally that the fibre over any natural number under that weight is a finite set. (We call such an arrangement (A,w) a weighted set.) Suppose additionally that an is the number of elements of A with weight n. Then we define the formal Dirichlet generating series for A with respect to w as follows:\n\n  \n    \n      \n        \n          \n            \n              D\n            \n          \n          \n            w\n          \n          \n            A\n          \n        \n        (\n        s\n        )\n        =\n        \n          ∑\n          \n            a\n            ∈\n            A\n          \n        \n        \n          \n            1\n            \n              w\n              (\n              a\n              \n                )\n                \n                  s\n                \n              \n            \n          \n        \n        =\n        \n          ∑\n          \n            n\n            =\n            1\n          \n          \n            ∞\n          \n        \n        \n          \n            \n              a\n              \n                n\n              \n            \n            \n              n\n              \n                s\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\mathfrak {D}}_{w}^{A}(s)=\\sum _{a\\in A}{\\frac {1}{w(a)^{s}}}=\\sum _{n=1}^{\\infty }{\\frac {a_{n}}{n^{s}}}}\n  \n\nNote that if A and B are disjoint subsets of some weighted set (U, w), then the Dirichlet series for their (disjoint) union is equal to the sum of their Dirichlet series:\n\n  \n    \n      \n        \n          \n            \n              D\n            \n          \n          \n            w\n          \n          \n            A\n            ⊎\n            B\n          \n        \n        (\n        s\n        )\n        =\n        \n          \n            \n              D\n            \n          \n          \n            w\n          \n          \n            A\n          \n        \n        (\n        s\n        )\n        +\n        \n          \n            \n              D\n            \n          \n          \n            w\n          \n          \n            B\n          \n        \n        (\n        s\n        )\n        .\n      \n    \n    {\\displaystyle {\\mathfrak {D}}_{w}^{A\\uplus B}(s)={\\mathfrak {D}}_{w}^{A}(s)+{\\mathfrak {D}}_{w}^{B}(s).}\n  \n\nMoreover, if (A, u) and (B, v) are two weighted sets, and we define a weight function w: A × B → N by\n\n  \n    \n      \n        w\n        (\n        a\n        ,\n        b\n        )\n        =\n        u\n        (\n        a\n        )\n        v\n       ",
    "links": [
      "1/2 + 1/4 + 1/8 + 1/16 + ⋯",
      "1/2 − 1/4 + 1/8 − 1/16 + ⋯",
      "1/4 + 1/16 + 1/64 + 1/256 + ⋯",
      "1 + 1 + 1 + 1 + ⋯",
      "1 + 2 + 3 + 4 + ⋯",
      "1 + 2 + 4 + 8 + ⋯",
      "1 − 1 + 2 − 6 + 24 − 120 + ⋯",
      "1 − 2 + 3 − 4 + ⋯",
      "1 − 2 + 4 − 8 + ⋯",
      "Abscissa of convergence",
      "Absolute convergence",
      "Absolutely convergent",
      "Additive function",
      "Alternating series",
      "Analytic function",
      "Analytic number theory",
      "ArXiv (identifier)",
      "Arithmetic function",
      "Arithmetic progression",
      "Bounded sequence",
      "Cambridge University Press",
      "Cauchy sequence",
      "Complete sequence",
      "Completely multiplicative function",
      "Complex number",
      "Conditional convergence",
      "Contour integral",
      "Convergent series",
      "Cube (algebra)",
      "Dirichlet's theorem on arithmetic progressions",
      "Dirichlet-multinomial distribution",
      "Dirichlet L-function",
      "Dirichlet character",
      "Dirichlet convolution",
      "Dirichlet distribution",
      "Dirichlet generating function",
      "Dirichlet integral",
      "Dirichlet inverse",
      "Dirichlet problem",
      "Dirichlet process",
      "Dirichlet series inversion",
      "Divergence of the sum of the reciprocals of the primes",
      "Divergent series",
      "Divisor function",
      "Doi (identifier)",
      "Euler product",
      "Factorial",
      "Fiber (mathematics)",
      "Fibonacci sequence",
      "Figurate number"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Series (mathematics)",
      "Category:Series expansions",
      "Category:Short description matches Wikidata",
      "Category:Zeta and L-functions"
    ]
  },
  "Adrien-Marie Legendre": {
    "title": "Adrien-Marie Legendre",
    "url": "https://en.wikipedia.org/wiki/Adrien-Marie_Legendre",
    "summary": "Adrien-Marie Legendre (; French: [adʁiɛ̃ maʁi ləʒɑ̃dʁ]; 18 September 1752 – 9 January 1833) was a French mathematician who made numerous contributions to mathematics. Well-known and important concepts such as the Legendre polynomials and Legendre transformation are named after him. He is also known for his contributions to the method of least squares, and was the first to officially publish on it, though Carl Friedrich Gauss had discovered it before him.",
    "content": "Adrien-Marie Legendre (; French: [adʁiɛ̃ maʁi ləʒɑ̃dʁ]; 18 September 1752 – 9 January 1833) was a French mathematician who made numerous contributions to mathematics. Well-known and important concepts such as the Legendre polynomials and Legendre transformation are named after him. He is also known for his contributions to the method of least squares, and was the first to officially publish on it, though Carl Friedrich Gauss had discovered it before him.\n\nLife\nAdrien-Marie Legendre was born in Paris on 18 September 1752 to a wealthy family. He received his education at the Collège Mazarin in Paris, and defended his thesis in physics and mathematics in 1770. He taught at the École Militaire in Paris from 1775 to 1780 and at the École Normale from 1795. At the same time, he was associated with the Bureau des Longitudes. In 1782, the Berlin Academy awarded Legendre a prize for his treatise on projectiles in resistant media. This treatise also brought him to the attention of Lagrange.\nThe Académie des sciences made Legendre an adjoint member in 1783 and an associate in 1785. In 1789, he was elected a Fellow of the Royal Society.\nHe assisted with the Anglo-French Survey (1784–1790) to calculate the precise distance between the Paris Observatory and the Royal Greenwich Observatory by means of trigonometry. To this end in 1787 he visited Dover and London together with Dominique, comte de Cassini and Pierre Méchain. The three also visited William Herschel, the discoverer of the planet Uranus.\nLegendre lost his private fortune in 1793 during the French Revolution. That year, he also married Marguerite-Claudine Couhin, who helped him put his affairs in order. In 1795, Legendre became one of six members of the mathematics section of the reconstituted Académie des Sciences, renamed the Institut National des Sciences et des Arts. Later, in 1803, Napoleon reorganized the Institut National, and Legendre became a member of the Geometry section. From 1799 to 1812, Legendre served as mathematics examiner for graduating artillery students at the École Militaire and from 1799 to 1815 he served as permanent mathematics examiner for the École Polytechnique. In 1824, Legendre's pension from the École Militaire was stopped because he refused to vote for the government candidate at the Institut National. In 1831, he was made an officer of the Légion d'Honneur.\nLegendre died in Paris on 9 January 1833, after a long and painful illness, and Legendre's widow carefully preserved his belongings to memorialize him. Upon her death in 1856, she was buried next to her husband in the village of Auteuil, where the couple had lived, and left their last country house to the village. Legendre's name is one of the 72 names inscribed on the Eiffel Tower.\n\nMathematical work\nAbel's work on elliptic functions was built on Legendre's, and some of Gauss's work in statistics and number theory completed that of Legendre. He developed, and first communicated to his contemporaries before Gauss, the least squares method  which has broad application in linear regression, signal processing, statistics, and curve fitting; this was published in 1806 as an appendix to his book on the paths of comets. Today, the term \"least squares method\" is used as a direct translation from the French \"méthode des moindres carrés\".\nHis major work is Exercices de Calcul Intégral, published in three volumes in 1811, 1817 and 1819. In the first volume he introduced the basic properties of elliptic integrals, beta functions and gamma functions, introducing the symbol Γ and normalizing it to Γ(n+1) = n!. Further results on the beta and gamma functions along with their applications to mechanics – such as the rotation of the earth, and the attraction of ellipsoids – appeared in the second volume. In 1830, he gave a proof of Fermat's Last Theorem for exponent n = 5, which was also proven by Lejeune Dirichlet in 1828.\nIn number theory, he conjectured the quadratic reciprocity law, subsequently proved by Gauss; in connection to this, the Legendre symbol is named after him. He also did pioneering work on the distribution of primes, and on the application of analysis to number theory. His 1798 conjecture of the prime number theorem was rigorously proved by Hadamard and de la Vallée-Poussin in 1896.\nLegendre did an impressive amount of work on elliptic functions, including the classification of elliptic integrals, but it took Abel's study of the inverses of Jacobi's functions to solve the problem completely.\nHe is known for the Legendre transformation, which is used to go from the Lagrangian to the Hamiltonian formulation of classical mechanics. In thermodynamics it is also used to obtain the enthalpy and the Helmholtz and Gibbs (free) energies from the internal energy. He is also the namesake of the Legendre polynomials, solutions to Legendre's differential equation, which occur frequently in physics and engineering applications, such as electrostatics.\nLegendre is best known as the author",
    "links": [
      "17th arrondissement of Paris",
      "26950 Legendre",
      "Académie des sciences",
      "American Academy of Arts and Sciences",
      "André Weil",
      "Anglo-French Survey (1784–1790)",
      "Associated Legendre polynomials",
      "Auteuil, Paris",
      "Beta function",
      "Bureau des Longitudes",
      "Carl Friedrich Gauss",
      "Carl Gustav Jakob Jacobi",
      "Charles Jean de la Vallée-Poussin",
      "Classical mechanics",
      "Collège Mazarin",
      "Curve fitting",
      "Doi (identifier)",
      "Dominique, comte de Cassini",
      "Edmund F. Robertson",
      "Eiffel Tower",
      "Electrostatics",
      "Elliptic function",
      "Elliptic integral",
      "Encyclopædia Britannica Eleventh Edition",
      "Enthalpy",
      "Euclid's Elements",
      "Fellow of the Royal Society",
      "Fermat's Last Theorem",
      "French Revolution",
      "French people",
      "Gamma function",
      "Gauss–Legendre algorithm",
      "Gibbs free energy",
      "Hamiltonian mechanics",
      "Helmholtz free energy",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "Internal energy",
      "JSTOR (identifier)",
      "Jacobi's elliptic functions",
      "Jacques Hadamard",
      "Joseph Fourier",
      "Julien-Léopold Boilly",
      "Kingdom of France",
      "Lagrange",
      "Lagrangian mechanics",
      "Least-squares spectral analysis",
      "Least squares",
      "Legendre's conjecture",
      "Legendre's constant"
    ],
    "categories": [
      "Category:1752 births",
      "Category:1833 deaths",
      "Category:18th-century French mathematicians",
      "Category:19th-century French mathematicians",
      "Category:Articles with French-language sources (fr)",
      "Category:Articles with hCards",
      "Category:Articles with short description",
      "Category:Commons category link from Wikidata",
      "Category:Fellows of the American Academy of Arts and Sciences",
      "Category:Fellows of the Royal Society"
    ]
  },
  "Carl Friedrich Gauss": {
    "title": "Carl Friedrich Gauss",
    "url": "https://en.wikipedia.org/wiki/Carl_Friedrich_Gauss",
    "summary": "Johann Carl Friedrich Gauss ( ; German: Gauß [kaʁl ˈfʁiːdʁɪç ˈɡaʊs] ; Latin: Carolus Fridericus Gauss; 30 April 1777 – 23 February 1855) was a German mathematician, astronomer, geodesist, and physicist, who contributed to many fields in mathematics and science. He was director of the Göttingen Observatory in Germany and professor of astronomy from 1807 until his death in 1855.\nWhile studying at the University of Göttingen, he propounded several mathematical theorems. As an independent scholar, he wrote the masterpieces Disquisitiones Arithmeticae and Theoria motus corporum coelestium. Gauss produced the second and third complete proofs of the fundamental theorem of algebra. In number theory, he made numerous contributions, such as the composition law, the law of quadratic reciprocity and one case  of the Fermat polygonal number theorem. He also contributed to the theory of binary and ternary quadratic forms, the construction of the heptadecagon, and the theory of hypergeometric series.",
    "content": "Johann Carl Friedrich Gauss ( ; German: Gauß [kaʁl ˈfʁiːdʁɪç ˈɡaʊs] ; Latin: Carolus Fridericus Gauss; 30 April 1777 – 23 February 1855) was a German mathematician, astronomer, geodesist, and physicist, who contributed to many fields in mathematics and science. He was director of the Göttingen Observatory in Germany and professor of astronomy from 1807 until his death in 1855.\nWhile studying at the University of Göttingen, he propounded several mathematical theorems. As an independent scholar, he wrote the masterpieces Disquisitiones Arithmeticae and Theoria motus corporum coelestium. Gauss produced the second and third complete proofs of the fundamental theorem of algebra. In number theory, he made numerous contributions, such as the composition law, the law of quadratic reciprocity and one case  of the Fermat polygonal number theorem. He also contributed to the theory of binary and ternary quadratic forms, the construction of the heptadecagon, and the theory of hypergeometric series. Due to Gauss' extensive and fundamental contributions to science and mathematics, more than 100 mathematical and scientific concepts are named after him.\nGauss was instrumental in the identification of Ceres as a dwarf planet. His work on the motion of planetoids disturbed by large planets led to the introduction of the Gaussian gravitational constant and the method of least squares, which he had discovered before Adrien-Marie Legendre published it. Gauss led the geodetic survey of the Kingdom of Hanover together with an arc measurement project from 1820 to 1844; he was one of the founders of geophysics and formulated the fundamental principles of magnetism. His practical work led to the invention of the heliotrope in 1821, a magnetometer in 1833 and – with Wilhelm Eduard Weber – the first electromagnetic telegraph in 1833.\nGauss was the first to discover and study non-Euclidean geometry, which he also named. He developed a fast Fourier transform some 160 years before John Tukey and James Cooley.\nGauss refused to publish incomplete work and left several works to be edited posthumously. He believed that the act of learning, not possession of knowledge, provided the greatest enjoyment. Gauss was not a committed or enthusiastic teacher, generally preferring to focus on his own work. Nevertheless, some of his students, such as Dedekind and Riemann, became well-known and influential mathematicians in their own right.\n\nBiography\nYouth and education\nGauss was born on 30 April 1777 in Brunswick, in the Duchy of Brunswick-Wolfenbüttel (now in the German state of Lower Saxony). His family was of relatively low social status. His father Gebhard Dietrich Gauss (1744–1808) worked variously as a butcher, bricklayer, gardener, and treasurer of a death-benefit fund. Gauss characterized his father as honourable and respected, but rough and dominating at home. He was experienced in writing and calculating, whereas his second wife Dorothea, Carl Friedrich's mother, was nearly illiterate. He had one elder brother from his father's first marriage.\nGauss was a child prodigy in mathematics. When the elementary teachers noticed his intellectual abilities, they brought him to the attention of the Duke of Brunswick who sent him to the local Collegium Carolinum, which he attended from 1792 to 1795 with Eberhard August Wilhelm von Zimmermann as one of his teachers. Thereafter the Duke granted him the resources for studies of mathematics, sciences, and classical languages at the University of Göttingen until 1798. His professor in mathematics was Abraham Gotthelf Kästner, whom Gauss called \"the leading mathematician among poets, and the leading poet among mathematicians\" because of his epigrams. Astronomy was taught by Karl Felix Seyffer, with whom Gauss stayed in correspondence after graduation; Olbers and Gauss mocked him in their correspondence. On the other hand, he thought highly of Georg Christoph Lichtenberg, his teacher of physics, and of Christian Gottlob Heyne, whose lectures in classics Gauss attended with pleasure. Fellow students of this time were Johann Friedrich Benzenberg, Farkas Bolyai, and Heinrich Wilhelm Brandes.\nHe was likely a self-taught student in mathematics since he independently rediscovered several theorems. He solved a geometrical problem that had occupied mathematicians since the Ancient Greeks when he determined in 1796 which regular polygons can be constructed by compass and straightedge. This discovery ultimately led Gauss to choose mathematics instead of philology as a career. Gauss's mathematical diary, a collection of short remarks about his results from the years 1796 until 1814, shows that many ideas for his mathematical magnum opus Disquisitiones Arithmeticae (1801) date from this time.\nAs an elementary student, Gauss and his class were tasked by their teacher, J.G. Büttner, to sum the numbers from 1 to 100. Much to Büttner's surprise, Gauss replied with the correct answer of 5050 in a vastly faster time than expect",
    "links": [
      "(2) Pallas",
      "2 Pallas",
      "7 Iris",
      "Aberration (astronomy)",
      "Abraham Gotthelf Kästner",
      "Accademia nazionale delle scienze",
      "Achromatic lens",
      "Acta Arithmetica",
      "Actuarial science",
      "Adolph Theodor Kupffer",
      "Adrien-Marie Legendre",
      "Albanifriedhof",
      "Alessandro Volta",
      "Alexander Graham Bell",
      "Alexander Ostrowski",
      "Alexander von Humboldt",
      "Allgemeine Deutsche Biographie",
      "Altitude (triangle)",
      "Altona, Hamburg",
      "American Academy of Arts and Sciences",
      "American Fur Company",
      "American Mathematical Monthly",
      "American Philosophical Society",
      "Ampere",
      "Analytic function",
      "Ancient Greece",
      "Anders Celsius",
      "Anders Jonas Ångström",
      "André-Marie Ampère",
      "Angle",
      "Angstrom",
      "Annals of Statistics",
      "Antoine César Becquerel",
      "Applied mathematics",
      "ArXiv (identifier)",
      "Arc measurement",
      "Archive for History of Exact Sciences",
      "Arithmetic-geometric mean",
      "Arithmetic–geometric mean",
      "Astley Cooper",
      "Astronomer",
      "Astronomical nutation",
      "Astronomische Nachrichten",
      "Astrophysics Data System",
      "August Ferdinand Möbius",
      "August Ritter (civil engineer)",
      "Austrian Academy of Sciences",
      "Austrian Empire",
      "Axiom",
      "Axonometry"
    ],
    "categories": [
      "Category:1777 births",
      "Category:1855 deaths",
      "Category:18th-century German astronomers",
      "Category:18th-century German mathematicians",
      "Category:18th-century German physicists",
      "Category:19th-century German astronomers",
      "Category:19th-century German inventors",
      "Category:19th-century German mathematicians",
      "Category:19th-century German physicists",
      "Category:Academic staff of the University of Göttingen"
    ]
  },
  "Composite number": {
    "title": "Composite number",
    "url": "https://en.wikipedia.org/wiki/Composite_number",
    "summary": "A composite number is a positive integer that can be formed by multiplying two smaller positive integers. Accordingly it is a positive integer that has at least one divisor other than 1 and itself. Every positive integer is composite, prime, or the unit 1, so the composite numbers are exactly the numbers that are not prime and not a unit. E.g., the integer 14 is a composite number because it is the product of the two smaller integers 2 × 7 but the integers 2 and 3 are not because each can only be divided by one and itself.\nThe composite numbers up to 150 are:\n\n4, 6, 8, 9, 10, 12, 14, 15, 16, 18, 20, 21, 22, 24, 25, 26, 27, 28, 30, 32, 33, 34, 35, 36, 38, 39, 40, 42, 44, 45, 46, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 60, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 75, 76, 77, 78, 80, 81, 82, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 102, 104, 105, 106, 108, 110, 111, 112, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 132, 133, 134, 135, ",
    "content": "A composite number is a positive integer that can be formed by multiplying two smaller positive integers. Accordingly it is a positive integer that has at least one divisor other than 1 and itself. Every positive integer is composite, prime, or the unit 1, so the composite numbers are exactly the numbers that are not prime and not a unit. E.g., the integer 14 is a composite number because it is the product of the two smaller integers 2 × 7 but the integers 2 and 3 are not because each can only be divided by one and itself.\nThe composite numbers up to 150 are:\n\n4, 6, 8, 9, 10, 12, 14, 15, 16, 18, 20, 21, 22, 24, 25, 26, 27, 28, 30, 32, 33, 34, 35, 36, 38, 39, 40, 42, 44, 45, 46, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 60, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 75, 76, 77, 78, 80, 81, 82, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 102, 104, 105, 106, 108, 110, 111, 112, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 132, 133, 134, 135, 136, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 150. (sequence A002808 in the OEIS)\nEvery composite number can be written as the product of two or more (not necessarily distinct) primes. For example, the composite number 299 can be written as 13 × 23, and the composite number 360 can be written as 23 × 32 × 5; furthermore, this representation is unique up to the order of the factors. This fact is called the fundamental theorem of arithmetic.\nThere are several known primality tests that can determine whether a number is prime or composite which do not necessarily reveal the factorization of a composite input.\n\nTypes\nOne way to classify composite numbers is by counting the number of prime factors. A composite number with two prime factors is a semiprime or 2-almost prime (the factors need not be distinct, hence squares of primes are included). A composite number with three distinct prime factors is a sphenic number. In some applications, it is necessary to differentiate between composite numbers with an odd number of distinct prime factors and those with an even number of distinct prime factors. For the latter \n\n  \n    \n      \n        μ\n        (\n        n\n        )\n        =\n        (\n        −\n        1\n        \n          )\n          \n            2\n            x\n          \n        \n        =\n        1\n      \n    \n    {\\displaystyle \\mu (n)=(-1)^{2x}=1}\n  \n\n(where μ is the Möbius function and x is half the total of prime factors), while for the former\n\n  \n    \n      \n        μ\n        (\n        n\n        )\n        =\n        (\n        −\n        1\n        \n          )\n          \n            2\n            x\n            +\n            1\n          \n        \n        =\n        −\n        1.\n      \n    \n    {\\displaystyle \\mu (n)=(-1)^{2x+1}=-1.}\n  \n\nHowever, for prime numbers, the function also returns −1 and \n  \n    \n      \n        μ\n        (\n        1\n        )\n        =\n        1\n      \n    \n    {\\displaystyle \\mu (1)=1}\n  \n. For a number n with one or more repeated prime factors,\n\n  \n    \n      \n        μ\n        (\n        n\n        )\n        =\n        0\n      \n    \n    {\\displaystyle \\mu (n)=0}\n  \n.\nIf all the prime factors of a number are repeated it is called a powerful number (All perfect powers are powerful numbers). If none of its prime factors are repeated, it is called squarefree. (All prime numbers and 1 are squarefree.)\nFor example, 72 = 23 × 32, all the prime factors are repeated, so 72 is a powerful number. 42 = 2 × 3 × 7, none of the prime factors are repeated, so 42 is squarefree.\n\nAnother way to classify composite numbers is by counting the number of divisors. All composite numbers have at least three divisors. In the case of squares of primes, those divisors are \n  \n    \n      \n        {\n        1\n        ,\n        p\n        ,\n        \n          p\n          \n            2\n          \n        \n        }\n      \n    \n    {\\displaystyle \\{1,p,p^{2}\\}}\n  \n. A number n that has more divisors than any x < n is a highly composite number (though the first two such numbers are 1 and 2).\nComposite numbers have also been called \"rectangular numbers\", but that name can also refer to the pronic numbers, numbers that are the product of two consecutive integers.\nYet another way to classify composite numbers is to determine whether all prime factors are either all below or all above some fixed (prime) number. Such numbers are called smooth numbers and rough numbers, respectively.\n\nSee also\nCanonical representation of a positive integer\nInteger factorization\nSieve of Eratosthenes\nTable of prime factors\n\nNotes\nReferences\nFraleigh, John B. (1976), A First Course In Abstract Algebra (2nd ed.), Reading: Addison-Wesley, ISBN 0-201-01984-1\nHerstein, I. N. (1964), Topics In Algebra, Waltham: Blaisdell Publishing Company, ISBN 978-1114541016 {{citation}}: ISBN / Date incompatibility (help)\nLong, Calvin T. (1972), Elementary Introduction to Number Theory (2nd ed.), Lexington: D. C. Heath and Company, LCCN 77-171950\nMcCoy, Neal H. (1968)",
    "links": [
      "299 (number)",
      "360 (number)",
      "42 (number)",
      "72 (number)",
      "Abundant number",
      "Achilles number",
      "Addison-Wesley",
      "Additive persistence",
      "Aliquot sequence",
      "Allyn and Bacon",
      "Almost perfect number",
      "Almost prime",
      "Amenable number",
      "Amicable numbers",
      "Amicable triple",
      "Arithmetic dynamics",
      "Arithmetic function",
      "Arithmetic number",
      "Aronson's sequence",
      "Automorphic number",
      "Ban number",
      "Bell number",
      "Betrothed numbers",
      "Binary number",
      "Blaisdell Publishing Company",
      "Blum integer",
      "Cake number",
      "Canonical representation of a positive integer",
      "Carmichael number",
      "Catalan number",
      "Catalan pseudoprime",
      "Centered cube number",
      "Centered decagonal number",
      "Centered dodecahedral number",
      "Centered heptagonal number",
      "Centered hexagonal number",
      "Centered icosahedral number",
      "Centered nonagonal number",
      "Centered octagonal number",
      "Centered octahedral number",
      "Centered pentagonal number",
      "Centered polygonal number",
      "Centered polyhedral number",
      "Centered square number",
      "Centered tetrahedral number",
      "Centered triangular number",
      "Colossally abundant number",
      "Congruent number",
      "Cube (algebra)",
      "Cuisenaire rods"
    ],
    "categories": [
      "Category:Arithmetic",
      "Category:Articles with short description",
      "Category:CS1 errors: ISBN date",
      "Category:Elementary number theory",
      "Category:Integer sequences",
      "Category:Prime numbers",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Computational number theory": {
    "title": "Computational number theory",
    "url": "https://en.wikipedia.org/wiki/Computational_number_theory",
    "summary": "In mathematics and computer science, computational number theory, also known as algorithmic number theory, is the study of \ncomputational methods for investigating and solving problems in number theory and arithmetic geometry, including algorithms for primality testing and integer factorization, finding solutions to diophantine equations, and explicit methods in arithmetic geometry.\nComputational number theory has applications to cryptography, including RSA, elliptic curve cryptography and post-quantum cryptography, and is used to investigate conjectures and open problems in number theory, including the Riemann hypothesis, the Birch and Swinnerton-Dyer conjecture, the ABC conjecture, the modularity conjecture, the Sato-Tate conjecture, and explicit aspects of the Langlands program.",
    "content": "In mathematics and computer science, computational number theory, also known as algorithmic number theory, is the study of \ncomputational methods for investigating and solving problems in number theory and arithmetic geometry, including algorithms for primality testing and integer factorization, finding solutions to diophantine equations, and explicit methods in arithmetic geometry.\nComputational number theory has applications to cryptography, including RSA, elliptic curve cryptography and post-quantum cryptography, and is used to investigate conjectures and open problems in number theory, including the Riemann hypothesis, the Birch and Swinnerton-Dyer conjecture, the ABC conjecture, the modularity conjecture, the Sato-Tate conjecture, and explicit aspects of the Langlands program.\n\nSoftware packages\nMagma computer algebra system\nSageMath\nNumber Theory Library\nPARI/GP\nFast Library for Number Theory\n\nFurther reading\nMichael E. Pohst (1993): Computational Algebraic Number Theory, Springer, ISBN 978-3-0348-8589-8\nEric Bach; Jeffrey Shallit (1996). Algorithmic Number Theory, Volume 1: Efficient Algorithms. MIT Press. ISBN 0-262-02405-5.\nDavid M. Bressoud (1989). Factorisation and Primality Testing. Springer-Verlag. ISBN 0-387-97040-1.\nJoe P. Buhler; Peter Stevenhagen, eds. (2008). Algorithmic Number Theory: Lattices, Number Fields, Curves and Cryptography. MSRI Publications. Vol. 44. Cambridge University Press. ISBN 978-0-521-20833-8. Zbl 1154.11002.\nHenri Cohen (1993). A Course In Computational Algebraic Number Theory. Graduate Texts in Mathematics. Vol. 138. Springer-Verlag. doi:10.1007/978-3-662-02945-9. ISBN 0-387-55640-0.\nHenri Cohen (2000). Advanced Topics in Computational Number Theory. Graduate Texts in Mathematics. Vol. 193. Springer-Verlag. doi:10.1007/978-1-4419-8489-0. ISBN 0-387-98727-4.\nHenri Cohen (2007). Number Theory – Volume I: Tools and Diophantine Equations. Graduate Texts in Mathematics. Vol. 239. Springer-Verlag. doi:10.1007/978-0-387-49923-9. ISBN 978-0-387-49922-2.\nHenri Cohen (2007). Number Theory – Volume II: Analytic and Modern Tools. Graduate Texts in Mathematics. Vol. 240. Springer-Verlag. doi:10.1007/978-0-387-49894-2. ISBN 978-0-387-49893-5.\nRichard Crandall; Carl Pomerance (2001). Prime Numbers: A Computational Perspective. Springer-Verlag. doi:10.1007/978-1-4684-9316-0. ISBN 0-387-94777-9.\nHans Riesel (1994). Prime Numbers and Computer Methods for Factorization. Progress in Mathematics. Vol. 126 (second ed.). Birkhäuser. ISBN 0-8176-3743-5. Zbl 0821.11001.\nVictor Shoup (2012). A Computational Introduction to Number Theory and Algebra. Cambridge University Press. doi:10.1017/CBO9781139165464. ISBN 9781139165464.\nSamuel S. Wagstaff, Jr. (2013). The Joy of Factoring. American Mathematical Society. ISBN 978-1-4704-1048-3.\nPeter Giblin (1993): Primes and Programming: An Introduction to Number Theory with Computing, Cambridge University Press, ISBN 0-521-40988-8\nNigel P. Smart (1998): The Algorithmic Resolution of Diophantine Equations, Cambridge University Press, ISBN 0-521-64633-2\nRamanujachary Kumanduri and Cristina Romero (1998): Number Theory with Computer Applications, Prentice Hall, ISBN 0-13-801812-X\nFernando Rodriguez Villegas (2007): Experimental Number Theory, Oxford University Press, ISBN 978-0-19-922730-3\nHarold M. Edwards (2008): Higher Arithmetic: An Algorithmic Introduction to Number Theory, American Mathematical Society, ISBN 978-1-4704-2153-3\nLasse Rempe-Gillen and Rebecca Waldecker (2014). Primality Testing for Beginners. American Mathematical Society. ISBN 978-0-8218-9883-3\n\nReferences\nExternal links\n Media related to Computational number theory at Wikimedia Commons",
    "links": [
      "0",
      "1",
      "ABC conjecture",
      "AF+BG theorem",
      "AKS primality test",
      "Abel–Jacobi map",
      "Acnode",
      "Additive number theory",
      "Adleman–Pomerance–Rumely primality test",
      "Ak singularity",
      "Algebraic curve",
      "Algebraic number",
      "Algebraic number theory",
      "Algorithm",
      "Anabelian geometry",
      "Analytic number theory",
      "Ancient Egyptian multiplication",
      "Arakelov theory",
      "Arithmetic",
      "Arithmetic combinatorics",
      "Arithmetic dynamics",
      "Arithmetic function",
      "Arithmetic geometry",
      "Arithmetic topology",
      "Baby-step giant-step",
      "Baillie–PSW primality test",
      "Belyi's theorem",
      "Berlekamp–Rabin algorithm",
      "Binary GCD algorithm",
      "Binary division",
      "Birch and Swinnerton-Dyer conjecture",
      "Birkhoff–Grothendieck theorem",
      "Bitangent",
      "Bolza surface",
      "Brill–Noether theory",
      "Bring's curve",
      "Bézout's theorem",
      "Cambridge University Press",
      "Carl Pomerance",
      "Cayley–Bacharach theorem",
      "Chakravala method",
      "Chinese remainder theorem",
      "Chunking (division)",
      "Cipolla's algorithm",
      "Class field theory",
      "Clifford's theorem on special divisors",
      "Compact Riemann surface",
      "Composite number",
      "Computation",
      "Computer science"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Commons category link from Wikidata",
      "Category:Computational fields of study",
      "Category:Computational number theory",
      "Category:Number theory",
      "Category:Short description matches Wikidata"
    ]
  },
  "Dirichlet character": {
    "title": "Dirichlet character",
    "url": "https://en.wikipedia.org/wiki/Dirichlet_character",
    "summary": "In analytic number theory and related branches of mathematics, a complex-valued arithmetic function  \n  \n    \n      \n        χ\n        :\n        \n          Z\n        \n        →\n        \n          C\n        \n      \n    \n    {\\displaystyle \\chi :\\mathbb {Z} \\rightarrow \\mathbb {C} }\n  \n is a Dirichlet character of modulus \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n  \n (where \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n  \n is a positive integer) if for all integers \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n and \n  \n    \n      \n        b\n      \n    \n    {\\displaystyle b}\n  \n:\n\n  \n    \n      \n        χ\n        (\n        a\n        b\n        )\n        =\n        χ\n        (\n        a\n        )\n        χ\n        (\n        b\n        )\n        ;\n      \n    \n    {\\displaystyle \\chi (ab)=\\chi (a)\\chi (b);}\n  \n that is, \n  \n    \n      \n        χ\n      \n    \n    {\\displaystyle \\chi }\n  \n is completely multiplicative.\n\n  \n    \n      \n        χ\n    ",
    "content": "In analytic number theory and related branches of mathematics, a complex-valued arithmetic function  \n  \n    \n      \n        χ\n        :\n        \n          Z\n        \n        →\n        \n          C\n        \n      \n    \n    {\\displaystyle \\chi :\\mathbb {Z} \\rightarrow \\mathbb {C} }\n  \n is a Dirichlet character of modulus \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n  \n (where \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n  \n is a positive integer) if for all integers \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n and \n  \n    \n      \n        b\n      \n    \n    {\\displaystyle b}\n  \n:\n\n  \n    \n      \n        χ\n        (\n        a\n        b\n        )\n        =\n        χ\n        (\n        a\n        )\n        χ\n        (\n        b\n        )\n        ;\n      \n    \n    {\\displaystyle \\chi (ab)=\\chi (a)\\chi (b);}\n  \n that is, \n  \n    \n      \n        χ\n      \n    \n    {\\displaystyle \\chi }\n  \n is completely multiplicative.\n\n  \n    \n      \n        χ\n        (\n        a\n        )\n        \n          \n            {\n            \n              \n                \n                  =\n                  0\n                \n                \n                  \n                    if \n                  \n                  gcd\n                  (\n                  a\n                  ,\n                  m\n                  )\n                  >\n                  1\n                \n              \n              \n                \n                  ≠\n                  0\n                \n                \n                  \n                    if \n                  \n                  gcd\n                  (\n                  a\n                  ,\n                  m\n                  )\n                  =\n                  1.\n                \n              \n            \n            \n          \n        \n      \n    \n    {\\displaystyle \\chi (a){\\begin{cases}=0&{\\text{if }}\\gcd(a,m)>1\\\\\\neq 0&{\\text{if }}\\gcd(a,m)=1.\\end{cases}}}\n  \n  (gcd is the greatest common divisor)\n\n  \n    \n      \n        χ\n        (\n        a\n        +\n        m\n        )\n        =\n        χ\n        (\n        a\n        )\n      \n    \n    {\\displaystyle \\chi (a+m)=\\chi (a)}\n  \n; that is, \n  \n    \n      \n        χ\n      \n    \n    {\\displaystyle \\chi }\n  \n is periodic with period \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n  \n.\nThe simplest possible character, called the principal character, usually denoted \n  \n    \n      \n        \n          χ\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\chi _{0}}\n  \n, (see Notation below) exists for all moduli:\n\n  \n    \n      \n        \n          χ\n          \n            0\n          \n        \n        (\n        a\n        )\n        =\n        \n          \n            {\n            \n              \n                \n                  0\n                \n                \n                  \n                    if \n                  \n                  gcd\n                  (\n                  a\n                  ,\n                  m\n                  )\n                  >\n                  1\n                \n              \n              \n                \n                  1\n                \n                \n                  \n                    if \n                  \n                  gcd\n                  (\n                  a\n                  ,\n                  m\n                  )\n                  =\n                  1.\n                \n              \n            \n            \n          \n        \n      \n    \n    {\\displaystyle \\chi _{0}(a)={\\begin{cases}0&{\\text{if }}\\gcd(a,m)>1\\\\1&{\\text{if }}\\gcd(a,m)=1.\\end{cases}}}\n  \n\nThe German mathematician Peter Gustav Lejeune Dirichlet—for whom the character is named—introduced these functions in his 1837 paper on primes in arithmetic progressions.\n\nNotation\nϕ\n        (\n        n\n        )\n      \n    \n    {\\displaystyle \\phi (n)}\n  \n is Euler's totient function.\n\n  \n    \n      \n        \n          ζ\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\zeta _{n}}\n  \n is a complex primitive n-th root of unity:\n\n  \n    \n      \n        \n          ζ\n          \n            n\n          \n          \n            n\n          \n        \n        =\n        1\n        ,\n      \n    \n    {\\displaystyle \\zeta _{n}^{n}=1,}\n  \n but \n  \n    \n      \n        \n          ζ\n          \n            n\n          \n        \n        ≠\n        1\n        ,\n        \n          ζ\n          \n            n\n          \n          \n            2\n          \n        \n        ≠\n        1\n        ,\n        .\n        .\n        .\n        \n          ζ\n          \n            n\n          \n          \n            n\n            −\n            1\n          \n        \n        ≠\n        1.\n      \n    \n    {\\displaystyle \\zeta _{n}\\neq 1,\\zeta _{n}^{2}\\neq 1,...\\zeta _{n}^{n-1}\\neq 1.}\n  \n\n  \n    \n      \n        (\n        \n          Z\n        \n        \n          /\n        \n        m\n        \n          Z\n        \n        \n          )\n          \n        ",
    "links": [
      "Abelian group",
      "Analytic number theory",
      "Analytically continued",
      "ArXiv (identifier)",
      "Arithmetic function",
      "Bibcode (identifier)",
      "Brian Conrey",
      "Character (mathematics)",
      "Character group",
      "Character sum",
      "Chi (letter)",
      "Chinese remainder theorem",
      "Class number (number theory)",
      "Class number formula",
      "Completely multiplicative function",
      "Complex conjugate",
      "Constructible number",
      "Coprime",
      "Cusp form",
      "Cyclic group",
      "Cyclotomic field",
      "Dirichlet's theorem on arithmetic progressions",
      "Dirichlet-multinomial distribution",
      "Dirichlet L-function",
      "Dirichlet convolution",
      "Dirichlet distribution",
      "Dirichlet integral",
      "Dirichlet problem",
      "Dirichlet process",
      "Dirichlet series",
      "Doi (identifier)",
      "Eisenstein integer",
      "Entire function",
      "Euler's theorem",
      "Euler's totient function",
      "Fourier transform on finite groups",
      "Fundamental discriminant",
      "Gauss sum",
      "Gaussian integer",
      "Greatest common divisor",
      "Group (mathematics)",
      "Harold Davenport",
      "Homomorphism",
      "ISBN (identifier)",
      "Indicator function",
      "Irregular prime",
      "Isomorphism",
      "Jacobi sum",
      "Kloosterman sum",
      "Kronecker symbol"
    ],
    "categories": [
      "Category:Analytic number theory",
      "Category:Articles with short description",
      "Category:Short description is different from Wikidata",
      "Category:Zeta and L-functions"
    ]
  },
  "Classical field theory": {
    "title": "Classical field theory",
    "url": "https://en.wikipedia.org/wiki/Classical_field_theory",
    "summary": "A classical field theory is a physical theory that predicts how one or more fields in physics interact with matter through field equations, without considering effects of quantization; theories that incorporate quantum mechanics are called quantum field theories. In most contexts, 'classical field theory' is specifically intended to describe electromagnetism and gravitation, two of the fundamental forces of nature.\nA physical field can be thought of as the assignment of a physical quantity at each point of space and time. For example, in a weather forecast, the wind velocity during a day over a country is described by assigning a vector to each point in space. Each vector represents the direction of the movement of air at that point, so the set of all wind vectors in an area at a given point in time constitutes a vector field. As the day progresses, the directions in which the vectors point change as the directions of the wind change.\nThe first field theories, Newtonian gravitation and",
    "content": "A classical field theory is a physical theory that predicts how one or more fields in physics interact with matter through field equations, without considering effects of quantization; theories that incorporate quantum mechanics are called quantum field theories. In most contexts, 'classical field theory' is specifically intended to describe electromagnetism and gravitation, two of the fundamental forces of nature.\nA physical field can be thought of as the assignment of a physical quantity at each point of space and time. For example, in a weather forecast, the wind velocity during a day over a country is described by assigning a vector to each point in space. Each vector represents the direction of the movement of air at that point, so the set of all wind vectors in an area at a given point in time constitutes a vector field. As the day progresses, the directions in which the vectors point change as the directions of the wind change.\nThe first field theories, Newtonian gravitation and Maxwell's equations of electromagnetic fields were developed in classical physics before the advent of relativity theory in 1905, and had to be revised to be consistent with that theory. Consequently, classical field theories are usually categorized as non-relativistic and relativistic. Modern field theories are usually expressed using the mathematics of tensor calculus. A more recent alternative mathematical formalism describes classical fields as sections of mathematical objects called fiber bundles.\n\nHistory\nMichael Faraday coined the term \"field\" and lines of forces to explain electric and magnetic phenomena. Lord Kelvin in 1851 formalized the concept of field in different areas of physics.\n\nNon-relativistic field theories\nSome of the simplest physical fields are vector force fields. Historically, the first time that fields were taken seriously was with Faraday's lines of force when describing the electric field. The gravitational field was then similarly described.\n\nNewtonian gravitation\nThe first field theory of gravity was Newton's theory of gravitation in which the mutual interaction between two masses obeys an inverse square law. This was very useful for predicting the motion of planets around the Sun.\nAny massive body M has a gravitational field g which describes its influence on other massive bodies. The gravitational field of M at a point r in space is found by determining the force F that M exerts on a small test mass m located at r, and then dividing by m:\n\n  \n    \n      \n        \n          g\n        \n        (\n        \n          r\n        \n        )\n        =\n        \n          \n            \n              \n                F\n              \n              (\n              \n                r\n              \n              )\n            \n            m\n          \n        \n        .\n      \n    \n    {\\displaystyle \\mathbf {g} (\\mathbf {r} )={\\frac {\\mathbf {F} (\\mathbf {r} )}{m}}.}\n  \n\nStipulating that m is much smaller than M ensures that the presence of m has a negligible influence on the behavior of M.\nAccording to Newton's law of universal gravitation, F(r) is given by\n\n  \n    \n      \n        \n          F\n        \n        (\n        \n          r\n        \n        )\n        =\n        −\n        \n          \n            \n              G\n              M\n              m\n            \n            \n              r\n              \n                2\n              \n            \n          \n        \n        \n          \n            \n              \n                r\n              \n              ^\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle \\mathbf {F} (\\mathbf {r} )=-{\\frac {GMm}{r^{2}}}{\\hat {\\mathbf {r} }},}\n  \n\nwhere \n  \n    \n      \n        \n          \n            \n              \n                r\n              \n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\hat {\\mathbf {r} }}}\n  \n is a unit vector pointing along the line from M to m, and G is Newton's gravitational constant. Therefore, the gravitational field of M is\n\n  \n    \n      \n        \n          g\n        \n        (\n        \n          r\n        \n        )\n        =\n        \n          \n            \n              \n                F\n              \n              (\n              \n                r\n              \n              )\n            \n            m\n          \n        \n        =\n        −\n        \n          \n            \n              G\n              M\n            \n            \n              r\n              \n                2\n              \n            \n          \n        \n        \n          \n            \n              \n                r\n              \n              ^\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\mathbf {g} (\\mathbf {r} )={\\frac {\\mathbf {F} (\\mathbf {r} )}{m}}=-{\\frac {GM}{r^{2}}}{\\hat {\\mathbf {r} }}.}\n  \n\nThe experimental observation that inertial mass and gravitational mass are equal to unprecedented levels of accuracy leads to the identification of the gravitati",
    "links": [
      "Acceleration",
      "Action (physics)",
      "Action principle",
      "Affine connection",
      "Albert Einstein",
      "Alexis Clairaut",
      "Algebra of physical space",
      "Algebraic structure",
      "Algorithm",
      "Algorithm design",
      "Analysis of algorithms",
      "Analytical mechanics",
      "Angular acceleration",
      "Angular displacement",
      "Angular frequency",
      "Angular momentum",
      "Angular velocity",
      "Appell's equation of motion",
      "Applied mathematics",
      "Applied mechanics",
      "Approximation theory",
      "ArXiv (identifier)",
      "Arthur Eddington",
      "Augustin-Louis Cauchy",
      "Automata theory",
      "Automated theorem proving",
      "Bernard Koopman",
      "Bianchi identity",
      "Bibcode (identifier)",
      "Biot–Savart law",
      "Bo Thidé",
      "Bosonic string theory",
      "Calculus of variations",
      "Carl Gustav Jacob Jacobi",
      "Celestial mechanics",
      "Centrifugal force",
      "Centripetal force",
      "Chaos theory",
      "Charge density",
      "Christiaan Huygens",
      "Circular motion",
      "Classical mechanics",
      "Classical physics",
      "Classical unified field theories",
      "Clifford Truesdell",
      "Clifford algebra",
      "Clifford analysis",
      "Coding theory",
      "Combinatorics",
      "Computational geometry"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1: long volume value",
      "Category:Classical field theory",
      "Category:Equations",
      "Category:Lagrangian mechanics",
      "Category:Mathematical physics",
      "Category:Short description matches Wikidata"
    ]
  },
  "Clifford analysis": {
    "title": "Clifford analysis",
    "url": "https://en.wikipedia.org/wiki/Clifford_analysis",
    "summary": "Clifford analysis, using Clifford algebras named after William Kingdon Clifford, is the study of Dirac operators, and Dirac type operators in analysis and geometry, together with their applications. Examples of Dirac type operators include, but are not limited to, the Hodge–Dirac operator, \n  \n    \n      \n        d\n        +\n        \n          ⋆\n        \n        d\n        \n          ⋆\n        \n      \n    \n    {\\displaystyle d+{\\star }d{\\star }}\n  \n on a Riemannian manifold, the Dirac operator in euclidean space and its inverse on \n  \n    \n      \n        \n          C\n          \n            0\n          \n          \n            ∞\n          \n        \n        (\n        \n          \n            R\n          \n          \n            n\n          \n        \n        )\n      \n    \n    {\\displaystyle C_{0}^{\\infty }(\\mathbf {R} ^{n})}\n  \n and their conformal equivalents on the sphere, the Laplacian in euclidean n-space and the Atiyah–Singer–Dirac operator on a spin manifold, Rarita–Schwinger/Stein–Weis",
    "content": "Clifford analysis, using Clifford algebras named after William Kingdon Clifford, is the study of Dirac operators, and Dirac type operators in analysis and geometry, together with their applications. Examples of Dirac type operators include, but are not limited to, the Hodge–Dirac operator, \n  \n    \n      \n        d\n        +\n        \n          ⋆\n        \n        d\n        \n          ⋆\n        \n      \n    \n    {\\displaystyle d+{\\star }d{\\star }}\n  \n on a Riemannian manifold, the Dirac operator in euclidean space and its inverse on \n  \n    \n      \n        \n          C\n          \n            0\n          \n          \n            ∞\n          \n        \n        (\n        \n          \n            R\n          \n          \n            n\n          \n        \n        )\n      \n    \n    {\\displaystyle C_{0}^{\\infty }(\\mathbf {R} ^{n})}\n  \n and their conformal equivalents on the sphere, the Laplacian in euclidean n-space and the Atiyah–Singer–Dirac operator on a spin manifold, Rarita–Schwinger/Stein–Weiss type operators, conformal Laplacians, spinorial Laplacians and Dirac operators on SpinC manifolds, systems of Dirac operators, the Paneitz operator, Dirac operators on hyperbolic space, the hyperbolic Laplacian and Weinstein equations.\n\nEuclidean space\nIn Euclidean space the Dirac operator has the form\n\n  \n    \n      \n        D\n        =\n        \n          ∑\n          \n            j\n            =\n            1\n          \n          \n            n\n          \n        \n        \n          e\n          \n            j\n          \n        \n        \n          \n            ∂\n            \n              ∂\n              \n                x\n                \n                  j\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle D=\\sum _{j=1}^{n}e_{j}{\\frac {\\partial }{\\partial x_{j}}}}\n  \n\nwhere e1, ..., en is an orthonormal basis for Rn, and Rn is considered to be embedded in a complex Clifford algebra, Cln(C) so that ej2 = −1.\nThis gives\n\n  \n    \n      \n        \n          D\n          \n            2\n          \n        \n        =\n        −\n        \n          Δ\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle D^{2}=-\\Delta _{n}}\n  \n\nwhere Δn is the Laplacian in n-euclidean space.\nThe fundamental solution to the euclidean Dirac operator is \n\n  \n    \n      \n        G\n        (\n        x\n        −\n        y\n        )\n        :=\n        \n          \n            1\n            \n              ω\n              \n                n\n              \n            \n          \n        \n        \n          \n            \n              x\n              −\n              y\n            \n            \n              ‖\n              x\n              −\n              y\n              \n                ‖\n                \n                  n\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle G(x-y):={\\frac {1}{\\omega _{n}}}{\\frac {x-y}{\\|x-y\\|^{n}}}}\n  \n\nwhere ωn is the surface area of the unit sphere Sn−1.\nNote that \n\n  \n    \n      \n        D\n        \n          \n            1\n            \n              (\n              n\n              −\n              2\n              )\n              \n                ω\n                \n                  n\n                \n              \n              ‖\n              x\n              −\n              y\n              \n                ‖\n                \n                  n\n                  −\n                  2\n                \n              \n            \n          \n        \n        =\n        G\n        (\n        x\n        −\n        y\n        )\n      \n    \n    {\\displaystyle D{\\frac {1}{(n-2)\\omega _{n}\\|x-y\\|^{n-2}}}=G(x-y)}\n  \n\nwhere \n\n  \n    \n      \n        \n          \n            1\n            \n              (\n              n\n              −\n              2\n              )\n              \n              \n                ω\n                \n                  n\n                \n              \n              \n              ‖\n              x\n              −\n              y\n              \n                ‖\n                \n                  n\n                  −\n                  2\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {1}{(n-2)\\;\\omega _{n}\\;\\|x-y\\|^{n-2}}}}\n  \n\nis the fundamental solution to Laplace's equation for n ≥ 3.\nThe most basic example of a Dirac operator is the Cauchy–Riemann operator \n\n  \n    \n      \n        \n          \n            ∂\n            \n              ∂\n              x\n            \n          \n        \n        +\n        i\n        \n          \n            ∂\n            \n              ∂\n              y\n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {\\partial }{\\partial x}}+i{\\frac {\\partial }{\\partial y}}}\n  \n\nin the complex plane. Indeed, many basic properties of one variable complex analysis follow through for many first order Dirac type operators. In euclidean space this includes a Cauchy Theorem, a Cauchy integral formula, Morera's theore",
    "links": [
      "Advances in Applied Clifford Algebras",
      "Algebra of physical space",
      "Algebraic structure",
      "Algorithm",
      "Algorithm design",
      "Almansi–Fischer decomposition",
      "American Mathematical Society",
      "Analysis of algorithms",
      "Analytical mechanics",
      "Antiautomorphism",
      "Applied mathematics",
      "Approximation theory",
      "Automata theory",
      "Automated theorem proving",
      "Bergman kernel",
      "Beurling–Ahlfors transform",
      "Bibcode (identifier)",
      "Bosonic string theory",
      "Boundary value problem",
      "CRC Press",
      "Calculus of variations",
      "Cauchy's theorem (geometry)",
      "Cauchy Riemann equations",
      "Cauchy integral formula",
      "Cauchy kernel",
      "Cauchy transform",
      "Cauchy–Kowalevski theorem",
      "Cauchy–Riemann operator",
      "Cayley transform",
      "Chaos theory",
      "Classic harmonic analysis",
      "Classical field theory",
      "Clifford Algebra",
      "Clifford algebra",
      "Clifford group",
      "Coding theory",
      "Combinatorics",
      "Complex analysis",
      "Complex spin structure",
      "Computational geometry",
      "Computational mathematics",
      "Computational number theory",
      "Computational statistics",
      "Computer algebra",
      "Conformal field theory",
      "Conformal manifold",
      "Conformally covariant",
      "Conformally flat manifold",
      "Constraint programming",
      "Constraint satisfaction problem"
    ],
    "categories": [
      "Category:All articles lacking in-text citations",
      "Category:Articles lacking in-text citations from April 2009",
      "Category:CS1: long volume value",
      "Category:CS1 maint: location missing publisher",
      "Category:Differential geometry"
    ]
  },
  "Computational statistics": {
    "title": "Computational statistics",
    "url": "https://en.wikipedia.org/wiki/Computational_statistics",
    "summary": "Computational statistics, or statistical computing, is the study which is the intersection of statistics and computer science, and refers to the statistical methods that are enabled by using computational methods. It is the area of computational science (or scientific computing) specific to the mathematical science of statistics. This area is fast developing. The view that the  broader concept of computing must be taught as part of general statistical education is gaining momentum.\nAs in traditional statistics the goal is to transform raw data into knowledge, but the focus lies on computer intensive statistical methods, such as cases with very large sample size and non-homogeneous data sets.\nThe terms 'computational statistics' and 'statistical computing' are often used interchangeably, although Carlo Lauro (a former president of the International Association for Statistical Computing) proposed making a distinction, defining 'statistical computing' as \"the application of computer scien",
    "content": "Computational statistics, or statistical computing, is the study which is the intersection of statistics and computer science, and refers to the statistical methods that are enabled by using computational methods. It is the area of computational science (or scientific computing) specific to the mathematical science of statistics. This area is fast developing. The view that the  broader concept of computing must be taught as part of general statistical education is gaining momentum.\nAs in traditional statistics the goal is to transform raw data into knowledge, but the focus lies on computer intensive statistical methods, such as cases with very large sample size and non-homogeneous data sets.\nThe terms 'computational statistics' and 'statistical computing' are often used interchangeably, although Carlo Lauro (a former president of the International Association for Statistical Computing) proposed making a distinction, defining 'statistical computing' as \"the application of computer science to statistics\",\nand 'computational statistics' as \"aiming at the design of algorithm for implementing\nstatistical methods on computers, including the ones unthinkable before the computer\nage (e.g. bootstrap, simulation), as well as to cope with analytically intractable problems\" [sic].\nThe term 'Computational statistics' may also be used to refer to computationally intensive statistical methods including resampling methods, Markov chain Monte Carlo methods, local regression, kernel density estimation, artificial neural networks and generalized additive models.\n\nHistory\nThough computational statistics is widely used today, it actually has a relatively short history of acceptance in the statistics community. For the most part, the founders of the field of statistics relied on mathematics and asymptotic approximations in the development of computational statistical methodology.\nIn 1908, William Sealy Gosset performed his now well-known Monte Carlo method simulation which led to the discovery of the Student’s t-distribution. With the help of computational methods, he also has plots of the empirical distributions overlaid on the corresponding theoretical distributions. The computer has revolutionized simulation and has made the replication of Gosset’s experiment little more than an exercise.\nLater on, the scientists put forward computational ways of generating pseudo-random deviates, performed methods to convert uniform deviates into other distributional forms using inverse cumulative distribution function or acceptance-rejection methods, and developed state-space methodology for Markov chain Monte Carlo. One of the first efforts to generate random digits in a fully automated way, was undertaken by the RAND Corporation in 1947. The tables produced were published as a book in 1955, and also as a series of punch cards.\nBy the mid-1950s, several articles and patents for devices had been proposed for random number generators. The development of these devices were motivated from the need to use random digits to perform simulations and other fundamental components in statistical analysis. One of the most well known of such devices is ERNIE, which produces random numbers that determine the winners of the Premium Bond, a lottery bond issued in the United Kingdom. In 1958, John Tukey’s jackknife was developed. It is as a method to reduce the bias of parameter estimates in samples under nonstandard conditions. This requires computers for practical implementations. To this point, computers have made many tedious statistical studies feasible.\n\nMethods\nMaximum likelihood estimation\nMaximum likelihood estimation is used to estimate the parameters of an assumed probability distribution, given some observed data. It is achieved by maximizing a likelihood function so that the observed data is most probable under the assumed statistical model.\n\nMonte Carlo method\nMonte Carlo is a statistical method that relies on repeated random sampling to obtain numerical results. The concept is to use randomness to solve problems that might be deterministic in principle. They are often used in physical and mathematical problems and are most useful when it is difficult to use other approaches. Monte Carlo methods are mainly used in three problem classes: optimization, numerical integration, and generating draws from a probability distribution.\n\nMarkov chain Monte Carlo\nThe Markov chain Monte Carlo method creates samples from a continuous random variable, with probability density proportional to a known function. These samples can be used to evaluate an integral over that variable, such as its expected value or variance. The more steps are included, the more closely the distribution of the sample matches the actual desired distribution.\n\nBootstrapping\nThe bootstrap is a resampling technique used to generate samples from an empirical probability distribution defined by an original sample of the population. It can be used to find a bootstrapped estimator of a popu",
    "links": [
      "A Million Random Digits with 100,000 Normal Deviates",
      "Algorithms for statistical classification",
      "ArXiv (identifier)",
      "Artificial neural networks",
      "Bias",
      "Biometrika",
      "Bootstrapping (statistics)",
      "Communications in Statistics",
      "Computational Statistics",
      "Computational Statistics & Data Analysis",
      "Computational Statistics (journal)",
      "Computational anatomy",
      "Computational astrophysics",
      "Computational biology",
      "Computational chemistry",
      "Computational cognition",
      "Computational economics",
      "Computational electromagnetics",
      "Computational engineering",
      "Computational finance",
      "Computational fluid dynamics",
      "Computational genomics",
      "Computational geophysics",
      "Computational lexicology",
      "Computational linguistics",
      "Computational materials science",
      "Computational mathematics",
      "Computational mechanics",
      "Computational neuroscience",
      "Computational particle physics",
      "Computational phylogenetics",
      "Computational physics",
      "Computational politics",
      "Computational psychometrics",
      "Computational science",
      "Computational semantics",
      "Computational semiotics",
      "Computational social science",
      "Computational sociology",
      "Computational thermodynamics",
      "Computational transportation science",
      "Computer",
      "Computer lab",
      "Computer science",
      "Cumulative distribution function",
      "Data journalism",
      "Data science",
      "Data set",
      "Deborah A. Nolan",
      "Deterministic system"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1 maint: numeric names: authors list",
      "Category:Computational fields of study",
      "Category:Computational statistics",
      "Category:Mathematics of computing",
      "Category:Numerical analysis",
      "Category:Short description matches Wikidata"
    ]
  },
  "Conformal field theory": {
    "title": "Conformal field theory",
    "url": "https://en.wikipedia.org/wiki/Conformal_field_theory",
    "summary": "A conformal field theory (CFT) is a quantum field theory that is invariant under conformal transformations. In two dimensions, there is an infinite-dimensional algebra of local conformal transformations, and conformal field theories can sometimes be exactly solved or classified.\nConformal field theory has important applications to condensed matter physics, statistical mechanics, quantum statistical mechanics, and  string theory. Statistical and condensed matter systems are indeed often conformally invariant at their thermodynamic or quantum critical points.",
    "content": "A conformal field theory (CFT) is a quantum field theory that is invariant under conformal transformations. In two dimensions, there is an infinite-dimensional algebra of local conformal transformations, and conformal field theories can sometimes be exactly solved or classified.\nConformal field theory has important applications to condensed matter physics, statistical mechanics, quantum statistical mechanics, and  string theory. Statistical and condensed matter systems are indeed often conformally invariant at their thermodynamic or quantum critical points.\n\nScale invariance vs conformal invariance\nIn quantum field theory, scale invariance is a common and natural symmetry, because any fixed point of the renormalization group is by definition scale invariant. Conformal symmetry is stronger than scale invariance, and one needs additional assumptions to argue that it should appear in nature. The basic idea behind its plausibility is that local scale invariant theories have their currents given by \n  \n    \n      \n        \n          T\n          \n            μ\n            ν\n          \n        \n        \n          ξ\n          \n            ν\n          \n        \n      \n    \n    {\\displaystyle T_{\\mu \\nu }\\xi ^{\\nu }}\n  \n where \n  \n    \n      \n        \n          ξ\n          \n            ν\n          \n        \n      \n    \n    {\\displaystyle \\xi ^{\\nu }}\n  \n is a Killing vector and \n  \n    \n      \n        \n          T\n          \n            μ\n            ν\n          \n        \n      \n    \n    {\\displaystyle T_{\\mu \\nu }}\n  \n is a conserved operator (the stress-tensor) of dimension exactly ⁠\n  \n    \n      \n        d\n      \n    \n    {\\displaystyle d}\n  \n⁠. For the associated symmetries to include scale but not conformal transformations, the trace \n  \n    \n      \n        \n          T\n          \n            μ\n          \n        \n        \n          \n\n          \n          \n            μ\n          \n        \n      \n    \n    {\\displaystyle T_{\\mu }{}^{\\mu }}\n  \n has to be a non-zero total derivative implying that there is a non-conserved operator of dimension exactly ⁠\n  \n    \n      \n        d\n        −\n        1\n      \n    \n    {\\displaystyle d-1}\n  \n⁠.\nUnder some assumptions it is possible to completely rule out this type of non-renormalization and hence prove that scale invariance implies conformal invariance in a quantum field theory, for example in unitary compact conformal field theories in two dimensions.\nWhile it is possible for a quantum field theory to be scale invariant  but not conformally invariant, examples are rare. For this reason, the terms are often used interchangeably in the context of quantum field theory.\n\nTwo dimensions vs higher dimensions\nThe number of independent conformal transformations is infinite in two dimensions, and finite in higher dimensions. This makes conformal symmetry much more constraining in two dimensions. All conformal field theories share the ideas and techniques of the conformal bootstrap. But the resulting equations are more powerful in two dimensions, where they are sometimes exactly solvable (for example in the case of minimal models), in contrast to higher dimensions, where numerical approaches dominate.\nThe development of conformal field theory has been earlier and deeper in the two-dimensional case, in particular after the 1983 article by Belavin, Polyakov and Zamolodchikov. \nThe term conformal field theory has sometimes been used with the meaning of two-dimensional conformal field theory, as in the title of a 1997 textbook.\nHigher-dimensional conformal field theories have become more popular with the AdS/CFT correspondence in the late 1990s, and the development of numerical conformal bootstrap techniques in the 2000s.\n\nGlobal vs local conformal symmetry in two dimensions\nThe global conformal group of the Riemann sphere is the group of Möbius transformations ⁠\n  \n    \n      \n        \n          \n            P\n            S\n            L\n          \n          \n            2\n          \n        \n        (\n        \n          C\n        \n        )\n      \n    \n    {\\displaystyle \\mathrm {PSL} _{2}(\\mathbb {C} )}\n  \n⁠, which is finite-dimensional. \nOn the other hand, infinitesimal conformal transformations form the infinite-dimensional Witt algebra: the conformal Killing equations in two dimensions, \n  \n    \n      \n        \n          ∂\n          \n            μ\n          \n        \n        \n          ξ\n          \n            ν\n          \n        \n        +\n        \n          ∂\n          \n            ν\n          \n        \n        \n          ξ\n          \n            μ\n          \n        \n        =\n        ∂\n        ⋅\n        ξ\n        \n          η\n          \n            μ\n            ν\n          \n        \n        ,\n         \n      \n    \n    {\\displaystyle \\partial _{\\mu }\\xi _{\\nu }+\\partial _{\\nu }\\xi _{\\mu }=\\partial \\cdot \\xi \\eta _{\\mu \\nu },~}\n  \n reduce to just the Cauchy-Riemann equations, ⁠\n  \n    \n      \n        \n          ∂\n          \n            \n              \n                z\n    ",
    "links": [
      "4D N = 1 global supersymmetry",
      "4D N = 1 supergravity",
      "6D (2,0) superconformal field theory",
      "ABJM superconformal field theory",
      "AdS/CFT correspondence",
      "Alexander Zamolodchikov",
      "Algebra of physical space",
      "Algebraic quantum field theory",
      "Algebraic structure",
      "Algorithm",
      "Algorithm design",
      "Analysis of algorithms",
      "Analytical mechanics",
      "Anti-de Sitter space",
      "Applied mathematics",
      "Approximation theory",
      "ArXiv (identifier)",
      "Automata theory",
      "Automated theorem proving",
      "Axiomatic quantum field theory",
      "BBGKY hierarchy",
      "BF model",
      "Banks-Zaks fixed point",
      "Bibcode (identifier)",
      "Boltzmann's entropy formula",
      "Boltzmann equation",
      "Boltzmann machine",
      "Born–Infeld model",
      "Bosonic string theory",
      "Boundary conformal field theory",
      "Bullough–Dodd model",
      "C-theorem",
      "Calculus of variations",
      "Cartan subalgebra",
      "Casimir effect",
      "Causality (physics)",
      "Chaos theory",
      "Chern–Simons theory",
      "Chiral model",
      "Classical field theory",
      "Clifford algebra",
      "Clifford analysis",
      "Coding theory",
      "Combinatorics",
      "Complex system",
      "Computational geometry",
      "Computational mathematics",
      "Computational number theory",
      "Computational statistics",
      "Computer algebra"
    ],
    "categories": [
      "Category:All articles with unsourced statements",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from May 2021",
      "Category:Commons category link from Wikidata",
      "Category:Conformal field theory",
      "Category:Mathematical physics",
      "Category:Scaling symmetries",
      "Category:Short description matches Wikidata",
      "Category:Symmetry",
      "Category:Wikipedia articles needing clarification from April 2023"
    ]
  },
  "Cryptography": {
    "title": "Cryptography",
    "url": "https://en.wikipedia.org/wiki/Cryptography",
    "summary": "Cryptography, or cryptology (from Ancient Greek: κρυπτός, romanized: kryptós \"hidden, secret\"; and γράφειν graphein, \"to write\", or -λογία -logia, \"study\", respectively), is the practice and study of techniques for secure communication in the presence of adversarial behavior. More generally, cryptography is about constructing and analyzing protocols that prevent third parties or the public from reading private messages. Modern cryptography exists at the intersection of the disciplines of mathematics, computer science, information security, electrical engineering, digital signal processing, physics, and others. Core concepts related to information security (data confidentiality, data integrity, authentication, and non-repudiation) are also central to cryptography. Practical applications of cryptography include electronic commerce, chip-based payment cards, digital currencies, computer passwords, and military communications.\nCryptography prior to the modern age was effectively synonymous",
    "content": "Cryptography, or cryptology (from Ancient Greek: κρυπτός, romanized: kryptós \"hidden, secret\"; and γράφειν graphein, \"to write\", or -λογία -logia, \"study\", respectively), is the practice and study of techniques for secure communication in the presence of adversarial behavior. More generally, cryptography is about constructing and analyzing protocols that prevent third parties or the public from reading private messages. Modern cryptography exists at the intersection of the disciplines of mathematics, computer science, information security, electrical engineering, digital signal processing, physics, and others. Core concepts related to information security (data confidentiality, data integrity, authentication, and non-repudiation) are also central to cryptography. Practical applications of cryptography include electronic commerce, chip-based payment cards, digital currencies, computer passwords, and military communications.\nCryptography prior to the modern age was effectively synonymous with encryption, converting readable information (plaintext) to unintelligible nonsense text (ciphertext), which can only be read by reversing the process (decryption). The sender of an encrypted (coded) message shares the decryption (decoding) technique only with the intended recipients to preclude access from adversaries. The cryptography literature often uses the names \"Alice\" (or \"A\") for the sender, \"Bob\" (or \"B\") for the intended recipient, and \"Eve\" (or \"E\") for the eavesdropping adversary. Since the development of rotor cipher machines in World War I and the advent of computers in World War II, cryptography methods have become increasingly complex and their applications more varied.\nModern cryptography is heavily based on mathematical theory and computer science practice; cryptographic algorithms are designed around computational hardness assumptions, making such algorithms hard to break in actual practice by any adversary. While it is theoretically possible to break into a well-designed system, it is infeasible in actual practice to do so. Such schemes, if well designed, are therefore termed \"computationally secure\". Theoretical advances (e.g., improvements in integer factorization algorithms) and faster computing technology require these designs to be continually reevaluated and, if necessary, adapted. Information-theoretically secure schemes that provably cannot be broken even with unlimited computing power, such as the one-time pad, are much more difficult to use in practice than the best theoretically breakable but computationally secure schemes.\nThe growth of cryptographic technology has raised a number of legal issues in the Information Age. Cryptography's potential for use as a tool for espionage and sedition has led many governments to classify it as a weapon and to limit or even prohibit its use and export. In some jurisdictions where the use of cryptography is legal, laws permit investigators to compel the disclosure of encryption keys for documents relevant to an investigation. Cryptography also plays a major role in digital rights management and copyright infringement disputes with regard to digital media.\n\nTerminology\nThe first use of the term \"cryptograph\" (as opposed to \"cryptogram\") dates back to the 19th century—originating from \"The Gold-Bug\", a story by Edgar Allan Poe.\nUntil modern times, cryptography referred almost exclusively to \"encryption\", which is the process of converting ordinary information (called plaintext) into an unintelligible form (called ciphertext). Decryption is the reverse, in other words, moving from the unintelligible ciphertext back to plaintext. A cipher (or cypher) is a pair of algorithms that carry out the encryption and the reversing decryption. The detailed operation of a cipher is controlled both by the algorithm and, in each instance, by a \"key\". The key is a secret (ideally known only to the communicants), usually a string of characters (ideally short so it can be remembered by the user), which is needed to decrypt the ciphertext. In formal mathematical terms, a \"cryptosystem\" is the ordered list of elements of finite possible plaintexts, finite possible cyphertexts, finite possible keys, and the encryption and decryption algorithms that correspond to each key. Keys are important both formally and in actual practice, as ciphers without variable keys can be trivially broken with only the knowledge of the cipher used and are therefore useless (or even counter-productive) for most purposes. Historically, ciphers were often used directly for encryption or decryption without additional procedures such as authentication or integrity checks.\nThere are two main types of cryptosystems: symmetric and asymmetric. In symmetric systems, the only ones known until the 1970s, the same secret key encrypts and decrypts a message. Data manipulation in symmetric systems is significantly faster than in asymmetric systems. Asymmetric systems use a \"public key\" to encrypt a message and a r",
    "links": [
      "-logy",
      "3-Way",
      "3-subset meet-in-the-middle attack",
      "A5/1",
      "A5/2",
      "AACS encryption key controversy",
      "AES instruction set",
      "ARIA (cipher)",
      "ARM architecture family",
      "A Greek-English Lexicon",
      "A History of US",
      "A Mathematical Theory of Communication",
      "Abstract algebra",
      "Abstract mathematics",
      "Achterbahn (stream cipher)",
      "Acoustic cryptanalysis",
      "Adi Shamir",
      "Adiantum (cipher)",
      "Advanced Encryption Standard",
      "Advanced Encryption Standard process",
      "Adversary (cryptography)",
      "Agent handling",
      "Agent provocateur",
      "Akelarre (cipher)",
      "Al-Khalil ibn Ahmad al-Farahidi",
      "Al-Kindi",
      "Alan Cox (computer programmer)",
      "Alberti Cipher Disk",
      "Algebraic Eraser",
      "Algorithm",
      "Alice and Bob",
      "All-source intelligence",
      "All Writs Act",
      "Alternating step generator",
      "Anagram",
      "Analysis of competing hypotheses",
      "Anchor Books",
      "Ancient Greece",
      "Ancient Greek",
      "Ancient Greek language",
      "Anubis (cipher)",
      "Apophenia",
      "Arabs",
      "Argon2",
      "Ascon (cipher)",
      "Asemic writing",
      "Asset (intelligence)",
      "Atbash",
      "Auguste Kerckhoffs",
      "Authenticated encryption"
    ],
    "categories": [
      "Category:All articles needing additional references",
      "Category:All articles to be expanded",
      "Category:All articles with unsourced statements",
      "Category:All articles with vague or ambiguous time",
      "Category:Applied mathematics",
      "Category:Articles containing Ancient Greek (to 1453)-language text",
      "Category:Articles needing additional references from March 2021",
      "Category:Articles to be expanded from December 2021",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from April 2016"
    ]
  },
  "Discrete geometry": {
    "title": "Discrete geometry",
    "url": "https://en.wikipedia.org/wiki/Discrete_geometry",
    "summary": "Discrete geometry and combinatorial geometry are branches of geometry that study combinatorial properties and constructive methods of discrete geometric objects.  Most questions in discrete geometry involve finite or discrete sets of basic geometric objects, such as points, lines, planes, circles, spheres, polygons, and so forth.  The subject focuses on the combinatorial properties of these objects, such as how they intersect one another, or how they may be arranged to cover a larger object.\nDiscrete geometry has a large overlap with convex geometry and computational geometry, and is closely related to subjects such as finite geometry, combinatorial optimization, digital geometry, discrete differential geometry, geometric graph theory, toric geometry, and combinatorial topology.",
    "content": "Discrete geometry and combinatorial geometry are branches of geometry that study combinatorial properties and constructive methods of discrete geometric objects.  Most questions in discrete geometry involve finite or discrete sets of basic geometric objects, such as points, lines, planes, circles, spheres, polygons, and so forth.  The subject focuses on the combinatorial properties of these objects, such as how they intersect one another, or how they may be arranged to cover a larger object.\nDiscrete geometry has a large overlap with convex geometry and computational geometry, and is closely related to subjects such as finite geometry, combinatorial optimization, digital geometry, discrete differential geometry, geometric graph theory, toric geometry, and combinatorial topology.\n\nHistory\nPolyhedra and tessellations had been studied for many years by people such as Kepler and Cauchy, modern discrete geometry has its origins in the late 19th century.  Early topics studied were: the density of circle packings by Thue, projective configurations by Reye and Steinitz, the geometry of numbers by Minkowski, and map colourings by Tait, Heawood, and Hadwiger.\nLászló Fejes Tóth, H.S.M. Coxeter, and Paul Erdős laid the foundations of discrete geometry.\n\nTopics\nPolyhedra and polytopes\nA polytope is a geometric object with flat sides, which exists in any general number of dimensions. A polygon is a polytope in two dimensions, a polyhedron in three dimensions, and so on in higher dimensions (such as a 4-polytope in four dimensions). Some theories further generalize the idea to include such objects as unbounded polytopes (apeirotopes and tessellations), and abstract polytopes.\nThe following are some of the aspects of polytopes studied in discrete geometry:\n\nPolyhedral combinatorics\nLattice polytopes\nEhrhart polynomials\nPick's theorem\nHirsch conjecture\nOpaque set\n\nPackings, coverings and tilings\nPackings, coverings, and tilings are all ways of arranging uniform objects (typically circles, spheres, or tiles) in a regular way on a surface or manifold.\nA sphere packing is an arrangement of non-overlapping spheres within a containing space. The spheres considered are usually all of identical size, and the space is usually three-dimensional Euclidean space. However, sphere packing problems can be generalised to consider unequal spheres, n-dimensional Euclidean space (where the problem becomes circle packing in two dimensions, or hypersphere packing in higher dimensions) or to non-Euclidean spaces such as hyperbolic space.\nA tessellation of a flat surface is the tiling of a plane using one or more geometric shapes, called tiles, with no overlaps and no gaps. In mathematics, tessellations can be generalized to higher dimensions.\nSpecific topics in this area include:\n\nCircle packings\nSphere packings\nKepler conjecture\nQuasicrystals\nAperiodic tilings\nPeriodic graph\nFinite subdivision rules\n\nStructural rigidity and flexibility\nStructural rigidity is a combinatorial theory for predicting the flexibility of ensembles formed by rigid bodies connected by flexible linkages or hinges.\nTopics in this area include:\n\nCauchy's theorem\nFlexible polyhedra\n\nIncidence structures\nIncidence structures generalize planes (such as affine, projective, and Möbius planes) as can be seen from their axiomatic definitions. Incidence structures also generalize the higher-dimensional analogs and the finite structures are sometimes called finite geometries.\nFormally, an incidence structure is a triple\n\n  \n    \n      \n        C\n        =\n        (\n        P\n        ,\n        L\n        ,\n        I\n        )\n        .\n        \n      \n    \n    {\\displaystyle C=(P,L,I).\\,}\n  \n\nwhere P is a set of \"points\", L is a set of \"lines\" and \n  \n    \n      \n        I\n        ⊆\n        P\n        ×\n        L\n      \n    \n    {\\displaystyle I\\subseteq P\\times L}\n  \n is the incidence relation. The elements of \n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n  \n are called flags. If\n\n  \n    \n      \n        (\n        p\n        ,\n        l\n        )\n        ∈\n        I\n        ,\n      \n    \n    {\\displaystyle (p,l)\\in I,}\n  \n\nwe say that point p \"lies on\" line \n  \n    \n      \n        l\n      \n    \n    {\\displaystyle l}\n  \n.\nTopics in this area include:\n\nConfigurations\nLine arrangements\nHyperplane arrangements\nBuildings\n\nOriented matroids\nAn oriented matroid is a mathematical structure that abstracts the properties of directed graphs and of arrangements of vectors in a vector space over an ordered field (particularly for partially ordered vector spaces). In comparison, an ordinary (i.e., non-oriented) matroid abstracts the dependence properties that are common both to graphs, which are not necessarily directed, and to arrangements of vectors over fields, which are not necessarily ordered.\n\nGeometric graph theory\nA geometric graph is a graph in which the vertices or edges are associated with geometric objects. Examples include Euclidean graphs, the 1-skeleton of a polyhedron ",
    "links": [
      "4-polytope",
      "Abstract algebra",
      "Abstract polytope",
      "Abstract simplicial complex",
      "Affine plane (incidence geometry)",
      "Alexander Lubotzky",
      "Algebra",
      "Algebraic geometry",
      "Algebraic number theory",
      "Algebraic topology",
      "Analysis on fractals",
      "Analytic geometry",
      "Analytic number theory",
      "Apeirotope",
      "Aperiodic tiling",
      "Applied mathematics",
      "Arithmetic",
      "Arithmetic geometry",
      "Armand Borel",
      "Arrangement of hyperplanes",
      "Arrangement of lines",
      "Augustin-Louis Cauchy",
      "Axel Thue",
      "Borsuk-Ulam theorem",
      "Building (mathematics)",
      "Calculus",
      "Category theory",
      "Cauchy's theorem (geometry)",
      "Circle",
      "Circle packing",
      "Combinatorial optimization",
      "Combinatorial topology",
      "Combinatorics",
      "Commutative algebra",
      "Complex analysis",
      "Computational complexity theory",
      "Computational geometry",
      "Computational mathematics",
      "Computer algebra",
      "Computer graphics",
      "Computer science",
      "Configuration (geometry)",
      "Control theory",
      "Convex geometry",
      "Convex lattice polytope",
      "Cycle graph",
      "Delaunay triangulation",
      "Differential equation",
      "Differential geometry",
      "Differential topology"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1 maint: multiple names: authors list",
      "Category:Discrete geometry",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Effective field theory": {
    "title": "Effective field theory",
    "url": "https://en.wikipedia.org/wiki/Effective_field_theory",
    "summary": "In physics, an effective field theory is a type of approximation, or effective theory, for an underlying physical theory, such as a quantum field theory or a statistical mechanics model. An effective field theory includes the appropriate degrees of freedom to describe physical phenomena occurring at a chosen length scale or energy scale, while ignoring substructure and degrees of freedom at shorter distances (or, equivalently, at higher energies). Intuitively, one averages over the behavior of the underlying theory at shorter length scales to derive what is hoped to be a simplified model at longer length scales. Effective field theories typically work best when there is a large separation between length scale of interest and the length scale of the underlying dynamics. Effective field theories have found use in particle physics, statistical mechanics, condensed matter physics, general relativity, and hydrodynamics. They simplify calculations, and allow treatment of dissipation and radi",
    "content": "In physics, an effective field theory is a type of approximation, or effective theory, for an underlying physical theory, such as a quantum field theory or a statistical mechanics model. An effective field theory includes the appropriate degrees of freedom to describe physical phenomena occurring at a chosen length scale or energy scale, while ignoring substructure and degrees of freedom at shorter distances (or, equivalently, at higher energies). Intuitively, one averages over the behavior of the underlying theory at shorter length scales to derive what is hoped to be a simplified model at longer length scales. Effective field theories typically work best when there is a large separation between length scale of interest and the length scale of the underlying dynamics. Effective field theories have found use in particle physics, statistical mechanics, condensed matter physics, general relativity, and hydrodynamics. They simplify calculations, and allow treatment of dissipation and radiation effects.\n\nRenormalization group\nPresently, effective field theories are discussed in the context of the renormalization group (RG) where the process of integrating out short distance degrees of freedom is made systematic. Although this method is not sufficiently concrete to allow the actual construction of effective field theories, the gross understanding of their usefulness becomes clear through an RG analysis. This method also lends credence to the main technique of constructing effective field theories, through the analysis of symmetries. If there is a single energy scale \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n  \n in the microscopic theory, then the effective field theory can be seen as an expansion in \n  \n    \n      \n        1\n        \n          /\n        \n        M\n      \n    \n    {\\displaystyle 1/M}\n  \n. The construction of an effective field theory accurate to some power of \n  \n    \n      \n        1\n        \n          /\n        \n        M\n      \n    \n    {\\displaystyle 1/M}\n  \n requires a new set of free parameters at each order of the expansion in \n  \n    \n      \n        1\n        \n          /\n        \n        M\n      \n    \n    {\\displaystyle 1/M}\n  \n. This technique is useful for scattering or other processes where the maximum momentum scale \n  \n    \n      \n        \n          k\n        \n      \n    \n    {\\displaystyle \\mathbf {k} }\n  \n satisfies the condition \n  \n    \n      \n        \n          |\n        \n        \n          k\n        \n        \n          |\n        \n        \n          /\n        \n        M\n        ≪\n        1\n      \n    \n    {\\displaystyle |\\mathbf {k} |/M\\ll 1}\n  \n. Since effective field theories are not valid at small length scales, they need not be renormalizable. Indeed, the ever expanding number of parameters at each order in \n  \n    \n      \n        1\n        \n          /\n        \n        M\n      \n    \n    {\\displaystyle 1/M}\n  \n required for an effective field theory means that they are generally not renormalizable in the same sense as quantum electrodynamics which requires only the renormalization of two parameters (the fine structure constant and the electron mass).\n\nExamples\nFermi theory of beta decay\nThe best-known example of an effective field theory is the Fermi theory of beta decay. This theory was developed during the early study of weak decays of nuclei when only the hadrons and leptons undergoing weak decay were known. The typical reactions studied were:\n\n  \n    \n      \n        \n          \n            \n              \n                n\n              \n              \n                \n                →\n                p\n                +\n                \n                  e\n                  \n                    −\n                  \n                \n                +\n                \n                  \n                    \n                      ν\n                      ¯\n                    \n                  \n                  \n                    e\n                  \n                \n              \n            \n            \n              \n                \n                  μ\n                  \n                    −\n                  \n                \n              \n              \n                \n                →\n                \n                  e\n                  \n                    −\n                  \n                \n                +\n                \n                  \n                    \n                      ν\n                      ¯\n                    \n                  \n                  \n                    e\n                  \n                \n                +\n                \n                  ν\n                  \n                    μ\n                  \n                \n                .\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}n&\\to p+e^{-}+{\\overline {\\nu }}_{e}\\\\\\mu ^{-}&\\to e^{-}+{\\overline {\\nu }}_{e}+\\nu _{\\mu }.\\end{aligned}}}\n  \n\nThis theory posited a pointlike interaction between the ",
    "links": [
      "Abdus Salam",
      "Alain Connes",
      "Alain Rouet",
      "Albert Schwarz",
      "Alexander Arkadyevich Migdal",
      "Alexander Belavin",
      "Alexander Markovich Polyakov",
      "Alexander Zamolodchikov",
      "Alexandru Proca",
      "Alexei Zamolodchikov",
      "Alexey Andreevich Anselm",
      "Algebra of physical space",
      "Algebraic structure",
      "Algorithm",
      "Algorithm design",
      "Analysis of algorithms",
      "Analytical mechanics",
      "André Neveu",
      "Annual Review of Nuclear and Particle Science",
      "Anomaly (physics)",
      "Anthony Zee",
      "Applied mathematics",
      "Approximation theory",
      "ArXiv (identifier)",
      "Arkady Vainshtein",
      "Arthur Jaffe",
      "Arthur Wightman",
      "Atomic nucleus",
      "Automata theory",
      "Automated theorem proving",
      "BCS theory",
      "BRST quantization",
      "Background field method",
      "Bargmann–Wigner equations",
      "Benjamin W. Lee",
      "Bibcode (identifier)",
      "Bosonic string theory",
      "Bottom quark",
      "Bruno Zumino",
      "Bryce DeWitt",
      "C. R. Hagen",
      "Calculus of variations",
      "Carlo Becchi",
      "Chaos theory",
      "Charge conjugation",
      "Charles M. Sommerfield",
      "Charm quark",
      "Chiral perturbation theory",
      "Christian Møller",
      "Christof Wetterich"
    ],
    "categories": [
      "Category:All articles lacking in-text citations",
      "Category:Articles lacking in-text citations from May 2013",
      "Category:Articles with short description",
      "Category:Chemical physics",
      "Category:Condensed matter physics",
      "Category:Nuclear physics",
      "Category:Quantum field theory",
      "Category:Renormalization group",
      "Category:Short description matches Wikidata",
      "Category:Statistical mechanics"
    ]
  },
  "Equioscillation theorem": {
    "title": "Equioscillation theorem",
    "url": "https://en.wikipedia.org/wiki/Equioscillation_theorem",
    "summary": "In mathematics, the equioscillation theorem concerns the approximation of continuous functions using polynomials when the merit function is the maximum difference (uniform norm). Its discovery is attributed to Chebyshev.",
    "content": "In mathematics, the equioscillation theorem concerns the approximation of continuous functions using polynomials when the merit function is the maximum difference (uniform norm). Its discovery is attributed to Chebyshev.\n\nStatement\nLet \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n be a continuous function from \n  \n    \n      \n        [\n        a\n        ,\n        b\n        ]\n      \n    \n    {\\displaystyle [a,b]}\n  \n to \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n. Among all the polynomials of degree \n  \n    \n      \n        ≤\n        n\n      \n    \n    {\\displaystyle \\leq n}\n  \n, the polynomial \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n  \n minimizes the uniform norm of the difference \n  \n    \n      \n        ‖\n        f\n        −\n        g\n        \n          ‖\n          \n            ∞\n          \n        \n      \n    \n    {\\displaystyle \\|f-g\\|_{\\infty }}\n  \n if and only if there are \n  \n    \n      \n        n\n        +\n        2\n      \n    \n    {\\displaystyle n+2}\n  \n points \n  \n    \n      \n        a\n        ≤\n        \n          x\n          \n            0\n          \n        \n        <\n        \n          x\n          \n            1\n          \n        \n        <\n        ⋯\n        <\n        \n          x\n          \n            n\n            +\n            1\n          \n        \n        ≤\n        b\n      \n    \n    {\\displaystyle a\\leq x_{0}<x_{1}<\\cdots <x_{n+1}\\leq b}\n  \n such that \n  \n    \n      \n        f\n        (\n        \n          x\n          \n            i\n          \n        \n        )\n        −\n        g\n        (\n        \n          x\n          \n            i\n          \n        \n        )\n        =\n        σ\n        (\n        −\n        1\n        \n          )\n          \n            i\n          \n        \n        ‖\n        f\n        −\n        g\n        \n          ‖\n          \n            ∞\n          \n        \n      \n    \n    {\\displaystyle f(x_{i})-g(x_{i})=\\sigma (-1)^{i}\\|f-g\\|_{\\infty }}\n  \n where \n  \n    \n      \n        σ\n      \n    \n    {\\displaystyle \\sigma }\n  \n is either -1 or +1.\nThat is, the polynomial \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n  \n oscillates above and below \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n at the interpolation points, and does so to the same degree.\n\nProof\nLet us define the equioscillation condition as the condition in the theorem statement, that is, the condition that there exists \n  \n    \n      \n        n\n        +\n        2\n      \n    \n    {\\displaystyle n+2}\n  \n ordered points in the interval such that the difference \n  \n    \n      \n        f\n        (\n        \n          x\n          \n            i\n          \n        \n        )\n        −\n        g\n        (\n        \n          x\n          \n            i\n          \n        \n        )\n      \n    \n    {\\displaystyle f(x_{i})-g(x_{i})}\n  \n alternates in sign and is equal in magnitude to the uniform-norm of \n  \n    \n      \n        f\n        (\n        x\n        )\n        −\n        g\n        (\n        x\n        )\n      \n    \n    {\\displaystyle f(x)-g(x)}\n  \n.\nWe need to prove that this condition is 'sufficient' for the polynomial \n  \n    \n      \n        g\n      \n    \n    {\\displaystyle g}\n  \n being the best uniform approximation to \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n, and we need to prove that this condition is 'necessary' for a polynomial to be the best uniform approximation.\n\nSufficiency\nAssume by contradiction that a polynomial \n  \n    \n      \n        p\n        (\n        x\n        )\n      \n    \n    {\\displaystyle p(x)}\n  \n of degree less than or equal to \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n existed that provides a uniformly better approximation to \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n, which means that \n  \n    \n      \n        ‖\n        f\n        −\n        p\n        \n          ‖\n          \n            ∞\n          \n        \n        <\n        ‖\n        f\n        −\n        g\n        \n          ‖\n          \n            ∞\n          \n        \n      \n    \n    {\\displaystyle \\|f-p\\|_{\\infty }<\\|f-g\\|_{\\infty }}\n  \n. Then the polynomial \n\n  \n    \n      \n        h\n        (\n        x\n        )\n        =\n        g\n        (\n        x\n        )\n        −\n        p\n        (\n        x\n        )\n        =\n        (\n        g\n        (\n        x\n        )\n        −\n        f\n        (\n        x\n        )\n        )\n        −\n        (\n        p\n        (\n        x\n        )\n        −\n        f\n        (\n        x\n        )\n        )\n      \n    \n    {\\displaystyle h(x)=g(x)-p(x)=(g(x)-f(x))-(p(x)-f(x))}\n  \n\nis also of degree less than or equal to \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n. However, for every \n  \n    \n      \n        \n          x\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle x_{i}}\n  \n of the \n  \n    \n      \n        n\n        +\n        2\n      \n    \n    {\\displaystyle n+2}\n  \n poin",
    "links": [
      "Approximation theory",
      "Continuous function",
      "Mathematical analysis",
      "Mathematics",
      "Minimax approximation algorithm",
      "Pafnuty Chebyshev",
      "Polynomial",
      "Remez algorithm",
      "Uniform norm",
      "Wayback Machine",
      "Wikipedia:Please clarify",
      "Wikipedia:Stub",
      "Template:Mathanalysis-stub",
      "Template talk:Mathanalysis-stub"
    ],
    "categories": [
      "Category:All stub articles",
      "Category:Articles with short description",
      "Category:Mathematical analysis stubs",
      "Category:Numerical analysis",
      "Category:Short description matches Wikidata",
      "Category:Theorems about polynomials",
      "Category:Theorems in mathematical analysis",
      "Category:Webarchive template wayback links",
      "Category:Wikipedia articles needing clarification from July 2025"
    ]
  },
  "Coding theory": {
    "title": "Coding theory",
    "url": "https://en.wikipedia.org/wiki/Coding_theory",
    "summary": "Coding theory is the study of the properties of codes and their respective fitness for specific applications. Codes are used for data compression, cryptography, error detection and correction, data transmission and data storage. Codes are studied by various scientific disciplines—such as information theory, electrical engineering,  mathematics, linguistics, and computer science—for the purpose of designing efficient and reliable data transmission methods. This typically involves the removal of redundancy and the correction or detection of errors in the transmitted data.\nThere are four types of coding:\n\nData compression (or source coding)\nError control (or channel coding)\nCryptographic coding\nLine coding\nData compression attempts to remove unwanted redundancy from the data from a source in order to transmit it more efficiently. For example, DEFLATE data compression makes files smaller, for purposes such as to reduce Internet traffic. Data compression and error correction may be studied ",
    "content": "Coding theory is the study of the properties of codes and their respective fitness for specific applications. Codes are used for data compression, cryptography, error detection and correction, data transmission and data storage. Codes are studied by various scientific disciplines—such as information theory, electrical engineering,  mathematics, linguistics, and computer science—for the purpose of designing efficient and reliable data transmission methods. This typically involves the removal of redundancy and the correction or detection of errors in the transmitted data.\nThere are four types of coding:\n\nData compression (or source coding)\nError control (or channel coding)\nCryptographic coding\nLine coding\nData compression attempts to remove unwanted redundancy from the data from a source in order to transmit it more efficiently. For example, DEFLATE data compression makes files smaller, for purposes such as to reduce Internet traffic. Data compression and error correction may be studied in combination.\nError correction adds useful redundancy to the data from a source to make the transmission more robust to disturbances present on the transmission channel. The ordinary user may not be aware of many applications using error correction. A typical music compact disc (CD) uses the Reed–Solomon code to correct for scratches and dust. In this application the transmission channel is the CD itself. Cell phones also use coding techniques to correct for the fading and noise of high frequency radio transmission. Data modems, telephone transmissions, and the NASA Deep Space Network all employ channel coding techniques to get the bits through, for example the turbo code and LDPC codes.\n\nHistory of coding theory\nShannon’s paper focuses on the problem of how to best encode the information a sender wants to transmit. In this fundamental work he used tools in probability theory, developed by Norbert Wiener, which were in their nascent stages of being applied to communication theory at that time. Shannon developed information entropy as a measure for the uncertainty in a message while essentially inventing the field of information theory.\nThe binary Golay code was developed in 1949. It is an error-correcting code capable of correcting up to three errors in each 24-bit word, and detecting a fourth.\nRichard Hamming won the Turing Award in 1968 for his work at Bell Labs in numerical methods, automatic coding systems, and error-detecting and error-correcting codes. He invented the concepts known as Hamming codes, Hamming windows, Hamming numbers, and Hamming distance.\nIn 1972, Nasir Ahmed proposed the discrete cosine transform (DCT), which he developed with T. Natarajan and K. R. Rao in 1973. The DCT is the most widely used lossy compression algorithm, the basis for multimedia formats such as JPEG, MPEG and MP3.\n\nSource coding\nThe aim of source coding is to take the source data and make it smaller.\n\nDefinition\nData can be seen as a random variable \n  \n    \n      \n        X\n        :\n        Ω\n        →\n        \n          \n            X\n          \n        \n      \n    \n    {\\displaystyle X:\\Omega \\to {\\mathcal {X}}}\n  \n, where \n  \n    \n      \n        x\n        ∈\n        \n          \n            X\n          \n        \n      \n    \n    {\\displaystyle x\\in {\\mathcal {X}}}\n  \n appears with probability \n  \n    \n      \n        \n          P\n        \n        [\n        X\n        =\n        x\n        ]\n      \n    \n    {\\displaystyle \\mathbb {P} [X=x]}\n  \n.\nData are encoded by strings (words) over an alphabet \n  \n    \n      \n        Σ\n      \n    \n    {\\displaystyle \\Sigma }\n  \n.\nA code is a function\n\n  \n    \n      \n        C\n        :\n        \n          \n            X\n          \n        \n        →\n        \n          Σ\n          \n            ∗\n          \n        \n      \n    \n    {\\displaystyle C:{\\mathcal {X}}\\to \\Sigma ^{*}}\n  \n (or \n  \n    \n      \n        \n          Σ\n          \n            +\n          \n        \n      \n    \n    {\\displaystyle \\Sigma ^{+}}\n  \n if the empty string is not part of the alphabet).\n\n  \n    \n      \n        C\n        (\n        x\n        )\n      \n    \n    {\\displaystyle C(x)}\n  \n is the code word associated with \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n.\nLength of the code word is written as\n\n  \n    \n      \n        l\n        (\n        C\n        (\n        x\n        )\n        )\n        .\n      \n    \n    {\\displaystyle l(C(x)).}\n  \n\nExpected length of a code is\n\n  \n    \n      \n        l\n        (\n        C\n        )\n        =\n        \n          ∑\n          \n            x\n            ∈\n            \n              \n                X\n              \n            \n          \n        \n        l\n        (\n        C\n        (\n        x\n        )\n        )\n        \n          P\n        \n        [\n        X\n        =\n        x\n        ]\n        .\n      \n    \n    {\\displaystyle l(C)=\\sum _{x\\in {\\mathcal {X}}}l(C(x))\\mathbb {P} [X=x].}\n  \n\nThe concatenation of code words \n  \n    \n      \n        C\n        (\n        \n   ",
    "links": [
      "A Mathematical Theory of Communication",
      "Adversary (cryptography)",
      "Algebra of physical space",
      "Algebraic geometric code",
      "Algebraic structure",
      "Algorithm",
      "Algorithm design",
      "Alphabet (computer science)",
      "Analog electronics",
      "Analog signal",
      "Analog signal processing",
      "Analysis of algorithms",
      "Analytical mechanics",
      "Applied mathematics",
      "Approximation theory",
      "ArXiv (identifier)",
      "Audrey Terras",
      "Authentication",
      "Automata theory",
      "Automated teller machine",
      "Automated theorem proving",
      "Automatic repeat-request",
      "BCH code",
      "Baseband",
      "Bell Labs",
      "Bell System Technical Journal",
      "Binary Golay code",
      "Bipolar encoding",
      "Bit",
      "Block code",
      "Bosonic string theory",
      "Brain",
      "Calculus of variations",
      "Cambridge University Press",
      "Channel capacity",
      "Chaos theory",
      "CiteSeerX (identifier)",
      "Classical field theory",
      "Claude E. Shannon",
      "Clifford algebra",
      "Clifford analysis",
      "Code",
      "Code-division multiple access",
      "Code word (communication)",
      "Coding gain",
      "Combinatorics",
      "Communications protocol",
      "Communications system",
      "Compact Disc Digital Audio",
      "Computational geometry"
    ],
    "categories": [
      "Category:All articles with unsourced statements",
      "Category:All misleading articles",
      "Category:Articles with excerpts",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from July 2008",
      "Category:Coding theory",
      "Category:Error detection and correction",
      "Category:Misleading articles from August 2012",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Control theory": {
    "title": "Control theory",
    "url": "https://en.wikipedia.org/wiki/Control_theory",
    "summary": "Control theory is a field of control engineering and applied mathematics that deals with the control of dynamical systems. The objective is to develop a model or algorithm governing the application of system inputs to drive the system to a desired state, while minimizing any delay, overshoot, or steady-state error and ensuring a level of control stability; often with the aim to achieve a degree of optimality.\nTo do this, a controller with the requisite corrective behavior is required. This controller monitors the controlled process variable (PV), and compares it with the reference or set point (SP). The difference between actual and desired value of the process variable, called the error signal, or SP-PV error, is applied as feedback to generate a control action to bring the controlled process variable to the same value as the set point. Other aspects which are also studied are  controllability and observability.  Control theory is used in control system engineering to design automatio",
    "content": "Control theory is a field of control engineering and applied mathematics that deals with the control of dynamical systems. The objective is to develop a model or algorithm governing the application of system inputs to drive the system to a desired state, while minimizing any delay, overshoot, or steady-state error and ensuring a level of control stability; often with the aim to achieve a degree of optimality.\nTo do this, a controller with the requisite corrective behavior is required. This controller monitors the controlled process variable (PV), and compares it with the reference or set point (SP). The difference between actual and desired value of the process variable, called the error signal, or SP-PV error, is applied as feedback to generate a control action to bring the controlled process variable to the same value as the set point. Other aspects which are also studied are  controllability and observability.  Control theory is used in control system engineering to design automation  that have revolutionized manufacturing, aircraft, communications and other industries, and created new fields such as robotics.  \nExtensive use is usually made of a diagrammatic style known as the block diagram. In it the transfer function, also known as the system function or network function, is a mathematical model of the relation between the input and output based on the differential equations describing the system.\nControl theory dates from the 19th century, when the theoretical basis for the operation of governors was first described by James Clerk Maxwell.  Control theory was further advanced by Edward Routh in 1874, Charles Sturm and in 1895, Adolf Hurwitz, who all contributed to the establishment of control stability criteria; and from 1922 onwards, the development of PID control theory by Nicolas Minorsky.\nAlthough the most direct application of mathematical control theory is its use in control systems engineering (dealing with process control systems for robotics and industry), control theory is routinely applied to problems both the natural and behavioral sciences. As the general theory of feedback systems, control theory is useful wherever feedback occurs, making it important to fields like economics, operations research, and the life sciences.\n\nHistory\nAlthough control systems of various types date back to antiquity, a more formal analysis of the field began with a dynamics analysis of the centrifugal governor, conducted by the physicist James Clerk Maxwell in 1868, entitled On Governors. A centrifugal governor was already used to regulate the velocity of windmills. Maxwell described and analyzed the phenomenon of self-oscillation, in which lags in the system may lead to overcompensation and unstable behavior. This generated a flurry of interest in the topic, during which Maxwell's classmate, Edward John Routh, abstracted Maxwell's results for the general class of linear systems. Independently, Adolf Hurwitz analyzed system stability using differential equations in 1877, resulting in what is now known as the Routh–Hurwitz theorem.\nA notable application of dynamic control was in the area of crewed flight. The Wright brothers made their first successful test flights on December 17, 1903, and were distinguished by their ability to control their flights for substantial periods (more so than the ability to produce lift from an airfoil, which was known). Continuous, reliable control of the airplane was necessary for flights lasting longer than a few seconds.\nBy World War II, control theory was becoming an important area of research. Irmgard Flügge-Lotz developed the theory of discontinuous automatic control systems, and applied the bang-bang principle to the development of automatic flight control equipment for aircraft. Other areas of application for discontinuous controls included fire-control systems, guidance systems and electronics.\nSometimes, mechanical methods are used to improve the stability of systems. For example, ship stabilizers are fins mounted beneath the waterline and emerging laterally.  In contemporary vessels, they may be gyroscopically controlled active fins, which have the capacity to change their angle of attack to counteract roll caused by wind or waves acting on the ship.\nThe Space Race also depended on accurate spacecraft control, and control theory has also seen an increasing use in fields such as economics and artificial intelligence. Here, one might say that the goal is to find an internal model that obeys the good regulator theorem. So, for example, in economics, the more accurately a (stock or commodities) trading model represents the actions of the market, the more easily it can control that market (and extract \"useful work\" (profits) from it). In AI, an example might be a chatbot modelling the discourse state of humans: the more accurately it can model the human state (e.g. on a telephone voice-support hotline), the better it can manipulate the human (e.g. into performing the correcti",
    "links": [
      "Absolute value",
      "Abstract algebra",
      "Active optics",
      "Actuator",
      "Adaptive control",
      "Adaptive system",
      "Adolf Hurwitz",
      "Aerospace industry",
      "Aleksandr Lyapunov",
      "Alexander Bogdanov",
      "Alexander Lerner",
      "Alexander Lyapunov",
      "Alexey Lyapunov",
      "Alfred Radcliffe-Brown",
      "Algebra",
      "Algebraic equation",
      "Algebraic geometry",
      "Algebraic number theory",
      "Algebraic topology",
      "Ali H. Nayfeh",
      "Allenna Leonard",
      "Analytic geometry",
      "Analytic number theory",
      "Anatol Rapoport",
      "Andrey Kolmogorov",
      "Anthony Stafford Beer",
      "Anthony Wilden",
      "Anti-wind up system (control)",
      "Applied mathematics",
      "ArXiv (identifier)",
      "Arithmetic",
      "Arithmetic geometry",
      "Artificial intelligence",
      "Artificial neural network",
      "Artificial neural networks",
      "Asymptotic stability",
      "Audio system",
      "Automation",
      "Automation and Remote Control",
      "Automation and remote control",
      "Autopilot",
      "BIBO stability",
      "Backstepping",
      "Bandwidth (signal processing)",
      "Bang-bang control",
      "Bang–bang control",
      "Barbara J. Grosz",
      "Bayesian probability",
      "Behavioral science",
      "Bibcode (identifier)"
    ],
    "categories": [
      "Category:All articles with unsourced statements",
      "Category:Articles with excerpts",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from December 2022",
      "Category:Commons category link from Wikidata",
      "Category:Computer engineering",
      "Category:Control engineering",
      "Category:Control theory",
      "Category:Pages displaying short descriptions of redirect targets via Module:Annotated link",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Estimation theory": {
    "title": "Estimation theory",
    "url": "https://en.wikipedia.org/wiki/Estimation_theory",
    "summary": "Estimation theory is a branch of statistics that deals with estimating the values of parameters based on measured empirical data that has a random component.  The parameters describe an underlying physical setting in such a way that their value affects the distribution of the measured data. An estimator attempts to approximate the unknown parameters using the measurements.\nIn estimation theory, two approaches are generally considered:\n\nThe probabilistic approach (described in this article) assumes that the measured data is random with probability distribution dependent on the parameters of interest\nThe set-membership approach assumes that the measured data vector belongs to a set which depends on the parameter vector.",
    "content": "Estimation theory is a branch of statistics that deals with estimating the values of parameters based on measured empirical data that has a random component.  The parameters describe an underlying physical setting in such a way that their value affects the distribution of the measured data. An estimator attempts to approximate the unknown parameters using the measurements.\nIn estimation theory, two approaches are generally considered:\n\nThe probabilistic approach (described in this article) assumes that the measured data is random with probability distribution dependent on the parameters of interest\nThe set-membership approach assumes that the measured data vector belongs to a set which depends on the parameter vector.\n\nExamples\nFor example, it is desired to estimate the proportion of a population of voters who will vote for a particular candidate.  That proportion is the parameter sought; the estimate is based on a small random sample of voters. Alternatively, it is desired to estimate the probability of a voter voting for a particular candidate, based on some demographic features, such as age.\nOr, for example, in radar the aim is to find the range of objects (airplanes, boats, etc.) by analyzing the two-way transit timing of received echoes of transmitted pulses. Since the reflected pulses are unavoidably embedded in electrical noise, their measured values are randomly distributed, so that the transit time must be estimated.\nAs another example, in electrical communication theory, the measurements which contain information regarding the parameters of interest are often associated with a noisy signal.\n\nBasics\nFor a given model, several statistical \"ingredients\" are needed so the estimator can be implemented. The first is a statistical sample – a set of data points taken from a random vector (RV) of size N. Put into a vector,\n\n  \n    \n      \n        \n          x\n        \n        =\n        \n          \n            [\n            \n              \n                \n                  x\n                  [\n                  0\n                  ]\n                \n              \n              \n                \n                  x\n                  [\n                  1\n                  ]\n                \n              \n              \n                \n                  ⋮\n                \n              \n              \n                \n                  x\n                  [\n                  N\n                  −\n                  1\n                  ]\n                \n              \n            \n            ]\n          \n        \n        .\n      \n    \n    {\\displaystyle \\mathbf {x} ={\\begin{bmatrix}x[0]\\\\x[1]\\\\\\vdots \\\\x[N-1]\\end{bmatrix}}.}\n  \n\nSecondly, there are M parameters\n\n  \n    \n      \n        \n          θ\n        \n        =\n        \n          \n            [\n            \n              \n                \n                  \n                    θ\n                    \n                      1\n                    \n                  \n                \n              \n              \n                \n                  \n                    θ\n                    \n                      2\n                    \n                  \n                \n              \n              \n                \n                  ⋮\n                \n              \n              \n                \n                  \n                    θ\n                    \n                      M\n                    \n                  \n                \n              \n            \n            ]\n          \n        \n        ,\n      \n    \n    {\\displaystyle {\\boldsymbol {\\theta }}={\\begin{bmatrix}\\theta _{1}\\\\\\theta _{2}\\\\\\vdots \\\\\\theta _{M}\\end{bmatrix}},}\n  \n\nwhose values are to be estimated. Third, the continuous probability density function (pdf) or its discrete counterpart, the probability mass function (pmf), of the underlying distribution that generated the data must be stated conditional on the values of the parameters:\n\n  \n    \n      \n        p\n        (\n        \n          x\n        \n        \n          |\n        \n        \n          θ\n        \n        )\n        .\n        \n      \n    \n    {\\displaystyle p(\\mathbf {x} |{\\boldsymbol {\\theta }}).\\,}\n  \n\nIt is also possible for the parameters themselves to have a probability distribution (e.g., Bayesian statistics). It is then necessary to define the Bayesian probability\n\n  \n    \n      \n        π\n        (\n        \n          θ\n        \n        )\n        .\n        \n      \n    \n    {\\displaystyle \\pi ({\\boldsymbol {\\theta }}).\\,}\n  \n\nAfter the model is formed, the goal is to estimate the parameters, with the estimates commonly denoted \n  \n    \n      \n        \n          \n            \n              θ\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\hat {\\boldsymbol {\\theta }}}}\n  \n, where the \"hat\" indicates the estimate.\nOne common estimator is the minimum mean squared error (MMSE) estimator, which utilizes the error between the estimated parameters and the actual value of the parameters\n",
    "links": [
      "Adaptive control",
      "Additive white Gaussian noise",
      "Advanced z-transform",
      "Ali H. Sayed",
      "Aliasing",
      "Anti-aliasing filter",
      "Audio signal processing",
      "Bayes estimator",
      "Bayesian probability",
      "Bayesian statistics",
      "Best linear unbiased estimator",
      "Biased estimator",
      "Bilinear transform",
      "Clinical trial",
      "Completeness (statistics)",
      "Constant-Q transform",
      "Control theory",
      "Cramér–Rao bound",
      "Cramér–Rao lower bound",
      "Derivative",
      "Detection theory",
      "Digital image processing",
      "Digital signal processing",
      "Discrete-time Fourier transform",
      "Discrete Fourier transform",
      "Discrete cosine transform",
      "Discrete signal",
      "Discrete time and continuous time",
      "Discrete uniform distribution",
      "Doi (identifier)",
      "Downsampling (signal processing)",
      "Efficiency (statistics)",
      "Efficient estimator",
      "Estimation (disambiguation)",
      "Estimator",
      "Estimator bias",
      "Expectation-maximization algorithm",
      "Expected value",
      "Experiment",
      "Fermi problem",
      "Fisher information",
      "German tank problem",
      "Grey box model",
      "ISBN (identifier)",
      "Impulse invariance",
      "Information theory",
      "Integral transform",
      "Interval estimation",
      "Kalman filter",
      "Laplace transform"
    ],
    "categories": [
      "Category:All articles lacking in-text citations",
      "Category:Articles lacking in-text citations from April 2025",
      "Category:Articles with short description",
      "Category:Commons category link from Wikidata",
      "Category:Estimation theory",
      "Category:Mathematical and quantitative methods (economics)",
      "Category:Short description matches Wikidata",
      "Category:Signal processing"
    ]
  },
  "Elementary algebra": {
    "title": "Elementary algebra",
    "url": "https://en.wikipedia.org/wiki/Elementary_algebra",
    "summary": "Elementary algebra, also known as high school algebra or college algebra, encompasses the basic concepts of algebra. It is often contrasted with arithmetic: arithmetic deals with specified numbers, whilst algebra introduces numerical variables (quantities without fixed values).\nThis use of variables entails use of algebraic notation and an understanding of the general rules of the operations introduced in arithmetic: addition, subtraction, multiplication, division, etc. Unlike abstract algebra, elementary algebra is not concerned with algebraic structures outside the realm of real and complex numbers.\nIt is typically taught to secondary school students and at introductory college level in the United States, and builds on their understanding of arithmetic. The use of variables to denote quantities allows general relationships between quantities to be formally and concisely expressed, and thus enables solving a broader scope of problems. Many quantitative relationships in science and mat",
    "content": "Elementary algebra, also known as high school algebra or college algebra, encompasses the basic concepts of algebra. It is often contrasted with arithmetic: arithmetic deals with specified numbers, whilst algebra introduces numerical variables (quantities without fixed values).\nThis use of variables entails use of algebraic notation and an understanding of the general rules of the operations introduced in arithmetic: addition, subtraction, multiplication, division, etc. Unlike abstract algebra, elementary algebra is not concerned with algebraic structures outside the realm of real and complex numbers.\nIt is typically taught to secondary school students and at introductory college level in the United States, and builds on their understanding of arithmetic. The use of variables to denote quantities allows general relationships between quantities to be formally and concisely expressed, and thus enables solving a broader scope of problems. Many quantitative relationships in science and mathematics are expressed as algebraic equations.\n\nAlgebraic operations\nAlgebraic notation\nAlgebraic notation describes the rules and conventions for writing mathematical expressions, as well as the terminology used for talking about parts of expressions. For example, the expression \n  \n    \n      \n        3\n        \n          x\n          \n            2\n          \n        \n        −\n        2\n        x\n        y\n        +\n        c\n      \n    \n    {\\displaystyle 3x^{2}-2xy+c}\n  \n has the following components:\n\nA coefficient is a numerical value, or letter representing a numerical constant, that multiplies a variable (the operator is omitted). A term is an addend or a summand, a group of coefficients, variables, constants and exponents that may be separated from the other terms by the plus and minus operators. Letters represent variables and constants. By convention, letters at the beginning of the alphabet (e.g. \n  \n    \n      \n        a\n        ,\n        b\n        ,\n        c\n      \n    \n    {\\displaystyle a,b,c}\n  \n) are typically used to represent constants, and those toward the end of the alphabet (e.g. \n  \n    \n      \n        x\n        ,\n        y\n      \n    \n    {\\displaystyle x,y}\n  \n and z) are used to represent variables. They are usually printed in italics.\nAlgebraic operations work in the same way as arithmetic operations, such as addition, subtraction, multiplication, division and exponentiation, and are applied to algebraic variables and terms.  Multiplication symbols are usually omitted, and implied when there is no space between two variables or terms, or when a coefficient is used. For example, \n  \n    \n      \n        3\n        ×\n        \n          x\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle 3\\times x^{2}}\n  \n is written as \n  \n    \n      \n        3\n        \n          x\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle 3x^{2}}\n  \n, and \n  \n    \n      \n        2\n        ×\n        x\n        ×\n        y\n      \n    \n    {\\displaystyle 2\\times x\\times y}\n  \n may be written \n  \n    \n      \n        2\n        x\n        y\n      \n    \n    {\\displaystyle 2xy}\n  \n.\nUsually terms with the highest power (exponent), are written on the left, for example, \n  \n    \n      \n        \n          x\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle x^{2}}\n  \n is written to the left of x. When a coefficient is one, it is usually omitted (e.g. \n  \n    \n      \n        1\n        \n          x\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle 1x^{2}}\n  \n is written \n  \n    \n      \n        \n          x\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle x^{2}}\n  \n). Likewise when the exponent (power) is one, (e.g. \n  \n    \n      \n        3\n        \n          x\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle 3x^{1}}\n  \n is written \n  \n    \n      \n        3\n        x\n      \n    \n    {\\displaystyle 3x}\n  \n). When the exponent is zero, the result is always 1 (e.g. \n  \n    \n      \n        \n          x\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle x^{0}}\n  \n is always rewritten to 1). However \n  \n    \n      \n        \n          0\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle 0^{0}}\n  \n, being undefined, should not appear in an expression, and care should be taken in simplifying expressions in which variables may appear in exponents.\n\nAlternative notation\nOther types of notation are used in algebraic expressions when the required formatting is not available, or can not be implied, such as where only letters and symbols are available. As an illustration of this, while exponents are usually formatted using superscripts, e.g., \n  \n    \n      \n        \n          x\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle x^{2}}\n  \n, in plain text, and in the TeX mark-up language, the caret symbol ^ represents exponentia",
    "links": [
      "Abstract algebra",
      "Ada (programming language)",
      "Addend",
      "Addition",
      "Affine space",
      "Algebra",
      "Algebraic expression",
      "Algebraic geometry",
      "Algebraic number theory",
      "Algebraic operation",
      "Algebraic structure",
      "Algebraic topology",
      "Algebraic variety",
      "Analytic geometry",
      "Analytic number theory",
      "Applied mathematics",
      "Arithmetic",
      "Arithmetic geometry",
      "Arithmetic operations",
      "Asymptotic",
      "Automorphism",
      "Basis (linear algebra)",
      "Binary operation",
      "Calculus",
      "Cancelling out",
      "Caret",
      "Cartesian product",
      "Category theory",
      "Circle",
      "Circumference",
      "Coefficient",
      "Combinatorics",
      "Commutative algebra",
      "Commutativity",
      "Completing the square",
      "Complex analysis",
      "Complex number",
      "Complex numbers",
      "Composition algebra",
      "Computational complexity theory",
      "Computational mathematics",
      "Computer algebra",
      "Computer science",
      "Control theory",
      "Coordinate",
      "Coordinate vector",
      "Cube root",
      "Cynthia Y. Young",
      "Derivative",
      "Determinant"
    ],
    "categories": [
      "Category:Algebra",
      "Category:Articles with excerpts",
      "Category:Articles with short description",
      "Category:Commons category link from Wikidata",
      "Category:Elementary algebra",
      "Category:Short description is different from Wikidata",
      "Category:Webarchive template wayback links"
    ]
  },
  "Mathematical analysis": {
    "title": "Mathematical analysis",
    "url": "https://en.wikipedia.org/wiki/Mathematical_analysis",
    "summary": "Analysis is the branch of mathematics dealing with continuous functions, limits, and related theories, such as differentiation, integration, measure, infinite sequences, series, and analytic functions.\nThese theories are usually studied in the context of real and complex numbers and functions. Analysis evolved from calculus, which involves the elementary concepts and techniques of analysis.\nAnalysis may be distinguished from geometry; however, it can be applied to any space of mathematical objects that has a definition of nearness (a topological space) or specific distances between objects  (a metric space).",
    "content": "Analysis is the branch of mathematics dealing with continuous functions, limits, and related theories, such as differentiation, integration, measure, infinite sequences, series, and analytic functions.\nThese theories are usually studied in the context of real and complex numbers and functions. Analysis evolved from calculus, which involves the elementary concepts and techniques of analysis.\nAnalysis may be distinguished from geometry; however, it can be applied to any space of mathematical objects that has a definition of nearness (a topological space) or specific distances between objects  (a metric space).\n\nHistory\nAncient\nMathematical analysis formally developed in the 17th century during the Scientific Revolution, but many of its ideas can be traced back to earlier mathematicians. Early results in analysis were implicitly present in the early days of ancient Greek mathematics. For instance, an infinite geometric sum is implicit in Zeno's paradox of the dichotomy. (Strictly speaking, the point of the paradox is to deny that the infinite sum exists.) Later, Greek mathematicians such as Eudoxus and Archimedes made more explicit, but informal, use of the concepts of limits and convergence when they used the method of exhaustion to compute the area and volume of regions and solids. The explicit use of infinitesimals appears in Archimedes' The Method of Mechanical Theorems, a work rediscovered in the 20th century. In Asia, the Chinese mathematician Liu Hui used the method of exhaustion in the 3rd century CE to find the area of a circle. From Jain literature, it appears that Hindus were in possession of the formulae for the sum of the arithmetic and geometric series as early as the 4th century BCE.\nĀcārya Bhadrabāhu uses the sum of a geometric series in his Kalpasūtra in 433 BCE.\n\nMedieval\nZu Chongzhi established a method that would later be called Cavalieri's principle to find the volume of a sphere in the 5th century. In the 12th century, the Indian mathematician Bhāskara II used infinitesimal and used what is now known as Rolle's theorem.\nIn the 14th century, Madhava of Sangamagrama developed infinite series expansions, now called Taylor series, of functions such as sine, cosine, tangent and arctangent. Alongside his development of Taylor series of trigonometric functions, he also estimated the magnitude of the error terms resulting of truncating these series, and gave a rational approximation of some infinite series.  His followers at the Kerala School of Astronomy and Mathematics further expanded his works, up to the 16th century.\n\nModern\nFoundations\nThe modern foundations of mathematical analysis were established in 17th century Europe. This began when Fermat and Descartes developed analytic geometry, which is the precursor to modern calculus. Fermat's method of adequality allowed him to determine the maxima and minima of functions and the tangents of curves. Descartes's publication of La Géométrie in 1637, which introduced the Cartesian coordinate system, is considered to be the establishment of mathematical analysis. It would be a few decades later that Newton and Leibniz independently developed infinitesimal calculus, which grew, with the stimulus of applied work that continued through the 18th century, into analysis topics such as the calculus of variations, ordinary and partial differential equations, Fourier analysis, and generating functions. During this period, calculus techniques were applied to approximate discrete problems by continuous ones.\n\nModernization\nIn the 18th century, Euler introduced the notion of a mathematical function. Real analysis began to emerge as an independent subject when Bernard Bolzano introduced the modern definition of continuity in 1816, but Bolzano's work did not become widely known until the 1870s. In 1821, Cauchy began to put calculus on a firm logical foundation by rejecting the principle of the generality of algebra widely used in earlier work, particularly by Euler.  Instead, Cauchy formulated calculus in terms of geometric ideas and infinitesimals.  Thus, his definition of continuity required an infinitesimal change in x to correspond to an infinitesimal change in y.  He also introduced the concept of the Cauchy sequence, and started the formal theory of complex analysis. Poisson, Liouville, Fourier and others studied partial differential equations and harmonic analysis.  The contributions of these mathematicians and others, such as Weierstrass, developed the (ε, δ)-definition of limit approach, thus founding the modern field of mathematical analysis. Around the same time, Riemann introduced his theory of integration, and made significant advances in complex analysis.\nTowards the end of the 19th century, mathematicians started worrying that they were assuming the existence of a continuum of real numbers without proof. Dedekind then constructed the real numbers by Dedekind cuts, in which irrational numbers are formally defined, which serve to fill the \"gaps\" bet",
    "links": [
      "(ε, δ)-definition of limit",
      "A History of Vector Analysis",
      "Abstract algebra",
      "Addison–Wesley",
      "Adequality",
      "Aleksandr Danilovich Aleksandrov",
      "Aleksandr Khinchin",
      "Algebra",
      "Algebra of physical space",
      "Algebraic geometry",
      "Algebraic number theory",
      "Algebraic structure",
      "Algebraic topology",
      "Algorithm",
      "Algorithm design",
      "Amazon Standard Identification Number",
      "American Mathematical Society",
      "Analysis of algorithms",
      "Analytic combinatorics",
      "Analytic function",
      "Analytic geometry",
      "Analytic number theory",
      "Analytical mechanics",
      "Andrey Kolmogorov",
      "Andrey Nikolaevich Kolmogorov",
      "Applied mathematics",
      "Approximation",
      "Approximation theory",
      "Archimedes",
      "Area",
      "Areas of mathematics",
      "Arithmetic",
      "Arithmetic geometry",
      "Arithmetic series",
      "At the University Press",
      "Augustin Louis Cauchy",
      "Automata theory",
      "Automated theorem proving",
      "Axiom of choice",
      "Baire category theorem",
      "Bernard Bolzano",
      "Bernhard Riemann",
      "Bhadrabahu",
      "Bhāskara II",
      "Bibcode (identifier)",
      "Biology",
      "Boris Demidovich",
      "Bosonic string theory",
      "Calculus",
      "Calculus of variations"
    ],
    "categories": [
      "Category:Articles using Template:ASIN with an all-numeric value",
      "Category:Articles with short description",
      "Category:CS1 French-language sources (fr)",
      "Category:CS1 Italian-language sources (it)",
      "Category:CS1 errors: ISBN date",
      "Category:Commons category link from Wikidata",
      "Category:Mathematical analysis",
      "Category:Pages using sidebar with the child parameter",
      "Category:Short description matches Wikidata",
      "Category:Use dmy dates from May 2021"
    ]
  },
  "Equation": {
    "title": "Equation",
    "url": "https://en.wikipedia.org/wiki/Equation",
    "summary": "In mathematics, an equation is a mathematical formula that expresses the equality of two expressions, by connecting them with the equals sign =. The word equation and its cognates in other languages may have subtly different meanings; for example, in French an équation is defined as containing one or more variables, while in English, any well-formed formula consisting of two expressions related with an equals sign is an equation.\nSolving an equation containing variables consists of determining which values of the variables make the equality true. The variables for which the equation has to be solved are also called unknowns, and the values of the unknowns that satisfy the equality are called solutions of the equation. There are two kinds of equations: identities and conditional equations. An identity is true for all values of the variables. A conditional equation is only true for particular values of the variables.\nThe \"=\" symbol, which appears in every equation, was invented in 1557 b",
    "content": "In mathematics, an equation is a mathematical formula that expresses the equality of two expressions, by connecting them with the equals sign =. The word equation and its cognates in other languages may have subtly different meanings; for example, in French an équation is defined as containing one or more variables, while in English, any well-formed formula consisting of two expressions related with an equals sign is an equation.\nSolving an equation containing variables consists of determining which values of the variables make the equality true. The variables for which the equation has to be solved are also called unknowns, and the values of the unknowns that satisfy the equality are called solutions of the equation. There are two kinds of equations: identities and conditional equations. An identity is true for all values of the variables. A conditional equation is only true for particular values of the variables.\nThe \"=\" symbol, which appears in every equation, was invented in 1557 by Robert Recorde, who considered that nothing could be more equal than parallel straight lines with the same length.\n\nDescription\nAn equation is written as two expressions, connected by an equals sign (\"=\"). The expressions on the two sides of the equals sign are called the \"left-hand side\" and \"right-hand side\" of the equation. Very often the right-hand side of an equation is assumed to be zero. This does not reduce the generality, as this can be realized by subtracting the right-hand side from both sides.\nThe most common type of equation is a polynomial equation (commonly called also an algebraic equation) in which the two sides are polynomials.\nThe sides of a polynomial equation contain one or more terms. For example, the equation \n\n  \n    \n      \n        A\n        \n          x\n          \n            2\n          \n        \n        +\n        B\n        x\n        +\n        C\n        −\n        y\n        =\n        0\n      \n    \n    {\\displaystyle Ax^{2}+Bx+C-y=0}\n  \n\nhas left-hand side \n  \n    \n      \n        A\n        \n          x\n          \n            2\n          \n        \n        +\n        B\n        x\n        +\n        C\n        −\n        y\n      \n    \n    {\\displaystyle Ax^{2}+Bx+C-y}\n  \n, which has four terms, and right-hand side \n  \n    \n      \n        0\n      \n    \n    {\\displaystyle 0}\n  \n, consisting of just one term. The names of the variables suggest that x and y are unknowns, and that  A, B, and C are parameters, but this is normally fixed by the context (in some contexts, y may be a parameter, or A, B, and C may be ordinary variables).\nAn equation is analogous to a scale into which weights are placed. When equal weights of something (e.g., grain) are placed into the two pans, the two weights cause the scale to be in balance and are said to be equal. If a quantity of grain is removed from one pan of the balance, an equal amount must be removed from the other pan to keep the scale in balance. More generally, an equation remains balanced if the same operation is performed on each side.\n\nProperties\nTwo equations or two systems of equations are equivalent, if they have the same set of solutions. The following operations transform an equation or a system of equations into an equivalent one – provided that the operations are meaningful for the expressions they are applied to:\n\nAdding or subtracting the same quantity to both sides of an equation. This shows that every equation is equivalent to an equation in which the right-hand side is zero.\nMultiplying or dividing both sides of an equation by a non-zero quantity.\nApplying an identity to transform one side of the equation. For example, expanding a product or factoring a sum.\nFor a system: adding to both sides of an equation the corresponding side of another equation, multiplied by the same quantity.\nIf some function is applied to both sides of an equation, the resulting equation has the solutions of the initial equation among its solutions, but may have further solutions called extraneous solutions. For example, the equation \n  \n    \n      \n        x\n        =\n        1\n      \n    \n    {\\displaystyle x=1}\n  \n has the solution \n  \n    \n      \n        x\n        =\n        1.\n      \n    \n    {\\displaystyle x=1.}\n  \n Raising both sides to the exponent of 2 (which means applying the function \n  \n    \n      \n        f\n        (\n        s\n        )\n        =\n        \n          s\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle f(s)=s^{2}}\n  \n to both sides of the equation) changes the equation to \n  \n    \n      \n        \n          x\n          \n            2\n          \n        \n        =\n        1\n      \n    \n    {\\displaystyle x^{2}=1}\n  \n, which not only has the previous solution but also introduces the extraneous solution, \n  \n    \n      \n        x\n        =\n        −\n        1.\n      \n    \n    {\\displaystyle x=-1.}\n  \n Moreover, if the function is not defined at some values (such as 1/x, which is not defined for x = 0), solutions existing at those val",
    "links": [
      "=",
      "Abel–Ruffini theorem",
      "Abstract algebra",
      "Addition",
      "Alexandria",
      "Algebra",
      "Algebraic curve",
      "Algebraic equation",
      "Algebraic expression",
      "Algebraic geometry",
      "Algebraic number",
      "Algebraic solution",
      "Algebraic surface",
      "Algebraic variety",
      "Algorithm",
      "Almost all",
      "Analytic geometry",
      "Antiderivative",
      "Approximation",
      "Cancelling out",
      "Cartesian coordinate",
      "Cartesian coordinates",
      "Cartesian geometry",
      "Cassini oval",
      "Chemistry",
      "Circle",
      "Clearing denominators",
      "Cognate",
      "Commutative algebra",
      "Complex number",
      "Computer model",
      "Computer science",
      "Computer simulation",
      "Cone",
      "Conic section",
      "Coordinates",
      "Cosine function",
      "Cubic curve",
      "Cubic equation",
      "Curve",
      "Degree of a polynomial",
      "Delay differential equation",
      "Derivative",
      "Descartes",
      "Difference equation",
      "Difference of two squares",
      "Differential equation",
      "Dimension",
      "Dimension of a manifold",
      "Diophantine equation"
    ],
    "categories": [
      "Category:Articles containing explicitly cited English-language text",
      "Category:Articles needing translation from French Wikipedia",
      "Category:Articles with short description",
      "Category:CS1 French-language sources (fr)",
      "Category:Elementary algebra",
      "Category:Equations",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Factoring a quadratic expression": {
    "title": "Quadratic equation",
    "url": "https://en.wikipedia.org/wiki/Quadratic_equation",
    "summary": "In mathematics, a quadratic equation (from Latin  quadratus 'square') is an equation that can be rearranged in standard form as\n\n  \n    \n      \n        a\n        \n          x\n          \n            2\n          \n        \n        +\n        b\n        x\n        +\n        c\n        =\n        0\n        \n        ,\n      \n    \n    {\\displaystyle ax^{2}+bx+c=0\\,,}\n  \n\nwhere the variable x represents an unknown number, and a, b, and c represent known numbers, where a ≠ 0. (If a = 0 and b ≠ 0 then the equation is linear, not quadratic.) The numbers a, b, and c are the coefficients of the equation and may be distinguished by respectively calling them, the quadratic coefficient, the linear coefficient and the constant coefficient or free term.\nThe values of x that satisfy the equation are called solutions of the equation, and roots or zeros of the quadratic function on its left-hand side. A quadratic equation has at most two solutions. If there is only one solution, one says that it is a double roo",
    "content": "In mathematics, a quadratic equation (from Latin  quadratus 'square') is an equation that can be rearranged in standard form as\n\n  \n    \n      \n        a\n        \n          x\n          \n            2\n          \n        \n        +\n        b\n        x\n        +\n        c\n        =\n        0\n        \n        ,\n      \n    \n    {\\displaystyle ax^{2}+bx+c=0\\,,}\n  \n\nwhere the variable x represents an unknown number, and a, b, and c represent known numbers, where a ≠ 0. (If a = 0 and b ≠ 0 then the equation is linear, not quadratic.) The numbers a, b, and c are the coefficients of the equation and may be distinguished by respectively calling them, the quadratic coefficient, the linear coefficient and the constant coefficient or free term.\nThe values of x that satisfy the equation are called solutions of the equation, and roots or zeros of the quadratic function on its left-hand side. A quadratic equation has at most two solutions. If there is only one solution, one says that it is a double root. If all the coefficients are real numbers, there are either two real solutions, or a single real double root, or two complex solutions that are complex conjugates of each other. A quadratic equation always has two roots, if complex roots are included and a double root is counted for two. A quadratic equation can be factored into an equivalent equation \n\n  \n    \n      \n        a\n        \n          x\n          \n            2\n          \n        \n        +\n        b\n        x\n        +\n        c\n        =\n        a\n        (\n        x\n        −\n        r\n        )\n        (\n        x\n        −\n        s\n        )\n        =\n        0\n      \n    \n    {\\displaystyle ax^{2}+bx+c=a(x-r)(x-s)=0}\n  \n\nwhere r and s are the solutions for x. \nThe quadratic formula\n\n  \n    \n      \n        x\n        =\n        \n          \n            \n              −\n              b\n              ±\n              \n                \n                  \n                    b\n                    \n                      2\n                    \n                  \n                  −\n                  4\n                  a\n                  c\n                \n              \n            \n            \n              2\n              a\n            \n          \n        \n      \n    \n    {\\displaystyle x={\\frac {-b\\pm {\\sqrt {b^{2}-4ac}}}{2a}}}\n  \n\nexpresses the solutions in terms of a, b, and c. Completing the square is one of several ways for deriving the formula.\nSolutions to problems that can be expressed in terms of quadratic equations were known as early as 2000 BC.\nBecause the quadratic equation involves only one unknown, it is called \"univariate\". The quadratic equation contains only powers of x that are non-negative integers, and therefore it is a polynomial equation. In particular, it is a second-degree polynomial equation, since the greatest power is two.\n\nSolving the quadratic equation\nA quadratic equation whose coefficients are real numbers can have either zero, one, or two distinct real-valued solutions, also called roots. When there is only one distinct root, it can be interpreted as two roots with the same value, called a double root. When there are no real roots, the coefficients can be considered as complex numbers with zero imaginary part, and the quadratic equation still has two complex-valued roots, complex conjugates of each-other with a non-zero imaginary part. A quadratic equation whose coefficients are arbitrary complex numbers always has two complex-valued roots which may or may not be distinct.\nThe solutions of a quadratic equation can be found by several alternative methods.\n\nFactoring by inspection\nIt may be possible to express a quadratic equation ax2 + bx + c = 0 as a product (px + q)(rx + s) = 0. In some cases, it is possible, by simple inspection, to determine values of p, q, r, and s that make the two forms equivalent to one another. If the quadratic equation is written in the second form, then the \"Zero Factor Property\" states that the quadratic equation is satisfied if px + q = 0 or rx + s = 0. Solving these two linear equations provides the roots of the quadratic.\nFor most students, factoring by inspection is the first method of solving quadratic equations to which they are exposed. If one is given a quadratic equation in the form x2 + bx + c = 0, the sought factorization has the form (x + q)(x + s), and one has to find two numbers q and s that add up to  b and whose product is c (this is sometimes called \"Vieta's rule\" and is related to Vieta's formulas). As an example, x2 + 5x + 6 factors as (x + 3)(x + 2). The more general case where a does not equal 1 can require a considerable effort in trial and error guess-and-check, assuming that it can be factored at all by inspection.\nExcept for special cases such as where b = 0 or c = 0, factoring by inspection only works for quadratic equations that have rational roots. This means that the great majority of quadratic equations that arise in practical applications cannot be solved by factoring by ",
    "links": [
      "'Abd al-Hamīd ibn Turk",
      "Abraham bar Hiyya",
      "Abū Kāmil Shujā ibn Aslam",
      "Acceleration",
      "Acid dissociation constant",
      "Acid strength",
      "Algorithm",
      "Arithmetica",
      "Artin–Schreier theory",
      "Babylonian mathematics",
      "Bakhshali Manuscript",
      "Berlin Papyrus 6619",
      "Bibcode (identifier)",
      "Bicentric quadrilateral",
      "Binomial (polynomial)",
      "Bisection",
      "Bivariate polynomial",
      "Brahmagupta",
      "Brāhmasphuṭasiddhānta",
      "Carlyle circle",
      "Catastrophic cancellation",
      "Celestial mechanics",
      "Characteristic (algebra)",
      "Chemistry",
      "Chinese mathematics",
      "Circle",
      "Circumscribed circle",
      "Clay tablet",
      "Coefficient",
      "Coefficients",
      "Common logarithm",
      "Completing the square",
      "Complex conjugate",
      "Complex number",
      "Complex numbers",
      "Conic sections",
      "Constant function",
      "Coordinates",
      "Cosine",
      "Critical point (mathematics)",
      "Cross multiplication",
      "Cube root",
      "Cubic equation",
      "Cubic function",
      "Degree of a polynomial",
      "Delta (letter)",
      "Descartes' theorem",
      "Diophantus",
      "Discriminant",
      "Displacement (geometry)"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1: unfit URL",
      "Category:CS1 errors: ISBN date",
      "Category:Commons category link from Wikidata",
      "Category:Elementary algebra",
      "Category:Equations",
      "Category:Short description is different from Wikidata",
      "Category:Webarchive template wayback links",
      "Category:Wikipedia articles needing clarification from September 2021"
    ]
  },
  "Field (mathematics)": {
    "title": "Field (mathematics)",
    "url": "https://en.wikipedia.org/wiki/Field_(mathematics)",
    "summary": "In mathematics, a field is a set on which addition, subtraction, multiplication, and division are defined and behave as the corresponding operations on rational and real numbers. A field is thus a fundamental algebraic structure which is widely used in algebra, number theory, and many other areas of mathematics.\nThe best known fields are the field of rational numbers, the field of real numbers and the field of complex numbers. Many other fields, such as fields of rational functions, algebraic function fields, algebraic number fields, and p-adic fields are commonly used and studied in mathematics, particularly in number theory and algebraic geometry. Most cryptographic protocols rely on finite fields, i.e., fields with finitely many elements.\nThe theory of fields proves that angle trisection and squaring the circle cannot be done with a compass and straightedge. Galois theory, devoted to understanding the symmetries of field extensions, provides an elegant proof of the Abel–Ruffini theo",
    "content": "In mathematics, a field is a set on which addition, subtraction, multiplication, and division are defined and behave as the corresponding operations on rational and real numbers. A field is thus a fundamental algebraic structure which is widely used in algebra, number theory, and many other areas of mathematics.\nThe best known fields are the field of rational numbers, the field of real numbers and the field of complex numbers. Many other fields, such as fields of rational functions, algebraic function fields, algebraic number fields, and p-adic fields are commonly used and studied in mathematics, particularly in number theory and algebraic geometry. Most cryptographic protocols rely on finite fields, i.e., fields with finitely many elements.\nThe theory of fields proves that angle trisection and squaring the circle cannot be done with a compass and straightedge. Galois theory, devoted to understanding the symmetries of field extensions, provides an elegant proof of the Abel–Ruffini theorem that general quintic equations cannot be solved in radicals.\nFields serve as foundational notions in several mathematical domains. This includes different branches of mathematical analysis, which are based on fields with additional structure. Basic theorems in analysis hinge on the structural properties of the field of real numbers. Most importantly for algebraic purposes, any field may be used as the scalars for a vector space, which is the standard general context for linear algebra. Number fields, the siblings of the field of rational numbers, are studied in depth in number theory. Function fields can help describe properties of geometric objects.\n\nDefinition\nInformally, a field is a set, along with two operations defined on that set: an addition operation a + b and a multiplication operation a ⋅ b, both of which behave similarly as they do for rational numbers and real numbers.  This includes the existence of an additive inverse −a for each element a and of a multiplicative inverse b−1 for each nonzero element b. This allows the definition of the so-called inverse operations, subtraction a − b and division a / b, as a − b = a + (−b) and a / b = a ⋅ b−1.\nOften the product a ⋅ b is represented by juxtaposition, as ab.\n\nClassic definition\nFormally, a field is a set F together with two binary operations on F called addition and multiplication. A binary operation on F is a mapping F × F → F, that is, a correspondence that associates with each ordered pair of elements of F a uniquely determined element of F. The result of the addition of a and b is called the sum of a and b, and is denoted a + b. Similarly, the result of the multiplication of a and b is called the product of a and b, and is denoted a ⋅ b. These operations are required to satisfy the following properties, referred to as field axioms. \nThese axioms are required to hold for all elements  a, b, c of the field F:\n\nAssociativity of addition and multiplication: a + (b + c) = (a + b) + c, and a ⋅ (b ⋅ c) = (a ⋅ b) ⋅ c.\nCommutativity of addition and multiplication: a + b = b + a, and a ⋅ b = b ⋅ a.\nAdditive and multiplicative identity: there exist two distinct elements 0 and 1 in F such that a + 0 = a and a ⋅ 1 = a.\nAdditive inverses: for every a in F, there exists an element in F, denoted −a, called the additive inverse of a, such that a + (−a) = 0.\nMultiplicative inverses: for every a ≠ 0 in F, there exists an element in F, denoted by a−1 or 1/a, called the multiplicative inverse of a, such that a ⋅ a−1 = 1.\nDistributivity of multiplication over addition: a ⋅ (b + c) = (a ⋅ b) + (a ⋅ c).\nAn equivalent, and more succinct, definition is: a field has two commutative operations, called addition and multiplication; it is a group under addition with 0 as the additive identity; the nonzero elements form a group under multiplication with 1 as the multiplicative identity; and multiplication distributes over addition.\nEven more succinctly: a field is a commutative ring where 0 ≠ 1 and all nonzero elements are invertible under multiplication.\n\nAlternative definition\nFields can also be defined in different, but equivalent ways. One can alternatively define a field by four binary operations (addition, subtraction, multiplication, and division) and their required properties. Division by zero is, by definition, excluded. In order to avoid existential quantifiers, fields can be defined by two binary operations (addition and multiplication), two unary operations (yielding the additive and multiplicative inverses respectively), and two nullary operations (the constants 0 and 1). These operations are then subject to the conditions above. Avoiding existential quantifiers is important in constructive mathematics and computing. One may equivalently define a field by the same two binary operations, one unary operation (the multiplicative inverse), and two (not necessarily distinct) constants 1 and −1, since 0 = 1 + (−1) and −a = (−1)a.\n\nExamples\nRational numbers\nRational numbers have bee",
    "links": [
      "Abelian extension",
      "Abelian group",
      "Abel–Ruffini theorem",
      "Absolute Galois group",
      "Absolute value",
      "Abstract algebraic variety",
      "Academic Press",
      "Addison-Wesley",
      "Addition",
      "Additive group",
      "Additive identity",
      "Additive inverse",
      "Adjunction (field theory)",
      "Affine space",
      "Alexandre-Théophile Vandermonde",
      "Algebra",
      "Algebra over a field",
      "Algebraic K-theory",
      "Algebraic closure",
      "Algebraic curve",
      "Algebraic element",
      "Algebraic extension",
      "Algebraic function field",
      "Algebraic geometry",
      "Algebraic number",
      "Algebraic number field",
      "Algebraic number theory",
      "Algebraic structure",
      "Algebraic topology",
      "Algebraically closed",
      "Algebraically independent",
      "Allyn and Bacon",
      "Alternative algebra",
      "Angle trisection",
      "ArXiv (identifier)",
      "Archimedean field",
      "Arithmetic geometry",
      "Arity",
      "Artin–Schreier theorem",
      "Associative algebra",
      "Associativity",
      "Axiom",
      "Axiom of choice",
      "Ax–Kochen theorem",
      "Basis (linear algebra)",
      "Bialgebra",
      "Bibcode (identifier)",
      "Bijection",
      "Binary field",
      "Binary operation"
    ],
    "categories": [
      "Category:Abstract algebra",
      "Category:Algebraic structures",
      "Category:Articles with short description",
      "Category:CS1 German-language sources (de)",
      "Category:Field (mathematics)",
      "Category:Good articles",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Function (mathematics)": {
    "title": "Function (mathematics)",
    "url": "https://en.wikipedia.org/wiki/Function_(mathematics)",
    "summary": "In mathematics, a function from a set X to a set Y assigns to each element of X exactly one element of Y. The set X is called the domain of the function and the set Y is called the codomain of the function.\nFunctions were originally the idealization of how a varying quantity depends on another quantity. For example, the position of a planet is a function of time. Historically, the concept was elaborated with the infinitesimal calculus at the end of the 17th century, and, until the 19th century, the functions that were considered were differentiable (that is, they had a high degree of regularity). The concept of a function was formalized at the end of the 19th century in terms of set theory, and this greatly increased the possible applications of the concept.\nA function is often denoted by a letter such as f, g or h. The value of a function f at an element x of its domain (that is, the element of the codomain that is associated with x) is denoted by f(x); for example, the value of f at ",
    "content": "In mathematics, a function from a set X to a set Y assigns to each element of X exactly one element of Y. The set X is called the domain of the function and the set Y is called the codomain of the function.\nFunctions were originally the idealization of how a varying quantity depends on another quantity. For example, the position of a planet is a function of time. Historically, the concept was elaborated with the infinitesimal calculus at the end of the 17th century, and, until the 19th century, the functions that were considered were differentiable (that is, they had a high degree of regularity). The concept of a function was formalized at the end of the 19th century in terms of set theory, and this greatly increased the possible applications of the concept.\nA function is often denoted by a letter such as f, g or h. The value of a function f at an element x of its domain (that is, the element of the codomain that is associated with x) is denoted by f(x); for example, the value of f at x = 4 is denoted by f(4). Commonly, a specific function is defined by means of an expression depending on x, such as \n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        \n          x\n          \n            2\n          \n        \n        +\n        1\n        ;\n      \n    \n    {\\displaystyle f(x)=x^{2}+1;}\n  \n in this case, some computation, called function evaluation, may be needed for deducing the value of the function at a particular value; for example, if \n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        \n          x\n          \n            2\n          \n        \n        +\n        1\n        ,\n      \n    \n    {\\displaystyle f(x)=x^{2}+1,}\n  \n then \n  \n    \n      \n        f\n        (\n        4\n        )\n        =\n        \n          4\n          \n            2\n          \n        \n        +\n        1\n        =\n        17.\n      \n    \n    {\\displaystyle f(4)=4^{2}+1=17.}\n  \n\nGiven its domain and its codomain, a function is uniquely represented by the set of all pairs (x, f (x)), called the graph of the function, a popular means of illustrating the function. When the domain and the codomain are sets of real numbers, each such pair may be thought of as the Cartesian coordinates of a point in the plane.\nFunctions are widely used in science, engineering, and in most fields of mathematics. It has been said that functions are \"the central objects of investigation\" in most fields of mathematics.\nThe concept of a function has evolved significantly over centuries, from its informal origins in ancient mathematics to its formalization in the 19th century. See History of the function concept for details.\n\nDefinition\nA function f from a set X to a set Y is an assignment of one element of Y to each element of X. The set X is called the domain of the function and the set Y is called the codomain of the function.\nIf the element y in Y is assigned to x in X by the function f, one says that f maps x to y, and this is commonly written \n  \n    \n      \n        y\n        =\n        f\n        (\n        x\n        )\n        .\n      \n    \n    {\\displaystyle y=f(x).}\n  \n In this notation, x is the argument or variable of the function.\nA specific element x of X is a value of the variable, and the corresponding element of Y is the value of the function at x, or the image of x under the function. The image of a function, sometimes called its range, is the set of the images of all elements in the domain.\nA function f, its domain X, and its codomain Y are often specified  by the notation \n  \n    \n      \n        f\n        :\n        X\n        →\n        Y\n        .\n      \n    \n    {\\displaystyle f:X\\to Y.}\n  \n One may write \n  \n    \n      \n        x\n        ↦\n        y\n      \n    \n    {\\displaystyle x\\mapsto y}\n  \n instead of \n  \n    \n      \n        y\n        =\n        f\n        (\n        x\n        )\n      \n    \n    {\\displaystyle y=f(x)}\n  \n, where the symbol \n  \n    \n      \n        ↦\n      \n    \n    {\\displaystyle \\mapsto }\n  \n (read 'maps to') is used to specify where a particular element x in the domain is mapped to by f.  This allows the definition of a function without naming. For example, the square function is the function \n  \n    \n      \n        x\n        ↦\n        \n          x\n          \n            2\n          \n        \n        .\n      \n    \n    {\\displaystyle x\\mapsto x^{2}.}\n  \n\nThe domain and codomain are not always explicitly given when a function is defined. In particular, it is common that one might only know, without some (possibly difficult) computation, that the domain of a specific function is contained in a larger set. For example, if \n  \n    \n      \n        f\n        :\n        \n          R\n        \n        →\n        \n          R\n        \n      \n    \n    {\\displaystyle f:\\mathbb {R} \\to \\mathbb {R} }\n  \n is a real function, the determination of the domain of the function \n  \n    \n      \n        x\n        ↦\n        1\n        \n          /\n        \n        f\n        (\n        x\n        )\n      \n    \n    {\\d",
    "links": [
      "Abstraction (computer science)",
      "Abuse of notation",
      "Addison-Wesley",
      "Algebraic function",
      "Algorithm",
      "Analytic continuation",
      "Analytic function",
      "Andrew M. Bruckner",
      "Antiderivative",
      "Arccosine",
      "Argument of a function",
      "Arithmetic operations",
      "Associative array",
      "Associative property",
      "Axiom",
      "Axiom of choice",
      "Bar chart",
      "Bijection",
      "Bijection, injection and surjection",
      "Bijective",
      "Binary operation",
      "Binary relation",
      "Binary representation",
      "Bit",
      "Bivariate interpolation",
      "Black box",
      "Boolean-valued function",
      "Boolean function",
      "Branch cut",
      "Bra–ket notation",
      "Bring radical",
      "Calculus",
      "Calculus of variations",
      "Cartesian coordinates",
      "Cartesian plane",
      "Cartesian product",
      "Category (mathematics)",
      "Category theory",
      "Church–Turing thesis",
      "CiteSeerX (identifier)",
      "Class (set theory)",
      "Closed-form expression",
      "Codomain",
      "Commutative diagram",
      "Commutative property",
      "Compact set",
      "Compact support",
      "Complex-valued function",
      "Complex analysis",
      "Complex function"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Basic concepts in set theory",
      "Category:CS1 errors: ISBN date",
      "Category:Elementary mathematics",
      "Category:Functions and mappings",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Group (mathematics)": {
    "title": "Group (mathematics)",
    "url": "https://en.wikipedia.org/wiki/Group_(mathematics)",
    "summary": "In mathematics, a group is a set with an operation that combines any two elements of the set to produce a third element within the same set and the following conditions must hold: the operation is associative, it has an identity element, and every element of the set has an inverse element. For example, the integers with the addition operation form a group.\nThe concept of a group was elaborated for handling, in a unified way, many mathematical structures such as numbers, geometric shapes and polynomial roots. Because the concept of groups is ubiquitous in numerous areas both within and outside mathematics, some authors consider it as a central organizing principle of contemporary mathematics.\nIn geometry, groups arise naturally in the study of symmetries and geometric transformations: The symmetries of an object form a group, called the symmetry group of the object, and the transformations of a given type form a general group.  Lie groups appear in symmetry groups in geometry, and also ",
    "content": "In mathematics, a group is a set with an operation that combines any two elements of the set to produce a third element within the same set and the following conditions must hold: the operation is associative, it has an identity element, and every element of the set has an inverse element. For example, the integers with the addition operation form a group.\nThe concept of a group was elaborated for handling, in a unified way, many mathematical structures such as numbers, geometric shapes and polynomial roots. Because the concept of groups is ubiquitous in numerous areas both within and outside mathematics, some authors consider it as a central organizing principle of contemporary mathematics.\nIn geometry, groups arise naturally in the study of symmetries and geometric transformations: The symmetries of an object form a group, called the symmetry group of the object, and the transformations of a given type form a general group.  Lie groups appear in symmetry groups in geometry, and also in the Standard Model of particle physics. The Poincaré group is a Lie group consisting of the symmetries of spacetime in special relativity. Point groups describe symmetry in molecular chemistry.\nThe concept of a group arose in the study of polynomial equations, starting with Évariste Galois in the 1830s, who introduced the term group (French: groupe) for the symmetry group of the roots of an equation, now called a Galois group. After contributions from other fields such as number theory and geometry, the group notion was generalized and firmly established around 1870. Modern group theory—an active mathematical discipline—studies groups in their own right. To explore groups, mathematicians have devised various notions to break groups into smaller, better-understandable pieces, such as subgroups, quotient groups and simple groups. In addition to their abstract properties, group theorists also study the different ways in which a group can be expressed concretely, both from a point of view of representation theory (that is, through the representations of the group) and of computational group theory. A theory has been developed for finite groups, which culminated with the classification of finite simple groups, completed in 2004. Since the mid-1980s, geometric group theory, which studies finitely generated groups as geometric objects, has become an active area in group theory.\n\nDefinition and illustration\nFirst example: the integers\nOne of the more familiar groups is the set of integers \n\n  \n    \n      \n        \n          Z\n        \n        =\n        {\n        …\n        ,\n        −\n        4\n        ,\n        −\n        3\n        ,\n        −\n        2\n        ,\n        −\n        1\n        ,\n        0\n        ,\n        1\n        ,\n        2\n        ,\n        3\n        ,\n        4\n        ,\n        …\n        }\n      \n    \n    {\\displaystyle \\mathbb {Z} =\\{\\ldots ,-4,-3,-2,-1,0,1,2,3,4,\\ldots \\}}\n  \n\ntogether with addition. For any two integers \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n and ⁠\n  \n    \n      \n        b\n      \n    \n    {\\displaystyle b}\n  \n⁠, the sum \n  \n    \n      \n        a\n        +\n        b\n      \n    \n    {\\displaystyle a+b}\n  \n is also an integer; this closure property says that \n  \n    \n      \n        +\n      \n    \n    {\\displaystyle +}\n  \n is a binary operation on ⁠\n  \n    \n      \n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} }\n  \n⁠. The following properties of integer addition serve as a model for the group axioms in the definition below.\n\nFor all integers ⁠\n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n⁠, \n  \n    \n      \n        b\n      \n    \n    {\\displaystyle b}\n  \n and ⁠\n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  \n⁠, one has ⁠\n  \n    \n      \n        (\n        a\n        +\n        b\n        )\n        +\n        c\n        =\n        a\n        +\n        (\n        b\n        +\n        c\n        )\n      \n    \n    {\\displaystyle (a+b)+c=a+(b+c)}\n  \n⁠. Expressed in words, adding \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n to \n  \n    \n      \n        b\n      \n    \n    {\\displaystyle b}\n  \n first, and then adding the result to \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  \n gives the same final result as adding \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n to the sum of \n  \n    \n      \n        b\n      \n    \n    {\\displaystyle b}\n  \n and ⁠\n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  \n⁠. This property is known as associativity.\nIf \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n is any integer, then \n  \n    \n      \n        0\n        +\n        a\n        =\n        a\n      \n    \n    {\\displaystyle 0+a=a}\n  \n and ⁠\n  \n    \n      \n        a\n        +\n        0\n        =\n        a\n      \n    \n    {\\displaystyle a+0=a}\n  \n⁠. Zero is called the identity element of addition because adding it to any integer returns the same integer.\nFor every integer ⁠\n  \n    \n      ",
    "links": [
      "(2,3,7) triangle group",
      "12-hour clock",
      "Abelian group",
      "Abelian variety",
      "Absolute Galois group",
      "Abstract algebra",
      "Abstract group",
      "Abstraction (mathematics)",
      "Abuse of notation",
      "Addison-Wesley",
      "Addition",
      "Additive group",
      "Adele ring",
      "Affine space",
      "Algebra",
      "Algebra (Lang)",
      "Algebra over a field",
      "Algebraic expression",
      "Algebraic geometry",
      "Algebraic group",
      "Algebraic number theory",
      "Algebraic structure",
      "Algebraic topology",
      "Algebraic variety",
      "Algorithm",
      "Allen Hatcher",
      "Alternating group",
      "American Mathematical Society",
      "Ammonia",
      "Ancient Greek",
      "Anna Romanowska",
      "Anthony Zee",
      "Antiderivative",
      "Applied mathematics",
      "ArXiv (identifier)",
      "Arithmetic group",
      "Arity",
      "Armand Borel",
      "Arthur Cayley",
      "Associative algebra",
      "Associative property",
      "Associativity",
      "Augustin Louis Cauchy",
      "Automorphism",
      "Automorphism group",
      "Axiom",
      "Baby monster group",
      "Basis (linear algebra)",
      "Bialgebra",
      "Bibcode (identifier)"
    ],
    "categories": [
      "Category:Algebraic structures",
      "Category:Articles containing French-language text",
      "Category:Articles containing German-language text",
      "Category:Articles with short description",
      "Category:CS1: long volume value",
      "Category:CS1 French-language sources (fr)",
      "Category:CS1 German-language sources (de)",
      "Category:CS1 errors: ISBN date",
      "Category:Featured articles",
      "Category:Group theory"
    ]
  },
  "Quadratic equation": {
    "title": "Quadratic equation",
    "url": "https://en.wikipedia.org/wiki/Quadratic_equation",
    "summary": "In mathematics, a quadratic equation (from Latin  quadratus 'square') is an equation that can be rearranged in standard form as\n\n  \n    \n      \n        a\n        \n          x\n          \n            2\n          \n        \n        +\n        b\n        x\n        +\n        c\n        =\n        0\n        \n        ,\n      \n    \n    {\\displaystyle ax^{2}+bx+c=0\\,,}\n  \n\nwhere the variable x represents an unknown number, and a, b, and c represent known numbers, where a ≠ 0. (If a = 0 and b ≠ 0 then the equation is linear, not quadratic.) The numbers a, b, and c are the coefficients of the equation and may be distinguished by respectively calling them, the quadratic coefficient, the linear coefficient and the constant coefficient or free term.\nThe values of x that satisfy the equation are called solutions of the equation, and roots or zeros of the quadratic function on its left-hand side. A quadratic equation has at most two solutions. If there is only one solution, one says that it is a double roo",
    "content": "In mathematics, a quadratic equation (from Latin  quadratus 'square') is an equation that can be rearranged in standard form as\n\n  \n    \n      \n        a\n        \n          x\n          \n            2\n          \n        \n        +\n        b\n        x\n        +\n        c\n        =\n        0\n        \n        ,\n      \n    \n    {\\displaystyle ax^{2}+bx+c=0\\,,}\n  \n\nwhere the variable x represents an unknown number, and a, b, and c represent known numbers, where a ≠ 0. (If a = 0 and b ≠ 0 then the equation is linear, not quadratic.) The numbers a, b, and c are the coefficients of the equation and may be distinguished by respectively calling them, the quadratic coefficient, the linear coefficient and the constant coefficient or free term.\nThe values of x that satisfy the equation are called solutions of the equation, and roots or zeros of the quadratic function on its left-hand side. A quadratic equation has at most two solutions. If there is only one solution, one says that it is a double root. If all the coefficients are real numbers, there are either two real solutions, or a single real double root, or two complex solutions that are complex conjugates of each other. A quadratic equation always has two roots, if complex roots are included and a double root is counted for two. A quadratic equation can be factored into an equivalent equation \n\n  \n    \n      \n        a\n        \n          x\n          \n            2\n          \n        \n        +\n        b\n        x\n        +\n        c\n        =\n        a\n        (\n        x\n        −\n        r\n        )\n        (\n        x\n        −\n        s\n        )\n        =\n        0\n      \n    \n    {\\displaystyle ax^{2}+bx+c=a(x-r)(x-s)=0}\n  \n\nwhere r and s are the solutions for x. \nThe quadratic formula\n\n  \n    \n      \n        x\n        =\n        \n          \n            \n              −\n              b\n              ±\n              \n                \n                  \n                    b\n                    \n                      2\n                    \n                  \n                  −\n                  4\n                  a\n                  c\n                \n              \n            \n            \n              2\n              a\n            \n          \n        \n      \n    \n    {\\displaystyle x={\\frac {-b\\pm {\\sqrt {b^{2}-4ac}}}{2a}}}\n  \n\nexpresses the solutions in terms of a, b, and c. Completing the square is one of several ways for deriving the formula.\nSolutions to problems that can be expressed in terms of quadratic equations were known as early as 2000 BC.\nBecause the quadratic equation involves only one unknown, it is called \"univariate\". The quadratic equation contains only powers of x that are non-negative integers, and therefore it is a polynomial equation. In particular, it is a second-degree polynomial equation, since the greatest power is two.\n\nSolving the quadratic equation\nA quadratic equation whose coefficients are real numbers can have either zero, one, or two distinct real-valued solutions, also called roots. When there is only one distinct root, it can be interpreted as two roots with the same value, called a double root. When there are no real roots, the coefficients can be considered as complex numbers with zero imaginary part, and the quadratic equation still has two complex-valued roots, complex conjugates of each-other with a non-zero imaginary part. A quadratic equation whose coefficients are arbitrary complex numbers always has two complex-valued roots which may or may not be distinct.\nThe solutions of a quadratic equation can be found by several alternative methods.\n\nFactoring by inspection\nIt may be possible to express a quadratic equation ax2 + bx + c = 0 as a product (px + q)(rx + s) = 0. In some cases, it is possible, by simple inspection, to determine values of p, q, r, and s that make the two forms equivalent to one another. If the quadratic equation is written in the second form, then the \"Zero Factor Property\" states that the quadratic equation is satisfied if px + q = 0 or rx + s = 0. Solving these two linear equations provides the roots of the quadratic.\nFor most students, factoring by inspection is the first method of solving quadratic equations to which they are exposed. If one is given a quadratic equation in the form x2 + bx + c = 0, the sought factorization has the form (x + q)(x + s), and one has to find two numbers q and s that add up to  b and whose product is c (this is sometimes called \"Vieta's rule\" and is related to Vieta's formulas). As an example, x2 + 5x + 6 factors as (x + 3)(x + 2). The more general case where a does not equal 1 can require a considerable effort in trial and error guess-and-check, assuming that it can be factored at all by inspection.\nExcept for special cases such as where b = 0 or c = 0, factoring by inspection only works for quadratic equations that have rational roots. This means that the great majority of quadratic equations that arise in practical applications cannot be solved by factoring by ",
    "links": [
      "'Abd al-Hamīd ibn Turk",
      "Abraham bar Hiyya",
      "Abū Kāmil Shujā ibn Aslam",
      "Acceleration",
      "Acid dissociation constant",
      "Acid strength",
      "Algorithm",
      "Arithmetica",
      "Artin–Schreier theory",
      "Babylonian mathematics",
      "Bakhshali Manuscript",
      "Berlin Papyrus 6619",
      "Bibcode (identifier)",
      "Bicentric quadrilateral",
      "Binomial (polynomial)",
      "Bisection",
      "Bivariate polynomial",
      "Brahmagupta",
      "Brāhmasphuṭasiddhānta",
      "Carlyle circle",
      "Catastrophic cancellation",
      "Celestial mechanics",
      "Characteristic (algebra)",
      "Chemistry",
      "Chinese mathematics",
      "Circle",
      "Circumscribed circle",
      "Clay tablet",
      "Coefficient",
      "Coefficients",
      "Common logarithm",
      "Completing the square",
      "Complex conjugate",
      "Complex number",
      "Complex numbers",
      "Conic sections",
      "Constant function",
      "Coordinates",
      "Cosine",
      "Critical point (mathematics)",
      "Cross multiplication",
      "Cube root",
      "Cubic equation",
      "Cubic function",
      "Degree of a polynomial",
      "Delta (letter)",
      "Descartes' theorem",
      "Diophantus",
      "Discriminant",
      "Displacement (geometry)"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1: unfit URL",
      "Category:CS1 errors: ISBN date",
      "Category:Commons category link from Wikidata",
      "Category:Elementary algebra",
      "Category:Equations",
      "Category:Short description is different from Wikidata",
      "Category:Webarchive template wayback links",
      "Category:Wikipedia articles needing clarification from September 2021"
    ]
  },
  "Multiplication": {
    "title": "Multiplication",
    "url": "https://en.wikipedia.org/wiki/Multiplication",
    "summary": "Multiplication is one of the four elementary mathematical operations of arithmetic, with the other ones being addition, subtraction, and division. The result of a multiplication operation is called a product. Multiplication is often denoted by the cross symbol, ×, by the mid-line dot operator, ·, by juxtaposition, or, in programming languages, by an asterisk, *.\nThe multiplication of whole numbers may be thought of as repeated addition; that is, the multiplication of two numbers is equivalent to adding as many copies of one of them, the multiplicand, as the quantity of the other one, the multiplier; both numbers can be referred to as factors. This is to be distinguished from terms, which are added.\n\n  \n    \n      \n        a\n        ×\n        b\n        =\n        \n          \n            \n              \n                b\n                +\n                ⋯\n                +\n                b\n              \n              ⏟\n            \n          \n          \n            a\n            \n     ",
    "content": "Multiplication is one of the four elementary mathematical operations of arithmetic, with the other ones being addition, subtraction, and division. The result of a multiplication operation is called a product. Multiplication is often denoted by the cross symbol, ×, by the mid-line dot operator, ·, by juxtaposition, or, in programming languages, by an asterisk, *.\nThe multiplication of whole numbers may be thought of as repeated addition; that is, the multiplication of two numbers is equivalent to adding as many copies of one of them, the multiplicand, as the quantity of the other one, the multiplier; both numbers can be referred to as factors. This is to be distinguished from terms, which are added.\n\n  \n    \n      \n        a\n        ×\n        b\n        =\n        \n          \n            \n              \n                b\n                +\n                ⋯\n                +\n                b\n              \n              ⏟\n            \n          \n          \n            a\n            \n               times\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle a\\times b=\\underbrace {b+\\cdots +b} _{a{\\text{ times}}}.}\n  \n\nWhether the first factor is the multiplier or the multiplicand may be ambiguous or depend upon context. For example, the expression \n  \n    \n      \n        3\n        ×\n        4\n      \n    \n    {\\displaystyle 3\\times 4}\n  \n, can be phrased as \"3 times 4\" and evaluated as \n  \n    \n      \n        4\n        +\n        4\n        +\n        4\n      \n    \n    {\\displaystyle 4+4+4}\n  \n, where 3 is the multiplier, but also as \"3 multiplied by 4\", in which case 3 becomes the multiplicand. One of the main properties of multiplication is the commutative property, which states in this case that adding 3 copies of 4 gives the same result as adding 4 copies of 3. Thus, the designation of multiplier and multiplicand does not affect the result of the multiplication.\n\nSystematic generalizations of this basic definition define the multiplication of integers (including negative numbers), rational numbers (fractions), and real numbers.\nMultiplication can also be visualized as counting objects arranged in a rectangle (for whole numbers) or as finding the area of a rectangle whose sides have some given lengths. The area of a rectangle does not depend on which side is measured first—a consequence of the commutative property.\nThe product of two measurements (or physical quantities) is a new type of measurement (or new quantity), usually with a derived unit of measurement. For example, multiplying the lengths (in meters or feet) of the two sides of a rectangle gives its area (in square meters or square feet). Such a product is the subject of dimensional analysis.\nThe inverse operation of multiplication is division. For example, since 4 multiplied by 3 equals 12, 12 divided by 3 equals 4. Indeed, multiplication by 3, followed by division by 3, yields the original number. The division of a number other than 0 by itself equals 1.\nSeveral mathematical concepts expand upon the fundamental idea of multiplication. The product of a sequence, vector multiplication, complex numbers, and matrices are all examples where this can be seen. These more advanced constructs tend to affect the basic properties in their own ways, such as becoming noncommutative in matrices and some forms of vector multiplication or changing the sign of complex numbers.\n\nNotation\nIn arithmetic, multiplication is often written using the multiplication sign (either × or \n  \n    \n      \n        ×\n      \n    \n    {\\displaystyle \\times }\n  \n) between the factors (that is, in infix notation). For example,\n\n  \n    \n      \n        2\n        ×\n        3\n        =\n        6\n        ,\n      \n    \n    {\\displaystyle 2\\times 3=6,}\n  \n (\"two times three equals six\")\n\n  \n    \n      \n        3\n        ×\n        4\n        =\n        12\n        ,\n      \n    \n    {\\displaystyle 3\\times 4=12,}\n  \n\n  \n    \n      \n        2\n        ×\n        3\n        ×\n        5\n        =\n        6\n        ×\n        5\n        =\n        30\n        ,\n      \n    \n    {\\displaystyle 2\\times 3\\times 5=6\\times 5=30,}\n  \n\n  \n    \n      \n        2\n        ×\n        2\n        ×\n        2\n        ×\n        2\n        ×\n        2\n        =\n        32.\n      \n    \n    {\\displaystyle 2\\times 2\\times 2\\times 2\\times 2=32.}\n  \n\nThere are other mathematical notations for multiplication:\n\nTo reduce confusion between the multiplication sign × and the common variable x, multiplication is also denoted by dot signs, usually a middle-position dot (rarely period): \n  \n    \n      \n        5\n        ⋅\n        2\n      \n    \n    {\\displaystyle 5\\cdot 2}\n  \n. The middle dot notation or dot operator is now standard in the United States and other countries. When the dot operator character is not accessible, the interpunct (·) is used. In most European and other countries that use a comma as a decimal point (and a period as a thousands separator), the multiplication sign or a middle dot is used to indicate mult",
    "links": [
      "ASCII",
      "Abelian group",
      "Absolute value",
      "Absorbing element",
      "Ackermann function",
      "Addition",
      "Additive inverse",
      "Al Khwarizmi",
      "Algebra",
      "Ancient Egypt",
      "Ancient Egyptian multiplication",
      "ArXiv (identifier)",
      "Arithmetic",
      "Arithmetic operation",
      "Arithmetic operations",
      "Arithmetices principia, nova methodo exposita",
      "Associative property",
      "Associativity",
      "Asterisk",
      "Babylonians",
      "Bibcode (identifier)",
      "Binary multiplier",
      "Booth's multiplication algorithm",
      "Brahmagupta",
      "Calculator",
      "Cardinal number",
      "Carl Boyer",
      "Cauchy sequence",
      "Central Africa",
      "Character set",
      "Chinese multiplication table",
      "Coefficient",
      "Comma (punctuation)",
      "Common logarithm",
      "Commutative property",
      "Commutativity",
      "Complex number",
      "Computational complexity",
      "Computer",
      "Computer programming",
      "Construction of the real numbers",
      "Conway chained arrow notation",
      "Cross product",
      "Cut-the-knot",
      "Decimal expansion",
      "Decimal point",
      "Decimal representation",
      "Determinant",
      "Dimension",
      "Dimensional analysis"
    ],
    "categories": [
      "Category:All articles needing additional references",
      "Category:All articles needing expert attention",
      "Category:All articles with specifically marked weasel-worded phrases",
      "Category:All articles with unsourced statements",
      "Category:All pages needing factual verification",
      "Category:Articles containing proofs",
      "Category:Articles needing additional references from April 2012",
      "Category:Articles needing expert attention from September 2023",
      "Category:Articles with short description",
      "Category:Articles with specifically marked weasel-worded phrases from December 2021"
    ]
  },
  "Number": {
    "title": "Number",
    "url": "https://en.wikipedia.org/wiki/Number",
    "summary": "A number is a mathematical object used to count, measure, and label. The most basic examples are the natural numbers 1, 2, 3, 4, and so forth. Individual numbers can be represented in language with number words or by dedicated symbols called numerals; for example, \"five\" is a number word and \"5\" is the corresponding numeral. As only a relatively small number of symbols can be memorized, basic numerals are commonly arranged in a numeral system, which is an organized way to represent any number. The most common numeral system is the Hindu–Arabic numeral system, which allows for the representation of any non-negative integer using a combination of ten fundamental numeric symbols, called digits. In addition to their use in counting and measuring, numerals are often used for labels (as with telephone numbers), for ordering (as with serial numbers), and for codes (as with ISBNs). In common usage, a numeral is not clearly distinguished from the number that it represents.\nIn mathematics, the n",
    "content": "A number is a mathematical object used to count, measure, and label. The most basic examples are the natural numbers 1, 2, 3, 4, and so forth. Individual numbers can be represented in language with number words or by dedicated symbols called numerals; for example, \"five\" is a number word and \"5\" is the corresponding numeral. As only a relatively small number of symbols can be memorized, basic numerals are commonly arranged in a numeral system, which is an organized way to represent any number. The most common numeral system is the Hindu–Arabic numeral system, which allows for the representation of any non-negative integer using a combination of ten fundamental numeric symbols, called digits. In addition to their use in counting and measuring, numerals are often used for labels (as with telephone numbers), for ordering (as with serial numbers), and for codes (as with ISBNs). In common usage, a numeral is not clearly distinguished from the number that it represents.\nIn mathematics, the notion of number has been extended over the centuries to include zero (0), negative numbers, rational numbers such as one half \n  \n    \n      \n        \n          (\n          \n            \n              \n                1\n                2\n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\left({\\tfrac {1}{2}}\\right)}\n  \n, real numbers such as the square root of 2 \n  \n    \n      \n        \n          (\n          \n            \n              2\n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\left({\\sqrt {2}}\\right)}\n  \n and π, and complex numbers which extend the real numbers with a square root of −1 (and its combinations with real numbers by adding or subtracting its multiples). Calculations with numbers are done with arithmetical operations, the most familiar being addition, subtraction, multiplication, division, and exponentiation. Their study or usage is called arithmetic, a term which may also refer to number theory, the study of the properties of numbers.\nBesides their practical uses, numbers have cultural significance throughout the world. For example, in Western society, the number 13 is often regarded as unlucky, and \"a million\" may signify \"a lot\" rather than an exact quantity. Though it is now regarded as pseudoscience, belief in a mystical significance of numbers, known as numerology, permeated ancient and medieval thought. Numerology heavily influenced the development of Greek mathematics, stimulating the investigation of many problems in number theory which are still of interest today.\nDuring the 19th century, mathematicians began to develop many different abstractions which share certain properties of numbers, and may be seen as extending the concept. Among the first were the hypercomplex numbers, which consist of various extensions or modifications of the complex number system. In modern mathematics, number systems are considered important special examples of more general algebraic structures such as rings and fields, and the application of the term \"number\" is a matter of convention, without fundamental significance.\n\nHistory\nFirst use of numbers\nBones and other artifacts have been discovered with marks cut into them that many believe are tally marks. Some historians suggest that the Lebombo bone (dated about 43,000 years ago) and the Ishango bone (dated about 22,000 to 30,000 years ago) are the oldest arithmetic artifacts but this interpretation is disputed. These tally marks may have been used for counting elapsed time, such as numbers of days, lunar cycles or keeping records of quantities, such as of animals.  A perceptual system for quantity thought to underlie numeracy, is shared with other species, a phylogenetic distribution suggesting it would have existed before the emergence of language.\nA tallying system has no concept of place value (as in modern decimal notation), which limits its representation of large numbers. Nonetheless, tallying systems are considered the first kind of abstract numeral system.\nThe earliest unambiguous numbers in the archaeological record are the Mesopotamian base 60 system (c. 3400 BC); place value emerged in it in the 3rd millennium BCE. The earliest known base 10 system dates to 3100 BC in Egypt.\n\nNumerals\nNumbers should be distinguished from numerals, the symbols used to represent numbers. The Egyptians invented the first ciphered numeral system, and the Greeks followed by mapping their counting numbers onto Ionian and Doric alphabets. Roman numerals, a system that used combinations of letters from the Roman alphabet, remained dominant in Europe until the spread of the Hindu–Arabic numeral system around the late 14th century, and the Hindu–Arabic numeral system remains the most common system for representing numbers in the world today. The key to the effectiveness of the system was the symbol for zero, which was developed by ancient Indian mathematicians around 500 AD.\n\nZero\nThe first known recorded use of zer",
    "links": [
      "0",
      "0.999...",
      "1",
      "13 (number)",
      "1 (number)",
      "Abel–Ruffini theorem",
      "Abraham Robinson",
      "Abraham de Moivre",
      "Absolute value",
      "Actual infinity",
      "Ad infinitum",
      "Addition",
      "Additive number theory",
      "Adrien-Marie Legendre",
      "Alfred North Whitehead",
      "Algebra of physical space",
      "Algebraic function",
      "Algebraic function field",
      "Algebraic integer",
      "Algebraic number",
      "Algebraic number theory",
      "Algebraic numbers",
      "Algebraically closed field",
      "Algorithm",
      "Almost all",
      "Alternative algebra",
      "Anabelian geometry",
      "Analytic number theory",
      "Ancient Egyptians",
      "Ancient Mesopotamian units of measurement",
      "ArXiv (identifier)",
      "Arakelov theory",
      "Aristotle",
      "Arithmetic",
      "Arithmetic combinatorics",
      "Arithmetic dynamics",
      "Arithmetic function",
      "Arithmetic geometry",
      "Arithmetic topology",
      "Arithmetica",
      "Ashtadhyayi",
      "Associative",
      "August Ferdinand Möbius",
      "Base 10",
      "Bede",
      "Bernhard Riemann",
      "Bertrand Russell",
      "Bhāskara II",
      "Bicomplex number",
      "Bijection"
    ],
    "categories": [
      "Category:Abstraction",
      "Category:All articles lacking reliable references",
      "Category:All articles needing additional references",
      "Category:All articles with unsourced statements",
      "Category:Articles containing German-language text",
      "Category:Articles containing Latin-language text",
      "Category:Articles containing Sanskrit-language text",
      "Category:Articles lacking reliable references from September 2020",
      "Category:Articles needing additional references from April 2025",
      "Category:Articles prone to spam from July 2022"
    ]
  },
  "Mathematical operation": {
    "title": "Operation (mathematics)",
    "url": "https://en.wikipedia.org/wiki/Operation_(mathematics)",
    "summary": "In mathematics, an operation is a function from a set to itself. For example, an operation on real numbers will take in real numbers and return a real number. An operation can take zero or more input values (also called \"operands\" or \"arguments\") to a well-defined output value. The number of operands is the arity of the operation.\nThe most commonly studied operations are binary operations (i.e., operations of arity 2), such as addition and multiplication, and unary operations (i.e., operations of arity 1), such as additive inverse and multiplicative inverse. An operation of arity zero, or nullary operation, is a constant. The mixed product is an example of an operation of arity 3, also called ternary operation.\nGenerally, the arity is taken to be finite. However, infinitary operations are sometimes considered, in which case the \"usual\" operations of finite arity are called finitary operations.\nA partial operation is defined similarly to an operation, but with a partial function in plac",
    "content": "In mathematics, an operation is a function from a set to itself. For example, an operation on real numbers will take in real numbers and return a real number. An operation can take zero or more input values (also called \"operands\" or \"arguments\") to a well-defined output value. The number of operands is the arity of the operation.\nThe most commonly studied operations are binary operations (i.e., operations of arity 2), such as addition and multiplication, and unary operations (i.e., operations of arity 1), such as additive inverse and multiplicative inverse. An operation of arity zero, or nullary operation, is a constant. The mixed product is an example of an operation of arity 3, also called ternary operation.\nGenerally, the arity is taken to be finite. However, infinitary operations are sometimes considered, in which case the \"usual\" operations of finite arity are called finitary operations.\nA partial operation is defined similarly to an operation, but with a partial function in place of a function.\n\nTypes of operation\nThere are two common types of operations: unary and binary. Unary operations involve only one value, such as negation and trigonometric functions. Binary operations, on the other hand, take two values, and include addition, subtraction, multiplication, division, and exponentiation.\nOperations can involve mathematical objects other than numbers. The logical values true and false can be combined using logic operations, such as and, or, and not. Vectors can be added and subtracted. Rotations can be combined using the function composition operation, performing the first rotation and then the second. Operations on sets include the binary operations union and intersection and the unary operation of complementation. Operations on functions include composition and convolution.\nOperations may not be defined for every possible value of its domain. For example, in the real numbers one cannot divide by zero or take square roots of negative numbers. The values for which an operation is defined form a set called its domain of definition or active domain. The set which contains the values produced is called the codomain, but the set of actual values attained by the operation is its codomain of definition, active codomain, image or range. For example, in the real numbers, the squaring operation only produces non-negative numbers; the codomain is the set of real numbers, but the range is the non-negative numbers.\nOperations can involve dissimilar objects: a vector can be multiplied by a scalar to form another vector (an operation known as scalar multiplication), and the inner product operation on two vectors produces a quantity that is scalar. An operation may or may not have certain properties, for example it may be associative, commutative, anticommutative, idempotent, and so on.\nThe values combined are called operands, arguments, or inputs, and the value produced is called the value, result, or output. Operations can have fewer or more than two inputs (including the case of zero input and infinitely many inputs).\nAn operator is similar to an operation in that it refers to the symbol or the process used to denote the operation. Hence, their point of view is different. For instance, one often speaks of \"the operation of addition\" or \"the addition operation,\" when focusing on the operands and result, but one switch to \"addition operator\" (rarely \"operator of addition\"), when focusing on the process, or from the more symbolic viewpoint, the function +: X × X → X (where X is a set such as the set of real numbers).\n\nDefinition\nAn n-ary operation ω on a set X is a function ω: Xn → X. The set Xn is called the domain of the operation, the output set is called the codomain of the operation, and the fixed non-negative integer n (the number of operands) is called the arity of the operation. Thus a unary operation has arity one, and a binary operation has arity two. An operation of arity zero, called a nullary operation, is simply an element of the codomain Y. An n-ary operation can also be viewed as an (n + 1)-ary relation that is total on its n input domains and unique on its output domain.\nAn n-ary partial operation ω from Xn to X  is a partial function ω: Xn → X. An n-ary partial operation can also be viewed as an (n + 1)-ary relation that is unique on its output domain.\nThe above describes what is usually called a finitary operation, referring to the finite number of operands (the value n). There are obvious extensions where the arity is taken to be an infinite ordinal or cardinal, or even an arbitrary set indexing the operands.\nOften, the use of the term operation implies that the domain of the function includes a power of the codomain (i.e. the Cartesian product of one or more copies of the codomain), although this is by no means universal, as in the case of dot product, where vectors are multiplied and result in a scalar. An n-ary operation ω: Xn → X is called an internal operation. An n-ary operation ω: Xi ×",
    "links": [
      "Addition",
      "Additive inverse",
      "Anticommutative",
      "Arity",
      "Associative",
      "Binary operation",
      "Cardinal number",
      "Cartesian product",
      "Codomain",
      "Commutative",
      "Complementation (mathematics)",
      "Constant (mathematics)",
      "Convolution",
      "Division (mathematics)",
      "Domain of a function",
      "Dot product",
      "Elementary arithmetic",
      "Eric W. Weisstein",
      "Exponentiation",
      "Finitary relation",
      "Function (mathematics)",
      "Function composition",
      "Hyperoperation",
      "ISBN (identifier)",
      "Idempotent",
      "Image (mathematics)",
      "Infinitary operation",
      "Infix notation",
      "Inner product",
      "Intersection (mathematics)",
      "Logic operation",
      "MathWorld",
      "Mathematics",
      "Mixed product",
      "Multiplication",
      "Multiplicative inverse",
      "Negation",
      "Nullary operation",
      "Operand",
      "Operator (mathematics)",
      "Order of operations",
      "Ordinal number",
      "Partial function",
      "Range of a function",
      "Real number",
      "Rotation",
      "Scalar (mathematics)",
      "Scalar multiplication",
      "Set (mathematics)",
      "Subtraction"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Elementary mathematics",
      "Category:Operations on numbers",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Order of operations": {
    "title": "Order of operations",
    "url": "https://en.wikipedia.org/wiki/Order_of_operations",
    "summary": "In mathematics and computer programming, the order of operations  is a collection of rules that reflect conventions about which operations to perform first in order to evaluate a given mathematical expression.\nThese rules are formalized with a ranking of the operations. The rank of an operation is called its precedence, and an operation with a higher precedence is performed before operations with lower precedence. Calculators generally perform operations with the same precedence from left to right, but some programming languages and calculators adopt different conventions.\nFor example, multiplication is granted a higher precedence than addition, and it has been this way since the introduction of modern algebraic notation. Thus, in the expression 1 + 2 × 3, the multiplication is performed before addition, and the expression has the value 1 + (2 × 3) = 7, and not (1 + 2) × 3 = 9. When exponents were introduced in the 16th and 17th centuries, they were given precedence over both addition ",
    "content": "In mathematics and computer programming, the order of operations  is a collection of rules that reflect conventions about which operations to perform first in order to evaluate a given mathematical expression.\nThese rules are formalized with a ranking of the operations. The rank of an operation is called its precedence, and an operation with a higher precedence is performed before operations with lower precedence. Calculators generally perform operations with the same precedence from left to right, but some programming languages and calculators adopt different conventions.\nFor example, multiplication is granted a higher precedence than addition, and it has been this way since the introduction of modern algebraic notation. Thus, in the expression 1 + 2 × 3, the multiplication is performed before addition, and the expression has the value 1 + (2 × 3) = 7, and not (1 + 2) × 3 = 9. When exponents were introduced in the 16th and 17th centuries, they were given precedence over both addition and multiplication and placed as a superscript to the right of their base. Thus 3 + 52 = 28 and 3 × 52 = 75.\nThese conventions exist to avoid notational ambiguity while allowing notation to remain brief. Where it is desired to override the precedence conventions, or even simply to emphasize them, parentheses ( ) can be used. For example, (2 + 3) × 4 = 20 forces addition to precede multiplication, while (3 + 5)2 = 64 forces addition to precede exponentiation. If multiple pairs of parentheses are required in a mathematical expression (such as in the case of nested parentheses), the parentheses may be replaced by other types of brackets to avoid confusion, as in [2 × (3 + 4)] − 5 = 9.\nThese rules are meaningful only when the usual notation (called infix notation) is used. When functional or Polish notation are used for all operations, the order of operations results from the notation itself.\n\nConventional order\nThe order of operations, that is, the order in which the operations in an expression are usually performed, results from a convention adopted  throughout mathematics, science, technology and many computer programming languages. It is summarized as:\n\nParentheses\nExponentiation\nMultiplication and division\nAddition and subtraction\nThis means that to evaluate an expression, one first evaluates any sub-expression inside parentheses, working inside to outside if there is more than one set. Whether inside parentheses or not, the operation that is higher in the above list should be applied first. Operations of the same precedence are conventionally evaluated from left to right.\nIf each division is replaced with multiplication by the reciprocal (multiplicative inverse) then the associative and commutative laws of multiplication allow the factors in each term to be multiplied together in any order. Sometimes multiplication and division are given equal precedence, or sometimes multiplication is given higher precedence than division; see § Mixed division and multiplication below. If each subtraction is replaced with addition of the opposite (additive inverse), then the associative and commutative laws of addition allow terms to be added in any order.\nThe radical symbol ⁠\n  \n    \n      \n        \n          \n            \n              \n                \n                  t\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\sqrt {\\vphantom {t}}}}\n  \n⁠ is traditionally extended by a bar (called vinculum) over the radicand (this avoids the need for parentheses around the radicand). Other functions use parentheses around the input to avoid ambiguity. The parentheses can be omitted if the input is a single numerical variable or constant, as in the case of sin x = sin(x) and sin π = sin(π).  Traditionally this convention extends to monomials; thus, sin 3x = sin(3x) and even sin ⁠1/2⁠xy = sin(⁠1/2⁠xy), but sin x + y = sin(x) + y, because x + y is not a monomial. However, this convention is not universally understood, and some authors prefer explicit parentheses. Some calculators and programming languages require parentheses around function inputs, while others do not.\n Parentheses and alternate symbols of grouping can be used to override the usual order of operations or to make the intended order explicit. Grouped symbols can be treated as a single expression.\n\nExamples\nMultiplication before addition:\n\n  \n    \n      \n        1\n        +\n        2\n        ×\n        3\n        =\n        1\n        +\n        6\n        =\n        7.\n      \n    \n    {\\displaystyle 1+2\\times 3=1+6=7.}\n  \n\nParenthetical subexpressions are evaluated first:\n\n  \n    \n      \n        (\n        1\n        +\n        2\n        )\n        ×\n        3\n        =\n        3\n        ×\n        3\n        =\n        9.\n      \n    \n    {\\displaystyle (1+2)\\times 3=3\\times 3=9.}\n  \n\nExponentiation before multiplication, multiplication before subtraction:\n\n  \n    \n      \n        1\n        −\n        2\n        ×\n        \n          3\n          \n      ",
    "links": [
      "ACM Press",
      "APL (programming language)",
      "A History of Mathematical Notations",
      "Abstract syntax tree",
      "Acronym",
      "Addend",
      "Addition",
      "Additive inverse",
      "Algebraic Operating System",
      "Algebraic fraction",
      "Ambiguity",
      "American Physical Society",
      "Arrow (symbol)",
      "Associative property",
      "Bc programming language",
      "Binary expression tree",
      "Bitwise operation",
      "Bracket",
      "Bracket (mathematics)",
      "Bronstein and Semendjajew",
      "C++",
      "C (programming language)",
      "Calculator",
      "Calculator input methods",
      "Caret",
      "Casio",
      "Casio fx-9750GIII",
      "Chain input",
      "Comma operator",
      "Common operator notation",
      "Commonwealth of Nations",
      "Commutative property",
      "Compiler",
      "Computer programming",
      "Concrete Mathematics",
      "Cons",
      "Context-free grammar",
      "Course of Theoretical Physics",
      "Dennis M. Ritchie",
      "Dennis Ritchie",
      "Division (mathematics)",
      "Division slash",
      "Doi (identifier)",
      "Donald E. Knuth",
      "Donald Knuth",
      "Eric Wolfgang Weisstein",
      "Eugenia Cheng",
      "Evgeny Lifshitz",
      "Exponentiation",
      "Facts On File, Inc."
    ],
    "categories": [
      "Category:Algebra",
      "Category:Articles containing German-language text",
      "Category:Articles with short description",
      "Category:CS1 French-language sources (fr)",
      "Category:CS1 German-language sources (de)",
      "Category:CS1 maint: DOI inactive as of July 2025",
      "Category:Mnemonics",
      "Category:Operators (programming)",
      "Category:Short description matches Wikidata",
      "Category:Use dmy dates from February 2015"
    ]
  },
  "Binary number": {
    "title": "Binary number",
    "url": "https://en.wikipedia.org/wiki/Binary_number",
    "summary": "A binary number is a number expressed in the base-2 numeral system or binary numeral system, a method for representing numbers that uses only two symbols for the natural numbers: typically \"0\" (zero) and \"1\" (one). A binary number  may also refer to a rational number that has a finite representation in the binary numeral system, that is, the quotient of an integer by a power of two.\nThe base-2 numeral system is a positional notation with a radix of 2. Each digit is referred to as a bit, or binary digit. Because of its straightforward implementation in digital electronic circuitry using logic gates, the binary system is used by almost all modern computers and computer-based devices, as a preferred system of use, over various other human techniques of communication, because of the simplicity of the language and the noise immunity in physical implementation.",
    "content": "A binary number is a number expressed in the base-2 numeral system or binary numeral system, a method for representing numbers that uses only two symbols for the natural numbers: typically \"0\" (zero) and \"1\" (one). A binary number  may also refer to a rational number that has a finite representation in the binary numeral system, that is, the quotient of an integer by a power of two.\nThe base-2 numeral system is a positional notation with a radix of 2. Each digit is referred to as a bit, or binary digit. Because of its straightforward implementation in digital electronic circuitry using logic gates, the binary system is used by almost all modern computers and computer-based devices, as a preferred system of use, over various other human techniques of communication, because of the simplicity of the language and the noise immunity in physical implementation.\n\nHistory\nThe modern  binary number system was studied in Europe in the 16th and 17th centuries by Thomas Harriot, and Gottfried Leibniz. However, systems related to binary numbers have appeared earlier in multiple cultures including ancient Egypt, China, Europe and India.\n\nEgypt\nThe scribes of ancient Egypt used two different systems for their fractions, Egyptian fractions (not related to the binary number system) and Horus-Eye fractions (so called because some historians of mathematics believed that the symbols used for this system could be arranged to form the eye of Horus, although this has been disputed). Horus-Eye fractions are a binary numbering system for fractional quantities of grain, liquids, or other measures, in which a fraction of a hekat is expressed as a sum of the binary fractions 1/2, 1/4, 1/8, 1/16, 1/32, and 1/64. Early forms of this system can be found in documents from the Fifth Dynasty of Egypt, approximately 2400 BC, and its fully developed hieroglyphic form dates to the Nineteenth Dynasty of Egypt, approximately 1200 BC.\nThe method used for ancient Egyptian multiplication is also closely related to binary numbers. In this method, multiplying one number by a second is performed by a sequence of steps in which a value (initially the first of the two numbers) is either doubled or has the first number added back into it; the order in which these steps are to be performed is given by the binary representation of the second number. This method can be seen in use, for instance, in the Rhind Mathematical Papyrus, which dates to around 1650 BC.\n\nChina\nThe I Ching dates from the 9th century BC in China. The binary notation in the I Ching is used to interpret its quaternary divination technique.\nIt is based on taoistic duality of yin and yang. Eight trigrams (Bagua) and a set of 64 hexagrams (\"sixty-four\" gua), analogous to the three-bit and six-bit binary numerals, were in use at least as early as the Zhou dynasty of ancient China.\nThe Song dynasty scholar Shao Yong (1011–1077) rearranged the hexagrams in a format that resembles modern binary numbers, although he did not intend his arrangement to be used mathematically. Viewing the least significant bit on top of single hexagrams in Shao Yong's square\nand reading along rows either from bottom right to top left with solid lines as 0 and broken lines as 1 or from top left to bottom right with solid lines as 1 and broken lines as 0 hexagrams can be interpreted as sequence from 0 to 63.\n\nClassical antiquity\nEtruscans divided the outer edge of divination livers into sixteen parts, each inscribed with the name of a divinity and its region of the sky. Each liver region produced a binary reading which was combined into a final binary for divination. \nDivination at Ancient Greek Dodona oracle worked by drawing from separate jars, questions tablets and \"yes\" and \"no\" pellets. The result was then combined to make a final prophecy.\n\nIndia\nThe Indian scholar Pingala (c. 2nd century BC) developed a binary system for describing prosody. He described meters in the form of short and long syllables (the latter equal in length to two short syllables). They were known as laghu (light) and guru (heavy) syllables.\nPingala's Hindu classic titled Chandaḥśāstra (8.23) describes the formation of a matrix in order to give a unique value to each meter. \"Chandaḥśāstra\" literally translates to science of meters in Sanskrit. The binary representations in Pingala's system increases towards the right, and not to the left like in the binary numbers of the modern positional notation. In Pingala's system, the numbers start from number one, and not zero. Four short syllables \"0000\" is the first pattern and corresponds to the value one. The numerical value is obtained by adding one to the sum of place values.\n\nAfrica\nThe Ifá is an African divination system. Similar to the I Ching, but has up to 256 binary signs, unlike the I Ching which has 64. The Ifá originated in 15th century West Africa among Yoruba people. In 2008, UNESCO added Ifá to its list of the \"Masterpieces of the Oral and Intangible Heritage of Humanity\".\n\nOther cult",
    "links": [
      "0",
      "0.111... = 1 (binary)",
      "1",
      "10",
      "11 (number)",
      "12 (number)",
      "13 (number)",
      "14 (number)",
      "15 (number)",
      "2",
      "3",
      "4",
      "5",
      "6",
      "7",
      "8",
      "9",
      "ASCII",
      "A Symbolic Analysis of Relay and Switching Circuits",
      "Abjad numerals",
      "Absolute value",
      "Adder (electronics)",
      "Aegean numerals",
      "Aksharapalli",
      "Alexey Stakhov",
      "Algebra",
      "Alphabetic numeral system",
      "Alphasyllabic numeral system",
      "American Mathematical Society",
      "Ancient Egyptian mathematics",
      "Ancient Egyptian multiplication",
      "Ancient history",
      "Arabic numerals",
      "Arithmetic",
      "Arithmetic shift",
      "Armenian numerals",
      "Asymmetric numeral systems",
      "Attic numerals",
      "Australian Aboriginal languages",
      "Aztec script",
      "Ba gua",
      "Babylonian cuneiform numerals",
      "Bacon's cipher",
      "Balanced ternary",
      "Balinese numerals",
      "Base 10",
      "Bell Labs",
      "Bengali numerals",
      "Bibcode (identifier)",
      "Bijective numeration"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Binary arithmetic",
      "Category:CS1: unfit URL",
      "Category:CS1 German-language sources (de)",
      "Category:Commons category link is on Wikidata",
      "Category:Computer arithmetic",
      "Category:Elementary arithmetic",
      "Category:Gottfried Wilhelm Leibniz",
      "Category:Pages using sidebar with the child parameter",
      "Category:Power-of-two numeral systems"
    ]
  },
  "Algebraic group": {
    "title": "Algebraic group",
    "url": "https://en.wikipedia.org/wiki/Algebraic_group",
    "summary": "In mathematics, an algebraic group is an algebraic variety endowed with a group structure that is compatible with its structure as an algebraic variety. Thus the study of algebraic groups belongs both to algebraic geometry and group theory.\nMany groups of geometric transformations are algebraic groups, including orthogonal groups, general linear groups, projective groups, Euclidean groups, etc. Many matrix groups are also algebraic. Other algebraic groups occur naturally in algebraic geometry, such as elliptic curves and Jacobian varieties.\nAn important class of algebraic groups is given by the affine algebraic groups, those whose underlying algebraic variety is an affine variety; they are exactly the algebraic subgroups of the general linear group, and are therefore also called linear algebraic groups. Another class is formed by the abelian varieties, which are the algebraic groups whose underlying variety is a projective variety. Chevalley's structure theorem states that every algebr",
    "content": "In mathematics, an algebraic group is an algebraic variety endowed with a group structure that is compatible with its structure as an algebraic variety. Thus the study of algebraic groups belongs both to algebraic geometry and group theory.\nMany groups of geometric transformations are algebraic groups, including orthogonal groups, general linear groups, projective groups, Euclidean groups, etc. Many matrix groups are also algebraic. Other algebraic groups occur naturally in algebraic geometry, such as elliptic curves and Jacobian varieties.\nAn important class of algebraic groups is given by the affine algebraic groups, those whose underlying algebraic variety is an affine variety; they are exactly the algebraic subgroups of the general linear group, and are therefore also called linear algebraic groups. Another class is formed by the abelian varieties, which are the algebraic groups whose underlying variety is a projective variety. Chevalley's structure theorem states that every algebraic group can be constructed from groups in those two families.\n\nDefinitions\nFormally, an algebraic group over a field \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n is an algebraic variety \n  \n    \n      \n        \n          G\n        \n      \n    \n    {\\displaystyle \\mathrm {G} }\n  \n over \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n, together with a distinguished element \n  \n    \n      \n        e\n        ∈\n        \n          G\n        \n        (\n        k\n        )\n      \n    \n    {\\displaystyle e\\in \\mathrm {G} (k)}\n  \n (the neutral element), and regular maps \n  \n    \n      \n        \n          G\n        \n        ×\n        \n          G\n        \n        →\n        \n          G\n        \n      \n    \n    {\\displaystyle \\mathrm {G} \\times \\mathrm {G} \\to \\mathrm {G} }\n  \n (the multiplication operation) and \n  \n    \n      \n        \n          G\n        \n        →\n        \n          G\n        \n      \n    \n    {\\displaystyle \\mathrm {G} \\to \\mathrm {G} }\n  \n (the inversion operation) that satisfy the group axioms.\n\nExamples\nThe additive group: the affine line \n  \n    \n      \n        \n          \n            A\n          \n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {A} ^{1}}\n  \n endowed with addition and opposite as group operations is an algebraic group. It is called the additive group (because its \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n-points are isomorphic as a group to the additive group of \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n), and usually denoted by \n  \n    \n      \n        \n          \n            G\n          \n          \n            a\n          \n        \n      \n    \n    {\\displaystyle \\mathrm {G} _{a}}\n  \n.\nThe multiplicative group: Let \n  \n    \n      \n        \n          \n            G\n          \n          \n            m\n          \n        \n      \n    \n    {\\displaystyle \\mathrm {G} _{m}}\n  \n be the affine variety defined by the equation \n  \n    \n      \n        x\n        y\n        =\n        1\n      \n    \n    {\\displaystyle xy=1}\n  \n in the affine plane \n  \n    \n      \n        \n          \n            A\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {A} ^{2}}\n  \n. The functions \n  \n    \n      \n        (\n        (\n        x\n        ,\n        y\n        )\n        ,\n        (\n        \n          x\n          ′\n        \n        ,\n        \n          y\n          ′\n        \n        )\n        )\n        ↦\n        (\n        x\n        \n          x\n          ′\n        \n        ,\n        y\n        \n          y\n          ′\n        \n        )\n      \n    \n    {\\displaystyle ((x,y),(x',y'))\\mapsto (xx',yy')}\n  \n and \n  \n    \n      \n        (\n        x\n        ,\n        y\n        )\n        ↦\n        (\n        \n          x\n          \n            −\n            1\n          \n        \n        ,\n        \n          y\n          \n            −\n            1\n          \n        \n        )\n      \n    \n    {\\displaystyle (x,y)\\mapsto (x^{-1},y^{-1})}\n  \n are regular on \n  \n    \n      \n        \n          \n            G\n          \n          \n            m\n          \n        \n      \n    \n    {\\displaystyle \\mathrm {G} _{m}}\n  \n, and they satisfy the group axioms (with neutral element \n  \n    \n      \n        (\n        1\n        ,\n        1\n        )\n      \n    \n    {\\displaystyle (1,1)}\n  \n). The algebraic group \n  \n    \n      \n        \n          \n            G\n          \n          \n            m\n          \n        \n      \n    \n    {\\displaystyle \\mathrm {G} _{m}}\n  \n is called the multiplicative group, because its \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n-points are isomorphic to the multiplicative group of the field \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n (an isomorphism is given by \n  \n    \n      \n        x\n        ↦\n        (\n        x\n        ,\n        \n          x\n          \n            −\n            1\n          \n        \n        )\n      \n    \n    {\\",
    "links": [
      "Abelian group",
      "Abelian varieties",
      "Abelian variety",
      "Additive group",
      "Adelic algebraic group",
      "Adjugate matrix",
      "Affine algebraic group",
      "Affine line",
      "Affine variety",
      "Algebraic geometry",
      "Algebraic structure",
      "Algebraic torus",
      "Algebraic variety",
      "Alternating group",
      "André Weil",
      "Arithmetic geometry",
      "Arithmetic group",
      "Armand Borel",
      "Borel subgroup",
      "Cambridge University Press",
      "Category (mathematics)",
      "Cauchy's theorem (group theory)",
      "Cayley's theorem",
      "Character variety",
      "Cherlin–Zilber conjecture",
      "Chevalley's structure theorem",
      "Circle group",
      "Classification of finite simple groups",
      "Commutative ring",
      "Conformal group",
      "Continuous group",
      "Coordinate ring",
      "Coxeter group",
      "Cubic curve",
      "Cyclic group",
      "David Mumford",
      "Derivation (differential algebra)",
      "Diffeomorphism",
      "Dihedral group",
      "Direct product of groups",
      "Direct sum of groups",
      "Discrete group",
      "Doi (identifier)",
      "E6 (mathematics)",
      "E7 (mathematics)",
      "E8 (mathematics)",
      "Elementary abelian group",
      "Elliptic curve",
      "Euclidean group",
      "F4 (mathematics)"
    ],
    "categories": [
      "Category:Algebraic groups",
      "Category:Articles with short description",
      "Category:Properties of groups",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Algebraically compact module": {
    "title": "Algebraically compact module",
    "url": "https://en.wikipedia.org/wiki/Algebraically_compact_module",
    "summary": "In mathematics, algebraically compact modules, also called pure-injective modules, are modules that have a certain \"nice\" property which allows the solution of infinite systems of equations in the module by finitary means.  The solutions to these systems allow the extension of certain kinds of module homomorphisms.  These algebraically compact modules are analogous to injective modules, where one can extend all module homomorphisms.  All injective modules are algebraically compact, and the analogy between the two is made quite precise by a category embedding.",
    "content": "In mathematics, algebraically compact modules, also called pure-injective modules, are modules that have a certain \"nice\" property which allows the solution of infinite systems of equations in the module by finitary means.  The solutions to these systems allow the extension of certain kinds of module homomorphisms.  These algebraically compact modules are analogous to injective modules, where one can extend all module homomorphisms.  All injective modules are algebraically compact, and the analogy between the two is made quite precise by a category embedding.\n\nDefinitions\nLet R be a ring, and M a left R-module. Consider a system of infinitely many linear equations\n\n  \n    \n      \n        \n          ∑\n          \n            j\n            ∈\n            J\n          \n        \n        \n          r\n          \n            i\n            ,\n            j\n          \n        \n        \n          x\n          \n            j\n          \n        \n        =\n        \n          m\n          \n            i\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\sum _{j\\in J}r_{i,j}x_{j}=m_{i},}\n  \n\nwhere both sets I and J may be infinite, \n  \n    \n      \n        \n          m\n          \n            i\n          \n        \n        ∈\n        M\n        ,\n      \n    \n    {\\displaystyle m_{i}\\in M,}\n  \n and for each i the number of nonzero \n  \n    \n      \n        \n          r\n          \n            i\n            ,\n            j\n          \n        \n        ∈\n        R\n      \n    \n    {\\displaystyle r_{i,j}\\in R}\n  \n is finite.\nThe goal is to decide whether such a system has a solution, that is whether there exist elements xj of M such that all the equations of the system are simultaneously satisfied. (It is not required that only finitely many xj are non-zero.)\nThe module M is algebraically compact if, for all such systems, if every subsystem formed by a finite number of the equations has a solution, then the whole system has a solution. (The solutions to the various subsystems may be different.)\nOn the other hand, a module homomorphism M → K is a pure embedding if the induced homomorphism between the tensor products C ⊗ M → C ⊗ K is injective for every right R-module C. The module M is pure-injective if any pure injective homomorphism j : M → K splits (that is, there exists f : K → M with \n  \n    \n      \n        f\n        ∘\n        j\n        =\n        \n          1\n          \n            M\n          \n        \n      \n    \n    {\\displaystyle f\\circ j=1_{M}}\n  \n).\nIt turns out that a module is algebraically compact if and only if it is pure-injective.\n\nExamples\nAll modules with finitely many elements are algebraically compact.\nEvery vector space is algebraically compact (since it is pure-injective). More generally, every injective module is algebraically compact, for the same reason.\nIf R is an associative algebra with 1 over some field k, then every R-module with finite k-dimension is algebraically compact. This, together with the fact that all finite modules are algebraically compact, gives rise to the intuition that algebraically compact modules are those (possibly \"large\") modules which share the nice properties of \"small\" modules.\nThe Prüfer groups are algebraically compact abelian groups (i.e. Z-modules). The ring of p-adic integers for each prime p is algebraically compact as both a module over itself and a module over Z. The rational numbers are algebraically compact as a Z-module. Together with the indecomposable finite modules over Z, this is a complete list of indecomposable algebraically compact modules.\nMany algebraically compact modules can be produced using the injective cogenerator Q/Z of abelian groups. If H is a right module over the ring R, one forms the (algebraic) character module H* consisting of all group homomorphisms from H to Q/Z. This is then a left R-module, and the *-operation yields a faithful contravariant functor from right R-modules to left R-modules. \nEvery module of the form H* is algebraically compact. Furthermore, there are pure injective homomorphisms H → H**, natural in H. One can often simplify a problem by first applying the *-functor, since algebraically compact modules are easier to deal with.\n\nFacts\nThe following condition is equivalent to M being algebraically compact:\n\nFor every index set I, the addition map M(I) → M can be extended to a module homomorphism MI → M (here M(I) denotes the direct sum of copies of M, one for each element of I; MI denotes the product of copies of M, one for each element of I).\nEvery indecomposable algebraically compact module has a local endomorphism ring.\nAlgebraically compact modules share many other properties with injective objects because of the following: there exists an embedding of R-Mod into a Grothendieck category G under which the algebraically compact R-modules precisely correspond to the injective objects in G.\nEvery R-module is elementary equivalent to an algebraically compact R-module and to a direct sum of indecomposable algebraically compact R-m",
    "links": [
      "Abelian group",
      "Associative algebra",
      "Dimension of a vector space",
      "Direct sum of modules",
      "Elementary equivalence",
      "Endomorphism ring",
      "Faithful functor",
      "Field (mathematics)",
      "Finitary",
      "Functor",
      "Grothendieck category",
      "Group homomorphism",
      "ISBN (identifier)",
      "If and only if",
      "Indecomposable module",
      "Induced homomorphism",
      "Injective",
      "Injective cogenerator",
      "Injective module",
      "Local ring",
      "Mathematics",
      "Module (mathematics)",
      "Module homomorphism",
      "Natural transformation",
      "P-adic number",
      "Product (category theory)",
      "Prüfer group",
      "Rational number",
      "Ring (mathematics)",
      "Split short exact sequence",
      "Tensor product",
      "Vector space"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Model theory",
      "Category:Module theory",
      "Category:Short description matches Wikidata"
    ]
  },
  "Alternating group": {
    "title": "Alternating group",
    "url": "https://en.wikipedia.org/wiki/Alternating_group",
    "summary": "In mathematics, an alternating group is the group of even permutations of a finite set. The alternating group on a set of n elements is called the alternating group of degree n, or the alternating group on n letters and denoted by An or Alt(n).",
    "content": "In mathematics, an alternating group is the group of even permutations of a finite set. The alternating group on a set of n elements is called the alternating group of degree n, or the alternating group on n letters and denoted by An or Alt(n).\n\nBasic properties\nFor n > 1, the group An is the commutator subgroup of the symmetric group Sn with index 2 and has therefore n!/2 elements. It is the kernel of the signature group homomorphism sgn : Sn → {1, −1} explained under symmetric group.\nThe group An is abelian if and only if n ≤ 3 and simple if and only if n = 3 or n ≥ 5.  A5 is the smallest non-abelian simple group, having order 60, and thus the smallest non-solvable group.\nThe group A4 has the Klein four-group V as a proper normal subgroup, namely the identity and the double transpositions { (),  (12)(34), (13)(24), (14)(23) }, that is the kernel of the surjection of A4 onto A3 ≅ Z3. We have the exact sequence V → A4 → A3 = Z3. In Galois theory, this map, or rather the corresponding map S4 → S3, corresponds to associating the Lagrange resolvent cubic to a quartic, which allows the quartic polynomial to be solved by radicals, as established by Lodovico Ferrari.\n\nConjugacy classes\nAs in the symmetric group, any two elements of An that are conjugate by an element of  An must have the same cycle shape. The converse is not necessarily true, however. If the cycle shape consists only of cycles of odd length with no two cycles the same length, where cycles of length one are included in the cycle type, then there are exactly two conjugacy classes for this cycle shape (Scott 1987, §11.1, p299).\nExamples:\n\nThe two permutations (123) and (132) are not conjugates in A3, although they have the same cycle shape, and are therefore conjugate in S3.\nThe permutation (123)(45678) is not conjugate to its inverse (132)(48765) in A8, although the two permutations have the same cycle shape, so they are conjugate in S8.\n\nRelation with symmetric group\nSee  Symmetric group.\nAs finite symmetric groups are the groups of all permutations of a set with finite elements, and the alternating groups are groups of even permutations, alternating groups are subgroups of finite symmetric groups.\n\nGenerators and relations\nFor n ≥ 3, An is generated by 3-cycles, since 3-cycles can be obtained by combining pairs of transpositions. This generating set is often used to prove that An is simple for n ≥ 5.\n\nAutomorphism group\nFor n > 3, except for n = 6, the  automorphism group of An is the symmetric group Sn, with inner automorphism group An and outer automorphism group Z2; the outer automorphism comes from conjugation by an odd permutation.\nFor n = 1 and 2, the automorphism group is trivial. For n = 3 the automorphism group is Z2, with trivial inner automorphism group and outer automorphism group Z2.\nThe outer automorphism group of A6 is the Klein four-group V = Z2 × Z2, and is related to the outer automorphism of S6. The extra outer automorphism in A6 swaps the 3-cycles (like (123)) with elements of shape 32 (like (123)(456)).\n\nExceptional isomorphisms\nThere are some exceptional isomorphisms between some of the small alternating groups and small groups of Lie type, particularly projective special linear groups. These are:\n\nA4 is isomorphic to PSL2(3) and the symmetry group of chiral tetrahedral symmetry.\nA5 is isomorphic to PSL2(4), PSL2(5), and the symmetry group of chiral icosahedral symmetry. (See  for an indirect isomorphism of PSL2(F5) → A5 using a classification of simple groups of order 60, and here for a direct proof).\nA6 is isomorphic to PSL2(9) and PSp4(2)'.\nA8 is isomorphic to PSL4(2).\nMore obviously, A3 is isomorphic to the cyclic group Z3, and A0, A1, and A2 are isomorphic to the trivial group (which is also SL1(q) = PSL1(q) for any q).\n\nExamples S4 and A4\nExample A5 as a subgroup of 3-space rotations\nA5 is the group of isometries of a dodecahedron in 3-space, so there is a representation A5 → SO3(R).\nIn this picture the vertices of the polyhedra represent the elements of the group, with the center of the sphere representing the identity element. Each vertex represents a rotation about the axis pointing from the center to that vertex, by an angle equal to the distance from the origin, in radians. Vertices in the same polyhedron are in the same conjugacy class. Since the conjugacy class equation for A5 is 1 + 12 + 12 + 15 + 20 = 60, we obtain four distinct (nontrivial) polyhedra.\nThe vertices of each polyhedron are in bijective correspondence with the elements of its conjugacy class, with the exception of the conjugacy class of (2,2)-cycles, which is represented by an icosidodecahedron on the outer surface, with its antipodal vertices identified with each other. The reason for this redundancy is that the corresponding rotations are by π radians, and so can be represented by a vector of length π in either of two directions. Thus the class of (2,2)-cycles contains 15 elements, while the icosidodecahedron has 30 vertices.\nThe two conjugacy ",
    "links": [
      "15 puzzle",
      "Abelian group",
      "Abelian variety",
      "Abelianization",
      "Additive group",
      "Algebraic group",
      "Algebraic structure",
      "Arithmetic group",
      "Automorphism group",
      "Automorphisms of the symmetric and alternating groups",
      "Ball (mathematics)",
      "Cauchy's theorem (group theory)",
      "Cayley table",
      "Circle group",
      "Classification of finite simple groups",
      "Commutator subgroup",
      "Conformal group",
      "Continuous group",
      "Covering groups of the alternating and symmetric groups",
      "Cycle graph (algebra)",
      "Cycle shape",
      "Cycles and fixed points",
      "Cyclic group",
      "Diffeomorphism",
      "Dihedral group",
      "Direct product of groups",
      "Direct sum of groups",
      "Discrete group",
      "Dodecahedron",
      "Doi (identifier)",
      "Dover Publications",
      "E6 (mathematics)",
      "E7 (mathematics)",
      "E8 (mathematics)",
      "Elementary abelian group",
      "Elliptic curve",
      "Eric W. Weisstein",
      "Euclidean group",
      "Even permutation",
      "Exact sequence",
      "Exceptional isomorphism",
      "F4 (mathematics)",
      "Factorial",
      "Finite group",
      "Finite set",
      "Free group",
      "Free product",
      "Frobenius group",
      "G2 (mathematics)",
      "Galois theory"
    ],
    "categories": [
      "Category:All articles lacking in-text citations",
      "Category:Articles lacking in-text citations from January 2008",
      "Category:Articles with short description",
      "Category:CS1 maint: postscript",
      "Category:Finite groups",
      "Category:Permutation groups",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Arithmetic group": {
    "title": "Arithmetic group",
    "url": "https://en.wikipedia.org/wiki/Arithmetic_group",
    "summary": "In mathematics, an arithmetic group is a group obtained as the integer points of an algebraic group, for example \n  \n    \n      \n        \n          \n            S\n            L\n          \n          \n            2\n          \n        \n        (\n        \n          Z\n        \n        )\n        .\n      \n    \n    {\\displaystyle \\mathrm {SL} _{2}(\\mathbb {Z} ).}\n  \n They arise naturally in the study of arithmetic properties of quadratic forms and other classical topics in number theory. They also give rise to very interesting examples of Riemannian manifolds and hence are objects of interest in differential geometry and topology. Finally, these two topics join in the theory of automorphic forms which is fundamental in modern number theory.",
    "content": "In mathematics, an arithmetic group is a group obtained as the integer points of an algebraic group, for example \n  \n    \n      \n        \n          \n            S\n            L\n          \n          \n            2\n          \n        \n        (\n        \n          Z\n        \n        )\n        .\n      \n    \n    {\\displaystyle \\mathrm {SL} _{2}(\\mathbb {Z} ).}\n  \n They arise naturally in the study of arithmetic properties of quadratic forms and other classical topics in number theory. They also give rise to very interesting examples of Riemannian manifolds and hence are objects of interest in differential geometry and topology. Finally, these two topics join in the theory of automorphic forms which is fundamental in modern number theory.\n\nHistory\nOne of the origins of the mathematical theory of arithmetic groups is algebraic number theory. The classical reduction theory of quadratic and Hermitian forms by Charles Hermite, Hermann Minkowski and others can be seen as computing fundamental domains for the action of certain arithmetic groups on the relevant symmetric spaces. The topic was related to Minkowski's geometry of numbers and the early development of the study of arithmetic invariant of number fields such as the discriminant. Arithmetic groups can be thought of as a vast generalisation of the unit groups of number fields to a noncommutative setting.\nThe same groups also appeared in analytic number theory as the study of classical modular forms and their generalisations developed. Of course the two topics were related, as can be seen for example in Langlands' computation of the volume of certain fundamental domains using analytic methods. This classical theory culminated with the work of Siegel, who showed the finiteness of the volume of a fundamental domain in many cases.\nFor the modern theory to begin foundational work was needed, and was provided by the work of Armand Borel, André Weil, Jacques Tits and others on algebraic groups. Shortly afterwards the finiteness of covolume was proven in full generality by Borel and Harish-Chandra. Meanwhile, there was progress on the general theory of lattices in Lie groups by Atle Selberg, Grigori Margulis,  David Kazhdan, M. S. Raghunathan and others. The state of the art after this period was essentially fixed in Raghunathan's treatise, published in 1972.\nIn the seventies Margulis revolutionised the topic by proving that in \"most\" cases the arithmetic constructions account for all lattices in a given Lie group. Some limited results in this direction had been obtained earlier by Selberg, but Margulis' methods (the use of ergodic-theoretical tools for actions on homogeneous spaces) were completely new in this context and were to be extremely influential on later developments, effectively renewing the old subject of geometry of numbers and allowing Margulis himself to prove the Oppenheim conjecture; stronger results (Ratner's theorems) were later obtained by Marina Ratner.\nIn another direction the classical topic of modular forms has blossomed into the modern theory of automorphic forms. The driving force behind this effort is mainly the Langlands program initiated by Robert Langlands. One of the main tool used there is the trace formula originating in Selberg's work and developed in the most general setting by James Arthur.\nFinally arithmetic groups are often used to construct interesting examples of locally symmetric Riemannian manifolds. A particularly active research topic has been arithmetic hyperbolic 3-manifolds, which as William Thurston wrote, \"...often seem to have special beauty.\"\n\nDefinition and construction\nArithmetic groups\nIf \n  \n    \n      \n        \n          G\n        \n      \n    \n    {\\displaystyle \\mathrm {G} }\n  \n is an algebraic subgroup of \n  \n    \n      \n        \n          \n            G\n            L\n          \n          \n            n\n          \n        \n        (\n        \n          Q\n        \n        )\n      \n    \n    {\\displaystyle \\mathrm {GL} _{n}(\\mathbb {Q} )}\n  \n for some \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n then we can define an arithmetic subgroup of \n  \n    \n      \n        \n          G\n        \n        (\n        \n          Q\n        \n        )\n      \n    \n    {\\displaystyle \\mathrm {G} (\\mathbb {Q} )}\n  \n as the group of integer points \n  \n    \n      \n        Γ\n        =\n        \n          \n            G\n            L\n          \n          \n            n\n          \n        \n        (\n        \n          Z\n        \n        )\n        ∩\n        \n          G\n        \n        (\n        \n          Q\n        \n        )\n        .\n      \n    \n    {\\displaystyle \\Gamma =\\mathrm {GL} _{n}(\\mathbb {Z} )\\cap \\mathrm {G} (\\mathbb {Q} ).}\n  \n In general it is not so obvious how to make precise sense of the notion of \"integer points\" of a \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n-group, and the subgroup defined above can change when we take different embeddings \n  \n    \n   ",
    "links": [
      "Abelian group",
      "Abelian variety",
      "Additive group",
      "Algebraic group",
      "Algebraic structure",
      "Alternating group",
      "Analytic number theory",
      "André Weil",
      "ArXiv (identifier)",
      "Arithmetic Fuchsian group",
      "Arithmetic hyperbolic 3-manifold",
      "Armand Borel",
      "Atle Selberg",
      "Automorphic form",
      "Betti number",
      "Bianchi group",
      "Cauchy's theorem (group theory)",
      "Charles Hermite",
      "Circle group",
      "Classification of finite simple groups",
      "Cocompact lattice",
      "Commensurability (group theory)",
      "Complex surface",
      "Conformal group",
      "Congruence subgroup",
      "Continuous group",
      "Cyclic group",
      "David Kazhdan",
      "Diffeomorphism",
      "Differential geometry",
      "Dihedral group",
      "Direct product of groups",
      "Direct sum of groups",
      "Dirichlet's unit theorem",
      "Discrete group",
      "Discriminant of an algebraic number field",
      "Doi (identifier)",
      "E6 (mathematics)",
      "E7 (mathematics)",
      "E8 (mathematics)",
      "Elementary abelian group",
      "Elliptic curve",
      "Ergodic theory",
      "Euclidean group",
      "F4 (mathematics)",
      "Finite group",
      "Free group",
      "Free product",
      "Frobenius group",
      "Fundamental domain"
    ],
    "categories": [
      "Category:Algebraic groups",
      "Category:CS1 French-language sources (fr)",
      "Category:CS1 Russian-language sources (ru)",
      "Category:CS1 maint: location missing publisher",
      "Category:Differential geometry",
      "Category:Group theory",
      "Category:Number theory"
    ]
  },
  "Automorphism group": {
    "title": "Automorphism group",
    "url": "https://en.wikipedia.org/wiki/Automorphism_group",
    "summary": "In mathematics, the automorphism group of an object X is the group consisting of automorphisms of X under composition of morphisms.  For example, if X is a finite-dimensional vector space, then the automorphism group of X is the group of invertible linear transformations from X to itself (the general linear group of X).  If instead X is a group, then its automorphism group \n  \n    \n      \n        Aut\n        ⁡\n        (\n        X\n        )\n      \n    \n    {\\displaystyle \\operatorname {Aut} (X)}\n  \n is the group consisting of all group automorphisms of X. \nEspecially in geometric contexts, an automorphism group is also called a symmetry group. A subgroup of an automorphism group is sometimes called a transformation group.\nAutomorphism groups are studied in a general way in the field of category theory.",
    "content": "In mathematics, the automorphism group of an object X is the group consisting of automorphisms of X under composition of morphisms.  For example, if X is a finite-dimensional vector space, then the automorphism group of X is the group of invertible linear transformations from X to itself (the general linear group of X).  If instead X is a group, then its automorphism group \n  \n    \n      \n        Aut\n        ⁡\n        (\n        X\n        )\n      \n    \n    {\\displaystyle \\operatorname {Aut} (X)}\n  \n is the group consisting of all group automorphisms of X. \nEspecially in geometric contexts, an automorphism group is also called a symmetry group. A subgroup of an automorphism group is sometimes called a transformation group.\nAutomorphism groups are studied in a general way in the field of category theory.\n\nExamples\nIf X is a set with no additional structure, then any bijection from X to itself is an automorphism, and hence the automorphism group of X in this case is precisely the symmetric group of X.  If the set X has additional structure, then it may be the case that not all bijections on the set preserve this structure, in which case the automorphism group will be a subgroup of the symmetric group on X.  Some examples of this include the following:\n\nThe automorphism group of a field extension \n  \n    \n      \n        L\n        \n          /\n        \n        K\n      \n    \n    {\\displaystyle L/K}\n  \n is the group consisting of field automorphisms of L that fix K. If the field extension is Galois, the automorphism group is called the Galois group of the field extension.\nThe automorphism group of the projective n-space over a field k is the projective linear group \n  \n    \n      \n        \n          PGL\n          \n            n\n          \n        \n        ⁡\n        (\n        k\n        )\n        .\n      \n    \n    {\\displaystyle \\operatorname {PGL} _{n}(k).}\n  \n\nThe automorphism group \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n of a finite cyclic group of order n is isomorphic to \n  \n    \n      \n        (\n        \n          Z\n        \n        \n          /\n        \n        n\n        \n          Z\n        \n        \n          )\n          \n            ×\n          \n        \n      \n    \n    {\\displaystyle (\\mathbb {Z} /n\\mathbb {Z} )^{\\times }}\n  \n, the multiplicative group of integers modulo n, with the isomorphism given by \n  \n    \n      \n        \n          \n            a\n            ¯\n          \n        \n        ↦\n        \n          σ\n          \n            a\n          \n        \n        ∈\n        G\n        ,\n        \n        \n          σ\n          \n            a\n          \n        \n        (\n        x\n        )\n        =\n        \n          x\n          \n            a\n          \n        \n      \n    \n    {\\displaystyle {\\overline {a}}\\mapsto \\sigma _{a}\\in G,\\,\\sigma _{a}(x)=x^{a}}\n  \n. In particular, \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n is an abelian group.\nThe automorphism group of a finite-dimensional real Lie algebra \n  \n    \n      \n        \n          \n            g\n          \n        \n      \n    \n    {\\displaystyle {\\mathfrak {g}}}\n  \n has the structure of a (real) Lie group (in fact, it is even a linear algebraic group: see below). If G is a Lie group with Lie algebra \n  \n    \n      \n        \n          \n            g\n          \n        \n      \n    \n    {\\displaystyle {\\mathfrak {g}}}\n  \n, then the automorphism group of G has a structure of a Lie group induced from that on the automorphism group of \n  \n    \n      \n        \n          \n            g\n          \n        \n      \n    \n    {\\displaystyle {\\mathfrak {g}}}\n  \n.\nIf G is a group acting on a set X, the action amounts to a group homomorphism from G to the automorphism group of X and conversely.  Indeed, each left G-action on a set X determines \n  \n    \n      \n        G\n        →\n        Aut\n        ⁡\n        (\n        X\n        )\n        ,\n        \n        g\n        ↦\n        \n          σ\n          \n            g\n          \n        \n        ,\n        \n        \n          σ\n          \n            g\n          \n        \n        (\n        x\n        )\n        =\n        g\n        ⋅\n        x\n      \n    \n    {\\displaystyle G\\to \\operatorname {Aut} (X),\\,g\\mapsto \\sigma _{g},\\,\\sigma _{g}(x)=g\\cdot x}\n  \n, and, conversely, each homomorphism \n  \n    \n      \n        φ\n        :\n        G\n        →\n        Aut\n        ⁡\n        (\n        X\n        )\n      \n    \n    {\\displaystyle \\varphi :G\\to \\operatorname {Aut} (X)}\n  \n defines an action by \n  \n    \n      \n        g\n        ⋅\n        x\n        =\n        φ\n        (\n        g\n        )\n        x\n      \n    \n    {\\displaystyle g\\cdot x=\\varphi (g)x}\n  \n.  This extends to the case when the set X has more structure than just a set.  For example, if X is a vector space, then a group action of G on X is a group representation of the group G, representing G as a group of linear transformations (automorphisms) of X; these representations are the main object of study in the field of repr",
    "links": [
      "Abelian group",
      "Algebra over a field",
      "Algebraic Geometry (book)",
      "Associative algebra",
      "Automorphism",
      "Bijection",
      "Cardinality",
      "Category (mathematics)",
      "Category of groups",
      "Category of rings",
      "Category theory",
      "Commutative ring",
      "Cyclic group",
      "Dimension (vector space)",
      "Doi (identifier)",
      "Embedding",
      "Endomorphism monoid",
      "Field (mathematics)",
      "Field extension",
      "Finitely generated module",
      "Fixed-point subring",
      "Function composition",
      "Functor",
      "Galois extension",
      "Galois group",
      "General linear group",
      "Graduate Texts in Mathematics",
      "Group (mathematics)",
      "Group action",
      "Group action (mathematics)",
      "Group automorphism",
      "Group functor",
      "Group homomorphism",
      "Group isomorphism",
      "Group representation",
      "Holonomy group",
      "ISBN (identifier)",
      "Inner automorphism",
      "JSTOR (identifier)",
      "Joe Harris (mathematician)",
      "John Milnor",
      "John Wiley & Sons",
      "Level structure (algebraic geometry)",
      "Lie algebra",
      "Lie group",
      "Linear algebraic group",
      "Linear map",
      "Linear transformations",
      "MR (identifier)",
      "Mathematics"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Group automorphisms",
      "Category:Short description matches Wikidata"
    ]
  },
  "Axiomatic set theory": {
    "title": "Set theory",
    "url": "https://en.wikipedia.org/wiki/Set_theory",
    "summary": "Set theory is the branch of mathematical logic that studies sets, which can be informally described as collections of objects. Although objects of any kind can be collected into a set, set theory – as a branch of mathematics – is mostly concerned with those that are relevant to mathematics as a whole.\nThe modern study of set theory was initiated by the German mathematicians Richard Dedekind and Georg Cantor in the 1870s. In particular, Georg Cantor is commonly considered the founder of set theory. The non-formalized systems investigated during this early stage go under the name of naive set theory. After the discovery of paradoxes within naive set theory (such as Russell's paradox, Cantor's paradox and the Burali-Forti paradox), various axiomatic systems were proposed in the early twentieth century, of which Zermelo–Fraenkel set theory (with or without the axiom of choice) is still the best-known and most studied.\nSet theory is commonly employed as a foundational system for the whole o",
    "content": "Set theory is the branch of mathematical logic that studies sets, which can be informally described as collections of objects. Although objects of any kind can be collected into a set, set theory – as a branch of mathematics – is mostly concerned with those that are relevant to mathematics as a whole.\nThe modern study of set theory was initiated by the German mathematicians Richard Dedekind and Georg Cantor in the 1870s. In particular, Georg Cantor is commonly considered the founder of set theory. The non-formalized systems investigated during this early stage go under the name of naive set theory. After the discovery of paradoxes within naive set theory (such as Russell's paradox, Cantor's paradox and the Burali-Forti paradox), various axiomatic systems were proposed in the early twentieth century, of which Zermelo–Fraenkel set theory (with or without the axiom of choice) is still the best-known and most studied.\nSet theory is commonly employed as a foundational system for the whole of mathematics, particularly in the form of Zermelo–Fraenkel set theory with the axiom of choice. Besides its foundational role, set theory also provides the framework to develop a mathematical theory of infinity, and has various applications in computer science (such as in the theory of relational algebra), philosophy, formal semantics, and evolutionary dynamics. Its foundational appeal, together with its paradoxes, and its implications for the concept of infinity and its multiple applications have made set theory an area of major interest for logicians and philosophers of mathematics. Contemporary research into set theory covers a vast array of topics, ranging from the structure of the real number line to the study of the consistency of large cardinals.\n\nHistory\nEarly history\nThe basic notion of grouping objects has existed since at least the emergence of numbers, and the notion of treating sets as their own objects has existed since at least the Tree of Porphyry in 3rd-century AD. The simplicity and ubiquity of sets makes it hard to determine the origin of sets as now used in mathematics; however, Bernard Bolzano's Paradoxes of the Infinite (Paradoxien des Unendlichen, 1851) is generally considered the first rigorous introduction of sets to mathematics. In his work, he (among other things) expanded on Galileo's paradox, and introduced one-to-one correspondence of infinite sets, for example between the intervals \n  \n    \n      \n        [\n        0\n        ,\n        5\n        ]\n      \n    \n    {\\displaystyle [0,5]}\n  \n and \n  \n    \n      \n        [\n        0\n        ,\n        12\n        ]\n      \n    \n    {\\displaystyle [0,12]}\n  \n by the relation \n  \n    \n      \n        5\n        y\n        =\n        12\n        x\n      \n    \n    {\\displaystyle 5y=12x}\n  \n. However, he resisted saying these sets were equinumerous, and his work is generally considered to have been uninfluential in mathematics of his time.\nBefore mathematical set theory, basic concepts of infinity were considered to be in the domain of philosophy (see: Infinity (philosophy) and Infinity § History). Since the 5th century BC, beginning with Greek philosopher Zeno of Elea in the West (and early Indian mathematicians in the East), mathematicians had struggled with the concept of infinity. With the development of calculus in the late 17th century, philosophers began to generally distinguish between potential and actual infinity, wherein mathematics was only considered in the latter. Carl Friedrich Gauss famously stated: \"Infinity is nothing more than a figure of speech which helps us talk about limits. The notion of a completed infinity doesn't belong in mathematics.\"\nDevelopment of mathematical set theory was motivated by several mathematicians. Bernhard Riemann's lecture On the Hypotheses which lie at the Foundations of Geometry (1854) proposed new ideas about topology. His lectures also introduced the concept of basing mathematics in terms of sets or manifolds in the sense of a class (which he called Mannigfaltigkeit) now called point-set topology. The lecture was published by Richard Dedekind in 1868, along with Riemann's paper on trigonometric series (which presented the Riemann integral), The latter was a starting point a movement in real analysis for the study of “seriously” discontinuous functions. A young Georg Cantor entered into this area, which led him to the study of point-sets. Around 1871, influenced by Riemann, Dedekind began working with sets in his publications, which dealt very clearly and precisely with equivalence relations, partitions of sets, and homomorphisms. Thus, many of the usual set-theoretic procedures of twentieth-century mathematics go back to his work. However, he did not publish a formal explanation of his set theory until 1888.\n\nNaive set theory\nSet theory, as understood by modern mathematicians, is generally considered to be founded by a single paper in 1874 by Georg Cantor titled On a Property of the Collection of All Real Algebraic",
    "links": [
      "Abraham Fraenkel",
      "Abstract algebra",
      "Abstract logic",
      "Ackermann set theory",
      "Actual infinity",
      "Akihiro Kanamori",
      "Aleph",
      "Aleph number",
      "Algebra",
      "Algebra of sets",
      "Algebraic geometry",
      "Algebraic logic",
      "Algebraic number theory",
      "Algebraic topology",
      "Almost",
      "Alphabet (formal languages)",
      "Alternative set theory",
      "Amorphous set",
      "Analytic geometry",
      "Analytic number theory",
      "Andrey Kolmogorov",
      "Antinomy",
      "Applied mathematics",
      "Areas of mathematics",
      "Argument",
      "Aristotle",
      "Arithmetic",
      "Arithmetic geometry",
      "Arity",
      "Arthur Schoenflies",
      "Atomic formula",
      "Atomic sentence",
      "Automata theory",
      "Automated theorem proving",
      "Axiom",
      "Axiom of adjunction",
      "Axiom of choice",
      "Axiom of constructibility",
      "Axiom of countable choice",
      "Axiom of dependent choice",
      "Axiom of determinacy",
      "Axiom of extensionality",
      "Axiom of global choice",
      "Axiom of infinity",
      "Axiom of limitation of size",
      "Axiom of pairing",
      "Axiom of power set",
      "Axiom of projective determinacy",
      "Axiom of regularity",
      "Axiom of union"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1: long volume value",
      "Category:CS1 German-language sources (de)",
      "Category:CS1 maint: multiple names: authors list",
      "Category:CS1 maint: publisher location",
      "Category:Formal methods",
      "Category:Georg Cantor",
      "Category:Mathematical logic",
      "Category:Pages using Sister project links with default search",
      "Category:Pages using sidebar with the child parameter"
    ]
  },
  "Baby monster group": {
    "title": "Baby monster group",
    "url": "https://en.wikipedia.org/wiki/Baby_monster_group",
    "summary": "In the area of modern algebra known as group theory, the baby monster group B (or, more simply, the baby monster) is a sporadic simple group of order\n\n   4,154,781,481,226,426,191,177,580,544,000,000\n= 241 · 313 · 56 · 72 · 11 · 13 · 17 · 19 · 23 · 31 · 47\n= 20! · 6!2 · 4! · 212 · 23 · 31 · 47\n≈ 4×1033.\nB is one of the 26 sporadic groups and has the second highest order of these, with the highest order being that of the monster group. The double cover of the baby monster is the centralizer of an element of order 2 in the monster group. The outer automorphism group of B is trivial and the Schur multiplier of B has order 2.",
    "content": "In the area of modern algebra known as group theory, the baby monster group B (or, more simply, the baby monster) is a sporadic simple group of order\n\n   4,154,781,481,226,426,191,177,580,544,000,000\n= 241 · 313 · 56 · 72 · 11 · 13 · 17 · 19 · 23 · 31 · 47\n= 20! · 6!2 · 4! · 212 · 23 · 31 · 47\n≈ 4×1033.\nB is one of the 26 sporadic groups and has the second highest order of these, with the highest order being that of the monster group. The double cover of the baby monster is the centralizer of an element of order 2 in the monster group. The outer automorphism group of B is trivial and the Schur multiplier of B has order 2.\n\nHistory\nThe existence of this group was suggested by Bernd Fischer in unpublished work from the early 1970s during his investigation of {3,4}-transposition groups: groups generated by a class of transpositions such that the product of any two elements has order at most 4. He investigated its properties and computed its character table. The first construction of the baby monster was later realized as a permutation group on 13,571,955,000 points using a computer by Jeffrey Leon and Charles Sims.  Robert Griess later found a computer-free construction using the fact that its double cover is contained in the monster group.  The name \"baby monster\" was suggested by John Horton Conway.\n\nRepresentations\nIn characteristic 0, the 4371-dimensional representation of the baby monster does not have a nontrivial invariant algebra structure analogous to the Griess algebra, but Ryba (2007) showed that it does have such an invariant algebra structure if it is reduced modulo 2.\nThe smallest faithful matrix representation of the Baby Monster is of size 4370 over the finite field of order 2.\nHöhn (1996) constructed a vertex operator algebra acted on by the baby monster.\n\nGeneralized monstrous moonshine\nConway and Norton suggested in their 1979 paper that monstrous moonshine is not limited to the monster, but that similar phenomena may be found for other groups. Larissa Queen and others subsequently found that one can construct the expansions of many Hauptmoduln from simple combinations of dimensions of sporadic groups. For the Baby monster B or F2, the relevant McKay–Thompson series is \n  \n    \n      \n        \n          T\n          \n            2\n            A\n          \n        \n        (\n        τ\n        )\n      \n    \n    {\\displaystyle T_{2A}(\\tau )}\n  \n where one can set the constant term a(0) = 104.\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  j\n                  \n                    2\n                    A\n                  \n                \n                (\n                τ\n                )\n              \n              \n                \n                =\n                \n                  T\n                  \n                    2\n                    A\n                  \n                \n                (\n                τ\n                )\n                +\n                104\n              \n            \n            \n              \n              \n                \n                =\n                \n                  \n                    (\n                    \n                      \n                        \n                          (\n                          \n                            \n                              \n                                \n                                  η\n                                  (\n                                  τ\n                                  )\n                                \n                                \n                                  η\n                                  (\n                                  2\n                                  τ\n                                  )\n                                \n                              \n                            \n                          \n                          )\n                        \n                        \n                          12\n                        \n                      \n                      +\n                      \n                        2\n                        \n                          6\n                        \n                      \n                      \n                        \n                          (\n                          \n                            \n                              \n                                \n                                  η\n                                  (\n                                  2\n                                  τ\n                                  )\n                                \n                                \n                                  η\n                                  (\n                                  τ\n                                  )\n                                \n                              \n                            \n                          \n                          )\n                        \n                        \n ",
    "links": [
      "Abelian group",
      "Abelian variety",
      "Additive group",
      "Algebraic group",
      "Algebraic structure",
      "Alternating group",
      "ArXiv (identifier)",
      "Arithmetic group",
      "Babymonster",
      "Bernd Fischer (mathematician)",
      "Bibcode (identifier)",
      "Cauchy's theorem (group theory)",
      "Centralizer",
      "Character table",
      "Charles Sims (mathematician)",
      "Circle group",
      "Classification of finite simple groups",
      "Conformal group",
      "Continuous group",
      "Conway group Co2",
      "Cyclic group",
      "Daniel Gorenstein",
      "Dedekind eta function",
      "Diffeomorphism",
      "Dihedral group",
      "Direct product of groups",
      "Direct sum of groups",
      "Discrete group",
      "Doi (identifier)",
      "Double cover (topology)",
      "E6 (mathematics)",
      "E7 (mathematics)",
      "E8 (mathematics)",
      "Elementary abelian group",
      "Elliptic curve",
      "Euclidean group",
      "F4 (mathematics)",
      "Finite field",
      "Finite group",
      "Fischer group Fi22",
      "Fischer group Fi23",
      "Free group",
      "Free product",
      "Frobenius group",
      "G2 (mathematics)",
      "General linear group",
      "Glossary of group theory",
      "Griess algebra",
      "Group action",
      "Group homomorphism"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Short description is different from Wikidata",
      "Category:Sporadic groups"
    ]
  },
  "Basic subgroup": {
    "title": "Basic subgroup",
    "url": "https://en.wikipedia.org/wiki/Basic_subgroup",
    "summary": "In abstract algebra, a basic subgroup is a subgroup of an abelian group which is a direct sum of cyclic subgroups and satisfies further technical conditions. This notion was introduced by L. Ya. Kulikov (for p-groups) and by László Fuchs (in general) in an attempt to formulate classification theory of infinite abelian groups that goes beyond the Prüfer theorems. It helps to reduce the classification problem to classification of possible extensions between two well understood classes of abelian groups: direct sums of cyclic groups and divisible groups.",
    "content": "In abstract algebra, a basic subgroup is a subgroup of an abelian group which is a direct sum of cyclic subgroups and satisfies further technical conditions. This notion was introduced by L. Ya. Kulikov (for p-groups) and by László Fuchs (in general) in an attempt to formulate classification theory of infinite abelian groups that goes beyond the Prüfer theorems. It helps to reduce the classification problem to classification of possible extensions between two well understood classes of abelian groups: direct sums of cyclic groups and divisible groups.\n\nDefinition and properties\nA subgroup, B, of an abelian group, A, is called  p-basic, for a fixed prime number, p, if the following conditions hold:\n\nB is a direct sum of cyclic groups of order pn and infinite cyclic groups;\nB is a p-pure subgroup of A;\nThe quotient group, A/B, is a p-divisible group.\nConditions 1–3 imply that the subgroup, B, is Hausdorff in the p-adic topology of B, which moreover coincides with the topology induced from A, and that B is dense in A. Picking a generator in each cyclic direct summand of B creates a  p-basis of B, which is analogous to a basis of a vector space or a free abelian group.\nEvery abelian group, A, contains p-basic subgroups for each p, and any 2 p-basic subgroups of A are isomorphic. Abelian groups that contain a unique p-basic subgroup have been completely characterized. For the case of p-groups they are either divisible or bounded; i.e., have bounded exponent. In general, the isomorphism class of the quotient, A/B by a basic subgroup, B, may depend on B.\n\nReferences\nLászló Fuchs (1970), Infinite abelian groups, Vol. I. Pure and Applied Mathematics, Vol. 36. New York–London: Academic Press MR 0255673\nL. Ya. Kulikov, On the theory of abelian groups of arbitrary cardinality (in Russian), Mat. Sb., 16 (1945), 129–162\nKurosh, A. G. (1960), The theory of groups, New York: Chelsea, MR 0109842",
    "links": [
      "Abelian group",
      "Abstract algebra",
      "Aleksandr Gennadievich Kurosh",
      "Basis (linear algebra)",
      "Cyclic group",
      "Dense subset",
      "Direct sum",
      "Divisible group",
      "Free abelian group",
      "Group extension",
      "Hausdorff topological space",
      "Induced topology",
      "MR (identifier)",
      "P-group",
      "Prime number",
      "Prüfer theorems",
      "Pure subgroup",
      "Subgroup",
      "Vector space"
    ],
    "categories": [
      "Category:Abelian group theory",
      "Category:Infinite group theory",
      "Category:Subgroup properties"
    ]
  },
  "Burnside ring": {
    "title": "Burnside ring",
    "url": "https://en.wikipedia.org/wiki/Burnside_ring",
    "summary": "In mathematics, the Burnside ring of a finite group is an algebraic construction that encodes the different ways the group can act on finite sets. The ideas were introduced by William Burnside at the end of the nineteenth century. The algebraic ring structure is a more recent development, due to Solomon (1967).",
    "content": "In mathematics, the Burnside ring of a finite group is an algebraic construction that encodes the different ways the group can act on finite sets. The ideas were introduced by William Burnside at the end of the nineteenth century. The algebraic ring structure is a more recent development, due to Solomon (1967).\n\nFormal definition\nGiven a finite group G, the generators of its Burnside ring Ω(G) are the formal sums of isomorphism classes of finite G-sets. For the ring structure, addition is given by disjoint union of G-sets and multiplication by their Cartesian product.\nThe Burnside ring is a free Z-module, whose generators are the (isomorphism classes of) orbit types of G.\nIf G acts on a finite set X, then one can write \n  \n    \n      \n        X\n        =\n        \n          ⋃\n          \n            i\n          \n        \n        \n          X\n          \n            i\n          \n        \n      \n    \n    {\\textstyle X=\\bigcup _{i}X_{i}}\n  \n (disjoint union), where each Xi is a single G-orbit. Choosing any element xi in Xi creates an isomorphism G/Gi → Xi, where Gi is the stabilizer (isotropy) subgroup of G at xi. A different choice of representative yi in Xi gives a conjugate subgroup to Gi as stabilizer.  This shows that the generators of Ω(G) as a Z-module are the orbits G/H as H ranges over conjugacy classes of subgroups of G.\nIn other words, a typical element of Ω(G) is\n\n  \n    \n      \n        \n          ∑\n          \n            i\n            =\n            1\n          \n          \n            N\n          \n        \n        \n          a\n          \n            i\n          \n        \n        [\n        G\n        \n          /\n        \n        \n          G\n          \n            i\n          \n        \n        ]\n        ,\n      \n    \n    {\\displaystyle \\sum _{i=1}^{N}a_{i}[G/G_{i}],}\n  \n\nwhere ai in Z and G1, G2, ..., GN are representatives of the conjugacy classes of subgroups of G.\n\nMarks\nMuch as character theory simplifies working with group representations, marks simplify working with permutation representations and the Burnside ring.\nIf G acts on X, and H ≤ G (H is a subgroup of G), then the mark of H on X is the number of elements of X that are fixed by every element of H: \n  \n    \n      \n        \n          m\n          \n            X\n          \n        \n        (\n        H\n        )\n        =\n        \n          |\n          \n            X\n            \n              H\n            \n          \n          |\n        \n      \n    \n    {\\displaystyle m_{X}(H)=\\left|X^{H}\\right|}\n  \n, where\n\n  \n    \n      \n        \n          X\n          \n            H\n          \n        \n        =\n        {\n        x\n        ∈\n        X\n        ∣\n        h\n        ⋅\n        x\n        =\n        x\n        ,\n        ∀\n        h\n        ∈\n        H\n        }\n        .\n      \n    \n    {\\displaystyle X^{H}=\\{x\\in X\\mid h\\cdot x=x,\\forall h\\in H\\}.}\n  \n\nIf H and K are conjugate subgroups, then mX(H) = mX(K) for any finite G-set X; indeed, if K = gHg−1 then XK = g · XH.\nIt is also easy to see that for each H ≤ G, the map Ω(G) → Z : X ↦ mX(H) is a homomorphism. This means that to know the marks of G, it is sufficient to evaluate them on the generators of Ω(G), viz. the orbits G/H.\nFor each pair of subgroups H,K ≤ G define\n\n  \n    \n      \n        m\n        (\n        K\n        ,\n        H\n        )\n        =\n        \n          |\n          \n            [\n            G\n            \n              /\n            \n            K\n            \n              ]\n              \n                H\n              \n            \n          \n          |\n        \n        =\n        #\n        \n          {\n          \n            g\n            K\n            ∈\n            G\n            \n              /\n            \n            K\n            ∣\n            H\n            g\n            K\n            =\n            g\n            K\n          \n          }\n        \n        .\n      \n    \n    {\\displaystyle m(K,H)=\\left|[G/K]^{H}\\right|=\\#\\left\\{gK\\in G/K\\mid HgK=gK\\right\\}.}\n  \n\nThis is mX(H) for X = G/K. The condition HgK = gK is equivalent to g−1Hg ≤ K, so if H is not conjugate to a subgroup of K then m(K, H) = 0.\nTo record all possible marks, one forms a table, Burnside's Table of Marks, as follows: Let G1 (= trivial subgroup), G2, ..., GN = G be representatives of the N conjugacy classes of subgroups of G, ordered in such a way that whenever Gi is conjugate to a subgroup of Gj, then i ≤ j.  Now define the N × N table (square matrix) whose (i, j)th entry is m(Gi, Gj). This matrix is lower triangular, and the elements on the diagonal are non-zero so it is invertible.\nIt follows that if X is a G-set, and u its row vector of marks, so ui = mX(Gi), then X decomposes as a disjoint union of ai copies of the orbit of type Gi, where the vector a satisfies,\n\naM = u,\nwhere M is the matrix of the table of marks.  This theorem is due to (Burnside 1897).\n\nExamples\nThe table of marks for the cyclic group of order 6:\n\nThe table of marks for the symmetric group S3:\n\nThe dots in the two tables are all",
    "links": [
      "Burnside category",
      "Cambridge University Press",
      "Cartesian product",
      "Character theory",
      "Compact group",
      "Conjugacy classes",
      "Cyclic group",
      "Disjoint union",
      "Doi (identifier)",
      "Finite group",
      "Group action (mathematics)",
      "Group representation",
      "Homotopy",
      "ISBN (identifier)",
      "Linear combination",
      "MR (identifier)",
      "Mathematics",
      "Module (mathematics)",
      "OCLC (identifier)",
      "Permutation representation",
      "Representation ring",
      "Ring (mathematics)",
      "Row and column vectors",
      "Segal conjecture",
      "Springer-Verlag",
      "Square matrix",
      "Subgroup",
      "Vector space",
      "William Burnside",
      "Wikipedia:Citing sources",
      "Wikipedia:External links",
      "Wikipedia:Further reading",
      "Wikipedia:When to cite",
      "Wikipedia:WikiProject Fact and Reference Check",
      "Help:Maintenance template removal"
    ],
    "categories": [
      "Category:All articles lacking in-text citations",
      "Category:Articles lacking in-text citations from May 2018",
      "Category:Articles with short description",
      "Category:Finite groups",
      "Category:Group theory",
      "Category:Permutation groups",
      "Category:Representation theory of groups",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Cambridge, Massachusetts": {
    "title": "Cambridge, Massachusetts",
    "url": "https://en.wikipedia.org/wiki/Cambridge,_Massachusetts",
    "summary": "Cambridge ( KAYM-brij) is a city in Middlesex County, Massachusetts, United States. It is a suburb in the Greater Boston metropolitan area, located directly across the Charles River from Boston. The city's population as of the 2020 U.S. census was 118,403, making it the most populous city in the county, the fourth-largest in Massachusetts behind Boston, Worcester, and Springfield, and ninth-most populous in New England. The city was named in honor of the University of Cambridge in Cambridge, England, which was an important center of the Puritan theology that was embraced by the town's founders.\nFounded in December 1630 during the colonial era, Cambridge was one among the first cities established in the Thirteen Colonies, and it went on to play a historic role during the American Revolution. In May 1775, approximately 16,000 American patriots assembled in Cambridge Common to begin organizing a military retaliation against British troops following the Battles of Lexington and Concord. On",
    "content": "Cambridge ( KAYM-brij) is a city in Middlesex County, Massachusetts, United States. It is a suburb in the Greater Boston metropolitan area, located directly across the Charles River from Boston. The city's population as of the 2020 U.S. census was 118,403, making it the most populous city in the county, the fourth-largest in Massachusetts behind Boston, Worcester, and Springfield, and ninth-most populous in New England. The city was named in honor of the University of Cambridge in Cambridge, England, which was an important center of the Puritan theology that was embraced by the town's founders.\nFounded in December 1630 during the colonial era, Cambridge was one among the first cities established in the Thirteen Colonies, and it went on to play a historic role during the American Revolution. In May 1775, approximately 16,000 American patriots assembled in Cambridge Common to begin organizing a military retaliation against British troops following the Battles of Lexington and Concord. On July 2, 1775, two weeks after the Second Continental Congress in Philadelphia formally established the Continental Army and appointed George Washington commander of it, Washington arrived at Cambridge Common to take command of the Patriot soldiers camped there. Many of these soldiers played a role in supporting Washington's successful siege of Boston, which trapped garrisoned British troops from moving by land, forcing the British to ultimately abandon Boston. Cambridge Common is thus celebrated as the birthplace of the Continental Army.\nHarvard University, an Ivy League university founded in Cambridge in 1636, is the oldest institution of higher learning in the United States. The Massachusetts Institute of Technology (MIT), Lesley University, and Hult International Business School also are based in Cambridge. Radcliffe College, a women's liberal arts college, was based in Cambridge from its 1879 founding until its assimilation into Harvard in 1999.\nKendall Square, near MIT in the eastern part of Cambridge, has been called \"the most innovative square mile on the planet\" due to the high concentration of startup companies that have emerged there since 2010. In 2022, Cambridge was home to over 250 biotech companies, with more than 120 located within the Kendall Square zipcode.\n\nHistory\nPre-colonization\nThe Massachusett inhabited the area that is now called Cambridge for thousands of years prior to European colonization of the Americas, most recently under the name Anmoughcawgen, which means 'fishing weir' or 'beaver dam' in Natick. At the time of European contact, the area was inhabited by Naumkeag or Pawtucket to the north and Massachusett to the south, and may have been inhabited by other groups such as the Totant, not well described in later European narratives. The contact period introduced a number of European infectious diseases which would decimate native populations in virgin soil epidemics, leaving the area uncontested upon the arrival of large groups of English settlers in 1630.\n\n17th century and colonialism\nThe first settlement of the Massachusetts Bay Colony was established in Salem, in June of 1630.  That December, the site of present-day Cambridge was chosen for development because it was safely upriver from Boston Harbor, making it easily defensible from attacks by enemy ships. The city was founded by Thomas Dudley, his daughter Anne Bradstreet, and his son-in-law Simon Bradstreet. The first houses were built in the spring of 1631. The settlement was initially referred to as \"the newe towne\". Official Massachusetts records show the name rendered as Newe Towne by 1632, and as Newtowne by 1638.\nLocated at the first convenient Charles River crossing west of Boston, Newtowne was one of several towns, including Boston, Dorchester, Watertown, and Weymouth, founded by the 700 original Puritan colonists of the Bay Colony under Governor John Winthrop. Its first preacher was Thomas Hooker, who led many of its original inhabitants west in 1636 to found Hartford and the Connecticut Colony; before leaving, they sold their plots to more recent immigrants from England. The original village site is now within Harvard Square. The marketplace where farmers sold crops from surrounding towns at the edge of a salt marsh (since filled) remains within a small park at the corner of John F. Kennedy and Winthrop Streets.\nIn 1636, Newe College, later renamed Harvard College after benefactor John Harvard, was founded as North America's first institution of higher learning. Its initial purpose was training ministers. According to Cotton Mather, Newtowne was chosen for the site of the college by the Great and General Court, then the legislature of the Massachusetts Bay Colony, primarily for its proximity to the popular and highly respected Puritan preacher Thomas Shepard. In May 1638, the settlement's name was changed to Cambridge in honor of the University of Cambridge in Cambridge, England.\nIn 1639, the Great and General Court purchased the ",
    "links": [
      "1790 United States census",
      "1800 United States census",
      "1810 United States census",
      "1820 United States census",
      "1830 United States census",
      "1840 United States census",
      "1850 United States census",
      "1860 United States census",
      "1860 United States presidential election",
      "1864 United States presidential election",
      "1868 United States presidential election",
      "1870 United States census",
      "1872 United States presidential election",
      "1876 United States presidential election",
      "1880 United States census",
      "1880 United States presidential election",
      "1884 United States presidential election",
      "1888 United States presidential election",
      "1890 United States census",
      "1892 United States presidential election",
      "1896 United States presidential election",
      "1900 United States census",
      "1900 United States presidential election",
      "1904 United States presidential election",
      "1908 United States presidential election",
      "1910 United States census",
      "1912 United States presidential election",
      "1916 United States presidential election",
      "1920 United States census",
      "1920 United States presidential election",
      "1924 United States presidential election",
      "1928 United States presidential election",
      "1930 United States census",
      "1932 United States presidential election",
      "1936 United States presidential election",
      "1940 United States census",
      "1940 United States presidential election",
      "1944 United States presidential election",
      "1948 United States presidential election",
      "1950 United States census",
      "1952 United States presidential election",
      "1956 United States presidential election",
      "1960 United States census",
      "1960 United States presidential election",
      "1964 United States presidential election",
      "1968 United States presidential election",
      "1970 United States census",
      "1972 United States presidential election",
      "1976 United States presidential election",
      "1980 United States census"
    ],
    "categories": [
      "Category:1630 establishments in the Massachusetts Bay Colony",
      "Category:All Wikipedia articles written in American English",
      "Category:All articles containing potentially dated statements",
      "Category:All articles lacking reliable references",
      "Category:All articles needing additional references",
      "Category:All articles with dead external links",
      "Category:All articles with unsourced statements",
      "Category:Articles containing potentially dated statements from 2007",
      "Category:Articles containing potentially dated statements from 2024",
      "Category:Articles containing potentially dated statements from October 2024"
    ]
  },
  "Category of abelian groups": {
    "title": "Category of abelian groups",
    "url": "https://en.wikipedia.org/wiki/Category_of_abelian_groups",
    "summary": "In mathematics, the category Ab has the abelian groups as objects and group homomorphisms as morphisms. This is the prototype of an abelian category: indeed, every small abelian category can be embedded in Ab.",
    "content": "In mathematics, the category Ab has the abelian groups as objects and group homomorphisms as morphisms. This is the prototype of an abelian category: indeed, every small abelian category can be embedded in Ab.\n\nProperties\nThe zero object of Ab is the trivial group {0} which consists only of its neutral element.\nThe monomorphisms in Ab are the injective group homomorphisms, the epimorphisms are the surjective group homomorphisms, and the isomorphisms are the bijective group homomorphisms.\nAb is a full subcategory of Grp, the category of all groups. The main difference between Ab and Grp is that the sum of two homomorphisms f and g between abelian groups is again a group homomorphism:\n\n(f+g)(x+y) = f(x+y) + g(x+y) = f(x) + f(y) + g(x) + g(y)\n       = f(x) + g(x) + f(y) + g(y) = (f+g)(x) + (f+g)(y)\nThe third equality requires the group to be abelian. This addition of morphism turns Ab into a preadditive category, and because the direct sum of finitely many abelian groups yields a biproduct, we indeed have an additive category.\nIn Ab, the notion of kernel in the category theory sense coincides with kernel in the algebraic sense, i.e. the categorical kernel of the morphism f : A → B is the subgroup K of A defined by K = {x ∈ A : f(x) = 0}, together with the inclusion homomorphism i : K → A. The same is true for cokernels; the cokernel of f is the quotient group C = B / f(A) together with the natural projection p : B → C. (Note a further crucial difference between Ab and Grp: in Grp it can happen that f(A) is not a normal subgroup of B, and that therefore the quotient group B / f(A) cannot be formed.) With these concrete descriptions of kernels and cokernels, it is quite easy to check that Ab is indeed an abelian category. \nThe forgetful functor from \n  \n    \n      \n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} }\n  \nMod to Ab that sends a \n  \n    \n      \n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} }\n  \n-module \n  \n    \n      \n        (\n        M\n        ,\n        +\n        ,\n        ⋅\n        )\n      \n    \n    {\\displaystyle (M,+,\\cdot )}\n  \n to its underlying abelian group \n  \n    \n      \n        (\n        M\n        ,\n        +\n        )\n      \n    \n    {\\displaystyle (M,+)}\n  \n and the functor from Ab to \n  \n    \n      \n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} }\n  \n that sends an abelian group \n  \n    \n      \n        (\n        G\n        ,\n        +\n        )\n      \n    \n    {\\displaystyle (G,+)}\n  \n to the \n  \n    \n      \n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} }\n  \n-module \n  \n    \n      \n        (\n        G\n        ,\n        +\n        ,\n        ⋅\n        )\n      \n    \n    {\\displaystyle (G,+,\\cdot )}\n  \n obtained by setting \n  \n    \n      \n        k\n        ⋅\n        g\n        :=\n        \n          g\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle k\\cdot g:=g^{k}}\n  \n define an isomorphism of categories.\nThe product in Ab is given by the product of groups, formed by taking the Cartesian product of the underlying sets and performing the group operation componentwise. Because Ab has kernels, one can then show that Ab is a complete category. The coproduct in Ab is given by the direct sum; since Ab has cokernels, it follows that Ab is also cocomplete.\nWe have a forgetful functor Ab → Set which assigns to each abelian group the underlying set, and to each group homomorphism the underlying function. This functor is faithful, and therefore Ab is a concrete category. The forgetful functor has a left adjoint (which associates to a given set the free abelian group with that set as basis) but does not have a right adjoint.\nTaking direct limits in Ab is an exact functor. Since the group of integers Z serves as a generator, the category Ab is therefore a Grothendieck category; indeed it is the prototypical example of a Grothendieck category.\nAn object in Ab is injective if and only if it is a divisible group; it is projective if and only if it is a free abelian group. The category has a projective generator (Z) and an injective cogenerator (Q/Z). \nGiven two abelian groups A and B, their tensor product A⊗B is defined; it is again an abelian group. With this notion of product, Ab is a closed symmetric monoidal category.\nAb is not a topos since e.g. it has a zero object.\n\nSee also\nCategory of modules\nAbelian sheaf — many facts about the category of abelian groups continue to hold for the category of sheaves of abelian groups\n\nReferences\n\nLang, Serge (2002), Algebra, Graduate Texts in Mathematics, vol. 211 (Revised third ed.), New York: Springer-Verlag, ISBN 978-0-387-95385-4, MR 1878556\nMac Lane, Saunders (1998). Categories for the Working Mathematician. Graduate Texts in Mathematics. Vol. 5 (2nd ed.). Springer. ISBN 0-387-98403-8. Zbl 0906.18001.\nPedicchio, Maria Cristina; Tholen, Walter, eds. (2004). Categorical foundations. Special topics in order, topology, algebra, and shea",
    "links": [
      "Abelian category",
      "Abelian group",
      "Abelian sheaf",
      "Additive category",
      "Adjoint functors",
      "Algebra (Lang)",
      "Bijective",
      "Biproduct",
      "Cambridge University Press",
      "Cartesian product",
      "Categories for the Working Mathematician",
      "Category of groups",
      "Category of modules",
      "Category of sets",
      "Category theory",
      "Closed monoidal category",
      "Cocomplete",
      "Cokernel",
      "Complete category",
      "Concrete category",
      "Coproduct",
      "Direct limit",
      "Direct product of groups",
      "Direct sum of abelian groups",
      "Divisible group",
      "Epimorphism",
      "Exact functor",
      "Faithful functor",
      "Forgetful functor",
      "Free abelian group",
      "Full subcategory",
      "Function (mathematics)",
      "Generator (category theory)",
      "Graduate Texts in Mathematics",
      "Grothendieck category",
      "Group homomorphism",
      "ISBN (identifier)",
      "Injective",
      "Injective cogenerator",
      "Injective module",
      "Isomorphism",
      "Isomorphism of categories",
      "Kernel (algebra)",
      "Kernel (category theory)",
      "M. Cristina Pedicchio",
      "MR (identifier)",
      "Mathematics",
      "Monoidal category",
      "Monomorphism",
      "Morphism"
    ],
    "categories": [
      "Category:Abelian group theory",
      "Category:Articles with short description",
      "Category:Categories in category theory",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Cauchy's theorem (group theory)": {
    "title": "Cauchy's theorem (group theory)",
    "url": "https://en.wikipedia.org/wiki/Cauchy%27s_theorem_(group_theory)",
    "summary": "In mathematics, specifically group theory, Cauchy's theorem states that if G is a finite group and p is a prime number dividing the order of G (the number of elements in G), then G contains an element of order p. That is, there is x in G such that p is the smallest positive integer with xp = e, where e is the identity element of G. It is named after Augustin-Louis Cauchy, who discovered it in 1845.\nThe theorem is a partial converse to Lagrange's theorem, which states that the order of any subgroup of a finite group G divides the order of G. In general, not every divisor of \n  \n    \n      \n        \n          |\n        \n        G\n        \n          |\n        \n      \n    \n    {\\displaystyle |G|}\n  \n arises as the order of a subgroup of \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n. Cauchy's theorem states that for any prime divisor p of the order of G, there is a subgroup of G whose order is p—the cyclic group generated by the element in Cauchy's theorem.\nCauchy's theore",
    "content": "In mathematics, specifically group theory, Cauchy's theorem states that if G is a finite group and p is a prime number dividing the order of G (the number of elements in G), then G contains an element of order p. That is, there is x in G such that p is the smallest positive integer with xp = e, where e is the identity element of G. It is named after Augustin-Louis Cauchy, who discovered it in 1845.\nThe theorem is a partial converse to Lagrange's theorem, which states that the order of any subgroup of a finite group G divides the order of G. In general, not every divisor of \n  \n    \n      \n        \n          |\n        \n        G\n        \n          |\n        \n      \n    \n    {\\displaystyle |G|}\n  \n arises as the order of a subgroup of \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n. Cauchy's theorem states that for any prime divisor p of the order of G, there is a subgroup of G whose order is p—the cyclic group generated by the element in Cauchy's theorem.\nCauchy's theorem is generalized by Sylow's first theorem, which implies that if pn is the maximal power of p dividing the order of G, then G has a subgroup of order pn (and using the fact that a p-group is solvable, one can show that G has subgroups of order pr for any r less than or equal to n).\n\nStatement and proof\nMany texts prove the theorem with the use of strong induction and the class equation, though considerably less machinery is required to prove the theorem in the abelian case. One can also invoke group actions for the proof.\n\nProof 1\nWe first prove the special case that where G is abelian, and then the general case; both proofs are by induction on n = |G|, and have as starting case n = p which is trivial because any non-identity element now has order p. Suppose first that G is abelian. Take any non-identity element a, and let H be the cyclic group it generates. If p divides |H|, then a|H|/p is an element of order p. If p does not divide |H|, then it divides the order [G:H] of the quotient group G/H, which therefore contains an element of order p by the inductive hypothesis. That element is a class xH for some x in G, and if m is the order of x in G, then xm = e in G gives (xH)m = eH in G/H, so p divides m; as before xm/p is now an element of order p in G, completing the proof for the abelian case.\nIn the general case, let Z be the center of G, which is an abelian subgroup. If p divides |Z|, then Z contains an element of order p by the case of abelian groups, and this element works for G as well. So we may assume that p does not divide the order of Z. Since p does divide |G|, and G is the disjoint union of Z and of the conjugacy classes of non-central elements, there exists a conjugacy class of a non-central element a whose size is not divisible by p. But the class equation shows that size is [G : CG(a)], so p divides the order of the centralizer CG(a) of a in G, which is a proper subgroup because a is not central. This subgroup contains an element of order p by the inductive hypothesis, and we are done.\n\nProof 2\nThis proof uses the fact that for any action of a (cyclic) group of prime order p, the only possible orbit sizes are 1 and p, which is immediate from the orbit stabilizer theorem.\nThe set that our cyclic group shall act on is the set \n\n  \n    \n      \n        X\n        =\n        {\n        \n        (\n        \n          x\n          \n            1\n          \n        \n        ,\n        …\n        ,\n        \n          x\n          \n            p\n          \n        \n        )\n        ∈\n        \n          G\n          \n            p\n          \n        \n        :\n        \n          x\n          \n            1\n          \n        \n        \n          x\n          \n            2\n          \n        \n        ⋯\n        \n          x\n          \n            p\n          \n        \n        =\n        e\n        \n        }\n      \n    \n    {\\displaystyle X=\\{\\,(x_{1},\\ldots ,x_{p})\\in G^{p}:x_{1}x_{2}\\cdots x_{p}=e\\,\\}}\n  \n\nof p-tuples of elements of G whose product (in order) gives the identity. Such a p-tuple is uniquely determined by all its components except the last one, as the last element must be the inverse of the product of those preceding elements. One also sees that those p − 1 elements can be chosen freely, so X has |G|p−1 elements, which is divisible by p.\nNow from the fact that in a group if ab = e then ba = e, it follows that any cyclic permutation of the components of an element of X again gives an element of X. Therefore one can define an action of the cyclic group Cp  of order p on X by cyclic permutations of components, in other words in which a chosen generator of Cp sends \n\n  \n    \n      \n        (\n        \n          x\n          \n            1\n          \n        \n        ,\n        \n          x\n          \n            2\n          \n        \n        ,\n        …\n        ,\n        \n          x\n          \n            p\n          \n        \n        )\n        ↦\n        (\n        \n          x\n          \n            2\n          \n        \n     ",
    "links": [
      "Abelian group",
      "Abelian variety",
      "Additive group",
      "Algebraic group",
      "Algebraic structure",
      "Alternating group",
      "American Mathematical Monthly",
      "Arithmetic group",
      "Augustin-Louis Cauchy",
      "Cauchy theorem (disambiguation)",
      "Center (group theory)",
      "Centralizer",
      "Circle group",
      "CiteSeerX (identifier)",
      "Classification of finite simple groups",
      "Conformal group",
      "Conjugacy class",
      "Continuous group",
      "Cyclic group",
      "Cyclic permutation",
      "Diffeomorphism",
      "Dihedral group",
      "Direct product of groups",
      "Direct sum of groups",
      "Discrete group",
      "Doi (identifier)",
      "Dover Publications",
      "E6 (mathematics)",
      "E7 (mathematics)",
      "E8 (mathematics)",
      "Elementary abelian group",
      "Elliptic curve",
      "Euclidean group",
      "F4 (mathematics)",
      "Finite group",
      "Free group",
      "Free product",
      "Frobenius group",
      "G2 (mathematics)",
      "General linear group",
      "Generator (mathematics)",
      "Glossary of group theory",
      "Group action",
      "Group action (mathematics)",
      "Group homomorphism",
      "Group of Lie type",
      "Group theory",
      "Hall subgroup",
      "Historia Mathematica",
      "Hyperbolic group"
    ],
    "categories": [
      "Category:Articles containing proofs",
      "Category:Articles with short description",
      "Category:Augustin-Louis Cauchy",
      "Category:Short description is different from Wikidata",
      "Category:Theorems about finite groups"
    ]
  },
  "Center (group theory)": {
    "title": "Center (group theory)",
    "url": "https://en.wikipedia.org/wiki/Center_(group_theory)",
    "summary": "In abstract algebra, the center of a group G is the set of elements that commute with every element of G. It is denoted Z(G), from German Zentrum, meaning center. In set-builder notation,\n\nZ(G) = {z ∈ G | ∀g ∈ G, zg = gz}.\nThe center is a normal subgroup, \n  \n    \n      \n        Z\n        (\n        G\n        )\n        ◃\n        G\n      \n    \n    {\\displaystyle Z(G)\\triangleleft G}\n  \n, and also a characteristic subgroup, but is not necessarily fully characteristic. The quotient group, G / Z(G), is isomorphic to the inner automorphism group, Inn(G).\nA group G is abelian if and only if Z(G) = G. At the other extreme, a group is said to be centerless if Z(G) is trivial; i.e., consists only of the identity element.\nThe elements of the center are central elements.",
    "content": "In abstract algebra, the center of a group G is the set of elements that commute with every element of G. It is denoted Z(G), from German Zentrum, meaning center. In set-builder notation,\n\nZ(G) = {z ∈ G | ∀g ∈ G, zg = gz}.\nThe center is a normal subgroup, \n  \n    \n      \n        Z\n        (\n        G\n        )\n        ◃\n        G\n      \n    \n    {\\displaystyle Z(G)\\triangleleft G}\n  \n, and also a characteristic subgroup, but is not necessarily fully characteristic. The quotient group, G / Z(G), is isomorphic to the inner automorphism group, Inn(G).\nA group G is abelian if and only if Z(G) = G. At the other extreme, a group is said to be centerless if Z(G) is trivial; i.e., consists only of the identity element.\nThe elements of the center are central elements.\n\nAs a subgroup\nThe center of G is always a subgroup of G.  In particular:\n\nZ(G) contains the identity element of G, because it commutes with every element of g, by definition: eg = g = ge, where e is the identity;\nIf x and y are in Z(G), then so is xy, by associativity: (xy)g = x(yg) = x(gy) = (xg)y = (gx)y = g(xy) for each g ∈ G; i.e., Z(G) is closed;\nIf x is in Z(G), then so is x−1 as, for all g in G, x−1 commutes with g: (gx = xg) ⇒ (x−1gxx−1 = x−1xgx−1) ⇒ (x−1g = gx−1).\nFurthermore, the center of G is always an abelian and normal subgroup of G. Since all elements of Z(G) commute, it is closed under conjugation.\nA group homomorphism f : G → H might not restrict to a homomorphism between their centers. The image elements  f (g) commute with the image f ( G ), but they need not commute with all of H unless f  is surjective. Thus the center mapping \n  \n    \n      \n        G\n        →\n        Z\n        (\n        G\n        )\n      \n    \n    {\\displaystyle G\\to Z(G)}\n  \n is not a functor between categories Grp and Ab, since it does not induce a map of arrows.\n\nConjugacy classes and centralizers\nBy definition, an element is central whenever its conjugacy class contains only the element itself; i.e. Cl(g) = {g}.\n\nThe center is the intersection of all the centralizers of elements of G:  \n  \n    \n      \n        Z\n        (\n        G\n        )\n        =\n        \n          ⋂\n          \n            g\n            ∈\n            G\n          \n        \n        \n          Z\n          \n            G\n          \n        \n        (\n        g\n        )\n        .\n      \n    \n    {\\displaystyle Z(G)=\\bigcap _{g\\in G}Z_{G}(g).}\n  \n   As centralizers are subgroups, this again shows that the center is a subgroup.\n\nConjugation\nConsider the map f : G → Aut(G), from G to the automorphism group of G defined by f(g) = ϕg, where ϕg is the automorphism of G defined by \n\nf(g)(h) = ϕg(h) = ghg−1.\nThe function, f is a group homomorphism, and its kernel is precisely the center of G, and its image is called the inner automorphism group of G, denoted Inn(G). By the first isomorphism theorem we get,\n\nG/Z(G) ≃ Inn(G).\nThe cokernel of this map is the group Out(G) of outer automorphisms, and these form the exact sequence\n\n1 ⟶ Z(G) ⟶ G ⟶ Aut(G) ⟶ Out(G) ⟶ 1.\n\nExamples\nThe center of an abelian group, G, is all of G.\nThe center of the Heisenberg group, H, is the set of matrices of the form: \n  \n    \n      \n        \n          \n            (\n            \n              \n                \n                  1\n                \n                \n                  0\n                \n                \n                  z\n                \n              \n              \n                \n                  0\n                \n                \n                  1\n                \n                \n                  0\n                \n              \n              \n                \n                  0\n                \n                \n                  0\n                \n                \n                  1\n                \n              \n            \n            )\n          \n        \n      \n    \n    {\\displaystyle {\\begin{pmatrix}1&0&z\\\\0&1&0\\\\0&0&1\\end{pmatrix}}}\n  \n\nThe center of a nonabelian simple group is trivial.\nThe center of the dihedral group, Dn, is trivial for odd n ≥ 3.  For even n ≥ 4, the center consists of the identity element together with the 180° rotation of the polygon.\nThe center of the quaternion group, Q8 = {1, −1, i, −i, j, −j, k, −k}, is {1, −1}.\nThe center of the symmetric group, Sn, is trivial for n ≥ 3.\nThe center of the alternating group, An, is trivial for n ≥ 4.\nThe center of the general linear group over a field F, GLn(F), is the collection of scalar matrices, { sIn ∣ s ∈ F \\ {0} }.\nThe center of the orthogonal group, On(F) is {In, −In}.\nThe center of the special orthogonal group, SO(n) is the whole group when n = 2, and otherwise {In, −In} when n is even, and trivial when n is odd.\nThe center of the unitary group, \n  \n    \n      \n        U\n        (\n        n\n        )\n      \n    \n    {\\displaystyle U(n)}\n  \n is \n  \n    \n      \n        \n          {\n          \n            \n              e\n              \n                i\n                θ\n              \n            \n            ⋅\n       ",
    "links": [
      "Abelian group",
      "Abstract algebra",
      "Aldo Tambellini",
      "Alternating group",
      "Automorphism group",
      "Cayley table",
      "Center (algebra)",
      "Center (ring theory)",
      "Centralizer and normalizer",
      "Characteristic subgroup",
      "Class equation",
      "Cokernel",
      "Commutative",
      "Conjugacy class",
      "Conjugate closure",
      "Cyclic group",
      "Diagonal matrix",
      "Dihedral group",
      "Dihedral group of order 8",
      "Doi (identifier)",
      "Encyclopedia of Mathematics",
      "European Mathematical Society",
      "Exact sequence",
      "Field (mathematics)",
      "Finite group",
      "First isomorphism theorem",
      "Fully characteristic subgroup",
      "General linear group",
      "Group (mathematics)",
      "Group homomorphism",
      "Group isomorphism",
      "Grün's lemma",
      "Heisenberg group",
      "Hypercenter",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "Identity element",
      "If and only if",
      "Inner automorphism",
      "Inner automorphism group",
      "Intersection (set theory)",
      "Kernel (algebra)",
      "Kilominx",
      "Megaminx",
      "Nonabelian group",
      "Normal subgroup",
      "Orthogonal group",
      "Outer automorphism",
      "P-group",
      "Perfect group"
    ],
    "categories": [
      "Category:All Wikipedia articles written in American English",
      "Category:Articles with short description",
      "Category:Functional subgroups",
      "Category:Group theory",
      "Category:Short description is different from Wikidata",
      "Category:Use American English from March 2021",
      "Category:Use mdy dates from March 2021"
    ]
  },
  "Characteristic subgroup": {
    "title": "Characteristic subgroup",
    "url": "https://en.wikipedia.org/wiki/Characteristic_subgroup",
    "summary": "In mathematics, particularly in the area of abstract algebra known as group theory, a characteristic subgroup is a subgroup that is mapped to itself by every automorphism of the parent group.  Because every conjugation map is an inner automorphism, every characteristic subgroup is normal; though the converse is not guaranteed.  Examples of characteristic subgroups include the commutator subgroup and the center of a group.",
    "content": "In mathematics, particularly in the area of abstract algebra known as group theory, a characteristic subgroup is a subgroup that is mapped to itself by every automorphism of the parent group.  Because every conjugation map is an inner automorphism, every characteristic subgroup is normal; though the converse is not guaranteed.  Examples of characteristic subgroups include the commutator subgroup and the center of a group.\n\nDefinition\nA subgroup H of a group G is called a characteristic subgroup if for every automorphism φ of G, one has φ(H) ≤ H; then write H char G.\nIt would be equivalent to require the stronger condition φ(H) = H for every automorphism φ of G, because φ−1(H) ≤ H implies the reverse inclusion H ≤ φ(H).\n\nBasic properties\nGiven H char G, every automorphism of G induces an automorphism of the quotient group G/H, which yields a homomorphism Aut(G) → Aut(G/H).\nIf G has a unique subgroup H of a given index, then H is characteristic in G.\n\nRelated concepts\nNormal subgroup\nA subgroup of H that is invariant under all inner automorphisms is called normal; also, an invariant subgroup.\n\n∀φ ∈ Inn(G)： φ(H) ≤ H\nSince Inn(G) ⊆ Aut(G) and a characteristic subgroup is invariant under all automorphisms, every characteristic subgroup is normal. However, not every normal subgroup is characteristic.  Here are several examples:\n\nLet H be a nontrivial group, and let G be the direct product, H × H.  Then the subgroups, {1} × H and H  × {1}, are both normal, but neither is characteristic.  In particular, neither of these subgroups is invariant under the automorphism, (x, y) → (y, x), that switches the two factors.\nFor a concrete example of this, let V be the Klein four-group (which is isomorphic to the direct product, \n  \n    \n      \n        \n          \n            Z\n          \n          \n            2\n          \n        \n        ×\n        \n          \n            Z\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {Z} _{2}\\times \\mathbb {Z} _{2}}\n  \n).  Since this group is abelian, every subgroup is normal; but every permutation of the 3 non-identity elements is an automorphism of V, so the 3 subgroups of order 2 are not characteristic.  Here V = {e, a, b, ab} . Consider H = {e, a} and consider the automorphism, T(e) = e, T(a) = b, T(b) = a, T(ab) = ab; then T(H) is not contained in H.\nIn the quaternion group of order 8, each of the cyclic subgroups of order 4 is normal, but none of these are characteristic.  However, the subgroup, {1, −1}, is characteristic, since it is the only subgroup of order 2.\nIf n > 2 is even, the dihedral group of order 2n has 3 subgroups of index 2, all of which are normal.  One of these is the cyclic subgroup, which is characteristic.  The other two subgroups are dihedral; these are permuted by an outer automorphism of the parent group, and are therefore not characteristic.\n\nStrictly characteristic subgroup\nA strictly characteristic subgroup, or a distinguished subgroup, is one which is invariant under surjective endomorphisms. For finite groups, surjectivity of an endomorphism implies injectivity, so a surjective endomorphism is an automorphism; thus being strictly characteristic is equivalent to characteristic. This is not the case anymore for infinite groups.\n\nFully characteristic subgroup\nFor an even stronger constraint, a fully characteristic subgroup (also, fully invariant subgroup) of a group G, is a subgroup H ≤ G that is invariant under every endomorphism of G (and not just every automorphism):\n\n∀φ ∈ End(G)： φ(H) ≤ H.\nEvery group has itself (the improper subgroup) and the trivial subgroup as two of its fully characteristic subgroups. The commutator subgroup of a group is always a fully characteristic subgroup.\nEvery endomorphism of G induces an endomorphism of G/H, which yields a map End(G) → End(G/H).\n\nVerbal subgroup\nAn even stronger constraint is verbal subgroup, which is the image of a fully invariant subgroup of a free group under a homomorphism. More generally, any verbal subgroup is always fully characteristic. For any reduced free group, and, in particular, for any free group, the converse also holds: every fully characteristic subgroup is verbal.\n\nTransitivity\nThe property of being characteristic or fully characteristic is transitive; if H is a (fully) characteristic subgroup of K, and K is a (fully) characteristic subgroup of G, then H is a (fully) characteristic subgroup of G.\n\nH char K char G ⇒ H char G.\nMoreover, while normality is not transitive, it is true that every characteristic subgroup of a normal subgroup is normal.\n\nH char K ⊲ G ⇒ H ⊲ G\nSimilarly, while being strictly characteristic (distinguished) is not transitive, it is true that every fully characteristic subgroup of a strictly characteristic subgroup is strictly characteristic.\nHowever, unlike normality, if H char G and K is a subgroup of G containing H, then in general H is not necessarily characteristic in K.\n\nH char G, H < K < G ⇏ H char K\n\nContainments\nEv",
    "links": [
      "Abelian group",
      "Abstract algebra",
      "Automorphism",
      "Center of a group",
      "Characteristically simple group",
      "Commutator subgroup",
      "Conjugacy class",
      "Cyclic group",
      "Derived subgroup",
      "Dihedral group",
      "Direct product of groups",
      "Endomorphism",
      "Finite group",
      "Free group",
      "Fully characteristic subgroup",
      "Graduate Texts in Mathematics",
      "Group (mathematics)",
      "Group homomorphism",
      "Group isomorphism",
      "Group theory",
      "ISBN (identifier)",
      "Identity component",
      "Index of a subgroup",
      "Inner automorphism",
      "John Wiley & Sons",
      "Klein four-group",
      "Mathematics",
      "Normal subgroup",
      "Outer automorphism group",
      "Quaternion group",
      "Quotient group",
      "Reduced free group",
      "Serge Lang",
      "Springer Science+Business Media",
      "Subgroup",
      "Surjective",
      "Symmetric group",
      "Topological group",
      "Torsion subgroup",
      "Transitive relation",
      "Verbal subgroup",
      "Wikipedia:Manual of Style",
      "Template:Math",
      "Help:Maintenance template removal",
      "MOS:FORMULA"
    ],
    "categories": [
      "Category:All articles with style issues",
      "Category:Articles with short description",
      "Category:Short description is different from Wikidata",
      "Category:Subgroup properties",
      "Category:Wikipedia articles with style issues from July 2025"
    ]
  },
  "Circle group": {
    "title": "Circle group",
    "url": "https://en.wikipedia.org/wiki/Circle_group",
    "summary": "In mathematics, the circle group, denoted by \n  \n    \n      \n        \n          T\n        \n      \n    \n    {\\displaystyle \\mathbb {T} }\n  \n or ⁠\n  \n    \n      \n        \n          \n            S\n          \n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {S} ^{1}}\n  \n⁠, is the multiplicative group of all complex numbers with absolute value 1, that is, the unit circle in the complex plane or simply the unit complex numbers\n\n  \n    \n      \n        \n          T\n        \n        =\n        {\n        z\n        ∈\n        \n          C\n        \n        :\n        \n          |\n        \n        z\n        \n          |\n        \n        =\n        1\n        }\n        .\n      \n    \n    {\\displaystyle \\mathbb {T} =\\{z\\in \\mathbb {C} :|z|=1\\}.}\n  \n\nThe circle group forms a subgroup of ⁠\n  \n    \n      \n        \n          \n            C\n          \n          \n            ×\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {C} ^{\\times }}\n  \n⁠, the multiplicative gr",
    "content": "In mathematics, the circle group, denoted by \n  \n    \n      \n        \n          T\n        \n      \n    \n    {\\displaystyle \\mathbb {T} }\n  \n or ⁠\n  \n    \n      \n        \n          \n            S\n          \n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {S} ^{1}}\n  \n⁠, is the multiplicative group of all complex numbers with absolute value 1, that is, the unit circle in the complex plane or simply the unit complex numbers\n\n  \n    \n      \n        \n          T\n        \n        =\n        {\n        z\n        ∈\n        \n          C\n        \n        :\n        \n          |\n        \n        z\n        \n          |\n        \n        =\n        1\n        }\n        .\n      \n    \n    {\\displaystyle \\mathbb {T} =\\{z\\in \\mathbb {C} :|z|=1\\}.}\n  \n\nThe circle group forms a subgroup of ⁠\n  \n    \n      \n        \n          \n            C\n          \n          \n            ×\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {C} ^{\\times }}\n  \n⁠, the multiplicative group of all nonzero complex numbers. Since \n  \n    \n      \n        \n          \n            C\n          \n          \n            ×\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {C} ^{\\times }}\n  \n is abelian, it follows that \n  \n    \n      \n        \n          T\n        \n      \n    \n    {\\displaystyle \\mathbb {T} }\n  \n is as well.\nA unit complex number in the circle group represents a rotation of the complex plane about the origin and can be parametrized by the angle measure ⁠\n  \n    \n      \n        θ\n      \n    \n    {\\displaystyle \\theta }\n  \n⁠:\n\n  \n    \n      \n        θ\n        ↦\n        z\n        =\n        \n          e\n          \n            i\n            θ\n          \n        \n        =\n        cos\n        ⁡\n        θ\n        +\n        i\n        sin\n        ⁡\n        θ\n        .\n      \n    \n    {\\displaystyle \\theta \\mapsto z=e^{i\\theta }=\\cos \\theta +i\\sin \\theta .}\n  \n\nThis is the exponential map for the circle group.\nThe circle group plays a central role in Pontryagin duality and in the theory of Lie groups.\nThe notation \n  \n    \n      \n        \n          T\n        \n      \n    \n    {\\displaystyle \\mathbb {T} }\n  \n for the circle group stems from the fact that, with the standard topology (see below), the circle group is a 1-torus. More generally, \n  \n    \n      \n        \n          \n            T\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {T} ^{n}}\n  \n (the direct product of \n  \n    \n      \n        \n          T\n        \n      \n    \n    {\\displaystyle \\mathbb {T} }\n  \n with itself \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n times) is geometrically an \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n-torus.\nThe circle group is isomorphic to the special orthogonal group ⁠\n  \n    \n      \n        \n          S\n          O\n        \n        (\n        2\n        )\n      \n    \n    {\\displaystyle \\mathrm {SO} (2)}\n  \n⁠.\n\nElementary introduction\nOne way to think about the circle group is that it describes how to add angles, where only angles between 0° and 360° or \n  \n    \n      \n        ∈\n        [\n        0\n        ,\n        2\n        π\n        )\n      \n    \n    {\\displaystyle \\in [0,2\\pi )}\n  \n or \n  \n    \n      \n        ∈\n        (\n        −\n        π\n        ,\n        +\n        π\n        ]\n      \n    \n    {\\displaystyle \\in (-\\pi ,+\\pi ]}\n  \n are permitted. For example, the diagram illustrates how to add 150° to 270°. The answer is 150° + 270° = 420°, but when thinking in terms of the circle group, we may \"forget\" the fact that we have wrapped once around the circle. Therefore, we adjust our answer by 360°, which gives 420° ≡ 60° (mod 360°).\nAnother description is in terms of ordinary (real) addition, where only numbers between 0 and 1 are allowed (with 1 corresponding to a full rotation: 360° or ⁠\n  \n    \n      \n        2\n        π\n      \n    \n    {\\displaystyle 2\\pi }\n  \n⁠), i.e. the real numbers modulo the integers: ⁠\n  \n    \n      \n        \n          T\n        \n        ≅\n        \n          R\n        \n        \n          /\n        \n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {T} \\cong \\mathbb {R} /\\mathbb {Z} }\n  \n⁠. This can be achieved by throwing away the digits occurring before the decimal point. For example, when we work out 0.4166... + 0.75, the answer is 1.1666..., but we may throw away the leading 1, so the answer (in the circle group) is just ⁠\n  \n    \n      \n        0.1\n        \n          \n            \n              6\n              ¯\n            \n          \n        \n        ≡\n        1.1\n        \n          \n            \n              6\n              ¯\n            \n          \n        \n        ≡\n        −\n        0.8\n        \n          \n            \n              3\n              ¯\n            \n          \n        \n        \n        (\n        \n          mod\n        \n        \n        \n          Z\n        \n        )\n      \n    \n    {\\displaystyle 0.1{\\bar {6}}\\equiv 1.1{\\bar {6}}\\equiv -0.8{\\bar {3}}\\;({\\tex",
    "links": [
      "1",
      "Abelian group",
      "Abelian variety",
      "Absolute value",
      "Additive group",
      "Adjoint representation",
      "Affine Lie algebra",
      "Algebraic group",
      "Algebraic structure",
      "Alternating group",
      "Analytic function",
      "Angle measure",
      "Arithmetic group",
      "Armand Borel",
      "Axiom of choice",
      "Borel–Weil–Bott theorem",
      "Cardinality of the continuum",
      "Cartan subalgebra",
      "Cauchy's theorem (group theory)",
      "Character (mathematics)",
      "Character group",
      "Circle (disambiguation)",
      "Classical group",
      "Classification of finite simple groups",
      "Claude Chevalley",
      "Closed set",
      "Closed subset",
      "Compact Lie algebra",
      "Compact space",
      "Completeness (topology)",
      "Complex conjugate",
      "Complex number",
      "Complex plane",
      "Complexification (Lie group)",
      "Conformal group",
      "Conjugate representation",
      "Connected space",
      "Continuous function (topology)",
      "Continuous group",
      "Cyclic group",
      "Determinant",
      "Diffeomorphism",
      "Dihedral group",
      "Direct limit",
      "Direct product of groups",
      "Direct sum of abelian groups",
      "Direct sum of groups",
      "Discrete group",
      "Divisible group",
      "Doi (identifier)"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Lie groups",
      "Category:Pages that use a deprecated format of the math tags",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Classification of finite simple groups": {
    "title": "Classification of finite simple groups",
    "url": "https://en.wikipedia.org/wiki/Classification_of_finite_simple_groups",
    "summary": "In mathematics, the classification of finite simple groups (popularly called the enormous theorem) is a result of group theory stating that every finite simple group is either cyclic, or alternating, or belongs to a broad infinite class called the groups of Lie type, or else it is one of twenty-six exceptions, called sporadic (the Tits group is sometimes regarded as a sporadic group because it is not strictly a group of Lie type, in which case there would be 27 sporadic groups). The proof consists of tens of thousands of pages in several hundred journal articles written by about 100 authors, published mostly between 1955 and 2004. \nSimple groups can be seen as the basic building blocks of all finite groups, reminiscent of the way the prime numbers are the basic building blocks of the natural numbers. The Jordan–Hölder theorem is a more precise way of stating this fact about finite groups. However, a significant difference from  integer factorization is that such \"building blocks\" do no",
    "content": "In mathematics, the classification of finite simple groups (popularly called the enormous theorem) is a result of group theory stating that every finite simple group is either cyclic, or alternating, or belongs to a broad infinite class called the groups of Lie type, or else it is one of twenty-six exceptions, called sporadic (the Tits group is sometimes regarded as a sporadic group because it is not strictly a group of Lie type, in which case there would be 27 sporadic groups). The proof consists of tens of thousands of pages in several hundred journal articles written by about 100 authors, published mostly between 1955 and 2004. \nSimple groups can be seen as the basic building blocks of all finite groups, reminiscent of the way the prime numbers are the basic building blocks of the natural numbers. The Jordan–Hölder theorem is a more precise way of stating this fact about finite groups. However, a significant difference from  integer factorization is that such \"building blocks\" do not necessarily determine a unique group, since there might be many non-isomorphic groups with the same composition series or, put in another way, the extension problem does not have a unique solution.\nDaniel Gorenstein (1923–1992), Richard Lyons, and Ronald Solomon are gradually publishing a simplified and revised version of the proof.\n\nStatement of the classification theorem\nThe classification theorem has applications in many branches of mathematics, as questions about the structure of finite groups (and their action on other mathematical objects) can sometimes be reduced to questions about finite simple groups. Thanks to the classification theorem, such questions can sometimes be answered by checking each family of simple groups and each sporadic group.\nDaniel Gorenstein announced in 1983 that the finite simple groups had all been classified, but this was premature as he had been misinformed about the proof of the classification of quasithin groups. The completed proof of the classification was announced by Aschbacher (2004) after Aschbacher and Smith published a 1221-page proof for the missing quasithin case.\n\nOverview of the proof of the classification theorem\nGorenstein (1982, 1983) wrote two volumes outlining the low rank and odd characteristic part of the proof, and Michael Aschbacher, Richard Lyons, and Stephen D. Smith et al. (2011)\nwrote a 3rd volume covering the remaining characteristic 2 case. The proof can be broken up into several major pieces as follows:\n\nGroups of small 2-rank\nThe simple groups of low 2-rank are mostly groups of Lie type of small rank over fields of odd characteristic, together with five alternating and seven characteristic 2 type and nine sporadic groups.\nThe simple groups of small 2-rank include:\n\nGroups of 2-rank 0, in other words groups of odd order, which are all solvable by the Feit–Thompson theorem.\nGroups of 2-rank 1. The Sylow 2-subgroups are either cyclic, which is easy to handle using the transfer map, or generalized quaternion, which are handled with the Brauer–Suzuki theorem: in particular there are no simple groups of 2-rank 1 except for the cyclic group of order two.\nGroups of 2-rank 2. Alperin showed that the Sylow subgroup must be dihedral, quasidihedral, wreathed, or a Sylow 2-subgroup of U3(4). The first case was done by the Gorenstein–Walter theorem which showed that the only simple groups are isomorphic to L2(q) for q odd or A7, the second and third cases were done by the Alperin–Brauer–Gorenstein theorem which implies that the only simple groups are isomorphic to L3(q) or U3(q) for q odd or M11, and the last case was done by Lyons who showed that U3(4) is the only simple possibility.\nGroups of sectional 2-rank at most 4, classified by the Gorenstein–Harada theorem.\nThe classification of groups of small 2-rank, especially ranks at most 2, makes heavy use of ordinary and modular character theory, which is almost never directly used elsewhere in the classification.\nAll groups not of small 2 rank can be split into two major classes: groups of component type and groups of characteristic 2 type. This is because if a group has sectional 2-rank at least 5 then MacWilliams showed that its Sylow 2-subgroups are connected, and the balance theorem implies that any simple group with connected Sylow 2-subgroups is either of component type or characteristic 2 type. (For groups of low 2-rank the proof of this breaks down, because theorems such as the signalizer functor theorem only work for groups with elementary abelian subgroups of rank at least 3.)\n\nGroups of component type\nA group is said to be of component type if for some centralizer C of an involution, C/O(C) has a component (where O(C) is the core of C, the maximal normal subgroup of odd order). These are more or less the groups of Lie type of odd characteristic of large rank, and alternating groups, together with some sporadic groups. A major step in this case is to eliminate the obstruction of the core of an involution. This is a",
    "links": [
      "2-generated core",
      "ATLAS of Finite Groups",
      "Abelian group",
      "Abelian variety",
      "Academic Press",
      "Additive group",
      "Algebraic group",
      "Algebraic structure",
      "Alperin–Brauer–Gorenstein theorem",
      "Alternating group",
      "Alternating groups",
      "American Mathematical Society",
      "Arithmetic group",
      "Atlas of Finite Groups",
      "B-theorem",
      "BN-pair",
      "BN pair",
      "B conjecture",
      "Baby monster group",
      "Balance theorem",
      "Brauer–Fowler theorem",
      "Brauer–Suzuki theorem",
      "Brauer–Suzuki–Wall theorem",
      "Bull. London Math. Soc.",
      "Burnside's theorem",
      "CA group",
      "CN group",
      "Cauchy's theorem (group theory)",
      "Cheryl Praeger",
      "Chevalley groups",
      "Circle group",
      "Classical involution theorem",
      "Compact Lie group",
      "Component theorem",
      "Composition series",
      "Conformal group",
      "Continuous group",
      "Conway groups",
      "Coq (software)",
      "Cyclic group",
      "Daniel Gorenstein",
      "Diffeomorphism",
      "Dihedral group",
      "Direct product of groups",
      "Direct sum of groups",
      "Discrete group",
      "Doi (identifier)",
      "Dynkin diagram",
      "E6 (mathematics)",
      "E7 (mathematics)"
    ],
    "categories": [
      "Category:2004 in science",
      "Category:All articles containing potentially dated statements",
      "Category:Articles containing potentially dated statements from 2023",
      "Category:Articles with short description",
      "Category:Finite groups",
      "Category:Group theory",
      "Category:History of mathematics",
      "Category:Mathematical classification systems",
      "Category:Short description is different from Wikidata",
      "Category:Sporadic groups"
    ]
  },
  "Cardinal number": {
    "title": "Cardinal number",
    "url": "https://en.wikipedia.org/wiki/Cardinal_number",
    "summary": "In mathematics, a cardinal number, or cardinal for short, is what is commonly called the number of elements of a set. In the case of a finite set, its cardinal number, or cardinality is therefore a natural number. For dealing with the case of infinite sets, the infinite cardinal numbers have been introduced, which are often denoted with the Hebrew letter \n  \n    \n      \n        ℵ\n      \n    \n    {\\displaystyle \\aleph }\n  \n (aleph) marked with subscript indicating their rank among the infinite cardinals.\nCardinality is defined in terms of bijective functions. Two sets have the same cardinality if, and only if, there is a one-to-one correspondence (bijection) between the elements of the two sets. In the case of finite sets, this agrees with the intuitive notion of number of elements. In the case of infinite sets, the behavior is more complex. A fundamental theorem due to Georg Cantor shows that it is possible for two infinite sets to have different cardinalities, and in particular the ca",
    "content": "In mathematics, a cardinal number, or cardinal for short, is what is commonly called the number of elements of a set. In the case of a finite set, its cardinal number, or cardinality is therefore a natural number. For dealing with the case of infinite sets, the infinite cardinal numbers have been introduced, which are often denoted with the Hebrew letter \n  \n    \n      \n        ℵ\n      \n    \n    {\\displaystyle \\aleph }\n  \n (aleph) marked with subscript indicating their rank among the infinite cardinals.\nCardinality is defined in terms of bijective functions. Two sets have the same cardinality if, and only if, there is a one-to-one correspondence (bijection) between the elements of the two sets. In the case of finite sets, this agrees with the intuitive notion of number of elements. In the case of infinite sets, the behavior is more complex. A fundamental theorem due to Georg Cantor shows that it is possible for two infinite sets to have different cardinalities, and in particular the cardinality of the set of real numbers is greater than the cardinality of the set of natural numbers. It is also possible for a proper subset of an infinite set to have the same cardinality as the original set—something that cannot happen with proper subsets of finite sets.\nThere is a transfinite sequence of cardinal numbers:\n\n  \n    \n      \n        0\n        ,\n        1\n        ,\n        2\n        ,\n        3\n        ,\n        …\n        ,\n        n\n        ,\n        …\n        ;\n        \n          ℵ\n          \n            0\n          \n        \n        ,\n        \n          ℵ\n          \n            1\n          \n        \n        ,\n        \n          ℵ\n          \n            2\n          \n        \n        ,\n        …\n        ,\n        \n          ℵ\n          \n            α\n          \n        \n        ,\n        …\n        .\n         \n      \n    \n    {\\displaystyle 0,1,2,3,\\ldots ,n,\\ldots ;\\aleph _{0},\\aleph _{1},\\aleph _{2},\\ldots ,\\aleph _{\\alpha },\\ldots .\\ }\n  \n\nThis sequence starts with the natural numbers including zero (finite cardinals), which are followed by the aleph numbers. The aleph numbers are indexed by ordinal numbers. If the axiom of choice is true, this transfinite sequence includes every cardinal number. If the axiom of choice is not true (see Axiom of choice § Independence), there are infinite cardinals that are not aleph numbers.\nCardinality is studied for its own sake as part of set theory. It is also a tool used in branches of mathematics including model theory, combinatorics, abstract algebra and mathematical analysis. In category theory, the cardinal numbers form a skeleton of the category of sets.\n\nHistory\nThe notion of cardinality, as now understood, was formulated by Georg Cantor, the originator of set theory, in 1874–1884. Cardinality can be used to compare an aspect of finite sets. For example, the sets {1,2,3} and {4,5,6} are not equal, but have the same cardinality, namely three. This is established by the existence of a bijection (i.e., a one-to-one correspondence) between the two sets, such as the correspondence {1→4, 2→5, 3→6}.\nCantor applied his concept of bijection to infinite sets (for example the set of natural numbers N = {0, 1, 2, 3, ...}). Thus, he called all sets having a bijection with N denumerable (countably infinite) sets, which all share the same cardinal number. This cardinal number is called \n  \n    \n      \n        \n          ℵ\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\aleph _{0}}\n  \n, aleph-null. He called the cardinal numbers of infinite sets transfinite cardinal numbers.\nCantor proved that any unbounded subset of N has the same cardinality as N, even though this might appear to run contrary to intuition. He also proved that the set of all ordered pairs of natural numbers is denumerable; this implies that the set of all rational numbers is also denumerable, since every rational can be represented by a pair of integers. He later proved that the set of all real algebraic numbers is also denumerable. Each real algebraic number z may be encoded as a finite sequence of integers, which are the coefficients in the polynomial equation of which it is a solution, i.e. the ordered n-tuple (a0, a1, ..., an), ai ∈ Z together with a pair of rationals (b0, b1) such that z is the unique root of the polynomial with coefficients (a0, a1, ..., an) that lies in the interval (b0, b1).\nIn his 1874 paper \"On a Property of the Collection of All Real Algebraic Numbers\", Cantor proved that there exist higher-order cardinal numbers, by showing that the set of real numbers has cardinality greater than that of N. His proof used an argument with nested intervals, but in an 1891 paper, he proved the same result using his ingenious and much simpler diagonal argument. The new cardinal number of the set of real numbers is called the cardinality of the continuum and Cantor used the symbol \n  \n    \n      \n        \n          \n            c\n          \n        \n      \n    \n    {\\displaysty",
    "links": [
      "Abraham Fraenkel",
      "Absorbing element",
      "Abstract algebra",
      "Abstract logic",
      "Ackermann set theory",
      "Aleph-null",
      "Aleph (Hebrew)",
      "Aleph null",
      "Aleph number",
      "Algebra of physical space",
      "Algebraic logic",
      "Algebraic number",
      "Almost",
      "Alphabet (formal languages)",
      "Alternative set theory",
      "Amorphous set",
      "Argument",
      "Arithmetic",
      "Arity",
      "Associative",
      "Atomic formula",
      "Atomic sentence",
      "Automata theory",
      "Automated theorem proving",
      "Axiom",
      "Axiom of adjunction",
      "Axiom of choice",
      "Axiom of constructibility",
      "Axiom of countable choice",
      "Axiom of dependent choice",
      "Axiom of determinacy",
      "Axiom of extensionality",
      "Axiom of global choice",
      "Axiom of infinity",
      "Axiom of limitation of size",
      "Axiom of pairing",
      "Axiom of power set",
      "Axiom of projective determinacy",
      "Axiom of regularity",
      "Axiom of union",
      "Axiom schema",
      "Axiom schema of replacement",
      "Axiom schema of specification",
      "Axiomatic set theory",
      "Axiomatic system",
      "Axiomatization of Boolean algebras",
      "Banach–Tarski paradox",
      "Bertrand Russell",
      "Beth number",
      "Bicomplex number"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1: long volume value",
      "Category:Cardinal numbers",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Cayley table": {
    "title": "Cayley table",
    "url": "https://en.wikipedia.org/wiki/Cayley_table",
    "summary": "Named after the 19th-century British mathematician Arthur Cayley, a Cayley table describes the structure of a finite group by arranging all the possible products of all the group's elements in a square table reminiscent of an addition or multiplication table.  Many properties of a group – such as whether or not it is abelian, which elements are inverses of which elements, and the size and contents of the group's center – can be discovered from its Cayley table.\nA simple example of a Cayley table is the one for the group {1, −1} under ordinary multiplication:",
    "content": "Named after the 19th-century British mathematician Arthur Cayley, a Cayley table describes the structure of a finite group by arranging all the possible products of all the group's elements in a square table reminiscent of an addition or multiplication table.  Many properties of a group – such as whether or not it is abelian, which elements are inverses of which elements, and the size and contents of the group's center – can be discovered from its Cayley table.\nA simple example of a Cayley table is the one for the group {1, −1} under ordinary multiplication:\n\nHistory\nCayley tables were first presented in Cayley's 1854 paper, \"On The Theory of Groups, as depending on the symbolic equation θ n = 1\".  In that paper they were referred to simply as tables, and were merely illustrative – they came to be known as Cayley tables later on, in honour of their creator.\n\nStructure and layout\nBecause many Cayley tables describe groups that are not abelian, the product ab with respect to the group's binary operation is not guaranteed to be equal to the product ba for all a and b in the group.  In order to avoid confusion, the convention is that the factor that labels the row (termed nearer factor by Cayley) comes first, and that the factor that labels the column (or further factor) is second. For example, the intersection of row a and column b is ab and not ba, as in the following example:\n\nProperties and uses\nCommutativity\nThe Cayley table tells us whether a group is abelian.  Because the group operation of an abelian group is commutative, a group is abelian if and only if its Cayley table's values are symmetric along its diagonal axis.  The group {1, −1} above and the cyclic group of order 3 under ordinary multiplication are both examples of abelian groups, and inspection of the symmetry of their Cayley tables verifies this.  In contrast, the smallest non-abelian group, the dihedral group of order 6, does not have a symmetric Cayley table.\n\nAssociativity\nBecause associativity is taken as an axiom when dealing with groups, it is often taken for granted when dealing with Cayley tables.  However, Cayley tables can also be used to characterize the operation of a quasigroup, which does not assume associativity as an axiom (indeed, Cayley tables can be used to characterize the operation of any finite magma).  Unfortunately, it is not generally possible to determine whether or not an operation is associative simply by glancing at its Cayley table, as it is with commutativity. This is because associativity depends on a 3 term equation, \n  \n    \n      \n        (\n        a\n        b\n        )\n        c\n        =\n        a\n        (\n        b\n        c\n        )\n      \n    \n    {\\displaystyle (ab)c=a(bc)}\n  \n, while the Cayley table shows 2-term products. However, Light's associativity test can determine associativity with less effort than brute force.\n\nPermutations\nBecause the cancellation property holds for groups (and indeed even quasigroups), no row or column of a Cayley table may contain the same element twice.  Thus each row and column of the table is a permutation of all the elements in the group.  This greatly restricts which Cayley tables could conceivably define a valid group operation.\nTo see why a row or column cannot contain the same element more than once, let a, x, and y all be elements of a group, with x and y distinct.  Then in the row representing the element a, the column corresponding to x contains the product ax, and similarly the column corresponding to y contains the product ay.  If these two products were equal – that is to say, row a contained the same element twice, our hypothesis – then ax would equal ay.  But because the cancellation law holds, we can conclude that if ax = ay, then x = y, a contradiction.  Therefore, our hypothesis is incorrect, and a row cannot contain the same element twice.  Exactly the same argument suffices to prove the column case, and so we conclude that each row and column contains no element more than once.  Because the group is finite, the pigeonhole principle guarantees that each element of the group will be represented in each row and in each column exactly once. Thus, the Cayley table of a group is an example of a latin square. An alternative and more succinct proof follows from the cancellation property. This property implies that for each x in the group, the one variable function of y f(x,y)= xy must be a one-to-one map. The result follows from the fact that one-to-one maps on finite sets are permutations.\n\nPermutation matrix generation\nThe standard form of a Cayley table has the order of the elements in the rows the same as the order in the columns. Another form is to arrange the elements of the columns so that the nth column corresponds to the inverse of the element in the nth row.  In our example of D3, we need only switch the last two columns, since f and d are the only elements that are not their own inverses, but instead inverses of each other.\n\nThis particular exam",
    "links": [
      "Abelian group",
      "Addition",
      "American Journal of Mathematics",
      "Arthur Cayley",
      "Associativity",
      "Binary operation",
      "Cancellation property",
      "Center (group theory)",
      "Commutative",
      "Dihedral group of order 6",
      "Finite group",
      "If and only if",
      "Inverse element",
      "Kronecker delta",
      "Latin square",
      "Light's associativity test",
      "Magma (algebra)",
      "Mathematician",
      "Multiplication",
      "Multiplication table",
      "Permutation",
      "Permutation group",
      "Permutation matrix",
      "Pigeonhole principle",
      "Quasigroup",
      "Reductio ad absurdum",
      "Semigroup",
      "Sudoku",
      "Symmetric",
      "United Kingdom"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Finite groups",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Cubic formula": {
    "title": "Cubic equation",
    "url": "https://en.wikipedia.org/wiki/Cubic_equation",
    "summary": "In algebra, a cubic equation in one variable is an equation of the form\n\n  \n    \n      \n        a\n        \n          x\n          \n            3\n          \n        \n        +\n        b\n        \n          x\n          \n            2\n          \n        \n        +\n        c\n        x\n        +\n        d\n        =\n        0\n      \n    \n    {\\displaystyle ax^{3}+bx^{2}+cx+d=0}\n  \n\nin which a is not zero.\nThe solutions of this equation are called roots of the cubic function defined by the left-hand side of the equation. If all of the coefficients a, b, c, and d of the cubic equation are real numbers, then it has at least one real root (this is true for all odd-degree polynomial functions). All of the roots of the cubic equation can be found by the following means:\n\nalgebraically: more precisely, they can be expressed by a cubic formula involving the four coefficients, the four basic arithmetic operations, square roots, and cube roots. (This is also true of quadratic (second-degree) and quartic",
    "content": "In algebra, a cubic equation in one variable is an equation of the form\n\n  \n    \n      \n        a\n        \n          x\n          \n            3\n          \n        \n        +\n        b\n        \n          x\n          \n            2\n          \n        \n        +\n        c\n        x\n        +\n        d\n        =\n        0\n      \n    \n    {\\displaystyle ax^{3}+bx^{2}+cx+d=0}\n  \n\nin which a is not zero.\nThe solutions of this equation are called roots of the cubic function defined by the left-hand side of the equation. If all of the coefficients a, b, c, and d of the cubic equation are real numbers, then it has at least one real root (this is true for all odd-degree polynomial functions). All of the roots of the cubic equation can be found by the following means:\n\nalgebraically: more precisely, they can be expressed by a cubic formula involving the four coefficients, the four basic arithmetic operations, square roots, and cube roots. (This is also true of quadratic (second-degree) and quartic (fourth-degree) equations, but not for higher-degree equations, by the Abel–Ruffini theorem.)\ngeometrically: using Omar Kahyyam's method.\ntrigonometrically\nnumerical approximations of the roots can be found using root-finding algorithms such as Newton's method.\nThe coefficients do not need to be real numbers. Much of what is covered below is valid for coefficients in any field with characteristic other than 2 and 3. The solutions of the cubic equation do not necessarily belong to the same field as the coefficients. For example, some cubic equations with rational coefficients have roots that are irrational (and even non-real) complex numbers.\n\nHistory\nCubic equations were known to the ancient Babylonians, Greeks, Chinese, Indians, and Egyptians. Babylonian (20th to 16th centuries BC) cuneiform tablets have been found with tables for calculating cubes and cube roots. The Babylonians could have used the tables to solve cubic equations, but no evidence exists to confirm that they did. The problem of doubling the cube involves the simplest and oldest studied cubic equation, and one for which the ancient Egyptians did not believe a solution existed. In the 5th century BC, Hippocrates reduced this problem to that of finding two mean proportionals between one line and another of twice its length, but could not solve this with a compass and straightedge construction, a task which is now known to be impossible. Methods for solving cubic equations appear in The Nine Chapters on the Mathematical Art, a Chinese mathematical text compiled around the 2nd century BC and commented on by Liu Hui in the 3rd century. \nIn the 3rd century AD, the Greek mathematician Diophantus found integer or rational solutions for some bivariate cubic equations (Diophantine equations). Hippocrates, Menaechmus and Archimedes are believed to have come close to solving the problem of doubling the cube using intersecting conic sections, though historians such as Reviel Netz dispute whether the Greeks were thinking about cubic equations or just problems that can lead to cubic equations. Some others like T. L. Heath, who translated all of Archimedes's works, disagree, putting forward evidence that Archimedes really solved cubic equations using intersections of two conics, but also discussed the conditions where the roots are 0, 1 or 2. \n\nIn the 7th century, the Tang dynasty astronomer mathematician Wang Xiaotong in his mathematical treatise titled Jigu Suanjing systematically established and solved numerically 25 cubic equations of the form x3 + px2 + qx = N, 23 of them with p, q ≠ 0, and two of them with q = 0.\n\nIn the 11th century, the Persian poet-mathematician, Omar Khayyam (1048–1131), made significant progress in the theory of cubic equations. In an early paper, he discovered that a cubic equation can have more than one solution and stated that it cannot be solved using compass and straightedge constructions. He also found a geometric solution. In his later work, the Treatise on Demonstration of Problems of Algebra, he wrote a complete classification of cubic equations with general geometric solutions found by means of intersecting conic sections. Khayyam made an attempt to come up with an algebraic formula for extracting cubic roots. He wrote: “We have tried to express these roots by algebra but have failed. It may be, however, that men who come after us will succeed.”\nIn the 12th century, the Indian mathematician Bhaskara II attempted the solution of cubic equations without general success. However, he gave one example of a cubic equation: x3 + 12x = 6x2 + 35. In the 12th century, another Persian mathematician, Sharaf al-Dīn al-Tūsī (1135–1213), wrote the Al-Muʿādalāt (Treatise on Equations), which dealt with eight types of cubic equations with positive solutions and five types of cubic equations which may not have positive solutions. He used what would later be known as the Horner–Ruffini method to numerically approximate the root of a cubic equation. He also",
    "links": [
      "Abel–Ruffini theorem",
      "Abscissa",
      "Algebra",
      "Algebraic expression",
      "Algebraically closed field",
      "American Mathematical Monthly",
      "Analytic function",
      "Analytical chemistry",
      "Angle trisection",
      "Arccosine",
      "Archimedes",
      "Area",
      "Arithmetic operations",
      "Ars Magna (Gerolamo Cardano)",
      "Babylonia",
      "Babylonian numerals",
      "Barry Mazur",
      "Bartel Leendert van der Waerden",
      "Bibhutibhushan Datta",
      "Binomial (polynomial)",
      "Birkhäuser",
      "Bivariate polynomial",
      "Buffer solution",
      "Bézier curve",
      "Cartesian plane",
      "Casus irreducibilis",
      "Cauchy–Euler equation",
      "Change of variable",
      "Characteristic (algebra)",
      "Characteristic equation (calculus)",
      "Characteristic polynomial",
      "Charlot equation",
      "Chinese mathematics",
      "Circumradius",
      "Coefficients",
      "Common multiple",
      "Compass-and-straightedge construction",
      "Compass and straightedge construction",
      "Complex conjugate",
      "Complex number",
      "Complex plane",
      "Conic section",
      "Conic sections",
      "Constant function",
      "Coprime integers",
      "Cosine",
      "Critical point (mathematics)",
      "Cube root",
      "Cubic equations of state",
      "Cubic function"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1 errors: ISBN date",
      "Category:Elementary algebra",
      "Category:Equations",
      "Category:Polynomials",
      "Category:Short description is different from Wikidata",
      "Category:Wikipedia articles needing clarification from September 2019"
    ]
  },
  "Fundamental theorem of algebra": {
    "title": "Fundamental theorem of algebra",
    "url": "https://en.wikipedia.org/wiki/Fundamental_theorem_of_algebra",
    "summary": "The fundamental theorem of algebra, also called d'Alembert's theorem or the d'Alembert–Gauss theorem, states that every non-constant single-variable polynomial with complex coefficients has at least one complex root. This includes polynomials with real coefficients, since every real number is a complex number with its imaginary part equal to zero.\nEquivalently (by definition), the theorem states that the field of complex numbers is algebraically closed.\nThe theorem is also stated as follows: every non-zero, single-variable, degree n polynomial with complex coefficients has, counted with multiplicity, exactly n complex roots. The equivalence of the two statements can be proven through the use of successive polynomial division.\nDespite its name, it is not fundamental for modern algebra; it was named when algebra was synonymous with the theory of equations.",
    "content": "The fundamental theorem of algebra, also called d'Alembert's theorem or the d'Alembert–Gauss theorem, states that every non-constant single-variable polynomial with complex coefficients has at least one complex root. This includes polynomials with real coefficients, since every real number is a complex number with its imaginary part equal to zero.\nEquivalently (by definition), the theorem states that the field of complex numbers is algebraically closed.\nThe theorem is also stated as follows: every non-zero, single-variable, degree n polynomial with complex coefficients has, counted with multiplicity, exactly n complex roots. The equivalence of the two statements can be proven through the use of successive polynomial division.\nDespite its name, it is not fundamental for modern algebra; it was named when algebra was synonymous with the theory of equations.\n\nHistory\nPeter Roth, in his book Arithmetica Philosophica (published in 1608, at Nürnberg, by Johann Lantzenberger), wrote that a polynomial equation of degree n (with real coefficients) may have n solutions. Albert Girard, in his book L'invention nouvelle en l'Algèbre (published in 1629), asserted that a polynomial equation of degree n has n solutions, but he did not state that they had to be real numbers. Furthermore, he added that his assertion holds \"unless the equation is incomplete\", where \"incomplete\" means that at least one coefficient is equal to 0. However, when he explains in detail what he means, it is clear that he actually believes that his assertion is always true; for instance, he shows that the equation \n  \n    \n      \n        \n          x\n          \n            4\n          \n        \n        =\n        4\n        x\n        −\n        3\n        ,\n      \n    \n    {\\displaystyle x^{4}=4x-3,}\n  \n although incomplete, has four solutions (counting multiplicities): 1 (twice), \n  \n    \n      \n        −\n        1\n        +\n        i\n        \n          \n            2\n          \n        \n        ,\n      \n    \n    {\\displaystyle -1+i{\\sqrt {2}},}\n  \n and \n  \n    \n      \n        −\n        1\n        −\n        i\n        \n          \n            2\n          \n        \n        .\n      \n    \n    {\\displaystyle -1-i{\\sqrt {2}}.}\n  \n\nAs will be mentioned again below, it follows from the fundamental theorem of algebra that every non-constant polynomial with real coefficients can be written as a product of polynomials with real coefficients whose degrees are either 1 or 2. However, in 1702 Leibniz erroneously said that no polynomial of the type x4 + a4 (with a real and distinct from 0) can be written in such a way. Later, Nikolaus Bernoulli made the same assertion concerning the polynomial x4 − 4x3 + 2x2 + 4x + 4, but he got a letter from Euler in 1742 in which it was shown that this polynomial is equal to\n\n  \n    \n      \n        \n          (\n          \n            \n              x\n              \n                2\n              \n            \n            −\n            (\n            2\n            +\n            α\n            )\n            x\n            +\n            1\n            +\n            \n              \n                7\n              \n            \n            +\n            α\n          \n          )\n        \n        \n          (\n          \n            \n              x\n              \n                2\n              \n            \n            −\n            (\n            2\n            −\n            α\n            )\n            x\n            +\n            1\n            +\n            \n              \n                7\n              \n            \n            −\n            α\n          \n          )\n        \n        ,\n      \n    \n    {\\displaystyle \\left(x^{2}-(2+\\alpha )x+1+{\\sqrt {7}}+\\alpha \\right)\\left(x^{2}-(2-\\alpha )x+1+{\\sqrt {7}}-\\alpha \\right),}\n  \n\nwith \n  \n    \n      \n        α\n        =\n        \n          \n            4\n            +\n            2\n            \n              \n                7\n              \n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\alpha ={\\sqrt {4+2{\\sqrt {7}}}}.}\n  \n\nEuler also pointed out that\n\n  \n    \n      \n        \n          x\n          \n            4\n          \n        \n        +\n        \n          a\n          \n            4\n          \n        \n        =\n        \n          (\n          \n            \n              x\n              \n                2\n              \n            \n            +\n            a\n            \n              \n                2\n              \n            \n            ⋅\n            x\n            +\n            \n              a\n              \n                2\n              \n            \n          \n          )\n        \n        \n          (\n          \n            \n              x\n              \n                2\n              \n            \n            −\n            a\n            \n              \n                2\n              \n            \n            ⋅\n            x\n            +\n            \n              a\n              \n                2\n              \n            \n          \n          )\n ",
    "links": [
      "A priori and a posteriori",
      "Abel–Ruffini theorem",
      "Albert Girard",
      "Alexander Ostrowski",
      "Algebraic closure",
      "Algebraic extension",
      "Algebraic function",
      "Algebraically closed field",
      "Analytic function",
      "Analytic proof",
      "Antiderivative",
      "ArXiv (identifier)",
      "Argument principle",
      "Augustin-Louis Cauchy",
      "Australian Mathematical Society",
      "Bartel Leendert van der Waerden",
      "Bulletin of the Belgian Mathematical Society",
      "Bézout's theorem",
      "Carl Friedrich Gauss",
      "Cauchy",
      "Cauchy's integral theorem",
      "Characteristic (algebra)",
      "Coefficient",
      "Compact set",
      "Complex conjugate",
      "Complex conjugate root theorem",
      "Complex number",
      "Constant polynomial",
      "Constant term",
      "Construction of the real numbers",
      "Constructive proof",
      "Constructivism (mathematics)",
      "Continuous function",
      "Corollary",
      "Countable choice",
      "Cours d'Analyse",
      "David Eugene Smith",
      "Degree of a polynomial",
      "Derivative",
      "Disc (mathematics)",
      "Disk (mathematics)",
      "Doi (identifier)",
      "Dover Publications",
      "Durand–Kerner method",
      "Edmund F. Robertson",
      "Eigenvalue",
      "Eilenberg–Niven theorem",
      "Elementary function (differential algebra)",
      "Elementary symmetric polynomial",
      "Entire function"
    ],
    "categories": [
      "Category:Articles containing proofs",
      "Category:Articles with short description",
      "Category:CS1: long volume value",
      "Category:CS1 errors: ISBN date",
      "Category:Field (mathematics)",
      "Category:Short description matches Wikidata",
      "Category:Theorems about polynomials",
      "Category:Theorems in complex analysis",
      "Category:Webarchive template wayback links",
      "Category:Wikisource templates with missing id"
    ]
  },
  "Galois theory": {
    "title": "Galois theory",
    "url": "https://en.wikipedia.org/wiki/Galois_theory",
    "summary": "In mathematics, Galois theory, originally introduced by Évariste Galois, provides a connection between field theory and group theory. This connection, the fundamental theorem of Galois theory, allows reducing certain problems in field theory to group theory, which makes them simpler and easier to understand.\nGalois introduced the subject for studying roots of polynomials. This allowed him to characterize the polynomial equations that are solvable by radicals in terms of properties of the permutation group of their roots—an equation is by definition solvable by radicals if its roots may be expressed by a formula involving only integers, nth roots, and the four basic arithmetic operations. This widely generalizes the Abel–Ruffini theorem, which asserts that a general polynomial of degree at least five cannot be solved by radicals. \nGalois theory has been used to solve classic problems including showing that two problems of antiquity cannot be solved as they were stated (doubling the cube",
    "content": "In mathematics, Galois theory, originally introduced by Évariste Galois, provides a connection between field theory and group theory. This connection, the fundamental theorem of Galois theory, allows reducing certain problems in field theory to group theory, which makes them simpler and easier to understand.\nGalois introduced the subject for studying roots of polynomials. This allowed him to characterize the polynomial equations that are solvable by radicals in terms of properties of the permutation group of their roots—an equation is by definition solvable by radicals if its roots may be expressed by a formula involving only integers, nth roots, and the four basic arithmetic operations. This widely generalizes the Abel–Ruffini theorem, which asserts that a general polynomial of degree at least five cannot be solved by radicals. \nGalois theory has been used to solve classic problems including showing that two problems of antiquity cannot be solved as they were stated (doubling the cube and trisecting the angle), and characterizing the regular polygons that are constructible (this characterization was previously given by Gauss but without the proof that the list of constructible polygons was complete; all known proofs that this characterization is complete require Galois theory).\nGalois' work was published by Joseph Liouville fourteen years after his death. The theory took longer to become popular among mathematicians and to be well understood.\nGalois theory has been generalized to Galois connections and Grothendieck's Galois theory.\n\nApplication to classical problems\nThe birth and development of Galois theory was caused by the following question, which was one of the main open mathematical questions until the beginning of 19th century:\n\nDoes there exist a formula for the roots of a fifth (or higher) degree polynomial equation in terms of the coefficients of the polynomial, using only the usual algebraic operations (addition, subtraction, multiplication, division) and application of radicals (square roots, cube roots, etc)?\nThe Abel–Ruffini theorem provides a counterexample proving that there are polynomial equations for which such a formula cannot exist. Galois' theory provides a much more complete answer to this question, by explaining why it is possible to solve some equations, including all those of degree four or lower, in the above manner, and why it is not possible for most equations of degree five or higher. Furthermore, it provides a means of determining whether a particular equation can be solved that is both conceptually clear and easily expressed as an algorithm.\nGalois' theory also gives a clear insight into questions concerning problems in compass and straightedge construction. It gives an elegant characterization of the ratios of lengths that can be constructed with this method. Using this, it becomes relatively easy to answer such classical problems of geometry as\n\nWhich regular polygons are constructible?\nWhy is it not possible to trisect every angle using a compass and a straightedge?\nWhy is doubling the cube not possible with the same method?\n\nHistory\nPre-history\nGalois' theory originated in the study of symmetric functions – the coefficients of a monic polynomial are (up to sign) the elementary symmetric polynomials in the roots. For instance, (x – a)(x – b) = x2 – (a + b)x + ab, where 1, a + b and ab are the elementary polynomials of degree 0, 1 and 2 in two variables.\nThis was first formalized by the 16th-century French mathematician François Viète, in Viète's formulas, for the case of positive real roots. In the opinion of the 18th-century British mathematician Charles Hutton, the expression of coefficients of a polynomial in terms of the roots (not only for positive roots) was first understood by the 17th-century French mathematician Albert Girard; Hutton writes:\n\n...[Girard was] the first person who understood the general doctrine of the formation of the coefficients of the powers from the sum of the roots and their products. He was the first who discovered the rules for summing the powers of the roots of any equation.\nIn this vein, the discriminant is a symmetric function in the roots that reflects properties of the roots – it is zero if and only if the polynomial has a multiple root, and for quadratic and cubic polynomials it is positive if and only if all roots are real and distinct, and negative if and only if there is a pair of distinct complex conjugate roots. See Discriminant § Low degrees for details.\nThe cubic was first partly solved by the 15–16th-century Italian mathematician Scipione del Ferro, who did not however publish his results; this method, though, only solved one type of cubic equation. This solution was then rediscovered independently in 1535 by Niccolò Fontana Tartaglia, who shared it with Gerolamo Cardano, asking him to not publish it. Cardano then extended this to numerous other cases, using similar arguments; see more details at Cardano's method. After the di",
    "links": [
      "Abel–Ruffini theorem",
      "Absolute Galois group",
      "Abstract algebra",
      "Albert Girard",
      "Algebraic closure",
      "Algebraic equation",
      "Algebraic geometry",
      "Algebraic number theory",
      "Algorithm",
      "Alternating group",
      "Angle trisection",
      "ArXiv (identifier)",
      "Arithmetic operations",
      "Ars Magna (Gerolamo Cardano)",
      "Arthur Cayley",
      "Artin–Schreier theory",
      "Automorphism",
      "Bartel Leendert van der Waerden",
      "Binomial theorem",
      "Cambridge University Press",
      "Camille Jordan",
      "Cayley's theorem",
      "Characteristic (algebra)",
      "Charles Hutton",
      "Coefficients",
      "Compass-and-straightedge construction",
      "Compass and straightedge",
      "Completing the square",
      "Complex numbers",
      "Composition series",
      "Constructible polygon",
      "Cubic equation",
      "Cyclic group",
      "Derivation (differential algebra)",
      "Derived algebraic geometry",
      "Differential Galois theory",
      "Discriminant",
      "Doi (identifier)",
      "Doubling the cube",
      "Elementary symmetric polynomial",
      "Emil Artin",
      "Encyclopedia of Mathematics",
      "Eugen Netto",
      "European Mathematical Society",
      "Factor group",
      "Field (mathematics)",
      "Field extension",
      "Finite field",
      "Fixed field",
      "François Viète"
    ],
    "categories": [
      "Category:All articles needing additional references",
      "Category:All articles with unsourced statements",
      "Category:Articles needing additional references from June 2023",
      "Category:Articles needing additional references from May 2025",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from January 2025",
      "Category:CS1 German-language sources (de)",
      "Category:CS1 Latin-language sources (la)",
      "Category:Commons category link from Wikidata",
      "Category:Galois theory"
    ]
  },
  "Abel's theorem": {
    "title": "Abel's theorem",
    "url": "https://en.wikipedia.org/wiki/Abel%27s_theorem",
    "summary": "In mathematics, Abel's theorem for power series relates a limit of a power series to the sum of its coefficients.  It is named after Norwegian mathematician Niels Henrik Abel, who proved it in 1826.",
    "content": "In mathematics, Abel's theorem for power series relates a limit of a power series to the sum of its coefficients.  It is named after Norwegian mathematician Niels Henrik Abel, who proved it in 1826.\n\nTheorem\nLet the Taylor series\n\n  \n    \n      \n        G\n        (\n        x\n        )\n        =\n        \n          ∑\n          \n            k\n            =\n            0\n          \n          \n            ∞\n          \n        \n        \n          a\n          \n            k\n          \n        \n        \n          x\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle G(x)=\\sum _{k=0}^{\\infty }a_{k}x^{k}}\n  \n\nbe a power series with real coefficients \n  \n    \n      \n        \n          a\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle a_{k}}\n  \n with radius of convergence \n  \n    \n      \n        1.\n      \n    \n    {\\displaystyle 1.}\n  \n  Suppose that the series \n\n  \n    \n      \n        \n          ∑\n          \n            k\n            =\n            0\n          \n          \n            ∞\n          \n        \n        \n          a\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle \\sum _{k=0}^{\\infty }a_{k}}\n  \n \nconverges. \nThen \n  \n    \n      \n        G\n        (\n        x\n        )\n      \n    \n    {\\displaystyle G(x)}\n  \n is continuous from the left at \n  \n    \n      \n        x\n        =\n        1\n        ,\n      \n    \n    {\\displaystyle x=1,}\n  \n that is,\n\n  \n    \n      \n        \n          lim\n          \n            x\n            →\n            \n              1\n              \n                −\n              \n            \n          \n        \n        G\n        (\n        x\n        )\n        =\n        \n          ∑\n          \n            k\n            =\n            0\n          \n          \n            ∞\n          \n        \n        \n          a\n          \n            k\n          \n        \n        .\n      \n    \n    {\\displaystyle \\lim _{x\\to 1^{-}}G(x)=\\sum _{k=0}^{\\infty }a_{k}.}\n  \n\nThe same theorem holds for complex power series \n\n  \n    \n      \n        G\n        (\n        z\n        )\n        =\n        \n          ∑\n          \n            k\n            =\n            0\n          \n          \n            ∞\n          \n        \n        \n          a\n          \n            k\n          \n        \n        \n          z\n          \n            k\n          \n        \n        ,\n      \n    \n    {\\displaystyle G(z)=\\sum _{k=0}^{\\infty }a_{k}z^{k},}\n  \n \nprovided that \n  \n    \n      \n        z\n        →\n        1\n      \n    \n    {\\displaystyle z\\to 1}\n  \n entirely within a single Stolz sector, that is, a region of the open unit disk where\n\n  \n    \n      \n        \n          |\n        \n        1\n        −\n        z\n        \n          |\n        \n        ≤\n        M\n        (\n        1\n        −\n        \n          |\n        \n        z\n        \n          |\n        \n        )\n      \n    \n    {\\displaystyle |1-z|\\leq M(1-|z|)}\n  \n\nfor some fixed finite \n  \n    \n      \n        M\n        >\n        1\n      \n    \n    {\\displaystyle M>1}\n  \n.  Without this restriction, the limit may fail to exist: for example, the power series\n\n  \n    \n      \n        \n          ∑\n          \n            n\n            >\n            0\n          \n        \n        \n          \n            \n              \n                z\n                \n                  \n                    3\n                    \n                      n\n                    \n                  \n                \n              \n              −\n              \n                z\n                \n                  2\n                  ⋅\n                  \n                    3\n                    \n                      n\n                    \n                  \n                \n              \n            \n            n\n          \n        \n      \n    \n    {\\displaystyle \\sum _{n>0}{\\frac {z^{3^{n}}-z^{2\\cdot 3^{n}}}{n}}}\n  \n\nconverges to \n  \n    \n      \n        0\n      \n    \n    {\\displaystyle 0}\n  \n at \n  \n    \n      \n        z\n        =\n        1\n        ,\n      \n    \n    {\\displaystyle z=1,}\n  \n but is unbounded near any point of the form \n  \n    \n      \n        \n          e\n          \n            π\n            i\n            \n              /\n            \n            \n              3\n              \n                n\n              \n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle e^{\\pi i/3^{n}},}\n  \n so the value at \n  \n    \n      \n        z\n        =\n        1\n      \n    \n    {\\displaystyle z=1}\n  \n is not the limit as \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n  \n tends to 1 in the whole open disk.\nNote that \n  \n    \n      \n        G\n        (\n        z\n        )\n      \n    \n    {\\displaystyle G(z)}\n  \n is continuous on the real closed interval \n  \n    \n      \n        [\n        0\n        ,\n        t\n        ]\n      \n    \n    {\\displaystyle [0,t]}\n  \n for \n  \n    \n      \n        t\n        <\n        1\n        ,\n      \n    \n    {\\displaystyle t<1,}\n  \n by virtue of the uniform convergence of the series ",
    "links": [
      "Abel's identity",
      "Abel's irreducibility theorem",
      "Abel's summation formula",
      "Abel–Jacobi map",
      "Abel–Ruffini theorem",
      "Algebraic curve",
      "Angle",
      "Binomial series",
      "Bounded function",
      "Closed interval",
      "Coefficient",
      "Compact space",
      "Complex number",
      "Continuous function",
      "Convergent series",
      "Converse (logic)",
      "Divergent series",
      "Encyclopedia of Mathematics",
      "Eric W. Weisstein",
      "European Mathematical Society",
      "Galton–Watson process",
      "Generating function",
      "ISBN (identifier)",
      "J. Reine Angew. Math.",
      "Lars Ahlfors",
      "Limit (mathematics)",
      "MathWorld",
      "Mathematics",
      "Nachbin resummation",
      "Niels Henrik Abel",
      "One-sided limit",
      "Open disk",
      "PlanetMath",
      "Power series",
      "Probability-generating function",
      "Radius of convergence",
      "Real number",
      "Sequence",
      "Summation by parts",
      "Tauberian theorems",
      "Taylor series",
      "Theorem",
      "Uniform convergence",
      "Unit disk",
      "Wikipedia:Citation needed",
      "Wikipedia:Citing sources",
      "Wikipedia:When to cite",
      "Wikipedia:WikiProject Reliability",
      "Help:Maintenance template removal"
    ],
    "categories": [
      "Category:All articles lacking in-text citations",
      "Category:All articles with unsourced statements",
      "Category:Articles lacking in-text citations from February 2013",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from May 2015",
      "Category:Niels Henrik Abel",
      "Category:Pages displaying short descriptions of redirect targets via Module:Annotated link",
      "Category:Series (mathematics)",
      "Category:Short description is different from Wikidata",
      "Category:Summability methods"
    ]
  },
  "Algebraic independence": {
    "title": "Algebraic independence",
    "url": "https://en.wikipedia.org/wiki/Algebraic_independence",
    "summary": "In abstract algebra, a subset \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n of a field \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  \n is algebraically independent over a subfield \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n if the elements of \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n do not satisfy any non-trivial polynomial equation with coefficients in \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n.\nIn particular, a one element set \n  \n    \n      \n        {\n        α\n        }\n      \n    \n    {\\displaystyle \\{\\alpha \\}}\n  \n is algebraically independent over \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n if and only if \n  \n    \n      \n        α\n      \n    \n    {\\displaystyle \\alpha }\n  \n is transcendental over \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n. In general, all the elements of an algebraically independent set \n  \n    \n      \n        S\n      \n    \n ",
    "content": "In abstract algebra, a subset \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n of a field \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  \n is algebraically independent over a subfield \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n if the elements of \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n do not satisfy any non-trivial polynomial equation with coefficients in \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n.\nIn particular, a one element set \n  \n    \n      \n        {\n        α\n        }\n      \n    \n    {\\displaystyle \\{\\alpha \\}}\n  \n is algebraically independent over \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n if and only if \n  \n    \n      \n        α\n      \n    \n    {\\displaystyle \\alpha }\n  \n is transcendental over \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n. In general, all the elements of an algebraically independent set \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n over \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n are by necessity transcendental over \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n, and over all of the field extensions over \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n generated by the remaining elements of \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n.\n\nExample\nThe real numbers \n  \n    \n      \n        \n          \n            π\n          \n        \n      \n    \n    {\\displaystyle {\\sqrt {\\pi }}}\n  \n and \n  \n    \n      \n        2\n        π\n        +\n        1\n      \n    \n    {\\displaystyle 2\\pi +1}\n  \n are transcendental numbers: they are not the roots of any nontrivial polynomial whose coefficients are rational numbers. Thus, the sets \n  \n    \n      \n        {\n        \n          \n            π\n          \n        \n        }\n      \n    \n    {\\displaystyle \\{{\\sqrt {\\pi }}\\}}\n  \n and \n  \n    \n      \n        {\n        2\n        π\n        +\n        1\n        }\n      \n    \n    {\\displaystyle \\{2\\pi +1\\}}\n  \n are both algebraically independent over the rational numbers.\nHowever, the set \n  \n    \n      \n        {\n        \n          \n            π\n          \n        \n        ,\n        2\n        π\n        +\n        1\n        }\n      \n    \n    {\\displaystyle \\{{\\sqrt {\\pi }},2\\pi +1\\}}\n  \n is not algebraically independent over the rational numbers \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n, because the nontrivial polynomial\n\n  \n    \n      \n        P\n        (\n        x\n        ,\n        y\n        )\n        =\n        2\n        \n          x\n          \n            2\n          \n        \n        −\n        y\n        +\n        1\n      \n    \n    {\\displaystyle P(x,y)=2x^{2}-y+1}\n  \n\nis zero when \n  \n    \n      \n        x\n        =\n        \n          \n            π\n          \n        \n      \n    \n    {\\displaystyle x={\\sqrt {\\pi }}}\n  \n and \n  \n    \n      \n        y\n        =\n        2\n        π\n        +\n        1\n      \n    \n    {\\displaystyle y=2\\pi +1}\n  \n.\n\nAlgebraic independence of known constants\nAlthough π and e are transcendental, it is not known whether \n  \n    \n      \n        {\n        π\n        ,\n        e\n        }\n      \n    \n    {\\displaystyle \\{\\pi ,e\\}}\n  \n is algebraically independent over \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n. In fact, it is not even known whether \n  \n    \n      \n        π\n        +\n        e\n      \n    \n    {\\displaystyle \\pi +e}\n  \n is irrational. Nesterenko proved in 1996 that:\n\nthe numbers \n  \n    \n      \n        π\n      \n    \n    {\\displaystyle \\pi }\n  \n, \n  \n    \n      \n        \n          e\n          \n            π\n          \n        \n      \n    \n    {\\displaystyle e^{\\pi }}\n  \n, and \n  \n    \n      \n        Γ\n        (\n        1\n        \n          /\n        \n        4\n        )\n      \n    \n    {\\displaystyle \\Gamma (1/4)}\n  \n, where \n  \n    \n      \n        Γ\n      \n    \n    {\\displaystyle \\Gamma }\n  \n is the gamma function, are algebraically independent over \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n;\nthe numbers \n  \n    \n      \n        \n          e\n          \n            π\n            \n              \n                3\n              \n            \n          \n        \n      \n    \n    {\\displaystyle e^{\\pi {\\sqrt {3}}}}\n  \n and \n  \n    \n      \n        Γ\n        (\n        1\n        \n          /\n        \n        3\n        )\n      \n    \n    {\\displaystyle \\Gamma (1/3)}\n  \n are algebraically independent over \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n;\nfor all positive integers \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n, the number \n  \n    \n      \n        \n          e\n          \n            π\n            \n              \n                n\n              \n            \n          \n        \n      \n    \n    {\\displaystyle e^{\\pi {\\sqrt {n}}}}\n",
    "links": [
      "Abstract algebra",
      "Algebraic matroid",
      "Algebraic number",
      "Algebraic number field",
      "Algebraic number theory",
      "Algebraic structure",
      "Associative algebra",
      "Ben J. Green",
      "Bulletin of the London Mathematical Society",
      "Cardinality",
      "Category of rings",
      "Clifford algebra",
      "Commutative algebra",
      "Commutative ring",
      "Commutator (ring theory)",
      "Complex numbers",
      "Comptes rendus de l'Académie des sciences",
      "Division ring",
      "Doi (identifier)",
      "E (mathematical constant)",
      "Euclidean domain",
      "Field (mathematics)",
      "Field extension",
      "Finite field",
      "Finite set",
      "Formal power series ring",
      "Fractional ideal",
      "Free algebra",
      "Free product of associative algebras",
      "Frobenius endomorphism",
      "GCD domain",
      "Gamma function",
      "Geometric algebra",
      "Graded ring",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "Ideal (ring theory)",
      "If and only if",
      "Indeterminate (variable)",
      "Inner automorphism",
      "Integer",
      "Integers modulo n",
      "Integral domain",
      "Integrally closed domain",
      "Involutive ring",
      "Jordan ring",
      "Kernel (algebra)",
      "Lie ring",
      "Lindemann-Weierstrass theorem",
      "Lindemann–Weierstrass theorem"
    ],
    "categories": [
      "Category:Abstract algebra",
      "Category:All Wikipedia articles written in American English",
      "Category:Articles with short description",
      "Category:Matroid theory",
      "Category:Short description is different from Wikidata",
      "Category:Use American English from January 2019",
      "Category:Use mdy dates from September 2021",
      "Category:Wikipedia articles needing clarification from January 2025"
    ]
  },
  "Cubic equation": {
    "title": "Cubic equation",
    "url": "https://en.wikipedia.org/wiki/Cubic_equation",
    "summary": "In algebra, a cubic equation in one variable is an equation of the form\n\n  \n    \n      \n        a\n        \n          x\n          \n            3\n          \n        \n        +\n        b\n        \n          x\n          \n            2\n          \n        \n        +\n        c\n        x\n        +\n        d\n        =\n        0\n      \n    \n    {\\displaystyle ax^{3}+bx^{2}+cx+d=0}\n  \n\nin which a is not zero.\nThe solutions of this equation are called roots of the cubic function defined by the left-hand side of the equation. If all of the coefficients a, b, c, and d of the cubic equation are real numbers, then it has at least one real root (this is true for all odd-degree polynomial functions). All of the roots of the cubic equation can be found by the following means:\n\nalgebraically: more precisely, they can be expressed by a cubic formula involving the four coefficients, the four basic arithmetic operations, square roots, and cube roots. (This is also true of quadratic (second-degree) and quartic",
    "content": "In algebra, a cubic equation in one variable is an equation of the form\n\n  \n    \n      \n        a\n        \n          x\n          \n            3\n          \n        \n        +\n        b\n        \n          x\n          \n            2\n          \n        \n        +\n        c\n        x\n        +\n        d\n        =\n        0\n      \n    \n    {\\displaystyle ax^{3}+bx^{2}+cx+d=0}\n  \n\nin which a is not zero.\nThe solutions of this equation are called roots of the cubic function defined by the left-hand side of the equation. If all of the coefficients a, b, c, and d of the cubic equation are real numbers, then it has at least one real root (this is true for all odd-degree polynomial functions). All of the roots of the cubic equation can be found by the following means:\n\nalgebraically: more precisely, they can be expressed by a cubic formula involving the four coefficients, the four basic arithmetic operations, square roots, and cube roots. (This is also true of quadratic (second-degree) and quartic (fourth-degree) equations, but not for higher-degree equations, by the Abel–Ruffini theorem.)\ngeometrically: using Omar Kahyyam's method.\ntrigonometrically\nnumerical approximations of the roots can be found using root-finding algorithms such as Newton's method.\nThe coefficients do not need to be real numbers. Much of what is covered below is valid for coefficients in any field with characteristic other than 2 and 3. The solutions of the cubic equation do not necessarily belong to the same field as the coefficients. For example, some cubic equations with rational coefficients have roots that are irrational (and even non-real) complex numbers.\n\nHistory\nCubic equations were known to the ancient Babylonians, Greeks, Chinese, Indians, and Egyptians. Babylonian (20th to 16th centuries BC) cuneiform tablets have been found with tables for calculating cubes and cube roots. The Babylonians could have used the tables to solve cubic equations, but no evidence exists to confirm that they did. The problem of doubling the cube involves the simplest and oldest studied cubic equation, and one for which the ancient Egyptians did not believe a solution existed. In the 5th century BC, Hippocrates reduced this problem to that of finding two mean proportionals between one line and another of twice its length, but could not solve this with a compass and straightedge construction, a task which is now known to be impossible. Methods for solving cubic equations appear in The Nine Chapters on the Mathematical Art, a Chinese mathematical text compiled around the 2nd century BC and commented on by Liu Hui in the 3rd century. \nIn the 3rd century AD, the Greek mathematician Diophantus found integer or rational solutions for some bivariate cubic equations (Diophantine equations). Hippocrates, Menaechmus and Archimedes are believed to have come close to solving the problem of doubling the cube using intersecting conic sections, though historians such as Reviel Netz dispute whether the Greeks were thinking about cubic equations or just problems that can lead to cubic equations. Some others like T. L. Heath, who translated all of Archimedes's works, disagree, putting forward evidence that Archimedes really solved cubic equations using intersections of two conics, but also discussed the conditions where the roots are 0, 1 or 2. \n\nIn the 7th century, the Tang dynasty astronomer mathematician Wang Xiaotong in his mathematical treatise titled Jigu Suanjing systematically established and solved numerically 25 cubic equations of the form x3 + px2 + qx = N, 23 of them with p, q ≠ 0, and two of them with q = 0.\n\nIn the 11th century, the Persian poet-mathematician, Omar Khayyam (1048–1131), made significant progress in the theory of cubic equations. In an early paper, he discovered that a cubic equation can have more than one solution and stated that it cannot be solved using compass and straightedge constructions. He also found a geometric solution. In his later work, the Treatise on Demonstration of Problems of Algebra, he wrote a complete classification of cubic equations with general geometric solutions found by means of intersecting conic sections. Khayyam made an attempt to come up with an algebraic formula for extracting cubic roots. He wrote: “We have tried to express these roots by algebra but have failed. It may be, however, that men who come after us will succeed.”\nIn the 12th century, the Indian mathematician Bhaskara II attempted the solution of cubic equations without general success. However, he gave one example of a cubic equation: x3 + 12x = 6x2 + 35. In the 12th century, another Persian mathematician, Sharaf al-Dīn al-Tūsī (1135–1213), wrote the Al-Muʿādalāt (Treatise on Equations), which dealt with eight types of cubic equations with positive solutions and five types of cubic equations which may not have positive solutions. He used what would later be known as the Horner–Ruffini method to numerically approximate the root of a cubic equation. He also",
    "links": [
      "Abel–Ruffini theorem",
      "Abscissa",
      "Algebra",
      "Algebraic expression",
      "Algebraically closed field",
      "American Mathematical Monthly",
      "Analytic function",
      "Analytical chemistry",
      "Angle trisection",
      "Arccosine",
      "Archimedes",
      "Area",
      "Arithmetic operations",
      "Ars Magna (Gerolamo Cardano)",
      "Babylonia",
      "Babylonian numerals",
      "Barry Mazur",
      "Bartel Leendert van der Waerden",
      "Bibhutibhushan Datta",
      "Binomial (polynomial)",
      "Birkhäuser",
      "Bivariate polynomial",
      "Buffer solution",
      "Bézier curve",
      "Cartesian plane",
      "Casus irreducibilis",
      "Cauchy–Euler equation",
      "Change of variable",
      "Characteristic (algebra)",
      "Characteristic equation (calculus)",
      "Characteristic polynomial",
      "Charlot equation",
      "Chinese mathematics",
      "Circumradius",
      "Coefficients",
      "Common multiple",
      "Compass-and-straightedge construction",
      "Compass and straightedge construction",
      "Complex conjugate",
      "Complex number",
      "Complex plane",
      "Conic section",
      "Conic sections",
      "Constant function",
      "Coprime integers",
      "Cosine",
      "Critical point (mathematics)",
      "Cube root",
      "Cubic equations of state",
      "Cubic function"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1 errors: ISBN date",
      "Category:Elementary algebra",
      "Category:Equations",
      "Category:Polynomials",
      "Category:Short description is different from Wikidata",
      "Category:Wikipedia articles needing clarification from September 2019"
    ]
  },
  "Cyclic group": {
    "title": "Cyclic group",
    "url": "https://en.wikipedia.org/wiki/Cyclic_group",
    "summary": "In abstract algebra, a cyclic group or monogenous group is a group, denoted Cn (also frequently \n  \n    \n      \n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} }\n  \nn or Zn, not to be confused with the commutative ring of p-adic numbers), that is generated by a single element. That is, it is a set of invertible elements with a single associative binary operation, and it contains an element g such that every other element of the group may be obtained by repeatedly applying the group operation to g or its inverse. Each element can be written as an integer power of g in multiplicative notation, or as an integer multiple of g in additive notation. This element g is called a generator of the group.\nEvery infinite cyclic group is isomorphic to the additive group of Z, the integers. Every finite cyclic group of order n is isomorphic to the additive group of Z/nZ, the integers modulo n. Every cyclic group is an abelian group (meaning that its group operation is commuta",
    "content": "In abstract algebra, a cyclic group or monogenous group is a group, denoted Cn (also frequently \n  \n    \n      \n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} }\n  \nn or Zn, not to be confused with the commutative ring of p-adic numbers), that is generated by a single element. That is, it is a set of invertible elements with a single associative binary operation, and it contains an element g such that every other element of the group may be obtained by repeatedly applying the group operation to g or its inverse. Each element can be written as an integer power of g in multiplicative notation, or as an integer multiple of g in additive notation. This element g is called a generator of the group.\nEvery infinite cyclic group is isomorphic to the additive group of Z, the integers. Every finite cyclic group of order n is isomorphic to the additive group of Z/nZ, the integers modulo n. Every cyclic group is an abelian group (meaning that its group operation is commutative), and every finitely generated abelian group is a direct product of cyclic groups.\nEvery cyclic group of prime order is a simple group, which cannot be broken down into smaller groups. In the classification of finite simple groups, one of the three infinite classes consists of the cyclic groups of prime order. The cyclic groups of prime order are thus among the building blocks from which all groups can be built.\n\nDefinition and notation\nFor any element g in any group G, one can form the subgroup that consists of all its integer powers: ⟨g⟩ = { gk | k ∈ Z }, called the cyclic subgroup generated by g. The order of g is |⟨g⟩|, the number of elements in ⟨g⟩, conventionally abbreviated as |g|, as ord(g), or as o(g). That is, the order of an element is equal to the order of the cyclic subgroup that it generates.\nA cyclic group is a group which is equal to one of its cyclic subgroups: G = ⟨g⟩ for some element g, called a generator of G.\nFor a finite cyclic group G of order n we have G = {e, g, g2, ... , gn−1}, where e is the identity element and gi = gj whenever i ≡ j (mod n);  in particular gn = g0 = e, and g−1 = gn−1. An abstract group defined by this multiplication is often denoted Cn, and we say that G is isomorphic to the standard cyclic group Cn. Such a group is also isomorphic to Z/nZ, the group of integers modulo n with the addition operation, which is the standard cyclic group in additive notation. Under the isomorphism χ defined by χ(gi) = i the identity element e corresponds to 0, products correspond to sums, and powers correspond to multiples.\nFor example, the set of complex 6th roots of unity: \n  \n    \n      \n        G\n        =\n        \n          {\n          \n            ±\n            1\n            ,\n            ±\n            \n              \n                (\n                \n                  \n                    \n                      \n                        1\n                        2\n                      \n                    \n                  \n                  +\n                  \n                    \n                      \n                        \n                          3\n                        \n                        2\n                      \n                    \n                  \n                  i\n                \n                )\n              \n            \n            ,\n            ±\n            \n              \n                (\n                \n                  \n                    \n                      \n                        1\n                        2\n                      \n                    \n                  \n                  −\n                  \n                    \n                      \n                        \n                          3\n                        \n                        2\n                      \n                    \n                  \n                  i\n                \n                )\n              \n            \n          \n          }\n        \n      \n    \n    {\\displaystyle G=\\left\\{\\pm 1,\\pm {\\left({\\tfrac {1}{2}}+{\\tfrac {\\sqrt {3}}{2}}i\\right)},\\pm {\\left({\\tfrac {1}{2}}-{\\tfrac {\\sqrt {3}}{2}}i\\right)}\\right\\}}\n  \n forms a group under multiplication. It is cyclic, since it is generated by the primitive root \n  \n    \n      \n        z\n        =\n        \n          \n            \n              1\n              2\n            \n          \n        \n        +\n        \n          \n            \n              \n                3\n              \n              2\n            \n          \n        \n        i\n        =\n        \n          e\n          \n            2\n            π\n            i\n            \n              /\n            \n            6\n          \n        \n        :\n      \n    \n    {\\displaystyle z={\\tfrac {1}{2}}+{\\tfrac {\\sqrt {3}}{2}}i=e^{2\\pi i/6}:}\n  \n that is, G = ⟨z⟩ = { 1, z, z2, z3, z4, z5 } with z6 = 1. Under a change of letters, this is isomorphic to (structurally the same as) the standard cyclic group of order 6, defined as C6 = ⟨g⟩ = { e, g, g2, g3, g4, g5 ",
    "links": [
      "Abelian group",
      "Abelian variety",
      "Abstract algebra",
      "Additive group",
      "Algebraic group",
      "Algebraic structure",
      "Alternating group",
      "American Mathematical Monthly",
      "Arithmetic group",
      "Associative",
      "Automorphism group",
      "Baby monster group",
      "Bijection",
      "Binary operation",
      "Brian Alspach",
      "Cauchy's theorem (group theory)",
      "Cayley graph",
      "Celtic knot",
      "Character theory",
      "Characteristic (algebra)",
      "Chinese remainder theorem",
      "Circle",
      "Circle group",
      "Circulant graph",
      "Circular graph",
      "Classification of finite simple groups",
      "Commutative property",
      "Commutative ring",
      "Commutator subgroup",
      "Complex number",
      "Composite number",
      "Conformal group",
      "Conjugacy class",
      "Continuous group",
      "Conway group",
      "Coprime",
      "Coset",
      "Countable",
      "Countable set",
      "Cycle graph",
      "Cycle graph (algebra)",
      "Cycle graph (group)",
      "Cyclic extension",
      "Cyclic module",
      "Cyclic number (group theory)",
      "Cyclic order",
      "Cyclic sieving",
      "Cyclically ordered group",
      "Cyclotomic polynomial",
      "David A. Cox"
    ],
    "categories": [
      "Category:Abelian group theory",
      "Category:Articles with short description",
      "Category:Properties of groups",
      "Category:Short description matches Wikidata"
    ]
  },
  "Field automorphism": {
    "title": "Automorphism",
    "url": "https://en.wikipedia.org/wiki/Automorphism",
    "summary": "In mathematics, an automorphism is an isomorphism from a mathematical object to itself. It is, in some sense, a symmetry of the object, and a way of mapping the object to itself while preserving all of its structure. The set of all automorphisms of an object forms a group, called the automorphism group. It is, loosely speaking, the symmetry group of the object.",
    "content": "In mathematics, an automorphism is an isomorphism from a mathematical object to itself. It is, in some sense, a symmetry of the object, and a way of mapping the object to itself while preserving all of its structure. The set of all automorphisms of an object forms a group, called the automorphism group. It is, loosely speaking, the symmetry group of the object.\n\nDefinition\nIn an algebraic structure such as a group, a ring, or vector space, an automorphism is simply a bijective homomorphism of an object into itself. (The definition of a homomorphism depends on the type of algebraic structure; see, for example, group homomorphism, ring homomorphism, and linear operator.) \nMore generally, for an object in some category, an automorphism is a morphism of the object to itself that has an inverse morphism; that is, a morphism \n  \n    \n      \n        f\n        :\n        X\n        →\n        X\n      \n    \n    {\\displaystyle f:X\\to X}\n  \n is an automorphism if there is a morphism \n  \n    \n      \n        g\n        :\n        X\n        →\n        X\n      \n    \n    {\\displaystyle g:X\\to X}\n  \n such that \n  \n    \n      \n        g\n        ∘\n        f\n        =\n        f\n        ∘\n        g\n        =\n        \n          id\n          \n            X\n          \n        \n        ,\n      \n    \n    {\\displaystyle g\\circ f=f\\circ g=\\operatorname {id} _{X},}\n  \n where \n  \n    \n      \n        \n          id\n          \n            X\n          \n        \n      \n    \n    {\\displaystyle \\operatorname {id} _{X}}\n  \n is the identity morphism  of X. For algebraic structures, the two definitions are equivalent; in this case, the identity morphism is simply the identity function, and is often called the trivial automorphism.\n\nAutomorphism group\nThe automorphisms of an object X form a group under composition of morphisms, which is called the automorphism group of X. This results straightforwardly from the definition of a category.\nThe automorphism group of an object X in a category C is often denoted AutC(X), or simply Aut(X) if the category is clear from context.\n\nExamples\nIn set theory, an arbitrary permutation of the elements of a set X is an automorphism. The automorphism group of X is also called the symmetric group on X.\nIn elementary arithmetic, the set of integers, ⁠\n  \n    \n      \n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} }\n  \n⁠, considered as a group under addition, has a unique nontrivial automorphism: negation. Considered as a ring, however, it has only the trivial automorphism. Generally speaking, negation is an automorphism of any abelian group, but not of a ring or field.\nA group automorphism is a group isomorphism from a group to itself. Informally, it is a permutation of the group elements such that the structure remains unchanged. For every group G there is a natural group homomorphism G → Aut(G) whose image is the group Inn(G) of inner automorphisms and whose kernel is the center of G. Thus, if G has trivial center it can be embedded into its own automorphism group.\nIn linear algebra, an endomorphism of a vector space V is a linear operator V → V. An automorphism is an invertible linear operator on V. When the vector space is finite-dimensional, the automorphism group of V is the same as the general linear group, GL(V).  (The algebraic structure of all endomorphisms of V is itself an algebra over the same base field as V, whose invertible elements precisely consist of GL(V).)\nA field automorphism is a bijective ring homomorphism from a field to itself.\nThe field \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n of the rational numbers has no other automorphism than the identity, since an automorphism must fix the additive identity 0 and the multiplicative identity  1; the sum of a finite number of 1 must be fixed, as well as the additive inverses of these sums (that is, the automorphism fixes all integers); finally, since every rational number is the quotient of two integers, all rational numbers must be fixed by any automorphism.\nThe field \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n of the real numbers has no automorphisms other than the identity. Indeed, the rational numbers must be fixed by every automorphism, per above; an automorphism must preserve inequalities since \n  \n    \n      \n        x\n        <\n        y\n      \n    \n    {\\displaystyle x<y}\n  \n is equivalent to \n  \n    \n      \n        ∃\n        z\n        ∣\n        y\n        −\n        x\n        =\n        \n          z\n          \n            2\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\exists z\\mid y-x=z^{2},}\n  \n and the latter property is preserved by every automorphism; finally every real number must be fixed since it is the least upper bound of a sequence of rational numbers.\nThe field \n  \n    \n      \n        \n          C\n        \n      \n    \n    {\\displaystyle \\mathbb {C} }\n  \n of the complex numbers has a unique nontrivi",
    "links": [
      "Abelian group",
      "Additive identity",
      "Algebra over a field",
      "Algebraic field extension",
      "Algebraic structure",
      "Antiautomorphism",
      "Automorphism group",
      "Axiom of choice",
      "Biholomorphy",
      "Bijection",
      "Bijective",
      "Category (mathematics)",
      "Cayley graph",
      "Cayley table",
      "Center (group theory)",
      "Characteristic subgroup",
      "Complex conjugation",
      "Complex number",
      "Conformal map",
      "Continuous function (topology)",
      "Cosets",
      "Cycle notation",
      "Diffeomorphism",
      "Doi (identifier)",
      "Elementary arithmetic",
      "Elsevier",
      "Endomorphism",
      "Endomorphism algebra",
      "Endomorphism ring",
      "Eric W. Weisstein",
      "Exceptional Lie algebra",
      "Field (mathematics)",
      "Fractional Fourier transform",
      "Frobenius automorphism",
      "Function composition",
      "G2 (mathematics)",
      "Galois theory",
      "General linear group",
      "Geometry",
      "Goursat's lemma",
      "Graph automorphism",
      "Graph theory",
      "Group (mathematics)",
      "Group homomorphism",
      "Group isomorphism",
      "Group of units",
      "Homeomorphism",
      "Homeomorphism group",
      "Homomorphism",
      "ISBN (identifier)"
    ],
    "categories": [
      "Category:Abstract algebra",
      "Category:Articles with short description",
      "Category:Morphisms",
      "Category:Short description is different from Wikidata",
      "Category:Symmetry"
    ]
  },
  "Field theory (mathematics)": {
    "title": "Field (mathematics)",
    "url": "https://en.wikipedia.org/wiki/Field_(mathematics)",
    "summary": "In mathematics, a field is a set on which addition, subtraction, multiplication, and division are defined and behave as the corresponding operations on rational and real numbers. A field is thus a fundamental algebraic structure which is widely used in algebra, number theory, and many other areas of mathematics.\nThe best known fields are the field of rational numbers, the field of real numbers and the field of complex numbers. Many other fields, such as fields of rational functions, algebraic function fields, algebraic number fields, and p-adic fields are commonly used and studied in mathematics, particularly in number theory and algebraic geometry. Most cryptographic protocols rely on finite fields, i.e., fields with finitely many elements.\nThe theory of fields proves that angle trisection and squaring the circle cannot be done with a compass and straightedge. Galois theory, devoted to understanding the symmetries of field extensions, provides an elegant proof of the Abel–Ruffini theo",
    "content": "In mathematics, a field is a set on which addition, subtraction, multiplication, and division are defined and behave as the corresponding operations on rational and real numbers. A field is thus a fundamental algebraic structure which is widely used in algebra, number theory, and many other areas of mathematics.\nThe best known fields are the field of rational numbers, the field of real numbers and the field of complex numbers. Many other fields, such as fields of rational functions, algebraic function fields, algebraic number fields, and p-adic fields are commonly used and studied in mathematics, particularly in number theory and algebraic geometry. Most cryptographic protocols rely on finite fields, i.e., fields with finitely many elements.\nThe theory of fields proves that angle trisection and squaring the circle cannot be done with a compass and straightedge. Galois theory, devoted to understanding the symmetries of field extensions, provides an elegant proof of the Abel–Ruffini theorem that general quintic equations cannot be solved in radicals.\nFields serve as foundational notions in several mathematical domains. This includes different branches of mathematical analysis, which are based on fields with additional structure. Basic theorems in analysis hinge on the structural properties of the field of real numbers. Most importantly for algebraic purposes, any field may be used as the scalars for a vector space, which is the standard general context for linear algebra. Number fields, the siblings of the field of rational numbers, are studied in depth in number theory. Function fields can help describe properties of geometric objects.\n\nDefinition\nInformally, a field is a set, along with two operations defined on that set: an addition operation a + b and a multiplication operation a ⋅ b, both of which behave similarly as they do for rational numbers and real numbers.  This includes the existence of an additive inverse −a for each element a and of a multiplicative inverse b−1 for each nonzero element b. This allows the definition of the so-called inverse operations, subtraction a − b and division a / b, as a − b = a + (−b) and a / b = a ⋅ b−1.\nOften the product a ⋅ b is represented by juxtaposition, as ab.\n\nClassic definition\nFormally, a field is a set F together with two binary operations on F called addition and multiplication. A binary operation on F is a mapping F × F → F, that is, a correspondence that associates with each ordered pair of elements of F a uniquely determined element of F. The result of the addition of a and b is called the sum of a and b, and is denoted a + b. Similarly, the result of the multiplication of a and b is called the product of a and b, and is denoted a ⋅ b. These operations are required to satisfy the following properties, referred to as field axioms. \nThese axioms are required to hold for all elements  a, b, c of the field F:\n\nAssociativity of addition and multiplication: a + (b + c) = (a + b) + c, and a ⋅ (b ⋅ c) = (a ⋅ b) ⋅ c.\nCommutativity of addition and multiplication: a + b = b + a, and a ⋅ b = b ⋅ a.\nAdditive and multiplicative identity: there exist two distinct elements 0 and 1 in F such that a + 0 = a and a ⋅ 1 = a.\nAdditive inverses: for every a in F, there exists an element in F, denoted −a, called the additive inverse of a, such that a + (−a) = 0.\nMultiplicative inverses: for every a ≠ 0 in F, there exists an element in F, denoted by a−1 or 1/a, called the multiplicative inverse of a, such that a ⋅ a−1 = 1.\nDistributivity of multiplication over addition: a ⋅ (b + c) = (a ⋅ b) + (a ⋅ c).\nAn equivalent, and more succinct, definition is: a field has two commutative operations, called addition and multiplication; it is a group under addition with 0 as the additive identity; the nonzero elements form a group under multiplication with 1 as the multiplicative identity; and multiplication distributes over addition.\nEven more succinctly: a field is a commutative ring where 0 ≠ 1 and all nonzero elements are invertible under multiplication.\n\nAlternative definition\nFields can also be defined in different, but equivalent ways. One can alternatively define a field by four binary operations (addition, subtraction, multiplication, and division) and their required properties. Division by zero is, by definition, excluded. In order to avoid existential quantifiers, fields can be defined by two binary operations (addition and multiplication), two unary operations (yielding the additive and multiplicative inverses respectively), and two nullary operations (the constants 0 and 1). These operations are then subject to the conditions above. Avoiding existential quantifiers is important in constructive mathematics and computing. One may equivalently define a field by the same two binary operations, one unary operation (the multiplicative inverse), and two (not necessarily distinct) constants 1 and −1, since 0 = 1 + (−1) and −a = (−1)a.\n\nExamples\nRational numbers\nRational numbers have bee",
    "links": [
      "Abelian extension",
      "Abelian group",
      "Abel–Ruffini theorem",
      "Absolute Galois group",
      "Absolute value",
      "Abstract algebraic variety",
      "Academic Press",
      "Addison-Wesley",
      "Addition",
      "Additive group",
      "Additive identity",
      "Additive inverse",
      "Adjunction (field theory)",
      "Affine space",
      "Alexandre-Théophile Vandermonde",
      "Algebra",
      "Algebra over a field",
      "Algebraic K-theory",
      "Algebraic closure",
      "Algebraic curve",
      "Algebraic element",
      "Algebraic extension",
      "Algebraic function field",
      "Algebraic geometry",
      "Algebraic number",
      "Algebraic number field",
      "Algebraic number theory",
      "Algebraic structure",
      "Algebraic topology",
      "Algebraically closed",
      "Algebraically independent",
      "Allyn and Bacon",
      "Alternative algebra",
      "Angle trisection",
      "ArXiv (identifier)",
      "Archimedean field",
      "Arithmetic geometry",
      "Arity",
      "Artin–Schreier theorem",
      "Associative algebra",
      "Associativity",
      "Axiom",
      "Axiom of choice",
      "Ax–Kochen theorem",
      "Basis (linear algebra)",
      "Bialgebra",
      "Bibcode (identifier)",
      "Bijection",
      "Binary field",
      "Binary operation"
    ],
    "categories": [
      "Category:Abstract algebra",
      "Category:Algebraic structures",
      "Category:Articles with short description",
      "Category:CS1 German-language sources (de)",
      "Category:Field (mathematics)",
      "Category:Good articles",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Fundamental theorem of finite abelian groups": {
    "title": "Abelian group",
    "url": "https://en.wikipedia.org/wiki/Abelian_group",
    "summary": "In mathematics, an abelian group, also called a commutative group, is a group in which the result of applying the group operation to two group elements does not depend on the order in which they are written. That is, the group operation is commutative. With addition as an operation, the integers and the real numbers form abelian groups, and the concept of an abelian group may be viewed as a generalization of these examples. Abelian groups are named after the Norwegian mathematician Niels Henrik Abel.\nThe concept of an abelian group underlies many fundamental algebraic structures, such as fields, rings, vector spaces, and algebras. The theory of abelian groups is generally simpler than that of their non-abelian counterparts, and finite abelian groups are very well understood and fully classified.",
    "content": "In mathematics, an abelian group, also called a commutative group, is a group in which the result of applying the group operation to two group elements does not depend on the order in which they are written. That is, the group operation is commutative. With addition as an operation, the integers and the real numbers form abelian groups, and the concept of an abelian group may be viewed as a generalization of these examples. Abelian groups are named after the Norwegian mathematician Niels Henrik Abel.\nThe concept of an abelian group underlies many fundamental algebraic structures, such as fields, rings, vector spaces, and algebras. The theory of abelian groups is generally simpler than that of their non-abelian counterparts, and finite abelian groups are very well understood and fully classified.\n\nDefinition\nAn abelian group is a set \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n, together with an operation ･ , that combines any two elements \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n and \n  \n    \n      \n        b\n      \n    \n    {\\displaystyle b}\n  \n of \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n to form another element of \n  \n    \n      \n        A\n        ,\n      \n    \n    {\\displaystyle A,}\n  \n denoted \n  \n    \n      \n        a\n        ⋅\n        b\n      \n    \n    {\\displaystyle a\\cdot b}\n  \n. The symbol ･ is a general placeholder for a concretely given operation. To qualify as an abelian group, the set and operation, \n  \n    \n      \n        (\n        A\n        ,\n        ⋅\n        )\n      \n    \n    {\\displaystyle (A,\\cdot )}\n  \n, must satisfy four requirements known as the abelian group axioms (some authors include in the axioms some properties that belong to the definition of an operation: namely that the operation is defined for any ordered pair of elements of A, that the result is well-defined, and that the result belongs to A):\n\nAssociativity\nFor all \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n, \n  \n    \n      \n        b\n      \n    \n    {\\displaystyle b}\n  \n, and \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  \n in \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n, the equation \n  \n    \n      \n        (\n        a\n        ⋅\n        b\n        )\n        ⋅\n        c\n        =\n        a\n        ⋅\n        (\n        b\n        ⋅\n        c\n        )\n      \n    \n    {\\displaystyle (a\\cdot b)\\cdot c=a\\cdot (b\\cdot c)}\n  \n holds.\nIdentity element\nThere exists an element \n  \n    \n      \n        e\n      \n    \n    {\\displaystyle e}\n  \n in \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n, such that for all elements \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n in \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n, the equation \n  \n    \n      \n        e\n        ⋅\n        a\n        =\n        a\n        ⋅\n        e\n        =\n        a\n      \n    \n    {\\displaystyle e\\cdot a=a\\cdot e=a}\n  \n holds.\nInverse element\nFor each \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n in \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n there exists an element \n  \n    \n      \n        b\n      \n    \n    {\\displaystyle b}\n  \n in \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n such that \n  \n    \n      \n        a\n        ⋅\n        b\n        =\n        b\n        ⋅\n        a\n        =\n        e\n      \n    \n    {\\displaystyle a\\cdot b=b\\cdot a=e}\n  \n, where \n  \n    \n      \n        e\n      \n    \n    {\\displaystyle e}\n  \n is the identity element.\nCommutativity\nFor all \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n, \n  \n    \n      \n        b\n      \n    \n    {\\displaystyle b}\n  \n in \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n, \n  \n    \n      \n        a\n        ⋅\n        b\n        =\n        b\n        ⋅\n        a\n      \n    \n    {\\displaystyle a\\cdot b=b\\cdot a}\n  \n.\nA group in which the group operation is not commutative is called a \"non-abelian group\" or \"non-commutative group\".\n\nFacts\nNotation\nThere are two main notational conventions for abelian groups – additive and multiplicative.\n\nGenerally, the multiplicative notation is the usual notation for groups, while the additive notation is the usual notation for modules and rings. The additive notation may also be used to emphasize that a particular group is abelian, whenever both abelian and non-abelian groups are considered, with some notable exceptions being near-rings and partially ordered groups, where an operation is written additively even when non-abelian.\n\nMultiplication table\nTo verify that a finite group is abelian, a table (matrix) – known as a Cayley table – can be constructed in a similar fashion to a multiplication table. If the group is \n  \n    \n      \n        G\n        =\n        {\n        \n          g\n          \n            1\n          \n        \n        =\n        e\n        ,\n        \n          g\n          \n            2\n          \n        \n        ,\n        ",
    "links": [
      "Abelian category",
      "Abelian variety",
      "Abelianization",
      "Abingdon-on-Thames",
      "Abraham Robinson",
      "Abstract algebra",
      "Academic Press",
      "Addition",
      "Additive group",
      "Additive identity",
      "Additive inverse",
      "Adjective",
      "Algebra over a field",
      "Algebraic group",
      "Algebraic structure",
      "Algebraically compact module",
      "Alternating group",
      "American Mathematical Monthly",
      "American Mathematical Society",
      "ArXiv (identifier)",
      "Arithmetic group",
      "Associative algebra",
      "Automorphism group",
      "Axiomatic set theory",
      "Baby monster group",
      "Baer's criterion",
      "Basel",
      "Basic subgroup",
      "Bialgebra",
      "Bibcode (identifier)",
      "Binary operation",
      "Boca Raton, Florida",
      "Boolean algebra (structure)",
      "Burnside ring",
      "CRC Press",
      "Cambridge, Massachusetts",
      "Camille Jordan",
      "Cardinal number",
      "Carl Friedrich Gauss",
      "Category of abelian groups",
      "Cauchy's theorem (group theory)",
      "Cayley table",
      "Center (group theory)",
      "Cham, Switzerland",
      "Characteristic subgroup",
      "Circle group",
      "Classification of finite simple groups",
      "Cokernel",
      "Commutative",
      "Commutative ring"
    ],
    "categories": [
      "Category:Abelian group theory",
      "Category:Articles with short description",
      "Category:CS1: long volume value",
      "Category:Niels Henrik Abel",
      "Category:Properties of groups",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Fundamental theorem of symmetric polynomials": {
    "title": "Elementary symmetric polynomial",
    "url": "https://en.wikipedia.org/wiki/Elementary_symmetric_polynomial",
    "summary": "In mathematics, specifically in commutative algebra, the elementary symmetric polynomials are one type of basic building block for symmetric polynomials, in the sense that any symmetric polynomial can be expressed as a polynomial in elementary symmetric polynomials.  That is, any symmetric polynomial P is given by an expression involving only additions and multiplication of constants and elementary symmetric polynomials.  There is one elementary symmetric polynomial of degree d in n variables for each positive integer d ≤ n, and it is formed by adding together all distinct products of d distinct variables.",
    "content": "In mathematics, specifically in commutative algebra, the elementary symmetric polynomials are one type of basic building block for symmetric polynomials, in the sense that any symmetric polynomial can be expressed as a polynomial in elementary symmetric polynomials.  That is, any symmetric polynomial P is given by an expression involving only additions and multiplication of constants and elementary symmetric polynomials.  There is one elementary symmetric polynomial of degree d in n variables for each positive integer d ≤ n, and it is formed by adding together all distinct products of d distinct variables.\n\nDefinition\nThe elementary symmetric polynomials in n variables X1, ..., Xn, written ek(X1, ..., Xn) for k = 1, ..., n, are defined by\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  e\n                  \n                    1\n                  \n                \n                (\n                \n                  X\n                  \n                    1\n                  \n                \n                ,\n                \n                  X\n                  \n                    2\n                  \n                \n                ,\n                …\n                ,\n                \n                  X\n                  \n                    n\n                  \n                \n                )\n              \n              \n                \n                =\n                \n                  ∑\n                  \n                    1\n                    ≤\n                    a\n                    ≤\n                    n\n                  \n                \n                \n                  X\n                  \n                    a\n                  \n                \n                ,\n              \n            \n            \n              \n                \n                  e\n                  \n                    2\n                  \n                \n                (\n                \n                  X\n                  \n                    1\n                  \n                \n                ,\n                \n                  X\n                  \n                    2\n                  \n                \n                ,\n                …\n                ,\n                \n                  X\n                  \n                    n\n                  \n                \n                )\n              \n              \n                \n                =\n                \n                  ∑\n                  \n                    1\n                    ≤\n                    a\n                    <\n                    b\n                    ≤\n                    n\n                  \n                \n                \n                  X\n                  \n                    a\n                  \n                \n                \n                  X\n                  \n                    b\n                  \n                \n                ,\n              \n            \n            \n              \n                \n                  e\n                  \n                    3\n                  \n                \n                (\n                \n                  X\n                  \n                    1\n                  \n                \n                ,\n                \n                  X\n                  \n                    2\n                  \n                \n                ,\n                …\n                ,\n                \n                  X\n                  \n                    n\n                  \n                \n                )\n              \n              \n                \n                =\n                \n                  ∑\n                  \n                    1\n                    ≤\n                    a\n                    <\n                    b\n                    <\n                    c\n                    ≤\n                    n\n                  \n                \n                \n                  X\n                  \n                    a\n                  \n                \n                \n                  X\n                  \n                    b\n                  \n                \n                \n                  X\n                  \n                    c\n                  \n                \n                ,\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}e_{1}(X_{1},X_{2},\\dots ,X_{n})&=\\sum _{1\\leq a\\leq n}X_{a},\\\\e_{2}(X_{1},X_{2},\\dots ,X_{n})&=\\sum _{1\\leq a<b\\leq n}X_{a}X_{b},\\\\e_{3}(X_{1},X_{2},\\dots ,X_{n})&=\\sum _{1\\leq a<b<c\\leq n}X_{a}X_{b}X_{c},\\\\\\end{aligned}}}\n  \n\nand so forth, ending with\n\n  \n    \n      \n        \n          e\n          \n            n\n          \n        \n        (\n        \n          X\n          \n            1\n          \n        \n        ,\n        \n          X\n          \n            2\n          \n        \n        ,\n        …\n        ,\n        \n          X\n          \n            n\n          \n        \n        )\n        =\n        \n     ",
    "links": [
      "Algebraically independent",
      "Characteristic polynomial",
      "Coefficient",
      "Commutative algebra",
      "Commutative ring",
      "Complete homogeneous symmetric polynomial",
      "Constant term",
      "Degree of a polynomial",
      "Determinant",
      "Eigenvalue",
      "Generator (mathematics)",
      "Homogeneous polynomial",
      "I. G. Macdonald",
      "ISBN (identifier)",
      "Integer partition",
      "Invariant theory",
      "Lexicographic order",
      "Linear combination",
      "MacMahon Master theorem",
      "Maclaurin's inequality",
      "Mathematical induction",
      "Mathematical proof",
      "Mathematics",
      "Matrix (mathematics)",
      "Monic polynomial",
      "Monomial",
      "Monomial order",
      "Newton's identities",
      "Newton's inequalities",
      "Polynomial ring",
      "Positive integer",
      "Power sum symmetric polynomial",
      "Representation theory",
      "Richard P. Stanley",
      "Ring (mathematics)",
      "Ring homomorphism",
      "Ring isomorphism",
      "Root of a polynomial",
      "Schur polynomial",
      "Square matrix",
      "Symmetric function",
      "Symmetric polynomial",
      "Trace (linear algebra)",
      "Univariate polynomial",
      "Up to",
      "Vieta's formulas",
      "Young diagram",
      "Wikipedia:Citing sources",
      "Wikipedia:External links",
      "Wikipedia:Further reading"
    ],
    "categories": [
      "Category:All articles lacking in-text citations",
      "Category:All articles with style issues",
      "Category:Articles containing proofs",
      "Category:Articles lacking in-text citations from January 2017",
      "Category:Articles with short description",
      "Category:Homogeneous polynomials",
      "Category:Short description is different from Wikidata",
      "Category:Symmetric functions",
      "Category:Wikipedia articles with style issues from July 2025"
    ]
  },
  "Galois group": {
    "title": "Galois group",
    "url": "https://en.wikipedia.org/wiki/Galois_group",
    "summary": "In mathematics, in the area of abstract algebra known as Galois theory, the Galois group of a certain type of field extension is a specific group associated with the field extension. The study of field extensions and their relationship to the polynomials that give rise to them via Galois groups is called Galois theory, so named in honor of Évariste Galois who first discovered them.\nFor a more elementary discussion of Galois groups in terms of permutation groups, see the article on Galois theory.",
    "content": "In mathematics, in the area of abstract algebra known as Galois theory, the Galois group of a certain type of field extension is a specific group associated with the field extension. The study of field extensions and their relationship to the polynomials that give rise to them via Galois groups is called Galois theory, so named in honor of Évariste Galois who first discovered them.\nFor a more elementary discussion of Galois groups in terms of permutation groups, see the article on Galois theory.\n\nDefinition\nSuppose that \n  \n    \n      \n        E\n      \n    \n    {\\displaystyle E}\n  \n is an extension of the field \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n (written as \n  \n    \n      \n        E\n        \n          /\n        \n        F\n      \n    \n    {\\displaystyle E/F}\n  \n and read \"E over F\"). An automorphism of \n  \n    \n      \n        E\n        \n          /\n        \n        F\n      \n    \n    {\\displaystyle E/F}\n  \n is defined to be an automorphism of \n  \n    \n      \n        E\n      \n    \n    {\\displaystyle E}\n  \n that fixes \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n pointwise. In other words, an automorphism of \n  \n    \n      \n        E\n        \n          /\n        \n        F\n      \n    \n    {\\displaystyle E/F}\n  \n is an isomorphism \n  \n    \n      \n        α\n        :\n        E\n        →\n        E\n      \n    \n    {\\displaystyle \\alpha :E\\to E}\n  \n such that \n  \n    \n      \n        α\n        (\n        x\n        )\n        =\n        x\n      \n    \n    {\\displaystyle \\alpha (x)=x}\n  \n for each \n  \n    \n      \n        x\n        ∈\n        F\n      \n    \n    {\\displaystyle x\\in F}\n  \n. The set of all automorphisms of \n  \n    \n      \n        E\n        \n          /\n        \n        F\n      \n    \n    {\\displaystyle E/F}\n  \n forms a group with the operation of function composition. This group is sometimes denoted by \n  \n    \n      \n        Aut\n        ⁡\n        (\n        E\n        \n          /\n        \n        F\n        )\n        .\n      \n    \n    {\\displaystyle \\operatorname {Aut} (E/F).}\n  \n\nIf \n  \n    \n      \n        E\n        \n          /\n        \n        F\n      \n    \n    {\\displaystyle E/F}\n  \n is a Galois extension, then \n  \n    \n      \n        Aut\n        ⁡\n        (\n        E\n        \n          /\n        \n        F\n        )\n      \n    \n    {\\displaystyle \\operatorname {Aut} (E/F)}\n  \n is called the Galois group of \n  \n    \n      \n        E\n        \n          /\n        \n        F\n      \n    \n    {\\displaystyle E/F}\n  \n, and is usually denoted by \n  \n    \n      \n        Gal\n        ⁡\n        (\n        E\n        \n          /\n        \n        F\n        )\n      \n    \n    {\\displaystyle \\operatorname {Gal} (E/F)}\n  \n.\nIf \n  \n    \n      \n        E\n        \n          /\n        \n        F\n      \n    \n    {\\displaystyle E/F}\n  \n is not a Galois extension, then the Galois group of \n  \n    \n      \n        E\n        \n          /\n        \n        F\n      \n    \n    {\\displaystyle E/F}\n  \n is sometimes defined as \n  \n    \n      \n        Aut\n        ⁡\n        (\n        K\n        \n          /\n        \n        F\n        )\n      \n    \n    {\\displaystyle \\operatorname {Aut} (K/F)}\n  \n, where \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n is the Galois closure of \n  \n    \n      \n        E\n      \n    \n    {\\displaystyle E}\n  \n.\n\nGalois group of a polynomial\nAnother definition of the Galois group comes from the Galois group of an irreducible polynomial \n  \n    \n      \n        f\n        ∈\n        F\n        [\n        x\n        ]\n      \n    \n    {\\displaystyle f\\in F[x]}\n  \n. If there is a field \n  \n    \n      \n        K\n        \n          /\n        \n        F\n      \n    \n    {\\displaystyle K/F}\n  \n such that \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n factors as a product of distinct linear polynomials\n\n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        (\n        x\n        −\n        \n          α\n          \n            1\n          \n        \n        )\n        ⋯\n        (\n        x\n        −\n        \n          α\n          \n            k\n          \n        \n        )\n        ∈\n        K\n        [\n        x\n        ]\n      \n    \n    {\\displaystyle f(x)=(x-\\alpha _{1})\\cdots (x-\\alpha _{k})\\in K[x]}\n  \n\nover the field \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n, then the Galois group of the polynomial \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n is defined as the Galois group of \n  \n    \n      \n        K\n        \n          /\n        \n        F\n      \n    \n    {\\displaystyle K/F}\n  \n where \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n is minimal among all such fields.\n\nStructure of Galois groups\nFundamental theorem of Galois theory\nOne of the important structure theorems from Galois theory comes from the fundamental theorem of Galois theory. This states that given a finite Galois extension \n  \n    \n      \n        K\n        \n          /\n        \n        k\n      \n    \n    {\\displaystyle K/k}",
    "links": [
      "Abelian group",
      "Absolute Galois group",
      "Abstract algebra",
      "Adjunction (field theory)",
      "Algebra (Lang)",
      "Automorphism",
      "Complex conjugation",
      "Complex number",
      "Cyclotomic field",
      "Cyclotomic polynomial",
      "Demushkin group",
      "Dihedral group of order 6",
      "Eisenstein's criterion",
      "Encyclopedia of Mathematics",
      "Euler's totient function",
      "European Mathematical Society",
      "Field (mathematics)",
      "Field extension",
      "Finite field",
      "Frobenius homomorphism",
      "Function composition",
      "Fundamental theorem of Galois theory",
      "Galois closure",
      "Galois extension",
      "Galois fields",
      "Galois representation",
      "Galois theory",
      "Global field",
      "Graduate Texts in Mathematics",
      "Group (mathematics)",
      "ISBN (identifier)",
      "Inverse limit",
      "Irreducible polynomial",
      "Isomorphism",
      "Klein four-group",
      "Kronecker–Weber theorem",
      "Krull topology",
      "Local field",
      "MR (identifier)",
      "Mathematics",
      "Nathan Jacobson",
      "Normal extension",
      "Normal subgroup",
      "Order theory",
      "Permutation group",
      "Polynomial",
      "Profinite group",
      "Quaternion group",
      "Rational number",
      "Real number"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Galois theory",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Affine algebraic set": {
    "title": "Affine variety",
    "url": "https://en.wikipedia.org/wiki/Affine_variety",
    "summary": "In algebraic geometry, an affine variety or affine algebraic variety is a certain kind of algebraic variety that can be described as a subset of an affine space.\nMore formally, an affine algebraic set is the set of the common zeros over an algebraically closed field k of some family of polynomials in the polynomial ring \n  \n    \n      \n        k\n        [\n        \n          x\n          \n            1\n          \n        \n        ,\n        …\n        ,\n        \n          x\n          \n            n\n          \n        \n        ]\n        .\n      \n    \n    {\\displaystyle k[x_{1},\\ldots ,x_{n}].}\n  \n An affine variety is an affine algebraic set which is not the union of two smaller algebraic sets; algebraically, this means that (the radical of) the ideal generated by the defining polynomials is prime. One-dimensional affine varieties are called affine algebraic curves, while two-dimensional ones are affine algebraic surfaces.\nSome texts use the term variety for any algebraic set, and irreducib",
    "content": "In algebraic geometry, an affine variety or affine algebraic variety is a certain kind of algebraic variety that can be described as a subset of an affine space.\nMore formally, an affine algebraic set is the set of the common zeros over an algebraically closed field k of some family of polynomials in the polynomial ring \n  \n    \n      \n        k\n        [\n        \n          x\n          \n            1\n          \n        \n        ,\n        …\n        ,\n        \n          x\n          \n            n\n          \n        \n        ]\n        .\n      \n    \n    {\\displaystyle k[x_{1},\\ldots ,x_{n}].}\n  \n An affine variety is an affine algebraic set which is not the union of two smaller algebraic sets; algebraically, this means that (the radical of) the ideal generated by the defining polynomials is prime. One-dimensional affine varieties are called affine algebraic curves, while two-dimensional ones are affine algebraic surfaces.\nSome texts use the term variety for any algebraic set, and irreducible variety an algebraic set whose defining ideal is prime (affine variety in the above sense).\nIn some contexts (see, for example, Hilbert's Nullstellensatz), it is useful to distinguish the field k in which the coefficients are considered, from the  algebraically closed field K (containing k) over which the common zeros are considered (that is, the points of the affine algebraic set are in Kn). In this case, the variety is said defined over k, and the points of the variety that belong to kn are said k-rational or rational over k. In the common case where k is the field of real numbers, a k-rational point is called a real point. When the field k is not specified, a rational point is a point that is rational over the rational numbers. For example, Fermat's Last Theorem asserts that the affine algebraic variety (it is a curve) defined by xn + yn − 1 = 0 has no rational points for any integer n greater than two.\n\nIntroduction\nAn affine algebraic set is the set of solutions in an algebraically closed field k of a system of polynomial equations with coefficients in k. More precisely, if \n  \n    \n      \n        \n          f\n          \n            1\n          \n        \n        ,\n        …\n        ,\n        \n          f\n          \n            m\n          \n        \n      \n    \n    {\\displaystyle f_{1},\\ldots ,f_{m}}\n  \n are polynomials with coefficients in k, they define an affine algebraic set \n\n  \n    \n      \n        V\n        (\n        \n          f\n          \n            1\n          \n        \n        ,\n        …\n        ,\n        \n          f\n          \n            m\n          \n        \n        )\n        =\n        \n          {\n          \n            (\n            \n              a\n              \n                1\n              \n            \n            ,\n            …\n            ,\n            \n              a\n              \n                n\n              \n            \n            )\n            ∈\n            \n              k\n              \n                n\n              \n            \n            \n            \n              |\n            \n            \n            \n              f\n              \n                1\n              \n            \n            (\n            \n              a\n              \n                1\n              \n            \n            ,\n            …\n            ,\n            \n              a\n              \n                n\n              \n            \n            )\n            =\n            …\n            =\n            \n              f\n              \n                m\n              \n            \n            (\n            \n              a\n              \n                1\n              \n            \n            ,\n            …\n            ,\n            \n              a\n              \n                n\n              \n            \n            )\n            =\n            0\n          \n          }\n        \n        .\n      \n    \n    {\\displaystyle V(f_{1},\\ldots ,f_{m})=\\left\\{(a_{1},\\ldots ,a_{n})\\in k^{n}\\;|\\;f_{1}(a_{1},\\ldots ,a_{n})=\\ldots =f_{m}(a_{1},\\ldots ,a_{n})=0\\right\\}.}\n  \n\nAn affine (algebraic) variety is an affine algebraic set that is not the union of two proper affine algebraic subsets. Such an affine algebraic set is often said to be irreducible. \nIf X is an affine algebraic set, and \n  \n    \n      \n        \n          I\n        \n        (\n        X\n        )\n      \n    \n    {\\displaystyle \\mathrm {I} (X)}\n  \n is the ideal of all polynomials that are zero on X, then the quotient ring \n  \n    \n      \n        A\n        (\n        X\n        )\n        =\n        k\n        [\n        \n          x\n          \n            1\n          \n        \n        ,\n        …\n        ,\n        \n          x\n          \n            n\n          \n        \n        ]\n        \n          /\n        \n        \n          I\n        \n        (\n        X\n        )\n      \n    \n    {\\displaystyle A(X)=k[x_{1},\\ldots ,x_{n}]/\\mathrm {I} (X)}\n  \n (also denoted \n  \n    \n      \n        Γ\n        (\n        X\n        )\n      \n    \n    {\\displaystyle \\",
    "links": [
      "Affine scheme",
      "Affine space",
      "Affine subspace",
      "Algebraic Geometry (book)",
      "Algebraic curve",
      "Algebraic curves",
      "Algebraic geometry",
      "Algebraic group",
      "Algebraic surface",
      "Algebraic varieties",
      "Algebraic variety",
      "Algebraic vector bundle",
      "Algebraically closed field",
      "Associativity",
      "Base (topology)",
      "Basis (linear algebra)",
      "Cartan's theorem B",
      "Category (mathematics)",
      "Circle",
      "Classification of finite simple groups",
      "Cohomological",
      "Complex analysis",
      "Cubic plane curve",
      "David Mumford",
      "Dense set",
      "Dimension of an algebraic variety",
      "Doi (identifier)",
      "Dual (category theory)",
      "Equivalence of categories",
      "Fermat's Last Theorem",
      "Field (mathematics)",
      "Finite field",
      "General linear group",
      "Generic point",
      "Glossary of algebraic geometry",
      "Graduate Texts in Mathematics",
      "Group (mathematics)",
      "Group of Lie type",
      "Hartogs' extension theorem",
      "Hilbert's Nullstellensatz",
      "Hilbert's nullstellensatz",
      "Hilbert nullstellensatz",
      "Hypersurface",
      "ISBN (identifier)",
      "Ideal (ring theory)",
      "Integral closure",
      "Integral domain",
      "Irreducible component",
      "Jacobian matrix",
      "James Milne (mathematician)"
    ],
    "categories": [
      "Category:Algebraic geometry",
      "Category:Articles with short description",
      "Category:Short description matches Wikidata"
    ]
  },
  "Affinity space": {
    "title": "Affinity space",
    "url": "https://en.wikipedia.org/wiki/Affinity_space",
    "summary": "An affinity space is a place where learning happens.  According to James Paul Gee, affinity spaces are locations where groups of people are drawn together because of a shared, strong interest or engagement in a common activity. Often but not always occurring online, affinity spaces encourage the sharing of knowledge or participation in a specific area, and informal learning is a common outcome. In his coining of the term, Gee takes the notion of participatory cultures, and reframes it to the idea of \"space\". To Gee, what is happening in these online cultures is not merely a \"culture\" – and far different from a \"community\". In Gee's view, the word \"community\" conjures up images of belongingness  and membership (p. 70). Instead, he has defined these worlds as \"spaces\" – a term that allows for the \"robust characterization of the ebbs and flows and differing levels of involvement and participation exhibited by members\" \nAccording to Gee (2004), \"An affinity space is a place or set of place",
    "content": "An affinity space is a place where learning happens.  According to James Paul Gee, affinity spaces are locations where groups of people are drawn together because of a shared, strong interest or engagement in a common activity. Often but not always occurring online, affinity spaces encourage the sharing of knowledge or participation in a specific area, and informal learning is a common outcome. In his coining of the term, Gee takes the notion of participatory cultures, and reframes it to the idea of \"space\". To Gee, what is happening in these online cultures is not merely a \"culture\" – and far different from a \"community\". In Gee's view, the word \"community\" conjures up images of belongingness  and membership (p. 70). Instead, he has defined these worlds as \"spaces\" – a term that allows for the \"robust characterization of the ebbs and flows and differing levels of involvement and participation exhibited by members\" \nAccording to Gee (2004), \"An affinity space is a place or set of places where people affiliate with others based primarily on shared activities, interests, and goals, not shared race, class culture, ethnicity, or gender\" (p. 67).\nGee (2004) refers to affinity spaces and states, \"Learners 'apprentice' themselves to a group of people who share a certain set of practices (e.g. learning to cook in a family, learning to play video games with a guild, learning to assemble circuit boards in a workplace, learning to splice genes in a biology lab), pick up these practices through joint action with more advanced peers, and advance their abilities to engage and work with others in carrying out such practices\" (p. 70).\nWhat Gee (2004) tries to explain about Affinity Spaces is not an attempt to label a group of people. By affinity space, he means a space where people can interact and share a lot with each other. The people who are interacting in a space might find themselves as sharing a community with some others in that space, while other people might view their interactions in the space differently. Gee (2004) adds, \" In any case, creating spaces within diverse sorts of people can interact is a leitmotif of the modern world\" (p. 71).\n\nHallmarks of Affinity Spaces\nGee described twelve hallmarks of what he terms \"nurturing\" affinity spaces:\n\nThe affinity in these spaces is to the endeavor, not other people. People from all ages, ethnicities, educational levels, and cultures play/create together – often anonymously or using alter-identities.\nNot segregated by age; there is no assumption that older or more senior participants are the only ones with something to teach.\nNot segregated by experience; newbies, masters, and everyone else share a common space.\nEveryone can, if they so wish, produce and not just consume. The idea that creation can come not only from a space's designers, but also from its users, is a hallmark of these spaces. Users – not just site designers – can help create, shape, and reshape the site and its content. Suggestions are welcome and encouraged, and site designers often use the suggestions of users to reform site designs and configurations.\nContent within the space is not fixed, but is transformed by interaction.\nBoth intensive and extensive knowledge are encouraged. Extensive knowledge is seen as broad, less specialized knowledge about many aspects of the space. Intensive knowledge is in-depth knowledge about certain aspects of the space.\nIndividual and distributed knowledge are valued.\nDispersed knowledge is encouraged.\nTacit knowledge is encouraged and honored. Members do not have to lead or design; those who wish to “just play” are valued as much as those who wish to contribute more substantially to the site.\nMany forms and routes to participation are available.\nDifferent routes to status are inherent in the game.\nLeadership is porous and leaders are resources.\n\nEducational uses\nBecause members of an affinity space are interested in a common practice/belief/activity, they have common ground and motivation together. Gee says that because of this common interest, affinity spaces are able to bridge barriers of age, race, socio-economic status, and educational level, and thus allow each user to participate as he/she chooses, and both experts and novices are equally legitimate participants in the affinity space  While not everyone in affinity spaces is an expert, they are not places where the \"blind are leading the blind.\"  Many spaces have unwritten rules that while sharing information, you must share only what you know, provide sources to back up what you say, and in general, leave feedback and comments only in areas you know.\n\nExamples\nOnline fan fiction sites are examples of affinity spaces.  While the goal of the sites is usually to share and read other people's fan fiction creations, informal learning takes place as people have their work read and commented on by \"'beta readers.'\"  It is up to the author then to decide what to do with this informal feedback; often, it is used to re",
    "links": [
      "Affine space",
      "Benjamin Bloom",
      "Dispersed knowledge",
      "Doi (identifier)",
      "Fan fiction",
      "Feedback",
      "Henry Jenkins",
      "Higher order thinking skills",
      "ISBN (identifier)",
      "Image editing",
      "James Paul Gee",
      "Learning",
      "Logic",
      "Race (classification of human beings)",
      "Rhetoric",
      "S. Bensen",
      "Socio-economic",
      "Tacit knowledge",
      "Wayback Machine",
      "Wikipedia:Citing sources",
      "Wikipedia:Please clarify"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Educational environment",
      "Category:Game design",
      "Category:Short description is different from Wikidata",
      "Category:Webarchive template wayback links",
      "Category:Wikipedia articles needing clarification from April 2010",
      "Category:Wikipedia articles needing page number citations from June 2016"
    ]
  },
  "Associated vector bundle": {
    "title": "Associated bundle",
    "url": "https://en.wikipedia.org/wiki/Associated_bundle",
    "summary": "In mathematics, the theory of fiber bundles with a structure group \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n (a topological group) allows an operation of creating an associated bundle, in which the typical fiber of a bundle changes from \n  \n    \n      \n        \n          F\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle F_{1}}\n  \n to \n  \n    \n      \n        \n          F\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle F_{2}}\n  \n, which are both topological spaces with a group action of \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n.  For a fiber bundle \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n with structure group \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n, the transition functions of the fiber (i.e., the cocycle) in an overlap of two coordinate systems \n  \n    \n      \n        \n          U\n          \n            α\n          \n        \n      \n    \n    {",
    "content": "In mathematics, the theory of fiber bundles with a structure group \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n (a topological group) allows an operation of creating an associated bundle, in which the typical fiber of a bundle changes from \n  \n    \n      \n        \n          F\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle F_{1}}\n  \n to \n  \n    \n      \n        \n          F\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle F_{2}}\n  \n, which are both topological spaces with a group action of \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n.  For a fiber bundle \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n with structure group \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n, the transition functions of the fiber (i.e., the cocycle) in an overlap of two coordinate systems \n  \n    \n      \n        \n          U\n          \n            α\n          \n        \n      \n    \n    {\\displaystyle U_{\\alpha }}\n  \n and \n  \n    \n      \n        \n          U\n          \n            β\n          \n        \n      \n    \n    {\\displaystyle U_{\\beta }}\n  \n are given as a \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n-valued function \n  \n    \n      \n        \n          g\n          \n            α\n            β\n          \n        \n      \n    \n    {\\displaystyle g_{\\alpha \\beta }}\n  \n on \n  \n    \n      \n        \n          U\n          \n            α\n          \n        \n        ∩\n        \n          U\n          \n            β\n          \n        \n      \n    \n    {\\displaystyle U_{\\alpha }\\cap U_{\\beta }}\n  \n.  One may then construct a fiber bundle \n  \n    \n      \n        \n          F\n          ′\n        \n      \n    \n    {\\displaystyle F'}\n  \n as a new fiber bundle having the same transition functions, but possibly a different fiber.\n\nAn example\nA simple case comes with the Möbius strip, for which \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n is the cyclic group of order 2, \n  \n    \n      \n        \n          \n            Z\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {Z} _{2}}\n  \n. We can take \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n to be any of the following: the real number line \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n, the interval \n  \n    \n      \n        [\n        −\n        1\n        ,\n         \n        1\n        ]\n      \n    \n    {\\displaystyle [-1,\\ 1]}\n  \n, the real number line less the point 0, or the two-point set \n  \n    \n      \n        {\n        −\n        1\n        ,\n         \n        1\n        }\n      \n    \n    {\\displaystyle \\{-1,\\ 1\\}}\n  \n. The action of \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n on these (the non-identity element acting as \n  \n    \n      \n        x\n         \n        →\n         \n        −\n        x\n      \n    \n    {\\displaystyle x\\ \\rightarrow \\ -x}\n  \n in each case) is comparable, in an intuitive sense. We could say that more formally in terms of gluing two rectangles \n  \n    \n      \n        [\n        −\n        1\n        ,\n         \n        1\n        ]\n        ×\n        I\n      \n    \n    {\\displaystyle [-1,\\ 1]\\times I}\n  \n and \n  \n    \n      \n        [\n        −\n        1\n        ,\n         \n        1\n        ]\n        ×\n        J\n      \n    \n    {\\displaystyle [-1,\\ 1]\\times J}\n  \n together: what we really need is the data to identify \n  \n    \n      \n        [\n        −\n        1\n        ,\n         \n        1\n        ]\n      \n    \n    {\\displaystyle [-1,\\ 1]}\n  \n to itself directly at one end, and with the twist over at the other end. This data can be written down as a patching function, with values in \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n. The associated bundle construction is just the observation that this data does just as well for \n  \n    \n      \n        {\n        −\n        1\n        ,\n         \n        1\n        }\n      \n    \n    {\\displaystyle \\{-1,\\ 1\\}}\n  \n as for \n  \n    \n      \n        [\n        −\n        1\n        ,\n         \n        1\n        ]\n      \n    \n    {\\displaystyle [-1,\\ 1]}\n  \n.\n\nConstruction\nIn general it is enough to explain the transition from a bundle with fiber \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n, on which \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n acts, to the associated principal bundle (namely the bundle where the fiber is \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n, considered to act by translation on itself). For then we can go from \n  \n    \n      \n        \n          F\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle F_{1}}\n  \n to \n  \n    \n      \n        \n          F\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle F_{2}}\n  \n, via the principal bundle.  Details in terms of data for an open covering are given as a case of descent.\nThis ",
    "links": [
      "Adjoint bundle",
      "Affine bundle",
      "Affine connection",
      "Almost-contact manifold",
      "Almost complex manifold",
      "Almost flat manifold",
      "Almost symplectic manifold",
      "Atiyah–Singer index theorem",
      "Atlas (topology)",
      "Banach manifold",
      "Bundle map",
      "Cartan connection",
      "Category theory",
      "Charles Ehresmann",
      "Classification of manifolds",
      "Closed and exact differential forms",
      "Closed manifold",
      "Cocycle (algebraic topology)",
      "Coequalizer",
      "Cofibration",
      "Collapsing manifold",
      "Complete manifold",
      "Complex manifold",
      "Connection (fibred manifold)",
      "Connection (mathematics)",
      "Connection (principal bundle)",
      "Connection (vector bundle)",
      "Connection form",
      "Contact manifold",
      "Cotangent bundle",
      "Cotangent space",
      "Covariant derivative",
      "Cyclic group",
      "Dale Husemoller",
      "Darboux's theorem",
      "De Rham cohomology",
      "Descent (category theory)",
      "Diffeology",
      "Diffeomorphism",
      "Differentiable curve",
      "Differentiable manifold",
      "Differential calculus over commutative algebras",
      "Differential form",
      "Differential structure",
      "Diffiety",
      "Distribution (differential geometry)",
      "Dual bundle",
      "Ehresmann connection",
      "Exponential map (Lie theory)",
      "Exponential map (Riemannian geometry)"
    ],
    "categories": [
      "Category:Algebraic topology",
      "Category:Articles with short description",
      "Category:CS1 errors: ISBN date",
      "Category:Differential geometry",
      "Category:Differential topology",
      "Category:Fiber bundles",
      "Category:Short description matches Wikidata"
    ]
  },
  "Chart (topology)": {
    "title": "Atlas (topology)",
    "url": "https://en.wikipedia.org/wiki/Atlas_(topology)",
    "summary": "In mathematics, particularly topology, an atlas is a concept used to describe a manifold. An atlas consists of individual charts that, roughly speaking, describe individual regions of the manifold. In general, the notion of atlas underlies the formal definition of a manifold and related structures such as vector bundles and other fiber bundles.",
    "content": "In mathematics, particularly topology, an atlas is a concept used to describe a manifold. An atlas consists of individual charts that, roughly speaking, describe individual regions of the manifold. In general, the notion of atlas underlies the formal definition of a manifold and related structures such as vector bundles and other fiber bundles.\n\nCharts\nThe definition of an atlas depends on the notion of a chart. A chart for a topological space M is a homeomorphism \n  \n    \n      \n        φ\n      \n    \n    {\\displaystyle \\varphi }\n  \n from an open subset U of M to an open subset of a Euclidean space. The chart is traditionally recorded as the ordered pair \n  \n    \n      \n        (\n        U\n        ,\n        φ\n        )\n      \n    \n    {\\displaystyle (U,\\varphi )}\n  \n.\nWhen a coordinate system is chosen in the Euclidean space, this defines coordinates on \n  \n    \n      \n        U\n      \n    \n    {\\displaystyle U}\n  \n: the coordinates of a point \n  \n    \n      \n        P\n      \n    \n    {\\displaystyle P}\n  \n of \n  \n    \n      \n        U\n      \n    \n    {\\displaystyle U}\n  \n are defined as the coordinates of \n  \n    \n      \n        φ\n        (\n        P\n        )\n        .\n      \n    \n    {\\displaystyle \\varphi (P).}\n  \n The pair formed by a chart and such a coordinate system is called a local coordinate system, coordinate chart, coordinate patch, coordinate map, or local frame.\n\nFormal definition of atlas\nAn atlas for a topological space \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n  \n is an indexed family \n  \n    \n      \n        {\n        (\n        \n          U\n          \n            α\n          \n        \n        ,\n        \n          φ\n          \n            α\n          \n        \n        )\n        :\n        α\n        ∈\n        I\n        }\n      \n    \n    {\\displaystyle \\{(U_{\\alpha },\\varphi _{\\alpha }):\\alpha \\in I\\}}\n  \n of charts on \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n  \n which covers \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n  \n (that is, \n  \n    \n      \n        \n          ⋃\n          \n            α\n            ∈\n            I\n          \n        \n        \n          U\n          \n            α\n          \n        \n        =\n        M\n      \n    \n    {\\textstyle \\bigcup _{\\alpha \\in I}U_{\\alpha }=M}\n  \n). If for some fixed n, the image of each chart is an open subset of n-dimensional Euclidean space, then \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n  \n is said to be an n-dimensional manifold. \nThe plural of atlas is atlases, although some authors use atlantes.\nAn atlas \n  \n    \n      \n        \n          \n            (\n            \n              \n                U\n                \n                  i\n                \n              \n              ,\n              \n                φ\n                \n                  i\n                \n              \n            \n            )\n          \n          \n            i\n            ∈\n            I\n          \n        \n      \n    \n    {\\displaystyle \\left(U_{i},\\varphi _{i}\\right)_{i\\in I}}\n  \n on an \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n-dimensional manifold \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n  \n is called an adequate atlas if the following conditions hold:\n\nThe image of each chart is either \n  \n    \n      \n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{n}}\n  \n or \n  \n    \n      \n        \n          \n            R\n          \n          \n            +\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} _{+}^{n}}\n  \n, where \n  \n    \n      \n        \n          \n            R\n          \n          \n            +\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} _{+}^{n}}\n  \n is the closed half-space,\n\n  \n    \n      \n        \n          \n            (\n            \n              U\n              \n                i\n              \n            \n            )\n          \n          \n            i\n            ∈\n            I\n          \n        \n      \n    \n    {\\displaystyle \\left(U_{i}\\right)_{i\\in I}}\n  \n is a locally finite open cover of \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n  \n, and\n\n  \n    \n      \n        M\n        =\n        \n          ⋃\n          \n            i\n            ∈\n            I\n          \n        \n        \n          φ\n          \n            i\n          \n          \n            −\n            1\n          \n        \n        \n          (\n          \n            B\n            \n              1\n            \n          \n          )\n        \n      \n    \n    {\\textstyle M=\\bigcup _{i\\in I}\\varphi _{i}^{-1}\\left(B_{1}\\right)}\n  \n, where \n  \n    \n      \n        \n          B\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle B_{1}}\n  \n is the open ball of radius 1 centered at the origin.\nEvery second-countable manifold admits an adequate atla",
    "links": [
      "Academic Press",
      "Adjoint bundle",
      "Affine bundle",
      "Affine connection",
      "Almost-contact manifold",
      "Almost complex manifold",
      "Almost flat manifold",
      "Almost symplectic manifold",
      "Associated bundle",
      "Atiyah–Singer index theorem",
      "Atlas (disambiguation)",
      "Banach manifold",
      "Cartan connection",
      "Classification of manifolds",
      "Closed and exact differential forms",
      "Closed half-space",
      "Closed manifold",
      "Cofibration",
      "Collapsing manifold",
      "Complete manifold",
      "Complex manifold",
      "Connection (fibred manifold)",
      "Connection (mathematics)",
      "Connection (principal bundle)",
      "Connection (vector bundle)",
      "Connection form",
      "Contact manifold",
      "Cotangent bundle",
      "Cotangent space",
      "Covariant derivative",
      "Cover (topology)",
      "Darboux's theorem",
      "De Rham cohomology",
      "Diffeology",
      "Diffeomorphism",
      "Differentiable curve",
      "Differentiable function",
      "Differentiable manifold",
      "Differential calculus over commutative algebras",
      "Differential form",
      "Differential structure",
      "Differentiation (mathematics)",
      "Diffiety",
      "Directional derivative",
      "Distribution (differential geometry)",
      "Domain of a function",
      "Dual bundle",
      "Ehresmann connection",
      "Empty set",
      "Euclidean space"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1 German-language sources (de)",
      "Category:Manifolds",
      "Category:Short description is different from Wikidata",
      "Category:Wikipedia articles needing clarification from May 2024"
    ]
  },
  "Coarser topology": {
    "title": "Comparison of topologies",
    "url": "https://en.wikipedia.org/wiki/Comparison_of_topologies",
    "summary": "In topology and related areas of mathematics, the set of all possible topologies on a given set forms a partially ordered set. This order relation can be used for comparison of the topologies.",
    "content": "In topology and related areas of mathematics, the set of all possible topologies on a given set forms a partially ordered set. This order relation can be used for comparison of the topologies.\n\nDefinition\nA topology on a set may be defined as the collection of subsets which are considered to be \"open\". (An alternative definition is that it is the collection of subsets which are considered \"closed\". These two ways of defining the topology are essentially equivalent because the complement of an open set is closed and vice versa. In the following, it doesn't matter which definition is used.) \nFor definiteness the reader should think of a topology as the family of open sets of a topological space, since that is the standard meaning of the word \"topology\".\nLet τ1 and τ2 be two topologies on a set X such that τ1 is contained in τ2:\n\n  \n    \n      \n        \n          τ\n          \n            1\n          \n        \n        ⊆\n        \n          τ\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\tau _{1}\\subseteq \\tau _{2}}\n  \n.\nThat is, every element of τ1 is also an element of τ2. Then the topology τ1 is said to be a coarser (weaker or smaller) topology than τ2, and  τ2 is said to be a finer (stronger or larger) topology than τ1.\n\nIf additionally \n\n  \n    \n      \n        \n          τ\n          \n            1\n          \n        \n        ≠\n        \n          τ\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\tau _{1}\\neq \\tau _{2}}\n  \n\nwe say τ1 is strictly coarser than  τ2 and τ2 is strictly finer than τ1.\nThe binary relation ⊆ defines a partial ordering relation on the set of all possible topologies on X.\n\nExamples\nThe finest topology on X is the discrete topology; this topology makes all subsets open.  The coarsest topology on X is the trivial topology; this topology only admits the empty set\nand the whole space as open sets.\nIn function spaces and spaces of measures there are often a number of possible topologies. See topologies on the set of operators on a Hilbert space for some intricate relationships.\nAll possible polar topologies on a dual pair are finer than the weak topology and coarser than the strong topology.\nThe complex vector space Cn may be equipped with either its usual (Euclidean) topology, or its Zariski topology. In the latter, a subset V of Cn is closed if and only if it consists of all solutions to some system of polynomial equations. Since any such V also is a closed set in the ordinary sense, but not vice versa, the Zariski topology is strictly weaker than the ordinary one.\n\nProperties\nLet τ1 and τ2 be two topologies on a set X. Then the following statements are equivalent:\n\nτ1 ⊆ τ2\nthe identity map idX : (X, τ2) → (X, τ1) is a continuous map.\nthe identity map idX : (X, τ1) → (X, τ2) is a strongly/relatively open map.\n(The identity map idX is surjective and therefore it is strongly open if and only if it is relatively open.)\nTwo immediate corollaries of the above equivalent statements are\n\nA continuous map f : X → Y remains continuous if the topology on Y becomes coarser or the topology on X finer.\nAn open (resp. closed) map f : X → Y remains open (resp. closed) if the topology on Y becomes finer or the topology on X coarser.\nOne can also compare topologies using neighborhood bases. Let τ1 and τ2 be two topologies on a set X and let Bi(x) be a local base for the topology τi at x ∈ X for i = 1,2. Then τ1 ⊆ τ2 if and only if for all x ∈ X, each open set U1 in B1(x) contains some open set U2 in B2(x). Intuitively, this makes sense: a finer topology should have smaller neighborhoods.\n\nLattice of topologies\nThe set of all topologies on a set X together with the partial ordering relation ⊆ forms a complete lattice that is also closed under arbitrary intersections.  That is, any collection of topologies on X have a meet (or infimum) and a join (or supremum). The meet of a collection of topologies is the intersection of those topologies. The join, however, is not generally the union of those topologies (the union of two topologies need not be a topology) but rather the topology generated by the union.\nEvery complete lattice is also a bounded lattice, which is to say that it has a greatest and least element. In the case of topologies, the greatest element is the discrete topology and the least element is the trivial topology.\nThe lattice of topologies on a set \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is a complemented lattice; that is, given a topology \n  \n    \n      \n        τ\n      \n    \n    {\\displaystyle \\tau }\n  \n on \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n there exists a topology \n  \n    \n      \n        \n          τ\n          ′\n        \n      \n    \n    {\\displaystyle \\tau '}\n  \n on \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n such that the intersection \n  \n    \n      \n        τ\n        ∩\n        \n          τ\n          ′\n        \n      \n    \n    {\\displaystyle \\tau \\cap \\tau '}\n ",
    "links": [
      "Binary relation",
      "Bounded lattice",
      "Complement (set theory)",
      "Complemented lattice",
      "Complete lattice",
      "Complex coordinate space",
      "Continuous map (topology)",
      "Discrete topology",
      "Distributive lattice",
      "Doi (identifier)",
      "Dual pair",
      "Final topology",
      "Function space",
      "Greatest element",
      "ISBN (identifier)",
      "Identity function",
      "Infimum",
      "Initial topology",
      "Intersection (set theory)",
      "James Munkres",
      "Least element",
      "Mathematical analysis",
      "Mathematics",
      "Measure (mathematics)",
      "Modular lattice",
      "Neighborhood base",
      "OCLC (identifier)",
      "Open map",
      "Open set",
      "Order relation",
      "Partial ordering relation",
      "Partially ordered set",
      "Polar topology",
      "Prentice Hall, Inc",
      "Strong topology (polar topology)",
      "Subbase",
      "Subset",
      "Supremum",
      "Surjective function",
      "Topologies on the set of operators on a Hilbert space",
      "Topology",
      "Trivial topology",
      "Union (set theory)",
      "Upper Saddle River, NJ",
      "Weak topology (polar topology)",
      "Zariski topology"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Comparison (mathematical)",
      "Category:General topology",
      "Category:Pages with references accessible to Internet Archive patrons with print disabilities",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Column space": {
    "title": "Row and column spaces",
    "url": "https://en.wikipedia.org/wiki/Row_and_column_spaces",
    "summary": "In linear algebra, the column space (also called the range or image) of a matrix A is the span (set of all possible linear combinations) of its column vectors. The column space of a matrix is the image or range of the corresponding matrix transformation.\nLet \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n be a field. The column space of an m × n matrix with components from \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n is a linear subspace of the m-space \n  \n    \n      \n        \n          F\n          \n            m\n          \n        \n      \n    \n    {\\displaystyle F^{m}}\n  \n.  The dimension of the column space is called the rank of the matrix and is at most min(m, n). A definition for matrices over a ring \n  \n    \n      \n        R\n      \n    \n    {\\displaystyle R}\n  \n is also possible.\nThe row space is defined similarly.\nThe row space and the column space of a matrix A are sometimes denoted as C(AT) and C(A) respectively.\nThis article considers matrice",
    "content": "In linear algebra, the column space (also called the range or image) of a matrix A is the span (set of all possible linear combinations) of its column vectors. The column space of a matrix is the image or range of the corresponding matrix transformation.\nLet \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n be a field. The column space of an m × n matrix with components from \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n is a linear subspace of the m-space \n  \n    \n      \n        \n          F\n          \n            m\n          \n        \n      \n    \n    {\\displaystyle F^{m}}\n  \n.  The dimension of the column space is called the rank of the matrix and is at most min(m, n). A definition for matrices over a ring \n  \n    \n      \n        R\n      \n    \n    {\\displaystyle R}\n  \n is also possible.\nThe row space is defined similarly.\nThe row space and the column space of a matrix A are sometimes denoted as C(AT) and C(A) respectively.\nThis article considers matrices of real numbers.  The row and column spaces are subspaces of the real spaces \n  \n    \n      \n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{n}}\n  \n and \n  \n    \n      \n        \n          \n            R\n          \n          \n            m\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{m}}\n  \n respectively.\n\nOverview\nLet A be an m-by-n matrix. Then\n\nrank(A) = dim(rowsp(A)) = dim(colsp(A)),\nrank(A) = number of pivots in any echelon form of A,\nrank(A) = the maximum number of linearly independent rows or columns of A.\nIf the matrix represents a linear transformation, the column space of the matrix equals the image of this linear transformation.\nThe column space of a matrix A is the set of all linear combinations of the columns in A.  If A = [a1 ⋯ an], then colsp(A) = span({a1, ..., an}).\nGiven a matrix A, the action of the matrix A on a vector x returns a linear combination of the columns of A with the coordinates of x as coefficients; that is, the columns of the matrix generate the column space.\n\nExample\nGiven a matrix J:\n\n  \n    \n      \n        J\n        =\n        \n          \n            [\n            \n              \n                \n                  2\n                \n                \n                  4\n                \n                \n                  1\n                \n                \n                  3\n                \n                \n                  2\n                \n              \n              \n                \n                  −\n                  1\n                \n                \n                  −\n                  2\n                \n                \n                  1\n                \n                \n                  0\n                \n                \n                  5\n                \n              \n              \n                \n                  1\n                \n                \n                  6\n                \n                \n                  2\n                \n                \n                  2\n                \n                \n                  2\n                \n              \n              \n                \n                  3\n                \n                \n                  6\n                \n                \n                  2\n                \n                \n                  5\n                \n                \n                  1\n                \n              \n            \n            ]\n          \n        \n      \n    \n    {\\displaystyle J={\\begin{bmatrix}2&4&1&3&2\\\\-1&-2&1&0&5\\\\1&6&2&2&2\\\\3&6&2&5&1\\end{bmatrix}}}\n  \n\nthe rows are\n\n  \n    \n      \n        \n          \n            r\n          \n          \n            1\n          \n        \n        =\n        \n          \n            [\n            \n              \n                \n                  2\n                \n                \n                  4\n                \n                \n                  1\n                \n                \n                  3\n                \n                \n                  2\n                \n              \n            \n            ]\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {r} _{1}={\\begin{bmatrix}2&4&1&3&2\\end{bmatrix}}}\n  \n,\n\n  \n    \n      \n        \n          \n            r\n          \n          \n            2\n          \n        \n        =\n        \n          \n            [\n            \n              \n                \n                  −\n                  1\n                \n                \n                  −\n                  2\n                \n                \n                  1\n                \n                \n                  0\n                \n                \n                  5\n                \n              \n            \n            ]\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {r} _{2}={\\begin{bmatrix}-1&-2&1&0&5\\end{bmatrix}}}\n  \n,\n\n  \n    \n      \n        \n          \n            r\n          \n          \n            3\n          \n        \n      ",
    "links": [
      "Basic Linear Algebra Subprograms",
      "Basis (linear algebra)",
      "Bilinear map",
      "Bivector",
      "Block matrix",
      "Cartesian coordinates",
      "Change of basis",
      "Characteristic (algebra)",
      "Coimage",
      "Column space",
      "Column vector",
      "Commutative ring",
      "Comparison of linear algebra libraries",
      "Cramer's rule",
      "Cross product",
      "Determinant",
      "Dimension (linear algebra)",
      "Direct sum of modules",
      "Dot product",
      "Dual space",
      "Eigenvalues and eigenvectors",
      "Elementary row operations",
      "Eric W. Weisstein",
      "Euclidean space",
      "Euclidean subspace",
      "Euclidean vector",
      "Examples of vector spaces",
      "Exterior algebra",
      "Field (mathematics)",
      "Floating-point arithmetic",
      "Four fundamental subspaces",
      "Free module",
      "Function space",
      "Gaussian elimination",
      "Geometric algebra",
      "Gilbert Strang",
      "Glossary of linear algebra",
      "Gram matrix",
      "Gram–Schmidt process",
      "Hadamard product (matrices)",
      "Houghton Mifflin Company",
      "ISBN (identifier)",
      "Image (mathematics)",
      "Inner product space",
      "Invertible matrix",
      "Isomorphism",
      "John Wiley & Sons",
      "Kernel (linear algebra)",
      "Kernel (matrix)",
      "Kronecker product"
    ],
    "categories": [
      "Category:Abstract algebra",
      "Category:Articles with short description",
      "Category:Linear algebra",
      "Category:Matrices (mathematics)",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Complementary subspace": {
    "title": "Direct sum of modules",
    "url": "https://en.wikipedia.org/wiki/Direct_sum_of_modules",
    "summary": "In abstract algebra, the direct sum is a construction which combines several modules into a new, larger module. The direct sum of modules is the smallest module which contains the given modules as submodules with no \"unnecessary\" constraints, making it an example of a coproduct. Contrast with the direct product, which is the dual notion.\nThe most familiar examples of this construction occur when considering vector spaces (modules over a field) and abelian groups (modules over the ring Z of integers). The construction may also be extended to cover Banach spaces and Hilbert spaces.\nSee the article decomposition of a module for a way to write a module as a direct sum of submodules.",
    "content": "In abstract algebra, the direct sum is a construction which combines several modules into a new, larger module. The direct sum of modules is the smallest module which contains the given modules as submodules with no \"unnecessary\" constraints, making it an example of a coproduct. Contrast with the direct product, which is the dual notion.\nThe most familiar examples of this construction occur when considering vector spaces (modules over a field) and abelian groups (modules over the ring Z of integers). The construction may also be extended to cover Banach spaces and Hilbert spaces.\nSee the article decomposition of a module for a way to write a module as a direct sum of submodules.\n\nConstruction for vector spaces and abelian groups\nWe give the construction first in these two cases, under the assumption that we have only two objects. Then we generalize to an arbitrary family of arbitrary modules. The key elements of the general construction are more clearly identified by considering these two cases in depth.\n\nConstruction for two vector spaces\nSuppose V and W are vector spaces over the field K. The Cartesian product V × W can be given the structure of a vector space over K (Halmos 1974, §18) by defining the operations componentwise:\n\n(v1, w1) + (v2, w2) = (v1 + v2, w1 + w2)\nα (v, w) = (α v, α w)\nfor v, v1, v2 ∈ V, w, w1, w2 ∈ W, and α ∈ K.\nThe resulting vector space is called the direct sum of V and W and is usually denoted by a plus symbol inside a circle:\n\n  \n    \n      \n        V\n        ⊕\n        W\n      \n    \n    {\\displaystyle V\\oplus W}\n  \n\nIt is customary to write the elements of an ordered sum not as ordered pairs (v, w), but as a sum v + w.\nThe subspace V × {0} of V ⊕ W is isomorphic to V and is often identified with V; similarly for {0} × W and W. (See internal direct sum below.) With this identification, every element of V ⊕ W can be written in one and only one way as the sum of an element of V and an element of W. The dimension of V ⊕ W is equal to the sum of the dimensions of V and W.  One elementary use is the reconstruction of a finite vector space from any subspace W and its orthogonal complement:  \n\n  \n    \n      \n        \n          \n            R\n          \n          \n            n\n          \n        \n        =\n        W\n        ⊕\n        \n          W\n          \n            ⊥\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{n}=W\\oplus W^{\\perp }}\n  \n\nThis construction readily generalizes to any finite number of vector spaces.\n\nConstruction for two abelian groups\nFor abelian groups G and H which are written additively, the direct product of G and H is also called a direct sum (Mac Lane & Birkhoff 1999, §V.6). Thus the Cartesian product G × H is equipped with the structure of an abelian group by defining the operations componentwise:\n\n(g1, h1) + (g2, h2) = (g1 + g2, h1 + h2)\nfor g1, g2 in G, and h1, h2 in H.\nIntegral multiples are similarly defined componentwise by\n\nn(g, h) = (ng, nh)\nfor g in G, h in H, and n an integer. This parallels the extension of the scalar product of vector spaces to the direct sum above.\nThe resulting abelian group is called the direct sum of G and H and is usually denoted by a plus symbol inside a circle:\n\n  \n    \n      \n        G\n        ⊕\n        H\n      \n    \n    {\\displaystyle G\\oplus H}\n  \n\nIt is customary to write the elements of an ordered sum not as ordered pairs (g, h), but as a sum g + h.\nThe subgroup G × {0} of G ⊕ H is isomorphic to G and is often identified with G; similarly for {0} × H and H. (See internal direct sum below.) With this identification, it is true that every element of G ⊕ H can be written in one and only one way as the sum of an element of G and an element of H. The rank of G ⊕ H is equal to the sum of the ranks of G and H.\nThis construction readily generalises to any finite number of abelian groups.\n\nConstruction for an arbitrary family of modules\nOne should notice a clear similarity between the definitions of the direct sum of two vector spaces and of two abelian groups. In fact, each is a special case of the construction of the direct sum of two modules. Additionally, by modifying the definition one can accommodate the direct sum of an infinite family of modules. The precise definition is as follows (Bourbaki 1989, §II.1.6).\nLet R be a ring, and {Mi : i ∈ I} a family of left R-modules indexed by the set I. The direct sum of {Mi} is then defined to be the set of all sequences \n  \n    \n      \n        (\n        \n          α\n          \n            i\n          \n        \n        )\n      \n    \n    {\\displaystyle (\\alpha _{i})}\n  \n where \n  \n    \n      \n        \n          α\n          \n            i\n          \n        \n        ∈\n        \n          M\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle \\alpha _{i}\\in M_{i}}\n  \n and \n  \n    \n      \n        \n          α\n          \n            i\n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle \\alpha _{i}=0}\n  \n for cofinitely many indices",
    "links": [
      "Abelian group",
      "Abstract algebra",
      "Algebra over a field",
      "Algebraic structure",
      "Associative",
      "Banach space",
      "Bilinear form",
      "Biproduct",
      "C0 space",
      "Cartesian product",
      "Category (category theory)",
      "Category theory",
      "Cofinitely many",
      "Commutative",
      "Compact support",
      "Complemented subspace",
      "Componentwise operation",
      "Coproduct",
      "Decomposition of a module",
      "Dimension of a vector space",
      "Direct product",
      "Direct sum",
      "Disjoint union",
      "Domain of a function",
      "Dual (category theory)",
      "Dual space",
      "Ergebnisse der Mathematik und ihrer Grenzgebiete",
      "Fiber bundle",
      "Field (mathematics)",
      "Finite set",
      "Function (mathematics)",
      "Garrett Birkhoff",
      "Grothendieck group",
      "Hilbert space",
      "Homomorphism",
      "Hypercomplex number",
      "ISBN (identifier)",
      "Iain T. Adamson",
      "Ian R. Porteous",
      "Indecomposable module",
      "Index set",
      "Indexed family",
      "Inner product",
      "Inner product space",
      "Integer",
      "Internal direct product",
      "Interval analysis",
      "James Cockle (lawyer)",
      "John Milnor",
      "Jordan–Hölder theorem"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Linear algebra",
      "Category:Module theory",
      "Category:Pages displaying short descriptions of redirect targets via Module:Annotated link",
      "Category:Short description matches Wikidata"
    ]
  },
  "Complementary subspaces": {
    "title": "Direct sum of modules",
    "url": "https://en.wikipedia.org/wiki/Direct_sum_of_modules",
    "summary": "In abstract algebra, the direct sum is a construction which combines several modules into a new, larger module. The direct sum of modules is the smallest module which contains the given modules as submodules with no \"unnecessary\" constraints, making it an example of a coproduct. Contrast with the direct product, which is the dual notion.\nThe most familiar examples of this construction occur when considering vector spaces (modules over a field) and abelian groups (modules over the ring Z of integers). The construction may also be extended to cover Banach spaces and Hilbert spaces.\nSee the article decomposition of a module for a way to write a module as a direct sum of submodules.",
    "content": "In abstract algebra, the direct sum is a construction which combines several modules into a new, larger module. The direct sum of modules is the smallest module which contains the given modules as submodules with no \"unnecessary\" constraints, making it an example of a coproduct. Contrast with the direct product, which is the dual notion.\nThe most familiar examples of this construction occur when considering vector spaces (modules over a field) and abelian groups (modules over the ring Z of integers). The construction may also be extended to cover Banach spaces and Hilbert spaces.\nSee the article decomposition of a module for a way to write a module as a direct sum of submodules.\n\nConstruction for vector spaces and abelian groups\nWe give the construction first in these two cases, under the assumption that we have only two objects. Then we generalize to an arbitrary family of arbitrary modules. The key elements of the general construction are more clearly identified by considering these two cases in depth.\n\nConstruction for two vector spaces\nSuppose V and W are vector spaces over the field K. The Cartesian product V × W can be given the structure of a vector space over K (Halmos 1974, §18) by defining the operations componentwise:\n\n(v1, w1) + (v2, w2) = (v1 + v2, w1 + w2)\nα (v, w) = (α v, α w)\nfor v, v1, v2 ∈ V, w, w1, w2 ∈ W, and α ∈ K.\nThe resulting vector space is called the direct sum of V and W and is usually denoted by a plus symbol inside a circle:\n\n  \n    \n      \n        V\n        ⊕\n        W\n      \n    \n    {\\displaystyle V\\oplus W}\n  \n\nIt is customary to write the elements of an ordered sum not as ordered pairs (v, w), but as a sum v + w.\nThe subspace V × {0} of V ⊕ W is isomorphic to V and is often identified with V; similarly for {0} × W and W. (See internal direct sum below.) With this identification, every element of V ⊕ W can be written in one and only one way as the sum of an element of V and an element of W. The dimension of V ⊕ W is equal to the sum of the dimensions of V and W.  One elementary use is the reconstruction of a finite vector space from any subspace W and its orthogonal complement:  \n\n  \n    \n      \n        \n          \n            R\n          \n          \n            n\n          \n        \n        =\n        W\n        ⊕\n        \n          W\n          \n            ⊥\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{n}=W\\oplus W^{\\perp }}\n  \n\nThis construction readily generalizes to any finite number of vector spaces.\n\nConstruction for two abelian groups\nFor abelian groups G and H which are written additively, the direct product of G and H is also called a direct sum (Mac Lane & Birkhoff 1999, §V.6). Thus the Cartesian product G × H is equipped with the structure of an abelian group by defining the operations componentwise:\n\n(g1, h1) + (g2, h2) = (g1 + g2, h1 + h2)\nfor g1, g2 in G, and h1, h2 in H.\nIntegral multiples are similarly defined componentwise by\n\nn(g, h) = (ng, nh)\nfor g in G, h in H, and n an integer. This parallels the extension of the scalar product of vector spaces to the direct sum above.\nThe resulting abelian group is called the direct sum of G and H and is usually denoted by a plus symbol inside a circle:\n\n  \n    \n      \n        G\n        ⊕\n        H\n      \n    \n    {\\displaystyle G\\oplus H}\n  \n\nIt is customary to write the elements of an ordered sum not as ordered pairs (g, h), but as a sum g + h.\nThe subgroup G × {0} of G ⊕ H is isomorphic to G and is often identified with G; similarly for {0} × H and H. (See internal direct sum below.) With this identification, it is true that every element of G ⊕ H can be written in one and only one way as the sum of an element of G and an element of H. The rank of G ⊕ H is equal to the sum of the ranks of G and H.\nThis construction readily generalises to any finite number of abelian groups.\n\nConstruction for an arbitrary family of modules\nOne should notice a clear similarity between the definitions of the direct sum of two vector spaces and of two abelian groups. In fact, each is a special case of the construction of the direct sum of two modules. Additionally, by modifying the definition one can accommodate the direct sum of an infinite family of modules. The precise definition is as follows (Bourbaki 1989, §II.1.6).\nLet R be a ring, and {Mi : i ∈ I} a family of left R-modules indexed by the set I. The direct sum of {Mi} is then defined to be the set of all sequences \n  \n    \n      \n        (\n        \n          α\n          \n            i\n          \n        \n        )\n      \n    \n    {\\displaystyle (\\alpha _{i})}\n  \n where \n  \n    \n      \n        \n          α\n          \n            i\n          \n        \n        ∈\n        \n          M\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle \\alpha _{i}\\in M_{i}}\n  \n and \n  \n    \n      \n        \n          α\n          \n            i\n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle \\alpha _{i}=0}\n  \n for cofinitely many indices",
    "links": [
      "Abelian group",
      "Abstract algebra",
      "Algebra over a field",
      "Algebraic structure",
      "Associative",
      "Banach space",
      "Bilinear form",
      "Biproduct",
      "C0 space",
      "Cartesian product",
      "Category (category theory)",
      "Category theory",
      "Cofinitely many",
      "Commutative",
      "Compact support",
      "Complemented subspace",
      "Componentwise operation",
      "Coproduct",
      "Decomposition of a module",
      "Dimension of a vector space",
      "Direct product",
      "Direct sum",
      "Disjoint union",
      "Domain of a function",
      "Dual (category theory)",
      "Dual space",
      "Ergebnisse der Mathematik und ihrer Grenzgebiete",
      "Fiber bundle",
      "Field (mathematics)",
      "Finite set",
      "Function (mathematics)",
      "Garrett Birkhoff",
      "Grothendieck group",
      "Hilbert space",
      "Homomorphism",
      "Hypercomplex number",
      "ISBN (identifier)",
      "Iain T. Adamson",
      "Ian R. Porteous",
      "Indecomposable module",
      "Index set",
      "Indexed family",
      "Inner product",
      "Inner product space",
      "Integer",
      "Internal direct product",
      "Interval analysis",
      "James Cockle (lawyer)",
      "John Milnor",
      "Jordan–Hölder theorem"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Linear algebra",
      "Category:Module theory",
      "Category:Pages displaying short descriptions of redirect targets via Module:Annotated link",
      "Category:Short description matches Wikidata"
    ]
  },
  "Complex affine space": {
    "title": "Complex affine space",
    "url": "https://en.wikipedia.org/wiki/Complex_affine_space",
    "summary": "Affine geometry, broadly speaking, is the study of the geometrical properties of lines, planes, and their higher dimensional analogs, in which a notion of \"parallel\" is retained, but no metrical notions of distance or angle are.  Affine spaces differ from linear spaces (that is, vector spaces) in that they do not have a distinguished choice of origin.  So, in the words of Marcel Berger, \"An affine space is nothing more than a vector space whose origin we try to forget about, by adding translations to the linear maps.\"  Accordingly, a complex affine space, that is an affine space over the complex numbers, is like a complex vector space, but without a distinguished point to serve as the origin.\nAffine geometry is one of the two main branches of classical algebraic geometry, the other being projective geometry.  A complex affine space can be obtained from a complex projective space by fixing a hyperplane, which can be thought of as a hyperplane of ideal points \"at infinity\" of the affine ",
    "content": "Affine geometry, broadly speaking, is the study of the geometrical properties of lines, planes, and their higher dimensional analogs, in which a notion of \"parallel\" is retained, but no metrical notions of distance or angle are.  Affine spaces differ from linear spaces (that is, vector spaces) in that they do not have a distinguished choice of origin.  So, in the words of Marcel Berger, \"An affine space is nothing more than a vector space whose origin we try to forget about, by adding translations to the linear maps.\"  Accordingly, a complex affine space, that is an affine space over the complex numbers, is like a complex vector space, but without a distinguished point to serve as the origin.\nAffine geometry is one of the two main branches of classical algebraic geometry, the other being projective geometry.  A complex affine space can be obtained from a complex projective space by fixing a hyperplane, which can be thought of as a hyperplane of ideal points \"at infinity\" of the affine space.  To illustrate the difference (over the real numbers), a parabola in the affine plane intersects the line at infinity, whereas an ellipse does not.  However, any two conic sections are projectively equivalent.  So a parabola and ellipse are the same when thought of projectively, but different when regarded as affine objects.  Somewhat less intuitively, over the complex numbers, an ellipse intersects the line at infinity in a pair of points while a parabola intersects the line at infinity in a single point.  So, for a slightly different reason, an ellipse and parabola are inequivalent over the complex affine plane but remain equivalent over the (complex) projective plane.\nAny complex vector space is an affine space: all one needs to do is forget the origin (and possibly any additional structure such as an inner product).  For example, the complex n-space \n  \n    \n      \n        \n          \n            C\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {C} ^{n}}\n  \n can be regarded as a complex affine space, when one is interested only in its affine properties (as opposed to its linear or metrical properties, for example).  Since any two affine spaces of the same dimension are isomorphic, in some situations it is appropriate to identify them with \n  \n    \n      \n        \n          \n            C\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {C} ^{n}}\n  \n, with the understanding that only affinely-invariant notions are ultimately meaningful. This usage is very common in modern algebraic geometry.\n\nAffine structure\nThere are several equivalent ways to specify the affine structure of an n-dimensional complex affine space A.  The simplest involves an auxiliary space V, called the difference space, which is a vector space over the complex numbers.  Then an affine space is a set A together with a simple and transitive action of V on A.  (That is, A is a V-torsor.)\nAnother way is to define a notion of affine combination, satisfying certain axioms.  An affine combination of points p1, …, pk ∊ A is expressed as a sum of the form\n\n  \n    \n      \n        \n          a\n          \n            1\n          \n        \n        \n          \n            p\n          \n          \n            1\n          \n        \n        +\n        ⋯\n        +\n        \n          a\n          \n            k\n          \n        \n        \n          \n            p\n          \n          \n            k\n          \n        \n      \n    \n    {\\displaystyle a_{1}\\mathbf {p} _{1}+\\cdots +a_{k}\\mathbf {p} _{k}}\n  \n\nwhere the scalars ai are complex numbers that sum to unity.\nThe difference space can be identified with the set of \"formal differences\" p − q, modulo the relation that formal differences respect affine combinations in an obvious way.\n\nAffine functions\nA function \n  \n    \n      \n        f\n        :\n        \n          A\n        \n        ↦\n        \n          C\n        \n      \n    \n    {\\displaystyle f:\\mathbf {A} \\mapsto \\mathbb {C} }\n  \n is called affine if it preserves affine combinations.  So\n\n  \n    \n      \n        f\n        (\n        \n          a\n          \n            1\n          \n        \n        \n          \n            p\n          \n          \n            1\n          \n        \n        +\n        ⋯\n        +\n        \n          a\n          \n            k\n          \n        \n        \n          \n            p\n          \n          \n            k\n          \n        \n        )\n        =\n        \n          a\n          \n            1\n          \n        \n        f\n        (\n        \n          \n            p\n          \n          \n            1\n          \n        \n        )\n        +\n        ⋯\n        +\n        \n          a\n          \n            k\n          \n        \n        f\n        (\n        \n          \n            p\n          \n          \n            k\n          \n        \n        )\n      \n    \n    {\\displaystyle f(a_{1}\\mathbf {p} _{1}+\\cdots +a_{k}\\mathbf {p} _{k})=a_{1}f(\\mathbf",
    "links": [
      "Affine coordinate ring",
      "Affine coordinate system",
      "Affine geometry",
      "Affine space",
      "Algebra homomorphism",
      "Algebraic geometry",
      "Analytic continuation",
      "Analytic space",
      "Coherent sheaf",
      "Complex-analytic space",
      "Complex coordinate space",
      "Complex manifold",
      "Complex number",
      "Complex polytope",
      "Coordinate space",
      "Domain of holomorphy",
      "Dual vector space",
      "Ellipse",
      "Euclidean space",
      "Exotic affine space",
      "Filtration (mathematics)",
      "Free vector space",
      "Function of several complex variables",
      "Hans Grauert",
      "Harold Scott Macdonald Coxeter",
      "Hausdorff topological space",
      "Holomorphic function",
      "ISBN (identifier)",
      "Inner product",
      "Isomorphism",
      "Jacobian conjecture",
      "Jacobian determinant",
      "Linear functional",
      "Linear space",
      "Marcel Berger",
      "Maximal ideal",
      "Metric space",
      "Minkowski space",
      "Nicolas Bourbaki",
      "Norm (mathematics)",
      "Oka's coherence theorem",
      "Parabola",
      "Polydisc",
      "Polynomial",
      "Projective geometry",
      "Reinhold Remmert",
      "Ring (mathematics)",
      "Sheaf (mathematics)",
      "Spectrum of a ring",
      "Stein manifold"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Complex manifolds",
      "Category:Short description matches Wikidata"
    ]
  },
  "Coordinate space": {
    "title": "Vector space",
    "url": "https://en.wikipedia.org/wiki/Vector_space",
    "summary": "In mathematics and physics, a vector space (also called a linear space) is a set whose elements, often called vectors, can be added together and multiplied (\"scaled\") by numbers called scalars. The operations of vector addition and scalar multiplication must satisfy certain requirements, called vector axioms. Real vector spaces and complex vector spaces are kinds of vector spaces based on different kinds of scalars: real numbers and complex numbers. Scalars can also be, more generally, elements of any field.\nVector spaces generalize Euclidean vectors, which allow modeling of physical quantities (such as forces and velocity) that have not only a magnitude, but also a direction. The concept of vector spaces is fundamental for linear algebra, together with the concept of matrices, which allows computing in vector spaces. This provides a concise and synthetic way for manipulating and studying systems of linear equations.\nVector spaces are characterized by their dimension, which, roughly sp",
    "content": "In mathematics and physics, a vector space (also called a linear space) is a set whose elements, often called vectors, can be added together and multiplied (\"scaled\") by numbers called scalars. The operations of vector addition and scalar multiplication must satisfy certain requirements, called vector axioms. Real vector spaces and complex vector spaces are kinds of vector spaces based on different kinds of scalars: real numbers and complex numbers. Scalars can also be, more generally, elements of any field.\nVector spaces generalize Euclidean vectors, which allow modeling of physical quantities (such as forces and velocity) that have not only a magnitude, but also a direction. The concept of vector spaces is fundamental for linear algebra, together with the concept of matrices, which allows computing in vector spaces. This provides a concise and synthetic way for manipulating and studying systems of linear equations.\nVector spaces are characterized by their dimension, which, roughly speaking, specifies the number of independent directions in the space. This means that, for two vector spaces over a given field and with the same dimension, the properties that depend only on the vector-space structure are exactly the same (technically the vector spaces are isomorphic). A vector space is finite-dimensional if its dimension is a natural number. Otherwise, it is infinite-dimensional, and its dimension is an infinite cardinal. Finite-dimensional vector spaces occur naturally in geometry and related areas. Infinite-dimensional vector spaces occur in many areas of mathematics. For example, polynomial rings are countably infinite-dimensional vector spaces, and many function spaces have the cardinality of the continuum as a dimension.\nMany vector spaces that are considered in mathematics are also endowed with other structures. This is the case of algebras, which include field extensions, polynomial rings, associative algebras and Lie algebras. This is also the case of topological vector spaces, which include function spaces, inner product spaces, normed spaces, Hilbert spaces and Banach spaces.\n\nDefinition and basic properties\nIn this article, vectors are represented in boldface to distinguish them from scalars.\nA vector space over a field F is a non-empty set V together with a binary operation and a binary function that satisfy the eight axioms listed below. In this context, the elements of V are commonly called vectors, and the elements of F are called scalars.\n\nThe binary operation, called vector addition or simply addition assigns to any two vectors v and w in V a third vector in V which is commonly written as v + w, and called the sum of these two vectors.\nThe binary function, called scalar multiplication, assigns to any scalar a in F and any vector v in V another vector in V, which is denoted av.\nTo have a vector space, the eight following axioms must be satisfied for every u, v and w in V, and a and b in F.\n\nWhen the scalar field is the real numbers, the vector space is called a real vector space, and when the scalar field is the complex numbers, the vector space is called a complex vector space. These two cases are the most common ones, but vector spaces with scalars in an arbitrary field F are also commonly considered. Such a vector space is called an F-vector space or a vector space over F.\nAn equivalent definition of a vector space can be given, which is much more concise but less elementary: the first four axioms (related to vector addition) say that a vector space is an abelian group under addition, and the four remaining axioms (related to the scalar multiplication) say that this operation defines a ring homomorphism from the field F into the endomorphism ring of this group.\nSubtraction of two vectors can be defined as\n\n  \n    \n      \n        \n          v\n        \n        −\n        \n          w\n        \n        =\n        \n          v\n        \n        +\n        (\n        −\n        \n          w\n        \n        )\n        .\n      \n    \n    {\\displaystyle \\mathbf {v} -\\mathbf {w} =\\mathbf {v} +(-\\mathbf {w} ).}\n  \n\nDirect consequences of the axioms include that, for every \n  \n    \n      \n        s\n        ∈\n        F\n      \n    \n    {\\displaystyle s\\in F}\n  \n and \n  \n    \n      \n        \n          v\n        \n        ∈\n        V\n        ,\n      \n    \n    {\\displaystyle \\mathbf {v} \\in V,}\n  \n one has\n\n  \n    \n      \n        0\n        \n          v\n        \n        =\n        \n          0\n        \n        ,\n      \n    \n    {\\displaystyle 0\\mathbf {v} =\\mathbf {0} ,}\n  \n\n  \n    \n      \n        s\n        \n          0\n        \n        =\n        \n          0\n        \n        ,\n      \n    \n    {\\displaystyle s\\mathbf {0} =\\mathbf {0} ,}\n  \n\n  \n    \n      \n        (\n        −\n        1\n        )\n        \n          v\n        \n        =\n        −\n        \n          v\n        \n        ,\n      \n    \n    {\\displaystyle (-1)\\mathbf {v} =-\\mathbf {v} ,}\n  \n\n  \n    \n      \n        s\n        \n          v\n        \n        =\n   ",
    "links": [
      "2-sphere",
      "Abelian category",
      "Abelian group",
      "Academic Press",
      "Addison-Wesley",
      "Additive inverse",
      "Affine geometry",
      "Affine space",
      "Algebra",
      "Algebra (Lang)",
      "Algebra over a field",
      "Algebraic geometry",
      "Algebraic number theory",
      "Algebraic structure",
      "Algebraically closed field",
      "Algebras over a field",
      "Almost everywhere",
      "American Mathematical Monthly",
      "American Mathematical Society",
      "Analytic geometry",
      "Anticommutativity",
      "Arnold Schönhage",
      "Arrow (symbol)",
      "Arthur Cayley",
      "Associative algebra",
      "Associative property",
      "Associativity",
      "August Ferdinand Möbius",
      "Axiom",
      "Axiom of choice",
      "Banach space",
      "Bartel Leendert van der Waerden",
      "Barycentric coordinates (mathematics)",
      "Basic Linear Algebra Subprograms",
      "Basis (linear algebra)",
      "Bernard Bolzano",
      "Bernhard Bolzano",
      "Bialgebra",
      "Bijection",
      "Bilinear map",
      "Bilinear operator",
      "Binary function",
      "Binary operation",
      "Bivector",
      "Block matrix",
      "Boolean algebra (structure)",
      "Cardinality",
      "Cardinality of the continuum",
      "Cartesian coordinates",
      "Cartesian product"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1 French-language sources (fr)",
      "Category:CS1 German-language sources (de)",
      "Category:CS1 Italian-language sources (it)",
      "Category:CS1 maint: location missing publisher",
      "Category:Concepts in physics",
      "Category:Good articles",
      "Category:Group theory",
      "Category:Mathematical structures",
      "Category:Pages using multiple image with auto scaled images"
    ]
  },
  "Coset": {
    "title": "Coset",
    "url": "https://en.wikipedia.org/wiki/Coset",
    "summary": "In mathematics, specifically group theory, a subgroup H of a group G may be used to decompose the underlying set of G into disjoint, equal-size subsets called cosets. There are left cosets and right cosets. Cosets (both left and right) have the same number of elements (cardinality) as does H. Furthermore, H itself is both a left coset and a right coset. The number of left cosets of H in G is equal to the number of right cosets of H in G. This common value is called the index of H in G and is usually denoted by [G : H].\nCosets are a basic tool in the study of groups; for example, they play a central role in Lagrange's theorem that states that for any finite group G, the number of elements of every subgroup H of G divides the number of elements of G. Cosets of a particular type of subgroup (a normal subgroup) can be used as the elements of another group called a quotient group or factor group. Cosets also appear in other areas of mathematics such as vector spaces and error-correcting cod",
    "content": "In mathematics, specifically group theory, a subgroup H of a group G may be used to decompose the underlying set of G into disjoint, equal-size subsets called cosets. There are left cosets and right cosets. Cosets (both left and right) have the same number of elements (cardinality) as does H. Furthermore, H itself is both a left coset and a right coset. The number of left cosets of H in G is equal to the number of right cosets of H in G. This common value is called the index of H in G and is usually denoted by [G : H].\nCosets are a basic tool in the study of groups; for example, they play a central role in Lagrange's theorem that states that for any finite group G, the number of elements of every subgroup H of G divides the number of elements of G. Cosets of a particular type of subgroup (a normal subgroup) can be used as the elements of another group called a quotient group or factor group. Cosets also appear in other areas of mathematics such as vector spaces and error-correcting codes.\n\nDefinition\nLet H be a subgroup of the group G whose operation is written multiplicatively (juxtaposition denotes the group operation). Given an element g of G, the left cosets of H in G are the sets obtained by multiplying each element of H by a fixed element g of G (where g is the left factor). In symbols these are,\n\nThe right cosets are defined similarly, except that the element g is now a right factor, that is,\n\nAs g varies through the group, it would appear that many cosets (right or left) would be generated. Nevertheless, it turns out that any two left cosets (respectively right cosets) are either disjoint or are identical as sets.\nIf the group operation is written additively, as is often the case when the group is abelian, the notation used changes to g + H or H + g, respectively.\nThe symbol G/H is sometimes used for the set of (left) cosets {gH : g an element of G} (see below for a extension to right cosets and double cosets).  However, some authors (including Dummit & Foote and Rotman) reserve this notation specifically for representing the quotient group formed from the cosets in the case where H is a normal subgroup of G.\n\nFirst example\nLet G be the dihedral group of order six. Its elements may be represented by {I, a, a2, b, ab, a2b}. In this group, a3 = b2 = I and ba = a2b. This is enough information to fill in the entire Cayley table:\n\nLet T be the subgroup {I, b}. The (distinct) left cosets of T are:\n\nIT = T = {I, b},\naT = {a, ab}, and\na2T = {a2, a2b}.\nSince all the elements of G have now appeared in one of these cosets, generating any more can not give new cosets; any new coset would have to have an element in common with one of these and therefore would be identical to one of these cosets. For instance, abT = {ab, a} = aT.\nThe right cosets of T are:\n\nTI = T = {I, b},\nTa = {a, ba} = {a, a2b} , and\nTa2 = {a2, ba2} = {a2, ab}.\nIn this example, except for T, no left coset is also a right coset.\nLet H be the subgroup {I, a, a2}. The left cosets of H are IH = H and bH = {b, ba, ba2}. The right cosets of H are HI = H and Hb = {b, ab, a2b} = {b, ba2, ba}. In this case, every left coset of H is also a right coset of H.\nLet H be a subgroup of a group G and suppose that g1, g2 ∈ G. The following statements are equivalent:\n\ng1H = g2H\nHg1−1 = Hg2−1\ng1H ⊂ g2H\ng2 ∈ g1H\ng1−1g2 ∈ H\n\nProperties\nThe disjointness of non-identical cosets is a result of the fact that if x belongs to gH then gH = xH. For if x ∈ gH then there must exist an a ∈ H such that ga = x. Thus xH = (ga)H = g(aH). Moreover, since H is a group, left multiplication by a is a bijection, and aH = H.\nThus every element of G belongs to exactly one left coset of the subgroup H, and H is itself a left coset (and the one that contains the identity).\nTwo elements being in the same left coset also provide a natural equivalence relation. Define two elements of G, x and y, to be equivalent with respect to the subgroup H if xH = yH (or equivalently if x−1y belongs to H). The equivalence classes of this relation are the left cosets of H. As with any set of equivalence classes, they form a partition of the underlying set. A coset representative is a representative in the equivalence class sense. A set of representatives of all the cosets is called a transversal. There are other types of equivalence relations in a group, such as conjugacy, that form different classes which do not have the properties discussed here.\nSimilar statements apply to right cosets.\nIf G is an abelian group, then g + H = H + g for every subgroup H of G and every element g of G. For general groups, given an element g and a subgroup H of a group G, the right coset of H with respect to g is also the left coset of the conjugate subgroup g−1Hg with respect to g, that is, Hg = g(g−1Hg).\n\nNormal subgroups\nA subgroup N of a group G is a normal subgroup of G if and only if for all elements g of G the corresponding left and right cosets are equal, that is, gN = Ng. This is the case for the subgroup H in the f",
    "links": [
      "Abelian group",
      "Additive group",
      "Affine subspace",
      "ArXiv (identifier)",
      "Camille Jordan",
      "Cardinality",
      "Cayley table",
      "Center (group theory)",
      "Clifford–Klein form",
      "Commutivity",
      "Conjugate subgroup",
      "Coset enumeration",
      "Coset leader",
      "Cosette",
      "Dihedral group of order 6",
      "Disjoint sets",
      "Doi (identifier)",
      "Double coset",
      "Eduard Ritter von Weber",
      "Encyclopedia of Mathematics",
      "Equivalence classes",
      "Equivalence relation",
      "Eric W. Weisstein",
      "Error-correcting code",
      "Euclidean space",
      "European Mathematical Society",
      "Finite group",
      "Galois",
      "Group (mathematics)",
      "Group action",
      "Group theory",
      "Hans Zassenhaus",
      "Heap (mathematics)",
      "Homogeneous space",
      "ISBN (identifier)",
      "If and only if",
      "Index of a subgroup",
      "Infinity",
      "Integers mod n",
      "Integers modulo n",
      "Lagrange's theorem (group theory)",
      "Linear subspace",
      "Linearity",
      "MathWorld",
      "Mathematics",
      "Modular arithmetic",
      "Non-measurable set",
      "Normal subgroup",
      "Optimal solutions for Rubik's Cube",
      "Orbit (group theory)"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Group theory",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Desargues's theorem": {
    "title": "Desargues's theorem",
    "url": "https://en.wikipedia.org/wiki/Desargues%27s_theorem",
    "summary": "In projective geometry, Desargues's theorem, named after Girard Desargues, states:\n\nTwo triangles are in perspective axially if and only if they are in perspective  centrally.\nDenote the three vertices of one triangle by a, b and c, and those of the other by A, B  and C.  Axial perspectivity means that lines ab and AB meet in a point, lines ac and AC meet in a second point, and lines bc and BC meet in a third point, and that these three points all lie on a common line called the axis of perspectivity.  Central perspectivity means that the three lines Aa, Bb and Cc are concurrent, at a point called the center of perspectivity.\nThis intersection theorem is true in the usual Euclidean plane but special care needs to be taken in exceptional cases, as when a pair of sides are parallel, so that their \"point of intersection\" recedes to infinity.  Commonly, to remove these exceptions, mathematicians \"complete\" the Euclidean plane by adding points at infinity, following Jean-Victor Poncelet. Th",
    "content": "In projective geometry, Desargues's theorem, named after Girard Desargues, states:\n\nTwo triangles are in perspective axially if and only if they are in perspective  centrally.\nDenote the three vertices of one triangle by a, b and c, and those of the other by A, B  and C.  Axial perspectivity means that lines ab and AB meet in a point, lines ac and AC meet in a second point, and lines bc and BC meet in a third point, and that these three points all lie on a common line called the axis of perspectivity.  Central perspectivity means that the three lines Aa, Bb and Cc are concurrent, at a point called the center of perspectivity.\nThis intersection theorem is true in the usual Euclidean plane but special care needs to be taken in exceptional cases, as when a pair of sides are parallel, so that their \"point of intersection\" recedes to infinity.  Commonly, to remove these exceptions, mathematicians \"complete\" the Euclidean plane by adding points at infinity, following Jean-Victor Poncelet. This results in a projective plane.\nDesargues's theorem is true for the real projective plane and for any projective space defined arithmetically from a field or division ring; that includes any projective space of dimension greater than two or in which Pappus's theorem holds. However, there are many \"non-Desarguesian planes\", in which Desargues's theorem is false.\n\nHistory\nDesargues never published this theorem, but it appeared in an appendix entitled Universal Method of M. Desargues for Using Perspective (Manière universelle de M. Desargues pour practiquer la perspective) to a practical book on the use of perspective published in 1648. by his friend and pupil Abraham Bosse (1602–1676).\n\nCoordinatization\nThe importance of Desargues's theorem in abstract projective geometry is due especially to the fact that a projective space satisfies that theorem if and only if it is isomorphic to a projective space defined over a field or division ring.\n\nProjective versus affine spaces\nIn an affine space such as the Euclidean plane a similar statement is true, but only if one lists various exceptions involving parallel lines. Desargues's theorem is therefore one of the simplest geometric theorems whose natural home is in projective rather than affine space.\n\nSelf-duality\nBy definition, two triangles are perspective if and only if they are in perspective centrally (or, equivalently according to this theorem, in perspective axially). Note that perspective triangles need not be similar.\nUnder the standard duality of plane projective geometry (where points correspond to lines and collinearity of points corresponds to concurrency of lines), the statement of Desargues's theorem is self-dual: axial perspectivity is translated into central perspectivity and vice versa. The Desargues configuration (below) is a self-dual configuration.\nThis self-duality in the statement is due to the usual modern way of writing the theorem. Historically, the theorem only read, \"In a projective space, a pair of centrally perspective triangles is axially perspective\" and the dual of this statement was called the converse of Desargues's theorem and was always referred to by that name.\n\nProof of Desargues's theorem\nDesargues's theorem holds for projective space of any dimension over any field or division ring, and also holds for abstract projective spaces of dimension at least 3. In dimension 2 the planes for which it holds are called Desarguesian planes and are the same as the planes that can be given coordinates over a division ring. There are also many non-Desarguesian planes where Desargues's theorem does not hold.\n\nThree-dimensional proof\nDesargues's theorem is true for any projective space of dimension at least 3, and more generally for any projective space that can be embedded in a space of dimension at least 3.\nDesargues's theorem can be stated as follows:\n\nIf lines Aa, Bb and Cc are concurrent (meet at a point), then\nthe points AB ∩ ab, AC ∩ ac and BC ∩ bc are collinear.\nThe points A, B, a and b are coplanar (lie in the same plane) because of the assumed concurrency of Aa and Bb. Therefore, the lines AB and ab belong to the same plane and must intersect. Further, if the two triangles lie on different planes, then the point AB ∩ ab belongs to both planes. By a symmetric argument, the points AC ∩ ac and BC ∩ bc also exist and belong to the planes of both triangles. Since these two planes intersect in more than one point, their intersection is a line that contains all three points.\nThis proves Desargues's theorem if the two triangles are not contained in the same plane. If they are in the same plane, Desargues's theorem can be proved by choosing a point not in the plane, using this to lift the triangles out of the plane so that the argument above works, and then projecting back into the plane. \nThe last step of the proof fails if the projective space has dimension less than 3, as in this case it is not possible to find a point not in the plane.\nMonge's theorem also ",
    "links": [
      "Affine space",
      "Bulletin of the London Mathematical Society",
      "Cambridge University Press",
      "Collinear",
      "Collineation",
      "Commutative",
      "Cut-the-knot",
      "David Hilbert",
      "Desargues configuration",
      "Desarguesian plane",
      "Division ring",
      "Doi (identifier)",
      "Duality (projective geometry)",
      "Encyclopedia of Mathematics",
      "Euclidean plane",
      "European Mathematical Society",
      "Field (mathematics)",
      "Girard Desargues",
      "Harold Scott MacDonald Coxeter",
      "Hexagon",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "If and only if",
      "Intersection theorem",
      "JSTOR (identifier)",
      "Jean-Victor Poncelet",
      "MR (identifier)",
      "MathWorld",
      "Mathematische Annalen",
      "Monge's theorem",
      "Moufang plane",
      "Necessary and sufficient",
      "Non-Desarguesian plane",
      "Non-Desarguesian projective plane",
      "Oxford University Press",
      "Pappus's hexagon theorem",
      "Pascal's theorem",
      "Perspective (geometry)",
      "Perspectivity",
      "PlanetMath",
      "Proceedings of the American Mathematical Society",
      "Projective configuration",
      "Projective geometry",
      "Projective plane",
      "Real projective plane",
      "S2CID (identifier)",
      "Similarity (geometry)",
      "Stephan Cohn-Vossen",
      "Symmetry",
      "Theorem"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1 errors: ISBN date",
      "Category:Euclidean plane geometry",
      "Category:Proof without words",
      "Category:Short description is different from Wikidata",
      "Category:Theorems about triangles",
      "Category:Theorems in projective geometry"
    ]
  },
  "Alice and Bob": {
    "title": "Alice and Bob",
    "url": "https://en.wikipedia.org/wiki/Alice_and_Bob",
    "summary": "Alice and Bob are fictional characters commonly used as placeholders in discussions about cryptographic systems and protocols, and in other science and engineering literature where there are several participants in a thought experiment. The Alice and Bob characters were created by Ron Rivest, Adi Shamir, and Leonard Adleman in their 1978 paper \"A Method for Obtaining Digital Signatures and Public-key Cryptosystems\". Subsequently, they have become common archetypes in many scientific and engineering fields, such as quantum cryptography, game theory and physics. As the use of Alice and Bob became more widespread, additional characters were added, sometimes each with a particular meaning. These characters do not have to refer to people; they refer to generic agents which might be different computers or even different programs running on a single computer.",
    "content": "Alice and Bob are fictional characters commonly used as placeholders in discussions about cryptographic systems and protocols, and in other science and engineering literature where there are several participants in a thought experiment. The Alice and Bob characters were created by Ron Rivest, Adi Shamir, and Leonard Adleman in their 1978 paper \"A Method for Obtaining Digital Signatures and Public-key Cryptosystems\". Subsequently, they have become common archetypes in many scientific and engineering fields, such as quantum cryptography, game theory and physics. As the use of Alice and Bob became more widespread, additional characters were added, sometimes each with a particular meaning. These characters do not have to refer to people; they refer to generic agents which might be different computers or even different programs running on a single computer.\n\nOverview\nAlice and Bob are the names of fictional characters used for convenience and to aid comprehension. For example, \"How can Bob send a private message M to Alice in a public-key cryptosystem?\" is believed to be easier to describe and understand than if the hypothetical people were simply named A and B as in \"How can B send a private message M to A in a public-key cryptosystem?\"\nThe names are conventional, and where relevant may use an alliterative mnemonic such as \"Mallory\" for \"malicious\" to associate the name with the typical role of that person.\n\nHistory\nScientific papers about thought experiments with several participants often used letters to identify them: A, B, C, etc.\nThe first mention of Alice and Bob in the context of cryptography was in Rivest, Shamir, and Adleman's 1978 article \"A method for obtaining digital signatures and public-key cryptosystems.\" They wrote, \"For our scenarios we suppose that A and B (also known as Alice and Bob) are two users of a public-key cryptosystem\". Previous to this article, cryptographers typically referred to message senders and receivers as A and B, or other simple symbols. In fact, in the two previous articles by Rivest, Shamir, and Adleman, introducing the RSA cryptosystem, there is no mention of Alice and Bob. The choice of the first three names may have come from the film Bob & Carol & Ted & Alice.\nWithin a few years, however, references to Alice and Bob in cryptological literature became a common trope. Cryptographers would often begin their academic papers with reference to Alice and Bob. For instance, Michael Rabin began his 1981 paper, \"Bob and Alice each have a secret, SB and SA, respectively, which they want to exchange.\" Early on, Alice and Bob were starting to appear in other domains, such as in Manuel Blum's 1981 article, \"Coin Flipping by Telephone: A Protocol for Solving Impossible Problems,\" which begins, \"Alice and Bob want to flip a coin by telephone.\"\nAlthough Alice and Bob were invented with no reference to their personality, authors soon began adding colorful descriptions. In 1983, Blum invented a backstory about a troubled relationship between Alice and Bob, writing, \"Alice and Bob, recently divorced, mutually distrustful, still do business together. They live on opposite coasts, communicate mainly by telephone, and use their computers to transact business over the telephone.\" In 1984, John Gordon delivered his famous \"After Dinner Speech\" about Alice and Bob, which he imagines to be the first \"definitive biography of Alice and Bob.\"\nIn addition to adding backstories and personalities to Alice and Bob, authors soon added other characters, with their own personalities. The first to be added was Eve, the \"eavesdropper.\" Eve was invented in 1988 by Charles Bennet, Gilles Brassard, and Jean-Marc Robert, in their paper, \"Privacy Amplification by Public Discussion.\" In Bruce Schneier's book Applied Cryptography, other characters are listed.\n\nCast of characters\nCryptographic systems\nThe most common characters are Alice and Bob. Eve, Mallory, and Trent are also common names, and have fairly well-established \"personalities\" (or functions). The names often use alliterative mnemonics (for example, Eve, \"eavesdropper\"; Mallory, \"malicious\") where different players have different motives. Other names are much less common and more flexible in use. Sometimes the genders are alternated: Alice, Bob, Carol, Dave, Eve, etc.\n\nInteractive proof systems\nFor interactive proof systems there are other characters:\n\nPhysics\nThe names Alice and Bob are often used to name the participants in thought experiments in physics. More alphabetical names, usually of alternating gender, are used as required, e.g. \"Alice and Bob (and Carol and Dick and Eve)\".\nIn experiments involving robotic systems, the terms \"Alice Robot\" and \"Bob Robot\" refer to mobile platforms responsible for transmitting quantum information and receiving it with quantum detectors, respectively, within the context of the field of quantum robotics.\n\nSee also\nDiffie–Hellman key exchange\nMartin Gardner\nPublic-key cryptography\nSecurity protocol notation\n\nRef",
    "links": [
      "Adi Shamir",
      "Adviser",
      "Alice & Bob (company)",
      "Alliteration",
      "Anagram",
      "ArXiv (identifier)",
      "Arbitral tribunal",
      "Archetype",
      "Bibcode (identifier)",
      "Black box",
      "Bob & Carol & Ted & Alice",
      "Brian LaMacchia",
      "Bruce Schneier",
      "Carsten Lund",
      "Charles L. Perkins",
      "CiteSeerX (identifier)",
      "Combinatorial game theory",
      "Cryptographic protocol",
      "Cryptography",
      "Diffie–Hellman key exchange",
      "Doi (identifier)",
      "Eavesdropping",
      "Game theory",
      "Hdl (identifier)",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "Interactive proof system",
      "Joel Spencer",
      "Journal of Computer and System Sciences",
      "Judge Judy",
      "King Arthur",
      "Leonard Adleman",
      "Man-in-the-middle attack",
      "Manuel Blum",
      "Martin Gardner",
      "Merlin (wizard)",
      "Michael O. Rabin",
      "Microphone",
      "Mnemonic",
      "N. David Mermin",
      "Nadia Heninger",
      "Nick Szabo",
      "Non-repudiation",
      "Oracle",
      "Oracle machine",
      "PMC (identifier)",
      "PMID (identifier)",
      "Password cracking",
      "Paul Erdős",
      "Pearson Prentice Hall"
    ],
    "categories": [
      "Category:All Wikipedia articles written in American English",
      "Category:All articles needing additional references",
      "Category:All articles with dead external links",
      "Category:All articles with unsourced statements",
      "Category:Articles needing additional references from May 2023",
      "Category:Articles with dead external links from August 2023",
      "Category:Articles with permanently dead external links",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from March 2016",
      "Category:CS1: long volume value"
    ]
  },
  "Euclidean space": {
    "title": "Euclidean space",
    "url": "https://en.wikipedia.org/wiki/Euclidean_space",
    "summary": "Euclidean space is the fundamental space of geometry, intended to represent physical space. Originally, in Euclid's Elements, it was the three-dimensional space of Euclidean geometry, but in modern mathematics there are Euclidean spaces of any positive integer dimension n, which are called Euclidean n-spaces when one wants to specify their dimension. For n equal to one or two, they are commonly called respectively Euclidean lines and Euclidean planes. The qualifier \"Euclidean\" is used to distinguish Euclidean spaces from other spaces that were later considered in physics and modern mathematics.\nAncient Greek geometers introduced Euclidean space for modeling the physical space. Their work was collected by the ancient Greek mathematician Euclid in his Elements, with the great innovation of proving all properties of the space as theorems, by starting from a few fundamental properties, called postulates, which either were considered as evident (for example, there is exactly one straight li",
    "content": "Euclidean space is the fundamental space of geometry, intended to represent physical space. Originally, in Euclid's Elements, it was the three-dimensional space of Euclidean geometry, but in modern mathematics there are Euclidean spaces of any positive integer dimension n, which are called Euclidean n-spaces when one wants to specify their dimension. For n equal to one or two, they are commonly called respectively Euclidean lines and Euclidean planes. The qualifier \"Euclidean\" is used to distinguish Euclidean spaces from other spaces that were later considered in physics and modern mathematics.\nAncient Greek geometers introduced Euclidean space for modeling the physical space. Their work was collected by the ancient Greek mathematician Euclid in his Elements, with the great innovation of proving all properties of the space as theorems, by starting from a few fundamental properties, called postulates, which either were considered as evident (for example, there is exactly one straight line passing through two points), or seemed impossible to prove (parallel postulate).\nAfter the introduction at the end of the 19th century of non-Euclidean geometries, the old postulates were re-formalized to define Euclidean spaces through axiomatic theory. Another definition of Euclidean spaces by means of vector spaces and linear algebra has been shown to be equivalent to the axiomatic definition. It is this definition that is more commonly used in modern mathematics, and detailed in this article. In all definitions, Euclidean spaces consist of points, which are defined only by the properties that they must have for forming a Euclidean space.\nThere is essentially only one Euclidean space of each dimension; that is, all Euclidean spaces of a given dimension are isomorphic. Therefore, it is usually possible to work with a specific Euclidean space, denoted \n  \n    \n      \n        \n          \n            E\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {E} ^{n}}\n  \n or \n  \n    \n      \n        \n          \n            E\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {E} ^{n}}\n  \n, which can be represented using Cartesian coordinates as the real n-space \n  \n    \n      \n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{n}}\n  \n equipped with the standard dot product.\n\nDefinition\nHistory of the definition\nEuclidean space was introduced by ancient Greeks as an abstraction of our physical space. Their great innovation, appearing in Euclid's Elements was to build and prove all geometry by starting from a few very basic properties, which are abstracted from the physical world, and cannot be mathematically proved because of the lack of more basic tools. These properties are called postulates, or axioms in modern language. This way of defining Euclidean space is still in use under the name of synthetic geometry.\nIn 1637, René Descartes introduced Cartesian coordinates, and showed that these allow reducing geometric problems to algebraic computations with numbers. This reduction of geometry to algebra was a major change in point of view, as, until then, the real numbers were defined in terms of lengths and distances.\nEuclidean geometry was not applied in spaces of dimension more than three until the 19th century. Ludwig Schläfli generalized Euclidean geometry to spaces of dimension n, using both synthetic and algebraic methods, and discovered all of the regular polytopes (higher-dimensional analogues of the Platonic solids) that exist in Euclidean spaces of any dimension.\nDespite the wide use of Descartes' approach, which was called analytic geometry, the definition of Euclidean space remained unchanged until the end of 19th century. The introduction of abstract vector spaces allowed their use in defining Euclidean spaces with a purely algebraic definition. This new definition has been shown to be equivalent to the classical definition in terms of geometric axioms. It is this algebraic definition that is now most often used for introducing Euclidean spaces.\n\nMotivation of the modern definition\nOne way to think of the Euclidean plane is as a set of points satisfying certain relationships, expressible in terms of distance and angles. For example, there are two fundamental operations (referred to as motions) on the plane. One is translation, which means a shifting of the plane so that every point is shifted in the same direction and by the same distance. The other is rotation around a fixed point in the plane, in which all points in the plane turn around that fixed point through the same angle. One of the basic tenets of Euclidean geometry is that two figures (usually considered as subsets) of the plane should be considered equivalent (congruent) if one can be transformed into the other by some sequence of translations, rotations and reflections (see below).\nIn order",
    "links": [
      "Abstraction",
      "Affine algebraic variety",
      "Affine basis",
      "Affine coordinates",
      "Affine frame",
      "Affine property",
      "Affine space",
      "Albert Einstein",
      "Alfred Tarski",
      "Algebra",
      "Algebraic geometry",
      "Algebraic group",
      "Algebraic number field",
      "Algebraically closed field",
      "Analytic geometry",
      "Analytic manifold",
      "Angle",
      "Antimeridian",
      "Arccosine",
      "Architecture",
      "Astronomy",
      "Axiom",
      "Axiomatic theory",
      "Barycentric coordinates",
      "Base (topology)",
      "Basis (vector space)",
      "Bijection",
      "Bilinear form",
      "Birkhoff's axioms",
      "Bounded set",
      "Cartesian coordinate system",
      "Cartesian coordinates",
      "Cartesian frame",
      "Cauchy–Schwarz inequality",
      "Cayley–Dickson construction",
      "Circle",
      "Codimension",
      "Complete metric",
      "Complete metric space",
      "Complex number",
      "Configuration space (physics)",
      "Congruence (geometry)",
      "Consistency",
      "Coordinate system",
      "Coordinate vector",
      "Coplanar",
      "Cross-polytope",
      "Cryptography",
      "Curvature of Riemannian manifolds",
      "Curved space"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1 errors: ISBN date",
      "Category:Euclidean geometry",
      "Category:Homogeneous spaces",
      "Category:Linear algebra",
      "Category:Norms (mathematics)",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Algebra over an operad": {
    "title": "Operad algebra",
    "url": "https://en.wikipedia.org/wiki/Operad_algebra",
    "summary": "In algebra, an operad algebra is an \"algebra\" over an operad. It is a generalization of an associative algebra over a commutative ring R, with an operad replacing R.",
    "content": "In algebra, an operad algebra is an \"algebra\" over an operad. It is a generalization of an associative algebra over a commutative ring R, with an operad replacing R.\n\nDefinitions\nGiven an operad O (say, a symmetric sequence in a symmetric monoidal ∞-category C), an algebra over an operad, or O-algebra for short, is, roughly, a left module over O with multiplications parametrized by O.\nIf O is a topological operad, then one can say an algebra over an operad is an O-monoid object in C. If C is symmetric monoidal, this recovers the usual definition.\nLet C be symmetric monoidal ∞-category with monoidal structure distributive over colimits. If \n  \n    \n      \n        f\n        :\n        O\n        →\n        \n          O\n          ′\n        \n      \n    \n    {\\displaystyle f:O\\to O'}\n  \n is a map of operads and, moreover, if f is a homotopy equivalence, then the ∞-category of algebras over O in C is equivalent to the ∞-category of algebras over O' in C.\n\nSee also\nEn-ring\nHomotopy Lie algebra\n\nNotes\nReferences\nFrancis, John. \"Derived Algebraic Geometry Over \n  \n    \n      \n        \n          \n            \n              E\n            \n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {E}}_{n}}\n  \n-Rings\" (PDF).\nHinich, Vladimir (1997-02-11). \"Homological algebra of homotopy algebras\". arXiv:q-alg/9702015.\n\nExternal links\n\"operad\", ncatlab.org\nhttp://ncatlab.org/nlab/show/algebra+over+an+operad",
    "links": [
      "Abstract algebra",
      "ArXiv (identifier)",
      "Associative algebra",
      "En-ring",
      "Homotopy Lie algebra",
      "Operad",
      "Symmetric monoidal ∞-category",
      "Symmetric sequence",
      "Topological operad",
      "Wikipedia:Stub",
      "Template:Abstract-algebra-stub",
      "Template talk:Abstract-algebra-stub"
    ],
    "categories": [
      "Category:Abstract algebra",
      "Category:Abstract algebra stubs",
      "Category:All stub articles"
    ]
  },
  "Alternative algebra": {
    "title": "Alternative algebra",
    "url": "https://en.wikipedia.org/wiki/Alternative_algebra",
    "summary": "In abstract algebra, an alternative algebra is an algebra in which multiplication need not be associative, only alternative. That is, one must have\n\n  \n    \n      \n        x\n        (\n        x\n        y\n        )\n        =\n        (\n        x\n        x\n        )\n        y\n      \n    \n    {\\displaystyle x(xy)=(xx)y}\n  \n\n  \n    \n      \n        (\n        y\n        x\n        )\n        x\n        =\n        y\n        (\n        x\n        x\n        )\n      \n    \n    {\\displaystyle (yx)x=y(xx)}\n  \n\nfor all x and y in the algebra.\nEvery associative algebra is obviously alternative, but so too are some strictly non-associative algebras such as the octonions.",
    "content": "In abstract algebra, an alternative algebra is an algebra in which multiplication need not be associative, only alternative. That is, one must have\n\n  \n    \n      \n        x\n        (\n        x\n        y\n        )\n        =\n        (\n        x\n        x\n        )\n        y\n      \n    \n    {\\displaystyle x(xy)=(xx)y}\n  \n\n  \n    \n      \n        (\n        y\n        x\n        )\n        x\n        =\n        y\n        (\n        x\n        x\n        )\n      \n    \n    {\\displaystyle (yx)x=y(xx)}\n  \n\nfor all x and y in the algebra.\nEvery associative algebra is obviously alternative, but so too are some strictly non-associative algebras such as the octonions.\n\nThe associator\nAlternative algebras are so named because they are the algebras for which the associator is alternating. The associator is a trilinear map given by\n\n  \n    \n      \n        [\n        x\n        ,\n        y\n        ,\n        z\n        ]\n        =\n        (\n        x\n        y\n        )\n        z\n        −\n        x\n        (\n        y\n        z\n        )\n      \n    \n    {\\displaystyle [x,y,z]=(xy)z-x(yz)}\n  \n.\nBy definition, a multilinear map is alternating if it vanishes whenever two of its arguments are equal. The left and right alternative identities for an algebra are equivalent to\n\n  \n    \n      \n        [\n        x\n        ,\n        x\n        ,\n        y\n        ]\n        =\n        0\n      \n    \n    {\\displaystyle [x,x,y]=0}\n  \n\n  \n    \n      \n        [\n        y\n        ,\n        x\n        ,\n        x\n        ]\n        =\n        0\n      \n    \n    {\\displaystyle [y,x,x]=0}\n  \n\nBoth of these identities together imply that:\n\n  \n    \n      \n        [\n        x\n        ,\n        y\n        ,\n        x\n        ]\n        =\n        [\n        x\n        ,\n        x\n        ,\n        x\n        ]\n        +\n        [\n        x\n        ,\n        y\n        ,\n        x\n        ]\n        +\n      \n    \n    {\\displaystyle [x,y,x]=[x,x,x]+[x,y,x]+}\n  \n\n  \n    \n      \n        −\n        [\n        x\n        ,\n        x\n        +\n        y\n        ,\n        x\n        +\n        y\n        ]\n        =\n      \n    \n    {\\displaystyle -[x,x+y,x+y]=}\n  \n\n  \n    \n      \n        =\n        [\n        x\n        ,\n        x\n        +\n        y\n        ,\n        −\n        y\n        ]\n        =\n      \n    \n    {\\displaystyle =[x,x+y,-y]=}\n  \n\n  \n    \n      \n        =\n        [\n        x\n        ,\n        x\n        ,\n        −\n        y\n        ]\n        −\n        [\n        x\n        ,\n        y\n        ,\n        y\n        ]\n        =\n        0\n      \n    \n    {\\displaystyle =[x,x,-y]-[x,y,y]=0}\n  \n\nfor all \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n and \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n. This is equivalent to the flexible identity\n\n  \n    \n      \n        (\n        x\n        y\n        )\n        x\n        =\n        x\n        (\n        y\n        x\n        )\n        .\n      \n    \n    {\\displaystyle (xy)x=x(yx).}\n  \n\nThe associator of an alternative algebra is therefore alternating. Conversely, any algebra whose associator is alternating is clearly alternative. By symmetry, any algebra which satisfies any two of:\n\nleft alternative identity: \n  \n    \n      \n        x\n        (\n        x\n        y\n        )\n        =\n        (\n        x\n        x\n        )\n        y\n      \n    \n    {\\displaystyle x(xy)=(xx)y}\n  \n\nright alternative identity: \n  \n    \n      \n        (\n        y\n        x\n        )\n        x\n        =\n        y\n        (\n        x\n        x\n        )\n      \n    \n    {\\displaystyle (yx)x=y(xx)}\n  \n\nflexible identity: \n  \n    \n      \n        (\n        x\n        y\n        )\n        x\n        =\n        x\n        (\n        y\n        x\n        )\n        .\n      \n    \n    {\\displaystyle (xy)x=x(yx).}\n  \n\nis alternative and therefore satisfies all three identities.\nAn alternating associator is always totally skew-symmetric. That is,\n\n  \n    \n      \n        [\n        \n          x\n          \n            σ\n            (\n            1\n            )\n          \n        \n        ,\n        \n          x\n          \n            σ\n            (\n            2\n            )\n          \n        \n        ,\n        \n          x\n          \n            σ\n            (\n            3\n            )\n          \n        \n        ]\n        =\n        sgn\n        ⁡\n        (\n        σ\n        )\n        [\n        \n          x\n          \n            1\n          \n        \n        ,\n        \n          x\n          \n            2\n          \n        \n        ,\n        \n          x\n          \n            3\n          \n        \n        ]\n      \n    \n    {\\displaystyle [x_{\\sigma (1)},x_{\\sigma (2)},x_{\\sigma (3)}]=\\operatorname {sgn}(\\sigma )[x_{1},x_{2},x_{3}]}\n  \n\nfor any permutation \n  \n    \n      \n        σ\n      \n    \n    {\\displaystyle \\sigma }\n  \n. The converse holds so long as the characteristic of the base field is not 2.\n\nExamples\nEvery associative algebra is alternative.\nThe octonions form a non-associative alternative algebra, a normed division algebra of dimens",
    "links": [
      "Abstract algebra",
      "Academic Press",
      "Algebra over a field",
      "Alternating form",
      "Alternativity",
      "ArXiv (identifier)",
      "Associative",
      "Associative algebra",
      "Associative ring",
      "Associator",
      "Cayley–Dickson algebra",
      "Center (ring theory)",
      "Characteristic (algebra)",
      "Composition algebra",
      "Converse (logic)",
      "Corollary",
      "Division ring",
      "Encyclopedia of Mathematics",
      "European Mathematical Society",
      "Field (mathematics)",
      "Flexible identity",
      "Group of units",
      "Homomorphism",
      "ISBN (identifier)",
      "Inverse element",
      "John Horton Conway",
      "MR (identifier)",
      "Maltsev algebra",
      "Moufang identities",
      "Moufang loop",
      "Moufang plane",
      "Multilinear map",
      "Non-associative algebra",
      "Normed division algebra",
      "Octonion",
      "Octonion algebra",
      "Permutation",
      "Power-associative",
      "Primitive element theorem",
      "Projective plane",
      "Real number",
      "Richard D. Schafer",
      "Sedenion",
      "Subalgebra",
      "Trigintaduonion",
      "Trilinear map",
      "Vanish (mathematics)",
      "Zbl (identifier)",
      "Zorn ring",
      "Wikipedia:Citing sources"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Non-associative algebras",
      "Category:Short description is different from Wikidata",
      "Category:Wikipedia articles needing page number citations from June 2025"
    ]
  },
  "B*-algebra": {
    "title": "C*-algebra",
    "url": "https://en.wikipedia.org/wiki/C*-algebra",
    "summary": "In mathematics, specifically in functional analysis, a C∗-algebra (pronounced \"C-star\") is a Banach algebra together with an involution satisfying the properties of the adjoint. A particular case is that of a complex algebra A of continuous linear operators on a complex Hilbert space with two additional properties:\n\nA is a topologically closed set in the norm topology of operators.\nA is closed under the operation of taking adjoints of operators.\nAnother important class of non-Hilbert C*-algebras includes the algebra \n  \n    \n      \n        \n          C\n          \n            0\n          \n        \n        (\n        X\n        )\n      \n    \n    {\\displaystyle C_{0}(X)}\n  \n of complex-valued continuous functions on X that vanish at infinity, where X is a locally compact Hausdorff space.\nC*-algebras were first considered primarily for their use in quantum mechanics to model algebras of physical observables.  This line of research began with Werner Heisenberg's matrix mechanics and in a more",
    "content": "In mathematics, specifically in functional analysis, a C∗-algebra (pronounced \"C-star\") is a Banach algebra together with an involution satisfying the properties of the adjoint. A particular case is that of a complex algebra A of continuous linear operators on a complex Hilbert space with two additional properties:\n\nA is a topologically closed set in the norm topology of operators.\nA is closed under the operation of taking adjoints of operators.\nAnother important class of non-Hilbert C*-algebras includes the algebra \n  \n    \n      \n        \n          C\n          \n            0\n          \n        \n        (\n        X\n        )\n      \n    \n    {\\displaystyle C_{0}(X)}\n  \n of complex-valued continuous functions on X that vanish at infinity, where X is a locally compact Hausdorff space.\nC*-algebras were first considered primarily for their use in quantum mechanics to model algebras of physical observables.  This line of research began with Werner Heisenberg's matrix mechanics and in a more mathematically developed form with Pascual Jordan around 1933.  Subsequently, John von Neumann attempted to establish a general framework for these algebras, which culminated in a series of papers on rings of operators.  These papers considered a special class of C*-algebras that are now known as von Neumann algebras.\nAround 1943, the work of Israel Gelfand and Mark Naimark yielded an abstract characterisation of C*-algebras making no reference to operators on a Hilbert space.\nC*-algebras are now an important tool in the theory of unitary representations of locally compact groups, and are also used in algebraic formulations of quantum mechanics. Another active area of research is the program to obtain classification, or to determine the extent of which classification is possible, for separable simple nuclear C*-algebras.\n\nAbstract characterization\nWe begin with the abstract characterization of C*-algebras given in the 1943 paper by Gelfand and Naimark.\nA C*-algebra, A, is a Banach algebra over the field of complex numbers, together with a map \n  \n    \n      \n        x\n        ↦\n        \n          x\n          \n            ∗\n          \n        \n      \n    \n    {\\textstyle x\\mapsto x^{*}}\n  \n for \n  \n    \n      \n        x\n        ∈\n        A\n      \n    \n    {\\textstyle x\\in A}\n  \n     with the following properties:\n\nIt is an involution, for every x in A:\n\n  \n    \n      \n        \n          x\n          \n            ∗\n            ∗\n          \n        \n        =\n        (\n        \n          x\n          \n            ∗\n          \n        \n        \n          )\n          \n            ∗\n          \n        \n        =\n        x\n      \n    \n    {\\displaystyle x^{**}=(x^{*})^{*}=x}\n  \n\nFor all x, y in A:\n\n  \n    \n      \n        (\n        x\n        +\n        y\n        \n          )\n          \n            ∗\n          \n        \n        =\n        \n          x\n          \n            ∗\n          \n        \n        +\n        \n          y\n          \n            ∗\n          \n        \n      \n    \n    {\\displaystyle (x+y)^{*}=x^{*}+y^{*}}\n  \n\n  \n    \n      \n        (\n        x\n        y\n        \n          )\n          \n            ∗\n          \n        \n        =\n        \n          y\n          \n            ∗\n          \n        \n        \n          x\n          \n            ∗\n          \n        \n      \n    \n    {\\displaystyle (xy)^{*}=y^{*}x^{*}}\n  \n\nFor every complex number \n  \n    \n      \n        λ\n        ∈\n        \n          C\n        \n      \n    \n    {\\displaystyle \\lambda \\in \\mathbb {C} }\n  \n and every x in A:\n\n  \n    \n      \n        (\n        λ\n        x\n        \n          )\n          \n            ∗\n          \n        \n        =\n        \n          \n            λ\n            ¯\n          \n        \n        \n          x\n          \n            ∗\n          \n        \n        .\n      \n    \n    {\\displaystyle (\\lambda x)^{*}={\\overline {\\lambda }}x^{*}.}\n  \n\nFor all x in A:\n\n  \n    \n      \n        ‖\n        x\n        \n          x\n          \n            ∗\n          \n        \n        ‖\n        =\n        ‖\n        x\n        ‖\n        ‖\n        \n          x\n          \n            ∗\n          \n        \n        ‖\n        .\n      \n    \n    {\\displaystyle \\|xx^{*}\\|=\\|x\\|\\|x^{*}\\|.}\n  \n\nRemark. The first four identities say that A is a *-algebra. The last identity is called the C* identity and is equivalent to:\n\n  \n    \n      \n        ‖\n        x\n        \n          x\n          \n            ∗\n          \n        \n        ‖\n        =\n        ‖\n        x\n        \n          ‖\n          \n            2\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\|xx^{*}\\|=\\|x\\|^{2},}\n  \n\nwhich is sometimes called the B*-identity. For history behind the names C*- and B*-algebras, see the history section below.\nThe C*-identity is a very strong requirement. For instance, together with the spectral radius formula, it implies that the C*-norm is uniquely determined by the algebraic structure:\n\n  \n    \n      \n        ‖\n        x\n        \n          ‖\n          \n            2\n     ",
    "links": [
      "*-algebra",
      "Abstract index group",
      "Adjoint of an operator",
      "Adjoint operator",
      "Alain Connes",
      "Algebra over a field",
      "Almost Mathieu operator",
      "Alon–Boppana bound",
      "Amenable Banach algebra",
      "Approximate identity",
      "Approximately finite dimensional C*-algebra",
      "Approximation property",
      "Artin–Wedderburn theorem",
      "Balanced set",
      "Banach *-algebra",
      "Banach algebra",
      "Banach algebra cohomology",
      "Banach function algebra",
      "Banach space",
      "Banach–Alaoglu theorem",
      "Banach–Mazur distance",
      "Barrelled space",
      "Bauer–Fike theorem",
      "Besov space",
      "Borel functional calculus",
      "Bounded linear map",
      "Bounded operator",
      "Calculus of variations",
      "Calkin algebra",
      "Canonical form",
      "Character (mathematics)",
      "Characteristic velocity",
      "Charles Earl Rickart",
      "Choquet theory",
      "Closed graph theorem (functional analysis)",
      "Closed set",
      "Cohen–Hewitt factorization theorem",
      "Compact operator",
      "Compact operator on Hilbert space",
      "Complete topological vector space",
      "Complex number",
      "Conjugate transpose",
      "Continuous functional calculus",
      "Continuous linear operator",
      "Continuous spectrum (functional analysis)",
      "Contraction (operator theory)",
      "Convex cone",
      "Corona theorem",
      "Dagger (typography)",
      "Decomposition of spectrum (functional analysis)"
    ],
    "categories": [
      "Category:All Wikipedia articles written in American English",
      "Category:All articles needing additional references",
      "Category:Articles needing additional references from February 2013",
      "Category:Articles with short description",
      "Category:C*-algebras",
      "Category:Functional analysis",
      "Category:Short description is different from Wikidata",
      "Category:Use American English from January 2019"
    ]
  },
  "Banach algebra": {
    "title": "Banach algebra",
    "url": "https://en.wikipedia.org/wiki/Banach_algebra",
    "summary": "In mathematics, especially functional analysis, a Banach algebra, named after Stefan Banach, is an associative algebra \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n over the real or complex numbers (or over a non-Archimedean complete normed field) that at the same time is also a Banach space, that is, a normed space that is complete in the metric induced by the norm. The norm is required to satisfy\n\n  \n    \n      \n        ‖\n        x\n        \n        y\n        ‖\n         \n        ≤\n        ‖\n        x\n        ‖\n        \n        ‖\n        y\n        ‖\n        \n        \n           for all \n        \n        x\n        ,\n        y\n        ∈\n        A\n        .\n      \n    \n    {\\displaystyle \\|x\\,y\\|\\ \\leq \\|x\\|\\,\\|y\\|\\quad {\\text{ for all }}x,y\\in A.}\n  \n\nThis ensures that the multiplication operation is continuous with respect to the metric topology.\nA Banach algebra is called unital if it has an identity element for the multiplication whose norm is \n  \n    \n      \n       ",
    "content": "In mathematics, especially functional analysis, a Banach algebra, named after Stefan Banach, is an associative algebra \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n over the real or complex numbers (or over a non-Archimedean complete normed field) that at the same time is also a Banach space, that is, a normed space that is complete in the metric induced by the norm. The norm is required to satisfy\n\n  \n    \n      \n        ‖\n        x\n        \n        y\n        ‖\n         \n        ≤\n        ‖\n        x\n        ‖\n        \n        ‖\n        y\n        ‖\n        \n        \n           for all \n        \n        x\n        ,\n        y\n        ∈\n        A\n        .\n      \n    \n    {\\displaystyle \\|x\\,y\\|\\ \\leq \\|x\\|\\,\\|y\\|\\quad {\\text{ for all }}x,y\\in A.}\n  \n\nThis ensures that the multiplication operation is continuous with respect to the metric topology.\nA Banach algebra is called unital if it has an identity element for the multiplication whose norm is \n  \n    \n      \n        1\n        ,\n      \n    \n    {\\displaystyle 1,}\n  \n and commutative if its multiplication is commutative.\nAny Banach algebra \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n (whether it is unital or not) can be embedded isometrically into a unital Banach algebra \n  \n    \n      \n        \n          A\n          \n            e\n          \n        \n      \n    \n    {\\displaystyle A_{e}}\n  \n so as to form a closed ideal of \n  \n    \n      \n        \n          A\n          \n            e\n          \n        \n      \n    \n    {\\displaystyle A_{e}}\n  \n. Often one assumes a priori that the algebra under consideration is unital because one can develop much of the theory by considering \n  \n    \n      \n        \n          A\n          \n            e\n          \n        \n      \n    \n    {\\displaystyle A_{e}}\n  \n and then applying the outcome in the original algebra. However, this is not the case all the time. For example, one cannot define all the trigonometric functions in a Banach algebra without identity.\nThe theory of real Banach algebras can be very different from the theory of complex Banach algebras. For example, the spectrum of an element of a nontrivial complex Banach algebra can never be empty, whereas in a real Banach algebra it could be empty for some elements.\nBanach algebras can also be defined over fields of \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n-adic numbers. This is part of \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n-adic analysis.\n\nExamples\nThe prototypical example of a Banach algebra is \n  \n    \n      \n        \n          C\n          \n            0\n          \n        \n        (\n        X\n        )\n      \n    \n    {\\displaystyle C_{0}(X)}\n  \n, the space of (complex-valued) continuous functions, defined on a locally compact Hausdorff space \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n, that vanish at infinity. \n  \n    \n      \n        \n          C\n          \n            0\n          \n        \n        (\n        X\n        )\n      \n    \n    {\\displaystyle C_{0}(X)}\n  \n is unital if and only if \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is compact. The complex conjugation being an involution, \n  \n    \n      \n        \n          C\n          \n            0\n          \n        \n        (\n        X\n        )\n      \n    \n    {\\displaystyle C_{0}(X)}\n  \n is in fact a C*-algebra. More generally, every C*-algebra is a Banach algebra by definition.\n\nThe set of real (or complex) numbers is a Banach algebra with norm given by the absolute value.\nThe set of all real or complex \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n-by-\n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n matrices becomes a unital Banach algebra if we equip it with a sub-multiplicative matrix norm.\nTake the Banach space \n  \n    \n      \n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{n}}\n  \n (or \n  \n    \n      \n        \n          \n            C\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {C} ^{n}}\n  \n) with norm \n  \n    \n      \n        ‖\n        x\n        ‖\n        =\n        \n          max\n          \n\n          \n        \n        \n          |\n        \n        \n          x\n          \n            i\n          \n        \n        \n          |\n        \n      \n    \n    {\\displaystyle \\|x\\|=\\max _{}|x_{i}|}\n  \n and define multiplication componentwise: \n  \n    \n      \n        \n          (\n          \n            \n              x\n              \n                1\n              \n            \n            ,\n            …\n            ,\n            \n              x\n              \n                n\n              \n            \n          \n          )\n        \n        \n          (\n          \n            \n              y\n              \n                1\n              \n            \n            ,\n            …\n            ,\n            \n           ",
    "links": [
      "*-algebra",
      "Absolute continuity",
      "Absolute value",
      "Absolutely convex set",
      "Absorbing set",
      "Abstract Wiener space",
      "Abstract index group",
      "Adjoint operator",
      "Affine hull",
      "Affine space",
      "Affinoid algebra",
      "Algebraic interior",
      "Almost Mathieu operator",
      "Alon–Boppana bound",
      "Amenable Banach algebra",
      "Anderson–Kadec theorem",
      "Approximate identity",
      "Approximation property",
      "Asplund space",
      "Associative algebra",
      "B-convex space",
      "BK-space",
      "Ba space",
      "Balanced set",
      "Banach *-algebra",
      "Banach algebra cohomology",
      "Banach bundle",
      "Banach function algebra",
      "Banach lattice",
      "Banach manifold",
      "Banach space",
      "Banach–Alaoglu theorem",
      "Banach–Mazur compactum",
      "Banach–Mazur distance",
      "Banach–Mazur theorem",
      "Banach–Saks theorem",
      "Barrelled space",
      "Bauer–Fike theorem",
      "Besov space",
      "Bessel's inequality",
      "Bilinear form",
      "Bilinear map",
      "Binomial theorem",
      "Birnbaum–Orlicz space",
      "Bochner integral",
      "Bochner space",
      "Borel functional calculus",
      "Bounded operator",
      "Bounded set (topological vector space)",
      "Bounded variation"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Banach algebras",
      "Category:Fourier analysis",
      "Category:Pages displaying short descriptions of redirect targets via Module:Annotated link",
      "Category:Science and technology in Poland",
      "Category:Short description matches Wikidata"
    ]
  },
  "C*-algebra": {
    "title": "C*-algebra",
    "url": "https://en.wikipedia.org/wiki/C*-algebra",
    "summary": "In mathematics, specifically in functional analysis, a C∗-algebra (pronounced \"C-star\") is a Banach algebra together with an involution satisfying the properties of the adjoint. A particular case is that of a complex algebra A of continuous linear operators on a complex Hilbert space with two additional properties:\n\nA is a topologically closed set in the norm topology of operators.\nA is closed under the operation of taking adjoints of operators.\nAnother important class of non-Hilbert C*-algebras includes the algebra \n  \n    \n      \n        \n          C\n          \n            0\n          \n        \n        (\n        X\n        )\n      \n    \n    {\\displaystyle C_{0}(X)}\n  \n of complex-valued continuous functions on X that vanish at infinity, where X is a locally compact Hausdorff space.\nC*-algebras were first considered primarily for their use in quantum mechanics to model algebras of physical observables.  This line of research began with Werner Heisenberg's matrix mechanics and in a more",
    "content": "In mathematics, specifically in functional analysis, a C∗-algebra (pronounced \"C-star\") is a Banach algebra together with an involution satisfying the properties of the adjoint. A particular case is that of a complex algebra A of continuous linear operators on a complex Hilbert space with two additional properties:\n\nA is a topologically closed set in the norm topology of operators.\nA is closed under the operation of taking adjoints of operators.\nAnother important class of non-Hilbert C*-algebras includes the algebra \n  \n    \n      \n        \n          C\n          \n            0\n          \n        \n        (\n        X\n        )\n      \n    \n    {\\displaystyle C_{0}(X)}\n  \n of complex-valued continuous functions on X that vanish at infinity, where X is a locally compact Hausdorff space.\nC*-algebras were first considered primarily for their use in quantum mechanics to model algebras of physical observables.  This line of research began with Werner Heisenberg's matrix mechanics and in a more mathematically developed form with Pascual Jordan around 1933.  Subsequently, John von Neumann attempted to establish a general framework for these algebras, which culminated in a series of papers on rings of operators.  These papers considered a special class of C*-algebras that are now known as von Neumann algebras.\nAround 1943, the work of Israel Gelfand and Mark Naimark yielded an abstract characterisation of C*-algebras making no reference to operators on a Hilbert space.\nC*-algebras are now an important tool in the theory of unitary representations of locally compact groups, and are also used in algebraic formulations of quantum mechanics. Another active area of research is the program to obtain classification, or to determine the extent of which classification is possible, for separable simple nuclear C*-algebras.\n\nAbstract characterization\nWe begin with the abstract characterization of C*-algebras given in the 1943 paper by Gelfand and Naimark.\nA C*-algebra, A, is a Banach algebra over the field of complex numbers, together with a map \n  \n    \n      \n        x\n        ↦\n        \n          x\n          \n            ∗\n          \n        \n      \n    \n    {\\textstyle x\\mapsto x^{*}}\n  \n for \n  \n    \n      \n        x\n        ∈\n        A\n      \n    \n    {\\textstyle x\\in A}\n  \n     with the following properties:\n\nIt is an involution, for every x in A:\n\n  \n    \n      \n        \n          x\n          \n            ∗\n            ∗\n          \n        \n        =\n        (\n        \n          x\n          \n            ∗\n          \n        \n        \n          )\n          \n            ∗\n          \n        \n        =\n        x\n      \n    \n    {\\displaystyle x^{**}=(x^{*})^{*}=x}\n  \n\nFor all x, y in A:\n\n  \n    \n      \n        (\n        x\n        +\n        y\n        \n          )\n          \n            ∗\n          \n        \n        =\n        \n          x\n          \n            ∗\n          \n        \n        +\n        \n          y\n          \n            ∗\n          \n        \n      \n    \n    {\\displaystyle (x+y)^{*}=x^{*}+y^{*}}\n  \n\n  \n    \n      \n        (\n        x\n        y\n        \n          )\n          \n            ∗\n          \n        \n        =\n        \n          y\n          \n            ∗\n          \n        \n        \n          x\n          \n            ∗\n          \n        \n      \n    \n    {\\displaystyle (xy)^{*}=y^{*}x^{*}}\n  \n\nFor every complex number \n  \n    \n      \n        λ\n        ∈\n        \n          C\n        \n      \n    \n    {\\displaystyle \\lambda \\in \\mathbb {C} }\n  \n and every x in A:\n\n  \n    \n      \n        (\n        λ\n        x\n        \n          )\n          \n            ∗\n          \n        \n        =\n        \n          \n            λ\n            ¯\n          \n        \n        \n          x\n          \n            ∗\n          \n        \n        .\n      \n    \n    {\\displaystyle (\\lambda x)^{*}={\\overline {\\lambda }}x^{*}.}\n  \n\nFor all x in A:\n\n  \n    \n      \n        ‖\n        x\n        \n          x\n          \n            ∗\n          \n        \n        ‖\n        =\n        ‖\n        x\n        ‖\n        ‖\n        \n          x\n          \n            ∗\n          \n        \n        ‖\n        .\n      \n    \n    {\\displaystyle \\|xx^{*}\\|=\\|x\\|\\|x^{*}\\|.}\n  \n\nRemark. The first four identities say that A is a *-algebra. The last identity is called the C* identity and is equivalent to:\n\n  \n    \n      \n        ‖\n        x\n        \n          x\n          \n            ∗\n          \n        \n        ‖\n        =\n        ‖\n        x\n        \n          ‖\n          \n            2\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\|xx^{*}\\|=\\|x\\|^{2},}\n  \n\nwhich is sometimes called the B*-identity. For history behind the names C*- and B*-algebras, see the history section below.\nThe C*-identity is a very strong requirement. For instance, together with the spectral radius formula, it implies that the C*-norm is uniquely determined by the algebraic structure:\n\n  \n    \n      \n        ‖\n        x\n        \n          ‖\n          \n            2\n     ",
    "links": [
      "*-algebra",
      "Abstract index group",
      "Adjoint of an operator",
      "Adjoint operator",
      "Alain Connes",
      "Algebra over a field",
      "Almost Mathieu operator",
      "Alon–Boppana bound",
      "Amenable Banach algebra",
      "Approximate identity",
      "Approximately finite dimensional C*-algebra",
      "Approximation property",
      "Artin–Wedderburn theorem",
      "Balanced set",
      "Banach *-algebra",
      "Banach algebra",
      "Banach algebra cohomology",
      "Banach function algebra",
      "Banach space",
      "Banach–Alaoglu theorem",
      "Banach–Mazur distance",
      "Barrelled space",
      "Bauer–Fike theorem",
      "Besov space",
      "Borel functional calculus",
      "Bounded linear map",
      "Bounded operator",
      "Calculus of variations",
      "Calkin algebra",
      "Canonical form",
      "Character (mathematics)",
      "Characteristic velocity",
      "Charles Earl Rickart",
      "Choquet theory",
      "Closed graph theorem (functional analysis)",
      "Closed set",
      "Cohen–Hewitt factorization theorem",
      "Compact operator",
      "Compact operator on Hilbert space",
      "Complete topological vector space",
      "Complex number",
      "Conjugate transpose",
      "Continuous functional calculus",
      "Continuous linear operator",
      "Continuous spectrum (functional analysis)",
      "Contraction (operator theory)",
      "Convex cone",
      "Corona theorem",
      "Dagger (typography)",
      "Decomposition of spectrum (functional analysis)"
    ],
    "categories": [
      "Category:All Wikipedia articles written in American English",
      "Category:All articles needing additional references",
      "Category:Articles needing additional references from February 2013",
      "Category:Articles with short description",
      "Category:C*-algebras",
      "Category:Functional analysis",
      "Category:Short description is different from Wikidata",
      "Category:Use American English from January 2019"
    ]
  },
  "Center (ring theory)": {
    "title": "Center (ring theory)",
    "url": "https://en.wikipedia.org/wiki/Center_(ring_theory)",
    "summary": "In algebra, the center of a ring R is the subring consisting of the elements x such that xy = yx for all elements y in R. It is a commutative ring and is denoted as Z(R); 'Z' stands for the German word Zentrum, meaning \"center\".\nIf R is a ring, then R is an associative algebra over its center. Conversely, if R is an associative algebra over a commutative subring S, then S is a subring of the center of R, and if S happens to be the center of R, then the algebra R is called a central algebra.",
    "content": "In algebra, the center of a ring R is the subring consisting of the elements x such that xy = yx for all elements y in R. It is a commutative ring and is denoted as Z(R); 'Z' stands for the German word Zentrum, meaning \"center\".\nIf R is a ring, then R is an associative algebra over its center. Conversely, if R is an associative algebra over a commutative subring S, then S is a subring of the center of R, and if S happens to be the center of R, then the algebra R is called a central algebra.\n\nExamples\nThe center of a commutative ring R is R itself.\nThe center of a skew-field is a field.\nThe center of the (full) matrix ring with entries in a commutative ring R consists of R-scalar multiples of the identity matrix.\nLet F be a field extension of a field k, and R an algebra over k. Then Z(R ⊗k F) = Z(R) ⊗k F.\nThe center of the universal enveloping algebra of a Lie algebra plays an important role in the representation theory of Lie algebras. For example, a Casimir element is an element of such a center that is used to analyze Lie algebra representations. See also: Harish-Chandra isomorphism.\nThe center of a simple algebra is a field.\n\nSee also\nCenter of a group\nCentral simple algebra\nMorita equivalence\n\nNotes\n\n\n== References ==",
    "links": [
      "Abstract algebra",
      "Algebra",
      "Associative algebra",
      "Casimir element",
      "Center of a group",
      "Central simple algebra",
      "Commutative ring",
      "Field (mathematics)",
      "Field extension",
      "Harish-Chandra isomorphism",
      "ISBN (identifier)",
      "Identity matrix",
      "Lie algebra",
      "Lie algebra representation",
      "Matrix ring",
      "Morita equivalence",
      "Representation theory of Lie algebras",
      "Simple algebra",
      "Skew-field",
      "Subring",
      "Universal enveloping algebra",
      "Wikipedia:Stub",
      "Template:Algebra-stub",
      "Template talk:Algebra-stub"
    ],
    "categories": [
      "Category:Algebra stubs",
      "Category:All Wikipedia articles written in American English",
      "Category:All stub articles",
      "Category:Articles with short description",
      "Category:Ring theory",
      "Category:Short description is different from Wikidata",
      "Category:Use American English from March 2021",
      "Category:Use mdy dates from March 2021"
    ]
  },
  "Covariance and contravariance of vectors": {
    "title": "Covariance and contravariance of vectors",
    "url": "https://en.wikipedia.org/wiki/Covariance_and_contravariance_of_vectors",
    "summary": "In physics, especially in multilinear algebra and tensor analysis, covariance and contravariance describe how the quantitative description of certain geometric or physical entities changes with a change of basis.  Briefly, a contravariant vector is a list of numbers that transforms oppositely to a change of basis, and a covariant vector is a list of numbers that transforms in the same way.  Contravariant vectors are often just called vectors and covariant vectors are called covectors or dual vectors.  The terms covariant and contravariant were introduced by James Joseph Sylvester in 1851.\nCurvilinear coordinate systems, such as cylindrical or spherical coordinates, are often used in physical and geometric problems.  Associated with any coordinate system is a natural choice of coordinate basis for vectors based at each point of the space, and covariance and contravariance are particularly important for understanding how the coordinate description of a vector changes by passing from one ",
    "content": "In physics, especially in multilinear algebra and tensor analysis, covariance and contravariance describe how the quantitative description of certain geometric or physical entities changes with a change of basis.  Briefly, a contravariant vector is a list of numbers that transforms oppositely to a change of basis, and a covariant vector is a list of numbers that transforms in the same way.  Contravariant vectors are often just called vectors and covariant vectors are called covectors or dual vectors.  The terms covariant and contravariant were introduced by James Joseph Sylvester in 1851.\nCurvilinear coordinate systems, such as cylindrical or spherical coordinates, are often used in physical and geometric problems.  Associated with any coordinate system is a natural choice of coordinate basis for vectors based at each point of the space, and covariance and contravariance are particularly important for understanding how the coordinate description of a vector changes by passing from one coordinate system to another. Tensors are objects in multilinear algebra that can have aspects of both covariance and contravariance.\n\nIntroduction\nIn physics, a vector typically arises as the outcome of a measurement or series of measurements, and is represented as a list (or tuple) of numbers such as\n\n  \n    \n      \n        (\n        \n          v\n          \n            1\n          \n        \n        ,\n        \n          v\n          \n            2\n          \n        \n        ,\n        \n          v\n          \n            3\n          \n        \n        )\n        .\n      \n    \n    {\\displaystyle (v_{1},v_{2},v_{3}).}\n  \n\nThe numbers in the list depend on the choice of coordinate system.  For instance, if the vector represents position with respect to an observer (position vector), then the coordinate system may be obtained from a system of rigid rods, or reference axes, along which the components v1, v2, and v3 are measured.  For a vector to represent a geometric object, it must be possible to describe how it looks in any other coordinate system.  That is to say, the components of the vectors will transform in a certain way in passing from one coordinate system to another.\nA simple illustrative case is that of a Euclidean vector.  For a vector, once a set of basis vectors has been defined, then the components of that vector will always vary opposite to that of the basis vectors.  That vector is therefore defined as a contravariant tensor.  Take a standard position vector for example. By changing the scale of the reference axes from meters to centimeters (that is, dividing the scale of the reference axes by 100, so that the basis vectors now are \n  \n    \n      \n        .01\n      \n    \n    {\\displaystyle .01}\n  \n meters long), the components of the measured position vector are multiplied by 100.  A vector's components change scale inversely to changes in scale to the reference axes, and consequently a vector is called a contravariant tensor.\nA vector, which is an example of a contravariant tensor, has components that transform inversely to the transformation of the reference axes, (with example transformations including rotation and dilation). The vector itself does not change under these operations; instead, the components of the vector change in a way that cancels the change in the spatial axes.  In other words, if the reference axes were rotated in one direction, the component representation of the vector would rotate in exactly the opposite way. Similarly, if the reference axes were stretched in one direction, the components of the vector, would reduce in an exactly compensating way.  Mathematically, if the coordinate system undergoes a transformation described by an \n  \n    \n      \n        n\n        ×\n        n\n      \n    \n    {\\displaystyle n\\times n}\n  \n invertible matrix M, so that the basis vectors transform according to \n  \n    \n      \n        \n          \n            [\n            \n              \n                \n                  \n                    \n                      e\n                    \n                    \n                      1\n                    \n                    \n                      ′\n                    \n                  \n                   \n                  \n                    \n                      e\n                    \n                    \n                      2\n                    \n                    \n                      ′\n                    \n                  \n                   \n                  .\n                  .\n                  .\n                   \n                  \n                    \n                      e\n                    \n                    \n                      n\n                    \n                    \n                      ′\n                    \n                  \n                \n              \n            \n            ]\n          \n        \n        =\n        \n          \n            [\n            \n              \n                \n                  \n              ",
    "links": [
      "1-form",
      "Abstract index notation",
      "Active and passive transformation",
      "Affine connection",
      "Albert Einstein",
      "Angular momentum",
      "Antisymmetric tensor",
      "Augustin-Louis Cauchy",
      "Basis (linear algebra)",
      "Basis of a vector space",
      "Basis vector",
      "Bernhard Riemann",
      "Bibcode (identifier)",
      "Bilinear form",
      "Carl Friedrich Gauss",
      "Cartan formalism (physics)",
      "Cartesian coordinate system",
      "Category theory",
      "Cauchy stress tensor",
      "Change of basis",
      "Column vector",
      "Computer vision",
      "Connection form",
      "Continuum mechanics",
      "Contraction of a tensor",
      "Contravariant functor",
      "Coordinate system",
      "Cotangent bundle",
      "Cotangent vector",
      "Covariance and contravariance (disambiguation)",
      "Covariant derivative",
      "Covariant functor",
      "Covariant transformation",
      "Curvilinear coordinate system",
      "Curvilinear coordinates",
      "Cylindrical coordinates",
      "Differential form",
      "Differential geometry",
      "Dilation (metric space)",
      "Dimension",
      "Doi (identifier)",
      "Dot product",
      "Dual basis",
      "Dual space",
      "Dyadics",
      "Einstein notation",
      "Einstein tensor",
      "Electromagnetic tensor",
      "Electromagnetism",
      "Elwin Bruno Christoffel"
    ],
    "categories": [
      "Category:Articles needing more detailed references",
      "Category:Articles with short description",
      "Category:CS1: long volume value",
      "Category:Differential geometry",
      "Category:Riemannian geometry",
      "Category:Short description is different from Wikidata",
      "Category:Tensors",
      "Category:Vectors (mathematics and physics)"
    ]
  },
  "Differential algebra": {
    "title": "Differential algebra",
    "url": "https://en.wikipedia.org/wiki/Differential_algebra",
    "summary": "In mathematics, differential algebra is, broadly speaking, the area of mathematics consisting in the study of differential equations and differential operators as algebraic objects in view of deriving properties of differential equations and operators without computing the solutions,  similarly as polynomial algebras are used for the study of algebraic varieties, which are solution sets of systems of polynomial equations. Weyl algebras and Lie algebras may be considered as belonging to differential algebra.\nMore specifically, differential algebra refers  to the theory introduced by Joseph Ritt in 1950, in which differential rings, differential fields, and differential algebras are rings, fields, and algebras equipped with finitely many derivations.\nA natural example of a differential field is the field of rational functions in one variable over the complex numbers, \n  \n    \n      \n        \n          C\n        \n        (\n        t\n        )\n        ,\n      \n    \n    {\\displaystyle \\math",
    "content": "In mathematics, differential algebra is, broadly speaking, the area of mathematics consisting in the study of differential equations and differential operators as algebraic objects in view of deriving properties of differential equations and operators without computing the solutions,  similarly as polynomial algebras are used for the study of algebraic varieties, which are solution sets of systems of polynomial equations. Weyl algebras and Lie algebras may be considered as belonging to differential algebra.\nMore specifically, differential algebra refers  to the theory introduced by Joseph Ritt in 1950, in which differential rings, differential fields, and differential algebras are rings, fields, and algebras equipped with finitely many derivations.\nA natural example of a differential field is the field of rational functions in one variable over the complex numbers, \n  \n    \n      \n        \n          C\n        \n        (\n        t\n        )\n        ,\n      \n    \n    {\\displaystyle \\mathbb {C} (t),}\n  \n where the derivation is differentiation with respect to \n  \n    \n      \n        t\n        .\n      \n    \n    {\\displaystyle t.}\n  \n More generally, every differential equation may be viewed as an element of a differential algebra over the differential field generated by the (known) functions appearing in the equation.\n\nHistory\nJoseph Ritt developed differential algebra because he viewed attempts to reduce systems of differential equations to various canonical forms as an unsatisfactory approach.  However, the success of algebraic elimination methods and algebraic manifold theory motivated Ritt to consider a similar approach for differential equations.  His efforts led to an initial paper Manifolds Of Functions Defined By Systems Of Algebraic Differential Equations and 2 books, Differential Equations From The Algebraic Standpoint and Differential Algebra.  Ellis Kolchin, Ritt's student, advanced this field and published Differential Algebra And Algebraic Groups.\n\nDifferential rings\nDefinition\nA derivation \n  \n    \n      \n        ∂\n      \n    \n    {\\textstyle \\partial }\n  \n on a ring \n  \n    \n      \n        R\n      \n    \n    {\\textstyle R}\n  \n is a function\n\n  \n    \n      \n        ∂\n        :\n        R\n        →\n        R\n        \n      \n    \n    {\\displaystyle \\partial :R\\to R\\,}\n  \n\nsuch that \n\n  \n    \n      \n        ∂\n        (\n        \n          r\n          \n            1\n          \n        \n        +\n        \n          r\n          \n            2\n          \n        \n        )\n        =\n        ∂\n        \n          r\n          \n            1\n          \n        \n        +\n        ∂\n        \n          r\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\partial (r_{1}+r_{2})=\\partial r_{1}+\\partial r_{2}}\n  \n\nand\n\n  \n    \n      \n        ∂\n        (\n        \n          r\n          \n            1\n          \n        \n        \n          r\n          \n            2\n          \n        \n        )\n        =\n        (\n        ∂\n        \n          r\n          \n            1\n          \n        \n        )\n        \n          r\n          \n            2\n          \n        \n        +\n        \n          r\n          \n            1\n          \n        \n        (\n        ∂\n        \n          r\n          \n            2\n          \n        \n        )\n        \n      \n    \n    {\\displaystyle \\partial (r_{1}r_{2})=(\\partial r_{1})r_{2}+r_{1}(\\partial r_{2})\\quad }\n  \n (Leibniz product rule),\nfor every \n  \n    \n      \n        \n          r\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle r_{1}}\n  \n and \n  \n    \n      \n        \n          r\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle r_{2}}\n  \n in \n  \n    \n      \n        R\n        .\n      \n    \n    {\\displaystyle R.}\n  \n\nA derivation is linear over the integers since these identities imply \n  \n    \n      \n        ∂\n        (\n        0\n        )\n        =\n        ∂\n        (\n        1\n        )\n        =\n        0\n      \n    \n    {\\displaystyle \\partial (0)=\\partial (1)=0}\n  \n and \n  \n    \n      \n        ∂\n        (\n        −\n        r\n        )\n        =\n        −\n        ∂\n        (\n        r\n        )\n        .\n      \n    \n    {\\displaystyle \\partial (-r)=-\\partial (r).}\n  \n\nA differential ring is a commutative ring \n  \n    \n      \n        R\n      \n    \n    {\\displaystyle R}\n  \n equipped with one or more derivations that commute pairwise; that is, \n  \n    \n      \n        \n          ∂\n          \n            1\n          \n        \n        (\n        \n          ∂\n          \n            2\n          \n        \n        (\n        r\n        )\n        )\n        =\n        \n          ∂\n          \n            2\n          \n        \n        (\n        \n          ∂\n          \n            1\n          \n        \n        (\n        r\n        )\n        )\n      \n    \n    {\\displaystyle \\partial _{1}(\\partial _{2}(r))=\\partial _{2}(\\partial _{1}(r))}\n  \n for every pair of derivations and every \n  \n    \n      \n        r\n        ∈\n      ",
    "links": [
      "Algebra",
      "Algebra over a field",
      "Algebraic varieties",
      "ArXiv (identifier)",
      "Arg max",
      "Arithmetic derivative",
      "Ascending chain condition",
      "Bibcode (identifier)",
      "Bilinear form",
      "Binomial coefficient",
      "Cell biology",
      "Chain complex",
      "Chaos theory",
      "Closure (mathematics)",
      "Coefficient",
      "Commutative ring",
      "Commutator",
      "Complex number",
      "Constant (mathematics)",
      "Constant function",
      "D-module",
      "Degree of a polynomial",
      "Derivation (differential algebra)",
      "Difference algebra",
      "Differential-algebraic system of equations",
      "Differential Galois theory",
      "Differential algebraic geometry",
      "Differential calculus over commutative algebras",
      "Differential equation",
      "Differential graded algebra",
      "Differential ideal",
      "Differential operator",
      "Differential operators",
      "Differentially closed field",
      "Direct sum",
      "Doi (identifier)",
      "Elimination theory",
      "Ellis Kolchin",
      "Endomorphism",
      "Field (mathematics)",
      "Finitely generated ideal",
      "Free commutative monoid",
      "Function (mathematics)",
      "Function composition",
      "Graded vector space",
      "Greatest common divisor",
      "Gröbner basis",
      "Hardy field",
      "Hdl (identifier)",
      "ISBN (identifier)"
    ],
    "categories": [
      "Category:All articles with unsourced statements",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from March 2023",
      "Category:CS1 errors: ISBN date",
      "Category:CS1 maint: location missing publisher",
      "Category:Differential algebra",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Dimension (linear algebra)": {
    "title": "Dimension (vector space)",
    "url": "https://en.wikipedia.org/wiki/Dimension_(vector_space)",
    "summary": "In mathematics, the dimension of a vector space V is the cardinality (i.e., the number of vectors) of a basis of V over its base field. It is sometimes called Hamel dimension (after Georg Hamel) or algebraic dimension to distinguish it from other types of dimension.\nFor every vector space there exists a basis, and all bases of a vector space have equal cardinality; as a result, the dimension of a vector space is uniquely defined. We say \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n is finite-dimensional if the dimension of \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n is finite, and infinite-dimensional if its dimension is infinite.\nThe dimension of the vector space \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n over the field \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n can be written as \n  \n    \n      \n        \n          dim\n          \n            F\n          \n        \n        ⁡\n        (\n        V\n        )\n    ",
    "content": "In mathematics, the dimension of a vector space V is the cardinality (i.e., the number of vectors) of a basis of V over its base field. It is sometimes called Hamel dimension (after Georg Hamel) or algebraic dimension to distinguish it from other types of dimension.\nFor every vector space there exists a basis, and all bases of a vector space have equal cardinality; as a result, the dimension of a vector space is uniquely defined. We say \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n is finite-dimensional if the dimension of \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n is finite, and infinite-dimensional if its dimension is infinite.\nThe dimension of the vector space \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n over the field \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n can be written as \n  \n    \n      \n        \n          dim\n          \n            F\n          \n        \n        ⁡\n        (\n        V\n        )\n      \n    \n    {\\displaystyle \\dim _{F}(V)}\n  \n or as \n  \n    \n      \n        [\n        V\n        :\n        F\n        ]\n        ,\n      \n    \n    {\\displaystyle [V:F],}\n  \n read \"dimension of \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n over \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n\". When \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n can be inferred from context, \n  \n    \n      \n        dim\n        ⁡\n        (\n        V\n        )\n      \n    \n    {\\displaystyle \\dim(V)}\n  \n is typically written.\n\nExamples\nThe vector space \n  \n    \n      \n        \n          \n            R\n          \n          \n            3\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{3}}\n  \n has\n\n  \n    \n      \n        \n          {\n          \n            \n              \n                (\n                \n                  \n                    \n                      1\n                    \n                  \n                  \n                    \n                      0\n                    \n                  \n                  \n                    \n                      0\n                    \n                  \n                \n                )\n              \n            \n            ,\n            \n              \n                (\n                \n                  \n                    \n                      0\n                    \n                  \n                  \n                    \n                      1\n                    \n                  \n                  \n                    \n                      0\n                    \n                  \n                \n                )\n              \n            \n            ,\n            \n              \n                (\n                \n                  \n                    \n                      0\n                    \n                  \n                  \n                    \n                      0\n                    \n                  \n                  \n                    \n                      1\n                    \n                  \n                \n                )\n              \n            \n          \n          }\n        \n      \n    \n    {\\displaystyle \\left\\{{\\begin{pmatrix}1\\\\0\\\\0\\end{pmatrix}},{\\begin{pmatrix}0\\\\1\\\\0\\end{pmatrix}},{\\begin{pmatrix}0\\\\0\\\\1\\end{pmatrix}}\\right\\}}\n  \n\nas a standard basis, and therefore \n  \n    \n      \n        \n          dim\n          \n            \n              R\n            \n          \n        \n        ⁡\n        (\n        \n          \n            R\n          \n          \n            3\n          \n        \n        )\n        =\n        3.\n      \n    \n    {\\displaystyle \\dim _{\\mathbb {R} }(\\mathbb {R} ^{3})=3.}\n  \n More generally, \n  \n    \n      \n        \n          dim\n          \n            \n              R\n            \n          \n        \n        ⁡\n        (\n        \n          \n            R\n          \n          \n            n\n          \n        \n        )\n        =\n        n\n        ,\n      \n    \n    {\\displaystyle \\dim _{\\mathbb {R} }(\\mathbb {R} ^{n})=n,}\n  \n and even more generally, \n  \n    \n      \n        \n          dim\n          \n            F\n          \n        \n        ⁡\n        (\n        \n          F\n          \n            n\n          \n        \n        )\n        =\n        n\n      \n    \n    {\\displaystyle \\dim _{F}(F^{n})=n}\n  \n for any field \n  \n    \n      \n        F\n        .\n      \n    \n    {\\displaystyle F.}\n  \n \nThe complex numbers \n  \n    \n      \n        \n          C\n        \n      \n    \n    {\\displaystyle \\mathbb {C} }\n  \n are both a real and complex vector space; we have \n  \n    \n      \n        \n          dim\n          \n            \n              R\n            \n          \n        \n        ⁡\n        (\n        \n          C\n        \n        )\n        =\n        2\n      \n    \n    {\\displaystyle \\dim _{\\mathbb {R} }(\\mathbb {C} )=2}\n  \n and \n  \n    \n      \n        \n          dim\n          \n            \n              C\n            \n          \n        \n        ⁡\n        (\n        ",
    "links": [
      "Affine space",
      "Algebra over a field",
      "Axiom of choice",
      "Banach space",
      "Basic Linear Algebra Subprograms",
      "Basis (linear algebra)",
      "Bialgebra",
      "Bijective",
      "Bilinear map",
      "Bivector",
      "Block matrix",
      "Cardinality",
      "Cayley–Dickson construction",
      "Change of basis",
      "Character (mathematics)",
      "Circular definition",
      "Codimension",
      "Comparison of linear algebra libraries",
      "Complex number",
      "Counit",
      "Cramer's rule",
      "Cross-polytope",
      "Cross product",
      "Degrees of freedom",
      "Demihypercube",
      "Determinant",
      "Dimension",
      "Dimension of an algebraic variety",
      "Dimension theorem for vector spaces",
      "Direct sum of modules",
      "Dot product",
      "Dual space",
      "Eigenvalues and eigenvectors",
      "Eight-dimensional space",
      "Euclidean space",
      "Euclidean vector",
      "Exterior algebra",
      "Field (mathematics)",
      "Field extension",
      "Five-dimensional space",
      "Floating-point arithmetic",
      "Four-dimensional space",
      "Fractal dimension",
      "Free module",
      "Function space",
      "Gaussian elimination",
      "Geometric algebra",
      "Georg Hamel",
      "Glossary of linear algebra",
      "Graded dimension"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Dimension",
      "Category:Linear algebra",
      "Category:Pages displaying short descriptions of redirect targets via Module:Annotated link",
      "Category:Short description matches Wikidata",
      "Category:Vector spaces",
      "Category:Vectors (mathematics and physics)"
    ]
  },
  "Division ring": {
    "title": "Division ring",
    "url": "https://en.wikipedia.org/wiki/Division_ring",
    "summary": "In algebra, a division ring, also called a skew field (or, occasionally, a sfield), is a nontrivial ring in which division by nonzero elements is defined. Specifically, it is a nontrivial ring in which every nonzero element a has a multiplicative inverse, that is, an element usually denoted a–1, such that a a–1 = a–1 a = 1. So, (right) division may be defined as a / b = a b–1, but this notation is avoided, as one may have a b–1 ≠ b–1 a.\nA commutative division ring is a field. Wedderburn's little theorem asserts that all finite division rings are commutative and therefore finite fields. \nHistorically, division rings were sometimes referred to as fields, while fields were called \"commutative fields\". In some languages, such as French, the word equivalent to \"field\" (\"corps\") is used for both commutative and noncommutative cases, and the distinction between the two cases is made by adding qualificatives such as \"corps commutatif\" (commutative field) or \"corps gauche\" (skew field).\nAll div",
    "content": "In algebra, a division ring, also called a skew field (or, occasionally, a sfield), is a nontrivial ring in which division by nonzero elements is defined. Specifically, it is a nontrivial ring in which every nonzero element a has a multiplicative inverse, that is, an element usually denoted a–1, such that a a–1 = a–1 a = 1. So, (right) division may be defined as a / b = a b–1, but this notation is avoided, as one may have a b–1 ≠ b–1 a.\nA commutative division ring is a field. Wedderburn's little theorem asserts that all finite division rings are commutative and therefore finite fields. \nHistorically, division rings were sometimes referred to as fields, while fields were called \"commutative fields\". In some languages, such as French, the word equivalent to \"field\" (\"corps\") is used for both commutative and noncommutative cases, and the distinction between the two cases is made by adding qualificatives such as \"corps commutatif\" (commutative field) or \"corps gauche\" (skew field).\nAll division rings are simple. That is, they have no two-sided ideal besides the zero ideal and itself.\n\nRelation to fields and linear algebra\nAll fields are division rings, and every non-field division ring is noncommutative. The best known example is the ring of quaternions. If one allows only rational instead of real coefficients in the constructions of the quaternions, one obtains another division ring. In general, if R is a ring and S is a simple module over R, then, by Schur's lemma, the endomorphism ring of S is a division ring; every division ring arises in this fashion from some simple module.\nMuch of linear algebra may be formulated, and remains correct, for modules over a division ring D instead of vector spaces over a field. Doing so, one must specify whether one is considering right or left modules, and some care is needed in properly distinguishing left and right in formulas. In particular, every module has a basis, and Gaussian elimination can be used. So, everything that can be defined with these tools works on division algebras. Matrices and their products are defined similarly. However, a matrix that is left invertible need not to be right invertible, and if it is, its right inverse can differ from its left inverse. (See Generalized inverse § One-sided inverse.)\nDeterminants are not defined over noncommutative division algebras.  Most things that require this concept cannot be generalized to noncommutative division algebras, although generalizations such as quasideterminants allow some results to be recovered.\nWorking in coordinates, elements of a finite-dimensional right module can be represented by column vectors, which can be multiplied on the right by scalars, and on the left by matrices (representing linear maps); for elements of a finite-dimensional left module, row vectors must be used, which can be multiplied on the left by scalars, and on the right by matrices. The dual of a right module is a left module, and vice versa. The transpose of a matrix must be viewed as a matrix over the opposite division ring Dop in order for the rule (AB)T = BTAT to remain valid.\nEvery module over a division ring is free; that is, it has a basis, and all bases of a module have the same number of elements. Linear maps between finite-dimensional modules over a division ring can be described by matrices; the fact that linear maps by definition commute with scalar multiplication is most conveniently represented in notation by writing them on the opposite side of vectors as scalars are. The Gaussian elimination algorithm remains applicable. The column rank of a matrix is the dimension of the right module generated by the columns, and the row rank is the dimension of the left module generated by the rows; the same proof as for the vector space case can be used to show that these ranks are the same and define the rank of a matrix.\nDivision rings are the only rings over which every module is free: a ring R is a division ring if and only if every R-module is free.\nThe center of a division ring is commutative and therefore a field. Every division ring is therefore a division algebra over its center. Division rings can be roughly classified according to whether or not they are finite dimensional or infinite dimensional over their centers. The former are called centrally finite and the latter centrally infinite. Every field is one dimensional over its center. The ring of Hamiltonian quaternions forms a four-dimensional algebra over its center, which is isomorphic to the real numbers.\n\nExamples\nAs noted above, all fields are division rings.\nThe quaternions form a noncommutative division ring.\nThe subset of the quaternions a + bi + cj + dk, such that a, b, c, and d belong to a fixed subfield of the real numbers, is a noncommutative division ring. When this subfield is the field of rational numbers, this is the division ring of rational quaternions.\nLet \n  \n    \n      \n        σ\n        :\n        \n          C\n        \n        →\n        \n     ",
    "links": [
      "Abelian group",
      "Algebra",
      "Algebra over a field",
      "Algebraic structure",
      "Associative algebra",
      "Automorphism",
      "Basis (linear algebra)",
      "Bialgebra",
      "Bibcode (identifier)",
      "Boolean algebra (structure)",
      "Cambridge University Press",
      "Center of a ring",
      "Commutative ring",
      "Complemented lattice",
      "Complex conjugate",
      "Complex number",
      "Composition algebra",
      "Determinant",
      "Distributive law",
      "Division (mathematics)",
      "Division algebra",
      "Doi (identifier)",
      "Domain (ring theory)",
      "Emil Artin",
      "Emmy Noether",
      "Endomorphism ring",
      "Ernst Witt",
      "Field (mathematics)",
      "Finite field",
      "Formal Laurent series",
      "Free module",
      "French language",
      "Frobenius theorem (real division algebras)",
      "Gaussian elimination",
      "Generalized inverse",
      "Google Books",
      "Graded ring",
      "Graduate Texts in Mathematics",
      "Group (mathematics)",
      "Group theory",
      "Group with operators",
      "Hamiltonian quaternions",
      "Heyting algebra",
      "Hopf algebra",
      "Hua's identity",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "Ideal (ring theory)",
      "Identity function",
      "Integral domain"
    ],
    "categories": [
      "Category:All articles with unsourced statements",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from July 2023",
      "Category:Ring theory",
      "Category:Short description is different from Wikidata",
      "Category:Wikipedia articles needing clarification from February 2025"
    ]
  },
  "Domain (ring theory)": {
    "title": "Domain (ring theory)",
    "url": "https://en.wikipedia.org/wiki/Domain_(ring_theory)",
    "summary": "In algebra, a domain is a nonzero ring in which ab = 0 implies a = 0 or b = 0. (Sometimes such a ring is said to \"have the zero-product property\".) Equivalently, a domain is a ring in which 0 is the only left zero divisor (or equivalently, the only right zero divisor).   A commutative domain is called an integral domain.  Mathematical literature contains multiple variants of the definition of \"domain\".",
    "content": "In algebra, a domain is a nonzero ring in which ab = 0 implies a = 0 or b = 0. (Sometimes such a ring is said to \"have the zero-product property\".) Equivalently, a domain is a ring in which 0 is the only left zero divisor (or equivalently, the only right zero divisor).   A commutative domain is called an integral domain.  Mathematical literature contains multiple variants of the definition of \"domain\".\n\nExamples and non-examples\nThe ring \n  \n    \n      \n        \n          Z\n        \n        \n          /\n        \n        6\n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} /6\\mathbb {Z} }\n  \n is not a domain, because the images of 2 and 3 in this ring are nonzero elements with product 0.  More generally, for a positive integer \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n, the ring \n  \n    \n      \n        \n          Z\n        \n        \n          /\n        \n        n\n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} /n\\mathbb {Z} }\n  \n is a domain if and only if \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n is prime.\nA finite domain is automatically a finite field, by Wedderburn's little theorem.\nThe quaternions form a noncommutative domain. More generally, any division ring is a domain, since every nonzero element is invertible.\nThe set of all Lipschitz quaternions, that is, quaternions of the form \n  \n    \n      \n        a\n        +\n        b\n        i\n        +\n        c\n        j\n        +\n        d\n        k\n      \n    \n    {\\displaystyle a+bi+cj+dk}\n  \n where a, b, c, d are integers, is a noncommutative subring of the quaternions, hence a noncommutative domain.\nSimilarly, the set of all Hurwitz quaternions, that is, quaternions of the form \n  \n    \n      \n        a\n        +\n        b\n        i\n        +\n        c\n        j\n        +\n        d\n        k\n      \n    \n    {\\displaystyle a+bi+cj+dk}\n  \n where a, b, c, d are either all integers or all half-integers, is a noncommutative domain.\nA matrix ring Mn(R) for n ≥ 2 is never a domain: if R is nonzero, such a matrix ring has nonzero zero divisors and even nilpotent elements other than 0. For example, the square of the matrix unit E12 is 0.\nThe tensor algebra of a vector space, or equivalently, the algebra of polynomials in noncommuting variables over a field, \n  \n    \n      \n        \n          K\n        \n        ⟨\n        \n          x\n          \n            1\n          \n        \n        ,\n        …\n        ,\n        \n          x\n          \n            n\n          \n        \n        ⟩\n        ,\n      \n    \n    {\\displaystyle \\mathbb {K} \\langle x_{1},\\ldots ,x_{n}\\rangle ,}\n  \n is a domain. This may be proved using an ordering on the noncommutative monomials.\nIf R is a domain and S is an Ore extension of R then S is a domain.\nThe Weyl algebra is a noncommutative domain.\nThe universal enveloping algebra of any Lie algebra over a field is a domain. The proof uses the standard filtration on the universal enveloping algebra and the Poincaré–Birkhoff–Witt theorem.\n\nGroup rings and the zero divisor problem\nSuppose that G is a group and K is a field. Is the group ring R = K[G] a domain?  The identity\n\n  \n    \n      \n        (\n        1\n        −\n        g\n        )\n        (\n        1\n        +\n        g\n        +\n        ⋯\n        +\n        \n          g\n          \n            n\n            −\n            1\n          \n        \n        )\n        =\n        1\n        −\n        \n          g\n          \n            n\n          \n        \n        ,\n      \n    \n    {\\displaystyle (1-g)(1+g+\\cdots +g^{n-1})=1-g^{n},}\n  \n\nshows that an element g of finite order n > 1 induces a zero divisor 1 − g in R. The zero divisor problem asks whether this is the only obstruction; in other words,\n\nGiven a field K and a torsion-free group G, is it true that K[G] contains no zero divisors?\nNo counterexamples are known, but the problem remains open in general (as of 2017).\nFor many special classes of groups, the answer is affirmative. Farkas and Snider proved in 1976 that if G is a torsion-free polycyclic-by-finite group and char K = 0 then the group ring K[G] is a domain. Later (1980) Cliff removed the restriction on the characteristic of the field. In 1988, Kropholler, Linnell and Moody generalized these results to the case of torsion-free solvable and solvable-by-finite groups. Earlier (1965) work of Michel Lazard, whose importance was not appreciated by the specialists in the field for about 20 years, had dealt with the case where K is the ring of p-adic integers and G is the pth congruence subgroup of GL(n, Z).\n\nSpectrum of an integral domain\nZero divisors have a topological interpretation, at least in the case of commutative rings: a ring R is an integral domain if and only if it is reduced and its spectrum Spec R is an irreducible topological space. The first property is often considered to encode some infinitesimal information, whereas the second one is more geometric.\nAn example: the ring k[x, y]/(xy",
    "links": [
      "A K Peters",
      "Abelian group",
      "Algebra",
      "Algebra over a field",
      "Algebraic structure",
      "Associative algebra",
      "Bialgebra",
      "Boolean algebra (structure)",
      "Commutative ring",
      "Complemented lattice",
      "Composition algebra",
      "Congruence subgroup",
      "Division ring",
      "Divisor (ring theory)",
      "Field (mathematics)",
      "Finite field",
      "Graded ring",
      "Group (mathematics)",
      "Group ring",
      "Group theory",
      "Group with operators",
      "Half-integers",
      "Heyting algebra",
      "Hopf algebra",
      "Hurwitz quaternion",
      "ISBN (identifier)",
      "Integral domain",
      "Invertible element",
      "Irreducible topological space",
      "Lattice (order)",
      "Lie algebra",
      "Lie group",
      "Linear algebra",
      "Lipschitz quaternion",
      "MR (identifier)",
      "Magma (algebra)",
      "Map of lattices",
      "Matrix ring",
      "Matrix unit",
      "Michel Lazard",
      "Modular arithmetic",
      "Module (mathematics)",
      "Monoid",
      "Nathan Jacobson",
      "Near-ring",
      "Nilpotent",
      "Non-associative algebra",
      "Order (group theory)",
      "Ore extension",
      "P-adic integers"
    ],
    "categories": [
      "Category:Algebraic structures",
      "Category:Articles with short description",
      "Category:Ring theory",
      "Category:Short description matches Wikidata"
    ]
  },
  "Field extension": {
    "title": "Field extension",
    "url": "https://en.wikipedia.org/wiki/Field_extension",
    "summary": "In mathematics, particularly in algebra, a field extension is a pair of fields \n  \n    \n      \n        K\n        ⊆\n        L\n      \n    \n    {\\displaystyle K\\subseteq L}\n  \n, such that the operations of K are those of L restricted to K. In this case, L is an extension field of K and K is a subfield of L. For example, under the usual notions of addition and multiplication, the complex numbers are an extension field of the real numbers; the real numbers are a subfield of the complex numbers.\nField extensions are fundamental in algebraic number theory, and in the study of polynomial roots through Galois theory, and are widely used in algebraic geometry.",
    "content": "In mathematics, particularly in algebra, a field extension is a pair of fields \n  \n    \n      \n        K\n        ⊆\n        L\n      \n    \n    {\\displaystyle K\\subseteq L}\n  \n, such that the operations of K are those of L restricted to K. In this case, L is an extension field of K and K is a subfield of L. For example, under the usual notions of addition and multiplication, the complex numbers are an extension field of the real numbers; the real numbers are a subfield of the complex numbers.\nField extensions are fundamental in algebraic number theory, and in the study of polynomial roots through Galois theory, and are widely used in algebraic geometry.\n\nSubfield\nA subfield \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n of a field \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  \n is a subset \n  \n    \n      \n        K\n        ⊆\n        L\n      \n    \n    {\\displaystyle K\\subseteq L}\n  \n that is a field with respect to the field operations inherited from \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  \n. Equivalently, a subfield is a subset that contains the multiplicative identity \n  \n    \n      \n        1\n      \n    \n    {\\displaystyle 1}\n  \n, and is closed under the operations of addition, subtraction, multiplication, and taking the inverse of a nonzero element of \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n.\nAs 1 – 1 = 0, the latter definition implies \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n and \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  \n have the same zero element.\nFor example, the field of rational numbers is a subfield of the real numbers, which is itself a subfield of the complex numbers. More generally, the field of rational numbers is (or is isomorphic to) a subfield of any field of characteristic \n  \n    \n      \n        0\n      \n    \n    {\\displaystyle 0}\n  \n.\nThe characteristic of a subfield is the same as the characteristic of the larger field.\n\nExtension field\nIf \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n is a subfield of \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  \n, then \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  \n is an extension field or simply extension of \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n, and this pair of fields is a field extension. Such a field extension is denoted \n  \n    \n      \n        L\n        \n          /\n        \n        K\n      \n    \n    {\\displaystyle L/K}\n  \n (read as \"\n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  \n over \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n\").\nIf \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  \n is an extension of \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n, which is in turn an extension of \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n, then \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n is said to be an intermediate field (or intermediate extension or subextension) of \n  \n    \n      \n        L\n        \n          /\n        \n        K\n      \n    \n    {\\displaystyle L/K}\n  \n.\nGiven a field extension \n  \n    \n      \n        L\n        \n          /\n        \n        K\n      \n    \n    {\\displaystyle L/K}\n  \n, the larger field \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  \n is a \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n-vector space. The dimension of this vector space is called the degree of the extension and is denoted by \n  \n    \n      \n        [\n        L\n        :\n        K\n        ]\n      \n    \n    {\\displaystyle [L:K]}\n  \n. \nThe degree of an extension is 1 if and only if the two fields are equal. In this case, the extension is a trivial extension. Extensions of degree 2 and 3 are called quadratic extensions and cubic extensions, respectively. A finite extension is an extension that has a finite degree.\nGiven two extensions \n  \n    \n      \n        L\n        \n          /\n        \n        K\n      \n    \n    {\\displaystyle L/K}\n  \n and \n  \n    \n      \n        M\n        \n          /\n        \n        L\n      \n    \n    {\\displaystyle M/L}\n  \n, the extension \n  \n    \n      \n        M\n        \n          /\n        \n        K\n      \n    \n    {\\displaystyle M/K}\n  \n is finite if and only if both \n  \n    \n      \n        L\n        \n          /\n        \n        K\n      \n    \n    {\\displaystyle L/K}\n  \n and \n  \n    \n      \n        M\n        \n          /\n        \n        L\n      \n    \n    {\\displaystyle M/L}\n  \n are finite. In this case, one has\n\n  \n    \n      \n        [\n        M\n        :\n        K\n        ]\n        =\n        [\n        M\n        :\n        L\n        ]\n        ⋅\n        [\n        L\n        :\n        K\n        ]\n        .\n      \n    \n    {\\displaystyle [M:K]=[M:L]\\cdot [L:K].}\n  \n\nGiven a field extension \n  \n    \n      \n        L\n        \n          /\n        \n        K\n      \n    \n    {\\displaystyle L/K}\n  \n and a subset \n  \n    ",
    "links": [
      "Abelian extension",
      "Abelian group",
      "Addison-Wesley",
      "Addition",
      "Algebra",
      "Algebra (Lang)",
      "Algebraic closure",
      "Algebraic element",
      "Algebraic extension",
      "Algebraic geometry",
      "Algebraic number field",
      "Algebraic number theory",
      "Algebraic variety",
      "Algebraically independent",
      "Allyn and Bacon",
      "Associative algebra",
      "Automorphism",
      "Azumaya algebra",
      "Bijection",
      "Blaisdell Publishing Company",
      "Brauer equivalent",
      "Cardinality of the continuum",
      "Category of fields",
      "Center (ring theory)",
      "Central simple algebra",
      "Characteristic (algebra)",
      "Characteristic of a ring",
      "Closure (mathematics)",
      "Complex number",
      "Complexification",
      "Constant function",
      "Degree of a field extension",
      "Dimension (vector space)",
      "Encyclopedia of Mathematics",
      "Equivalence class",
      "European Mathematical Society",
      "Extension of scalars",
      "Field (mathematics)",
      "Field of fractions",
      "Field theory (mathematics)",
      "Finite field",
      "Function field of an algebraic variety",
      "Fundamental theorem of Galois theory",
      "Galois extension",
      "Galois group",
      "Galois theory",
      "Generating set",
      "Glossary of field theory",
      "Graduate Texts in Mathematics",
      "Group representation"
    ],
    "categories": [
      "Category:All Wikipedia articles written in American English",
      "Category:Articles with short description",
      "Category:CS1 errors: ISBN date",
      "Category:Field extensions",
      "Category:Short description is different from Wikidata",
      "Category:Use American English from January 2019"
    ]
  },
  "Dual number": {
    "title": "Dual number",
    "url": "https://en.wikipedia.org/wiki/Dual_number",
    "summary": "In algebra, the dual numbers are a hypercomplex number system first introduced in the 19th century. They are expressions of the form a + bε, where a and b are real numbers, and ε is a symbol taken to satisfy \n  \n    \n      \n        \n          ε\n          \n            2\n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle \\varepsilon ^{2}=0}\n  \n with \n  \n    \n      \n        ε\n        ≠\n        0\n      \n    \n    {\\displaystyle \\varepsilon \\neq 0}\n  \n.\nDual numbers can be added component-wise, and multiplied by the formula\n\n  \n    \n      \n        (\n        a\n        +\n        b\n        ε\n        )\n        (\n        c\n        +\n        d\n        ε\n        )\n        =\n        a\n        c\n        +\n        (\n        a\n        d\n        +\n        b\n        c\n        )\n        ε\n        ,\n      \n    \n    {\\displaystyle (a+b\\varepsilon )(c+d\\varepsilon )=ac+(ad+bc)\\varepsilon ,}\n  \n\nwhich follows from the property ε2 = 0 and the fact that multiplication is a bilinear operation",
    "content": "In algebra, the dual numbers are a hypercomplex number system first introduced in the 19th century. They are expressions of the form a + bε, where a and b are real numbers, and ε is a symbol taken to satisfy \n  \n    \n      \n        \n          ε\n          \n            2\n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle \\varepsilon ^{2}=0}\n  \n with \n  \n    \n      \n        ε\n        ≠\n        0\n      \n    \n    {\\displaystyle \\varepsilon \\neq 0}\n  \n.\nDual numbers can be added component-wise, and multiplied by the formula\n\n  \n    \n      \n        (\n        a\n        +\n        b\n        ε\n        )\n        (\n        c\n        +\n        d\n        ε\n        )\n        =\n        a\n        c\n        +\n        (\n        a\n        d\n        +\n        b\n        c\n        )\n        ε\n        ,\n      \n    \n    {\\displaystyle (a+b\\varepsilon )(c+d\\varepsilon )=ac+(ad+bc)\\varepsilon ,}\n  \n\nwhich follows from the property ε2 = 0 and the fact that multiplication is a bilinear operation.\nThe dual numbers form a commutative algebra of dimension two over the reals, and also an Artinian local ring. They are one of the simplest examples of a ring that has nonzero nilpotent elements.\n\nHistory\nDual numbers were introduced in 1873 by William Clifford, and were used at the beginning of the twentieth century by the German mathematician Eduard Study, who used them to represent the dual angle which measures the relative position of two skew lines in space. Study defined a dual angle as θ + dε, where θ is the angle between the directions of two lines in three-dimensional space and d is a distance between them. The n-dimensional generalization, the Grassmann number, was introduced by Hermann Grassmann in the late 19th century.\n\nModern definition\nIn modern algebra, the algebra of dual numbers is often defined as the quotient of a polynomial ring over the real numbers \n  \n    \n      \n        (\n        \n          R\n        \n        )\n      \n    \n    {\\displaystyle (\\mathbb {R} )}\n  \n by the principal ideal generated by the square of the indeterminate, that is\n\n  \n    \n      \n        \n          R\n        \n        [\n        X\n        ]\n        \n          /\n        \n        \n          ⟨\n          \n            X\n            \n              2\n            \n          \n          ⟩\n        \n        .\n      \n    \n    {\\displaystyle \\mathbb {R} [X]/\\left\\langle X^{2}\\right\\rangle .}\n  \n\nIt may also be defined as the exterior algebra of a one-dimensional vector space with \n  \n    \n      \n        ε\n      \n    \n    {\\displaystyle \\varepsilon }\n  \n as its basis element.\n\nDivision\nDivision of dual numbers is defined when the real part of the denominator is non-zero. The division process is analogous to complex division in that the denominator is multiplied by its conjugate in order to cancel the non-real parts.\nTherefore, to evaluate an expression of the form\n\n  \n    \n      \n        \n          \n            \n              a\n              +\n              b\n              ε\n            \n            \n              c\n              +\n              d\n              ε\n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {a+b\\varepsilon }{c+d\\varepsilon }}}\n  \n\nwe multiply the numerator and denominator by the conjugate of the denominator:\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      a\n                      +\n                      b\n                      ε\n                    \n                    \n                      c\n                      +\n                      d\n                      ε\n                    \n                  \n                \n              \n              \n                \n                =\n                \n                  \n                    \n                      (\n                      a\n                      +\n                      b\n                      ε\n                      )\n                      (\n                      c\n                      −\n                      d\n                      ε\n                      )\n                    \n                    \n                      (\n                      c\n                      +\n                      d\n                      ε\n                      )\n                      (\n                      c\n                      −\n                      d\n                      ε\n                      )\n                    \n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                \n                  \n                    \n                      a\n                      c\n                      −\n                      a\n                      d\n                      ε\n                      +\n                      b\n                      c\n                      ε\n                      −\n                      b\n                      d\n                      \n                     ",
    "links": [
      "Abraham Robinson",
      "Absolute space and time",
      "Academic Press",
      "Adequality",
      "Algebra",
      "Algebra of physical space",
      "Algebra over a field",
      "Algebraic geometry",
      "Algebraic number",
      "Analyse des Infiniment Petits pour l'Intelligence des Lignes Courbes",
      "Artinian local ring",
      "Augustin-Louis Cauchy",
      "Automatic differentiation",
      "Bicomplex number",
      "Bilinear operation",
      "Bioctonion",
      "Biquaternion",
      "Cardinal number",
      "Cavalieri's principle",
      "Clifford algebra",
      "Closed-form expression",
      "Commutative algebra (structure)",
      "Commutative ring",
      "Complex number",
      "Complex plane",
      "Complex projective line",
      "Composition algebra",
      "Computable number",
      "Constructible number",
      "Constructive nonstandard analysis",
      "Cornell University",
      "Corrado Segre",
      "Cours d'analyse",
      "Criticism of nonstandard analysis",
      "Cylinder (geometry)",
      "Definable number",
      "Definable real number",
      "Differential (mathematics)",
      "Differential geometry",
      "Dimension (linear algebra)",
      "Division algebra",
      "Division by zero",
      "Doi (identifier)",
      "Dual-complex number",
      "Dual (grammatical number)",
      "Dual quaternion",
      "Eduard Study",
      "Eisenstein integer",
      "Elementary Calculus: An Infinitesimal Approach",
      "Embedding"
    ],
    "categories": [
      "Category:All articles lacking in-text citations",
      "Category:Articles lacking in-text citations from April 2023",
      "Category:Articles with short description",
      "Category:CS1 Italian-language sources (it)",
      "Category:Commutative algebra",
      "Category:Differential algebra",
      "Category:Hypercomplex numbers",
      "Category:Linear algebra",
      "Category:Nonstandard analysis",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Algebraic extension": {
    "title": "Algebraic extension",
    "url": "https://en.wikipedia.org/wiki/Algebraic_extension",
    "summary": "In mathematics, an algebraic extension is a field extension L/K such that every element of the larger field L is algebraic over the smaller field K; that is, every element of L is a root of a non-zero polynomial with coefficients in K. A field extension that is not algebraic, is said to be transcendental, and must contain transcendental elements, that is, elements that are not algebraic.\nThe algebraic extensions of the field \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n of the rational numbers are called algebraic number fields and are the main objects of study of algebraic number theory. Another example of a common algebraic extension is the extension \n  \n    \n      \n        \n          C\n        \n        \n          /\n        \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {C} /\\mathbb {R} }\n  \n of the real numbers by the complex numbers.",
    "content": "In mathematics, an algebraic extension is a field extension L/K such that every element of the larger field L is algebraic over the smaller field K; that is, every element of L is a root of a non-zero polynomial with coefficients in K. A field extension that is not algebraic, is said to be transcendental, and must contain transcendental elements, that is, elements that are not algebraic.\nThe algebraic extensions of the field \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n of the rational numbers are called algebraic number fields and are the main objects of study of algebraic number theory. Another example of a common algebraic extension is the extension \n  \n    \n      \n        \n          C\n        \n        \n          /\n        \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {C} /\\mathbb {R} }\n  \n of the real numbers by the complex numbers.\n\nSome properties\nAll transcendental extensions are of infinite degree. This in turn implies that all finite extensions are algebraic. The converse is not true however: there are infinite extensions which are algebraic.  For instance, the field of all algebraic numbers is an infinite algebraic extension of the rational numbers.\nLet E be an extension field of K, and a ∈ E. The smallest subfield of E that contains K and a is commonly denoted \n  \n    \n      \n        K\n        (\n        a\n        )\n        .\n      \n    \n    {\\displaystyle K(a).}\n  \n If a is algebraic over K, then the elements of K(a) can be expressed as polynomials in a with coefficients in K; that is, \n  \n    \n      \n        K\n        (\n        a\n        )\n        =\n        K\n        [\n        a\n        ]\n      \n    \n    {\\displaystyle K(a)=K[a]}\n  \n, the smallest ring containing K and a. In this case, \n  \n    \n      \n        K\n        (\n        a\n        )\n      \n    \n    {\\displaystyle K(a)}\n  \n is a finite extension of K and all its elements are algebraic over K.  In particular, \n  \n    \n      \n        K\n        (\n        a\n        )\n      \n    \n    {\\displaystyle K(a)}\n  \n is a K-vector space with basis \n  \n    \n      \n        {\n        1\n        ,\n        a\n        ,\n        .\n        .\n        .\n        ,\n        \n          a\n          \n            d\n            −\n            1\n          \n        \n        }\n      \n    \n    {\\displaystyle \\{1,a,...,a^{d-1}\\}}\n  \n, where d is the degree of the minimal polynomial of a. These properties do not hold if a is not algebraic. For example, \n  \n    \n      \n        \n          Q\n        \n        (\n        π\n        )\n        ≠\n        \n          Q\n        \n        [\n        π\n        ]\n        ,\n      \n    \n    {\\displaystyle \\mathbb {Q} (\\pi )\\neq \\mathbb {Q} [\\pi ],}\n  \n and they are both infinite dimensional vector spaces over \n  \n    \n      \n        \n          Q\n        \n        .\n      \n    \n    {\\displaystyle \\mathbb {Q} .}\n  \n\nAn algebraically closed field F has no proper algebraic extensions, that is, no algebraic extensions E with F < E. An example is the field of complex numbers. Every field has an algebraic extension which is algebraically closed (called its algebraic closure), but proving this in general requires some form of the axiom of choice.\nAn extension L/K is algebraic if and only if every sub K-algebra of L is a field.\n\nProperties\nThe following three properties hold:\n\nIf E is an algebraic extension of F and F is an algebraic extension of K then E is an algebraic extension of K.\nIf E and F are algebraic extensions of K in a common overfield C, then the compositum EF is an algebraic extension of K.\nIf E is an algebraic extension of F and E > K > F then E is an algebraic extension of K.\nThese finitary results can be generalized using transfinite induction:\n\nThis fact, together with Zorn's lemma (applied to an appropriately chosen poset), establishes the existence of algebraic closures.\n\nGeneralizations\nModel theory generalizes the notion of algebraic extension to arbitrary theories: an embedding of M into N is called an algebraic extension if for every x in N there is a formula p with parameters in M, such that p(x) is true and the set\n\n  \n    \n      \n        \n          {\n          \n            y\n            ∈\n            N\n            ∣\n            p\n            (\n            y\n            )\n          \n          }\n        \n      \n    \n    {\\displaystyle \\left\\{y\\in N\\mid p(y)\\right\\}}\n  \n\nis finite. It turns out that applying this definition to the theory of fields gives the usual definition of algebraic extension. The Galois group of N over M can again be defined as the group of automorphisms, and it turns out that most of the theory of Galois groups can be developed for the general case.\n\nRelative algebraic closures\nGiven a field k and a field K containing k, one defines the relative algebraic closure of k in K to be the subfield of K consisting of all elements of K that are algebraic over k, that is all elements of K that are a root of some nonzero polynomial with coefficients",
    "links": [
      "Algebra (Lang)",
      "Algebra over a field",
      "Algebraic closure",
      "Algebraic element",
      "Algebraic number",
      "Algebraic number field",
      "Algebraic number theory",
      "Algebraically closed field",
      "Automorphism",
      "Axiom of choice",
      "Complex number",
      "Compositum",
      "Converse (logic)",
      "Degree of a field extension",
      "Embedding",
      "Field (mathematics)",
      "Field extension",
      "Galois extension",
      "Galois group",
      "Group (mathematics)",
      "ISBN (identifier)",
      "If and only if",
      "Integral element",
      "Lüroth's theorem",
      "Mathematical proof",
      "Mathematics",
      "Michiel Hazewinkel",
      "Minimal polynomial (field theory)",
      "Model theory",
      "Normal extension",
      "Polynomial",
      "Poset",
      "Rational number",
      "Real number",
      "Ring (mathematics)",
      "Separable extension",
      "Serge Lang",
      "Substructure (mathematics)",
      "Transcendental element",
      "Union (set theory)",
      "Well-formed formula",
      "Zbl (identifier)",
      "Zorn's lemma"
    ],
    "categories": [
      "Category:All Wikipedia articles written in American English",
      "Category:Articles with short description",
      "Category:Field extensions",
      "Category:Short description is different from Wikidata",
      "Category:Use American English from January 2019",
      "Category:Use mdy dates from September 2021"
    ]
  },
  "Finite field": {
    "title": "Finite field",
    "url": "https://en.wikipedia.org/wiki/Finite_field",
    "summary": "In mathematics, a finite field or Galois field (so-named in honor of Évariste Galois) is a field that has a finite number of elements.  As with any field, a finite field is a set on which the operations of multiplication, addition, subtraction and division are defined and satisfy certain basic rules.  The most common examples of finite fields are the integers mod \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n when \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n is a prime number.\nThe order of a finite field is its number of elements, which is either a prime number or a prime power. For every prime number \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n and every positive integer \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n there are fields of order \n  \n    \n      \n        \n          p\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle p^{k}}\n  \n. All finite fields of a given order are isomorphic",
    "content": "In mathematics, a finite field or Galois field (so-named in honor of Évariste Galois) is a field that has a finite number of elements.  As with any field, a finite field is a set on which the operations of multiplication, addition, subtraction and division are defined and satisfy certain basic rules.  The most common examples of finite fields are the integers mod \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n when \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n is a prime number.\nThe order of a finite field is its number of elements, which is either a prime number or a prime power. For every prime number \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n and every positive integer \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n there are fields of order \n  \n    \n      \n        \n          p\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle p^{k}}\n  \n. All finite fields of a given order are isomorphic.\nFinite fields are fundamental in a number of areas of mathematics and computer science, including number theory, algebraic geometry, Galois theory, finite geometry, cryptography and coding theory.\n\nProperties\nA finite field is a field that is a finite set; this means that it has a finite number of elements on which multiplication, addition, subtraction and division (excluding division by zero) are defined and satisfy  the field axioms.\nThe number of elements of a finite field is called its order or, sometimes, its size. A finite field of order \n  \n    \n      \n        q\n      \n    \n    {\\displaystyle q}\n  \n exists if and only if \n  \n    \n      \n        q\n      \n    \n    {\\displaystyle q}\n  \n is a prime power \n  \n    \n      \n        \n          p\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle p^{k}}\n  \n (where \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n is a prime number and \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n is a positive integer). In a field of order \n  \n    \n      \n        \n          p\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle p^{k}}\n  \n, adding \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n copies of any element always results in zero; that is, the characteristic of the field is \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n.\nFor \n  \n    \n      \n        q\n        =\n        \n          p\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle q=p^{k}}\n  \n, all fields of order \n  \n    \n      \n        q\n      \n    \n    {\\displaystyle q}\n  \n are isomorphic (see § Existence and uniqueness below). Moreover, a field cannot contain two different finite subfields with the same order. One may therefore identify all finite fields with the same order, and they are unambiguously denoted \n  \n    \n      \n        \n          \n            F\n          \n          \n            q\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {F} _{q}}\n  \n, \n  \n    \n      \n        \n          \n            F\n          \n          \n            q\n          \n        \n      \n    \n    {\\displaystyle \\mathbf {F} _{q}}\n  \n or \n  \n    \n      \n        \n          G\n          F\n        \n        (\n        q\n        )\n      \n    \n    {\\displaystyle \\mathrm {GF} (q)}\n  \n, where the letters GF stand for \"Galois field\".\nIn a finite field of order \n  \n    \n      \n        q\n      \n    \n    {\\displaystyle q}\n  \n, the polynomial \n  \n    \n      \n        \n          X\n          \n            q\n          \n        \n        −\n        X\n      \n    \n    {\\displaystyle X^{q}-X}\n  \n has all \n  \n    \n      \n        q\n      \n    \n    {\\displaystyle q}\n  \n elements of the finite field as roots. The non-zero elements of a finite field form a multiplicative group. This group is cyclic, so all non-zero elements can be expressed as powers of a single element called a primitive element of the field. (In general there will be several primitive elements for a given field.)\nThe simplest examples of finite fields are the fields of prime order: for each prime number \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n, the prime field of order \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n may be constructed as the integers modulo \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n, \n  \n    \n      \n        \n          Z\n        \n        \n          /\n        \n        p\n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} /p\\mathbb {Z} }\n  \n.\nThe elements of the prime field of order \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n may be represented by integers in the range \n  \n    \n      \n        0\n        ,\n        …\n        ,\n        p\n        −\n        1\n      \n    \n    {\\displaystyle 0,\\ldots ,p-1}\n  \n. The sum, the difference and the product are the remainder of the division by \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n of the result of ",
    "links": [
      "Abelian group",
      "Algebra over a field",
      "Algebraic geometry",
      "Algebraic structure",
      "Algebraic variety",
      "Alternative division ring",
      "Alternativity",
      "ArXiv (identifier)",
      "Arithmetic combinatorics",
      "Artin–Zorn theorem",
      "Associative algebra",
      "Associativity",
      "BCH code",
      "Bialgebra",
      "Binomial coefficient",
      "Binomial theorem",
      "Boolean algebra (structure)",
      "Bulletin of the American Mathematical Society",
      "Cambridge University Press",
      "Carry-less product",
      "Character sum",
      "Characteristic (algebra)",
      "Chevalley–Warning theorem",
      "Chinese remainder theorem",
      "Claude Chevalley",
      "Coding theory",
      "Combinatorics",
      "Commutative property",
      "Commutative ring",
      "Complemented lattice",
      "Composition algebra",
      "Computer algebra system",
      "Computer science",
      "Conway polynomial (finite fields)",
      "Coprime",
      "Cryptographic protocol",
      "Cryptography",
      "Cyclic group",
      "Cyclotomic polynomial",
      "Diffie–Hellman",
      "Digital certificate",
      "Direct limit",
      "Directed set",
      "Discrete logarithm",
      "Discrete logarithm problem",
      "Discriminant",
      "Distinct degree factorization",
      "Distributive law",
      "Division by 0",
      "Division ring"
    ],
    "categories": [
      "Category:All articles lacking in-text citations",
      "Category:All articles with unsourced statements",
      "Category:Articles lacking in-text citations from February 2015",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from April 2025",
      "Category:Finite fields",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Ultrafilter lemma": {
    "title": "Ultrafilter on a set",
    "url": "https://en.wikipedia.org/wiki/Ultrafilter_on_a_set",
    "summary": "In the mathematical field of set theory, an ultrafilter on a set \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is a maximal filter on the set \n  \n    \n      \n        X\n        .\n      \n    \n    {\\displaystyle X.}\n  \n  In other words, it is a collection of subsets of \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n that satisfies the definition of a filter on \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n and that is maximal with respect to inclusion, in the sense that there does not exist a strictly larger collection of subsets of \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n that is also a filter.  (In the above, by definition a filter on a set does not contain the empty set.)  Equivalently, an ultrafilter on the set \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n can also be characterized as a filter on \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n with the property that for every su",
    "content": "In the mathematical field of set theory, an ultrafilter on a set \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is a maximal filter on the set \n  \n    \n      \n        X\n        .\n      \n    \n    {\\displaystyle X.}\n  \n  In other words, it is a collection of subsets of \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n that satisfies the definition of a filter on \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n and that is maximal with respect to inclusion, in the sense that there does not exist a strictly larger collection of subsets of \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n that is also a filter.  (In the above, by definition a filter on a set does not contain the empty set.)  Equivalently, an ultrafilter on the set \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n can also be characterized as a filter on \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n with the property that for every subset \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n of \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n either \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n or its complement \n  \n    \n      \n        X\n        ∖\n        A\n      \n    \n    {\\displaystyle X\\setminus A}\n  \n belongs to the ultrafilter.\nUltrafilters on sets are an important special instance of ultrafilters on partially ordered sets, where the partially ordered set consists of the power set \n  \n    \n      \n        ℘\n        (\n        X\n        )\n      \n    \n    {\\displaystyle \\wp (X)}\n  \n and the partial order is subset inclusion \n  \n    \n      \n        \n        ⊆\n        .\n      \n    \n    {\\displaystyle \\,\\subseteq .}\n  \n  This article deals specifically with ultrafilters on a set and does not cover the more general notion.\nThere are two types of ultrafilter on a set. A principal ultrafilter on \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is the collection of all subsets of \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n that contain a fixed element \n  \n    \n      \n        x\n        ∈\n        X\n      \n    \n    {\\displaystyle x\\in X}\n  \n. The ultrafilters that are not principal are the free ultrafilters. The existence of free ultrafilters on any infinite set is implied by the ultrafilter lemma, which can be proven in ZFC. On the other hand, there exists models of ZF where every ultrafilter on a set is principal.\nUltrafilters have many applications in set theory, model theory, and topology. Usually, only free ultrafilters lead to non-trivial constructions. For example, an ultraproduct modulo a principal ultrafilter is always isomorphic to one of the factors, while an ultraproduct modulo a free ultrafilter usually has a more complex structure.\n\nDefinitions\nGiven an arbitrary set \n  \n    \n      \n        X\n        ,\n      \n    \n    {\\displaystyle X,}\n  \n an ultrafilter on \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is a non-empty family \n  \n    \n      \n        U\n      \n    \n    {\\displaystyle U}\n  \n of subsets of \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n such that:\n\nProper or non-degenerate: The empty set is not an element of \n  \n    \n      \n        U\n        .\n      \n    \n    {\\displaystyle U.}\n  \n\nUpward closed in \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n: If \n  \n    \n      \n        A\n        ∈\n        U\n      \n    \n    {\\displaystyle A\\in U}\n  \n and if \n  \n    \n      \n        B\n        ⊆\n        X\n      \n    \n    {\\displaystyle B\\subseteq X}\n  \n is any superset of \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n (that is, if \n  \n    \n      \n        A\n        ⊆\n        B\n        ⊆\n        X\n      \n    \n    {\\displaystyle A\\subseteq B\\subseteq X}\n  \n) then \n  \n    \n      \n        B\n        ∈\n        U\n        .\n      \n    \n    {\\displaystyle B\\in U.}\n  \n\nπ−system: If \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n and \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  \n are elements of \n  \n    \n      \n        U\n      \n    \n    {\\displaystyle U}\n  \n then so is their intersection \n  \n    \n      \n        A\n        ∩\n        B\n        .\n      \n    \n    {\\displaystyle A\\cap B.}\n  \n\nIf \n  \n    \n      \n        A\n        ⊆\n        X\n      \n    \n    {\\displaystyle A\\subseteq X}\n  \n then either \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n or its complement \n  \n    \n      \n        X\n        ∖\n        A\n      \n    \n    {\\displaystyle X\\setminus A}\n  \n is an element of \n  \n    \n      \n        U\n        .\n      \n    \n    {\\displaystyle U.}\n  \n\nProperties (1), (2), and (3) are the defining properties of a filter on \n  \n    \n      \n        X\n        .\n      \n    \n    {\\displaystyle X.}\n  \n Some authors do not include non-degeneracy (which is property (1) above) in their definition of \"filter\". However, the definition of \"ultrafilter\" (and also of \"prefilter\" and \"filter subbase\") ",
    "links": [
      "Abraham Fraenkel",
      "Abstract logic",
      "Ackermann set theory",
      "Aleph-naught",
      "Aleph number",
      "Alexander Arhangelskii",
      "Alexander subbase theorem",
      "Alfred Tarski",
      "Algebraic closure",
      "Algebraic logic",
      "Almost",
      "Alphabet (formal languages)",
      "Alternative set theory",
      "Amorphous set",
      "ArXiv (identifier)",
      "Argument",
      "Arity",
      "Atomic formula",
      "Atomic sentence",
      "Automata theory",
      "Automated theorem proving",
      "Axiom",
      "Axiom of Choice",
      "Axiom of adjunction",
      "Axiom of choice",
      "Axiom of constructibility",
      "Axiom of countable choice",
      "Axiom of dependent choice",
      "Axiom of determinacy",
      "Axiom of extensionality",
      "Axiom of global choice",
      "Axiom of infinity",
      "Axiom of limitation of size",
      "Axiom of pairing",
      "Axiom of power set",
      "Axiom of projective determinacy",
      "Axiom of regularity",
      "Axiom of union",
      "Axiom schema",
      "Axiom schema of replacement",
      "Axiom schema of specification",
      "Axiomatic system",
      "Axiomatization of Boolean algebras",
      "Banach-Alaoglu theorem",
      "Banach–Tarski paradox",
      "Bertrand Russell",
      "Bibcode (identifier)",
      "Bijection",
      "Binary operation",
      "Boolean algebra"
    ],
    "categories": [
      "Category:All articles with unsourced statements",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from July 2016",
      "Category:Families of sets",
      "Category:Nonstandard analysis",
      "Category:Order theory",
      "Category:Pages displaying short descriptions of redirect targets via Module:Annotated link",
      "Category:Short description matches Wikidata"
    ]
  },
  "Zorn's lemma": {
    "title": "Zorn's lemma",
    "url": "https://en.wikipedia.org/wiki/Zorn%27s_lemma",
    "summary": "Zorn's lemma, also known as the Kuratowski–Zorn lemma, is a proposition of set theory. It states that a partially ordered set containing upper bounds for every chain (that is, every totally ordered subset) necessarily contains at least one maximal element.\nThe lemma was proven (assuming the axiom of choice) by Kazimierz Kuratowski in 1922 and independently by Max Zorn in 1935. It occurs in the proofs of several theorems of crucial importance, for instance the Hahn–Banach theorem in functional analysis, the theorem that every vector space has a basis, Tychonoff's theorem in topology stating that every product of compact spaces is compact, and the theorems in abstract algebra that in a ring with identity every proper ideal is contained in a maximal ideal and that every field has an algebraic closure.\nZorn's lemma is equivalent to the well-ordering theorem and also to the axiom of choice, in the sense that within ZF (Zermelo–Fraenkel set theory without the axiom of choice) any one of the ",
    "content": "Zorn's lemma, also known as the Kuratowski–Zorn lemma, is a proposition of set theory. It states that a partially ordered set containing upper bounds for every chain (that is, every totally ordered subset) necessarily contains at least one maximal element.\nThe lemma was proven (assuming the axiom of choice) by Kazimierz Kuratowski in 1922 and independently by Max Zorn in 1935. It occurs in the proofs of several theorems of crucial importance, for instance the Hahn–Banach theorem in functional analysis, the theorem that every vector space has a basis, Tychonoff's theorem in topology stating that every product of compact spaces is compact, and the theorems in abstract algebra that in a ring with identity every proper ideal is contained in a maximal ideal and that every field has an algebraic closure.\nZorn's lemma is equivalent to the well-ordering theorem and also to the axiom of choice, in the sense that within ZF (Zermelo–Fraenkel set theory without the axiom of choice) any one of the three is sufficient to prove the other two. An earlier formulation of Zorn's lemma is the Hausdorff maximal principle which states that every totally ordered subset of a given partially ordered set is contained in a maximal totally ordered subset of that partially ordered set.\n\nMotivation\nTo prove the existence of a mathematical object that can be viewed as a maximal element in some partially ordered set in some way, one can try proving the existence of such an object by assuming there is no maximal element and using transfinite induction and the assumptions of the situation to get a contradiction. Zorn's lemma tidies up the conditions a situation needs to satisfy in order for such an argument to work and enables mathematicians to not have to repeat the transfinite induction argument by hand each time, but just check the conditions of Zorn's lemma.\n\nIf you are building a mathematical object in stages and find that (i) you have not finished even after infinitely many stages, and (ii) there seems to be nothing to stop you continuing to build, then Zorn’s lemma may well be able to help you.\n\nStatement of the lemma\nPreliminary notions:\n\nA set P equipped with a binary relation ≤ that is reflexive (x ≤ x for every x), antisymmetric (if both x ≤ y and y ≤ x hold, then x = y), and transitive (if x ≤ y and y ≤ z then x ≤ z) is said to be (partially) ordered by ≤. Given two elements x and y of P with x ≤ y, y is said to be greater than or equal to x. The word \"partial\" is meant to indicate that not every pair of elements of a partially ordered set is required to be comparable under the order relation, that is, in a partially ordered set P with order relation ≤ there may be elements x and y with neither x ≤ y nor y ≤ x. An ordered set in which every pair of elements is comparable is called totally ordered.\nEvery subset S of a partially ordered set P can itself be seen as partially ordered by restricting the order relation inherited from P to S. A subset S of a partially ordered set P is called a chain (in P) if it is totally ordered in the inherited order.\nAn element m of a partially ordered set P with order relation ≤ is maximal (with respect to ≤) if there is no other element of P greater than m, that is, there is no s in P with s ≠ m and m ≤ s. Depending on the order relation, a partially ordered set may have any number of maximal elements. However, a totally ordered set can have at most one maximal element.\nGiven a subset S of a partially ordered set P, an element u of P is an upper bound of S if it is greater than or equal to every element of S. Here, S is not required to be a chain, and u is required to be comparable to every element of S but need not itself be an element of S.\nZorn's lemma can then be stated as:\n\nIn fact, property (1) is redundant, since property (2) says, in particular, that the empty chain has an upper bound in \n  \n    \n      \n        P\n      \n    \n    {\\displaystyle P}\n  \n, implying \n  \n    \n      \n        P\n      \n    \n    {\\displaystyle P}\n  \n is nonempty. However, in practice, one often checks (1) and then verifies (2) only for nonempty chains, since the case of the empty chain is taken care by (1).\nIn the terminology of Bourbaki, a partially ordered set is called inductive if each chain has an upper bound in the set (in particular, the set is then nonempty). Then the lemma can be stated as:\n\nFor some applications, the following variant may be useful.\n\nIndeed, let \n  \n    \n      \n        Q\n        =\n        {\n        x\n        ∈\n        P\n        ∣\n        x\n        ≥\n        a\n        }\n      \n    \n    {\\displaystyle Q=\\{x\\in P\\mid x\\geq a\\}}\n  \n with the partial ordering from \n  \n    \n      \n        P\n      \n    \n    {\\displaystyle P}\n  \n. Then, for a chain in \n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n  \n, an upper bound in \n  \n    \n      \n        P\n      \n    \n    {\\displaystyle P}\n  \n is in \n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n  \n and so \n  \n    \n      \n        Q\n",
    "links": [
      "Abstract algebra",
      "Abstract logic",
      "Ackermann set theory",
      "Aleph number",
      "Alexandrov topology",
      "Algebraic closure",
      "Algebraic logic",
      "Alphabet (formal languages)",
      "Antichain",
      "Antisymmetric relation",
      "Argument",
      "Arity",
      "Asymmetric relation",
      "Atomic formula",
      "Atomic sentence",
      "Automata theory",
      "Automated theorem proving",
      "Axiom",
      "Axiom of choice",
      "Axiom of dependent choice",
      "Axiom of union",
      "Axiom schema",
      "Axiomatic system",
      "Axiomatization of Boolean algebras",
      "Banach's extension theorem",
      "Banach lattice",
      "Banach–Tarski paradox",
      "Bart's New Friend",
      "Basis (linear algebra)",
      "Better-quasi-ordering",
      "Bijection",
      "Binary operation",
      "Binary relation",
      "Boolean algebra",
      "Boolean algebra (structure)",
      "Boolean algebras canonically defined",
      "Boolean function",
      "Boolean prime ideal theorem",
      "Bounded lattice",
      "Bourbaki–Witt theorem",
      "Canadian Mathematical Bulletin",
      "Cantor's diagonal argument",
      "Cantor's isomorphism theorem",
      "Cantor's paradox",
      "Cantor's theorem",
      "Cantor–Bernstein theorem",
      "Cardinality",
      "Cartesian product",
      "Categorical theory",
      "Category (mathematics)"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Axiom of choice",
      "Category:CS1: long volume value",
      "Category:CS1 French-language sources (fr)",
      "Category:Lemmas in set theory",
      "Category:Order theory",
      "Category:Pages displaying short descriptions of redirect targets via Module:Annotated link",
      "Category:Short description is different from Wikidata",
      "Category:Use dmy dates from December 2015"
    ]
  },
  "Absolute Galois group": {
    "title": "Absolute Galois group",
    "url": "https://en.wikipedia.org/wiki/Absolute_Galois_group",
    "summary": "In mathematics, particularly in anabelian geometry and p-adic geometry, the absolute Galois group GK of a field K is the Galois group of Ksep over K, where Ksep is a separable closure of K. Alternatively it is the group of all automorphisms of the algebraic closure of K that fix K. The absolute Galois group is well-defined up to inner automorphism. It is a profinite group.\n(When K is a perfect field, Ksep is the same as an algebraic closure Kalg of K. This holds e.g. for K of characteristic zero, or K a finite field.)",
    "content": "In mathematics, particularly in anabelian geometry and p-adic geometry, the absolute Galois group GK of a field K is the Galois group of Ksep over K, where Ksep is a separable closure of K. Alternatively it is the group of all automorphisms of the algebraic closure of K that fix K. The absolute Galois group is well-defined up to inner automorphism. It is a profinite group.\n(When K is a perfect field, Ksep is the same as an algebraic closure Kalg of K. This holds e.g. for K of characteristic zero, or K a finite field.)\n\nExamples\nThe absolute Galois group of an algebraically closed field is trivial.\nThe absolute Galois group of the real numbers is a cyclic group of two elements (complex conjugation and the identity map), since C is the separable closure of R, and its degree over R is [C:R] = 2.\nThe absolute Galois group of a finite field K is isomorphic to the group of profinite integers\n\n  \n    \n      \n        \n          \n            \n              \n                Z\n              \n              ^\n            \n          \n        \n        =\n        \n          \n            lim\n            ←\n          \n        \n        ⁡\n        \n          Z\n        \n        \n          /\n        \n        n\n        \n          Z\n        \n        .\n      \n    \n    {\\displaystyle {\\hat {\\mathbf {Z} }}=\\varprojlim \\mathbf {Z} /n\\mathbf {Z} .}\n  \n\n(For the notation, see Inverse limit.)\nThe Frobenius automorphism Fr is a canonical (topological) generator of GK. (If K has q elements, Fr is given by Fr(x) = xq for all x in Kalg.)\nThe absolute Galois group of the field of rational functions with complex coefficients is free (as a profinite group). This result is due to Adrien Douady and has its origins in Riemann's existence theorem.\nMore generally, let C be an algebraically closed field and x an indeterminate.  Then the absolute Galois group of K = C(x) is free of rank equal to the cardinality of C. This result is due to David Harbater and Florian Pop, and was also proved later by Dan Haran and Moshe Jarden using algebraic methods.\nLet K be a finite extension of the p-adic numbers Qp. For p ≠ 2, its absolute Galois group is generated by [K:Qp] + 3 elements and has an explicit description by generators and relations. This is a result of Uwe Jannsen and Kay Wingberg. Some results are known in the case p = 2, but the structure for Q2 is not known.\nAnother case in which the absolute Galois group has been determined is for the largest totally real subfield of the field of algebraic numbers.\n\nProblems\nNo direct description is known for the absolute Galois group of the rational numbers. In this case, it follows from Belyi's theorem that the absolute Galois group has a faithful action on the dessins d'enfants of Grothendieck (maps on surfaces), enabling us to \"see\" the Galois theory of algebraic number fields. It is one of the goals of anabelian geometry to solve this problem\nLet K be the maximal abelian extension of the rational numbers. Then Shafarevich's conjecture asserts that the absolute Galois group of K is a free profinite group.\nAn interesting problem is to settle Ján Mináč and Nguyên Duy Tân's conjecture about vanishing of \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n- Massey products for \n  \n    \n      \n        n\n        ≥\n        3\n      \n    \n    {\\displaystyle n\\geq 3}\n  \n.\n\nSome general results\nThe Neukirch–Uchida theorem asserts that every isomorphism of the absolute Galois groups of algebraic number fields arises from a field automorphism. In particular, two absolute Galois groups of number fields are isomorphic if and only if the base fields are isomorphic.\nEvery profinite group occurs as a Galois group of some Galois extension; however, not every profinite group occurs as an absolute Galois group. For example, the Artin–Schreier theorem asserts that the only finite absolute Galois groups are either trivial or of order 2, that is only two isomorphism classes.\nEvery projective profinite group can be realized as an absolute Galois group of a pseudo algebraically closed field. This result is due to Alexander Lubotzky and Lou van den Dries.\n\nUses in the Geometrization of the Local Langlands Correspondence\nIn the Geometrization of the Local Langlands Correspondence (2022), Laurent Fargues and Peter Scholze looked to recover information about a ring E via the absolute Galois Group of E, which is isomorphic to the Étale fundamental group of Spec E. This result was calculated while trying to evaluate the Weil Group of E. This result arrives from the idea of the automorphism group G(E) of the trivial G-Torsor over Spec E, thus G(E) relates to information over Spec E, which is an anabelian question.\n\nReferences\nSources\nDouady, Adrien (1964), \"Détermination d'un groupe de Galois\", Comptes Rendus de l'Académie des Sciences de Paris, 258: 5305–5308, MR 0162796\nFried, Michael D.; Jarden, Moshe (2008), Field arithmetic, Ergebnisse der Mathematik und ihrer Grenzgebiete. 3. Folge, vol. 11 (3rd ed.), Springer-Verlag, ISBN 978-",
    "links": [
      "Abelian extension",
      "Adrien Douady",
      "Alexander Lubotzky",
      "Algebraic closure",
      "Algebraic number",
      "Algebraic number field",
      "American Mathematical Society",
      "Anabelian geometry",
      "Automorphisms",
      "Belyi's theorem",
      "Bibcode (identifier)",
      "Cambridge",
      "Cambridge University Press",
      "Characteristic zero",
      "Complex conjugate",
      "Cyclic group",
      "Dan Haran",
      "David Harbater",
      "Degree of a field extension",
      "Dessins d'enfants",
      "Doi (identifier)",
      "Field (mathematics)",
      "Field of rational functions",
      "Finite extension",
      "Finite field",
      "Florian Pop",
      "Frobenius automorphism",
      "Galois extension",
      "Galois group",
      "Grothendieck",
      "Group action",
      "ISBN (identifier)",
      "Inner automorphism",
      "Inventiones Mathematicae",
      "Inverse limit",
      "Ján Mináč",
      "Jürgen Neukirch",
      "Laurent Fargues",
      "Lou van den Dries",
      "MR (identifier)",
      "Mathematics",
      "Moshe Jarden",
      "Neukirch–Uchida theorem",
      "P-adic number",
      "Perfect field",
      "Peter Scholze",
      "Profinite group",
      "Profinite integer",
      "Projective profinite group",
      "Providence, Rhode Island"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Galois theory",
      "Category:Short description matches Wikidata"
    ]
  },
  "Algebraic closure (convex analysis)": {
    "title": "Algebraic closure (convex analysis)",
    "url": "https://en.wikipedia.org/wiki/Algebraic_closure_(convex_analysis)",
    "summary": "Algebraic closure of a subset \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n of a vector space \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is the set of all points that are linearly accessible from \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n. It is denoted by \n  \n    \n      \n        acl\n        ⁡\n        A\n      \n    \n    {\\displaystyle \\operatorname {acl} A}\n  \n or \n  \n    \n      \n        \n          acl\n          \n            X\n          \n        \n        ⁡\n        A\n      \n    \n    {\\displaystyle \\operatorname {acl} _{X}A}\n  \n.\nA point \n  \n    \n      \n        x\n        ∈\n        X\n      \n    \n    {\\displaystyle x\\in X}\n  \n is said to be linearly accessible from a subset \n  \n    \n      \n        A\n        ⊆\n        X\n      \n    \n    {\\displaystyle A\\subseteq X}\n  \n if there exists some \n  \n    \n      \n        a\n        ∈\n        A\n      \n    \n    {\\displaystyle a\\in A}\n  \n such that the line segment \n  \n    \n      \n        [\n    ",
    "content": "Algebraic closure of a subset \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n of a vector space \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is the set of all points that are linearly accessible from \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n. It is denoted by \n  \n    \n      \n        acl\n        ⁡\n        A\n      \n    \n    {\\displaystyle \\operatorname {acl} A}\n  \n or \n  \n    \n      \n        \n          acl\n          \n            X\n          \n        \n        ⁡\n        A\n      \n    \n    {\\displaystyle \\operatorname {acl} _{X}A}\n  \n.\nA point \n  \n    \n      \n        x\n        ∈\n        X\n      \n    \n    {\\displaystyle x\\in X}\n  \n is said to be linearly accessible from a subset \n  \n    \n      \n        A\n        ⊆\n        X\n      \n    \n    {\\displaystyle A\\subseteq X}\n  \n if there exists some \n  \n    \n      \n        a\n        ∈\n        A\n      \n    \n    {\\displaystyle a\\in A}\n  \n such that the line segment \n  \n    \n      \n        [\n        a\n        ,\n        x\n        )\n        :=\n        a\n        +\n        [\n        0\n        ,\n        1\n        )\n        (\n        x\n        −\n        a\n        )\n      \n    \n    {\\displaystyle [a,x):=a+[0,1)(x-a)}\n  \n is contained in \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n.\nNecessarily, \n  \n    \n      \n        A\n        ⊆\n        acl\n        ⁡\n        A\n        ⊆\n        acl\n        ⁡\n        acl\n        ⁡\n        A\n        ⊆\n        \n          \n            A\n            ¯\n          \n        \n      \n    \n    {\\displaystyle A\\subseteq \\operatorname {acl} A\\subseteq \\operatorname {acl} \\operatorname {acl} A\\subseteq {\\overline {A}}}\n  \n (the last inclusion holds when X is equipped by any vector topology, Hausdorff or not).\nThe set A is algebraically closed if \n  \n    \n      \n        A\n        =\n        acl\n        ⁡\n        A\n      \n    \n    {\\displaystyle A=\\operatorname {acl} A}\n  \n.\nThe set \n  \n    \n      \n        acl\n        ⁡\n        A\n        ∖\n        aint\n        ⁡\n        A\n      \n    \n    {\\displaystyle \\operatorname {acl} A\\setminus \\operatorname {aint} A}\n  \n is the algebraic boundary of A in X.\n\nExamples\nThe set \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n of rational numbers is algebraically closed but \n  \n    \n      \n        \n          \n            Q\n          \n          \n            c\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {Q} ^{c}}\n  \n is not algebraically open\nIf \n  \n    \n      \n        A\n        =\n        {\n        (\n        x\n        ,\n        y\n        )\n        ∈\n        \n          \n            R\n          \n          \n            2\n          \n        \n        :\n        0\n        <\n        y\n        <\n        \n          x\n          \n            2\n          \n        \n        }\n        ⊆\n        \n          \n            R\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle A=\\{(x,y)\\in \\mathbb {R} ^{2}:0<y<x^{2}\\}\\subseteq \\mathbb {R} ^{2}}\n  \n then \n\n  \n    \n      \n        0\n        ∈\n        (\n        acl\n        ⁡\n        acl\n        ⁡\n        A\n        )\n        ∖\n        acl\n        ⁡\n        A\n      \n    \n    {\\displaystyle 0\\in (\\operatorname {acl} \\operatorname {acl} A)\\setminus \\operatorname {acl} A}\n  \n. In particular, the algebraic closure need not be algebraically closed.\nHere, \n  \n    \n      \n        \n          \n            A\n            ¯\n          \n        \n        =\n        acl\n        ⁡\n        acl\n        ⁡\n        A\n        =\n        {\n        (\n        x\n        ,\n        y\n        )\n        ∈\n        \n          \n            R\n          \n          \n            2\n          \n        \n        :\n        0\n        ≤\n        y\n        ≤\n        \n          x\n          \n            2\n          \n        \n        }\n        =\n        (\n        acl\n        ⁡\n        A\n        )\n        ∪\n        {\n        0\n        }\n      \n    \n    {\\displaystyle {\\overline {A}}=\\operatorname {acl} \\operatorname {acl} A=\\{(x,y)\\in \\mathbb {R} ^{2}:0\\leq y\\leq x^{2}\\}=(\\operatorname {acl} A)\\cup \\{0\\}}\n  \n.\nHowever, \n  \n    \n      \n        acl\n        ⁡\n        A\n        =\n        \n          \n            A\n            ¯\n          \n        \n      \n    \n    {\\displaystyle \\operatorname {acl} A={\\overline {A}}}\n  \n for every finite-dimensional convex set A.\nMoreover, a convex set is algebraically closed if and only if its complement is algebraically open.\n\nSee also\nAlgebraic interior\n\nReferences\nBibliography\nNarici, Lawrence; Beckenstein, Edward (2011). Topological Vector Spaces. Pure and applied mathematics (Second ed.). Boca Raton, FL: CRC Press. ISBN 978-1584888666. OCLC 144216834.",
    "links": [
      "Absolutely convex set",
      "Absorbing set",
      "Adjoint operator",
      "Affine hull",
      "Affine space",
      "Algebraic closure",
      "Algebraic interior",
      "Algebraically open",
      "Almost open linear map",
      "Anderson–Kadec theorem",
      "Approximation property",
      "Asplund space",
      "Auxiliary normed space",
      "B-convex space",
      "BK-space",
      "Balanced set",
      "Banach algebra",
      "Banach space",
      "Banach–Alaoglu theorem",
      "Banach–Mazur distance",
      "Barrelled space",
      "Besov space",
      "Bilinear form",
      "Bilinear operator",
      "Bornological space",
      "Bounded inverse theorem",
      "Bounded operator",
      "Bounded set (topological vector space)",
      "Bounding point",
      "Brauner space",
      "C*-algebra",
      "Calculus of variations",
      "Carathéodory's theorem (convex hull)",
      "Choquet theory",
      "Closed convex function",
      "Closed graph theorem (functional analysis)",
      "Closed linear operator",
      "Compact operator",
      "Complemented subspace",
      "Complete topological vector space",
      "Concave function",
      "Cone (linear algebra)",
      "Continuous linear operator",
      "Convenient vector space",
      "Convex analysis",
      "Convex combination",
      "Convex cone",
      "Convex conjugate",
      "Convex function",
      "Convex geometry"
    ],
    "categories": [
      "Category:All articles lacking in-text citations",
      "Category:All articles needing additional references",
      "Category:Articles lacking in-text citations from December 2024",
      "Category:Articles needing additional references from December 2024",
      "Category:Convex analysis",
      "Category:Functional analysis",
      "Category:Mathematical analysis",
      "Category:Topology"
    ]
  },
  "Characteristic of a field": {
    "title": "Characteristic (algebra)",
    "url": "https://en.wikipedia.org/wiki/Characteristic_(algebra)",
    "summary": "In mathematics, the characteristic of a ring R, often denoted char(R), is defined to be the smallest positive number of copies of the ring's multiplicative identity (1) that will sum to the additive identity (0). If no such number exists, the ring is said to have characteristic zero. \nThat is, char(R) is the smallest positive number n such that: \n\n  \n    \n      \n        \n          \n            \n              \n                1\n                +\n                ⋯\n                +\n                1\n              \n              ⏟\n            \n          \n          \n            n\n            \n               summands\n            \n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle \\underbrace {1+\\cdots +1} _{n{\\text{ summands}}}=0}\n  \n\nif such a number n exists, and 0 otherwise.",
    "content": "In mathematics, the characteristic of a ring R, often denoted char(R), is defined to be the smallest positive number of copies of the ring's multiplicative identity (1) that will sum to the additive identity (0). If no such number exists, the ring is said to have characteristic zero. \nThat is, char(R) is the smallest positive number n such that: \n\n  \n    \n      \n        \n          \n            \n              \n                1\n                +\n                ⋯\n                +\n                1\n              \n              ⏟\n            \n          \n          \n            n\n            \n               summands\n            \n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle \\underbrace {1+\\cdots +1} _{n{\\text{ summands}}}=0}\n  \n\nif such a number n exists, and 0 otherwise.\n\nMotivation\nThe special definition of the characteristic zero is motivated by the equivalent definitions characterized in the next section, where the characteristic zero is not required to be considered separately.\nThe characteristic may also be taken to be the exponent of the ring's additive group, that is, the smallest positive integer n such that:\n\n  \n    \n      \n        \n          \n            \n              \n                a\n                +\n                ⋯\n                +\n                a\n              \n              ⏟\n            \n          \n          \n            n\n            \n               summands\n            \n          \n        \n        =\n        0\n      \n    \n    {\\displaystyle \\underbrace {a+\\cdots +a} _{n{\\text{ summands}}}=0}\n  \n\nfor every element a of the ring (again, if n exists; otherwise zero). This definition applies in the more general class of rngs (see Ring (mathematics) § Multiplicative identity and the term \"ring\"); for (unital) rings the two definitions are equivalent due to their distributive law.\n\nEquivalent characterizations\nThe characteristic of a ring R is the natural number n such that n\n  \n    \n      \n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} }\n  \n is the kernel of the unique ring homomorphism from \n  \n    \n      \n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} }\n  \n to R.\nThe characteristic is the natural number n such that R contains a subring isomorphic to the factor ring \n  \n    \n      \n        \n          Z\n        \n        \n          /\n        \n        n\n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} /n\\mathbb {Z} }\n  \n, which is the image of the above homomorphism.\nWhen the non-negative integers {0, 1, 2, 3, ...} are partially ordered by divisibility, then 1 is the smallest and 0 is the largest.  Then the characteristic of a ring is the smallest value of n for which n ⋅ 1 = 0. If nothing \"smaller\" (in this ordering) than 0 will suffice, then the characteristic is 0. This is the appropriate partial ordering because of such facts as that char(A × B) is the least common multiple of char A and char B, and that no ring homomorphism f : A → B exists unless char B divides char A.\nThe characteristic of a ring R is n precisely if the statement ka = 0 for all a ∈ R implies that k is a multiple of n.\n\nCase of rings\nIf R and S are rings and there exists a ring homomorphism R → S, then the characteristic of S divides the characteristic of R. This can sometimes be used to exclude the possibility of certain ring homomorphisms. The only ring with characteristic 1 is the zero ring, which has only a single element 0. If a nontrivial ring R does not have any nontrivial zero divisors, then its characteristic is either 0 or prime. In particular, this applies to all fields, to all integral domains, and to all division rings. Any ring of characteristic zero is infinite.\nThe ring \n  \n    \n      \n        \n          Z\n        \n        \n          /\n        \n        n\n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} /n\\mathbb {Z} }\n  \n of integers modulo n has characteristic n. If R is a subring of S, then R and S have the same characteristic. For example, if p is prime and q(X) is an irreducible polynomial with coefficients in the field \n  \n    \n      \n        \n          \n            F\n          \n          \n            p\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {F} _{p}}\n  \n with p elements, then the quotient ring \n  \n    \n      \n        \n          \n            F\n          \n          \n            p\n          \n        \n        [\n        X\n        ]\n        \n          /\n        \n        (\n        q\n        (\n        X\n        )\n        )\n      \n    \n    {\\displaystyle \\mathbb {F} _{p}[X]/(q(X))}\n  \n is a field of characteristic p. Another example: The field \n  \n    \n      \n        \n          C\n        \n      \n    \n    {\\displaystyle \\mathbb {C} }\n  \n of complex numbers contains \n  \n    \n      \n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} }\n  \n, so the characteristic of \n  \n    \n      \n        \n          C\n        \n      \n    \n    {\\displaystyle \\mathb",
    "links": [
      "Additive group",
      "Additive identity",
      "Algebraic closure",
      "Algebraic number field",
      "Category of rings",
      "Category theory",
      "Chelsea Publishing",
      "Complex number",
      "Distributive law",
      "Division ring",
      "Doi (identifier)",
      "Exponent (group theory)",
      "Factor ring",
      "Field (mathematics)",
      "Field extension",
      "Finite field",
      "Finite ring",
      "Formal power series",
      "Freshman's dream",
      "Frobenius homomorphism",
      "ISBN (identifier)",
      "Identity element",
      "Image (mathematics)",
      "Initial object",
      "Injective",
      "Integral domain",
      "Irreducible polynomial",
      "Kernel (ring theory)",
      "Least common multiple",
      "Linear algebra",
      "Mathematics",
      "Modular arithmetic",
      "Natural number",
      "Nicolas Bourbaki",
      "Ordered field",
      "P-adic field",
      "Partially ordered set",
      "Pearson Education",
      "Prime field",
      "Prime number",
      "Quotient ring",
      "Rational fraction",
      "Rational function",
      "Rational number",
      "Real number",
      "Ring (mathematics)",
      "Ring homomorphism",
      "Ring of mixed characteristic",
      "Rng (algebra)",
      "Subring"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Field (mathematics)",
      "Category:Ring theory",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Ideal of a ring": {
    "title": "Ideal (ring theory)",
    "url": "https://en.wikipedia.org/wiki/Ideal_(ring_theory)",
    "summary": "In mathematics, and more specifically in ring theory, an ideal of a ring is a special subset of its elements. Ideals generalize certain subsets of the integers, such as the even numbers or the multiples of 3. Addition and subtraction of even numbers preserves evenness, and multiplying an even number by any integer (even or odd) results in an even number; these closure and absorption properties are the defining properties of an ideal.  An ideal can be used to construct a quotient ring in a way similar to how, in group theory, a normal subgroup can be used to construct a quotient group.\nAmong the integers, the ideals correspond one-for-one with the non-negative integers: in this ring, every ideal is a principal ideal consisting of the multiples of a single non-negative number. However, in other rings, the ideals may not correspond directly to the ring elements, and certain properties of integers, when generalized to rings, attach more naturally to the ideals than to the elements of the r",
    "content": "In mathematics, and more specifically in ring theory, an ideal of a ring is a special subset of its elements. Ideals generalize certain subsets of the integers, such as the even numbers or the multiples of 3. Addition and subtraction of even numbers preserves evenness, and multiplying an even number by any integer (even or odd) results in an even number; these closure and absorption properties are the defining properties of an ideal.  An ideal can be used to construct a quotient ring in a way similar to how, in group theory, a normal subgroup can be used to construct a quotient group.\nAmong the integers, the ideals correspond one-for-one with the non-negative integers: in this ring, every ideal is a principal ideal consisting of the multiples of a single non-negative number. However, in other rings, the ideals may not correspond directly to the ring elements, and certain properties of integers, when generalized to rings, attach more naturally to the ideals than to the elements of the ring. For instance, the prime ideals of a ring are analogous to prime numbers, and the Chinese remainder theorem can be generalized to ideals.  There is a version of unique prime factorization for the ideals of a Dedekind domain (a type of ring important in number theory).\nThe related, but distinct, concept of an ideal in order theory is derived from the notion of an ideal in ring theory. A fractional ideal is a generalization of an ideal, and the usual ideals are sometimes called integral ideals for clarity.\n\nHistory\nErnst Kummer invented the concept of ideal numbers to serve as the \"missing\" factors in number rings in which unique factorization fails; here the word \"ideal\" is in the sense of existing in imagination only, in analogy with \"ideal\" objects in geometry such as points at infinity.\nIn 1876, Richard Dedekind replaced Kummer's undefined concept by concrete sets of numbers, sets that he called ideals, in the third edition of Dirichlet's book Vorlesungen über Zahlentheorie, to which Dedekind had added many supplements.\nLater the notion was extended beyond number rings to the setting of polynomial rings and other commutative rings by David Hilbert and especially Emmy Noether.\n\nDefinitions\nGiven a ring R, a left ideal is a subset I of R that is a subgroup of the additive group of \n  \n    \n      \n        R\n      \n    \n    {\\displaystyle R}\n  \n that \"absorbs multiplication from the left by elements of ⁠\n  \n    \n      \n        R\n      \n    \n    {\\displaystyle R}\n  \n⁠\"; that is, \n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n  \n is a left ideal if it satisfies the following two conditions:\n\n  \n    \n      \n        (\n        I\n        ,\n        +\n        )\n      \n    \n    {\\displaystyle (I,+)}\n  \n is a subgroup of ⁠\n  \n    \n      \n        (\n        R\n        ,\n        +\n        )\n      \n    \n    {\\displaystyle (R,+)}\n  \n⁠,\nFor every \n  \n    \n      \n        r\n        ∈\n        R\n      \n    \n    {\\displaystyle r\\in R}\n  \n and every ⁠\n  \n    \n      \n        x\n        ∈\n        I\n      \n    \n    {\\displaystyle x\\in I}\n  \n⁠, the product \n  \n    \n      \n        r\n        x\n      \n    \n    {\\displaystyle rx}\n  \n is in ⁠\n  \n    \n      \n        I\n      \n    \n    {\\displaystyle I}\n  \n⁠.\nIn other words, a left ideal is a left submodule of R, considered as a left module over itself.\nA right ideal is defined similarly, with the condition \n  \n    \n      \n        r\n        x\n        ∈\n        I\n      \n    \n    {\\displaystyle rx\\in I}\n  \n replaced by ⁠\n  \n    \n      \n        x\n        r\n        ∈\n        I\n      \n    \n    {\\displaystyle xr\\in I}\n  \n⁠. A two-sided ideal is a left ideal that is also a right ideal.\nIf the ring is commutative, the definitions of left, right, and two-sided ideal coincide, and one talks simply of an ideal. In the non-commutative case, \"ideal\" is often used instead of \"two-sided ideal\".\nIf I is a left, right or two-sided ideal, the relation\n\n  \n    \n      \n        x\n        ∼\n        y\n        \n        ⟺\n        \n        x\n        −\n        y\n        ∈\n        I\n      \n    \n    {\\displaystyle x\\sim y\\iff x-y\\in I}\n  \n\nis an equivalence relation on R, and the set of equivalence classes forms a left, right or bi module denoted \n  \n    \n      \n        R\n        \n          /\n        \n        I\n      \n    \n    {\\displaystyle R/I}\n  \n and called the quotient of R by I. (It is an instance of a congruence relation and is a generalization of modular arithmetic.)\nIf the ideal I is two-sided, \n  \n    \n      \n        R\n        \n          /\n        \n        I\n      \n    \n    {\\displaystyle R/I}\n  \n is a ring, and the function \n\n  \n    \n      \n        R\n        →\n        R\n        \n          /\n        \n        I\n      \n    \n    {\\displaystyle R\\to R/I}\n  \n\nthat associates to each element of R its equivalence class is a surjective ring homomorphism that has the ideal as its kernel. Conversely, the kernel of a ring homomorphism is a two-sided ideal. Therefore, the two-sided ideals are exactly the kernels of ring homomor",
    "links": [
      "Absorbing element",
      "Additive group",
      "Algebraic number field",
      "Algebraic number theory",
      "Algebraic structure",
      "Annihilator (ring theory)",
      "Artinian ring",
      "Ascending chain",
      "Associated prime",
      "Associative algebra",
      "Boolean prime ideal theorem",
      "Category of rings",
      "Chinese remainder theorem",
      "Clifford algebra",
      "Closure (mathematics)",
      "Cohen–Macaulay ring",
      "Commutative algebra",
      "Commutative ring",
      "Commutator (ring theory)",
      "Complete lattice",
      "Congruence relation",
      "Continuous function",
      "David Eisenbud",
      "David Hilbert",
      "Dedekind domain",
      "Dirichlet",
      "Distributive lattice",
      "Division ring",
      "Doi (identifier)",
      "Embedding",
      "Emmy Noether",
      "Equidimensionality",
      "Equivalence class",
      "Equivalence relation",
      "Ernst Kummer",
      "Euclidean division",
      "Euclidean domain",
      "Even numbers",
      "Factor ring",
      "Field (mathematics)",
      "Field extension",
      "Finite field",
      "Finite set",
      "Finitely generated module",
      "Forgetful functor",
      "Formal power series ring",
      "Fractional ideal",
      "Fraktur",
      "Free algebra",
      "Free product of associative algebras"
    ],
    "categories": [
      "Category:Algebraic number theory",
      "Category:Algebraic structures",
      "Category:Articles with short description",
      "Category:Commutative algebra",
      "Category:Ideals (ring theory)",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Perfect field": {
    "title": "Perfect field",
    "url": "https://en.wikipedia.org/wiki/Perfect_field",
    "summary": "In algebra, a field k is perfect if any one of the following equivalent conditions holds:\n\nEvery irreducible polynomial over k has no multiple roots in any field extension F/k.\nEvery irreducible polynomial over k has non-zero formal derivative.\nEvery irreducible polynomial over k is separable.\nEvery finite extension of k is separable.\nEvery algebraic extension of k is separable.\nEither k has characteristic 0, or, when k has characteristic p > 0, every element of k is a pth power.\nEither k has characteristic 0, or, when k has characteristic p > 0, the Frobenius endomorphism x ↦ xp is an automorphism of k.\nThe separable closure of k is algebraically closed.\nEvery reduced commutative k-algebra A is a separable algebra; i.e., \n  \n    \n      \n        A\n        \n          ⊗\n          \n            k\n          \n        \n        F\n      \n    \n    {\\displaystyle A\\otimes _{k}F}\n  \n is reduced for every field extension F/k. (see below)\nOtherwise, k is called imperfect.\nIn particular, all fields o",
    "content": "In algebra, a field k is perfect if any one of the following equivalent conditions holds:\n\nEvery irreducible polynomial over k has no multiple roots in any field extension F/k.\nEvery irreducible polynomial over k has non-zero formal derivative.\nEvery irreducible polynomial over k is separable.\nEvery finite extension of k is separable.\nEvery algebraic extension of k is separable.\nEither k has characteristic 0, or, when k has characteristic p > 0, every element of k is a pth power.\nEither k has characteristic 0, or, when k has characteristic p > 0, the Frobenius endomorphism x ↦ xp is an automorphism of k.\nThe separable closure of k is algebraically closed.\nEvery reduced commutative k-algebra A is a separable algebra; i.e., \n  \n    \n      \n        A\n        \n          ⊗\n          \n            k\n          \n        \n        F\n      \n    \n    {\\displaystyle A\\otimes _{k}F}\n  \n is reduced for every field extension F/k. (see below)\nOtherwise, k is called imperfect.\nIn particular, all fields of characteristic zero and all finite fields are perfect.\nPerfect fields are significant because Galois theory over these fields becomes simpler, since the general Galois assumption of field extensions being separable is automatically satisfied over these fields (see third condition above).\nAnother important property of perfect fields is that they admit Witt vectors.\nMore generally, a ring of characteristic p (p a prime) is called perfect if the Frobenius endomorphism is an automorphism. (When restricted to integral domains, this is equivalent to the above condition \"every element of k is a pth power\".)\n\nExamples\nExamples of perfect fields are: \n\nevery field of characteristic zero, so \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n and every finite extension, and \n  \n    \n      \n        \n          C\n        \n      \n    \n    {\\displaystyle \\mathbb {C} }\n  \n;\nevery finite field \n  \n    \n      \n        \n          \n            F\n          \n          \n            q\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {F} _{q}}\n  \n;\nevery algebraically closed field;\nthe union of a set of perfect fields totally ordered by extension;\nfields algebraic over a perfect field.\nMost fields that are encountered in practice are perfect. The imperfect case arises mainly in algebraic geometry in characteristic p > 0. Every imperfect field is necessarily transcendental over its prime subfield (the minimal subfield), because the latter is perfect.\nAn example of an imperfect field is the field \n  \n    \n      \n        \n          \n            F\n          \n          \n            p\n          \n        \n        (\n        x\n        )\n      \n    \n    {\\displaystyle \\mathbf {F} _{p}(x)}\n  \n of rational polynomials in an unknown element \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n. This can be seen from the fact that the Frobenius endomorphism sends \n  \n    \n      \n        x\n        ↦\n        \n          x\n          \n            p\n          \n        \n      \n    \n    {\\displaystyle x\\mapsto x^{p}}\n  \n and therefore is not surjective. Equivalently, one can show that the polynomial \n  \n    \n      \n        f\n        (\n        X\n        )\n        =\n        \n          X\n          \n            p\n          \n        \n        −\n        x\n      \n    \n    {\\displaystyle f(X)=X^{p}-x}\n  \n, which is an element of \n  \n    \n      \n        (\n        \n          \n            F\n          \n          \n            p\n          \n        \n        (\n        x\n        )\n        )\n        [\n        X\n        ]\n      \n    \n    {\\displaystyle (\\mathbf {F} _{p}(x))[X]}\n  \n, is irreducible but inseparable.\nThis field embeds into the perfect field\n\n  \n    \n      \n        \n          \n            F\n          \n          \n            q\n          \n        \n        (\n        x\n        ,\n        \n          x\n          \n            1\n            \n              /\n            \n            p\n          \n        \n        ,\n        \n          x\n          \n            1\n            \n              /\n            \n            \n              p\n              \n                2\n              \n            \n          \n        \n        ,\n        …\n        )\n      \n    \n    {\\displaystyle \\mathbf {F} _{q}(x,x^{1/p},x^{1/p^{2}},\\ldots )}\n  \n\ncalled its perfection. Imperfect fields cause technical difficulties because irreducible polynomials can become reducible in the algebraic closure of the base field. For example, consider \n  \n    \n      \n        f\n        (\n        x\n        ,\n        y\n        )\n        =\n        \n          x\n          \n            p\n          \n        \n        +\n        a\n        \n          y\n          \n            p\n          \n        \n        ∈\n        k\n        [\n        x\n        ,\n        y\n        ]\n      \n    \n    {\\displaystyle f(x,y)=x^{p}+ay^{p}\\in k[x,y]}\n  \n for \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n an imperfect field of characteristic \n  \n    \n      \n        p\n      \n    \n    {\\displays",
    "links": [
      "Abstract algebra",
      "Affine curve",
      "Algebra (Lang)",
      "Algebra (ring theory)",
      "Algebraic extension",
      "Algebraic geometry",
      "Algebraically closed",
      "Algebraically closed field",
      "Automorphism",
      "Brian Conrad",
      "Cambridge Studies in Advanced Mathematics",
      "Characteristic (algebra)",
      "Complex numbers",
      "Encyclopedia of Mathematics",
      "European Mathematical Society",
      "Field (mathematics)",
      "Field extension",
      "Finite extension",
      "Finite field",
      "Finitely generated field extension",
      "Formal derivative",
      "Frobenius endomorphism",
      "Galois theory",
      "Graduate Texts in Mathematics",
      "Hideyuki Matsumura",
      "ISBN (identifier)",
      "Integral domain",
      "Inverse limit",
      "Irreducible polynomial",
      "James Milne (mathematician)",
      "Jean-Pierre Serre",
      "Local Fields (book)",
      "MR (identifier)",
      "Multiplicity (mathematics)",
      "Nicolas Bourbaki",
      "P-ring",
      "Paul Cohn",
      "Perfect ring",
      "Plane curve",
      "Positive integer",
      "Power (mathematics)",
      "Prime number",
      "Prime subfield",
      "Projective system",
      "Quasi-finite field",
      "Rational numbers",
      "Real numbers",
      "Reduced ring",
      "Ring (mathematics)",
      "Ring homomorphism"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Field (mathematics)",
      "Category:Ring theory",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Splitting field": {
    "title": "Splitting field",
    "url": "https://en.wikipedia.org/wiki/Splitting_field",
    "summary": "In abstract algebra, a splitting field of a polynomial with coefficients in a field is the smallest field extension of that field over which the polynomial splits, i.e., decomposes into linear factors.",
    "content": "In abstract algebra, a splitting field of a polynomial with coefficients in a field is the smallest field extension of that field over which the polynomial splits, i.e., decomposes into linear factors.\n\nDefinition\nA splitting field of a polynomial p(X) over a field K is a field extension L of K over which p factors into linear factors\n\n  \n    \n      \n        p\n        (\n        X\n        )\n        =\n        c\n        \n          ∏\n          \n            i\n            =\n            1\n          \n          \n            deg\n            ⁡\n            p\n          \n        \n        (\n        X\n        −\n        \n          a\n          \n            i\n          \n        \n        )\n      \n    \n    {\\displaystyle p(X)=c\\prod _{i=1}^{\\deg p}(X-a_{i})}\n  \n\nwhere \n  \n    \n      \n        c\n        ∈\n        K\n      \n    \n    {\\displaystyle c\\in K}\n  \n and for each \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n we have \n  \n    \n      \n        X\n        −\n        \n          a\n          \n            i\n          \n        \n        ∈\n        L\n        [\n        X\n        ]\n      \n    \n    {\\displaystyle X-a_{i}\\in L[X]}\n  \n with ai not necessarily distinct and such that the roots ai generate L over K. The extension L is then an extension of minimal degree over K in which p splits. It can be shown that such splitting fields exist and are unique up to isomorphism. The amount of freedom in that isomorphism is known as the Galois group of p (if we assume it is separable).\nA splitting field of a set P of polynomials is the smallest field over which each of the polynomials in P splits.\n\nProperties\nAn extension L that is a splitting field for a set of polynomials p(X) over K is called a normal extension of K.\nGiven an algebraically closed field A containing K, there is a unique splitting field L of p between K and A, generated by the roots of p. If K is a subfield of the complex numbers, the existence is immediate. On the other hand, the existence of algebraic closures in general is often proved by 'passing to the limit' from the splitting field result, which therefore requires an independent proof to avoid circular reasoning.\nGiven a separable extension K′ of K, a Galois closure L of K′ is a type of splitting field, and also a Galois extension of K containing K′ that is minimal, in an obvious sense. Such a Galois closure should contain a splitting field for all the polynomials p over K that are minimal polynomials over K of elements of K′.\n\nConstructing splitting fields\nMotivation\nFinding roots of polynomials has been an important problem since the time of the ancient Greeks. Some polynomials, however, such as x2 + 1 over R, the real numbers, have no roots. By constructing the splitting field for such a polynomial one can find the roots of the polynomial in the new field.\n\nThe construction\nLet F be a field and p(X) be a polynomial in the polynomial ring F[X] of degree n. The general process for constructing K, the splitting field of p(X) over F, is to construct a chain of fields \n  \n    \n      \n        F\n        =\n        \n          K\n          \n            0\n          \n        \n        ⊆\n        \n          K\n          \n            1\n          \n        \n        ⊆\n        ⋯\n        ⊆\n        \n          K\n          \n            r\n            −\n            1\n          \n        \n        ⊆\n        \n          K\n          \n            r\n          \n        \n        =\n        K\n      \n    \n    {\\displaystyle F=K_{0}\\subseteq K_{1}\\subseteq \\cdots \\subseteq K_{r-1}\\subseteq K_{r}=K}\n  \n such that Ki is an extension of Ki−1 containing a new root of p(X). Since p(X) has at most n roots the construction will require at most n extensions. The steps for constructing Ki are given as follows:\n\nFactorize p(X) over Ki into irreducible factors \n  \n    \n      \n        \n          f\n          \n            1\n          \n        \n        (\n        X\n        )\n        \n          f\n          \n            2\n          \n        \n        (\n        X\n        )\n        ⋯\n        \n          f\n          \n            k\n          \n        \n        (\n        X\n        )\n      \n    \n    {\\displaystyle f_{1}(X)f_{2}(X)\\cdots f_{k}(X)}\n  \n.\nChoose any nonlinear irreducible factor f(X).\nConstruct the field extension Ki+1 of Ki as the quotient ring Ki+1 = Ki[X] / (f(X)) where (f(X)) denotes the ideal in Ki[X] generated by f(X).\nRepeat the process for Ki+1 until p(X) completely factors.\nThe irreducible factor f(X) used in the quotient construction may be chosen arbitrarily. Although different choices of factors may lead to different subfield sequences, the resulting splitting fields will be isomorphic.\nSince f(X) is irreducible, (f(X)) is a maximal ideal of Ki[X] and Ki[X] / (f(X)) is, in fact, a field, the residue field for that maximal ideal. Moreover, if we let \n  \n    \n      \n        π\n        :\n        \n          K\n          \n            i\n          \n        \n        [\n        X\n        ]\n        →\n        \n          K\n          \n            i\n          \n   ",
    "links": [
      "Abstract algebra",
      "Algebraic closure",
      "Algebraically closed field",
      "Augustin-Louis Cauchy",
      "Basis (linear algebra)",
      "Bijective",
      "Central simple algebra",
      "Chain (ordered set)",
      "Characteristic (algebra)",
      "Circular definition",
      "Coefficient",
      "Complex number",
      "Comptes Rendus Hebdomadaires des Séances de l'Académie des Sciences",
      "Congruence relation",
      "Converse (logic)",
      "Cube root",
      "Cube root of unity",
      "Degree of a field extension",
      "Degree of a polynomial",
      "Encyclopedia of Mathematics",
      "Equivalence class",
      "Eric W. Weisstein",
      "European Mathematical Society",
      "Factorization of polynomials",
      "Field (mathematics)",
      "Field extension",
      "Finite field",
      "Galois extension",
      "Galois group",
      "Homomorphism",
      "ISBN (identifier)",
      "Ideal (ring theory)",
      "Indeterminate (variable)",
      "Injective",
      "Irreducible polynomial",
      "Isomorphic",
      "Isomorphism",
      "Jean-Pierre Serre",
      "Linear polynomial",
      "MathWorld",
      "Mathematical proof",
      "Maximal ideal",
      "Minimal polynomial (field theory)",
      "Modular arithmetic",
      "Monic polynomial",
      "Parity (mathematics)",
      "Polynomial",
      "Polynomial long division",
      "Polynomial ring",
      "Prime number"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1 French-language sources (fr)",
      "Category:Field (mathematics)",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Springer-Verlag": {
    "title": "Springer Science+Business Media",
    "url": "https://en.wikipedia.org/wiki/Springer_Science%2BBusiness_Media",
    "summary": "Springer Science+Business Media, commonly known as Springer, is a German multinational publishing company of books, e-books and peer-reviewed journals in science, humanities, technical and medical (STM) publishing.\nOriginally founded in 1842 in Berlin, it expanded internationally in the 1960s, and through mergers in the 1990s and a sale to venture capitalists it fused with Wolters Kluwer and eventually became part of Springer Nature in 2015. Springer has major offices in Berlin, Heidelberg, Dordrecht, and New York City.",
    "content": "Springer Science+Business Media, commonly known as Springer, is a German multinational publishing company of books, e-books and peer-reviewed journals in science, humanities, technical and medical (STM) publishing.\nOriginally founded in 1842 in Berlin, it expanded internationally in the 1960s, and through mergers in the 1990s and a sale to venture capitalists it fused with Wolters Kluwer and eventually became part of Springer Nature in 2015. Springer has major offices in Berlin, Heidelberg, Dordrecht, and New York City.\n\nHistory\nJulius Springer founded Springer-Verlag in Berlin in 1842 and his son Ferdinand Springer grew it from a small firm of 4 employees into Germany's then second-largest academic publisher with 65 staff in 1872. In 1964, Springer expanded its business internationally, opening an office in New York City. Offices in Tokyo, Paris, Milan, Hong Kong, and Delhi soon followed.\nIn 1999, the academic publishing company BertelsmannSpringer was formed after the media and entertainment company Bertelsmann bought a majority stake in Springer-Verlag. In 2003, the British investment groups Cinven and Candover bought BertelsmannSpringer from Bertelsmann. They merged the company in 2004 with the Dutch publisher Kluwer Academic Publishers (successor of D. Reidel,  Dr. W. Junk, Plenum Publishers, most of Chapman & Hall, and Baltzer Science Publishers) which they bought from Wolters Kluwer in 2002, to form Springer Science+Business Media.\nIn 2006, Springer acquired Humana Press.\nSpringer acquired the open-access publisher BioMed Central in October 2008 for an undisclosed amount.\nIn 2009, Cinven and Candover sold Springer to two private equity firms, EQT AB and Government of Singapore Investment Corporation, confirmed in February 2010 after the competition authorities in the US and in Europe approved the transfer.\nIn 2011, Springer acquired Pharma Marketing and Publishing Services (MPS) from Wolters Kluwer.\nIn 2013, the London-based private equity firm BC Partners acquired a majority stake in Springer from EQT and GIC for $4.4 billion.\nIn January 2015, Holtzbrinck Publishing Group / Nature Publishing Group and Springer Science+Business Media announced a merger. in May 2015 they concluded the transaction and formed a new joint venture company, Springer Nature with Holtzbrinck in the majority 53% share and BC Partners retaining 47% interest in the company.\n\nProducts\nIn 1996, Springer launched electronic book and journal content on its SpringerLink site.\nSpringerImages was launched in 2008. In 2009, SpringerMaterials, a platform for accessing the Landolt-Börnstein database of research and information on materials and their properties, was launched.\nAuthorMapper is a free online tool for visualizing scientific research that enables document discovery based on author locations and geographic maps, helping users explore patterns in scientific research, identify literature trends, discover collaborative relationships, and locate experts in several scientific/medical fields.\nSpringer Protocols contained a collection of laboratory protocols, recipes that provide step-by-step instructions for conducting experiments, which in 2018 was made available in SpringerLink instead.\nBook publications include major reference works, textbooks, monographs and book series; more than 168,000 titles are available as e-books in 24 subject collections.\n\nOpen access\nSpringer is a member of the Open Access Scholarly Publishers Association. For some of its journals, Springer does not require its authors to transfer their copyrights, and allows them to decide whether their articles are published under an open-access license or in the traditional restricted licence model. While open-access publishing typically requires the author to pay a fee for copyright retention, this fee is sometimes covered by a third party. For example, a national institution in Poland allows authors to publish in open-access journals without incurring any personal cost but using public funds.\n\nControversies\nIn 1938, Springer-Verlag was pressed to apply Nazi principles on the journal Zentralblatt MATH. Tullio Levi-Civita, who was Jewish, was forced out from the editorial board, and Otto Neugebauer resigned in protest along with most of the rest of the board.\nIn 2014, it was revealed that 16 papers in conference proceedings published by Springer had been computer-generated using SCIgen. Springer subsequently retracted all papers from these proceedings. IEEE had removed more than 100 fake papers from its conference proceedings.\nIn 2015, Springer retracted 64 papers from 10 of its journals it had published after a fraudulent peer review process was uncovered.\n\nManipulation of bibliometrics\nAccording to Goodhart's law and concerned academics like the signatories of the San Francisco Declaration on Research Assessment, commercial academic publishers benefit from manipulation of bibliometrics and scientometrics like the journal impact factor, which is often used as a proxy",
    "links": [
      "Albuquerque Journal",
      "Altmetric",
      "Apress",
      "Axel Springer SE",
      "BC Partners",
      "Baltzer Science Publishers",
      "Bedford-St. Martin's",
      "Berlin",
      "Bertelsmann",
      "Bibliometrics",
      "BioMed Central",
      "Birkhäuser",
      "Birkhäuser Verlag",
      "Bloomberg.com",
      "Candover Investments",
      "Cellular Oncology",
      "Chapman & Hall",
      "Chemistry Central",
      "Cinven",
      "D. Reidel",
      "Die Zeit",
      "Digital Science",
      "Doi (identifier)",
      "Dordrecht",
      "Droemer Knaur",
      "E-book",
      "EQT AB",
      "Encyclopaedia of Mathematics",
      "Ergebnisse der Mathematik und ihrer Grenzgebiete",
      "Farrar, Straus and Giroux",
      "Feiwel and Friends",
      "First Second Books",
      "Germany",
      "Goodhart's law",
      "Government of Singapore Investment Corporation",
      "Graduate Texts in Mathematics",
      "Grothendieck's Séminaire de géométrie algébrique",
      "Gutefrage.net",
      "Hayden-McNeil",
      "Heidelberg",
      "Henry Holt and Company",
      "Holtzbrinck Publishing Group",
      "Humana Press",
      "IEEE",
      "Iclicker",
      "Journal Citation Reports",
      "Journal impact factor",
      "Julius Springer",
      "Kiepenheuer & Witsch",
      "Kingfisher (publisher)"
    ],
    "categories": [
      "Category:1842 establishments in Prussia",
      "Category:Academic publishing companies",
      "Category:All articles with unsourced statements",
      "Category:All articles with vague or ambiguous time",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from April 2020",
      "Category:Commercial digital libraries",
      "Category:Companies disestablished in 2015",
      "Category:Computer book publishing companies",
      "Category:German companies disestablished in 2015"
    ]
  },
  "Prime number": {
    "title": "Prime number",
    "url": "https://en.wikipedia.org/wiki/Prime_number",
    "summary": "A prime number (or a prime) is a natural number greater than 1 that is not a product of two smaller natural numbers. A natural number greater than 1 that is not prime is called a composite number. For example, 5 is prime because the only ways of writing it as a product, 1 × 5 or 5 × 1, involve 5 itself. However, 4 is composite because it is a product (2 × 2) in which both numbers are smaller than 4. Primes are central in number theory because of the fundamental theorem of arithmetic: every natural number greater than 1 is either a prime itself or can be factorized as a product of primes that is unique up to their order.\nThe property of being prime is called primality. A simple but slow method of checking the primality of a given number ⁠\n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n⁠, called trial division, tests whether ⁠\n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n⁠ is a multiple of any integer between 2 and ⁠\n  \n    \n      \n        \n          \n    ",
    "content": "A prime number (or a prime) is a natural number greater than 1 that is not a product of two smaller natural numbers. A natural number greater than 1 that is not prime is called a composite number. For example, 5 is prime because the only ways of writing it as a product, 1 × 5 or 5 × 1, involve 5 itself. However, 4 is composite because it is a product (2 × 2) in which both numbers are smaller than 4. Primes are central in number theory because of the fundamental theorem of arithmetic: every natural number greater than 1 is either a prime itself or can be factorized as a product of primes that is unique up to their order.\nThe property of being prime is called primality. A simple but slow method of checking the primality of a given number ⁠\n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n⁠, called trial division, tests whether ⁠\n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n⁠ is a multiple of any integer between 2 and ⁠\n  \n    \n      \n        \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle {\\sqrt {n}}}\n  \n⁠. Faster algorithms include the Miller–Rabin primality test, which is fast but has a small chance of error, and the AKS primality test, which always produces the correct answer in polynomial time but is too slow to be practical. Particularly fast methods are available for numbers of special forms, such as Mersenne numbers. As of October 2024 the largest known prime number is a Mersenne prime with 41,024,320 decimal digits.\nThere are infinitely many primes, as demonstrated by Euclid around 300 BC. No known simple formula separates prime numbers from composite numbers. However, the distribution of primes within the natural numbers in the large can be statistically modelled. The first result in that direction is the prime number theorem, proven at the end of the 19th century, which says roughly that the probability of a randomly chosen large number being prime is inversely proportional to its number of digits, that is, to its logarithm.\nSeveral historical questions regarding prime numbers are still unsolved. These include Goldbach's conjecture, that every even integer greater than 2 can be expressed as the sum of two primes, and the twin prime conjecture, that there are infinitely many pairs of primes that differ by two. Such questions spurred the development of various branches of number theory, focusing on analytic or algebraic aspects of numbers. Primes are used in several routines in information technology, such as public-key cryptography, which relies on the difficulty of factoring large numbers into their prime factors. In abstract algebra, objects that behave in a generalized way like prime numbers include prime elements and prime ideals.\n\nDefinition and examples\nA natural number (1, 2, 3, 4, 5, 6, etc.) is called a prime number (or a prime) if it is greater than 1 and cannot be written as the product of two smaller natural numbers. The numbers greater than 1 that are not prime are called composite numbers. In other words, ⁠\n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n⁠ is prime if ⁠\n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n⁠ items cannot be divided up into smaller equal-size groups of more than one item, or if it is not possible to arrange ⁠\n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n⁠ dots into a rectangular grid that is more than one dot wide and more than one dot high. For example, among the numbers 1 through 6, the numbers 2, 3, and 5 are the prime numbers, as there are no other numbers that divide them evenly (without a remainder). 1 is not prime, as it is specifically excluded in the definition. 4 = 2 × 2 and 6 = 2 × 3 are both composite.\n\nThe divisors of a natural number ⁠\n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n⁠ are the natural numbers that divide ⁠\n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n⁠ evenly. Every natural number has both 1 and itself as a divisor. If it has any other divisor, it cannot be prime. This leads to an equivalent definition of prime numbers: they are the numbers with exactly two positive divisors. Those two are 1 and the number itself. As 1 has only one divisor, itself, it is not prime by this definition. Yet another way to express the same thing is that a number ⁠\n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n⁠ is prime if it is greater than one and if none of the numbers \n  \n    \n      \n        2\n        ,\n        3\n        ,\n        …\n        ,\n        n\n        −\n        1\n      \n    \n    {\\displaystyle 2,3,\\dots ,n-1}\n  \n divides ⁠\n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n⁠ evenly.\nThe first 25 prime numbers (all the prime numbers less than 100) are:\n\n2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97 (sequence A000040 in the OEIS).\nNo even number ⁠\n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n⁠ greater than 2 is prime",
    "links": [
      "0",
      "1",
      "101 (number)",
      "103 (number)",
      "107 (number)",
      "109 (number)",
      "113 (number)",
      "11 (number)",
      "127 (number)",
      "131 (number)",
      "137 (number)",
      "139 (number)",
      "13 (number)",
      "149 (number)",
      "151 (number)",
      "157 (number)",
      "163 (number)",
      "167 (number)",
      "173 (number)",
      "179 (number)",
      "17 (number)",
      "181 (number)",
      "191 (number)",
      "193 (number)",
      "197 (number)",
      "199 (number)",
      "19 (number)",
      "2",
      "211 (number)",
      "223 (number)",
      "227 (number)",
      "229 (number)",
      "233 (number)",
      "239 (number)",
      "23 (number)",
      "241 (number)",
      "251 (number)",
      "257 (number)",
      "263 (number)",
      "269 (number)",
      "271 (number)",
      "277 (number)",
      "281 (number)",
      "29 (number)",
      "3",
      "31 (number)",
      "37 (number)",
      "41 (number)",
      "43 (number)",
      "47 (number)"
    ],
    "categories": [
      "Category:All articles containing potentially dated statements",
      "Category:Articles containing Ancient Greek (to 1453)-language text",
      "Category:Articles containing potentially dated statements from 2014",
      "Category:Articles containing potentially dated statements from December 2019",
      "Category:Articles containing potentially dated statements from October 2012",
      "Category:Articles containing potentially dated statements from October 2024",
      "Category:Articles containing proofs",
      "Category:Articles with short description",
      "Category:CS1 French-language sources (fr)",
      "Category:CS1 Italian-language sources (it)"
    ]
  },
  "Real number": {
    "title": "Real number",
    "url": "https://en.wikipedia.org/wiki/Real_number",
    "summary": "In mathematics, a real number is a number that can be used to measure a continuous one-dimensional quantity such as a length, duration or temperature. Here, continuous means that pairs of values can have arbitrarily small differences. Every real number can be almost uniquely represented by an infinite decimal expansion.\nThe real numbers are fundamental in calculus (and in many other branches of mathematics), in particular by their role in the classical definitions of limits, continuity and derivatives.\nThe set of real numbers, sometimes called \"the reals\", is traditionally denoted by a bold R, often using blackboard bold, ⁠\n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n⁠.\nThe adjective real, used in the 17th century by René Descartes, distinguishes real numbers from imaginary numbers such as the square roots of −1.\nThe real numbers include the rational numbers, such as the integer −5 and the fraction 4 / 3. The rest of the real numbers are",
    "content": "In mathematics, a real number is a number that can be used to measure a continuous one-dimensional quantity such as a length, duration or temperature. Here, continuous means that pairs of values can have arbitrarily small differences. Every real number can be almost uniquely represented by an infinite decimal expansion.\nThe real numbers are fundamental in calculus (and in many other branches of mathematics), in particular by their role in the classical definitions of limits, continuity and derivatives.\nThe set of real numbers, sometimes called \"the reals\", is traditionally denoted by a bold R, often using blackboard bold, ⁠\n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n⁠.\nThe adjective real, used in the 17th century by René Descartes, distinguishes real numbers from imaginary numbers such as the square roots of −1.\nThe real numbers include the rational numbers, such as the integer −5 and the fraction 4 / 3. The rest of the real numbers are called irrational numbers. Some irrational numbers (as well as all the rationals) are the root of a polynomial with integer coefficients, such as the square root √2 = 1.414...; these are called algebraic numbers. There are also real numbers which are not, such as π = 3.1415...; these are called transcendental numbers.\n\nReal numbers can be thought of as all points on a line called the number line or real line, where the points corresponding to integers (..., −2, −1, 0, 1, 2, ...) are equally spaced.\nThe informal descriptions above of the real numbers are not sufficient for ensuring the correctness of proofs of theorems involving real numbers. The realization that a better definition was needed, and the elaboration of such a definition was a major development of 19th-century mathematics and is the foundation of real analysis, the study of real functions and real-valued sequences. A current axiomatic definition is that real numbers form the unique (up to an isomorphism) Dedekind-complete ordered field. Other common definitions of real numbers include equivalence classes of Cauchy sequences (of rational numbers), Dedekind cuts, and infinite decimal representations. All these definitions satisfy the axiomatic definition and are thus equivalent.\n\nCharacterizing properties\nReal numbers are completely characterized by their fundamental properties that can be summarized by saying that they form an ordered field that is Dedekind complete. Here, \"completely characterized\" means that there is a unique isomorphism between any two Dedekind complete ordered fields, and thus that their elements have exactly the same properties. This implies that one can manipulate real numbers and compute with them, without knowing how they can be defined; this is what mathematicians and physicists did during several centuries before the first formal definitions were provided in the second half of the 19th century. See Construction of the real numbers for details about these formal definitions and the proof of their equivalence.\n\nArithmetic\nThe real numbers form an ordered field. Intuitively, this means that methods and rules of elementary arithmetic apply to them. More precisely, there are two binary operations, addition and multiplication, and a total order that have the following properties.\n\nThe addition of two real numbers a and b produce a real number denoted \n  \n    \n      \n        a\n        +\n        b\n        ,\n      \n    \n    {\\displaystyle a+b,}\n  \n which is the sum of a and b.\nThe multiplication of two real numbers a and b produce a real number denoted \n  \n    \n      \n        a\n        b\n        ,\n      \n    \n    {\\displaystyle ab,}\n  \n \n  \n    \n      \n        a\n        ⋅\n        b\n      \n    \n    {\\displaystyle a\\cdot b}\n  \n or \n  \n    \n      \n        a\n        ×\n        b\n        ,\n      \n    \n    {\\displaystyle a\\times b,}\n  \n which is the product of a and b.\nAddition and multiplication are both commutative, which means that \n  \n    \n      \n        a\n        +\n        b\n        =\n        b\n        +\n        a\n      \n    \n    {\\displaystyle a+b=b+a}\n  \n and \n  \n    \n      \n        a\n        b\n        =\n        b\n        a\n      \n    \n    {\\displaystyle ab=ba}\n  \n for every real numbers a and b.\nAddition and multiplication are both associative, which means that \n  \n    \n      \n        (\n        a\n        +\n        b\n        )\n        +\n        c\n        =\n        a\n        +\n        (\n        b\n        +\n        c\n        )\n      \n    \n    {\\displaystyle (a+b)+c=a+(b+c)}\n  \n and \n  \n    \n      \n        (\n        a\n        b\n        )\n        c\n        =\n        a\n        (\n        b\n        c\n        )\n      \n    \n    {\\displaystyle (ab)c=a(bc)}\n  \n for every real numbers a, b and c, and that parentheses may be omitted in both cases.\nMultiplication is distributive over addition, which means that \n  \n    \n      \n        a\n        (\n        b\n        +\n        c\n        )\n        =\n        a\n        b\n        +\n        a\n        c\n      \n    \n    ",
    "links": [
      "0.999...",
      "Abraham Robinson",
      "Absolute difference",
      "Absolute value",
      "Abuse of notation",
      "Abū Kāmil Shujā ibn Aslam",
      "Accuracy and precision",
      "Addition",
      "Additive identity",
      "Additive inverse",
      "Adolf Hurwitz",
      "Adrien-Marie Legendre",
      "Affinely extended real number system",
      "Aleph-zero",
      "Alfred Tarski",
      "Algebra of physical space",
      "Algebraic number",
      "Algebraically closed field",
      "Algorithm",
      "Algorithmically random sequence",
      "Almost all",
      "American Scientist",
      "Amos Tversky",
      "ArXiv (identifier)",
      "Arbitrary-precision arithmetic",
      "Archimedean field",
      "Archimedean property",
      "Arithmetic operation",
      "Associative",
      "Associative algebra",
      "Augustin Louis Cauchy",
      "Axiom",
      "Axiom of choice",
      "Axiomatic system",
      "Baire space (set theory)",
      "Basis (linear algebra)",
      "Bernhard Riemann",
      "Bibcode (identifier)",
      "Bicomplex number",
      "Bijection",
      "Binary number",
      "Binary operation",
      "Bioctonion",
      "Biquaternion",
      "Blackboard bold",
      "Calculator",
      "Calculus",
      "Cantor's diagonal argument",
      "Cantor's first set theory article",
      "Cantor's first uncountability proof"
    ],
    "categories": [
      "Category:All articles lacking in-text citations",
      "Category:Articles containing French-language text",
      "Category:Articles lacking in-text citations from July 2024",
      "Category:Articles with short description",
      "Category:CS1 German-language sources (de)",
      "Category:Elementary mathematics",
      "Category:Real algebraic geometry",
      "Category:Real numbers",
      "Category:Short description is different from Wikidata",
      "Category:Webarchive template wayback links"
    ]
  },
  "Group theory": {
    "title": "Group theory",
    "url": "https://en.wikipedia.org/wiki/Group_theory",
    "summary": "In abstract algebra, group theory studies the algebraic structures known as groups.  \nThe concept of a group is central to abstract algebra: other well-known algebraic structures, such as rings, fields, and vector spaces, can all be seen as groups endowed with additional operations and axioms. Groups recur throughout mathematics, and the methods of group theory have influenced many parts of algebra. Linear algebraic groups and Lie groups are two branches of group theory that have experienced advances and have become subject areas in their own right.\nVarious physical systems, such as crystals and the hydrogen atom, and three of the four known fundamental forces in the universe, may be modelled by symmetry groups. Thus group theory and the closely related representation theory have many important applications in physics, chemistry, and materials science. Group theory is also central to public key cryptography.\nThe early history of group theory dates from the 19th century. One of the most",
    "content": "In abstract algebra, group theory studies the algebraic structures known as groups.  \nThe concept of a group is central to abstract algebra: other well-known algebraic structures, such as rings, fields, and vector spaces, can all be seen as groups endowed with additional operations and axioms. Groups recur throughout mathematics, and the methods of group theory have influenced many parts of algebra. Linear algebraic groups and Lie groups are two branches of group theory that have experienced advances and have become subject areas in their own right.\nVarious physical systems, such as crystals and the hydrogen atom, and three of the four known fundamental forces in the universe, may be modelled by symmetry groups. Thus group theory and the closely related representation theory have many important applications in physics, chemistry, and materials science. Group theory is also central to public key cryptography.\nThe early history of group theory dates from the 19th century. One of the most important mathematical achievements of the 20th century was the collaborative effort, taking up more than 10,000 journal pages and mostly published between 1960 and 2004, that culminated in a complete classification of finite simple groups.\n\nHistory\nGroup theory has three main historical sources: number theory, the theory of algebraic equations, and geometry. The number-theoretic strand was begun by Leonhard Euler, and developed by Gauss's work on modular arithmetic and additive and multiplicative groups related to quadratic fields. Early results about permutation groups were obtained by Lagrange, Ruffini, and Abel in their quest for general solutions of polynomial equations of high degree. Évariste Galois coined the term \"group\" and established a connection, now known as Galois theory, between the nascent theory of groups and field theory. In geometry, groups first became important in projective geometry and, later, non-Euclidean geometry. Felix Klein's Erlangen program proclaimed group theory to be the organizing principle of geometry.\nGalois, in the 1830s, was the first to employ groups to determine the solvability of polynomial equations. Arthur Cayley and Augustin Louis Cauchy pushed these investigations further by creating the theory of permutation groups. The second historical source for groups stems from geometrical situations. In an attempt to come to grips with possible geometries (such as euclidean, hyperbolic or projective geometry) using group theory, Felix Klein initiated the Erlangen programme. Sophus Lie, in 1884, started using groups (now called Lie groups) attached to analytic problems. Thirdly, groups were, at first implicitly and later explicitly, used in algebraic number theory.\nThe different scope of these early sources resulted in different notions of groups. The theory of groups was unified starting around 1880. Since then, the impact of group theory has been ever growing, giving rise to the birth of abstract algebra in the early 20th century, representation theory, and many more influential spin-off domains. The classification of finite simple groups is a vast body of work from the mid 20th century, classifying all the finite simple groups.\n\nMain classes of groups\nThe range of groups being considered has gradually expanded from finite permutation groups and special examples of matrix groups to abstract groups that may be specified through a presentation by generators and relations.\n\nPermutation groups\nThe first class of groups to undergo a systematic study was permutation groups. Given any set X and a collection G of bijections of X into itself (known as permutations) that is closed under compositions and inverses, G is a group acting on X. If X consists of n elements and G consists of all permutations, G is the symmetric group Sn; in general, any permutation group G is a subgroup of the symmetric group of X. An early construction due to Cayley exhibited any group as a permutation group, acting on itself (X = G) by means of the left regular representation.\nIn many cases, the structure of a permutation group can be studied using the properties of its action on the corresponding set. For example, in this way one proves that for n ≥ 5, the alternating group An is simple, i.e. does not admit any proper normal subgroups. This fact plays a key role in the impossibility of solving a general algebraic equation of degree n ≥ 5 in radicals.\n\nMatrix groups\nThe next important class of groups is given by matrix groups, or linear groups. Here G is a set consisting of invertible matrices of given order n over a field K that is closed under the products and inverses. Such a group acts on the n-dimensional vector space Kn by linear transformations. This action makes matrix groups conceptually similar to permutation groups, and the geometry of the action may be usefully exploited to establish properties of the group G.\n\nTransformation groups\nPermutation groups and matrix groups are special cases of transformation group",
    "links": [
      "Abelian group",
      "Abelian variety",
      "Abel–Ruffini theorem",
      "Absolute value",
      "Abstract algebra",
      "Abstract harmonic analysis",
      "Additive group",
      "Algebra",
      "Algebraic K-theory",
      "Algebraic equation",
      "Algebraic equations",
      "Algebraic field extension",
      "Algebraic geometry",
      "Algebraic group",
      "Algebraic number field",
      "Algebraic number theory",
      "Algebraic structure",
      "Algebraic topology",
      "Algebraic variety",
      "Algorithm",
      "Alternating group",
      "Analysis (mathematics)",
      "Analytic geometry",
      "Analytic number theory",
      "Angle",
      "Applied mathematics",
      "ArXiv (identifier)",
      "Arithmetic",
      "Arithmetic geometry",
      "Arithmetic group",
      "Armand Borel",
      "Arthur Cayley",
      "Augustin Louis Cauchy",
      "Automorphism",
      "Automorphism group",
      "Axiom",
      "Bass-Serre theory",
      "Bijection",
      "Binary relation",
      "Birch and Swinnerton-Dyer conjecture",
      "Boron trifluoride",
      "Braid group",
      "Burnside's lemma",
      "Caesar's cipher",
      "Caesar cipher",
      "Calculus",
      "Carl Friedrich Gauss",
      "Category (mathematics)",
      "Category theory",
      "Cauchy's theorem (group theory)"
    ],
    "categories": [
      "Category:All articles with unsourced statements",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from December 2013",
      "Category:Articles with unsourced statements from June 2012",
      "Category:Group theory",
      "Category:Pages using Sister project links with hidden wikidata",
      "Category:Short description is different from Wikidata",
      "Category:Wikipedia articles incorporating a citation from the 1911 Encyclopaedia Britannica with Wikisource reference"
    ]
  },
  "Finite geometry": {
    "title": "Finite geometry",
    "url": "https://en.wikipedia.org/wiki/Finite_geometry",
    "summary": "A finite geometry is any geometric system that has only a finite number of points.\nThe familiar Euclidean geometry is not finite, because a Euclidean line contains infinitely many points. A geometry based on the graphics displayed on a computer screen, where the pixels are considered to be the points, would be a finite geometry. While there are many systems that could be called finite geometries, attention is mostly paid to the finite projective and affine spaces because of their regularity and simplicity.  Other significant types of finite geometry are finite Möbius or inversive planes and Laguerre planes, which are examples of a general type called Benz planes, and their higher-dimensional analogs such as higher finite inversive geometries.\nFinite geometries may be constructed via linear algebra, starting from vector spaces over a finite field; the affine and projective planes so constructed are called Galois geometries.  Finite geometries can also be defined purely axiomatically. Mo",
    "content": "A finite geometry is any geometric system that has only a finite number of points.\nThe familiar Euclidean geometry is not finite, because a Euclidean line contains infinitely many points. A geometry based on the graphics displayed on a computer screen, where the pixels are considered to be the points, would be a finite geometry. While there are many systems that could be called finite geometries, attention is mostly paid to the finite projective and affine spaces because of their regularity and simplicity.  Other significant types of finite geometry are finite Möbius or inversive planes and Laguerre planes, which are examples of a general type called Benz planes, and their higher-dimensional analogs such as higher finite inversive geometries.\nFinite geometries may be constructed via linear algebra, starting from vector spaces over a finite field; the affine and projective planes so constructed are called Galois geometries.  Finite geometries can also be defined purely axiomatically. Most common finite geometries are Galois geometries, since any finite projective space of dimension three or greater is isomorphic to a projective space over a finite field (that is, the projectivization of a vector space over a finite field). However, dimension two has affine and projective planes that are not isomorphic to Galois geometries, namely the non-Desarguesian planes.  Similar results hold for other kinds of finite geometries.\n\nFinite planes\nThe following remarks apply only to finite planes.\nThere are two main kinds of finite plane geometry: affine and projective.\nIn an affine plane, the normal sense of parallel lines applies.\nIn a projective plane, by contrast, any two lines intersect at a unique point, so parallel lines do not exist.  Both finite affine plane geometry and finite projective plane geometry may be described by fairly simple axioms.\n\nFinite affine planes\nAn affine plane geometry is a nonempty set X (whose elements are called \"points\"), along with a nonempty collection L of subsets of X (whose elements are called \"lines\"), such that:\n\nFor every two distinct points, there is exactly one line that contains both points.\nPlayfair's axiom: Given a line \n  \n    \n      \n        ℓ\n      \n    \n    {\\displaystyle \\ell }\n  \n and a point \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n not on \n  \n    \n      \n        ℓ\n      \n    \n    {\\displaystyle \\ell }\n  \n, there exists exactly one line \n  \n    \n      \n        \n          ℓ\n          ′\n        \n      \n    \n    {\\displaystyle \\ell '}\n  \n containing \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n such that \n  \n    \n      \n        ℓ\n        ∩\n        \n          ℓ\n          ′\n        \n        =\n        ∅\n        .\n      \n    \n    {\\displaystyle \\ell \\cap \\ell '=\\varnothing .}\n  \n\nThere exists a set of four points, no three of which belong to the same line.\nThe last axiom ensures that the geometry is not trivial (either empty or too simple to be of interest, such as a single line with an arbitrary number of points on it), while the first two specify the nature of the geometry.\nThe simplest affine plane contains only four points; it is called the affine plane of order 2. (The order of an affine plane is the number of points on any line, see below.) Since no three are collinear, any pair of points determines a unique line, and so this plane contains six lines. It corresponds to a tetrahedron where non-intersecting edges are considered \"parallel\", or a square where not only opposite sides, but also diagonals are considered \"parallel\".\nThe affine plane of order 3 is known as the Hesse configuration.\nMore generally, a finite affine plane of order n has n2 points and n2 + n lines; each line contains n points, and each point is on n + 1 lines.\n\nFinite projective planes\nA projective plane geometry is a nonempty set X (whose elements are called \"points\"), along with a nonempty collection L of subsets of X (whose elements are called \"lines\"), such that:\n\nFor every two distinct points, there is exactly one line that contains both points.\nThe intersection of any two distinct lines contains exactly one point.\nThere exists a set of four points, no three of which belong to the same line.\n\nAn examination of the first two axioms shows that they are nearly identical, except that the roles of points and lines have been interchanged.\nThis suggests the principle of duality for projective plane geometries, meaning that any true statement valid in all these geometries remains true if we exchange points for lines and lines for points.\nThe smallest geometry satisfying all three axioms contains seven points. In this simplest of the projective planes, there are also seven lines; each point is on three lines, and each line contains three points.\n\nThis particular projective plane is sometimes called the Fano plane.\nIf any of the lines is removed from the plane, along with the points on that line, the resulting geometry is the affine plane of order 2.\nThe Fano plane i",
    "links": [
      "Abstract algebra",
      "Affine geometry",
      "Affine plane (incidence geometry)",
      "Affine space",
      "Ahmes",
      "Algebra",
      "Algebraic geometry",
      "Algebraic number theory",
      "Algebraic topology",
      "Alhazen",
      "Altitude (triangle)",
      "American Mathematical Monthly",
      "Analytic geometry",
      "Analytic number theory",
      "Angle",
      "Apollonius of Perga",
      "Applied mathematics",
      "ArXiv (identifier)",
      "Archimedes",
      "Area",
      "Area of a circle",
      "Arithmetic",
      "Arithmetic geometry",
      "Aryabhata",
      "Axiom",
      "Axiomatic projective space",
      "Baudhayana",
      "Before Common Era",
      "Beniamino Segre",
      "Benz plane",
      "Bernhard Riemann",
      "Binomial coefficient",
      "Blaise Pascal",
      "Block design",
      "Brahmagupta",
      "Bruck–Ryser theorem",
      "Burkard Polster",
      "Calculus",
      "Cambridge University Press",
      "Carl Friedrich Gauss",
      "Category theory",
      "Christiaan Huygens",
      "Circle",
      "Circumference",
      "Collineation",
      "Collineation group",
      "Combinatorics",
      "Combinatorics of Finite Geometries",
      "Commutative algebra",
      "Complex analysis"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1 maint: postscript",
      "Category:Combinatorics",
      "Category:Finite geometry",
      "Category:Pages using sidebar with the child parameter",
      "Category:Short description is different from Wikidata",
      "Category:Webarchive template wayback links"
    ]
  },
  "Algebraic Combinatorics (journal)": {
    "title": "Algebraic Combinatorics (journal)",
    "url": "https://en.wikipedia.org/wiki/Algebraic_Combinatorics_(journal)",
    "summary": "Algebraic Combinatorics is a peer-reviewed diamond open access mathematical journal specializing in the field of algebraic combinatorics. Established in 2018, the journal is published by the Centre Mersenne. It is a member of the Free Journal Network.",
    "content": "Algebraic Combinatorics is a peer-reviewed diamond open access mathematical journal specializing in the field of algebraic combinatorics. Established in 2018, the journal is published by the Centre Mersenne. It is a member of the Free Journal Network.\n\nHistory\nThe journal was established in 2018, when the editorial board of the Springer Science+Business Media Journal of Algebraic Combinatorics resigned to protest the publisher's high prices and limited accessibility. The board criticized Springer for \"double-dipping\", that is, charging large subscription fees to libraries in addition to high fees for authors who wished to make their publications open access.\n\nOperations\nAlgebraic Combinatorics operates on a diamond open access model, in which publication costs are underwritten by voluntary contributions from universities, foundations, and other organizations. Authors do not pay submission fees or article processing charges. All content is published under a Creative Commons license.\nThe journal's editors-in-chief are Akihiro Munemasa (Tohoku University), Satoshi Murai (Waseda University), Hendrik Van Maldeghem (Ghent University), Brendon Rhoades (University of California, San Diego), and David Speyer (University of Michigan).\n\nAbstracting and indexing\nThe journal is abstracted and indexed in the Web of Science, Directory of Open Access Journals, Scopus, Mathematical Reviews, and zbMath.\n\nReferences\nExternal links\nOfficial website",
    "links": [
      "Academic publishing",
      "Algebraic combinatorics",
      "Article processing charge",
      "Centre Mersenne",
      "Copyright",
      "Creative Commons license",
      "Diamond open access",
      "Directory of Open Access Journals",
      "Editor-in-chief",
      "Editorial board",
      "Editors-in-chief",
      "Free Journal Network",
      "Ghent University",
      "ISO 4",
      "ISSN (identifier)",
      "Inside Higher Ed",
      "Journal of Algebraic Combinatorics",
      "London School of Economics and Political Science",
      "Mathematical Reviews",
      "Mathematical journal",
      "Mathematics",
      "OCLC (identifier)",
      "Open access",
      "Outline of academic disciplines",
      "Peer-reviewed",
      "Periodical literature",
      "Scopus",
      "Springer Science+Business Media",
      "Timothy Gowers",
      "Tohoku University",
      "University of California, San Diego",
      "University of Michigan",
      "Waseda University",
      "Web of Science",
      "ZbMath",
      "Wikipedia:WikiProject Academic Journals/Bluebook journals"
    ],
    "categories": [
      "Category:5 times per year journals",
      "Category:Academic journals established in 2018",
      "Category:Articles with short description",
      "Category:Bimonthly journals (infobox)",
      "Category:Combinatorics journals",
      "Category:Creative Commons Attribution-licensed journals",
      "Category:Open access journals",
      "Category:Open access journals (infobox)",
      "Category:Short description matches Wikidata"
    ]
  },
  "Association scheme": {
    "title": "Association scheme",
    "url": "https://en.wikipedia.org/wiki/Association_scheme",
    "summary": "The theory of association schemes arose in statistics, in the theory of experimental design for the analysis of variance. In mathematics, association schemes belong to both algebra and combinatorics. In algebraic combinatorics, association schemes provide a unified approach to many topics, for example combinatorial designs and the theory of error-correcting codes. In algebra, the theory of association schemes generalizes the character theory of linear representations of groups.",
    "content": "The theory of association schemes arose in statistics, in the theory of experimental design for the analysis of variance. In mathematics, association schemes belong to both algebra and combinatorics. In algebraic combinatorics, association schemes provide a unified approach to many topics, for example combinatorial designs and the theory of error-correcting codes. In algebra, the theory of association schemes generalizes the character theory of linear representations of groups.\n\nDefinition\nAn n-class association scheme consists of a set X  together with a partition S of X × X into n + 1 binary relations, R0, R1, ..., Rn which satisfy:\n\n  \n    \n      \n        \n          R\n          \n            0\n          \n        \n        =\n        {\n        (\n        x\n        ,\n        x\n        )\n        :\n        x\n        ∈\n        X\n        }\n      \n    \n    {\\displaystyle R_{0}=\\{(x,x):x\\in X\\}}\n  \n; it is called the identity relation.\nDefining \n  \n    \n      \n        \n          R\n          \n            ∗\n          \n        \n        :=\n        {\n        (\n        x\n        ,\n        y\n        )\n        :\n        (\n        y\n        ,\n        x\n        )\n        ∈\n        R\n        }\n      \n    \n    {\\displaystyle R^{*}:=\\{(x,y):(y,x)\\in R\\}}\n  \n, if R in S, then R* in S.\nIf \n  \n    \n      \n        (\n        x\n        ,\n        y\n        )\n        ∈\n        \n          R\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle (x,y)\\in R_{k}}\n  \n, the number of \n  \n    \n      \n        z\n        ∈\n        X\n      \n    \n    {\\displaystyle z\\in X}\n  \n such that \n  \n    \n      \n        (\n        x\n        ,\n        z\n        )\n        ∈\n        \n          R\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle (x,z)\\in R_{i}}\n  \n and \n  \n    \n      \n        (\n        z\n        ,\n        y\n        )\n        ∈\n        \n          R\n          \n            j\n          \n        \n      \n    \n    {\\displaystyle (z,y)\\in R_{j}}\n  \n is a constant \n  \n    \n      \n        \n          p\n          \n            i\n            j\n          \n          \n            k\n          \n        \n      \n    \n    {\\displaystyle p_{ij}^{k}}\n  \n depending on \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n, \n  \n    \n      \n        j\n      \n    \n    {\\displaystyle j}\n  \n, \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n but not on the particular choice of \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n and \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n.\nAn association scheme is commutative if \n  \n    \n      \n        \n          p\n          \n            i\n            j\n          \n          \n            k\n          \n        \n        =\n        \n          p\n          \n            j\n            i\n          \n          \n            k\n          \n        \n      \n    \n    {\\displaystyle p_{ij}^{k}=p_{ji}^{k}}\n  \n for all \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n, \n  \n    \n      \n        j\n      \n    \n    {\\displaystyle j}\n  \n and \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n. Most authors assume this property.\nNote, however, that while the notion of an association scheme generalizes the notion of a group, the notion of a commutative association scheme only generalizes the notion of a commutative group.\nA symmetric association scheme is one in which each \n  \n    \n      \n        \n          R\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle R_{i}}\n  \n is a symmetric relation. That is:\n\nif (x, y)  ∈ Ri, then (y, x) ∈ Ri. (Or equivalently, R* = R.)\nEvery symmetric association scheme is commutative.\nTwo points x and y are called i th associates if \n  \n    \n      \n        (\n        x\n        ,\n        y\n        )\n        ∈\n        \n          R\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle (x,y)\\in R_{i}}\n  \n. The definition states that if x and y are i th associates then so are y and x. Every pair of points are i th associates for exactly one \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n. Each point is its own zeroth associate while distinct points are never zeroth associates. If x and y are k th associates then the number of points \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n  \n which are both i th associates of \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n and j th associates of \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n is a constant \n  \n    \n      \n        \n          p\n          \n            i\n            j\n          \n          \n            k\n          \n        \n      \n    \n    {\\displaystyle p_{ij}^{k}}\n  \n.\n\nGraph interpretation and adjacency matrices\nA symmetric association scheme can be visualized as a complete graph with labeled edges. The graph has \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n  \n vertices, one for each point of \n  \n    \n      \n        X\n      \n    \n    {\\displayst",
    "links": [
      "(0,1)-matrix",
      "Abelian group",
      "Accelerated failure time model",
      "Actuarial science",
      "Adaptive clinical trial",
      "Adjacency matrix",
      "Adjacency relation",
      "Akaike information criterion",
      "Algebra",
      "Algebraic combinatorics",
      "Analysis of covariance",
      "Analysis of variance",
      "Anderson–Darling test",
      "Annals of Mathematical Statistics",
      "Anne Penfold Street",
      "Arithmetic mean",
      "Arithmetic–geometric mean",
      "Associative algebra",
      "Asymptotic theory (statistics)",
      "Autocorrelation",
      "Autoregressive conditional heteroskedasticity",
      "Autoregressive–moving-average model",
      "Average absolute deviation",
      "Bar chart",
      "Bayes estimator",
      "Bayes factor",
      "Bayesian experimental design",
      "Bayesian inference",
      "Bayesian information criterion",
      "Bayesian linear regression",
      "Bayesian probability",
      "Bias of an estimator",
      "Binary relation",
      "Binomial regression",
      "Bioinformatics",
      "Biostatistics",
      "Biplot",
      "Blind experiment",
      "Block design",
      "Blocking (statistics)",
      "Bootstrapping (statistics)",
      "Bose–Mesner algebra",
      "Box plot",
      "Box–Behnken design",
      "Box–Jenkins method",
      "Breusch–Godfrey test",
      "Canonical correlation",
      "Cartography",
      "Categorical variable",
      "Census"
    ],
    "categories": [
      "Category:Algebraic combinatorics",
      "Category:All articles covered by WikiProject Wikify",
      "Category:All pages needing cleanup",
      "Category:Analysis of variance",
      "Category:Articles covered by WikiProject Wikify from March 2013",
      "Category:Design of experiments",
      "Category:Representation theory",
      "Category:Use dmy dates from December 2020",
      "Category:Wikipedia introduction cleanup from March 2013"
    ]
  },
  "Combinatorial commutative algebra": {
    "title": "Combinatorial commutative algebra",
    "url": "https://en.wikipedia.org/wiki/Combinatorial_commutative_algebra",
    "summary": "Combinatorial commutative algebra is a relatively new, rapidly developing mathematical discipline. As the name implies, it lies at the intersection of two more established fields, commutative algebra and combinatorics, and frequently uses methods of one to address problems arising in the other. Less obviously, polyhedral geometry plays a significant role.\nOne of the milestones in the development of the subject was Richard Stanley's 1975 proof of the Upper Bound Conjecture for simplicial spheres, which was based on earlier work of Melvin Hochster and Gerald Reisner. While the problem can be formulated purely in geometric terms, the methods of the proof drew on commutative algebra techniques.\nA signature theorem in combinatorial commutative algebra is the characterization of h-vectors of simplicial polytopes conjectured in 1970 by Peter McMullen. Known as the g-theorem, it was proved in 1979 by Stanley (necessity of the conditions, algebraic argument) and by Louis Billera and Carl W. Lee",
    "content": "Combinatorial commutative algebra is a relatively new, rapidly developing mathematical discipline. As the name implies, it lies at the intersection of two more established fields, commutative algebra and combinatorics, and frequently uses methods of one to address problems arising in the other. Less obviously, polyhedral geometry plays a significant role.\nOne of the milestones in the development of the subject was Richard Stanley's 1975 proof of the Upper Bound Conjecture for simplicial spheres, which was based on earlier work of Melvin Hochster and Gerald Reisner. While the problem can be formulated purely in geometric terms, the methods of the proof drew on commutative algebra techniques.\nA signature theorem in combinatorial commutative algebra is the characterization of h-vectors of simplicial polytopes conjectured in 1970 by Peter McMullen. Known as the g-theorem, it was proved in 1979 by Stanley (necessity of the conditions, algebraic argument) and by Louis Billera and Carl W. Lee (sufficiency, combinatorial and geometric construction). A major open question was the extension of this characterization from simplicial polytopes to simplicial spheres, the g-conjecture, which was resolved in 2018 by Karim Adiprasito.\n\nImportant notions of combinatorial commutative algebra\nSquare-free monomial ideal in a polynomial ring and Stanley–Reisner ring of a simplicial complex.\nCohen–Macaulay rings.\nMonomial ring, closely related to an affine semigroup ring and to the coordinate ring of an affine toric variety.\nAlgebra with a straightening law. There are several versions of those, including Hodge algebras of Corrado de Concini,  David Eisenbud, and Claudio Procesi.\n\nSee also\nAlgebraic combinatorics\nPolyhedral combinatorics\nZero-divisor graph\n\nReferences\nA foundational paper on Stanley–Reisner complexes by one of the pioneers of the theory:\n\nHochster, Melvin (1977). \"Cohen–Macaulay rings, combinatorics, and simplicial complexes\". Ring Theory II: Proceedings of the Second Oklahoma Conference. Lecture Notes in Pure and Applied Mathematics. Vol. 26. Dekker. pp. 171–223. ISBN 0-8247-6575-3. OCLC 610144046. Zbl 0351.13009.\nThe first book is a classic (first edition published in 1983):\n\nStanley, Richard (1996). Combinatorics and commutative algebra. Progress in Mathematics. Vol. 41 (2nd ed.). Birkhäuser. ISBN 0-8176-3836-9. Zbl 0838.13008.\nVery influential, and well written, textbook-monograph:\n\nBruns, Winfried; Herzog, Jürgen (1993). Cohen–Macaulay rings. Vol. 39. Cambridge Studies in Advanced Mathematics: Cambridge University Press. ISBN 0-521-41068-1. OCLC 802912314. Zbl 0788.13005.\nAdditional reading:\n\nVillarreal, Rafael H. (2001). Monomial algebras. Monographs and Textbooks in Pure and Applied Mathematics. Vol. 238. Marcel Dekker. ISBN 0-8247-0524-6. Zbl 1002.13010.\nHibi, Takayuki (1992). Algebraic combinatorics on convex polytopes. Glebe, Australia: Carslaw Publications. ISBN 1875399046. OCLC 29023080.\nSturmfels, Bernd (1996). Gröbner bases and convex polytopes. University Lecture Series. Vol. 8. American Mathematical Society. ISBN 0-8218-0487-1. OCLC 907364245. Zbl 0856.13020.\nBruns, Winfried; Gubeladze, Joseph (2009). Polytopes, Rings, and K-Theory. Springer Monographs in Mathematics. Springer. doi:10.1007/b105283. ISBN 978-0-387-76355-2. Zbl 1168.13001.\nA recent addition to the growing literature in the field, contains exposition of current research topics:\n\nMiller, Ezra; Sturmfels, Bernd (2005). Combinatorial commutative algebra. Graduate Texts in Mathematics. Vol. 227. Springer. ISBN 0-387-22356-8. Zbl 1066.13001.\nHerzog, Jürgen; Hibi, Takayuki (2011). Monomial Ideals. Graduate Texts in Mathematics. Vol. 260. Springer. ISBN 978-0-85729-106-6. Zbl 1206.13001.\nHerzog, Jürgen; Hibi, Takayuki; Oshugi, Hidefumi (2018). Binomial Ideals. Graduate Texts in Mathematics. Vol. 279. Springer. ISBN 978-3-319-95349-6. Zbl 1403.13004.",
    "links": [
      "Affine variety",
      "Algebraic combinatorics",
      "Bernd Sturmfels",
      "Claudio Procesi",
      "Cohen–Macaulay ring",
      "Combinatorics",
      "Commutative algebra",
      "Conjecture",
      "Convex polytope",
      "Coordinate ring",
      "Corrado de Concini",
      "David Eisenbud",
      "Doi (identifier)",
      "G-conjecture",
      "G-theorem",
      "Graduate Texts in Mathematics",
      "H-vector",
      "ISBN (identifier)",
      "Karim Adiprasito",
      "Louis Billera",
      "Mathematical proof",
      "Mathematics",
      "Melvin Hochster",
      "Monomial ideal",
      "Monomial ring",
      "Necessity and sufficiency",
      "OCLC (identifier)",
      "Open problem",
      "Peter McMullen",
      "Polyhedral combinatorics",
      "Polynomial ring",
      "Richard P. Stanley",
      "Simplicial complex",
      "Simplicial polytope",
      "Simplicial sphere",
      "Stanley–Reisner ring",
      "Theorem",
      "Toric variety",
      "Upper Bound Conjecture",
      "Zbl (identifier)",
      "Zero-divisor graph"
    ],
    "categories": [
      "Category:Algebraic combinatorics",
      "Category:Algebraic geometry",
      "Category:Commutative algebra"
    ]
  },
  "Combinatorial optimization": {
    "title": "Combinatorial optimization",
    "url": "https://en.wikipedia.org/wiki/Combinatorial_optimization",
    "summary": "Combinatorial optimization is a subfield of mathematical optimization   that consists of finding an optimal object from a finite set of objects, where the set of feasible solutions is discrete or can be reduced to a discrete set. Typical combinatorial optimization problems are the travelling salesman problem (\"TSP\"), the minimum spanning tree problem (\"MST\"), and the knapsack problem. In many such problems, such as the ones previously mentioned, exhaustive search is not tractable, and so specialized algorithms that quickly rule out large parts of the search space or approximation algorithms must be resorted to instead.\nCombinatorial optimization is related to operations research, algorithm theory, and computational complexity theory. It has important applications in several fields, including artificial intelligence, machine learning, auction theory, software engineering, VLSI, applied mathematics and theoretical computer science.",
    "content": "Combinatorial optimization is a subfield of mathematical optimization   that consists of finding an optimal object from a finite set of objects, where the set of feasible solutions is discrete or can be reduced to a discrete set. Typical combinatorial optimization problems are the travelling salesman problem (\"TSP\"), the minimum spanning tree problem (\"MST\"), and the knapsack problem. In many such problems, such as the ones previously mentioned, exhaustive search is not tractable, and so specialized algorithms that quickly rule out large parts of the search space or approximation algorithms must be resorted to instead.\nCombinatorial optimization is related to operations research, algorithm theory, and computational complexity theory. It has important applications in several fields, including artificial intelligence, machine learning, auction theory, software engineering, VLSI, applied mathematics and theoretical computer science.\n\nApplications\nBasic applications of combinatorial optimization include, but are not limited to:\n\nLogistics\nSupply chain optimization\nDeveloping the best airline network of spokes and destinations\nDeciding which taxis in a fleet to route to pick up fares\nDetermining the optimal way to deliver packages\nAllocating jobs to people optimally\nDesigning water distribution networks\nEarth science problems (e.g. reservoir flow-rates)\n\nMethods\nThere is a large amount of literature on polynomial-time algorithms for certain special classes of discrete optimization. A considerable amount of it is unified by the theory of linear programming. Some examples of combinatorial optimization problems that are covered by this framework are shortest paths and shortest-path trees, flows and circulations, spanning trees, matching, and matroid problems.\nFor NP-complete discrete optimization problems, current research literature includes the following topics:\n\npolynomial-time exactly solvable special cases of the problem at hand (e.g. fixed-parameter tractable problems)\nalgorithms that perform well on \"random\" instances (e.g. for the traveling salesman problem)\napproximation algorithms that run in polynomial time and find a solution that is close to optimal\nparameterized approximation algorithms that run in FPT time and find a solution close to the optimum\nsolving real-world instances that arise in practice and do not necessarily exhibit the worst-case behavior of in NP-complete problems (e.g. real-world TSP instances with tens of thousands of nodes).\nCombinatorial optimization problems can be viewed as searching for the best element of some set of discrete items; therefore, in principle, any sort of search algorithm or metaheuristic can be used to solve them. Widely applicable approaches include branch-and-bound (an exact algorithm which can be stopped at any point in time to serve as heuristic), branch-and-cut (uses linear optimisation to generate bounds), dynamic programming (a recursive solution construction with limited search window) and tabu search (a greedy-type swapping algorithm). However, generic search algorithms are not guaranteed to find an optimal solution first, nor are they guaranteed to run quickly (in polynomial time). Since some discrete optimization problems are NP-complete, such as the traveling salesman (decision) problem, this is expected unless P=NP.\nFor each combinatorial optimization problem, there is a corresponding decision problem that asks whether there is a feasible solution for some particular measure \n  \n    \n      \n        \n          m\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle m_{0}}\n  \n. For example, if there is a graph \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n which contains vertices \n  \n    \n      \n        u\n      \n    \n    {\\displaystyle u}\n  \n and \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n  \n, an optimization problem might be \"find a path from \n  \n    \n      \n        u\n      \n    \n    {\\displaystyle u}\n  \n to \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n  \n that uses the fewest edges\". This problem might have an answer of, say, 4. A corresponding decision problem would be \"is there a path from \n  \n    \n      \n        u\n      \n    \n    {\\displaystyle u}\n  \n to \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n  \n that uses 10 or fewer edges?\" This problem can be answered with a simple 'yes' or 'no'.\nThe field of approximation algorithms deals with algorithms to find near-optimal solutions to hard problems. The usual decision version is then an inadequate definition of the problem since it only specifies acceptable solutions. Even though we could introduce suitable decision problems, the problem is then more naturally characterized as an optimization problem.\n\nNP optimization problem\nAn NP-optimization problem (NPO) is a combinatorial optimization problem with the following additional conditions. Note that the below referred polynomials are functions of the size of the respec",
    "links": [
      "Active-set method",
      "Affine scaling",
      "Alexander Schrijver",
      "Algorithm",
      "Applied mathematics",
      "Approximation algorithm",
      "ArXiv (identifier)",
      "Artificial intelligence",
      "Assignment problem",
      "Auction theory",
      "Augmented Lagrangian method",
      "Barrier function",
      "Bellman–Ford algorithm",
      "Berndt–Hall–Hall–Hausman algorithm",
      "Bibcode (identifier)",
      "Bikas K Chakrabarti",
      "Bin packing problem",
      "Borůvka's algorithm",
      "Bounded set",
      "Branch and bound",
      "Branch and cut",
      "Broyden–Fletcher–Goldfarb–Shanno algorithm",
      "Candidate solution",
      "Chinese postman problem",
      "CiteSeerX (identifier)",
      "Clique problem",
      "Closure problem",
      "Comparison of optimization software",
      "Computational complexity theory",
      "Constraint composite graph",
      "Constraint satisfaction problem",
      "Convex minimization",
      "Convex optimization",
      "Criss-cross algorithm",
      "Cutting-plane method",
      "Cutting stock problem",
      "Davidon–Fletcher–Powell formula",
      "Decidable language",
      "Decision problem",
      "Dijkstra's algorithm",
      "Dinic's algorithm",
      "Discrete set",
      "Doi (identifier)",
      "Dominating set",
      "Dynamic programming",
      "Earth science",
      "Edmonds–Karp algorithm",
      "Ellipsoid method",
      "Eugene Lawler",
      "Evolutionary algorithm"
    ],
    "categories": [
      "Category:All Wikipedia articles needing clarification",
      "Category:All articles with specifically marked weasel-worded phrases",
      "Category:Articles with short description",
      "Category:Articles with specifically marked weasel-worded phrases from December 2021",
      "Category:Combinatorial optimization",
      "Category:Commons category link from Wikidata",
      "Category:Computational complexity theory",
      "Category:Dynamic lists",
      "Category:Short description is different from Wikidata",
      "Category:Theoretical computer science"
    ]
  },
  "Complement graph": {
    "title": "Complement graph",
    "url": "https://en.wikipedia.org/wiki/Complement_graph",
    "summary": "In the mathematical field of graph theory, the complement or inverse of a graph G is a graph H on the same vertices such that two distinct vertices of H are adjacent if and only if they are not adjacent in G. That is, to generate the complement of a graph, one fills in all the missing edges required to form a complete graph, and removes all the edges that were previously there. \nThe complement is not the set complement of the graph; only the edges are complemented.",
    "content": "In the mathematical field of graph theory, the complement or inverse of a graph G is a graph H on the same vertices such that two distinct vertices of H are adjacent if and only if they are not adjacent in G. That is, to generate the complement of a graph, one fills in all the missing edges required to form a complete graph, and removes all the edges that were previously there. \nThe complement is not the set complement of the graph; only the edges are complemented.\n\nDefinition\nLet G = (V, E) be a simple graph and let K consist of all 2-element subsets of V. Then H = (V, K \\ E) is the complement of G, where K \\ E is the relative complement of E in K. For directed graphs, the complement can be defined in the same way, as a directed graph on the same vertex set, using the set of all 2-element ordered pairs of V in place of the set K in the formula above. In terms of the adjacency matrix A of the graph, if Q is the adjacency matrix of the complete graph of the same number of vertices (i.e. all entries are unity except the diagonal entries which are zero), then the adjacency matrix of the complement of A is Q-A.\nThe complement is not defined for multigraphs. In graphs that allow self-loops (but not multiple adjacencies) the complement of G may be defined by adding a self-loop to every vertex that does not have one in G, and otherwise using the same formula as above. This operation is, however, different from the one for simple graphs, since applying it to a graph with no self-loops would result in a graph with self-loops on all vertices.\n\nApplications and examples\nSeveral graph-theoretic concepts are related to each other via complementation:\n\nThe complement of an edgeless graph is a complete graph and vice versa.\nAny induced subgraph of the complement graph of a graph G is the complement of the corresponding induced subgraph in G.\nAn independent set in a graph is a clique in the complement graph and vice versa. This is a special case of the previous two properties, as an independent set is an edgeless induced subgraph and a clique is a complete induced subgraph.\nThe automorphism group of a graph is the automorphism group of its complement.\nThe complement of every triangle-free graph is a claw-free graph, although the reverse is not true.\n\nSelf-complementary graphs and graph classes\nA self-complementary graph is a graph that is isomorphic to its own complement. Examples include the four-vertex path graph and five-vertex cycle graph.  There is no known characterization of self-complementary graphs.\nSeveral classes of graphs are self-complementary, in the sense that the complement of any graph in one of these classes is another graph in the same class.\n\nPerfect graphs are the graphs in which, for every induced subgraph, the chromatic number equals the size of the maximum clique. The fact that the complement of a perfect graph is also perfect is the perfect graph theorem of László Lovász.\nCographs are defined as the graphs that can be built up from single vertices by disjoint union and complementation operations. They form a self-complementary family of graphs: the complement of any cograph is another different cograph. For cographs of more than one vertex, exactly one graph in each complementary pair is connected, and one equivalent definition of cographs is that each of their connected induced subgraphs has a disconnected complement. Another, self-complementary definition is that they are the graphs with no induced subgraph in the form of a four-vertex path.\nAnother self-complementary class of graphs is the class of split graphs, the graphs in which the vertices can be partitioned into a clique and an independent set. The same partition gives an independent set and a clique in the complement graph.\nThe threshold graphs are the graphs formed by repeatedly adding either an independent vertex (one with no neighbors) or a universal vertex (adjacent to all previously-added vertices). These two operations are complementary and they generate a self-complementary class of graphs.\n\nAlgorithmic aspects\nIn the analysis of algorithms on graphs, the distinction between a graph and its complement is an important one, because a sparse graph (one with a small number of edges compared to the number of pairs of vertices) will in general not have a sparse complement, and so an algorithm that takes time proportional to the number of edges on a given graph may take a much larger amount of time if the same algorithm is run on an explicit representation of the complement graph. Therefore, researchers have studied algorithms that perform standard graph computations on the complement of an input graph, using an implicit graph representation that does not require the explicit construction of the complement graph. In particular, it is possible to simulate either depth-first search or breadth-first search on the complement graph, in an amount of time that is linear in the size of the given graph, even when the complement graph may have a mu",
    "links": [
      "Adjacency matrix",
      "Analysis of algorithms",
      "Breadth-first search",
      "Chromatic number",
      "Claw-free graph",
      "Clique (graph theory)",
      "Cograph",
      "Complement (set theory)",
      "Complete graph",
      "Cycle graph",
      "Depth-first search",
      "Derek Corneil",
      "Directed graph",
      "Discrete Applied Mathematics",
      "Discrete Mathematics (journal)",
      "Disjoint union",
      "Doi (identifier)",
      "Edge (graph theory)",
      "Edgeless graph",
      "Graph (discrete mathematics)",
      "Graph automorphism",
      "Graph isomorphism",
      "Graph theory",
      "ISBN (identifier)",
      "If and only if",
      "Implicit graph",
      "Independent set (graph theory)",
      "Induced subgraph",
      "Information Processing Letters",
      "John Adrian Bondy",
      "Loop (graph theory)",
      "László Lovász",
      "MR (identifier)",
      "Maria Chudnovsky",
      "Martin Charles Golumbic",
      "Mathematical",
      "Multigraph",
      "Ordered pair",
      "Path graph",
      "Paul Seymour (mathematician)",
      "Perfect graph",
      "Perfect graph theorem",
      "Petersen graph",
      "Relative complement",
      "Self-complementary graph",
      "Shang-Hua Teng",
      "Simple graph",
      "Sparse graph",
      "Split graph",
      "Springer Science+Business Media"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Graph operations",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Complete graph": {
    "title": "Complete graph",
    "url": "https://en.wikipedia.org/wiki/Complete_graph",
    "summary": "In the mathematical field of graph theory, a complete graph is a simple undirected graph in which every pair of distinct vertices is connected by a unique edge.  A complete digraph is a directed graph in which every pair of distinct vertices is connected by a pair of unique edges (one in each direction).\nGraph theory itself is typically dated as beginning with Leonhard Euler's 1736 work on the Seven Bridges of Königsberg. However, drawings of complete graphs, with their vertices placed on the points of a regular polygon, had already appeared in the 13th century, in the work of Ramon Llull. Such a drawing is sometimes referred to as a mystic rose.",
    "content": "In the mathematical field of graph theory, a complete graph is a simple undirected graph in which every pair of distinct vertices is connected by a unique edge.  A complete digraph is a directed graph in which every pair of distinct vertices is connected by a pair of unique edges (one in each direction).\nGraph theory itself is typically dated as beginning with Leonhard Euler's 1736 work on the Seven Bridges of Königsberg. However, drawings of complete graphs, with their vertices placed on the points of a regular polygon, had already appeared in the 13th century, in the work of Ramon Llull. Such a drawing is sometimes referred to as a mystic rose.\n\nProperties\nThe complete graph on n vertices is denoted by Kn. Some sources claim that the letter K in this notation stands for the German word komplett, but the German name for a complete graph, vollständiger Graph, does not contain the letter K, and other sources state that the notation honors the contributions of Kazimierz Kuratowski to graph theory.\nKn has n(n − 1)/2 edges (a triangular number), and is a regular graph of degree n − 1.  All complete graphs are their own maximal cliques. They are maximally connected as the only vertex cut which disconnects the graph is the complete set of vertices. The complement graph of a complete graph is an empty graph.\nIf the edges of a complete graph are each given an orientation, the resulting directed graph is called a tournament.\nKn can be decomposed into n trees Ti such that Ti has i vertices. Ringel's conjecture asks if the complete graph K2n+1 can be decomposed into copies of any tree with n edges. This is known to be true for sufficiently large n.\nThe number of all distinct paths between a specific pair of vertices in Kn+2 is given by\n\n  \n    \n      \n        \n          w\n          \n            n\n            +\n            2\n          \n        \n        =\n        n\n        !\n        \n          e\n          \n            n\n          \n        \n        =\n        ⌊\n        e\n        n\n        !\n        ⌋\n        ,\n      \n    \n    {\\displaystyle w_{n+2}=n!e_{n}=\\lfloor en!\\rfloor ,}\n  \n\nwhere e refers to Euler's constant, and\n\n  \n    \n      \n        \n          e\n          \n            n\n          \n        \n        =\n        \n          ∑\n          \n            k\n            =\n            0\n          \n          \n            n\n          \n        \n        \n          \n            1\n            \n              k\n              !\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle e_{n}=\\sum _{k=0}^{n}{\\frac {1}{k!}}.}\n  \n\nThe number of matchings of the complete graphs are given by the telephone numbers\n\n1, 1, 2, 4, 10, 26, 76, 232, 764, 2620, 9496, 35696, 140152, 568504, 2390480, 10349536, 46206736, ... (sequence A000085 in the OEIS).\nThese numbers give the largest possible value of the Hosoya index for an n-vertex graph. The number of perfect matchings of the complete graph Kn (with n even) is given by the double factorial (n − 1)!!.\nThe crossing numbers up to K27 are known, with K28 requiring either 7233 or 7234 crossings. Further values are collected by the Rectilinear Crossing Number project. Rectilinear Crossing numbers for Kn are \n\n0, 0, 0, 0, 1, 3, 9, 19, 36, 62, 102, 153, 229, 324, 447, 603, 798, 1029, 1318, 1657, 2055, 2528, 3077, 3699, 4430, 5250, 6180, ... (sequence A014540 in the OEIS).\n\nGeometry and topology\nA complete graph with n nodes is the edge graph of an (n − 1)-dimensional simplex.  Geometrically K3 forms the edge set of a triangle, K4 a tetrahedron, etc.  The Császár polyhedron, a nonconvex polyhedron with the topology of a torus, has the complete graph K7 as its skeleton. Every neighborly polytope in four or more dimensions also has a complete skeleton.\nK1 through K4 are all planar graphs.  However, every planar drawing of a complete graph with five or more vertices must contain a crossing, and the nonplanar complete graph K5 plays a key role in the characterizations of planar graphs: by Kuratowski's theorem, a graph is planar if and only if it contains neither K5 nor the complete bipartite graph K3,3 as a subdivision, and by Wagner's theorem the same result holds for graph minors in place of subdivisions.  As part of the Petersen family, K6 plays a similar role as one of the forbidden minors for linkless embedding. In other words, and as Conway and Gordon proved, every embedding of K6 into three-dimensional space is intrinsically linked, with at least one pair of linked triangles.  Conway and Gordon also showed that any three-dimensional embedding of K7 contains a Hamiltonian cycle that is embedded in space as a nontrivial knot.\n\nExamples\nComplete graphs on \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n vertices, for \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n between 1 and 12, are shown below along with the numbers of edges:\n\nSee also\nFully connected network, in computer networking\nComplete bipartite graph (or biclique), a special bipartite graph where",
    "links": [
      "ArXiv (identifier)",
      "Bibcode (identifier)",
      "Bipartite graph",
      "Cameron Gordon (mathematician)",
      "Chromatic index",
      "Chromatic number",
      "CiteSeerX (identifier)",
      "Clique (graph theory)",
      "Complement graph",
      "Complete bipartite graph",
      "Connectivity (graph theory)",
      "Crossing number (graph theory)",
      "Csaszar polyhedron",
      "Császár polyhedron",
      "David Gries",
      "Degree (graph theory)",
      "Diameter (graph theory)",
      "Dimension",
      "Directed graph",
      "Distance (graph theory)",
      "Doi (identifier)",
      "Donald Knuth",
      "Double factorial",
      "E (mathematical constant)",
      "Edge-transitive graph",
      "Edge (graph theory)",
      "Empty graph",
      "Eric W. Weisstein",
      "Forbidden minor",
      "Fred B. Schneider",
      "Girth (graph theory)",
      "Graph automorphism",
      "Graph drawing",
      "Graph minor",
      "Graph of a polytope",
      "Graph theory",
      "Hamiltonian cycle",
      "Hosoya index",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "Integral graph",
      "J. H. Conway",
      "Journal of Computational Biology",
      "Journal of Graph Theory",
      "Journal of the European Mathematical Society",
      "Kazimierz Kuratowski",
      "Knot (mathematics)",
      "Kuratowski's theorem",
      "Leonhard Euler",
      "Linkless embedding"
    ],
    "categories": [
      "Category:Articles containing German-language text",
      "Category:Articles with short description",
      "Category:Commons category link from Wikidata",
      "Category:Parametric families of graphs",
      "Category:Regular graphs",
      "Category:Short description is different from Wikidata",
      "Category:Webarchive template wayback links"
    ]
  },
  "Euclidean geometry": {
    "title": "Euclidean geometry",
    "url": "https://en.wikipedia.org/wiki/Euclidean_geometry",
    "summary": "Euclidean geometry is a mathematical system attributed to Euclid, an ancient Greek mathematician, which he described in his textbook on geometry, Elements. Euclid's approach consists in assuming a small set of intuitively appealing axioms (postulates) and deducing many other propositions (theorems) from these. One of those is the parallel postulate which relates to parallel lines on a Euclidean plane. Although many of Euclid's results had been stated earlier, Euclid was the first to organize these propositions into a logical system in which each result is proved from axioms and previously proved theorems.\nThe Elements begins with plane geometry, still taught in secondary school (high school) as the first axiomatic system and the first examples of mathematical proofs. It goes on to the solid geometry of three dimensions. Much of the Elements states results of what are now called algebra and number theory, explained in geometrical language.\nFor more than two thousand years, the adjective",
    "content": "Euclidean geometry is a mathematical system attributed to Euclid, an ancient Greek mathematician, which he described in his textbook on geometry, Elements. Euclid's approach consists in assuming a small set of intuitively appealing axioms (postulates) and deducing many other propositions (theorems) from these. One of those is the parallel postulate which relates to parallel lines on a Euclidean plane. Although many of Euclid's results had been stated earlier, Euclid was the first to organize these propositions into a logical system in which each result is proved from axioms and previously proved theorems.\nThe Elements begins with plane geometry, still taught in secondary school (high school) as the first axiomatic system and the first examples of mathematical proofs. It goes on to the solid geometry of three dimensions. Much of the Elements states results of what are now called algebra and number theory, explained in geometrical language.\nFor more than two thousand years, the adjective \"Euclidean\" was unnecessary because\nEuclid's axioms seemed so intuitively obvious (with the possible exception of the parallel postulate) that theorems proved from them were deemed absolutely true, and thus no other sorts of geometry were possible. Today, however, many other self-consistent non-Euclidean geometries are known, the first ones having been discovered in the early 19th century. An implication of Albert Einstein's theory of general relativity is that physical space itself is not Euclidean, and Euclidean space is a good approximation for it only over short distances (relative to the strength of the gravitational field).\nEuclidean geometry is an example of synthetic geometry, in that it proceeds logically from axioms describing basic properties of geometric objects such as points and lines, to propositions about those objects. This is in contrast to analytic geometry, introduced almost 2,000 years later by René Descartes, which uses coordinates to express geometric properties by means of algebraic formulas.\n\nThe Elements\nThe Elements is mainly a systematization of earlier knowledge of geometry. Its improvement over earlier treatments was rapidly recognized, with the result that there was little interest in preserving the earlier ones, and they are now nearly all lost.\nThere are 13 books in the Elements:\nBooks I–IV and VI discuss plane geometry. Many results about plane figures are proved, for example, \"In any triangle, two angles taken together in any manner are less than two right angles.\" (Book I proposition 17) and the Pythagorean theorem \"In right-angled triangles the square on the side subtending the right angle is equal to the squares on the sides containing the right angle.\" (Book I, proposition 47)\nBooks V and VII–X deal with number theory, with numbers treated geometrically as lengths of line segments or areas of surface regions. Notions such as prime numbers and rational and irrational numbers are introduced. It is proved that there are infinitely many prime numbers.\nBooks XI–XIII concern solid geometry. A typical result is the 1:3 ratio between the volume of a cone and a cylinder with the same height and base. The platonic solids are constructed.\n\nAxioms\nEuclidean geometry is an axiomatic system, in which all theorems (\"true statements\") are derived from a small number of simple axioms. Until the advent of non-Euclidean geometry, these axioms were considered to be obviously true in the physical world, so that all the theorems would be equally true. However, Euclid's reasoning from assumptions to conclusions remains valid independently from the physical reality.\nNear the beginning of the first book of the Elements, Euclid gives five postulates (axioms) for plane geometry, stated in terms of constructions (as translated by Thomas Heath):\n\nLet the following be postulated:\nTo draw a straight line from any point to any point.\nTo produce (extend) a finite straight line continuously in a straight line.\nTo describe a circle with any centre and distance (radius).\nThat all right angles are equal to one another.\n[The parallel postulate]: That, if a straight line falling on two straight lines makes the interior angles on the same side less than two right angles, the two straight lines, if produced indefinitely, meet on that side on which the angles are less than two right angles.\nAlthough Euclid explicitly only asserts the existence of the constructed objects, in his reasoning he also implicitly assumes them to be unique.\nThe Elements also include the following five \"common notions\":\n\nThings that are equal to the same thing are also equal to one another (the transitive property of a Euclidean relation).\nIf equals are added to equals, then the wholes are equal (Addition property of equality).\nIf equals are subtracted from equals, then the differences are equal (subtraction property of equality).\nThings that coincide with one another are equal to one another (reflexive property).\nThe whole is greater than the part.\nMode",
    "links": [
      "120-cell",
      "16-cell",
      "24-cell",
      "3-sphere",
      "30-gon",
      "4-dimensional space",
      "5-cell",
      "600-cell",
      "8-cell",
      "A History of Greek Mathematics",
      "Abraham Robinson",
      "Absolute geometry",
      "Abstract algebra",
      "Aerodynamics",
      "Affine geometry",
      "Ahmes",
      "Aircraft",
      "Airfoil",
      "Airplane",
      "Albert Einstein",
      "Alessandro Padoa",
      "Alfred Tarski",
      "Algebra",
      "Algebraic formula",
      "Algebraic geometry",
      "Algebraic number theory",
      "Algebraic topology",
      "Alhazen",
      "Almagest",
      "Altitude (triangle)",
      "Anabelian geometry",
      "Analytic geometry",
      "Analytic number theory",
      "Anaxagoras",
      "Ancient Egyptian mathematics",
      "Ancient Greek astronomy",
      "Ancient Greek mathematics",
      "Angle",
      "Angle bisector theorem",
      "Angle trisection",
      "Antenna (radio)",
      "Antenna array",
      "Antenna types",
      "Anthemius of Tralles",
      "Apollonian circles",
      "Apollonian gasket",
      "Apollonius's theorem",
      "Apollonius of Perga",
      "Applied mathematics",
      "Archimedean property"
    ],
    "categories": [
      "Category:All articles to be expanded",
      "Category:Articles to be expanded from June 2010",
      "Category:Articles with short description",
      "Category:CS1 errors: ISBN date",
      "Category:Commons category link from Wikidata",
      "Category:Elementary geometry",
      "Category:Euclidean geometry",
      "Category:Greek inventions",
      "Category:Pages using sidebar with the child parameter",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Finite set": {
    "title": "Finite set",
    "url": "https://en.wikipedia.org/wiki/Finite_set",
    "summary": "In mathematics, particularly set theory, a finite set is a set that has a finite number of elements.  Informally, a finite set is a set which one could in principle count and finish counting. For example,\n\nis a finite set with five elements. The number of elements of a finite set is a natural number (possibly zero) and is called the cardinality (or the cardinal number) of the set. A set that is not a finite set is called an infinite set. For example, the set of all positive integers is infinite:\n\nFinite sets are particularly important in combinatorics, the mathematical study of counting. Many arguments involving finite sets rely on the pigeonhole principle, which states that there cannot exist an injective function from a larger finite set to a smaller finite set.",
    "content": "In mathematics, particularly set theory, a finite set is a set that has a finite number of elements.  Informally, a finite set is a set which one could in principle count and finish counting. For example,\n\nis a finite set with five elements. The number of elements of a finite set is a natural number (possibly zero) and is called the cardinality (or the cardinal number) of the set. A set that is not a finite set is called an infinite set. For example, the set of all positive integers is infinite:\n\nFinite sets are particularly important in combinatorics, the mathematical study of counting. Many arguments involving finite sets rely on the pigeonhole principle, which states that there cannot exist an injective function from a larger finite set to a smaller finite set.\n\nDefinition and terminology\nThe natural numbers are defined abstractly by the Peano axioms, and may be constructed set-theoreticaly (for example, by the Von Neumann ordinals). Then, formally, a set \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n is called finite if there exists a bijection\n\nfor some natural number \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n, analogous to counting its elements. If \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n is empty, this is vacuously satisfied for \n  \n    \n      \n        n\n        =\n        0\n      \n    \n    {\\displaystyle n=0}\n  \n with the empty function. The number \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n is the set's cardinality, denoted as \n  \n    \n      \n        \n          |\n        \n        S\n        \n          |\n        \n      \n    \n    {\\displaystyle |S|}\n  \n.\nIf a nonempty set is finite, its elements may be written in a sequence:\n\nIf n≥2, then there are multiple such sequences.\nIn combinatorics, a finite set with \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n elements is sometimes called an \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n-set and a subset with \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n elements is called a \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n-subset.  For example, the set \n  \n    \n      \n        {\n        5\n        ,\n        6\n        ,\n        7\n        }\n      \n    \n    {\\displaystyle \\{5,6,7\\}}\n  \n is a 3-set – a finite set with three elements – and \n  \n    \n      \n        {\n        6\n        ,\n        7\n        }\n      \n    \n    {\\displaystyle \\{6,7\\}}\n  \n is a 2-subset of it.\nThis notation \n  \n    \n      \n        {\n        1\n        ,\n        ⋯\n        ,\n        n\n        }\n      \n    \n    {\\displaystyle \\{1,\\cdots ,n\\}}\n  \n, may be defined recursively as\n\n  \n    \n      \n        {\n        1\n        ,\n        ⋯\n        ,\n        n\n        }\n        =\n        \n          {\n          \n            \n              \n                \n                  ∅\n                  \n                     (the empty set)\n                  \n                \n                \n                  \n                    if\n                  \n                \n                \n                  n\n                  =\n                  0\n                \n              \n              \n                \n                  {\n                  1\n                  ,\n                  ⋯\n                  ,\n                  n\n                  −\n                  1\n                  }\n                  ∪\n                  {\n                  n\n                  }\n                \n                \n                  \n                    if\n                  \n                \n                \n                  n\n                  ≥\n                  1\n                \n              \n            \n          \n          \n        \n      \n    \n    {\\displaystyle \\{1,\\cdots ,n\\}=\\left\\{{\\begin{array}{lll}\\varnothing {\\text{ (the empty set)}}&{\\text{if}}&n=0\\\\\\{1,\\cdots ,n-1\\}\\cup \\{n\\}&{\\text{if}}&n\\geq 1\\\\\\end{array}}\\right.}\n\nBasic properties\nAny proper subset of a finite set \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n is finite and has fewer elements than S itself.  As a consequence, there cannot exist a bijection between a finite set S and a proper subset of S.  Any set with this property is called Dedekind-finite.  Using the standard ZFC axioms for set theory, every Dedekind-finite set is also finite, but this implication cannot be proved in ZF (Zermelo–Fraenkel axioms without the axiom of choice) alone.\nThe axiom of countable choice, a weak version of the axiom of choice, is sufficient to prove this equivalence.\nAny injective function between two finite sets of the same cardinality is also a surjective function (a surjection). Similarly, any surjection between two finite sets of the same cardinality is also an injection.\nThe union of two finite sets is finite, with\n\nIn fact, by the inclusion–exclusion principle:\n\nMore generally, the union of any finite number of finite sets is finite.  The Cartesian product of finite sets is also finite, with:\n\nSimilarly",
    "links": [
      "Abraham Fraenkel",
      "Abstract logic",
      "Ackermann set theory",
      "Addison-Wesley",
      "Aleph number",
      "Alfred North Whitehead",
      "Alfred Tarski",
      "Algebraic logic",
      "Almost",
      "Alphabet (formal languages)",
      "Alternative set theory",
      "Amorphous set",
      "Argument",
      "Arity",
      "Atomic formula",
      "Atomic sentence",
      "Automata theory",
      "Automated theorem proving",
      "Axiom",
      "Axiom of adjunction",
      "Axiom of choice",
      "Axiom of constructibility",
      "Axiom of countable choice",
      "Axiom of dependent choice",
      "Axiom of determinacy",
      "Axiom of extensionality",
      "Axiom of global choice",
      "Axiom of infinity",
      "Axiom of limitation of size",
      "Axiom of pairing",
      "Axiom of power set",
      "Axiom of projective determinacy",
      "Axiom of regularity",
      "Axiom of union",
      "Axiom schema",
      "Axiom schema of replacement",
      "Axiom schema of specification",
      "Axiomatic system",
      "Axiomatization of Boolean algebras",
      "Azriel Lévy",
      "Banach–Tarski paradox",
      "Bertrand Russell",
      "Bijection",
      "Binary operation",
      "Boolean algebra",
      "Boolean algebras canonically defined",
      "Boolean function",
      "Burali-Forti paradox",
      "Cantor's diagonal argument",
      "Cantor's paradox"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Basic concepts in set theory",
      "Category:CS1 errors: ISBN date",
      "Category:CS1 maint: multiple names: authors list",
      "Category:Cardinal numbers",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Galois geometry": {
    "title": "Galois geometry",
    "url": "https://en.wikipedia.org/wiki/Galois_geometry",
    "summary": "Galois geometry (named after the 19th-century French mathematician Évariste Galois) is the branch of finite geometry that is concerned with algebraic and analytic geometry over a finite field (or Galois field). More narrowly, a Galois geometry may be defined as a projective space over a finite field.\nObjects of study include affine and projective spaces over finite fields and various structures that are contained in them. In particular, arcs, ovals, hyperovals, unitals, blocking sets, ovoids, caps, spreads and all finite analogues of structures found in non-finite geometries. Vector spaces defined over finite fields play a significant role, especially in construction methods.",
    "content": "Galois geometry (named after the 19th-century French mathematician Évariste Galois) is the branch of finite geometry that is concerned with algebraic and analytic geometry over a finite field (or Galois field). More narrowly, a Galois geometry may be defined as a projective space over a finite field.\nObjects of study include affine and projective spaces over finite fields and various structures that are contained in them. In particular, arcs, ovals, hyperovals, unitals, blocking sets, ovoids, caps, spreads and all finite analogues of structures found in non-finite geometries. Vector spaces defined over finite fields play a significant role, especially in construction methods.\n\nProjective spaces over finite fields\nNotation\nAlthough the generic notation of projective geometry is sometimes used, it is more common to denote projective spaces over finite fields by PG(n, q), where n is the \"geometric\" dimension (see below), and q is the order of the finite field (or Galois field) GF(q), which must be an integer that is a prime or prime power.\nThe geometric dimension in the above notation refers to the system whereby lines are 1-dimensional, planes are 2-dimensional, points are 0-dimensional, etc. The modifier, sometimes the term projective instead of geometric is used, is necessary since this concept of dimension differs from the concept used for vector spaces (that is, the number of elements in a basis). Normally having two different concepts with the same name does not cause much difficulty in separate areas due to context, but in this subject both vector spaces and projective spaces play important roles and confusion is highly likely. The vector space concept is at times referred to as the algebraic dimension.\n\nConstruction\nLet V = V(n + 1, q) denote the vector space of (algebraic) dimension n + 1 defined over the finite field GF(q). The projective space PG(n, q) consists of all the positive (algebraic) dimensional vector subspaces of V. An alternate way to view the construction is to define the points of PG(n, q) as the equivalence classes of the non-zero vectors of V under the equivalence relation whereby two vectors are equivalent if one is a scalar multiple of the other. Subspaces are then built up from the points using the definition of linear independence of sets of points.\n\nSubspaces\nA vector subspace of algebraic dimension d + 1 of V is a (projective) subspace of PG(n, q) of geometric dimension d. The projective subspaces are given common geometric names; points, lines, planes and solids are the 0,1,2 and 3-dimensional subspaces, respectively. The whole space is an n-dimensional subspace and an (n − 1)-dimensional subspace is called a hyperplane (or prime).\nThe number of vector subspaces of algebraic dimension d in vector space V(n, q) is given by the Gaussian binomial coefficient,\n\n  \n    \n      \n        \n          \n            [\n            \n              \n                \n                  \n                    n\n                  \n                \n                \n                  \n                    d\n                  \n                \n              \n            \n            ]\n          \n          \n            q\n          \n        \n        =\n        \n          \n            \n              (\n              \n                q\n                \n                  n\n                \n              \n              −\n              1\n              )\n              (\n              \n                q\n                \n                  n\n                \n              \n              −\n              q\n              )\n              ⋯\n              (\n              \n                q\n                \n                  n\n                \n              \n              −\n              \n                q\n                \n                  d\n                  −\n                  1\n                \n              \n              )\n            \n            \n              (\n              \n                q\n                \n                  d\n                \n              \n              −\n              1\n              )\n              (\n              \n                q\n                \n                  d\n                \n              \n              −\n              q\n              )\n              ⋯\n              (\n              \n                q\n                \n                  d\n                \n              \n              −\n              \n                q\n                \n                  d\n                  −\n                  1\n                \n              \n              )\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle \\left[{\\begin{matrix}n\\\\d\\end{matrix}}\\right]_{q}={\\frac {(q^{n}-1)(q^{n}-q)\\cdots (q^{n}-q^{d-1})}{(q^{d}-1)(q^{d}-q)\\cdots (q^{d}-q^{d-1})}}.}\n  \n\nTherefore, the number of k dimensional projective subspaces in PG(n, q) is given by\n\n  \n    \n      \n        \n          \n            [\n            \n              \n                \n                  \n                    n\n      ",
    "links": [
      "Affine space",
      "Algebraic geometry",
      "Analytic geometry",
      "Annals of Mathematics",
      "ArXiv (identifier)",
      "Arc (projective geometry)",
      "Beniamino Segre",
      "Blocking set",
      "Characteristic (field)",
      "Characteristic 0",
      "Conic section",
      "Doi (identifier)",
      "Equivalence class",
      "Equivalence relation",
      "Fano plane",
      "Finite field",
      "Finite geometry",
      "GF(2)",
      "Gaussian binomial coefficient",
      "Gino Fano",
      "Homogeneous coordinates",
      "Hyperoval",
      "ISBN (identifier)",
      "Incidence geometry",
      "International Mathematical Congress",
      "J. A. Thas",
      "J. W. P. Hirschfeld",
      "Kirkman's schoolgirl problem",
      "Klein quadric",
      "Linear independence",
      "Mathematician",
      "Oval (projective plane)",
      "Ovoid",
      "Oxford University Press",
      "PG(3,2)",
      "Plücker coordinates",
      "Projective geometry",
      "Projective harmonic conjugate",
      "Projective plane",
      "Projective space",
      "Scalar multiple",
      "Segre's theorem",
      "Skew lines",
      "Unital (geometry)",
      "Vector space",
      "Évariste Galois",
      "Template:Citation",
      "Category:CS1 maint: postscript"
    ],
    "categories": [
      "Category:Algebraic geometry",
      "Category:Analytic geometry",
      "Category:Articles with short description",
      "Category:CS1 maint: postscript",
      "Category:Finite fields",
      "Category:Finite geometry",
      "Category:Short description matches Wikidata"
    ]
  },
  "General linear group": {
    "title": "General linear group",
    "url": "https://en.wikipedia.org/wiki/General_linear_group",
    "summary": "In mathematics, the general linear group of degree \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n is the set of \n  \n    \n      \n        n\n        ×\n        n\n      \n    \n    {\\displaystyle n\\times n}\n  \n invertible matrices, together with the operation of ordinary matrix multiplication. This forms a group, because the product of two invertible matrices is again invertible, and the inverse of an invertible matrix is invertible, with the identity matrix as the identity element of the group. The group is so named because the columns (and also the rows) of an invertible matrix are linearly independent, hence the vectors/points they define are in general linear position, and matrices in the general linear group take points in general linear position to points in general linear position.\nTo be more precise, it is necessary to specify what kind of objects may appear in the entries of the matrix. For example, the general linear group over \n  \n    \n      \n        \n          R\n ",
    "content": "In mathematics, the general linear group of degree \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n is the set of \n  \n    \n      \n        n\n        ×\n        n\n      \n    \n    {\\displaystyle n\\times n}\n  \n invertible matrices, together with the operation of ordinary matrix multiplication. This forms a group, because the product of two invertible matrices is again invertible, and the inverse of an invertible matrix is invertible, with the identity matrix as the identity element of the group. The group is so named because the columns (and also the rows) of an invertible matrix are linearly independent, hence the vectors/points they define are in general linear position, and matrices in the general linear group take points in general linear position to points in general linear position.\nTo be more precise, it is necessary to specify what kind of objects may appear in the entries of the matrix. For example, the general linear group over \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n (the set of real numbers) is the group of \n  \n    \n      \n        n\n        ×\n        n\n      \n    \n    {\\displaystyle n\\times n}\n  \n invertible matrices of real numbers, and is denoted by \n  \n    \n      \n        \n          GL\n          \n            n\n          \n        \n        ⁡\n        (\n        \n          R\n        \n        )\n      \n    \n    {\\displaystyle \\operatorname {GL} _{n}(\\mathbb {R} )}\n  \n or \n  \n    \n      \n        GL\n        ⁡\n        (\n        n\n        ,\n        \n          R\n        \n        )\n      \n    \n    {\\displaystyle \\operatorname {GL} (n,\\mathbb {R} )}\n  \n.\nMore generally, the general linear group of degree \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n over any field \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n (such as the complex numbers), or a ring \n  \n    \n      \n        R\n      \n    \n    {\\displaystyle R}\n  \n (such as the ring of integers), is the set of \n  \n    \n      \n        n\n        ×\n        n\n      \n    \n    {\\displaystyle n\\times n}\n  \n invertible matrices with entries from \n  \n    \n      \n        F\n      \n    \n    {\\displaystyle F}\n  \n (or \n  \n    \n      \n        R\n      \n    \n    {\\displaystyle R}\n  \n), again with matrix multiplication as the group operation. Typical notation is \n  \n    \n      \n        GL\n        ⁡\n        (\n        n\n        ,\n        F\n        )\n      \n    \n    {\\displaystyle \\operatorname {GL} (n,F)}\n  \n or \n  \n    \n      \n        \n          GL\n          \n            n\n          \n        \n        ⁡\n        (\n        F\n        )\n      \n    \n    {\\displaystyle \\operatorname {GL} _{n}(F)}\n  \n, or simply \n  \n    \n      \n        GL\n        ⁡\n        (\n        n\n        )\n      \n    \n    {\\displaystyle \\operatorname {GL} (n)}\n  \n if the field is understood.\nMore generally still, the general linear group of a vector space \n  \n    \n      \n        GL\n        ⁡\n        (\n        V\n        )\n      \n    \n    {\\displaystyle \\operatorname {GL} (V)}\n  \n is the automorphism group, not necessarily written as matrices.\nThe special linear group, written \n  \n    \n      \n        SL\n        ⁡\n        (\n        n\n        ,\n        F\n        )\n      \n    \n    {\\displaystyle \\operatorname {SL} (n,F)}\n  \n or \n  \n    \n      \n        \n          SL\n          \n            n\n          \n        \n        ⁡\n        (\n        F\n        )\n      \n    \n    {\\displaystyle \\operatorname {SL} _{n}(F)}\n  \n, is the subgroup of \n  \n    \n      \n        GL\n        ⁡\n        (\n        n\n        ,\n        F\n        )\n      \n    \n    {\\displaystyle \\operatorname {GL} (n,F)}\n  \n consisting of matrices with a determinant of 1.\nThe group \n  \n    \n      \n        GL\n        ⁡\n        (\n        n\n        ,\n        F\n        )\n      \n    \n    {\\displaystyle \\operatorname {GL} (n,F)}\n  \n and its subgroups are often called linear groups or matrix groups (the automorphism group \n  \n    \n      \n        GL\n        ⁡\n        (\n        V\n        )\n      \n    \n    {\\displaystyle \\operatorname {GL} (V)}\n  \n is a linear group but not a matrix group). These groups are important in the theory of group representations, and also arise in the study of spatial symmetries and symmetries of vector spaces in general, as well as the study of polynomials. The modular group may be realised as a quotient of the special linear group \n  \n    \n      \n        SL\n        ⁡\n        (\n        2\n        ,\n        \n          Z\n        \n        )\n      \n    \n    {\\displaystyle \\operatorname {SL} (2,\\mathbb {Z} )}\n  \n.\nIf \n  \n    \n      \n        n\n        ≥\n        2\n      \n    \n    {\\displaystyle n\\geq 2}\n  \n, then the group \n  \n    \n      \n        GL\n        ⁡\n        (\n        n\n        ,\n        F\n        )\n      \n    \n    {\\displaystyle \\operatorname {GL} (n,F)}\n  \n is not abelian.\n\nGeneral linear group of a vector space\nIf \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n is a vector space over the field \n  \n    \n      \n        F\n      \n    \n  ",
    "links": [
      "Abelian group",
      "Abelian variety",
      "Additive group",
      "Adjoint representation",
      "Affine Lie algebra",
      "Affine group",
      "Affine space",
      "Affine transformation",
      "Algebraic K-theory",
      "Algebraic group",
      "Algebraic structure",
      "Algebraic variety",
      "Alternating form",
      "Alternating group",
      "Arithmetic group",
      "Armand Borel",
      "Automorphism",
      "Automorphism group",
      "Basis (linear algebra)",
      "Betti number",
      "Bijective",
      "Bilinear form",
      "Block matrix",
      "Borel–Weil–Bott theorem",
      "Bott periodicity",
      "Cartan subalgebra",
      "Cauchy's theorem (group theory)",
      "Cayley table",
      "Center of a group",
      "Circle group",
      "Classical group",
      "Classification of finite simple groups",
      "Claude Chevalley",
      "Coarsest topology",
      "Collineation group",
      "Commutative ring",
      "Commutator",
      "Compact Lie algebra",
      "Compact space",
      "Complex number",
      "Complexification (Lie group)",
      "Conformal group",
      "Connected space",
      "Continuous function (topology)",
      "Continuous group",
      "Cyclic group",
      "Derived group",
      "Determinant",
      "Diagonal matrix",
      "Diffeomorphism"
    ],
    "categories": [
      "Category:Abstract algebra",
      "Category:All Wikipedia articles written in American English",
      "Category:All articles to be expanded",
      "Category:Articles to be expanded from April 2015",
      "Category:Articles with short description",
      "Category:CS1 maint: postscript",
      "Category:Lie groups",
      "Category:Linear algebra",
      "Category:Linear algebraic groups",
      "Category:Pages that use a deprecated format of the math tags"
    ]
  },
  "Group action (mathematics)": {
    "title": "Group action",
    "url": "https://en.wikipedia.org/wiki/Group_action",
    "summary": "In mathematics, a group action of a group \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n on a set \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n is a group homomorphism from \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n to some group (under function composition) of functions from \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n to itself. It is said that \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n acts on \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n.\nMany sets of transformations form a group under function composition; for example, the rotations around a point in the plane. It is often useful to consider the group as an abstract group, and to say that one has a group action of the abstract group that consists of performing the transformations of the group of transformations. The reason for distinguishing the group from the transformations is that, generally, a group of transformati",
    "content": "In mathematics, a group action of a group \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n on a set \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n is a group homomorphism from \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n to some group (under function composition) of functions from \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n to itself. It is said that \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n acts on \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n.\nMany sets of transformations form a group under function composition; for example, the rotations around a point in the plane. It is often useful to consider the group as an abstract group, and to say that one has a group action of the abstract group that consists of performing the transformations of the group of transformations. The reason for distinguishing the group from the transformations is that, generally, a group of transformations of a structure acts also on various related structures; for example, the above rotation group also acts on triangles by transforming triangles into triangles.\nIf a group acts on a structure, it will usually also act on objects built from that structure. For example, the group of Euclidean isometries acts on Euclidean space and also on the figures drawn in it; in particular, it acts on the set of all triangles. Similarly, the group of symmetries of a polyhedron acts on the vertices, the edges, and the faces of the polyhedron.\nA group action on a vector space is called a representation of the group. In the case of a finite-dimensional vector space, it allows one to identify many groups with subgroups of the general linear group \n  \n    \n      \n        GL\n        ⁡\n        (\n        n\n        ,\n        K\n        )\n      \n    \n    {\\displaystyle \\operatorname {GL} (n,K)}\n  \n, the group of the invertible matrices of dimension \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n over a field \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n.\nThe symmetric group \n  \n    \n      \n        \n          S\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle S_{n}}\n  \n acts on any set with \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n elements by permuting the elements of the set. Although the group of all permutations of a set depends formally on the set, the concept of group action allows one to consider a single group for studying the permutations of all sets with the same cardinality.\n\nDefinition\nLeft group action\nIf \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n is a group with identity element \n  \n    \n      \n        e\n      \n    \n    {\\displaystyle e}\n  \n, and \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n is a set, then a (left) group action \n  \n    \n      \n        α\n      \n    \n    {\\displaystyle \\alpha }\n  \n of \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n on X is a function\n\n  \n    \n      \n        α\n        :\n        G\n        ×\n        X\n        →\n        X\n      \n    \n    {\\displaystyle \\alpha :G\\times X\\to X}\n  \n\nthat satisfies the following two axioms:\n\nfor all g and h in G and all x in \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n.\nThe group \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n is then said to act on \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n (from the left). A set \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n  \n together with an action of \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n is called a (left) \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n-set.\nIt can be notationally convenient to curry the action \n  \n    \n      \n        α\n      \n    \n    {\\displaystyle \\alpha }\n  \n, so that, instead, one has a collection of transformations αg : X → X, with one transformation αg for each group element g ∈ G. The identity and compatibility relations then read\n\n  \n    \n      \n        \n          α\n          \n            e\n          \n        \n        (\n        x\n        )\n        =\n        x\n      \n    \n    {\\displaystyle \\alpha _{e}(x)=x}\n  \n\nand\n\n  \n    \n      \n        \n          α\n          \n            g\n          \n        \n        (\n        \n          α\n          \n            h\n          \n        \n        (\n        x\n        )\n        )\n        =\n        (\n        \n          α\n          \n            g\n          \n        \n        ∘\n        \n          α\n          \n            h\n          \n        \n        )\n        (\n        x\n        )\n        =\n        \n          α\n          \n            g\n            h\n          \n        \n        (\n        x\n        )\n      \n    \n    {\\displaystyle \\alpha _{g}(\\alpha _{h}(x))=(\\alpha _{g}\\circ \\alpha _{h})(x)=\\alpha _{gh}(x)}\n  \n\nThe second axiom states that the function composition is compatible with the group multiplication; they form a commutative diagram. This",
    "links": [
      "2-transitive group",
      "Abelian group",
      "Abelian variety",
      "Abstract group",
      "Additive group",
      "Affine group",
      "Affine space",
      "Algebraic group",
      "Algebraic structure",
      "Algebraic variety",
      "Allen Hatcher",
      "Alternating group",
      "Arithmetic group",
      "Automorphism",
      "Axioms",
      "Bijection",
      "Burnside's lemma",
      "Burnside ring",
      "Cardinality",
      "Cartesian product",
      "Category (mathematics)",
      "Category of sets",
      "Category of vector spaces",
      "Category theory",
      "Cauchy's theorem (group theory)",
      "Cayley's theorem",
      "Circle group",
      "Classical mechanics",
      "Classification of finite simple groups",
      "Cocompact group action",
      "Commutative diagram",
      "Commutative ring",
      "Compact space",
      "Compound of five tetrahedra",
      "Conformal group",
      "Conjugacy class",
      "Continuous group",
      "Continuous group action",
      "Coordinate space",
      "Coset",
      "Covering space",
      "Cross ratio",
      "Cubical graph",
      "Currying",
      "Cyclic group",
      "Deck transformation",
      "Degree of a permutation group",
      "Derived functor",
      "Diffeomorphism",
      "Differentiable manifold"
    ],
    "categories": [
      "Category:All accuracy disputes",
      "Category:All articles with unsourced statements",
      "Category:Articles with disputed statements from March 2015",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from May 2023",
      "Category:Group actions",
      "Category:Group theory",
      "Category:Representation theory of groups",
      "Category:Short description is different from Wikidata",
      "Category:Symmetry"
    ]
  },
  "Group character": {
    "title": "Character theory",
    "url": "https://en.wikipedia.org/wiki/Character_theory",
    "summary": "In mathematics, more specifically in group theory, the character of a group representation is a function on the group that associates to each group element the trace of the corresponding matrix. The character carries the essential information about the representation in a more condensed form. Georg Frobenius initially developed representation theory of finite groups entirely based on the characters, and without any explicit matrix realization of representations themselves. This is possible because a complex representation of a finite group is determined (up to isomorphism) by its character. The situation with representations over a field of positive characteristic, so-called \"modular representations\", is more delicate, but Richard Brauer developed a powerful theory of characters in this case as well. Many deep theorems on the structure of finite groups use characters of modular representations.",
    "content": "In mathematics, more specifically in group theory, the character of a group representation is a function on the group that associates to each group element the trace of the corresponding matrix. The character carries the essential information about the representation in a more condensed form. Georg Frobenius initially developed representation theory of finite groups entirely based on the characters, and without any explicit matrix realization of representations themselves. This is possible because a complex representation of a finite group is determined (up to isomorphism) by its character. The situation with representations over a field of positive characteristic, so-called \"modular representations\", is more delicate, but Richard Brauer developed a powerful theory of characters in this case as well. Many deep theorems on the structure of finite groups use characters of modular representations.\n\nApplications\nCharacters of irreducible representations encode many important properties of a group and can thus be used to study its structure. Character theory is an essential tool in the classification of finite simple groups. Close to half of the proof of the Feit–Thompson theorem involves intricate calculations with character values. Easier, but still essential, results that use character theory include Burnside's theorem (a purely group-theoretic proof of Burnside's theorem has since been found, but that proof came over half a century after Burnside's original proof), and a theorem of Richard Brauer and Michio Suzuki stating that a finite simple group cannot have a generalized quaternion group as its Sylow 2-subgroup.\n\nDefinitions\nLet V be a finite-dimensional vector space over a field F and let ρ : G → GL(V) be a representation of a group G on V. The character of ρ is the function χρ : G → F given by\n\n  \n    \n      \n        \n          χ\n          \n            ρ\n          \n        \n        (\n        g\n        )\n        =\n        Tr\n        ⁡\n        (\n        ρ\n        (\n        g\n        )\n        )\n      \n    \n    {\\displaystyle \\chi _{\\rho }(g)=\\operatorname {Tr} (\\rho (g))}\n  \n\nwhere Tr is the trace.\nA character χρ is called irreducible or simple if ρ is an irreducible representation.  The degree of the character χ is the dimension of ρ; in characteristic zero this is equal to the value χ(1). A character of degree 1 is called linear. When G is finite and F has characteristic zero, the kernel of the character χρ is the normal subgroup:\n\n  \n    \n      \n        ker\n        ⁡\n        \n          χ\n          \n            ρ\n          \n        \n        :=\n        \n          {\n          \n            g\n            ∈\n            G\n            ∣\n            \n              χ\n              \n                ρ\n              \n            \n            (\n            g\n            )\n            =\n            \n              χ\n              \n                ρ\n              \n            \n            (\n            1\n            )\n          \n          }\n        \n        ,\n      \n    \n    {\\displaystyle \\ker \\chi _{\\rho }:=\\left\\lbrace g\\in G\\mid \\chi _{\\rho }(g)=\\chi _{\\rho }(1)\\right\\rbrace ,}\n  \n\nwhich is precisely the kernel of the representation ρ. However, the character is not a group homomorphism in general.\n\nProperties\nCharacters are class functions, that is, they each take a constant value on a given conjugacy class. More precisely, the set of irreducible characters of a given group G into a field F form a basis of the F-vector space of all class functions G → F.\nIsomorphic representations have the same characters. Over a field of characteristic 0, two representations are isomorphic if and only if they have the same character.\nIf a representation is the direct sum of subrepresentations, then the corresponding character is the sum of the characters of those subrepresentations.\nIf a character of the finite group G is restricted to a subgroup H, then the result is also a character of H.\nEvery character value χ(g) is a sum of n m-th roots of unity, where n is the degree (that is, the dimension of the associated vector space) of the representation with character χ and m is the order of g. In particular, when F = C, every such character value is an algebraic integer.\nIf F = C and χ is irreducible, then  \n  \n    \n      \n        [\n        G\n        :\n        \n          C\n          \n            G\n          \n        \n        (\n        x\n        )\n        ]\n        \n          \n            \n              χ\n              (\n              x\n              )\n            \n            \n              χ\n              (\n              1\n              )\n            \n          \n        \n      \n    \n    {\\displaystyle [G:C_{G}(x)]{\\frac {\\chi (x)}{\\chi (1)}}}\n  \n is an algebraic integer for all x in G.\nIf F is algebraically closed and char(F) does not divide the order of G, then the number of irreducible characters of G is equal to the number of conjugacy classes of G. Furthermore, in this case, the degrees of the irreducible characters are divisors",
    "links": [
      "A. H. Clifford",
      "Abelian group",
      "Absolute value",
      "Algebraic character",
      "Algebraic integer",
      "Algebraically closed",
      "Association scheme",
      "Basis (linear algebra)",
      "Burnside's theorem",
      "Centralizer",
      "Character (mathematics)",
      "Character group",
      "Character table",
      "Characteristic (algebra)",
      "Characteristic of a ring",
      "Class function",
      "Classification of finite simple groups",
      "Clifford theory",
      "Commutator subgroup",
      "Complex conjugate",
      "Complex number",
      "Conjugacy class",
      "Conjugate transpose",
      "Coset",
      "Cyclic group",
      "Dihedral group",
      "Dimension (vector space)",
      "Dimension of a representation",
      "Direct sum of representations",
      "Dirichlet character",
      "Disjoint union",
      "Doi (identifier)",
      "E. C. Dade",
      "Emil Artin",
      "Exterior algebra",
      "Feit–Thompson theorem",
      "Ferdinand Georg Frobenius",
      "Field (mathematics)",
      "Finite group",
      "Fourier analysis",
      "Frobenius formula",
      "Frobenius reciprocity",
      "Function (mathematics)",
      "G. Mackey",
      "Generalized quaternion group",
      "Georg Frobenius",
      "Graded dimension",
      "Graduate Texts in Mathematics",
      "Graham Higman",
      "Group (mathematics)"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Representation theory of groups",
      "Category:Short description is different from Wikidata",
      "Category:Wikipedia articles needing clarification from June 2011"
    ]
  },
  "Group representation": {
    "title": "Group representation",
    "url": "https://en.wikipedia.org/wiki/Group_representation",
    "summary": "In the mathematical field of representation theory, group representations describe abstract groups in terms of bijective linear transformations of a vector space to itself (i.e. vector space automorphisms); in particular, they can be used to represent group elements as invertible matrices so that the group operation can be represented by matrix multiplication.\nIn chemistry, a group representation can relate mathematical group elements to symmetric rotations and reflections of molecules.\nRepresentations of groups allow many group-theoretic problems to be reduced to problems in linear algebra. In physics, they describe how the symmetry group of a physical system affects the solutions of equations describing that system.\nThe term representation of a group is also used in a more general sense to mean any \"description\" of a group as a group of transformations of some mathematical object. More formally, a \"representation\" means a homomorphism from the group to the automorphism group of an ob",
    "content": "In the mathematical field of representation theory, group representations describe abstract groups in terms of bijective linear transformations of a vector space to itself (i.e. vector space automorphisms); in particular, they can be used to represent group elements as invertible matrices so that the group operation can be represented by matrix multiplication.\nIn chemistry, a group representation can relate mathematical group elements to symmetric rotations and reflections of molecules.\nRepresentations of groups allow many group-theoretic problems to be reduced to problems in linear algebra. In physics, they describe how the symmetry group of a physical system affects the solutions of equations describing that system.\nThe term representation of a group is also used in a more general sense to mean any \"description\" of a group as a group of transformations of some mathematical object. More formally, a \"representation\" means a homomorphism from the group to the automorphism group of an object. If the object is a vector space we have a linear representation. Some people use realization for the general notion and reserve the term representation for the special case of linear representations. The bulk of this article describes linear representation theory; see the last section for generalizations.\n\nBranches of group representation theory\nThe representation theory of groups divides into subtheories depending on the kind of group being represented. The various theories are quite different in detail, though some basic definitions and concepts are similar. The most important divisions are:\n\nFinite groups — Group representations are a very important tool in the study of finite groups. They also arise in the applications of finite group theory to crystallography and to geometry. If the field of scalars of the vector space has characteristic p, and if p divides the order of the group, then this is called modular representation theory; this special case has very different properties. See Representation theory of finite groups.\nCompact groups or locally compact groups — Many of the results of finite group representation theory are proved by averaging over the group. These proofs can be carried over to infinite groups by replacement of the average with an integral, provided that an acceptable notion of integral can be defined. This can be done for locally compact groups, using the Haar measure. The resulting theory is a central part of harmonic analysis. The Pontryagin duality describes the theory for commutative groups, as a generalised Fourier transform. See also: Peter–Weyl theorem.\nLie groups — Many important Lie groups are compact, so the results of compact representation theory apply to them. Other techniques specific to Lie groups are used as well. Most of the groups important in physics and chemistry are Lie groups, and their representation theory is crucial to the application of group theory in those fields. See Representations of Lie groups and Representations of Lie algebras.\nLinear algebraic groups (or more generally  affine group schemes) — These are the analogues of Lie groups, but over more general fields than just R or C. Although  linear algebraic groups have a classification that is very similar to that of Lie groups, and give rise to the same families of Lie algebras, their representations are rather different (and much less well understood). The analytic techniques used for studying Lie groups must be replaced by techniques from algebraic geometry, where the relatively weak Zariski topology causes many technical complications.\nNon-compact topological groups — The class of non-compact groups is too broad to construct any general representation theory, but specific special cases have been studied, sometimes using ad hoc techniques. The semisimple Lie groups have a deep theory, building on the compact case. The complementary solvable Lie groups cannot be classified in the same way. The general theory for Lie groups deals with semidirect products of the two types, by means of general results called Mackey theory, which is a generalization of Wigner's classification methods.\nRepresentation theory also depends heavily on the type of vector space on which the group acts. One distinguishes between finite-dimensional representations and infinite-dimensional ones. In the infinite-dimensional case, additional structures are important (e.g. whether or not the space is a Hilbert space, Banach space, etc.).\nOne must also consider the type of field over which the vector space is defined. The most important case is the field of complex numbers. The other important cases are the field of real numbers, finite fields, and fields of p-adic numbers. In general, algebraically closed fields are easier to handle than non-algebraically closed ones. The characteristic of the field is also significant; many theorems for finite groups depend on the characteristic of the field not dividing the order of the group.\n\nDefinitions\nA rep",
    "links": [
      "Affine representation",
      "Affine space",
      "Algebraic geometry",
      "Algebraically closed",
      "Automorphism",
      "Automorphism group",
      "Banach space",
      "Basis (linear algebra)",
      "Bijection",
      "Bijective",
      "Category (mathematics)",
      "Category of abelian groups",
      "Category of sets",
      "Category of topological spaces",
      "Category of vector spaces",
      "Character table",
      "Character theory",
      "Characteristic (algebra)",
      "Compact group",
      "Complex number",
      "Complex numbers",
      "Composite number",
      "Continuous function (topology)",
      "Crystallography",
      "Cyclic group",
      "Dihedral group",
      "Direct sum of groups",
      "Doi (identifier)",
      "Euclidean group",
      "Euclidean space",
      "Faithful representation",
      "Field (mathematics)",
      "Finite field",
      "Finite group",
      "Fourier transform",
      "Function (mathematics)",
      "Functor",
      "G-module",
      "General linear group",
      "Graduate Texts in Mathematics",
      "Group (mathematics)",
      "Group action (mathematics)",
      "Group homomorphism",
      "Group scheme",
      "Group theory",
      "Haar measure",
      "Harmonic analysis",
      "Hilbert space",
      "Homeomorphism",
      "Homomorphism"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Group theory",
      "Category:Representation theory",
      "Category:Representation theory of groups",
      "Category:Short description matches Wikidata"
    ]
  },
  "International Conference on Formal Power Series and Algebraic Combinatorics": {
    "title": "International Conference on Formal Power Series and Algebraic Combinatorics",
    "url": "https://en.wikipedia.org/wiki/International_Conference_on_Formal_Power_Series_and_Algebraic_Combinatorics",
    "summary": "The International Conference on Formal Power Series and Algebraic Combinatorics (FPSAC) is an annual academic conference in the areas of algebraic and enumerative combinatorics and their applications and relations with other areas of mathematics, physics, biology and computer science.",
    "content": "The International Conference on Formal Power Series and Algebraic Combinatorics (FPSAC) is an annual academic conference in the areas of algebraic and enumerative combinatorics and their applications and relations with other areas of mathematics, physics, biology and computer science.\n\nHistory\nFPSAC was first held in 1988 and has been held annually since 1990, typically in June or July.\nThe most recent conference in the series, FPSAC 2025, was held in July 2025 at Hokkaido University in Sapporo, Japan. The next conference in the series is slated to take place July 13-17, 2026 at the University of Washington in Seattle, Washington, USA.\nThe proceedings of conferences in the series have appeared variously as books published by the American Mathematical Society and Springer, and as issues in the journals Discrete Mathematics, Discrete Mathematics and Theoretical Computer Science, and Séminaire Lotharingien de Combinatoire.\nInvited speakers at previous FPSAC conferences include Fields Medalist June Huh, Shaw Prize and Wolf Prize recipient Noga Alon, and Steele Prize recipient Richard Stanley.\n\nReferences\nExternal links\nOfficial website",
    "links": [
      "Academic conference",
      "Algebraic combinatorics",
      "American Mathematical Society",
      "Discrete Mathematics (journal)",
      "Discrete Mathematics and Theoretical Computer Science",
      "Doi (identifier)",
      "Enumerative combinatorics",
      "Fields Medal",
      "Hokkaido University",
      "ISBN (identifier)",
      "June Huh",
      "Leroy P. Steele Prize",
      "Mathematics",
      "Noga Alon",
      "Richard P. Stanley",
      "Sapporo",
      "Seattle",
      "Shaw Prize",
      "Springer Science+Business Media",
      "Séminaire Lotharingien de Combinatoire",
      "University of Washington",
      "Wolf Prize in Mathematics",
      "Wikipedia:No original research",
      "Wikipedia:Stub",
      "Wikipedia:Verifiability",
      "Template:Math-org-stub",
      "Template talk:Math-org-stub",
      "Help:Maintenance template removal"
    ],
    "categories": [
      "Category:All articles lacking reliable references",
      "Category:All stub articles",
      "Category:Articles lacking reliable references from October 2023",
      "Category:Mathematics conferences",
      "Category:Mathematics organization stubs",
      "Category:Official website different in Wikidata and Wikipedia",
      "Category:Use dmy dates from October 2023"
    ]
  },
  "Georg Frobenius": {
    "title": "Ferdinand Georg Frobenius",
    "url": "https://en.wikipedia.org/wiki/Ferdinand_Georg_Frobenius",
    "summary": "Ferdinand Georg Frobenius (26 October 1849 – 3 August 1917) was a German mathematician, best known for his contributions to the theory of elliptic functions, differential equations, number theory, and to group theory. He is known for the famous determinantal identities, known as Frobenius–Stickelberger formulae, governing elliptic functions, and for developing the theory of biquadratic forms. He was also the first to introduce the notion of rational approximations of functions (nowadays known as Padé approximants), and gave the first full proof for the Cayley–Hamilton theorem. He also lent his name to certain differential-geometric objects in modern mathematical physics, known as Frobenius manifolds.",
    "content": "Ferdinand Georg Frobenius (26 October 1849 – 3 August 1917) was a German mathematician, best known for his contributions to the theory of elliptic functions, differential equations, number theory, and to group theory. He is known for the famous determinantal identities, known as Frobenius–Stickelberger formulae, governing elliptic functions, and for developing the theory of biquadratic forms. He was also the first to introduce the notion of rational approximations of functions (nowadays known as Padé approximants), and gave the first full proof for the Cayley–Hamilton theorem. He also lent his name to certain differential-geometric objects in modern mathematical physics, known as Frobenius manifolds.\n\nBiography\nFerdinand Georg Frobenius was born on 26 October 1849 in Charlottenburg, a suburb of Berlin, from parents Christian Ferdinand Frobenius, a Protestant parson, and Christine Elizabeth Friedrich. He entered the Joachimsthal Gymnasium in 1860 when he was nearly eleven.\nIn 1867, after graduating, he went to the University of Göttingen, where he began his university studies. However, he studied there for only one semester before returning to Berlin, where he attended lectures by Kronecker, Kummer and Karl Weierstrass. He received his doctorate (awarded with distinction) in 1870 supervised by Weierstrass. His thesis was on the solution of differential equations. In 1874, after having taught at secondary school level — first at the Joachimsthal Gymnasium, then at the Sophienrealschule — he was appointed to the University of Berlin as an extraordinary professor of mathematics.\nFrobenius was in Berlin only a year before he went to Zürich to take up an appointment as an ordinary professor at the Eidgenössische Polytechnikum. For seventeen years, between 1875 and 1892, Frobenius worked in Zürich. It was there that he married, brought up his family, and did much important work in widely differing areas of mathematics.\nIn the last days of December 1891, Kronecker died, and therefore his chair in Berlin became vacant. Weierstrass, strongly believing that Frobenius was the right person to keep Berlin in the forefront of mathematics, used his considerable influence to have Frobenius appointed. In 1893 he returned to Berlin, where he was elected to the Prussian Academy of Sciences.\n\nContributions to group theory\nGroup theory was one of Frobenius' principal interests in the second half of his career. One of his first contributions was the proof of the Sylow theorems for abstract groups. Earlier proofs had been for permutation groups. His proof of the first Sylow theorem (on the existence of Sylow groups) is one of those frequently used today.\n\nFrobenius also proved the following fundamental theorem: If a positive integer n divides the order |G|  of a finite group G, then the number of solutions of the equation  xn = 1  in G is equal to  k n  for some positive integer k .\nHe also posed the following conjecture: If, in the above theorem,  k = 1 , then the solutions of the equation  xn = 1  in G form a subgroup.\nMany years ago this conjecture was proved correct for solvable groups. Only in 1991, after the classification of finite simple groups, was this problem solved in general.\nMore important was his creation of the theory of group characters and group representations, which are fundamental tools for studying the structure of groups. This work led to the notion of Frobenius reciprocity and the definition of what are now called Frobenius groups. A group G is said to be a Frobenius group if there is a subgroup  H < G  such that\n\n  \n    \n      \n         \n        H\n         \n        ∩\n         \n        \n          H\n          \n            x\n          \n        \n        =\n        {\n         \n        1\n         \n        }\n        \n      \n    \n    {\\displaystyle \\ H\\ \\cap \\ H^{x}=\\{\\ 1\\ \\}\\quad }\n  \n for all \n  \n    \n      \n        \n        x\n        ∈\n        G\n         \n        ∖\n         \n        H\n         \n        .\n      \n    \n    {\\displaystyle \\quad x\\in G\\ \\backslash \\ H~.}\n  \n\nIn that case, the set\n\n  \n    \n      \n         \n        N\n        =\n        G\n         \n        ∖\n        \n        \n        \n        \n          ⋃\n          \n            x\n            ∈\n             \n            G\n             \n            ∖\n             \n            H\n          \n        \n        \n        \n        \n        \n          H\n          \n            x\n          \n        \n         \n      \n    \n    {\\displaystyle \\ N=G\\ \\backslash \\!\\!\\!\\bigcup _{x\\in \\ G\\ \\backslash \\ H}\\!\\!\\!H^{x}\\ }\n  \n\ntogether with the identity element of G forms a subgroup which is nilpotent as John G. Thompson showed in 1959. All known proofs of that theorem make use of characters. In his first paper about characters (1896), Frobenius constructed the character table of the group \n  \n    \n      \n         \n        \n          P\n          S\n          L\n        \n        (\n        2\n        ,\n        p\n        )\n         \n      \n    \n    {\\displaystyle \\ \\mathrm {PSL} (2,p",
    "links": [
      "American Mathematical Society",
      "Berlin",
      "Cayley–Hamilton theorem",
      "Character theory",
      "Charles W. Curtis",
      "Charlottenburg",
      "Classification of finite simple groups",
      "Comptes rendus de l'Académie des sciences",
      "Conjugacy classes",
      "Cyclotomic field",
      "Differential equations",
      "Doctoral advisor",
      "Doi (identifier)",
      "ETH Zurich",
      "Edmund F. Robertson",
      "Edmund Landau",
      "Elliptic functions",
      "Ernst Eduard Kummer",
      "Ernst Kummer",
      "Finite group",
      "Frobenius group",
      "Frobenius inner product",
      "Frobenius manifold",
      "Frobenius matrix",
      "Frobenius method",
      "Galois group",
      "German Empire",
      "Germans",
      "Google Books",
      "Group representation",
      "Group theory",
      "Humboldt University of Berlin",
      "ISBN (identifier)",
      "Issai Schur",
      "Joachimsthal Gymnasium",
      "John G. Thompson",
      "Journal für die reine und angewandte Mathematik",
      "Karl Weierstrass",
      "Kingdom of Prussia",
      "Konrad Knopp",
      "Leopold Kronecker",
      "List of finite simple groups",
      "List of things named after Ferdinand Georg Frobenius",
      "MR (identifier)",
      "MacTutor History of Mathematics Archive",
      "Marshall Hall (mathematician)",
      "Mathematical physics",
      "Mathematician",
      "Mathematics",
      "Mathematische Zeitschrift"
    ],
    "categories": [
      "Category:1849 births",
      "Category:1917 deaths",
      "Category:19th-century German mathematicians",
      "Category:20th-century German mathematicians",
      "Category:Academic staff of ETH Zurich",
      "Category:Academic staff of the Humboldt University of Berlin",
      "Category:Articles with hCards",
      "Category:Articles with short description",
      "Category:Commons category link is on Wikidata",
      "Category:Group theorists"
    ]
  },
  "Algebraic solution": {
    "title": "Solution in radicals",
    "url": "https://en.wikipedia.org/wiki/Solution_in_radicals",
    "summary": "A solution in radicals or algebraic solution is an expression of a solution of a polynomial equation that is algebraic, that is, relies only on addition, subtraction, multiplication, division, raising to integer powers, and extraction of nth roots (square roots, cube roots, etc.).\nA well-known example is the quadratic formula \n\n  \n    \n      \n        x\n        =\n        \n          \n            \n              −\n              b\n              ±\n              \n                \n                  \n                    b\n                    \n                      2\n                    \n                  \n                  −\n                  4\n                  a\n                  c\n                   \n                \n              \n            \n            \n              2\n              a\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle x={\\frac {-b\\pm {\\sqrt {b^{2}-4ac\\ }}}{2a}},}\n  \n\nwhich expresses the solutions of the quadratic equation\n\n  \n    \n      \n        a\n",
    "content": "A solution in radicals or algebraic solution is an expression of a solution of a polynomial equation that is algebraic, that is, relies only on addition, subtraction, multiplication, division, raising to integer powers, and extraction of nth roots (square roots, cube roots, etc.).\nA well-known example is the quadratic formula \n\n  \n    \n      \n        x\n        =\n        \n          \n            \n              −\n              b\n              ±\n              \n                \n                  \n                    b\n                    \n                      2\n                    \n                  \n                  −\n                  4\n                  a\n                  c\n                   \n                \n              \n            \n            \n              2\n              a\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle x={\\frac {-b\\pm {\\sqrt {b^{2}-4ac\\ }}}{2a}},}\n  \n\nwhich expresses the solutions of the quadratic equation\n\n  \n    \n      \n        a\n        \n          x\n          \n            2\n          \n        \n        +\n        b\n        x\n        +\n        c\n        =\n        0.\n      \n    \n    {\\displaystyle ax^{2}+bx+c=0.}\n  \n\nThere exist algebraic solutions for cubic equations and quartic equations, which are more complicated than the quadratic formula. The Abel–Ruffini theorem, and, more generally Galois theory, state that some quintic equations, such as \n\n  \n    \n      \n        \n          x\n          \n            5\n          \n        \n        −\n        x\n        +\n        1\n        =\n        0\n        ,\n      \n    \n    {\\displaystyle x^{5}-x+1=0,}\n  \n\ndo not have any algebraic solution. The same is true for every higher degree. However, for any degree there are some polynomial equations that have algebraic solutions; for example, the equation \n  \n    \n      \n        \n          x\n          \n            10\n          \n        \n        =\n        2\n      \n    \n    {\\displaystyle x^{10}=2}\n  \n can be solved as \n  \n    \n      \n        x\n        =\n        ±\n        \n          \n            2\n            \n              10\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle x=\\pm {\\sqrt[{10}]{2}}.}\n  \n The eight other solutions are nonreal complex numbers, which are also algebraic and have the form \n  \n    \n      \n        x\n        =\n        ±\n        r\n        \n          \n            2\n            \n              10\n            \n          \n        \n        ,\n      \n    \n    {\\displaystyle x=\\pm r{\\sqrt[{10}]{2}},}\n  \n where r is a fifth root of unity, which can be expressed with two nested square roots. See also Quintic function § Other solvable quintics for various other examples in degree 5.\nÉvariste Galois introduced a criterion allowing one to decide which equations are solvable in radicals. See Radical extension for the precise formulation of his result.\n\nSee also\nRadical symbol\nSolvable quintics\nSolvable sextics\nSolvable septics\n\n\n== References ==",
    "links": [
      "Abel–Ruffini theorem",
      "Addition",
      "Algebra",
      "Algebraic expression",
      "Algebraic number",
      "Complex number",
      "Cube roots",
      "Cubic equation",
      "Division (mathematics)",
      "Exponentiation",
      "Expression (mathematics)",
      "Galois theory",
      "ISBN (identifier)",
      "Multiplication",
      "Nested radical",
      "Nth root",
      "Polynomial equation",
      "Quadratic equation",
      "Quadratic formula",
      "Quartic equation",
      "Quintic equation",
      "Quintic function",
      "Radical extension",
      "Radical symbol",
      "Root of unity",
      "Septic equation",
      "Sextic equation",
      "Square roots",
      "Subtraction",
      "Évariste Galois",
      "Wikipedia:Stub",
      "Template:Algebra-stub",
      "Template talk:Algebra-stub"
    ],
    "categories": [
      "Category:Algebra",
      "Category:Algebra stubs",
      "Category:All Wikipedia articles written in American English",
      "Category:All stub articles",
      "Category:Articles with short description",
      "Category:Equations",
      "Category:Short description is different from Wikidata",
      "Category:Use American English from January 2019",
      "Category:Use mdy dates from September 2021"
    ]
  },
  "Cramer's theorem (algebraic curves)": {
    "title": "Cramer's theorem (algebraic curves)",
    "url": "https://en.wikipedia.org/wiki/Cramer%27s_theorem_(algebraic_curves)",
    "summary": "In algebraic geometry, Cramer's theorem on algebraic curves gives the necessary and sufficient number of points in the real plane falling on an algebraic curve to uniquely determine the curve in non-degenerate cases. This number is \n\n  \n    \n      \n        \n          \n            \n              n\n              (\n              n\n              +\n              3\n              )\n            \n            2\n          \n        \n        ,\n      \n    \n    {\\displaystyle {\\frac {n(n+3)}{2}},}\n  \n\nwhere n is the degree of the curve. The theorem is due to Gabriel Cramer, who published it in 1750.\nFor example, a line (of degree 1) is determined by 2 distinct points on it: one and only one line goes through those two points. Likewise, a non-degenerate conic (polynomial equation in x and y with the sum of their powers in any term not exceeding 2, hence with degree 2) is uniquely determined by 5 points in general position (no three of which are on a straight line).\nThe intuition of the conic case is t",
    "content": "In algebraic geometry, Cramer's theorem on algebraic curves gives the necessary and sufficient number of points in the real plane falling on an algebraic curve to uniquely determine the curve in non-degenerate cases. This number is \n\n  \n    \n      \n        \n          \n            \n              n\n              (\n              n\n              +\n              3\n              )\n            \n            2\n          \n        \n        ,\n      \n    \n    {\\displaystyle {\\frac {n(n+3)}{2}},}\n  \n\nwhere n is the degree of the curve. The theorem is due to Gabriel Cramer, who published it in 1750.\nFor example, a line (of degree 1) is determined by 2 distinct points on it: one and only one line goes through those two points. Likewise, a non-degenerate conic (polynomial equation in x and y with the sum of their powers in any term not exceeding 2, hence with degree 2) is uniquely determined by 5 points in general position (no three of which are on a straight line).\nThe intuition of the conic case is this: Suppose the given points fall on, specifically, an ellipse. Then five pieces of information are necessary and sufficient to identify the ellipse—the horizontal location of the ellipse's center, the vertical location of the center, the major axis (the length of the longest chord), the minor axis (the length of the shortest chord through the center, perpendicular to the major axis), and the ellipse's rotational orientation (the extent to which the major axis departs from the horizontal). Five points in general position suffice to provide these five pieces of information, while four points do not.\n\nDerivation of the formula\nThe number of distinct terms (including those with a zero coefficient) in an n-th degree equation in two variables is (n + 1)(n + 2) / 2. This is because the n-th degree terms are \n  \n    \n      \n        \n          x\n          \n            n\n          \n        \n        ,\n        \n        \n          x\n          \n            n\n            −\n            1\n          \n        \n        \n          y\n          \n            1\n          \n        \n        ,\n        \n        …\n        ,\n        \n        \n          y\n          \n            n\n          \n        \n        ,\n      \n    \n    {\\displaystyle x^{n},\\,x^{n-1}y^{1},\\,\\dots ,\\,y^{n},}\n  \n numbering n + 1 in total; the (n − 1) degree terms are \n  \n    \n      \n        \n          x\n          \n            n\n            −\n            1\n          \n        \n        ,\n        \n        \n          x\n          \n            n\n            −\n            2\n          \n        \n        \n          y\n          \n            1\n          \n        \n        ,\n        \n        …\n        ,\n        \n        \n          y\n          \n            n\n            −\n            1\n          \n        \n        ,\n      \n    \n    {\\displaystyle x^{n-1},\\,x^{n-2}y^{1},\\,\\dots ,\\,y^{n-1},}\n  \n numbering n in total; and so on through the first degree terms \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n and \n  \n    \n      \n        y\n        ,\n      \n    \n    {\\displaystyle y,}\n  \n numbering 2 in total, and the single zero degree term (the constant). The sum of these is (n + 1) + n + (n − 1) + ... + 2 + 1 = (n + 1)(n + 2) / 2 terms, each with its own coefficient. However, one of these coefficients is redundant in determining the curve, because we can always divide through the polynomial equation by any one of the coefficients, giving an equivalent equation with one coefficient fixed at 1, and thus [(n + 1)(n + 2) / 2] − 1 = n(n + 3) / 2  remaining coefficients. \nFor example, a fourth-degree equation has the general form\n\n  \n    \n      \n        \n          x\n          \n            4\n          \n        \n        +\n        \n          c\n          \n            1\n          \n        \n        \n          x\n          \n            3\n          \n        \n        y\n        +\n        \n          c\n          \n            2\n          \n        \n        \n          x\n          \n            2\n          \n        \n        \n          y\n          \n            2\n          \n        \n        +\n        \n          c\n          \n            3\n          \n        \n        x\n        \n          y\n          \n            3\n          \n        \n        +\n        \n          c\n          \n            4\n          \n        \n        \n          y\n          \n            4\n          \n        \n        +\n        \n          c\n          \n            5\n          \n        \n        \n          x\n          \n            3\n          \n        \n        +\n        \n          c\n          \n            6\n          \n        \n        \n          x\n          \n            2\n          \n        \n        y\n        +\n        \n          c\n          \n            7\n          \n        \n        x\n        \n          y\n          \n            2\n          \n        \n        +\n        \n          c\n          \n            8\n          \n        \n        \n          y\n          \n            3\n          \n        \n        +\n        \n          c\n          \n            9\n          \n     ",
    "links": [
      "Algebraic curve",
      "Algebraic geometry",
      "Bézout's theorem",
      "Chord (geometry)",
      "Circle",
      "Coefficient",
      "Cramer's paradox",
      "Degeneracy (mathematics)",
      "Degenerate conic",
      "Degree of a polynomial",
      "Determinant (mathematics)",
      "Ellipse",
      "Five points determine a conic",
      "Gabriel Cramer",
      "General position",
      "Google Books",
      "Major axis",
      "Minor axis",
      "Necessary and sufficient",
      "Perpendicular",
      "Plane (mathematics)",
      "Polynomial equation",
      "Radius",
      "Rotation (mathematics)",
      "Talk:Cramer's theorem (algebraic curves)",
      "Wikipedia:Articles with a single source",
      "Help:Referencing for beginners"
    ],
    "categories": [
      "Category:Algebraic geometry",
      "Category:All articles needing additional references",
      "Category:Analytic geometry",
      "Category:Articles needing additional references from May 2024",
      "Category:Articles with short description",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Cubic function": {
    "title": "Cubic function",
    "url": "https://en.wikipedia.org/wiki/Cubic_function",
    "summary": "In mathematics, a cubic function is a function of the form \n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        a\n        \n          x\n          \n            3\n          \n        \n        +\n        b\n        \n          x\n          \n            2\n          \n        \n        +\n        c\n        x\n        +\n        d\n        ,\n      \n    \n    {\\displaystyle f(x)=ax^{3}+bx^{2}+cx+d,}\n  \n that is, a polynomial function of degree three. In many texts, the coefficients a, b, c, and d are supposed to be real numbers, and the function is considered as a real function that maps real numbers to real numbers or as a complex function that maps complex numbers to complex numbers. In other cases, the coefficients may be complex numbers, and the function is a complex function that has the set of the complex numbers as its codomain, even when the domain is restricted to the real numbers.\nSetting f(x) = 0 produces a cubic equation of the form\n\n  \n    \n      \n        a\n        \n     ",
    "content": "In mathematics, a cubic function is a function of the form \n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        a\n        \n          x\n          \n            3\n          \n        \n        +\n        b\n        \n          x\n          \n            2\n          \n        \n        +\n        c\n        x\n        +\n        d\n        ,\n      \n    \n    {\\displaystyle f(x)=ax^{3}+bx^{2}+cx+d,}\n  \n that is, a polynomial function of degree three. In many texts, the coefficients a, b, c, and d are supposed to be real numbers, and the function is considered as a real function that maps real numbers to real numbers or as a complex function that maps complex numbers to complex numbers. In other cases, the coefficients may be complex numbers, and the function is a complex function that has the set of the complex numbers as its codomain, even when the domain is restricted to the real numbers.\nSetting f(x) = 0 produces a cubic equation of the form\n\n  \n    \n      \n        a\n        \n          x\n          \n            3\n          \n        \n        +\n        b\n        \n          x\n          \n            2\n          \n        \n        +\n        c\n        x\n        +\n        d\n        =\n        0\n        ,\n      \n    \n    {\\displaystyle ax^{3}+bx^{2}+cx+d=0,}\n  \n\nwhose solutions are called roots of the function. The derivative of a cubic function is a quadratic function.\nA cubic function with real coefficients has either one or three real roots (which may not be distinct); all odd-degree polynomials with real coefficients have at least one real root.\nThe graph of a cubic function always has a single inflection point. It may have two critical points, a local minimum and a local maximum. Otherwise, a cubic function is monotonic. The graph of a cubic function is symmetric with respect to its inflection point; that is, it is invariant under a rotation of a half turn around this point. Up to an affine transformation, there are only three possible graphs for cubic functions.\nCubic functions are fundamental for cubic interpolation.\n\nHistory\nCritical and inflection points\nThe critical points of a cubic function are its stationary points, that is the points where the slope of the function is zero. Thus the critical points of a cubic function f defined by \n\nf(x) = ax3 + bx2 + cx + d,\noccur at values of x such that the derivative\n\n  \n    \n      \n        3\n        a\n        \n          x\n          \n            2\n          \n        \n        +\n        2\n        b\n        x\n        +\n        c\n        =\n        0\n      \n    \n    {\\displaystyle 3ax^{2}+2bx+c=0}\n  \n\nof the cubic function is zero.\nThe solutions of this equation are the x-values of the critical points and are given, using the quadratic formula, by \n\n  \n    \n      \n        \n          x\n          \n            critical\n          \n        \n        =\n        \n          \n            \n              −\n              b\n              ±\n              \n                \n                  \n                    b\n                    \n                      2\n                    \n                  \n                  −\n                  3\n                  a\n                  c\n                \n              \n            \n            \n              3\n              a\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle x_{\\text{critical}}={\\frac {-b\\pm {\\sqrt {b^{2}-3ac}}}{3a}}.}\n  \n\nThe sign of the expression Δ0 = b2 − 3ac inside the square root determines the number of critical points. If it is positive, then there are two critical points, one is a local maximum, and the other is a local minimum. If b2 − 3ac = 0, then there is only one critical point, which is an inflection point. If b2 − 3ac < 0, then there are no (real) critical points. In the two latter cases, that is, if b2 − 3ac is nonpositive, the cubic function is strictly monotonic. See the figure for an example of the case Δ0 > 0.\nThe inflection point of a function is where that function changes concavity. An inflection point occurs when the second derivative \n  \n    \n      \n        \n          f\n          ″\n        \n        (\n        x\n        )\n        =\n        6\n        a\n        x\n        +\n        2\n        b\n        ,\n      \n    \n    {\\displaystyle f''(x)=6ax+2b,}\n  \n is zero, and the third derivative is nonzero. Thus a cubic function has always a single inflection point, which occurs at\n\n  \n    \n      \n        \n          x\n          \n            inflection\n          \n        \n        =\n        −\n        \n          \n            b\n            \n              3\n              a\n            \n          \n        \n        .\n      \n    \n    {\\displaystyle x_{\\text{inflection}}=-{\\frac {b}{3a}}.}\n\nClassification\nThe graph of a cubic function is a cubic curve, though many cubic curves are not graphs of functions.\nAlthough cubic functions depend on four parameters, their graph can have only very few shapes. In fact, the graph of a cubic function is always similar to the graph of a function of the form\n\n  \n    \n  ",
    "links": [
      "Affine transformation",
      "Binomial (polynomial)",
      "Bivariate polynomial",
      "Change of variable",
      "Codomain",
      "Collinear points",
      "Complex number",
      "Concave function",
      "Constant function",
      "Continuously differentiable function",
      "Critical point (mathematics)",
      "Cubic Hermite spline",
      "Cubic curve",
      "Cubic equation",
      "Cubic interpolation",
      "Cubic polynomial",
      "Curvature",
      "Degree of a polynomial",
      "Derivative",
      "Discriminant",
      "Domain of a function",
      "Encyclopedia of Mathematics",
      "European Mathematical Society",
      "Factorization of polynomials",
      "Function (mathematics)",
      "Geometric transformation",
      "Graph of a function",
      "Gröbner basis",
      "Homogeneous polynomial",
      "Homothecy",
      "Horner's method",
      "ISBN (identifier)",
      "Inflection point",
      "Irreducible polynomial",
      "Linear equation",
      "Linear function (calculus)",
      "MacTutor archive",
      "Mathematics",
      "Mirror image",
      "Monomial",
      "Monotonic",
      "Multiplicity (mathematics)",
      "Multivariate polynomial",
      "Odd function",
      "Piecewise",
      "Polynomial",
      "Polynomial equation",
      "Polynomial function",
      "Polynomial greatest common divisor",
      "Polynomial identity testing"
    ],
    "categories": [
      "Category:All articles needing additional references",
      "Category:Articles needing additional references from September 2019",
      "Category:Articles with short description",
      "Category:Calculus",
      "Category:Commons category link is on Wikidata",
      "Category:Polynomial functions",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Elementary function": {
    "title": "Elementary function",
    "url": "https://en.wikipedia.org/wiki/Elementary_function",
    "summary": "In mathematics, elementary functions are those functions that are most commonly encountered by beginners. They are typically real functions of a single real variable that can be defined by applying the operations of addition, multiplication, division, nth root, and function composition to polynomial, exponential, logarithm, and trigonometric functions. They include inverse trigonometric functions, hyperbolic functions and inverse hyperbolic functions, which can be expressed in terms of logarithms and exponential function.\nAll elementary functions have derivatives of any order, which are also elementary, and can be algorithmically computed by applying the differentiation rules. The Taylor series of an elementary function converges in a neighborhood of every point of its domain.  More generally, they are global analytic functions, defined (possibly with multiple values, such as the elementary function \n  \n    \n      \n        \n          \n            z\n          \n        \n      \n    \n    {",
    "content": "In mathematics, elementary functions are those functions that are most commonly encountered by beginners. They are typically real functions of a single real variable that can be defined by applying the operations of addition, multiplication, division, nth root, and function composition to polynomial, exponential, logarithm, and trigonometric functions. They include inverse trigonometric functions, hyperbolic functions and inverse hyperbolic functions, which can be expressed in terms of logarithms and exponential function.\nAll elementary functions have derivatives of any order, which are also elementary, and can be algorithmically computed by applying the differentiation rules. The Taylor series of an elementary function converges in a neighborhood of every point of its domain.  More generally, they are global analytic functions, defined (possibly with multiple values, such as the elementary function \n  \n    \n      \n        \n          \n            z\n          \n        \n      \n    \n    {\\displaystyle {\\sqrt {z}}}\n  \n or \n  \n    \n      \n        log\n        ⁡\n        z\n      \n    \n    {\\displaystyle \\log z}\n  \n) for every complex argument, except at isolated points. In contrast, antiderivatives of elementary functions need not be elementary and is difficult to decide whether a specific elementary function has an elementary antiderivative.\nIn an attempt to solve this problem, Joseph Liouville introduced in 1833 a definition of elementary functions that extends the above one and is commonly accepted: An elementary function is a function that can be built, using addition, multiplication, division, and function composition, from constant functions, exponential functions, the complex logarithm, and roots of polynomials with elementary functions as coefficients. This includes the trigonometric functions, since, for example, ⁠\n  \n    \n      \n        \n          cos\n          ⁡\n          x\n          =\n          \n            \n              \n                \n                  e\n                  \n                    i\n                    x\n                  \n                \n                +\n                \n                  e\n                  \n                    −\n                    i\n                    x\n                  \n                \n              \n              2\n            \n          \n        \n      \n    \n    {\\displaystyle \\textstyle \\cos x={\\frac {e^{ix}+e^{-ix}}{2}}}\n  \n⁠, as well as every algebraic function.\nLiouville's result is that, if an elementary function has an elementary antiderivative, then this antiderivative is a linear combination of logarithms, where the coefficients and the arguments of the logarithms are elementary functions involved, in some sense, in the definition of the function. More than 130 years later, Risch algorithm, named after Robert Henry Risch, is an algorithm to decide whether an elementary function has an elementary antiderivative, and, if it has, to compute this antiderivative. Despite dealing with elementary functions, the Risch algorithm is far from elementary; as of 2025, it seems that no complete implementation is available.\n\nExamples\nBasic examples\nElementary functions of a single variable x include:\n\nConstant functions: \n  \n    \n      \n        2\n        ,\n         \n        π\n        ,\n         \n        e\n        ,\n      \n    \n    {\\displaystyle 2,\\ \\pi ,\\ e,}\n  \n the Euler–Mascheroni constant, Apéry's constant, Khinchin's constant, etc.  Any constant real (or complex) number.\nPowers of ⁠\n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n⁠: \n  \n    \n      \n        \n          x\n          \n            α\n          \n        \n        =\n        \n          e\n          \n            α\n            log\n            ⁡\n            x\n          \n        \n      \n    \n    {\\displaystyle x^{\\alpha }=e^{\\alpha \\log x}}\n  \n etc. (The exponent can be any real or complex constant.)\nExponential functions: \n  \n    \n      \n        \n          \n            e\n            \n              x\n            \n          \n          ,\n          \n          \n            a\n            \n              x\n            \n          \n          =\n          \n            e\n            \n              x\n              log\n              ⁡\n              a\n            \n          \n        \n      \n    \n    {\\displaystyle \\textstyle e^{x},\\quad a^{x}=e^{x\\log a}}\n  \n\nLogarithms: \n  \n    \n      \n        \n          log\n          ⁡\n          x\n          ,\n          \n          \n            log\n            \n              a\n            \n          \n          ⁡\n          x\n          =\n          \n            \n              \n                log\n                ⁡\n                x\n              \n              \n                log\n                ⁡\n                a\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\textstyle \\log x,\\quad \\log _{a}x={\\frac {\\log x}{\\log a}}}\n  \n\nTrigonometric functions: \n  \n    \n      \n        \n          sin\n          ⁡\n          x\n          =\n          \n            ",
    "links": [
      "Absolute value",
      "Addition",
      "Algebraic function",
      "Algorithmically",
      "American Journal of Mathematics",
      "American Mathematical Monthly",
      "American Mathematical Society",
      "Analytic function",
      "Antiderivative",
      "Apéry's constant",
      "Closed-form expression",
      "Closure (mathematics)",
      "Complex logarithm",
      "Complex number",
      "Complex plane",
      "Constant function",
      "Derivative",
      "Differential Galois theory",
      "Differential algebra",
      "Differentiation rules",
      "Dirichlet integral",
      "Division (mathematics)",
      "Doi (identifier)",
      "Elementary function arithmetic",
      "Elementary recursive function",
      "Elliptic function",
      "Elliptic integral",
      "Eric W. Weisstein",
      "Error function",
      "Euler–Mascheroni constant",
      "Exponential function",
      "Exponential integral",
      "Exponentiation",
      "Field (mathematics)",
      "Field extension",
      "Fresnel integral",
      "Function (mathematics)",
      "Function composition",
      "Gamma function",
      "Global analytic function",
      "Hyperbolic function",
      "Hyperbolic functions",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "Inverse hyperbolic function",
      "Inverse hyperbolic functions",
      "Inverse trigonometric function",
      "Inverse trigonometric functions",
      "Isolated point",
      "JSTOR (identifier)"
    ],
    "categories": [
      "Category:All articles containing potentially dated statements",
      "Category:Articles containing potentially dated statements from 2025",
      "Category:Articles with short description",
      "Category:CS1: long volume value",
      "Category:Computer algebra",
      "Category:Differential algebra",
      "Category:Short description is different from Wikidata",
      "Category:Types of functions"
    ]
  },
  "Elliptical function": {
    "title": "Elliptic function",
    "url": "https://en.wikipedia.org/wiki/Elliptic_function",
    "summary": "In the mathematical field of complex analysis, elliptic functions are special kinds of meromorphic functions, that satisfy two periodicity conditions. They are named elliptic functions because they come from elliptic integrals. Those integrals are in turn named elliptic because they first were encountered for the calculation of the arc length of an ellipse.\nImportant elliptic functions are Jacobi elliptic functions and the Weierstrass \n  \n    \n      \n        ℘\n      \n    \n    {\\displaystyle \\wp }\n  \n-function.\nFurther development of this theory led to hyperelliptic functions and modular forms.",
    "content": "In the mathematical field of complex analysis, elliptic functions are special kinds of meromorphic functions, that satisfy two periodicity conditions. They are named elliptic functions because they come from elliptic integrals. Those integrals are in turn named elliptic because they first were encountered for the calculation of the arc length of an ellipse.\nImportant elliptic functions are Jacobi elliptic functions and the Weierstrass \n  \n    \n      \n        ℘\n      \n    \n    {\\displaystyle \\wp }\n  \n-function.\nFurther development of this theory led to hyperelliptic functions and modular forms.\n\nDefinition\nA meromorphic function is called an elliptic function, if there are two  \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n-linear independent complex numbers \n  \n    \n      \n        \n          ω\n          \n            1\n          \n        \n        ,\n        \n          ω\n          \n            2\n          \n        \n        ∈\n        \n          C\n        \n      \n    \n    {\\displaystyle \\omega _{1},\\omega _{2}\\in \\mathbb {C} }\n  \n such that\n\n  \n    \n      \n        f\n        (\n        z\n        +\n        \n          ω\n          \n            1\n          \n        \n        )\n        =\n        f\n        (\n        z\n        )\n      \n    \n    {\\displaystyle f(z+\\omega _{1})=f(z)}\n  \n and \n  \n    \n      \n        f\n        (\n        z\n        +\n        \n          ω\n          \n            2\n          \n        \n        )\n        =\n        f\n        (\n        z\n        )\n        ,\n        \n        ∀\n        z\n        ∈\n        \n          C\n        \n      \n    \n    {\\displaystyle f(z+\\omega _{2})=f(z),\\quad \\forall z\\in \\mathbb {C} }\n  \n.\nSo elliptic functions have two periods and are therefore doubly periodic functions.\n\nPeriod lattice and fundamental domain\nIf \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n is an elliptic function with periods \n  \n    \n      \n        \n          ω\n          \n            1\n          \n        \n        ,\n        \n          ω\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\omega _{1},\\omega _{2}}\n  \n it also holds that\n\n  \n    \n      \n        f\n        (\n        z\n        +\n        γ\n        )\n        =\n        f\n        (\n        z\n        )\n      \n    \n    {\\displaystyle f(z+\\gamma )=f(z)}\n  \n\nfor every linear combination \n  \n    \n      \n        γ\n        =\n        m\n        \n          ω\n          \n            1\n          \n        \n        +\n        n\n        \n          ω\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\gamma =m\\omega _{1}+n\\omega _{2}}\n  \n with \n  \n    \n      \n        m\n        ,\n        n\n        ∈\n        \n          Z\n        \n      \n    \n    {\\displaystyle m,n\\in \\mathbb {Z} }\n  \n.\nThe abelian group\n\n  \n    \n      \n        Λ\n        :=\n        ⟨\n        \n          ω\n          \n            1\n          \n        \n        ,\n        \n          ω\n          \n            2\n          \n        \n        \n          ⟩\n          \n            \n              Z\n            \n          \n        \n        :=\n        \n          Z\n        \n        \n          ω\n          \n            1\n          \n        \n        +\n        \n          Z\n        \n        \n          ω\n          \n            2\n          \n        \n        :=\n        {\n        m\n        \n          ω\n          \n            1\n          \n        \n        +\n        n\n        \n          ω\n          \n            2\n          \n        \n        ∣\n        m\n        ,\n        n\n        ∈\n        \n          Z\n        \n        }\n      \n    \n    {\\displaystyle \\Lambda :=\\langle \\omega _{1},\\omega _{2}\\rangle _{\\mathbb {Z} }:=\\mathbb {Z} \\omega _{1}+\\mathbb {Z} \\omega _{2}:=\\{m\\omega _{1}+n\\omega _{2}\\mid m,n\\in \\mathbb {Z} \\}}\n  \n\nis called the period lattice.\nThe parallelogram generated by \n  \n    \n      \n        \n          ω\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\omega _{1}}\n  \nand \n  \n    \n      \n        \n          ω\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\omega _{2}}\n  \n\n  \n    \n      \n        {\n        μ\n        \n          ω\n          \n            1\n          \n        \n        +\n        ν\n        \n          ω\n          \n            2\n          \n        \n        ∣\n        0\n        ≤\n        μ\n        ,\n        ν\n        ≤\n        1\n        }\n      \n    \n    {\\displaystyle \\{\\mu \\omega _{1}+\\nu \\omega _{2}\\mid 0\\leq \\mu ,\\nu \\leq 1\\}}\n  \n\nis a fundamental domain of \n  \n    \n      \n        Λ\n      \n    \n    {\\displaystyle \\Lambda }\n  \n acting on \n  \n    \n      \n        \n          C\n        \n      \n    \n    {\\displaystyle \\mathbb {C} }\n  \n.\nGeometrically the complex plane is tiled with parallelograms. Everything that happens in one fundamental domain repeats in all the others. For that reason we can view elliptic function as functions with the quotient group \n  \n    \n      \n        \n          C\n        \n        \n          /\n        \n        Λ\n      \n    \n",
    "links": [
      "AF+BG theorem",
      "Abel elliptic functions",
      "Abelian group",
      "Abel–Jacobi map",
      "Abramowitz and Stegun",
      "Acnode",
      "Adrien-Marie Legendre",
      "Ak singularity",
      "Algebraic curve",
      "ArXiv (identifier)",
      "Belyi's theorem",
      "Birkhoff–Grothendieck theorem",
      "Bitangent",
      "Bolza surface",
      "Brill–Noether theory",
      "Bring's curve",
      "Bézout's theorem",
      "Calculus",
      "Carl Friedrich Gauss",
      "Carl Gustav Jacob Jacobi",
      "Cayley–Bacharach theorem",
      "Charles Auguste Briot",
      "Clifford's theorem on special divisors",
      "Compact Riemann surface",
      "Complex analysis",
      "Complex number",
      "Conic section",
      "Counting points on elliptic curves",
      "Cramer's paradox",
      "Crunode",
      "Cubic plane curve",
      "Cusp (singularity)",
      "De Franchis theorem",
      "Delta invariant",
      "Dessin d'enfant",
      "Differential equation",
      "Differential of the first kind",
      "Division polynomials",
      "Doubly periodic function",
      "Dual curve",
      "E. T. Whittaker",
      "ELSV formula",
      "Eisenstein series",
      "Ellipse",
      "Elliptic curve",
      "Elliptic curve cryptography",
      "Elliptic curve primality",
      "Elliptic integral",
      "Encyclopedia of Mathematics",
      "European Mathematical Society"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1 German-language sources (de)",
      "Category:CS1 maint: location missing publisher",
      "Category:Commons category link is on Wikidata",
      "Category:Elliptic functions",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Equation solving": {
    "title": "Equation solving",
    "url": "https://en.wikipedia.org/wiki/Equation_solving",
    "summary": "In mathematics, to solve an equation is to find its solutions, which are the values (numbers, functions, sets, etc.) that fulfill the condition stated by the equation, consisting generally of two expressions related by an equals sign. When seeking a solution, one or more variables are designated as unknowns. A solution is an assignment of values to the unknown variables that makes the equality in the equation true. In other words, a solution is a value or a collection of values (one for each unknown) such that, when substituted for the unknowns, the equation becomes an equality.\nA solution of an equation is often called a root of the equation, particularly but not only for polynomial equations. The set of all solutions of an equation is its solution set.\nAn equation may be solved either numerically or symbolically. Solving an equation numerically means that only numbers are admitted as solutions. Solving an equation symbolically means that expressions can be used for representing the s",
    "content": "In mathematics, to solve an equation is to find its solutions, which are the values (numbers, functions, sets, etc.) that fulfill the condition stated by the equation, consisting generally of two expressions related by an equals sign. When seeking a solution, one or more variables are designated as unknowns. A solution is an assignment of values to the unknown variables that makes the equality in the equation true. In other words, a solution is a value or a collection of values (one for each unknown) such that, when substituted for the unknowns, the equation becomes an equality.\nA solution of an equation is often called a root of the equation, particularly but not only for polynomial equations. The set of all solutions of an equation is its solution set.\nAn equation may be solved either numerically or symbolically. Solving an equation numerically means that only numbers are admitted as solutions. Solving an equation symbolically means that expressions can be used for representing the solutions.\nFor example, the equation x + y = 2x – 1 is solved for the unknown x by the expression x = y + 1, because substituting y + 1 for x in the equation results in (y + 1) + y = 2(y + 1) – 1, a true statement. It is also possible to take the variable y to be the unknown, and then the equation is solved by y = x – 1. Or x and y can both be treated as unknowns, and then there are many solutions to the equation; a symbolic solution is (x, y) = (a + 1, a), where the variable a may take any value. Instantiating a symbolic solution with specific numbers gives a numerical solution; for example, a = 0 gives (x, y) = (1, 0) (that is, x = 1, y = 0), and a = 1 gives (x, y) = (2, 1). \nThe distinction between known variables and unknown variables is generally made in the statement of the problem, by phrases such as \"an equation in x and y\", or \"solve for x and y\", which indicate the unknowns, here x and y.\nHowever, it is common to reserve x, y, z, ... to denote the unknowns, and to use a, b, c, ... to denote the known variables, which are often called parameters. This is typically the case when considering polynomial equations, such as quadratic equations. However, for some problems, all variables may assume either role.\nDepending on the context, solving an equation may consist to find either any solution (finding a single solution is enough), all solutions, or a solution that satisfies further properties, such as belonging to a given interval. When the task is to find the solution that is the best under some criterion, this is an optimization problem. Solving an optimization problem is generally not referred to as \"equation solving\", as, generally, solving methods start from a particular solution for finding a better solution, and repeating the process until finding eventually the best solution.\n\nOverview\nOne general form of an equation is\n\n  \n    \n      \n        f\n        \n          (\n          \n            \n              x\n              \n                1\n              \n            \n            ,\n            …\n            ,\n            \n              x\n              \n                n\n              \n            \n          \n          )\n        \n        =\n        c\n        ,\n      \n    \n    {\\displaystyle f\\left(x_{1},\\dots ,x_{n}\\right)=c,}\n  \n\nwhere f is a function, x1, ..., xn are the unknowns, and c is a constant. Its solutions are the elements of the inverse image (fiber)\n\n  \n    \n      \n        \n          f\n          \n            −\n            1\n          \n        \n        (\n        c\n        )\n        =\n        \n          \n            {\n          \n        \n        (\n        \n          a\n          \n            1\n          \n        \n        ,\n        …\n        ,\n        \n          a\n          \n            n\n          \n        \n        )\n        ∈\n        D\n        ∣\n        f\n        \n          (\n          \n            \n              a\n              \n                1\n              \n            \n            ,\n            …\n            ,\n            \n              a\n              \n                n\n              \n            \n          \n          )\n        \n        =\n        c\n        \n          \n            }\n          \n        \n        ,\n      \n    \n    {\\displaystyle f^{-1}(c)={\\bigl \\{}(a_{1},\\dots ,a_{n})\\in D\\mid f\\left(a_{1},\\dots ,a_{n}\\right)=c{\\bigr \\}},}\n  \n\nwhere D is the domain of the function f. The set of solutions can be the empty set (there are no solutions), a singleton (there is exactly one solution), finite, or infinite (there are infinitely many solutions).\nFor example, an equation such as\n\n  \n    \n      \n        3\n        x\n        +\n        2\n        y\n        =\n        21\n        z\n        ,\n      \n    \n    {\\displaystyle 3x+2y=21z,}\n  \n\nwith unknowns x, y and z, can be put in the above form by subtracting 21z from both sides of the equation, to obtain\n\n  \n    \n      \n        3\n        x\n        +\n        2\n        y\n        −\n        21\n        z\n        =\n        0\n      \n    \n    {\\displaystyle 3x+2y-21z",
    "links": [
      "Algebraic equation",
      "Algebraic geometry",
      "Algebraic variety",
      "Algorithm",
      "Bring radical",
      "Brute-force search",
      "Calculus",
      "Candidate solutions",
      "Cartesian coordinate",
      "Complex number",
      "Computer algebra system",
      "Constraint satisfaction problem",
      "Coordinates",
      "Curve (geometry)",
      "Differential equation",
      "Diophantine equation",
      "Diophantine equations",
      "Domain of a function",
      "Elementary algebra",
      "Ellipse",
      "Empty set",
      "Encryption",
      "Equality (mathematics)",
      "Equals sign",
      "Equating coefficients",
      "Equation",
      "Exhaustive search",
      "Expression (mathematics)",
      "Extraneous and missing solutions",
      "Factorization",
      "Feasible solution",
      "Fiber (mathematics)",
      "Function (mathematics)",
      "Gaussian elimination",
      "Geometry",
      "Heuristic",
      "Hilbert's tenth problem",
      "ISBN (identifier)",
      "Implicit function",
      "Indeterminate (variable)",
      "Inequality (mathematics)",
      "Infinite set",
      "Integer",
      "Integral",
      "Interval (mathematics)",
      "Inverse function",
      "Inverse image",
      "Inverse problem",
      "Inverse trigonometric function",
      "Lambert's W function"
    ],
    "categories": [
      "Category:All articles needing additional references",
      "Category:All articles with unsourced statements",
      "Category:Articles needing additional references from December 2009",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from July 2019",
      "Category:Equations",
      "Category:Inverse functions",
      "Category:Short description matches Wikidata",
      "Category:Unification (computer science)"
    ]
  },
  "Hyperbolic functions": {
    "title": "Hyperbolic functions",
    "url": "https://en.wikipedia.org/wiki/Hyperbolic_functions",
    "summary": "In mathematics, hyperbolic functions are analogues of the ordinary trigonometric functions, but defined using the hyperbola rather than the circle. Just as the points (cos t, sin t) form a circle with a unit radius, the points (cosh t, sinh t) form the right half of the unit hyperbola. Also, similarly to how the derivatives of sin(t) and cos(t) are cos(t) and –sin(t) respectively, the derivatives of sinh(t) and cosh(t) are cosh(t) and sinh(t) respectively.\nHyperbolic functions are used to express the angle of parallelism in hyperbolic geometry. They are used to express Lorentz boosts as hyperbolic rotations in special relativity. They also occur in the solutions of many linear differential equations (such as the equation defining a catenary), cubic equations, and Laplace's equation in Cartesian coordinates. Laplace's equations are important in many areas of physics, including electromagnetic theory, heat transfer, and fluid dynamics.\nThe basic hyperbolic functions are:\n\nhyperbolic sine",
    "content": "In mathematics, hyperbolic functions are analogues of the ordinary trigonometric functions, but defined using the hyperbola rather than the circle. Just as the points (cos t, sin t) form a circle with a unit radius, the points (cosh t, sinh t) form the right half of the unit hyperbola. Also, similarly to how the derivatives of sin(t) and cos(t) are cos(t) and –sin(t) respectively, the derivatives of sinh(t) and cosh(t) are cosh(t) and sinh(t) respectively.\nHyperbolic functions are used to express the angle of parallelism in hyperbolic geometry. They are used to express Lorentz boosts as hyperbolic rotations in special relativity. They also occur in the solutions of many linear differential equations (such as the equation defining a catenary), cubic equations, and Laplace's equation in Cartesian coordinates. Laplace's equations are important in many areas of physics, including electromagnetic theory, heat transfer, and fluid dynamics.\nThe basic hyperbolic functions are:\n\nhyperbolic sine \"sinh\" (),\nhyperbolic cosine \"cosh\" (),\nfrom which are derived:\n\nhyperbolic tangent \"tanh\" (),\nhyperbolic cotangent \"coth\" (),\nhyperbolic secant \"sech\" (),\nhyperbolic cosecant \"csch\" or \"cosech\" ()\ncorresponding to the derived trigonometric functions.\nThe inverse hyperbolic functions are:\n\ninverse hyperbolic sine \"arsinh\" (also denoted \"sinh−1\", \"asinh\" or sometimes \"arcsinh\")\ninverse hyperbolic cosine \"arcosh\" (also denoted \"cosh−1\", \"acosh\" or sometimes \"arccosh\")\ninverse hyperbolic tangent \"artanh\" (also denoted \"tanh−1\", \"atanh\" or sometimes \"arctanh\")\ninverse hyperbolic cotangent \"arcoth\" (also denoted \"coth−1\", \"acoth\" or sometimes \"arccoth\")\ninverse hyperbolic secant \"arsech\" (also denoted \"sech−1\", \"asech\" or sometimes \"arcsech\")\ninverse hyperbolic cosecant \"arcsch\" (also denoted \"arcosech\", \"csch−1\", \"cosech−1\",\"acsch\", \"acosech\", or sometimes \"arccsch\" or \"arccosech\")\n\nThe hyperbolic functions take a real argument called a hyperbolic angle. The magnitude of a hyperbolic angle is the area of its hyperbolic sector to xy = 1. The hyperbolic functions may be defined in terms of the legs of a right triangle covering this sector.\nIn complex analysis, the hyperbolic functions arise when applying the ordinary sine and cosine functions to an imaginary angle. The hyperbolic sine and the hyperbolic cosine are entire functions. As a result, the other hyperbolic functions are meromorphic in the whole complex plane.\nBy Lindemann–Weierstrass theorem, the hyperbolic functions have a transcendental value for every non-zero algebraic value of the argument.\n\nHistory\nThe first known calculation of a hyperbolic trigonometry problem is attributed to Gerardus Mercator when issuing the Mercator map projection circa 1566. It requires tabulating solutions to a transcendental equation involving hyperbolic functions.\nThe first to suggest a similarity between the sector of the circle and that of the hyperbola was Isaac Newton in his 1687 Principia Mathematica.\nRoger Cotes suggested to modify the trigonometric functions using the imaginary unit \n  \n    \n      \n        i\n        =\n        \n          \n            −\n            1\n          \n        \n      \n    \n    {\\displaystyle i={\\sqrt {-1}}}\n  \n to obtain an oblate spheroid from a prolate one.\nHyperbolic functions were formally introduced in 1757 by Vincenzo Riccati. Riccati used Sc. and Cc. (sinus/cosinus circulare) to refer to circular functions and Sh. and Ch. (sinus/cosinus hyperbolico) to refer to hyperbolic functions. As early as 1759, Daviet de Foncenex showed the interchangeability of the trigonometric and hyperbolic functions using the imaginary unit and extended de Moivre's formula to hyperbolic functions.\nDuring the 1760s, Johann Heinrich Lambert systematized the use functions and provided exponential expressions in various publications. Lambert credited Riccati for the terminology and names of the functions, but altered the abbreviations to those used today.\n\nNotation\nDefinitions\nWith hyperbolic angle u, the hyperbolic functions sinh and cosh can defined with the exponential function eu. In the figure\n\n  \n    \n      \n        A\n        =\n        (\n        \n          e\n          \n            −\n            u\n          \n        \n        ,\n        \n          e\n          \n            u\n          \n        \n        )\n        ,\n         \n        B\n        =\n        (\n        \n          e\n          \n            u\n          \n        \n        ,\n         \n        \n          e\n          \n            −\n            u\n          \n        \n        )\n        ,\n         \n        O\n        A\n        +\n        O\n        B\n        =\n        O\n        C\n      \n    \n    {\\displaystyle A=(e^{-u},e^{u}),\\ B=(e^{u},\\ e^{-u}),\\ OA+OB=OC}\n  \n .\n\nExponential definitions\nHyperbolic sine: the odd part of the exponential function, that is, \n  \n    \n      \n        sinh\n        ⁡\n        x\n        =\n        \n          \n            \n              \n                e\n                \n                  x\n                \n ",
    "links": [
      "Abramowitz and Stegun",
      "Algebraic number",
      "Angle",
      "Angle of parallelism",
      "Arc length",
      "Area",
      "Area under the curve",
      "Argument of a function",
      "Arithmetic mean",
      "Atan2",
      "Bernoulli number",
      "Bulletin of the American Mathematical Society",
      "Cartesian coordinates",
      "Catenary",
      "Circle",
      "Circular function",
      "Circular sector",
      "Complex analysis",
      "Complex number",
      "Constant of integration",
      "Convergent series",
      "Cubic equation",
      "De Moivre's formula",
      "Differential equation",
      "Digital Library of Mathematical Functions",
      "Doi (identifier)",
      "Domain of convergence",
      "Dover Publications",
      "E (mathematical constant)",
      "Electromagnetic theory",
      "Encyclopedia of Mathematics",
      "Entire function",
      "Equal incircles theorem",
      "Eric W. Weisstein",
      "Euler's formula",
      "Euler number",
      "European Mathematical Society",
      "Even function",
      "Even part of a function",
      "Even–odd decomposition",
      "Exponential function",
      "Exsecant",
      "Fluid dynamics",
      "Frank W. J. Olver",
      "François Daviet de Foncenex",
      "General complex exponential function",
      "Gerardus Mercator",
      "Google Books",
      "Gudermannian function",
      "Heat transfer"
    ],
    "categories": [
      "Category:Analytic functions",
      "Category:Articles containing Latin-language text",
      "Category:Articles with short description",
      "Category:Commons category link is on Wikidata",
      "Category:Exponentials",
      "Category:Hyperbolic functions",
      "Category:Hyperbolic geometry",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Integral domain": {
    "title": "Integral domain",
    "url": "https://en.wikipedia.org/wiki/Integral_domain",
    "summary": "In mathematics, an integral domain is a nonzero commutative ring in which the product of any two nonzero elements is nonzero. Integral domains are generalizations of the ring of integers and provide a natural setting for studying divisibility.  In an integral domain, every nonzero element a has the cancellation property, that is, if a ≠ 0, an equality ab = ac implies b = c.\n\"Integral domain\" is defined almost universally as above, but there is some variation. This article follows the convention that rings have a multiplicative identity, generally denoted 1, but some authors do not follow this, by not requiring integral domains to have a multiplicative identity. Noncommutative integral domains are sometimes admitted.  This article, however, follows the much more usual convention of reserving the term \"integral domain\" for the commutative case and using \"domain\" for the general case including noncommutative rings.\nSome sources, notably Lang, use the term entire ring for integral domain.\n",
    "content": "In mathematics, an integral domain is a nonzero commutative ring in which the product of any two nonzero elements is nonzero. Integral domains are generalizations of the ring of integers and provide a natural setting for studying divisibility.  In an integral domain, every nonzero element a has the cancellation property, that is, if a ≠ 0, an equality ab = ac implies b = c.\n\"Integral domain\" is defined almost universally as above, but there is some variation. This article follows the convention that rings have a multiplicative identity, generally denoted 1, but some authors do not follow this, by not requiring integral domains to have a multiplicative identity. Noncommutative integral domains are sometimes admitted.  This article, however, follows the much more usual convention of reserving the term \"integral domain\" for the commutative case and using \"domain\" for the general case including noncommutative rings.\nSome sources, notably Lang, use the term entire ring for integral domain.\nSome specific kinds of integral domains are given with the following chain of class inclusions:\n\nrngs ⊃ rings ⊃ commutative rings ⊃  integral domains ⊃ integrally closed domains ⊃ GCD domains ⊃ unique factorization domains ⊃ principal ideal domains ⊃ euclidean domains ⊃ fields ⊃ algebraically closed fields\n\nDefinition\nAn integral domain is a nonzero commutative ring in which the product of any two nonzero elements is nonzero.  Equivalently:\n\nAn integral domain is a nonzero commutative ring with no nonzero zero divisors.\nAn integral domain is a commutative ring in which the zero ideal {0} is a prime ideal.\nAn integral domain is a nonzero commutative ring for which every nonzero element is cancellable under multiplication.\nAn integral domain is a ring for which the set of nonzero elements is a commutative monoid under multiplication (because a monoid must be  closed under multiplication).\nAn integral domain is a nonzero commutative ring in which for every nonzero element r, the function that maps each element x of the ring to the product xr is injective. Elements r with this property are called regular, so it is equivalent to require that every nonzero element of the ring be regular.\nAn integral domain is a ring that is isomorphic to a subring of a field.  (Given an integral domain, one can embed it in its field of fractions.)\n\nExamples\nThe archetypical example is the ring \n  \n    \n      \n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} }\n  \n of all integers.\nEvery field is an integral domain. For example, the field \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n of all real numbers is an integral domain.  Conversely, every Artinian integral domain is a field. In particular, all finite integral domains are finite fields (more generally, by Wedderburn's little theorem, finite domains are finite fields). The ring of integers \n  \n    \n      \n        \n          Z\n        \n      \n    \n    {\\displaystyle \\mathbb {Z} }\n  \n provides an example of a non-Artinian infinite integral domain that is not a field, possessing infinite descending sequences of ideals such as:\n\n  \n    \n      \n        \n          Z\n        \n        ⊃\n        2\n        \n          Z\n        \n        ⊃\n        ⋯\n        ⊃\n        \n          2\n          \n            n\n          \n        \n        \n          Z\n        \n        ⊃\n        \n          2\n          \n            n\n            +\n            1\n          \n        \n        \n          Z\n        \n        ⊃\n        ⋯\n      \n    \n    {\\displaystyle \\mathbb {Z} \\supset 2\\mathbb {Z} \\supset \\cdots \\supset 2^{n}\\mathbb {Z} \\supset 2^{n+1}\\mathbb {Z} \\supset \\cdots }\n  \n\nRings of polynomials are integral domains if the coefficients come from an integral domain. For instance, the ring \n  \n    \n      \n        \n          Z\n        \n        [\n        x\n        ]\n      \n    \n    {\\displaystyle \\mathbb {Z} [x]}\n  \n of all polynomials in one variable with integer coefficients is an integral domain; so is the ring \n  \n    \n      \n        \n          C\n        \n        [\n        \n          x\n          \n            1\n          \n        \n        ,\n        …\n        ,\n        \n          x\n          \n            n\n          \n        \n        ]\n      \n    \n    {\\displaystyle \\mathbb {C} [x_{1},\\ldots ,x_{n}]}\n  \n of all polynomials in n-variables with complex coefficients.\nThe previous example can be further exploited by taking quotients from prime ideals. For example, the ring \n  \n    \n      \n        \n          C\n        \n        [\n        x\n        ,\n        y\n        ]\n        \n          /\n        \n        (\n        \n          y\n          \n            2\n          \n        \n        −\n        x\n        (\n        x\n        −\n        1\n        )\n        (\n        x\n        −\n        2\n        )\n        )\n      \n    \n    {\\displaystyle \\mathbb {C} [x,y]/(y^{2}-x(x-1)(x-2))}\n  \n corresponding to a plane elliptic curve is an integral domain. Integrality can be checked by sh",
    "links": [
      "A K Peters",
      "Abelian group",
      "Affine algebraic set",
      "Affine scheme",
      "Algebra (Lang)",
      "Algebra over a field",
      "Algebraic geometry",
      "Algebraic number field",
      "Algebraic number theory",
      "Algebraic structure",
      "Algebraic variety",
      "Algebraically closed field",
      "American Journal of Mathematics",
      "Analytic function",
      "Artinian ring",
      "Associative algebra",
      "Bartel Leendert van der Waerden",
      "Bialgebra",
      "Bibcode (identifier)",
      "Boolean algebra (structure)",
      "Cambridge University Press",
      "Cancellation property",
      "Category of rings",
      "Characteristic (algebra)",
      "Clifford algebra",
      "Closure (mathematics)",
      "Commutative algebra",
      "Commutative ring",
      "Commutator (ring theory)",
      "Complemented lattice",
      "Complex number",
      "Composite number",
      "Composition algebra",
      "Connectedness",
      "Continuous function",
      "Coordinate ring",
      "Dedekind–Hasse norm",
      "Divisibility (ring theory)",
      "Division ring",
      "Doi (identifier)",
      "Domain (ring theory)",
      "Elliptic curve",
      "Euclidean domain",
      "Fiber product of schemes",
      "Field (mathematics)",
      "Field of fractions",
      "Finite field",
      "Formal power series",
      "Formal power series ring",
      "Fractional ideal"
    ],
    "categories": [
      "Category:All Wikipedia articles written in American English",
      "Category:Articles with short description",
      "Category:Commutative algebra",
      "Category:Pages that use a deprecated format of the math tags",
      "Category:Ring theory",
      "Category:Short description matches Wikidata",
      "Category:Use American English from March 2019"
    ]
  },
  "Intermediate value theorem": {
    "title": "Intermediate value theorem",
    "url": "https://en.wikipedia.org/wiki/Intermediate_value_theorem",
    "summary": "In mathematical analysis, the intermediate value theorem states that if \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n is a continuous function whose domain contains the interval [a, b], then it takes on any given value between \n  \n    \n      \n        f\n        (\n        a\n        )\n      \n    \n    {\\displaystyle f(a)}\n  \n and \n  \n    \n      \n        f\n        (\n        b\n        )\n      \n    \n    {\\displaystyle f(b)}\n  \n at some point within the interval.\nThis has two important corollaries:\n\nIf a continuous function has values of opposite sign inside an interval, then it has a root in that interval (Bolzano's theorem).\nThe image of a continuous function over an interval is itself an interval.",
    "content": "In mathematical analysis, the intermediate value theorem states that if \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n is a continuous function whose domain contains the interval [a, b], then it takes on any given value between \n  \n    \n      \n        f\n        (\n        a\n        )\n      \n    \n    {\\displaystyle f(a)}\n  \n and \n  \n    \n      \n        f\n        (\n        b\n        )\n      \n    \n    {\\displaystyle f(b)}\n  \n at some point within the interval.\nThis has two important corollaries:\n\nIf a continuous function has values of opposite sign inside an interval, then it has a root in that interval (Bolzano's theorem).\nThe image of a continuous function over an interval is itself an interval.\n\nMotivation\nThis captures an intuitive property of continuous functions over the real numbers: given \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n continuous on \n  \n    \n      \n        [\n        1\n        ,\n        2\n        ]\n      \n    \n    {\\displaystyle [1,2]}\n  \n with the known values \n  \n    \n      \n        f\n        (\n        1\n        )\n        =\n        3\n      \n    \n    {\\displaystyle f(1)=3}\n  \n and \n  \n    \n      \n        f\n        (\n        2\n        )\n        =\n        5\n      \n    \n    {\\displaystyle f(2)=5}\n  \n, then the graph of \n  \n    \n      \n        y\n        =\n        f\n        (\n        x\n        )\n      \n    \n    {\\displaystyle y=f(x)}\n  \n must pass through the horizontal line \n  \n    \n      \n        y\n        =\n        4\n      \n    \n    {\\displaystyle y=4}\n  \n while \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n moves from \n  \n    \n      \n        1\n      \n    \n    {\\displaystyle 1}\n  \n to \n  \n    \n      \n        2\n      \n    \n    {\\displaystyle 2}\n  \n. It represents the idea that the graph of a continuous function on a closed interval can be drawn without lifting a pencil from the paper.\n\nTheorem\nThe intermediate value theorem states the following:\nConsider the closed interval \n  \n    \n      \n        I\n        =\n        [\n        a\n        ,\n        b\n        ]\n      \n    \n    {\\displaystyle I=[a,b]}\n  \n of real numbers \n  \n    \n      \n        \n          R\n        \n      \n    \n    {\\displaystyle \\mathbb {R} }\n  \n and a continuous function \n  \n    \n      \n        f\n        :\n        I\n        →\n        \n          R\n        \n      \n    \n    {\\displaystyle f\\colon I\\to \\mathbb {R} }\n  \n. Then\n\nVersion I. if \n  \n    \n      \n        u\n      \n    \n    {\\displaystyle u}\n  \n is a number between \n  \n    \n      \n        f\n        (\n        a\n        )\n      \n    \n    {\\displaystyle f(a)}\n  \n and \n  \n    \n      \n        f\n        (\n        b\n        )\n      \n    \n    {\\displaystyle f(b)}\n  \n, that is, \n  \n    \n      \n        min\n        (\n        f\n        (\n        a\n        )\n        ,\n        f\n        (\n        b\n        )\n        )\n        <\n        u\n        <\n        max\n        (\n        f\n        (\n        a\n        )\n        ,\n        f\n        (\n        b\n        )\n        )\n        ,\n      \n    \n    {\\displaystyle \\min(f(a),f(b))<u<\\max(f(a),f(b)),}\n  \n then there is a \n  \n    \n      \n        c\n        ∈\n        (\n        a\n        ,\n        b\n        )\n      \n    \n    {\\displaystyle c\\in (a,b)}\n  \n such that \n  \n    \n      \n        f\n        (\n        c\n        )\n        =\n        u\n      \n    \n    {\\displaystyle f(c)=u}\n  \n.\nVersion II. the image set \n  \n    \n      \n        f\n        (\n        I\n        )\n      \n    \n    {\\displaystyle f(I)}\n  \n is also a closed interval, and it contains \n  \n    \n      \n        \n          \n            [\n          \n        \n        min\n        (\n        f\n        (\n        a\n        )\n        ,\n        f\n        (\n        b\n        )\n        )\n        ,\n        max\n        (\n        f\n        (\n        a\n        )\n        ,\n        f\n        (\n        b\n        )\n        )\n        \n          \n            ]\n          \n        \n      \n    \n    {\\displaystyle {\\bigl [}\\min(f(a),f(b)),\\max(f(a),f(b)){\\bigr ]}}\n  \n.\nRemark: Version II states that the set of function values has no gap. For any two function values \n  \n    \n      \n        c\n        ,\n        d\n        ∈\n        f\n        (\n        I\n        )\n      \n    \n    {\\displaystyle c,d\\in f(I)}\n  \n with \n  \n    \n      \n        c\n        <\n        d\n      \n    \n    {\\displaystyle c<d}\n  \n all points in the interval \n  \n    \n      \n        \n          \n            [\n          \n        \n        c\n        ,\n        d\n        \n          \n            ]\n          \n        \n      \n    \n    {\\displaystyle {\\bigl [}c,d{\\bigr ]}}\n  \n are also function values, \n  \n    \n      \n        \n          \n            [\n          \n        \n        c\n        ,\n        d\n        \n          \n            ]\n          \n        \n        ⊆\n        f\n        (\n        I\n        )\n        .\n      \n    \n    {\\displaystyle {\\bigl [}c,d{\\bigr ]}\\subseteq f(I).}\n  \n\nA subset of the real numbers with no internal gap is an interval. Version I is naturally contained in Version II.\n\nRelation to comp",
    "links": [
      "ArXiv (identifier)",
      "Augustin-Louis Cauchy",
      "Bernard Bolzano",
      "Borsuk–Ulam theorem",
      "Brouwer fixed-point theorem",
      "Bryson of Heraclea",
      "Closed interval",
      "Completeness (order theory)",
      "Completeness of the real numbers",
      "Connected space",
      "Connectedness (topology)",
      "Constant function",
      "Constructive mathematics",
      "Continuous function",
      "Conway's base 13 function",
      "Corollary",
      "Cubic function",
      "Cut-the-knot",
      "Darboux's theorem (analysis)",
      "Darboux function",
      "Derivative",
      "Doi (identifier)",
      "Domain of a function",
      "Edmund F. Robertson",
      "Eric W. Weisstein",
      "Foundations of Science",
      "Function (mathematics)",
      "Function of a real variable",
      "Hairy ball theorem",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "If and only if",
      "Image (mathematics)",
      "Image of a function",
      "Infinitesimal",
      "Interior (topology)",
      "Intermediate value property",
      "Interval (mathematics)",
      "Irrational numbers",
      "JSTOR (identifier)",
      "Joseph-Louis Lagrange",
      "Keith Devlin",
      "Knaster–Kuratowski–Mazurkiewicz lemma",
      "Limit of a function",
      "Louis Arbogast",
      "MR (identifier)",
      "MacTutor History of Mathematics Archive",
      "MathWorld",
      "Mathematical analysis",
      "Mean value theorem"
    ],
    "categories": [
      "Category:Articles containing proofs",
      "Category:Articles with short description",
      "Category:Short description is different from Wikidata",
      "Category:Theorems in calculus",
      "Category:Theorems in real analysis",
      "Category:Theory of continuous functions",
      "Category:Wikipedia articles needing clarification from January 2023"
    ]
  },
  "Algebraic numbers": {
    "title": "Algebraic number",
    "url": "https://en.wikipedia.org/wiki/Algebraic_number",
    "summary": "In mathematics, an algebraic number is a number that is a root of a non-zero polynomial in one variable with integer (or, equivalently, rational) coefficients.  For example, the golden ratio \n  \n    \n      \n        (\n        1\n        +\n        \n          \n            5\n          \n        \n        )\n        \n          /\n        \n        2\n      \n    \n    {\\displaystyle (1+{\\sqrt {5}})/2}\n  \n is an algebraic number, because it is a root of the polynomial \n  \n    \n      \n        \n          X\n          \n            2\n          \n        \n        −\n        X\n        −\n        1\n      \n    \n    {\\displaystyle X^{2}-X-1}\n  \n, i.e., a solution of the equation \n  \n    \n      \n        \n          x\n          \n            2\n          \n        \n        −\n        x\n        −\n        1\n        =\n        0\n      \n    \n    {\\displaystyle x^{2}-x-1=0}\n  \n, and the complex number \n  \n    \n      \n        1\n        +\n        i\n      \n    \n    {\\displaystyle 1+i}\n  \n is algebraic as a root of \n  \n    \n     ",
    "content": "In mathematics, an algebraic number is a number that is a root of a non-zero polynomial in one variable with integer (or, equivalently, rational) coefficients.  For example, the golden ratio \n  \n    \n      \n        (\n        1\n        +\n        \n          \n            5\n          \n        \n        )\n        \n          /\n        \n        2\n      \n    \n    {\\displaystyle (1+{\\sqrt {5}})/2}\n  \n is an algebraic number, because it is a root of the polynomial \n  \n    \n      \n        \n          X\n          \n            2\n          \n        \n        −\n        X\n        −\n        1\n      \n    \n    {\\displaystyle X^{2}-X-1}\n  \n, i.e., a solution of the equation \n  \n    \n      \n        \n          x\n          \n            2\n          \n        \n        −\n        x\n        −\n        1\n        =\n        0\n      \n    \n    {\\displaystyle x^{2}-x-1=0}\n  \n, and the complex number \n  \n    \n      \n        1\n        +\n        i\n      \n    \n    {\\displaystyle 1+i}\n  \n is algebraic as a root of \n  \n    \n      \n        \n          X\n          \n            4\n          \n        \n        +\n        4\n      \n    \n    {\\displaystyle X^{4}+4}\n  \n. Algebraic numbers include all integers, rational numbers, and n-th roots of integers.\nAlgebraic complex numbers are closed under addition, subtraction, multiplication and division, and hence form a field, denoted \n  \n    \n      \n        \n          \n            \n              Q\n            \n            ¯\n          \n        \n      \n    \n    {\\displaystyle {\\overline {\\mathbb {Q} }}}\n  \n. The set of algebraic real numbers \n  \n    \n      \n        \n          \n            \n              Q\n            \n            ¯\n          \n        \n        ∩\n        \n          R\n        \n      \n    \n    {\\displaystyle {\\overline {\\mathbb {Q} }}\\cap \\mathbb {R} }\n  \n is also a field.\nNumbers which are not algebraic are called transcendental and include π and e. There are countably many algebraic numbers, hence almost all real (or complex) numbers (in the sense of Lebesgue measure) are transcendental.\n\nExamples\nAll rational numbers are algebraic. Any rational number, expressed as the quotient of an integer a and a (non-zero) natural number b, satisfies the above definition, because x = ⁠a/b⁠ is the root of a non-zero polynomial, namely bx − a.\nQuadratic irrational numbers, irrational solutions of a quadratic polynomial ax2 + bx + c with integer coefficients a, b, and c, are algebraic numbers. If the quadratic polynomial is monic (a = 1), the roots are further qualified as quadratic integers.\nGaussian integers, complex numbers a + bi for which both a and b are integers, are also quadratic integers. This is because a + bi and a − bi are the two roots of the quadratic x2 − 2ax + a2 + b2.\nA constructible number can be constructed from a given unit length using a straightedge and compass. It includes all quadratic irrational roots, all rational numbers, and all numbers that can be formed from these using the basic arithmetic operations and the extraction of square roots. (By designating cardinal directions for +1, −1, +i, and −i, complex numbers such as \n  \n    \n      \n        3\n        +\n        i\n        \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle 3+i{\\sqrt {2}}}\n  \n are considered constructible.)\nAny expression formed from algebraic numbers using any finite combination of the basic arithmetic operations and extraction of nth roots gives another algebraic number.\nPolynomial roots that cannot be expressed in terms of the basic arithmetic operations and extraction of nth roots (such as the roots of x5 − x + 1). That happens with many but not all polynomials of degree 5 or higher.\nValues of trigonometric functions of rational multiples of π (except when undefined): for example, cos ⁠π/7⁠, cos ⁠3π/7⁠, and cos ⁠5π/7⁠ satisfy 8x3 − 4x2 − 4x + 1 = 0. This polynomial is irreducible over the rationals and so the three cosines are conjugate algebraic numbers. Likewise, tan ⁠3π/16⁠, tan ⁠7π/16⁠, tan ⁠11π/16⁠, and tan ⁠15π/16⁠ satisfy the irreducible polynomial x4 − 4x3 − 6x2 + 4x + 1 = 0, and so are conjugate algebraic integers. This is the equivalent of angles which, when measured in degrees, have rational numbers.\nSome but not all irrational numbers are algebraic:\nThe numbers \n  \n    \n      \n        \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle {\\sqrt {2}}}\n  \n and \n  \n    \n      \n        \n          \n            \n              3\n              \n                3\n              \n            \n            2\n          \n        \n      \n    \n    {\\displaystyle {\\frac {\\sqrt[{3}]{3}}{2}}}\n  \n are algebraic since they are roots of polynomials x2 − 2 and 8x3 − 3, respectively.\nThe golden ratio φ is algebraic since it is a root of the polynomial x2 − x − 1.\nThe numbers π and e are not algebraic numbers (see the Lindemann–Weierstrass theorem).\n\nProperties\nIf a polynomial with rational coefficients is multiplied through by the least common denominator, the resulting polynomial wit",
    "links": [
      "Abel–Ruffini theorem",
      "Addition",
      "Adele ring",
      "Algebra of physical space",
      "Algebraic closure",
      "Algebraic integer",
      "Algebraic number field",
      "Algebraic solution",
      "Algebraically closed field",
      "Almost all",
      "Almost everywhere",
      "Arithmetic operations",
      "Arithmetical numbers",
      "Bicomplex number",
      "Bioctonion",
      "Biquaternion",
      "Cardinal number",
      "Chebyshev nodes",
      "Clifford algebra",
      "Closed-form expression",
      "Closed-form number",
      "Complex number",
      "Complex plane",
      "Composition algebra",
      "Computable number",
      "Constructible number",
      "Countable set",
      "Cyclotomic field",
      "Dedekind domain",
      "Definable number",
      "Definable real number",
      "Degree of a field extension",
      "Degree of a polynomial",
      "Dense set",
      "Densely ordered",
      "Division (mathematics)",
      "Division algebra",
      "Doi (identifier)",
      "Doubling the cube",
      "Dual-complex number",
      "Dual number",
      "Dual quaternion",
      "E. M. Wright",
      "E (mathematical constant)",
      "Eisenstein integer",
      "Elementary number",
      "Extended natural numbers",
      "Extended real number line",
      "Field (mathematics)",
      "Finite set"
    ],
    "categories": [
      "Category:Algebraic numbers",
      "Category:Articles with short description",
      "Category:Short description matches Wikidata",
      "Category:Use shortened footnotes from September 2024",
      "Category:Wikipedia articles needing clarification from July 2024"
    ]
  },
  "Algebraically independent": {
    "title": "Algebraic independence",
    "url": "https://en.wikipedia.org/wiki/Algebraic_independence",
    "summary": "In abstract algebra, a subset \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n of a field \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  \n is algebraically independent over a subfield \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n if the elements of \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n do not satisfy any non-trivial polynomial equation with coefficients in \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n.\nIn particular, a one element set \n  \n    \n      \n        {\n        α\n        }\n      \n    \n    {\\displaystyle \\{\\alpha \\}}\n  \n is algebraically independent over \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n if and only if \n  \n    \n      \n        α\n      \n    \n    {\\displaystyle \\alpha }\n  \n is transcendental over \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n. In general, all the elements of an algebraically independent set \n  \n    \n      \n        S\n      \n    \n ",
    "content": "In abstract algebra, a subset \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n of a field \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  \n is algebraically independent over a subfield \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n if the elements of \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n do not satisfy any non-trivial polynomial equation with coefficients in \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n.\nIn particular, a one element set \n  \n    \n      \n        {\n        α\n        }\n      \n    \n    {\\displaystyle \\{\\alpha \\}}\n  \n is algebraically independent over \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n if and only if \n  \n    \n      \n        α\n      \n    \n    {\\displaystyle \\alpha }\n  \n is transcendental over \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n. In general, all the elements of an algebraically independent set \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n over \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n are by necessity transcendental over \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n, and over all of the field extensions over \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n generated by the remaining elements of \n  \n    \n      \n        S\n      \n    \n    {\\displaystyle S}\n  \n.\n\nExample\nThe real numbers \n  \n    \n      \n        \n          \n            π\n          \n        \n      \n    \n    {\\displaystyle {\\sqrt {\\pi }}}\n  \n and \n  \n    \n      \n        2\n        π\n        +\n        1\n      \n    \n    {\\displaystyle 2\\pi +1}\n  \n are transcendental numbers: they are not the roots of any nontrivial polynomial whose coefficients are rational numbers. Thus, the sets \n  \n    \n      \n        {\n        \n          \n            π\n          \n        \n        }\n      \n    \n    {\\displaystyle \\{{\\sqrt {\\pi }}\\}}\n  \n and \n  \n    \n      \n        {\n        2\n        π\n        +\n        1\n        }\n      \n    \n    {\\displaystyle \\{2\\pi +1\\}}\n  \n are both algebraically independent over the rational numbers.\nHowever, the set \n  \n    \n      \n        {\n        \n          \n            π\n          \n        \n        ,\n        2\n        π\n        +\n        1\n        }\n      \n    \n    {\\displaystyle \\{{\\sqrt {\\pi }},2\\pi +1\\}}\n  \n is not algebraically independent over the rational numbers \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n, because the nontrivial polynomial\n\n  \n    \n      \n        P\n        (\n        x\n        ,\n        y\n        )\n        =\n        2\n        \n          x\n          \n            2\n          \n        \n        −\n        y\n        +\n        1\n      \n    \n    {\\displaystyle P(x,y)=2x^{2}-y+1}\n  \n\nis zero when \n  \n    \n      \n        x\n        =\n        \n          \n            π\n          \n        \n      \n    \n    {\\displaystyle x={\\sqrt {\\pi }}}\n  \n and \n  \n    \n      \n        y\n        =\n        2\n        π\n        +\n        1\n      \n    \n    {\\displaystyle y=2\\pi +1}\n  \n.\n\nAlgebraic independence of known constants\nAlthough π and e are transcendental, it is not known whether \n  \n    \n      \n        {\n        π\n        ,\n        e\n        }\n      \n    \n    {\\displaystyle \\{\\pi ,e\\}}\n  \n is algebraically independent over \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n. In fact, it is not even known whether \n  \n    \n      \n        π\n        +\n        e\n      \n    \n    {\\displaystyle \\pi +e}\n  \n is irrational. Nesterenko proved in 1996 that:\n\nthe numbers \n  \n    \n      \n        π\n      \n    \n    {\\displaystyle \\pi }\n  \n, \n  \n    \n      \n        \n          e\n          \n            π\n          \n        \n      \n    \n    {\\displaystyle e^{\\pi }}\n  \n, and \n  \n    \n      \n        Γ\n        (\n        1\n        \n          /\n        \n        4\n        )\n      \n    \n    {\\displaystyle \\Gamma (1/4)}\n  \n, where \n  \n    \n      \n        Γ\n      \n    \n    {\\displaystyle \\Gamma }\n  \n is the gamma function, are algebraically independent over \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n;\nthe numbers \n  \n    \n      \n        \n          e\n          \n            π\n            \n              \n                3\n              \n            \n          \n        \n      \n    \n    {\\displaystyle e^{\\pi {\\sqrt {3}}}}\n  \n and \n  \n    \n      \n        Γ\n        (\n        1\n        \n          /\n        \n        3\n        )\n      \n    \n    {\\displaystyle \\Gamma (1/3)}\n  \n are algebraically independent over \n  \n    \n      \n        \n          Q\n        \n      \n    \n    {\\displaystyle \\mathbb {Q} }\n  \n;\nfor all positive integers \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n, the number \n  \n    \n      \n        \n          e\n          \n            π\n            \n              \n                n\n              \n            \n          \n        \n      \n    \n    {\\displaystyle e^{\\pi {\\sqrt {n}}}}\n",
    "links": [
      "Abstract algebra",
      "Algebraic matroid",
      "Algebraic number",
      "Algebraic number field",
      "Algebraic number theory",
      "Algebraic structure",
      "Associative algebra",
      "Ben J. Green",
      "Bulletin of the London Mathematical Society",
      "Cardinality",
      "Category of rings",
      "Clifford algebra",
      "Commutative algebra",
      "Commutative ring",
      "Commutator (ring theory)",
      "Complex numbers",
      "Comptes rendus de l'Académie des sciences",
      "Division ring",
      "Doi (identifier)",
      "E (mathematical constant)",
      "Euclidean domain",
      "Field (mathematics)",
      "Field extension",
      "Finite field",
      "Finite set",
      "Formal power series ring",
      "Fractional ideal",
      "Free algebra",
      "Free product of associative algebras",
      "Frobenius endomorphism",
      "GCD domain",
      "Gamma function",
      "Geometric algebra",
      "Graded ring",
      "ISBN (identifier)",
      "ISSN (identifier)",
      "Ideal (ring theory)",
      "If and only if",
      "Indeterminate (variable)",
      "Inner automorphism",
      "Integer",
      "Integers modulo n",
      "Integral domain",
      "Integrally closed domain",
      "Involutive ring",
      "Jordan ring",
      "Kernel (algebra)",
      "Lie ring",
      "Lindemann-Weierstrass theorem",
      "Lindemann–Weierstrass theorem"
    ],
    "categories": [
      "Category:Abstract algebra",
      "Category:All Wikipedia articles written in American English",
      "Category:Articles with short description",
      "Category:Matroid theory",
      "Category:Short description is different from Wikidata",
      "Category:Use American English from January 2019",
      "Category:Use mdy dates from September 2021",
      "Category:Wikipedia articles needing clarification from January 2025"
    ]
  },
  "Bessel function": {
    "title": "Bessel function",
    "url": "https://en.wikipedia.org/wiki/Bessel_function",
    "summary": "Bessel functions are mathematical special functions that commonly appear in problems involving wave motion, heat conduction, and other physical phenomena with circular symmetry or cylindrical symmetry. They are named after the German astronomer and mathematician Friedrich Bessel, who studied them systematically in 1824.\nBessel functions are solutions to a particular type of ordinary differential equation: \n  \n    \n      \n        \n          x\n          \n            2\n          \n        \n        \n          \n            \n              \n                d\n                \n                  2\n                \n              \n              y\n            \n            \n              d\n              \n                x\n                \n                  2\n                \n              \n            \n          \n        \n        +\n        x\n        \n          \n            \n              d\n              y\n            \n            \n              d\n              x\n            \n          \n        \n     ",
    "content": "Bessel functions are mathematical special functions that commonly appear in problems involving wave motion, heat conduction, and other physical phenomena with circular symmetry or cylindrical symmetry. They are named after the German astronomer and mathematician Friedrich Bessel, who studied them systematically in 1824.\nBessel functions are solutions to a particular type of ordinary differential equation: \n  \n    \n      \n        \n          x\n          \n            2\n          \n        \n        \n          \n            \n              \n                d\n                \n                  2\n                \n              \n              y\n            \n            \n              d\n              \n                x\n                \n                  2\n                \n              \n            \n          \n        \n        +\n        x\n        \n          \n            \n              d\n              y\n            \n            \n              d\n              x\n            \n          \n        \n        +\n        \n          (\n          \n            \n              x\n              \n                2\n              \n            \n            −\n            \n              α\n              \n                2\n              \n            \n          \n          )\n        \n        y\n        =\n        0\n        ,\n      \n    \n    {\\displaystyle x^{2}{\\frac {d^{2}y}{dx^{2}}}+x{\\frac {dy}{dx}}+\\left(x^{2}-\\alpha ^{2}\\right)y=0,}\n  \n where \n  \n    \n      \n        α\n      \n    \n    {\\displaystyle \\alpha }\n  \n is a number that determines the shape of the solution. This number is called the order of the Bessel function and can be any complex number. Although the same equation arises for both \n  \n    \n      \n        α\n      \n    \n    {\\displaystyle \\alpha }\n  \n and \n  \n    \n      \n        −\n        α\n      \n    \n    {\\displaystyle -\\alpha }\n  \n, mathematicians define separate Bessel functions for each to ensure the functions behave smoothly as the order changes.\nThe most important cases are when \n  \n    \n      \n        α\n      \n    \n    {\\displaystyle \\alpha }\n  \n is an integer or a half-integer. When \n  \n    \n      \n        α\n      \n    \n    {\\displaystyle \\alpha }\n  \n is an integer, the resulting Bessel functions are often called cylinder functions or cylindrical harmonics because they naturally arise when solving problems (like Laplace's equation) in cylindrical coordinates. When \n  \n    \n      \n        α\n      \n    \n    {\\displaystyle \\alpha }\n  \n is a half-integer, the solutions are called spherical Bessel functions and are used in spherical systems, such as in solving the Helmholtz equation in spherical coordinates.\n\nApplications\nBessel's equation arises when finding separable solutions to Laplace's equation and the Helmholtz equation in cylindrical or spherical coordinates. Bessel functions are therefore especially important for many problems of wave propagation and static potentials. In solving problems in cylindrical coordinate systems, one obtains Bessel functions of integer order (α = n); in spherical problems, one obtains half-integer orders (α = n + 1/2). For example:\n\nElectromagnetic waves in a cylindrical waveguide\nPressure amplitudes of inviscid rotational flows\nHeat conduction in a cylindrical object\nModes of vibration of a thin circular or annular acoustic membrane (such as a drumhead or other membranophone) or thicker plates such as sheet metal (see Kirchhoff–Love plate theory, Mindlin–Reissner plate theory)\nDiffusion problems on a lattice\nSolutions to the Schrödinger equation in spherical and cylindrical coordinates for a free particle\nPosition space representation of the Feynman propagator in quantum field theory\nSolving for patterns of acoustical radiation\nFrequency-dependent friction in circular pipelines\nDynamics of floating bodies\nAngular resolution\nDiffraction from helical objects, including DNA\nProbability density function of product of two normally distributed random variables\nAnalyzing of the surface waves generated by microtremors, in geophysics and seismology.\nBessel functions also appear in other problems, such as signal processing (e.g., see FM audio synthesis, Kaiser window, or Bessel filter).\n\nDefinitions\nBecause this is a linear differential equation, solutions can be scaled to any amplitude.  The amplitudes chosen for the functions originate from the early work in which the functions appeared as solutions to definite integrals rather than solutions to differential equations.  Because the differential equation is second-order, there must be two linearly independent solutions: one of the first kind and one of the second kind. Depending upon the circumstances, however, various formulations of these solutions are convenient. Different variations are summarized in the table below and described in the following sections.The subscript n is typically used in place of \n  \n    \n      \n        α\n      \n    \n    {\\displaystyle \\alpha }\n  \n when \n  \n    \n      \n        α\n      \n    \n    {\\displaystyle \\alpha }\n  \n is known",
    "links": [
      "A Course of Modern Analysis",
      "Abel's identity",
      "Abramowitz and Stegun",
      "Academic Press, Inc.",
      "Acoustic membrane",
      "Alfred Barnard Basset",
      "Anger function",
      "Angular resolution",
      "ArXiv (identifier)",
      "Asymptotic analysis",
      "Asymptotic expansion",
      "Bessel filter",
      "Bessel polynomials",
      "Bessel–Clifford function",
      "Bessel–Maitland function",
      "Bibcode (identifier)",
      "Boxcar function",
      "Buckling",
      "Carl Friedrich Gauss",
      "Carl Ludwig Siegel",
      "Carl Neumann",
      "Circular symmetry",
      "Complex number",
      "Complex plane",
      "Conduction (heat)",
      "Cosine",
      "Cylindrical harmonics",
      "Cylindrical symmetry",
      "D'Alembert's formula",
      "DNA",
      "Daniel Bernoulli",
      "Digamma function",
      "Digital Library of Mathematical Functions",
      "Dirac delta function",
      "Distribution (mathematics)",
      "Doi (identifier)",
      "Drumhead",
      "Edmund T. Whittaker",
      "Electromagnetic radiation",
      "Electromagnetic wave equation",
      "Encyclopedia of Mathematics",
      "Entire function",
      "Eric W. Weisstein",
      "Eta (letter)",
      "Euler's constant",
      "Euler's critical load",
      "Euler's formula",
      "Euler–Mascheroni constant",
      "European Mathematical Society",
      "Exponential decay"
    ],
    "categories": [
      "Category:All Wikipedia articles written in American English",
      "Category:Articles with short description",
      "Category:CS1 German-language sources (de)",
      "Category:Fourier analysis",
      "Category:Short description matches Wikidata",
      "Category:Special hypergeometric functions",
      "Category:Use American English from January 2019"
    ]
  },
  "Exponential function": {
    "title": "Exponential function",
    "url": "https://en.wikipedia.org/wiki/Exponential_function",
    "summary": "In mathematics, the exponential function is the unique real function which maps zero to one and has a derivative everywhere equal to its value. The exponential of a variable ⁠\n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n⁠ is denoted ⁠\n  \n    \n      \n        exp\n        ⁡\n        x\n      \n    \n    {\\displaystyle \\exp x}\n  \n⁠ or ⁠\n  \n    \n      \n        \n          e\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle e^{x}}\n  \n⁠, with the two notations used interchangeably. It is called exponential because its argument can be seen as an exponent to which a constant number e ≈ 2.718, the base, is raised. There are several other definitions of the exponential function, which are all equivalent although being of very different nature.\nThe exponential function converts sums to products: it maps the additive identity 0 to the multiplicative identity 1, and the exponential of a sum is equal to the product of separate exponentials, ⁠\n  \n    \n      \n    ",
    "content": "In mathematics, the exponential function is the unique real function which maps zero to one and has a derivative everywhere equal to its value. The exponential of a variable ⁠\n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n⁠ is denoted ⁠\n  \n    \n      \n        exp\n        ⁡\n        x\n      \n    \n    {\\displaystyle \\exp x}\n  \n⁠ or ⁠\n  \n    \n      \n        \n          e\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle e^{x}}\n  \n⁠, with the two notations used interchangeably. It is called exponential because its argument can be seen as an exponent to which a constant number e ≈ 2.718, the base, is raised. There are several other definitions of the exponential function, which are all equivalent although being of very different nature.\nThe exponential function converts sums to products: it maps the additive identity 0 to the multiplicative identity 1, and the exponential of a sum is equal to the product of separate exponentials, ⁠\n  \n    \n      \n        exp\n        ⁡\n        (\n        x\n        +\n        y\n        )\n        =\n        exp\n        ⁡\n        x\n        ⋅\n        exp\n        ⁡\n        y\n      \n    \n    {\\displaystyle \\exp(x+y)=\\exp x\\cdot \\exp y}\n  \n⁠. Its inverse function, the natural logarithm, ⁠\n  \n    \n      \n        ln\n      \n    \n    {\\displaystyle \\ln }\n  \n⁠ or ⁠\n  \n    \n      \n        log\n      \n    \n    {\\displaystyle \\log }\n  \n⁠, converts products to sums: ⁠\n  \n    \n      \n        ln\n        ⁡\n        (\n        x\n        ⋅\n        y\n        )\n        =\n        ln\n        ⁡\n        x\n        +\n        ln\n        ⁡\n        y\n      \n    \n    {\\displaystyle \\ln(x\\cdot y)=\\ln x+\\ln y}\n  \n⁠.\nThe exponential function is occasionally called the natural exponential function, matching the name natural logarithm, for distinguishing it from some other functions that are also commonly called exponential functions. These functions include the functions of the form ⁠\n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        \n          b\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle f(x)=b^{x}}\n  \n⁠, which is exponentiation with a fixed base ⁠\n  \n    \n      \n        b\n      \n    \n    {\\displaystyle b}\n  \n⁠. More generally, and especially in applications, functions of the general form ⁠\n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        a\n        \n          b\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle f(x)=ab^{x}}\n  \n⁠ are also called exponential functions. They grow or decay exponentially in that the rate that ⁠\n  \n    \n      \n        f\n        (\n        x\n        )\n      \n    \n    {\\displaystyle f(x)}\n  \n⁠ changes when ⁠\n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n⁠ is increased is proportional to the current value of ⁠\n  \n    \n      \n        f\n        (\n        x\n        )\n      \n    \n    {\\displaystyle f(x)}\n  \n⁠.\nThe exponential function can be generalized to accept complex numbers as arguments. This reveals relations between multiplication of complex numbers, rotations in the complex plane, and trigonometry. Euler's formula ⁠\n  \n    \n      \n        exp\n        ⁡\n        i\n        θ\n        =\n        cos\n        ⁡\n        θ\n        +\n        i\n        sin\n        ⁡\n        θ\n      \n    \n    {\\displaystyle \\exp i\\theta =\\cos \\theta +i\\sin \\theta }\n  \n⁠ expresses and summarizes these relations.\nThe exponential function can be even further generalized to accept other types of arguments, such as matrices and elements of Lie algebras.\n\nGraph\nThe graph of \n  \n    \n      \n        y\n        =\n        \n          e\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle y=e^{x}}\n  \n is upward-sloping, and increases faster than every power of ⁠\n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n⁠. The graph always lies above the x-axis, but becomes arbitrarily close to it for large negative x; thus, the x-axis is a horizontal asymptote. The equation \n  \n    \n      \n        \n          \n            \n              d\n              \n                d\n                x\n              \n            \n          \n        \n        \n          e\n          \n            x\n          \n        \n        =\n        \n          e\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle {\\tfrac {d}{dx}}e^{x}=e^{x}}\n  \n means that the slope of the tangent to the graph at each point is equal to its height (its y-coordinate) at that point.\n\nDefinitions and fundamental properties\nThere are several equivalent definitions of the exponential function, although of very different nature.\n\nDifferential equation\nOne of the simplest definitions is: The exponential function is the unique differentiable function that equals its derivative, and takes the value 1 for the value 0 of its variable.\nThis \"conceptual\" definition requires a uniqueness proof and an existence proof, but it allows an easy derivation of the main properties of the exponential ",
    "links": [
      "(ε, δ)-definition of limit",
      "0",
      "1",
      "Abel's test",
      "Absolutely convergent",
      "Addison Wesley",
      "Additive identity",
      "Adequality",
      "Alternating series",
      "Alternating series test",
      "Antiderivative",
      "Arc length",
      "Argument (complex analysis)",
      "Arithmetico-geometric sequence",
      "Asymptote",
      "Baker–Campbell–Hausdorff formula",
      "Banach algebra",
      "Berkeley UNIX 4.3BSD",
      "Bernoulli number",
      "Binomial series",
      "Binomial theorem",
      "Brook Taylor",
      "C99",
      "Calculus",
      "Carlitz exponential",
      "Cauchy condensation test",
      "Chain rule",
      "Characterizations of the exponential function",
      "Codomain",
      "Colin Maclaurin",
      "Complex conjugate",
      "Complex derivative",
      "Complex function",
      "Complex logarithm",
      "Complex number",
      "Complex plane",
      "Compound interest",
      "Computer algebra system",
      "Concave function",
      "Constant of integration",
      "Continued fraction",
      "Continuous function",
      "Contour integral",
      "Curl (mathematics)",
      "Curvature",
      "Derivative",
      "Derivative (mathematics)",
      "Differentiable function",
      "Differential (mathematics)",
      "Differential calculus"
    ],
    "categories": [
      "Category:Analytic functions",
      "Category:Articles with short description",
      "Category:E (mathematical constant)",
      "Category:Elementary special functions",
      "Category:Exponentials",
      "Category:Pages that use a deprecated format of the math tags",
      "Category:Short description is different from Wikidata",
      "Category:Special hypergeometric functions",
      "Category:Use dmy dates from August 2019"
    ]
  },
  "Gamma function": {
    "title": "Gamma function",
    "url": "https://en.wikipedia.org/wiki/Gamma_function",
    "summary": "In mathematics, the gamma function (represented by Γ, capital Greek letter gamma) is the most common extension of the factorial function to complex numbers. Derived by Daniel Bernoulli, the gamma function \n  \n    \n      \n        Γ\n        (\n        z\n        )\n      \n    \n    {\\displaystyle \\Gamma (z)}\n  \n is defined for all complex numbers \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n  \n except non-positive integers, and \n  \n    \n      \n        Γ\n        (\n        n\n        )\n        =\n        (\n        n\n        −\n        1\n        )\n        !\n      \n    \n    {\\displaystyle \\Gamma (n)=(n-1)!}\n  \n for every positive integer ⁠\n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n⁠. The gamma function can be defined via a convergent improper integral for complex numbers with positive real part:\n\n  \n    \n      \n        Γ\n        (\n        z\n        )\n        =\n        \n          ∫\n          \n            0\n          \n          \n            ∞\n          \n        \n   ",
    "content": "In mathematics, the gamma function (represented by Γ, capital Greek letter gamma) is the most common extension of the factorial function to complex numbers. Derived by Daniel Bernoulli, the gamma function \n  \n    \n      \n        Γ\n        (\n        z\n        )\n      \n    \n    {\\displaystyle \\Gamma (z)}\n  \n is defined for all complex numbers \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n  \n except non-positive integers, and \n  \n    \n      \n        Γ\n        (\n        n\n        )\n        =\n        (\n        n\n        −\n        1\n        )\n        !\n      \n    \n    {\\displaystyle \\Gamma (n)=(n-1)!}\n  \n for every positive integer ⁠\n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n⁠. The gamma function can be defined via a convergent improper integral for complex numbers with positive real part:\n\n  \n    \n      \n        Γ\n        (\n        z\n        )\n        =\n        \n          ∫\n          \n            0\n          \n          \n            ∞\n          \n        \n        \n          t\n          \n            z\n            −\n            1\n          \n        \n        \n          e\n          \n            −\n            t\n          \n        \n        \n           d\n        \n        t\n        ,\n         \n        \n        ℜ\n        (\n        z\n        )\n        >\n        0\n        \n        .\n      \n    \n    {\\displaystyle \\Gamma (z)=\\int _{0}^{\\infty }t^{z-1}e^{-t}{\\text{ d}}t,\\ \\qquad \\Re (z)>0\\,.}\n  \nThe gamma function then is defined in the complex plane as the analytic continuation of this integral function: it is a meromorphic function which is holomorphic except at zero and the negative integers, where it has simple poles.\nThe gamma function has no zeros, so the reciprocal gamma function ⁠1/Γ(z)⁠ is an entire function. In fact, the gamma function corresponds to the Mellin transform of the negative exponential function:\n\n  \n    \n      \n        Γ\n        (\n        z\n        )\n        =\n        \n          \n            M\n          \n        \n        {\n        \n          e\n          \n            −\n            x\n          \n        \n        }\n        (\n        z\n        )\n        \n        .\n      \n    \n    {\\displaystyle \\Gamma (z)={\\mathcal {M}}\\{e^{-x}\\}(z)\\,.}\n  \n\nOther extensions of the factorial function do exist, but the gamma function is the most popular and useful. It appears as a factor in various probability-distribution functions and other formulas in the fields of probability, statistics, analytic number theory, and combinatorics.\n\nMotivation\nThe gamma function can be seen as a solution to the interpolation problem of finding a smooth curve \n  \n    \n      \n        y\n        =\n        f\n        (\n        x\n        )\n      \n    \n    {\\displaystyle y=f(x)}\n  \n that connects the points of the factorial sequence: \n  \n    \n      \n        (\n        x\n        ,\n        y\n        )\n        =\n        (\n        n\n        ,\n        n\n        !\n        )\n      \n    \n    {\\displaystyle (x,y)=(n,n!)}\n  \n for all positive integer values of ⁠\n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n⁠. The simple formula for the factorial, x! = 1 × 2 × ⋯ × x is only valid when x is a positive integer, and no elementary function has this property, but a good solution is the gamma function ⁠\n  \n    \n      \n        f\n        (\n        x\n        )\n        =\n        Γ\n        (\n        x\n        +\n        1\n        )\n      \n    \n    {\\displaystyle f(x)=\\Gamma (x+1)}\n  \n⁠.\nThe gamma function is not only smooth but analytic (except at the non-positive integers), and it can be defined in several explicit ways. However, it is not the only analytic function that extends the factorial, as one may add any analytic function that is zero on the positive integers, such as \n  \n    \n      \n        k\n        sin\n        ⁡\n        (\n        m\n        π\n        x\n        )\n      \n    \n    {\\displaystyle k\\sin(m\\pi x)}\n  \n for an integer ⁠\n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n  \n⁠. Such a function is known as a pseudogamma function, the most famous being the Hadamard function.\n\nA more restrictive requirement is the functional equation which interpolates the shifted factorial \n  \n    \n      \n        f\n        (\n        n\n        )\n        =\n        (\n        n\n        \n          −\n        \n        1\n        )\n        !\n      \n    \n    {\\displaystyle f(n)=(n{-}1)!}\n  \n :\n\n  \n    \n      \n        f\n        (\n        x\n        +\n        1\n        )\n        =\n        x\n        f\n        (\n        x\n        )\n         \n        \n           for all \n        \n        x\n        >\n        0\n        ,\n        \n        f\n        (\n        1\n        )\n        =\n        1.\n      \n    \n    {\\displaystyle f(x+1)=xf(x)\\ {\\text{ for all }}x>0,\\qquad f(1)=1.}\n  \n\nBut this still does not give a unique solution, since it allows for multiplication by any periodic function \n  \n    \n      \n        g\n        (\n        x\n        )\n      \n    \n    {\\displaystyle g(x)}\n  \n with \n  \n    \n      \n        g\n        (\n        x\n        ",
    "links": [
      "A Course of Modern Analysis",
      "Abramowitz and Stegun",
      "Absolute convergence",
      "Adrien-Marie Legendre",
      "Algebraic differential equation",
      "Algebraic independence",
      "American Mathematical Monthly",
      "Analytic continuation",
      "Analytic function",
      "Analytic number theory",
      "ArXiv (identifier)",
      "Arc length",
      "Arithmetic–geometric mean",
      "Ascending factorial",
      "Astrophysics",
      "Barnes G-function",
      "Barnes integral",
      "Bell polynomials",
      "Bernhard Riemann",
      "Bernoulli numbers",
      "Beta function",
      "Bibcode (identifier)",
      "Binomial coefficient",
      "Bohr–Mollerup theorem",
      "Bourbaki group",
      "C (programming language)",
      "Cahen–Mellin integral",
      "Carl Friedrich Gauss",
      "Carl Johan Malmsten",
      "Character (mathematics)",
      "Charles Hermite",
      "Chauvenet Prize",
      "Christian Goldbach",
      "Citizendium",
      "Closed-form expression",
      "Combinatorics",
      "Complex analysis",
      "Complex number",
      "Computer algebra system",
      "Continued fraction",
      "Contour integral",
      "Convex function",
      "Cornelius Lanczos",
      "Cubic Hermite spline",
      "Daniel Bernoulli",
      "Differential equation",
      "Differentiation under the integral sign",
      "Digamma function",
      "Digital Library of Mathematical Functions",
      "Division by zero"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:CS1: long volume value",
      "Category:CS1 errors: ISBN date",
      "Category:CS1 maint: location",
      "Category:Commons category link is on Wikidata",
      "Category:Gamma and related functions",
      "Category:Meromorphic functions",
      "Category:Short description is different from Wikidata",
      "Category:Special hypergeometric functions",
      "Category:Use dmy dates from December 2016"
    ]
  },
  "Hyperbolic function": {
    "title": "Hyperbolic functions",
    "url": "https://en.wikipedia.org/wiki/Hyperbolic_functions",
    "summary": "In mathematics, hyperbolic functions are analogues of the ordinary trigonometric functions, but defined using the hyperbola rather than the circle. Just as the points (cos t, sin t) form a circle with a unit radius, the points (cosh t, sinh t) form the right half of the unit hyperbola. Also, similarly to how the derivatives of sin(t) and cos(t) are cos(t) and –sin(t) respectively, the derivatives of sinh(t) and cosh(t) are cosh(t) and sinh(t) respectively.\nHyperbolic functions are used to express the angle of parallelism in hyperbolic geometry. They are used to express Lorentz boosts as hyperbolic rotations in special relativity. They also occur in the solutions of many linear differential equations (such as the equation defining a catenary), cubic equations, and Laplace's equation in Cartesian coordinates. Laplace's equations are important in many areas of physics, including electromagnetic theory, heat transfer, and fluid dynamics.\nThe basic hyperbolic functions are:\n\nhyperbolic sine",
    "content": "In mathematics, hyperbolic functions are analogues of the ordinary trigonometric functions, but defined using the hyperbola rather than the circle. Just as the points (cos t, sin t) form a circle with a unit radius, the points (cosh t, sinh t) form the right half of the unit hyperbola. Also, similarly to how the derivatives of sin(t) and cos(t) are cos(t) and –sin(t) respectively, the derivatives of sinh(t) and cosh(t) are cosh(t) and sinh(t) respectively.\nHyperbolic functions are used to express the angle of parallelism in hyperbolic geometry. They are used to express Lorentz boosts as hyperbolic rotations in special relativity. They also occur in the solutions of many linear differential equations (such as the equation defining a catenary), cubic equations, and Laplace's equation in Cartesian coordinates. Laplace's equations are important in many areas of physics, including electromagnetic theory, heat transfer, and fluid dynamics.\nThe basic hyperbolic functions are:\n\nhyperbolic sine \"sinh\" (),\nhyperbolic cosine \"cosh\" (),\nfrom which are derived:\n\nhyperbolic tangent \"tanh\" (),\nhyperbolic cotangent \"coth\" (),\nhyperbolic secant \"sech\" (),\nhyperbolic cosecant \"csch\" or \"cosech\" ()\ncorresponding to the derived trigonometric functions.\nThe inverse hyperbolic functions are:\n\ninverse hyperbolic sine \"arsinh\" (also denoted \"sinh−1\", \"asinh\" or sometimes \"arcsinh\")\ninverse hyperbolic cosine \"arcosh\" (also denoted \"cosh−1\", \"acosh\" or sometimes \"arccosh\")\ninverse hyperbolic tangent \"artanh\" (also denoted \"tanh−1\", \"atanh\" or sometimes \"arctanh\")\ninverse hyperbolic cotangent \"arcoth\" (also denoted \"coth−1\", \"acoth\" or sometimes \"arccoth\")\ninverse hyperbolic secant \"arsech\" (also denoted \"sech−1\", \"asech\" or sometimes \"arcsech\")\ninverse hyperbolic cosecant \"arcsch\" (also denoted \"arcosech\", \"csch−1\", \"cosech−1\",\"acsch\", \"acosech\", or sometimes \"arccsch\" or \"arccosech\")\n\nThe hyperbolic functions take a real argument called a hyperbolic angle. The magnitude of a hyperbolic angle is the area of its hyperbolic sector to xy = 1. The hyperbolic functions may be defined in terms of the legs of a right triangle covering this sector.\nIn complex analysis, the hyperbolic functions arise when applying the ordinary sine and cosine functions to an imaginary angle. The hyperbolic sine and the hyperbolic cosine are entire functions. As a result, the other hyperbolic functions are meromorphic in the whole complex plane.\nBy Lindemann–Weierstrass theorem, the hyperbolic functions have a transcendental value for every non-zero algebraic value of the argument.\n\nHistory\nThe first known calculation of a hyperbolic trigonometry problem is attributed to Gerardus Mercator when issuing the Mercator map projection circa 1566. It requires tabulating solutions to a transcendental equation involving hyperbolic functions.\nThe first to suggest a similarity between the sector of the circle and that of the hyperbola was Isaac Newton in his 1687 Principia Mathematica.\nRoger Cotes suggested to modify the trigonometric functions using the imaginary unit \n  \n    \n      \n        i\n        =\n        \n          \n            −\n            1\n          \n        \n      \n    \n    {\\displaystyle i={\\sqrt {-1}}}\n  \n to obtain an oblate spheroid from a prolate one.\nHyperbolic functions were formally introduced in 1757 by Vincenzo Riccati. Riccati used Sc. and Cc. (sinus/cosinus circulare) to refer to circular functions and Sh. and Ch. (sinus/cosinus hyperbolico) to refer to hyperbolic functions. As early as 1759, Daviet de Foncenex showed the interchangeability of the trigonometric and hyperbolic functions using the imaginary unit and extended de Moivre's formula to hyperbolic functions.\nDuring the 1760s, Johann Heinrich Lambert systematized the use functions and provided exponential expressions in various publications. Lambert credited Riccati for the terminology and names of the functions, but altered the abbreviations to those used today.\n\nNotation\nDefinitions\nWith hyperbolic angle u, the hyperbolic functions sinh and cosh can defined with the exponential function eu. In the figure\n\n  \n    \n      \n        A\n        =\n        (\n        \n          e\n          \n            −\n            u\n          \n        \n        ,\n        \n          e\n          \n            u\n          \n        \n        )\n        ,\n         \n        B\n        =\n        (\n        \n          e\n          \n            u\n          \n        \n        ,\n         \n        \n          e\n          \n            −\n            u\n          \n        \n        )\n        ,\n         \n        O\n        A\n        +\n        O\n        B\n        =\n        O\n        C\n      \n    \n    {\\displaystyle A=(e^{-u},e^{u}),\\ B=(e^{u},\\ e^{-u}),\\ OA+OB=OC}\n  \n .\n\nExponential definitions\nHyperbolic sine: the odd part of the exponential function, that is, \n  \n    \n      \n        sinh\n        ⁡\n        x\n        =\n        \n          \n            \n              \n                e\n                \n                  x\n                \n ",
    "links": [
      "Abramowitz and Stegun",
      "Algebraic number",
      "Angle",
      "Angle of parallelism",
      "Arc length",
      "Area",
      "Area under the curve",
      "Argument of a function",
      "Arithmetic mean",
      "Atan2",
      "Bernoulli number",
      "Bulletin of the American Mathematical Society",
      "Cartesian coordinates",
      "Catenary",
      "Circle",
      "Circular function",
      "Circular sector",
      "Complex analysis",
      "Complex number",
      "Constant of integration",
      "Convergent series",
      "Cubic equation",
      "De Moivre's formula",
      "Differential equation",
      "Digital Library of Mathematical Functions",
      "Doi (identifier)",
      "Domain of convergence",
      "Dover Publications",
      "E (mathematical constant)",
      "Electromagnetic theory",
      "Encyclopedia of Mathematics",
      "Entire function",
      "Equal incircles theorem",
      "Eric W. Weisstein",
      "Euler's formula",
      "Euler number",
      "European Mathematical Society",
      "Even function",
      "Even part of a function",
      "Even–odd decomposition",
      "Exponential function",
      "Exsecant",
      "Fluid dynamics",
      "Frank W. J. Olver",
      "François Daviet de Foncenex",
      "General complex exponential function",
      "Gerardus Mercator",
      "Google Books",
      "Gudermannian function",
      "Heat transfer"
    ],
    "categories": [
      "Category:Analytic functions",
      "Category:Articles containing Latin-language text",
      "Category:Articles with short description",
      "Category:Commons category link is on Wikidata",
      "Category:Exponentials",
      "Category:Hyperbolic functions",
      "Category:Hyperbolic geometry",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Inverse hyperbolic functions": {
    "title": "Inverse hyperbolic functions",
    "url": "https://en.wikipedia.org/wiki/Inverse_hyperbolic_functions",
    "summary": "In mathematics, the inverse hyperbolic functions are inverses of the hyperbolic functions, analogous to the inverse circular functions. There are six in common use: inverse hyperbolic sine, inverse hyperbolic cosine, inverse hyperbolic tangent, inverse hyperbolic cosecant, inverse hyperbolic secant, and inverse hyperbolic cotangent. They are commonly denoted by the symbols for the hyperbolic functions, prefixed with arc- or ar- or with a superscript \n  \n    \n      \n        \n          −\n          1\n        \n      \n    \n    {\\displaystyle {-1}}\n  \n (for example arcsinh, arsinh, or \n  \n    \n      \n        \n          sinh\n          \n            −\n            1\n          \n        \n      \n    \n    {\\displaystyle \\sinh ^{-1}}\n  \n).\nFor a given value of a hyperbolic function, the inverse hyperbolic function provides the corresponding hyperbolic angle measure, for example \n  \n    \n      \n        arsinh\n        ⁡\n        (\n        sinh\n        ⁡\n        a\n        )\n        =\n        a\n      \n   ",
    "content": "In mathematics, the inverse hyperbolic functions are inverses of the hyperbolic functions, analogous to the inverse circular functions. There are six in common use: inverse hyperbolic sine, inverse hyperbolic cosine, inverse hyperbolic tangent, inverse hyperbolic cosecant, inverse hyperbolic secant, and inverse hyperbolic cotangent. They are commonly denoted by the symbols for the hyperbolic functions, prefixed with arc- or ar- or with a superscript \n  \n    \n      \n        \n          −\n          1\n        \n      \n    \n    {\\displaystyle {-1}}\n  \n (for example arcsinh, arsinh, or \n  \n    \n      \n        \n          sinh\n          \n            −\n            1\n          \n        \n      \n    \n    {\\displaystyle \\sinh ^{-1}}\n  \n).\nFor a given value of a hyperbolic function, the inverse hyperbolic function provides the corresponding hyperbolic angle measure, for example \n  \n    \n      \n        arsinh\n        ⁡\n        (\n        sinh\n        ⁡\n        a\n        )\n        =\n        a\n      \n    \n    {\\displaystyle \\operatorname {arsinh} (\\sinh a)=a}\n  \n and \n  \n    \n      \n        sinh\n        ⁡\n        (\n        arsinh\n        ⁡\n        x\n        )\n        =\n        x\n        .\n      \n    \n    {\\displaystyle \\sinh(\\operatorname {arsinh} x)=x.}\n  \n  Hyperbolic angle measure is the length of an arc of a unit hyperbola \n  \n    \n      \n        \n          x\n          \n            2\n          \n        \n        −\n        \n          y\n          \n            2\n          \n        \n        =\n        1\n      \n    \n    {\\displaystyle x^{2}-y^{2}=1}\n  \n as measured in the Lorentzian plane (not the length of a hyperbolic arc in the Euclidean plane), and twice the area of the corresponding hyperbolic sector. This is analogous to the way circular angle measure is the arc length of an arc of the unit circle in the Euclidean plane or twice the area of the corresponding circular sector. Alternately hyperbolic angle is the area of a sector of the hyperbola \n  \n    \n      \n        x\n        y\n        =\n        1.\n      \n    \n    {\\displaystyle xy=1.}\n  \n Some authors call the inverse hyperbolic functions hyperbolic area functions.\nHyperbolic functions occur in the calculation of angles and distances in hyperbolic geometry. They also occur in the solutions of many linear differential equations (such as the equation defining a catenary), cubic equations, and Laplace's equation in Cartesian coordinates. Laplace's equations are important in many areas of physics, including electromagnetic theory, heat transfer, fluid dynamics, and special relativity.\n\nNotation\nThe earliest and most widely adopted symbols use the prefix arc- (that is: arcsinh, arccosh,  arctanh,  arcsech, arccsch, arccoth), by analogy with the inverse circular functions (arcsin, etc.). For a unit hyperbola (\"Lorentzian circle\") in the Lorentzian plane (pseudo-Euclidean plane of signature (1, 1)) or in the hyperbolic number plane, the hyperbolic angle measure (argument to the hyperbolic functions) is indeed the arc length of a hyperbolic arc.\nAlso common is the notation \n  \n    \n      \n        \n          sinh\n          \n            −\n            1\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\sinh ^{-1},}\n  \n \n  \n    \n      \n        \n          cosh\n          \n            −\n            1\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\cosh ^{-1},}\n  \n etc., although care must be taken to avoid misinterpretations of the superscript −1 as an exponent.  The standard convention is that \n  \n    \n      \n        \n          sinh\n          \n            −\n            1\n          \n        \n        ⁡\n        x\n      \n    \n    {\\displaystyle \\sinh ^{-1}x}\n  \n or \n  \n    \n      \n        \n          sinh\n          \n            −\n            1\n          \n        \n        ⁡\n        (\n        x\n        )\n      \n    \n    {\\displaystyle \\sinh ^{-1}(x)}\n  \n means the inverse function while \n  \n    \n      \n        (\n        sinh\n        ⁡\n        x\n        \n          )\n          \n            −\n            1\n          \n        \n      \n    \n    {\\displaystyle (\\sinh x)^{-1}}\n  \n or \n  \n    \n      \n        sinh\n        ⁡\n        (\n        x\n        \n          )\n          \n            −\n            1\n          \n        \n      \n    \n    {\\displaystyle \\sinh(x)^{-1}}\n  \n means the reciprocal \n  \n    \n      \n        1\n        \n          /\n        \n        sinh\n        ⁡\n        x\n        .\n      \n    \n    {\\displaystyle 1/\\sinh x.}\n  \n Especially inconsistent is the conventional use of positive integer superscripts to indicate an exponent rather than function composition, e.g. \n  \n    \n      \n        \n          sinh\n          \n            2\n          \n        \n        ⁡\n        x\n      \n    \n    {\\displaystyle \\sinh ^{2}x}\n  \n conventionally means \n  \n    \n      \n        (\n        sinh\n        ⁡\n        x\n        \n          )\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle (\\sinh x)^{2}}\n  \n and not \n  \n    \n      \n        sinh\n        ⁡\n        (\n ",
    "links": [
      "Academic Press",
      "Analytic continuation",
      "Analytic function",
      "Angle",
      "Arc (geometry)",
      "Arc length",
      "Area",
      "Asymptotic expansion",
      "Atan2",
      "Back-formation",
      "Branch cut",
      "Cartesian coordinates",
      "Catenary",
      "Circular sector",
      "Complex logarithm",
      "Complex number",
      "Complex plane",
      "Connected space",
      "Cubic function",
      "Differential equation",
      "Doi (identifier)",
      "Domain coloring",
      "Eberhard Zeidler (mathematician)",
      "Electromagnetic theory",
      "Encyclopedia of Mathematics",
      "Euclidean plane",
      "European Mathematical Society",
      "Exsecant",
      "Fluid dynamics",
      "Functions of a complex variable",
      "Half line",
      "Handbook of Mathematics",
      "Heat transfer",
      "Herbert Busemann",
      "Hyperbolic angle",
      "Hyperbolic functions",
      "Hyperbolic geometry",
      "Hyperbolic number",
      "Hyperbolic secant distribution",
      "Hyperbolic sector",
      "ISBN (identifier)",
      "ISO 80000-2",
      "If and only if",
      "Ilja N. Bronshtein",
      "Imaginary part",
      "Integer",
      "Inverse function",
      "Inverse trigonometric functions",
      "JSTOR (identifier)",
      "Jan Gullberg"
    ],
    "categories": [
      "Category:All articles with unsourced statements",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from December 2015",
      "Category:Inverse hyperbolic functions",
      "Category:Short description is different from Wikidata"
    ]
  },
  "Inverse trigonometric functions": {
    "title": "Inverse trigonometric functions",
    "url": "https://en.wikipedia.org/wiki/Inverse_trigonometric_functions",
    "summary": "In mathematics, the inverse trigonometric functions (occasionally also called antitrigonometric, cyclometric, or arcus functions) are the inverse functions of the trigonometric functions, under suitably restricted domains. Specifically, they are the inverses of the sine, cosine, tangent, cotangent, secant, and cosecant functions, and are used to obtain an angle from any of the angle's trigonometric ratios. Inverse trigonometric functions are widely used in engineering, navigation, physics, and geometry.",
    "content": "In mathematics, the inverse trigonometric functions (occasionally also called antitrigonometric, cyclometric, or arcus functions) are the inverse functions of the trigonometric functions, under suitably restricted domains. Specifically, they are the inverses of the sine, cosine, tangent, cotangent, secant, and cosecant functions, and are used to obtain an angle from any of the angle's trigonometric ratios. Inverse trigonometric functions are widely used in engineering, navigation, physics, and geometry.\n\nNotation\nSeveral notations for the inverse trigonometric functions exist. The most common convention is to name inverse trigonometric functions using an arc- prefix: arcsin(x), arccos(x), arctan(x), etc. (This convention is used throughout this article.)  This notation arises from the following geometric relationships:\nwhen measuring in radians, an angle of θ radians will correspond to an arc whose length is rθ, where r is the radius of the circle. Thus in the unit circle, the cosine of x function is both the arc and the angle, because the arc of a circle of radius 1 is the same as the angle. Or, \"the arc whose cosine is x\" is the same as \"the angle whose cosine is x\", because the length of the arc of the circle in radii is the same as the measurement of the angle in radians. In computer programming languages, the inverse trigonometric functions are often called by the abbreviated forms asin, acos, atan.\nThe notations sin−1(x), cos−1(x), tan−1(x), etc., as introduced by John Herschel in 1813, are often used as well in English-language sources, much more than the also established sin[−1](x), cos[−1](x), tan[−1](x) – conventions consistent with the notation of an inverse function, that is useful (for example) to define the multivalued version of each inverse trigonometric function: \n  \n    \n      \n        \n          tan\n          \n            −\n            1\n          \n        \n        ⁡\n        (\n        x\n        )\n        =\n        {\n        arctan\n        ⁡\n        (\n        x\n        )\n        +\n        π\n        k\n        ∣\n        k\n        ∈\n        \n          Z\n        \n        }\n         \n        .\n      \n    \n    {\\displaystyle \\tan ^{-1}(x)=\\{\\arctan(x)+\\pi k\\mid k\\in \\mathbb {Z} \\}~.}\n  \n However, this might appear to conflict logically with the common semantics for expressions such as sin2(x) (although only sin2 x, without parentheses, is the really common use), which refer to numeric power rather than function composition, and therefore may result in confusion between notation for the reciprocal (multiplicative inverse) and inverse function.\nThe confusion is somewhat mitigated by the fact that each of the reciprocal trigonometric functions has its own name — for example, (cos(x))−1 = sec(x). Nevertheless, certain authors advise against using it, since it is ambiguous. Another precarious convention used by a small number of authors is to use an uppercase first letter, along with a “−1” superscript: Sin−1(x), Cos−1(x), Tan−1(x), etc. Although it is intended to avoid confusion with the reciprocal, which should be represented by sin−1(x), cos−1(x), etc., or, better, by sin−1 x, cos−1 x, etc., it in turn creates yet another major source of ambiguity, especially since many popular high-level programming languages (e.g. Mathematica and MAGMA) use those very same capitalised representations for the standard trig functions, whereas others (Python, SymPy, NumPy, Matlab, MAPLE, etc.) use lower-case. \nHence, since 2009, the ISO 80000-2 standard has specified solely the \"arc\" prefix for the inverse functions.\n\nBasic concepts\nPrincipal values\nSince none of the six trigonometric functions are one-to-one, they must be restricted in order to have inverse functions. Therefore, the result ranges of the inverse functions are proper (i.e. strict) subsets of the domains of the original functions.\nFor example, using function in the sense of multivalued functions, just as the square root function \n  \n    \n      \n        y\n        =\n        \n          \n            x\n          \n        \n      \n    \n    {\\displaystyle y={\\sqrt {x}}}\n  \n could be defined from \n  \n    \n      \n        \n          y\n          \n            2\n          \n        \n        =\n        x\n        ,\n      \n    \n    {\\displaystyle y^{2}=x,}\n  \n the function \n  \n    \n      \n        y\n        =\n        arcsin\n        ⁡\n        (\n        x\n        )\n      \n    \n    {\\displaystyle y=\\arcsin(x)}\n  \n is defined so that \n  \n    \n      \n        sin\n        ⁡\n        (\n        y\n        )\n        =\n        x\n        .\n      \n    \n    {\\displaystyle \\sin(y)=x.}\n  \n For a given real number \n  \n    \n      \n        x\n        ,\n      \n    \n    {\\displaystyle x,}\n  \n with \n  \n    \n      \n        −\n        1\n        ≤\n        x\n        ≤\n        1\n        ,\n      \n    \n    {\\displaystyle -1\\leq x\\leq 1,}\n  \n there are multiple (in fact, countably infinitely many) numbers \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n such that \n  \n    \n      \n        s",
    "links": [
      "A. K. Peters",
      "Abraham de Moivre",
      "Absolute value",
      "Al-Battani",
      "Analytic function",
      "Angle sum and difference identities",
      "Anti-function",
      "Anti-sine",
      "ArXiv (identifier)",
      "Arc-sine",
      "Arcsine distribution",
      "Arctangent (disambiguation)",
      "Arg (mathematics)",
      "Argument (complex analysis)",
      "Atan2",
      "Bibcode (identifier)",
      "Binomial series",
      "Brahmagupta",
      "Branch cut",
      "Branch point",
      "C (programming language)",
      "Calculus",
      "Cambridge University Press",
      "Carl Friedrich Gauss",
      "Circular arc",
      "Complex logarithm",
      "Complex number",
      "Complex plane",
      "Cosecant",
      "Cosine",
      "Cotangent",
      "Countably infinite",
      "Degree (angle)",
      "Derivative",
      "Differentiation of trigonometric functions",
      "Doi (identifier)",
      "Domain coloring",
      "Domain of a function",
      "Dover Publications",
      "Dover Publications, Inc.",
      "Empty product",
      "Encyclopedia of Mathematics",
      "Engineering",
      "Eric W. Weisstein",
      "Euler's formula",
      "Exact trigonometric values",
      "Exsecant",
      "Felix Klein",
      "Florian Cajori",
      "François Viète"
    ],
    "categories": [
      "Category:All articles with unsourced statements",
      "Category:Articles with short description",
      "Category:Articles with unsourced statements from January 2019",
      "Category:Articles with unsourced statements from March 2020",
      "Category:CS1: long volume value",
      "Category:CS1 German-language sources (de)",
      "Category:CS1 errors: ISBN date",
      "Category:CS1 location test",
      "Category:CS1 maint: DOI inactive as of July 2025",
      "Category:Dimensionless numbers"
    ]
  },
  "Limit (mathematics)": {
    "title": "Limit (mathematics)",
    "url": "https://en.wikipedia.org/wiki/Limit_(mathematics)",
    "summary": "In mathematics, a limit is the value that a function (or sequence) approaches as the argument (or index) approaches some value. Limits of functions are essential to calculus and mathematical analysis, and are used to define continuity, derivatives, and integrals.\nThe concept of a limit of a sequence is further generalized to the concept of a limit of a topological net, and is closely related to limit and direct limit in category theory.\nThe limit inferior and limit superior provide generalizations of the concept of a limit which are particularly relevant when the limit at a point may not exist.",
    "content": "In mathematics, a limit is the value that a function (or sequence) approaches as the argument (or index) approaches some value. Limits of functions are essential to calculus and mathematical analysis, and are used to define continuity, derivatives, and integrals.\nThe concept of a limit of a sequence is further generalized to the concept of a limit of a topological net, and is closely related to limit and direct limit in category theory.\nThe limit inferior and limit superior provide generalizations of the concept of a limit which are particularly relevant when the limit at a point may not exist.\n\nNotation\nIn formulas, a limit of a function is usually written as\n\n  \n    \n      \n        \n          lim\n          \n            x\n            →\n            c\n          \n        \n        f\n        (\n        x\n        )\n        =\n        L\n        ,\n      \n    \n    {\\displaystyle \\lim _{x\\to c}f(x)=L,}\n  \n\nand is read as \"the limit of f of x as x approaches c equals L\". This means that the value of the function f can be made arbitrarily close to L, by choosing x sufficiently close to c. Alternatively, the fact that a function f approaches the limit L as x approaches c is sometimes denoted by a right arrow (→ or \n  \n    \n      \n        →\n      \n    \n    {\\displaystyle \\rightarrow }\n  \n), as in\n\n  \n    \n      \n        f\n        (\n        x\n        )\n        →\n        L\n        \n           as \n        \n        x\n        →\n        c\n        ,\n      \n    \n    {\\displaystyle f(x)\\to L{\\text{ as }}x\\to c,}\n  \n\nwhich reads \"\n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n of \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n tends to \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  \n as \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n tends to \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  \n\".\n\nHistory\nAccording to Hankel (1871), the modern concept of limit originates from Proposition X.1 of Euclid's Elements, which forms the basis of the Method of exhaustion found in Euclid and Archimedes: \"Two unequal magnitudes being set out, if from the greater there is subtracted a magnitude greater than its half, and from that which is left a magnitude greater than its half, and if this process is repeated continually, then there will be left some magnitude less than the lesser magnitude set out.\"\nGrégoire de Saint-Vincent gave the first definition of limit (terminus) of a geometric series in his work Opus Geometricum (1647): \"The terminus of a progression is the end of the series, which none progression can reach, even not if she is continued in infinity, but which she can approach nearer than a given segment.\"\nIn the Scholium to Principia in 1687, Isaac Newton had a clear definition of a limit, stating that \"Those ultimate ratios... are not actually ratios of ultimate quantities, but limits... which they can approach so closely that their difference is less than any given quantity\".\nThe modern definition of a limit goes back to Bernard Bolzano who, in 1817, developed the basics of the epsilon-delta technique to define continuous functions. However, his work remained unknown to other mathematicians until thirty years after his death.\nAugustin-Louis Cauchy in 1821, followed by Karl Weierstrass, formalized the definition of the limit of a function which became known as the (ε, δ)-definition of limit.\nThe modern notation of placing the arrow below the limit symbol is due to G. H. Hardy, who introduced it in his book A Course of Pure Mathematics in 1908.\n\nTypes of limits\nIn sequences\nReal numbers\nThe expression 0.999... should be interpreted as the limit of the sequence 0.9, 0.99, 0.999, ... and so on. This sequence can be rigorously shown to have the limit 1, and therefore this expression is meaningfully interpreted as having the value 1.\nFormally, suppose a1, a2, ... is a sequence of real numbers. When the limit of the sequence exists, the real number L is the limit of this sequence if and only if for every real number ε > 0, there exists a natural number N such that for all n > N, we have |an − L| < ε.\nThe common notation\n\n  \n    \n      \n        \n          lim\n          \n            n\n            →\n            ∞\n          \n        \n        \n          a\n          \n            n\n          \n        \n        =\n        L\n      \n    \n    {\\displaystyle \\lim _{n\\to \\infty }a_{n}=L}\n  \n\nis read as:\n\n\"The limit of an as n approaches infinity equals L\" or \"The limit as n approaches infinity of an equals L\".\nThe formal definition intuitively means that eventually, all elements of the sequence get arbitrarily close to the limit, since the absolute value |an − L| is the distance between an and L. \nNot every sequence has a limit. A sequence with a limit is called convergent; otherwise it is called divergent. One can show that a convergent sequence has only one limit.\nThe limit of a sequence and the limit of a function are closely related. On one hand, the limit as n approaches inf",
    "links": [
      "(ε, δ)-definition of limit",
      "0.999...",
      "A Course of Pure Mathematics",
      "Absolute convergence",
      "Absolute value",
      "Addison-Wesley",
      "Argument of a function",
      "Asymptotic analysis",
      "Augustin-Louis Cauchy",
      "Banach limit",
      "Basel problem",
      "Bernard Bolzano",
      "Big O notation",
      "Brooks/Cole",
      "Calculus",
      "Calculus of variations",
      "Category theory",
      "Cauchy sequence",
      "Cauchy sequences",
      "Cengage Learning",
      "Closed set",
      "Complete metric space",
      "Complex analysis",
      "Complex number",
      "Conditionally convergent",
      "Continuous function",
      "Convergence of random variables",
      "Convergence tests",
      "Convergent matrix",
      "Convergent series",
      "Derivative",
      "Differential equation",
      "Direct limit",
      "Doi (identifier)",
      "Dynamical systems",
      "Epsilon-delta",
      "Euclid's Elements",
      "Euclidean distance",
      "Fourier analysis",
      "Function (mathematics)",
      "Functional analysis",
      "Fundamental theorem of calculus",
      "G. H. Hardy",
      "Geometric series",
      "Grégoire de Saint-Vincent",
      "Harmonic analysis",
      "Hausdorff space",
      "Hermann Hankel",
      "Hypercomplex analysis",
      "Hypernatural"
    ],
    "categories": [
      "Category:Articles with short description",
      "Category:Asymptotic analysis",
      "Category:Convergence (mathematics)",
      "Category:Differential calculus",
      "Category:General topology",
      "Category:Limits (mathematics)",
      "Category:Real analysis",
      "Category:Short description is different from Wikidata"
    ]
  },
  "E (mathematical constant)": {
    "title": "E (mathematical constant)",
    "url": "https://en.wikipedia.org/wiki/E_(mathematical_constant)",
    "summary": "The number e is a mathematical constant approximately equal to 2.71828 that is the base of the natural logarithm and exponential function. It is sometimes called Euler's number, after the Swiss mathematician Leonhard Euler, though this can invite confusion with Euler numbers, or with Euler's constant, a different constant typically denoted \n  \n    \n      \n        γ\n      \n    \n    {\\displaystyle \\gamma }\n  \n. Alternatively, e can be called Napier's constant after John Napier. The Swiss mathematician Jacob Bernoulli discovered the constant while studying compound interest.\nThe number e is of great importance in mathematics, alongside 0, 1, π, and i. All five appear in one formulation of Euler's identity \n  \n    \n      \n        \n          e\n          \n            i\n            π\n          \n        \n        +\n        1\n        =\n        0\n      \n    \n    {\\displaystyle e^{i\\pi }+1=0}\n  \n and play important and recurring roles across mathematics. Like the constant π, e is irrational, meani",
    "content": "The number e is a mathematical constant approximately equal to 2.71828 that is the base of the natural logarithm and exponential function. It is sometimes called Euler's number, after the Swiss mathematician Leonhard Euler, though this can invite confusion with Euler numbers, or with Euler's constant, a different constant typically denoted \n  \n    \n      \n        γ\n      \n    \n    {\\displaystyle \\gamma }\n  \n. Alternatively, e can be called Napier's constant after John Napier. The Swiss mathematician Jacob Bernoulli discovered the constant while studying compound interest.\nThe number e is of great importance in mathematics, alongside 0, 1, π, and i. All five appear in one formulation of Euler's identity \n  \n    \n      \n        \n          e\n          \n            i\n            π\n          \n        \n        +\n        1\n        =\n        0\n      \n    \n    {\\displaystyle e^{i\\pi }+1=0}\n  \n and play important and recurring roles across mathematics. Like the constant π, e is irrational, meaning that it cannot be represented as a ratio of integers, and moreover it is transcendental, meaning that it is not a root of any non-zero polynomial with rational coefficients. To 30 decimal places, the value of e is:\n\nDefinitions\nThe number e is the limit \n\n  \n    \n      \n        \n          lim\n          \n            n\n            →\n            ∞\n          \n        \n        \n          \n            (\n            \n              1\n              +\n              \n                \n                  1\n                  n\n                \n              \n            \n            )\n          \n          \n            n\n          \n        \n        ,\n      \n    \n    {\\displaystyle \\lim _{n\\to \\infty }\\left(1+{\\frac {1}{n}}\\right)^{n},}\n  \n\nan expression that arises in the computation of compound interest.\nIt is the sum of the infinite series\n\n  \n    \n      \n        e\n        =\n        \n          ∑\n          \n            n\n            =\n            0\n          \n          \n            ∞\n          \n        \n        \n          \n            1\n            \n              n\n              !\n            \n          \n        \n        =\n        1\n        +\n        \n          \n            1\n            1\n          \n        \n        +\n        \n          \n            1\n            \n              1\n              ⋅\n              2\n            \n          \n        \n        +\n        \n          \n            1\n            \n              1\n              ⋅\n              2\n              ⋅\n              3\n            \n          \n        \n        +\n        ⋯\n        .\n      \n    \n    {\\displaystyle e=\\sum \\limits _{n=0}^{\\infty }{\\frac {1}{n!}}=1+{\\frac {1}{1}}+{\\frac {1}{1\\cdot 2}}+{\\frac {1}{1\\cdot 2\\cdot 3}}+\\cdots .}\n  \n\nIt is the unique positive number a such that the graph of the function y = ax has a slope of 1 at x = 0.\nOne has \n  \n    \n      \n        e\n        =\n        exp\n        ⁡\n        (\n        1\n        )\n        ,\n      \n    \n    {\\displaystyle e=\\exp(1),}\n  \n where \n  \n    \n      \n        exp\n      \n    \n    {\\displaystyle \\exp }\n  \n is the (natural) exponential function, the unique function that equals its own derivative and satisfies the equation \n  \n    \n      \n        exp\n        ⁡\n        (\n        0\n        )\n        =\n        1.\n      \n    \n    {\\displaystyle \\exp(0)=1.}\n  \n Since the exponential function is commonly denoted as \n  \n    \n      \n        x\n        ↦\n        \n          e\n          \n            x\n          \n        \n        ,\n      \n    \n    {\\displaystyle x\\mapsto e^{x},}\n  \n one has also\n\n  \n    \n      \n        e\n        =\n        \n          e\n          \n            1\n          \n        \n        .\n      \n    \n    {\\displaystyle e=e^{1}.}\n  \n\nThe logarithm of base b can be defined as the inverse function of the function \n  \n    \n      \n        x\n        ↦\n        \n          b\n          \n            x\n          \n        \n        .\n      \n    \n    {\\displaystyle x\\mapsto b^{x}.}\n  \n Since \n  \n    \n      \n        b\n        =\n        \n          b\n          \n            1\n          \n        \n        ,\n      \n    \n    {\\displaystyle b=b^{1},}\n  \n one has \n  \n    \n      \n        \n          log\n          \n            b\n          \n        \n        ⁡\n        b\n        =\n        1.\n      \n    \n    {\\displaystyle \\log _{b}b=1.}\n  \n The equation \n  \n    \n      \n        e\n        =\n        \n          e\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle e=e^{1}}\n  \n implies therefore that e is the base of the natural logarithm.\nThe number e can also be characterized in terms of an integral:\n\n  \n    \n      \n        \n          ∫\n          \n            1\n          \n          \n            e\n          \n        \n        \n          \n            \n              d\n              x\n            \n            x\n          \n        \n        =\n        1.\n      \n    \n    {\\displaystyle \\int _{1}^{e}{\\frac {dx}{x}}=1.}\n  \n\nFor other characterizations, see § Representations.\n\nHistory\nThe first references to the constant were published in ",
    "links": [
      "A Course of Modern Analysis",
      "Alexander Gelfond",
      "Algebraic function",
      "Algebraic geometry",
      "Algebraic independence",
      "Antiderivative",
      "Apple II",
      "Apéry's constant",
      "ArXiv (identifier)",
      "Area under the curve",
      "Arithmetic-geometric mean",
      "Asymptotic analysis",
      "Asymptotics",
      "Austin, Texas",
      "Base of a logarithm",
      "Bernoulli's inequality",
      "Bernoulli trial",
      "Binary splitting",
      "Binomial distribution",
      "Binomial theorem",
      "Bit complexity",
      "Cahen's constant",
      "Calculus",
      "Cambridge, Massachusetts",
      "Cambridge University Press",
      "Chaitin's constant",
      "Characterizations of the exponential function",
      "Charles Hermite",
      "Christiaan Huygens",
      "Christian Goldbach",
      "Clay Mathematics Institute",
      "Complex number",
      "Compound interest",
      "Computer scientist",
      "Continued fraction",
      "Continuous compounding",
      "Convergent series",
      "Daniel Shanks",
      "Davar Khoshnevisan",
      "De Moivre's formula",
      "Derangement",
      "Derivative",
      "Derivative (mathematics)",
      "Desktop computer",
      "Differential equation",
      "Digital Library of Mathematical Functions",
      "Doi (identifier)",
      "Domain of a function",
      "Don Zagier",
      "Donald Knuth"
    ],
    "categories": [
      "Category:Articles containing Latin-language text",
      "Category:Articles with short description",
      "Category:CS1 German-language sources (de)",
      "Category:Commons category link from Wikidata",
      "Category:E (mathematical constant)",
      "Category:Good articles",
      "Category:Leonhard Euler",
      "Category:Mathematical constants",
      "Category:Real transcendental numbers",
      "Category:Short description is different from Wikidata"
    ]
  }
}